[36m 
############################### DATA ACQUISITION ############################### [39m
Data has been correctly loaded from ../../config/files/dataset_paths.yaml file
Data has been correctly loaded from ../../config/files/json_paths.yaml file
Data has been correctly loaded from ../../json_dir/indexes/gene_expression_names.json file
Data has been correctly loaded from ../../data/datasets/gene_expression_and_overall_survival_dataset.csv file
DIMENSIONS:
	--> Training Set: 223
	--> Testing Set: 56
[36m 
########################### TRAINING SET MANAGEMENT ############################ [39m
[36m 
################### EXPLORATORY DATA ANALYSIS with RAW DATA #################### [39m
[36m 
############################ FEATURES PREPROCESSING ############################ [39m
ADMITTED SAMPLES VALUES:
	--> 47 samples with a label lower than 1000
	--> 48 samples with a label bigger than 3000
[36m 
############################## FEATURES SELECTION ############################## [39m
VARIANCE SELECTION:
	--> New Feature Space Dimension: 2000
CORRELATION FILTER:
	--> New Feature Space Dimension: 200
[36m 
############################ TESTING SET MANAGEMENT ############################ [39m
[36m 
################### EXPLORATORY DATA ANALYSIS with RAW DATA #################### [39m
[36m 
############################ FEATURES PREPROCESSING ############################ [39m
ADMITTED SAMPLES VALUES:
	--> 6 samples with a label lower than 1000
	--> 15 samples with a label bigger than 3000
[36m 
############################## FEATURES SELECTION ############################## [39m
TOP FEATURES SELECTION:
	--> New Feature Space Dimension: 200
[36m 
############################### SKLEARN TO TORCH ############################### [39m
[36m 
############################ HYPERPARAMETERS LISTS ############################# [39m
[36m 
################################# GRID SEARCH ################################## [39m
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2907
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2826
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7474, Mean Validation Loss: 0.5128
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2811
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3406
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7158, Mean Validation Loss: 0.5654
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2625
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.3041
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4184
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2521
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3494
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7474, Mean Validation Loss: 0.5360
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2611
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3341
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7895, Mean Validation Loss: 0.5860
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2818
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2729
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7368, Mean Validation Loss: 0.5192
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2636
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3387
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.7579, Mean Validation Loss: 0.4934
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3101
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2951
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7158, Mean Validation Loss: 0.5837
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2623
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3496
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7789, Mean Validation Loss: 0.5312
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2253
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3527
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.4676
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3040
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2952
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.4568
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3304
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3234
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7895, Mean Validation Loss: 0.5307
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3063
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3436
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.4642
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3419
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3702
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5119
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2737
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.4120
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.7684, Mean Validation Loss: 0.5465
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.9158, Mean Validation Loss: 0.2110
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2936
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7368, Mean Validation Loss: 0.5648
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3004
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.3038
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.4677
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3105
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2821
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.6211, Mean Validation Loss: 0.6251
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2961
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3106
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5037
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.7579, Mean Validation Loss: 0.3585
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3943
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.4470
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3240
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3694
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5106
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3201
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3825
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8000, Mean Validation Loss: 0.5407
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3305
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3372
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4767
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3217
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3335
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7158, Mean Validation Loss: 0.5954
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.7579, Mean Validation Loss: 0.4273
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.4571
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.6842, Mean Validation Loss: 0.6087
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.7895, Mean Validation Loss: 0.4096
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.4120
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7368, Mean Validation Loss: 0.5707
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3018
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.4151
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.4421, Mean Validation Loss: 0.6649
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3161
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3756
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7579, Mean Validation Loss: 0.5629
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3415
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.7474, Mean Validation Loss: 0.4580
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.6211, Mean Validation Loss: 0.6756
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3262
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8105, Mean Validation Loss: 0.4974
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.5474, Mean Validation Loss: 0.6778
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.4026
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8000, Mean Validation Loss: 0.4924
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.5368, Mean Validation Loss: 0.6567
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.7368, Mean Validation Loss: 0.4302
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.7263, Mean Validation Loss: 0.4948
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.5263, Mean Validation Loss: 0.6868
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5333
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.6000, Mean Validation Loss: 0.6499
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.4842, Mean Validation Loss: 0.7153
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.5789, Mean Validation Loss: 0.6116
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.5263, Mean Validation Loss: 0.7082
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.5789, Mean Validation Loss: 0.6773
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.6947, Mean Validation Loss: 0.5720
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.6526, Mean Validation Loss: 0.6231
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.5158, Mean Validation Loss: 0.6961
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.5684, Mean Validation Loss: 0.5889
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.5895, Mean Validation Loss: 0.6567
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.6000, Mean Validation Loss: 0.6743
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.6526, Mean Validation Loss: 0.6221
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.5789, Mean Validation Loss: 0.6643
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.5474, Mean Validation Loss: 0.6822
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.5263, Mean Validation Loss: 0.6473
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.4947, Mean Validation Loss: 0.7127
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.5263, Mean Validation Loss: 0.6940
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.6842, Mean Validation Loss: 0.6021
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.5158, Mean Validation Loss: 0.6966
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.5053, Mean Validation Loss: 0.6868
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.6526, Mean Validation Loss: 0.6180
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.5579, Mean Validation Loss: 0.6761
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.5474, Mean Validation Loss: 0.6967
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.4842, Mean Validation Loss: 0.7313
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.5263, Mean Validation Loss: 0.6812
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.5053, Mean Validation Loss: 0.7066
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.5368, Mean Validation Loss: 0.6580
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.5474, Mean Validation Loss: 0.6932
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.4421, Mean Validation Loss: 0.7063
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.6211, Mean Validation Loss: 0.6712
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.4842, Mean Validation Loss: 0.7041
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.5895, Mean Validation Loss: 0.6727
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.5263, Mean Validation Loss: 0.6732
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.5684, Mean Validation Loss: 0.6931
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.5263, Mean Validation Loss: 0.7073
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.4947, Mean Validation Loss: 0.6988
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.5789, Mean Validation Loss: 0.6705
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.5368, Mean Validation Loss: 0.6850
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.5474, Mean Validation Loss: 0.6887
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.6316, Mean Validation Loss: 0.6733
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.4737, Mean Validation Loss: 0.7292
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.5158, Mean Validation Loss: 0.6868
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.6105, Mean Validation Loss: 0.6739
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.4316, Mean Validation Loss: 0.7211
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.4421, Mean Validation Loss: 0.7142
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.4737, Mean Validation Loss: 0.7137
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.4842, Mean Validation Loss: 0.7011
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2258
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2177
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8000, Mean Validation Loss: 0.3740
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8211, Mean Validation Loss: 0.2747
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2693
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3342
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2679
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.3035
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8211, Mean Validation Loss: 0.4340
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2646
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2581
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2635
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2529
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2303
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.9053, Mean Validation Loss: 0.3116
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2512
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2629
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3118
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2493
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2719
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2634
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2679
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2484
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2949
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2821
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3332
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3544
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.9158, Mean Validation Loss: 0.2441
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2559
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2940
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2768
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2423
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3196
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2925
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2700
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8105, Mean Validation Loss: 0.3543
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2494
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2702
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3729
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2343
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3244
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7474, Mean Validation Loss: 0.4372
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3019
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3087
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3503
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2501
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2762
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3197
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2761
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2682
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3142
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2857
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2587
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3454
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2606
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2567
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3768
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2441
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2576
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7895, Mean Validation Loss: 0.3974
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2795
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2425
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3155
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2650
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2816
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3484
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2817
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2945
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3863
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2637
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2713
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8947, Mean Validation Loss: 0.3376
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2709
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2837
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3951
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2566
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2674
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3516
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2617
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2932
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4519
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2845
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3079
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8105, Mean Validation Loss: 0.4985
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3412
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.3164
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.4639
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.7895, Mean Validation Loss: 0.3890
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.3150
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7579, Mean Validation Loss: 0.5592
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3097
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3212
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.4247
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3399
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2992
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7579, Mean Validation Loss: 0.5360
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.4601
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8000, Mean Validation Loss: 0.5506
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7053, Mean Validation Loss: 0.6331
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.7684, Mean Validation Loss: 0.5212
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.7368, Mean Validation Loss: 0.5697
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.6632, Mean Validation Loss: 0.6401
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8105, Mean Validation Loss: 0.4942
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.5418
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.6947, Mean Validation Loss: 0.6337
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.4855
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.7684, Mean Validation Loss: 0.5542
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7368, Mean Validation Loss: 0.6342
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.5328
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.6632, Mean Validation Loss: 0.6328
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.6842, Mean Validation Loss: 0.6466
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5569
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.6947, Mean Validation Loss: 0.6012
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.6842, Mean Validation Loss: 0.6494
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.7368, Mean Validation Loss: 0.5790
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.7158, Mean Validation Loss: 0.6084
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.5263, Mean Validation Loss: 0.6746
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.6737, Mean Validation Loss: 0.5819
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.7895, Mean Validation Loss: 0.6186
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.6737, Mean Validation Loss: 0.6645
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.7579, Mean Validation Loss: 0.6007
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.6211, Mean Validation Loss: 0.6615
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.4842, Mean Validation Loss: 0.6965
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.6421, Mean Validation Loss: 0.6235
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.6000, Mean Validation Loss: 0.6559
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.5368, Mean Validation Loss: 0.6711
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.7158, Mean Validation Loss: 0.5940
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.6526, Mean Validation Loss: 0.6285
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.4842, Mean Validation Loss: 0.7107
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.7789, Mean Validation Loss: 0.6025
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.6421, Mean Validation Loss: 0.6347
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.6000, Mean Validation Loss: 0.6663
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.6842, Mean Validation Loss: 0.6303
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.6737, Mean Validation Loss: 0.6563
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.6000, Mean Validation Loss: 0.6791
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.6000, Mean Validation Loss: 0.6574
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.5158, Mean Validation Loss: 0.6824
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.5158, Mean Validation Loss: 0.6830
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.5684, Mean Validation Loss: 0.6566
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.6000, Mean Validation Loss: 0.6613
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.5368, Mean Validation Loss: 0.6878
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.5053, Mean Validation Loss: 0.6753
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.6000, Mean Validation Loss: 0.6632
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.4316, Mean Validation Loss: 0.7103
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2676
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2509
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2605
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2480
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2504
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8211, Mean Validation Loss: 0.3049
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2808
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2330
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2805
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2554
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.2669
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2982
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2640
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2165
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2870
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2222
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8105, Mean Validation Loss: 0.2906
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2269
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2341
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2226
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2581
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2065
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2670
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2546
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2700
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2692
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2678
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2384
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2695
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2418
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2652
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2225
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3214
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2455
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2203
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2314
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2399
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2943
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2708
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2458
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2661
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2744
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2552
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2800
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2864
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2713
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2707
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2403
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3029
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3037
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2960
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.9263, Mean Validation Loss: 0.2605
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2502
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2803
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2636
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2969
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2956
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2536
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2878
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2608
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2717
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.9158, Mean Validation Loss: 0.2251
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3097
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2597
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2556
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2669
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2279
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2722
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2595
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2724
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2776
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2469
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2779
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2512
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2800
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2966
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2508
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2791
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2740
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2798
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2519
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2796
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2719
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2598
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2732
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2798
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.3048
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3220
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2720
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7789, Mean Validation Loss: 0.4091
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2836
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2947
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3079
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2740
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2653
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3192
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3563
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4576
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7895, Mean Validation Loss: 0.6106
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3406
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.4648
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7684, Mean Validation Loss: 0.5891
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3675
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.4800
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.7368, Mean Validation Loss: 0.6186
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3577
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4491
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8105, Mean Validation Loss: 0.6005
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8211, Mean Validation Loss: 0.4580
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8000, Mean Validation Loss: 0.5516
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7263, Mean Validation Loss: 0.6344
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4714
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8105, Mean Validation Loss: 0.5514
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7158, Mean Validation Loss: 0.6286
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8000, Mean Validation Loss: 0.4642
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8000, Mean Validation Loss: 0.5528
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.7579, Mean Validation Loss: 0.6317
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8211, Mean Validation Loss: 0.4758
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8105, Mean Validation Loss: 0.5596
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.6842, Mean Validation Loss: 0.6414
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8211, Mean Validation Loss: 0.5232
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.6947, Mean Validation Loss: 0.5925
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7053, Mean Validation Loss: 0.6423
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8105, Mean Validation Loss: 0.5322
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.6526, Mean Validation Loss: 0.6178
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7263, Mean Validation Loss: 0.6497
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8105, Mean Validation Loss: 0.5640
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.5921
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.7684, Mean Validation Loss: 0.6392
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.7684, Mean Validation Loss: 0.5443
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.6000
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7158, Mean Validation Loss: 0.6581
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.7895, Mean Validation Loss: 0.6013
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.6632, Mean Validation Loss: 0.6364
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.6105, Mean Validation Loss: 0.6629
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.6211, Mean Validation Loss: 0.6365
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.6105, Mean Validation Loss: 0.6339
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.5368, Mean Validation Loss: 0.6666
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.6632, Mean Validation Loss: 0.6301
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.6947, Mean Validation Loss: 0.6462
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.6421, Mean Validation Loss: 0.6675
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8105, Mean Validation Loss: 0.5892
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.6737, Mean Validation Loss: 0.6540
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.5474, Mean Validation Loss: 0.6777
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2317
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2573
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2610
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2708
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8000, Mean Validation Loss: 0.2627
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3231
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3191
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2565
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2702
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2598
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2543
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2607
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2510
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2985
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2652
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2207
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2305
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2315
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2626
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2169
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3009
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2609
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2277
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2525
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2612
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2589
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2881
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2823
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2285
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8211, Mean Validation Loss: 0.3016
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3078
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2148
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2455
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2520
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2552
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2377
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2099
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2418
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2633
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2226
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2429
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2784
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2966
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2654
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2397
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2694
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2648
	--> Hidden Size: [64, 32], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3244
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2457
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2585
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2785
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2727
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2384
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2338
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2776
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2484
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2496
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2596
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2464
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2795
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2532
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2590
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2457
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2962
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2428
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2945
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2513
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2462
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2519
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2996
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2490
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2748
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2528
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2400
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2653
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2708
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2720
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2662
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2775
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2823
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2783
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2713
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2887
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2798
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2983
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2780
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2654
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2485
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2666
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2463
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2513
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2701
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2788
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2631
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2504
	--> Hidden Size: [64, 32], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2835
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2941
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3400
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4701
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2884
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3624
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8105, Mean Validation Loss: 0.5139
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2897
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3288
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4909
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2810
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3545
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.4979
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3480
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4313
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8000, Mean Validation Loss: 0.5707
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3508
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.4309
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8105, Mean Validation Loss: 0.5695
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3365
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4212
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5777
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.3407
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.4325
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7895, Mean Validation Loss: 0.5730
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4307
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.5050
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7684, Mean Validation Loss: 0.6272
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.4189
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.5361
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7684, Mean Validation Loss: 0.6083
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.4535
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.5295
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.7368, Mean Validation Loss: 0.6268
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4373
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.5234
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.7053, Mean Validation Loss: 0.6316
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8211, Mean Validation Loss: 0.5639
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5833
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.6737, Mean Validation Loss: 0.6376
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.5209
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.7579, Mean Validation Loss: 0.5986
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7263, Mean Validation Loss: 0.6522
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.5367
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.5927
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.7263, Mean Validation Loss: 0.6545
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.5513
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5898
	--> Hidden Size: [64, 32], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.6632, Mean Validation Loss: 0.6559
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8211, Mean Validation Loss: 0.3406
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8105, Mean Validation Loss: 0.3885
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2597
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.7895, Mean Validation Loss: 0.3121
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8105, Mean Validation Loss: 0.3201
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3243
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8105, Mean Validation Loss: 0.3889
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8000, Mean Validation Loss: 0.3025
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3009
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3317
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2812
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3164
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2297
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2652
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2692
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2385
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.3242
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7895, Mean Validation Loss: 0.2775
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2500
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.2501
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2968
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2915
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.2702
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2712
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2860
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2866
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8211, Mean Validation Loss: 0.2842
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2697
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3052
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3465
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2646
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2790
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2627
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2673
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2498
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2441
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2850
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2350
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2817
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2490
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2530
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.3119
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2366
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.2958
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2951
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2766
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2559
	--> Hidden Size: [128, 64], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3023
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2522
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2608
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2666
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2930
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2668
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2658
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2763
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2514
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2663
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2367
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2535
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2754
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2814
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2438
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2731
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2764
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2794
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2673
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2525
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2855
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2582
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2571
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2548
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2634
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2428
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2662
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2194
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2808
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2799
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2811
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2606
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2732
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2773
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2614
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2768
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2840
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2672
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2563
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2399
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2635
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2692
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2854
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.2724
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2828
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2622
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.9158, Mean Validation Loss: 0.2676
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2756
	--> Hidden Size: [128, 64], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.2731
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3268
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2746
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3767
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2845
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.3118
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3531
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2921
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.2699
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3840
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2671
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2759
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3790
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8316, Mean Validation Loss: 0.2984
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3323
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4550
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.2953
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3409
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8737, Mean Validation Loss: 0.4570
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.9053, Mean Validation Loss: 0.2659
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3248
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.4659
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.2749
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3127
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8421, Mean Validation Loss: 0.4728
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.3354
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4045
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.5415
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8421, Mean Validation Loss: 0.3473
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8211, Mean Validation Loss: 0.4200
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.8632, Mean Validation Loss: 0.5359
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8632, Mean Validation Loss: 0.3342
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8737, Mean Validation Loss: 0.4116
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8526, Mean Validation Loss: 0.5658
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8947, Mean Validation Loss: 0.3325
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.4092
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5483
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4306
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.5238
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Mean Accuracy: 0.7579, Mean Validation Loss: 0.6068
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4277
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.5, Mean Accuracy: 0.8632, Mean Validation Loss: 0.4969
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.7, Mean Accuracy: 0.7895, Mean Validation Loss: 0.6129
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Mean Accuracy: 0.8526, Mean Validation Loss: 0.4300
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Mean Accuracy: 0.8316, Mean Validation Loss: 0.5171
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Mean Accuracy: 0.8211, Mean Validation Loss: 0.5987
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Mean Accuracy: 0.8842, Mean Validation Loss: 0.4308
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Mean Accuracy: 0.8421, Mean Validation Loss: 0.5040
	--> Hidden Size: [128, 64], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Mean Accuracy: 0.8000, Mean Validation Loss: 0.6113

Best value for each hyperparameter:
	--> Hidden Size: [8, 4],
	--> Learning Rate: 0.01,
	--> Batch Size: 64,
	--> Alpha: 0.0001,
	--> Dropout: 0.3
	--> Best Mean Accuracy: 0.9158, Best Mean Validation Loss: 0.2110
[36m 
################################### TRAINING ################################### [39m

Fold 1/5
	--> Epoch [1/100], Loss: 0.6777, Validation Loss: 0.6606
	--> Epoch [2/100], Loss: 0.6731, Validation Loss: 0.6285
	--> Epoch [3/100], Loss: 0.6039, Validation Loss: 0.5966
	--> Epoch [4/100], Loss: 0.6069, Validation Loss: 0.5913
	--> Epoch [5/100], Loss: 0.5482, Validation Loss: 0.5870
	--> Epoch [6/100], Loss: 0.6634, Validation Loss: 0.5825
	--> Epoch [7/100], Loss: 0.6276, Validation Loss: 0.5820
	--> Epoch [8/100], Loss: 0.4467, Validation Loss: 0.5814
	--> Epoch [9/100], Loss: 0.6659, Validation Loss: 0.5812
	--> Epoch [10/100], Loss: 0.5536, Validation Loss: 0.5811
	--> Epoch [11/100], Loss: 0.5473, Validation Loss: 0.5811
	--> Epoch [12/100], Loss: 0.5402, Validation Loss: 0.5810
	--> Epoch [13/100], Loss: 0.5550, Validation Loss: 0.5810
	--> Epoch [14/100], Loss: 0.5874, Validation Loss: 0.5810
	--> Epoch [15/100], Loss: 0.6457, Validation Loss: 0.5810
	--> Epoch [16/100], Loss: 0.5573, Validation Loss: 0.5810
	--> Epoch [17/100], Loss: 0.5752, Validation Loss: 0.5810
	--> Epoch [18/100], Loss: 0.5433, Validation Loss: 0.5810
	--> Epoch [19/100], Loss: 0.6489, Validation Loss: 0.5810
	--> Epoch [20/100], Loss: 0.5812, Validation Loss: 0.5810
	--> Epoch [21/100], Loss: 0.6201, Validation Loss: 0.5810
	--> Epoch [22/100], Loss: 0.6408, Validation Loss: 0.5810
Early stopping
	--> Training for Fold 1 took 0.14987778663635254 sec

Fold 2/5
	--> Epoch [1/100], Loss: 0.6026, Validation Loss: 0.6158
	--> Epoch [2/100], Loss: 0.5619, Validation Loss: 0.5580
	--> Epoch [3/100], Loss: 0.6264, Validation Loss: 0.5406
	--> Epoch [4/100], Loss: 0.4637, Validation Loss: 0.5379
	--> Epoch [5/100], Loss: 0.4384, Validation Loss: 0.5317
	--> Epoch [6/100], Loss: 0.4723, Validation Loss: 0.5261
	--> Epoch [7/100], Loss: 0.4285, Validation Loss: 0.5257
	--> Epoch [8/100], Loss: 0.5178, Validation Loss: 0.5252
	--> Epoch [9/100], Loss: 0.6541, Validation Loss: 0.5251
	--> Epoch [10/100], Loss: 0.3981, Validation Loss: 0.5250
	--> Epoch [11/100], Loss: 0.6041, Validation Loss: 0.5249
	--> Epoch [12/100], Loss: 0.3954, Validation Loss: 0.5249
	--> Epoch [13/100], Loss: 0.4232, Validation Loss: 0.5249
	--> Epoch [14/100], Loss: 0.3406, Validation Loss: 0.5248
	--> Epoch [15/100], Loss: 0.4747, Validation Loss: 0.5248
	--> Epoch [16/100], Loss: 0.4534, Validation Loss: 0.5248
	--> Epoch [17/100], Loss: 0.4193, Validation Loss: 0.5248
	--> Epoch [18/100], Loss: 0.5437, Validation Loss: 0.5248
	--> Epoch [19/100], Loss: 0.4147, Validation Loss: 0.5248
	--> Epoch [20/100], Loss: 0.3662, Validation Loss: 0.5248
	--> Epoch [21/100], Loss: 0.3365, Validation Loss: 0.5248
	--> Epoch [22/100], Loss: 0.2933, Validation Loss: 0.5248
	--> Epoch [23/100], Loss: 0.5433, Validation Loss: 0.5248
Early stopping
	--> Training for Fold 2 took 0.2021489143371582 sec

Fold 3/5
	--> Epoch [1/100], Loss: 0.6879, Validation Loss: 0.6907
	--> Epoch [2/100], Loss: 0.6640, Validation Loss: 0.6628
	--> Epoch [3/100], Loss: 0.5693, Validation Loss: 0.6234
	--> Epoch [4/100], Loss: 0.5710, Validation Loss: 0.6204
	--> Epoch [5/100], Loss: 0.5601, Validation Loss: 0.6193
	--> Epoch [6/100], Loss: 0.5134, Validation Loss: 0.6177
	--> Epoch [7/100], Loss: 0.6769, Validation Loss: 0.6177
	--> Epoch [8/100], Loss: 0.4955, Validation Loss: 0.6175
	--> Epoch [9/100], Loss: 0.5848, Validation Loss: 0.6172
	--> Epoch [10/100], Loss: 0.6764, Validation Loss: 0.6172
	--> Epoch [11/100], Loss: 0.5083, Validation Loss: 0.6172
	--> Epoch [12/100], Loss: 0.6681, Validation Loss: 0.6172
	--> Epoch [13/100], Loss: 0.3780, Validation Loss: 0.6172
	--> Epoch [14/100], Loss: 0.5412, Validation Loss: 0.6172
	--> Epoch [15/100], Loss: 0.5792, Validation Loss: 0.6172
	--> Epoch [16/100], Loss: 0.6002, Validation Loss: 0.6172
	--> Epoch [17/100], Loss: 0.5811, Validation Loss: 0.6172
	--> Epoch [18/100], Loss: 0.4984, Validation Loss: 0.6172
	--> Epoch [19/100], Loss: 0.6144, Validation Loss: 0.6172
	--> Epoch [20/100], Loss: 0.6812, Validation Loss: 0.6172
	--> Epoch [21/100], Loss: 0.6229, Validation Loss: 0.6172
Early stopping
	--> Training for Fold 3 took 0.18889260292053223 sec

Fold 4/5
	--> Epoch [1/100], Loss: 0.6587, Validation Loss: 0.6170
	--> Epoch [2/100], Loss: 0.6857, Validation Loss: 0.5938
	--> Epoch [3/100], Loss: 0.5765, Validation Loss: 0.5323
	--> Epoch [4/100], Loss: 0.5593, Validation Loss: 0.5305
	--> Epoch [5/100], Loss: 0.7155, Validation Loss: 0.5329
	--> Epoch [6/100], Loss: 0.5865, Validation Loss: 0.5314
Early stopping
	--> Training for Fold 4 took 0.04751229286193848 sec

Fold 5/5
	--> Epoch [1/100], Loss: 0.6853, Validation Loss: 0.6647
	--> Epoch [2/100], Loss: 0.6794, Validation Loss: 0.6250
	--> Epoch [3/100], Loss: 0.5475, Validation Loss: 0.5342
	--> Epoch [4/100], Loss: 0.5321, Validation Loss: 0.5266
	--> Epoch [5/100], Loss: 0.4146, Validation Loss: 0.5188
	--> Epoch [6/100], Loss: 0.5100, Validation Loss: 0.5130
	--> Epoch [7/100], Loss: 0.5391, Validation Loss: 0.5125
	--> Epoch [8/100], Loss: 0.4999, Validation Loss: 0.5118
	--> Epoch [9/100], Loss: 0.4699, Validation Loss: 0.5117
	--> Epoch [10/100], Loss: 0.5373, Validation Loss: 0.5116
	--> Epoch [11/100], Loss: 0.4361, Validation Loss: 0.5115
	--> Epoch [12/100], Loss: 0.5610, Validation Loss: 0.5115
	--> Epoch [13/100], Loss: 0.4554, Validation Loss: 0.5115
	--> Epoch [14/100], Loss: 0.5284, Validation Loss: 0.5115
	--> Epoch [15/100], Loss: 0.5484, Validation Loss: 0.5115
	--> Epoch [16/100], Loss: 0.4183, Validation Loss: 0.5115
	--> Epoch [17/100], Loss: 0.5229, Validation Loss: 0.5115
	--> Epoch [18/100], Loss: 0.5445, Validation Loss: 0.5115
	--> Epoch [19/100], Loss: 0.5213, Validation Loss: 0.5115
	--> Epoch [20/100], Loss: 0.4256, Validation Loss: 0.5115
	--> Epoch [21/100], Loss: 0.5225, Validation Loss: 0.5115
	--> Epoch [22/100], Loss: 0.4544, Validation Loss: 0.5115
	--> Epoch [23/100], Loss: 0.5756, Validation Loss: 0.5115
Early stopping
	--> Training for Fold 5 took 0.20435523986816406 sec

Best validation loss across all folds: 0.5115
[36m 
################################### TESTING #################################### [39m
	--> Testing took 0.002170562744140625 sec
	--> Final Accuracy: 0.7143
