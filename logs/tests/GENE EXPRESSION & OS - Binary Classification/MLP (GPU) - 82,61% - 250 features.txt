[36m 
############################### DATA ACQUISITION ############################### [39m
Data has been correctly loaded from ../../config/files/dataset_paths.yaml file
Data has been correctly loaded from ../../config/files/json_paths.yaml file
Data has been correctly loaded from ../../json_dir/indexes/gene_expression_names.json file
Data has been correctly loaded from ../../data/datasets/gene_expression_and_overall_survival_dataset.csv file
DIMENSIONS:
	--> Training Set: 223
	--> Testing Set: 56
[36m 
########################### TRAINING SET MANAGEMENT ############################ [39m
[36m 
################### EXPLORATORY DATA ANALYSIS with RAW DATA #################### [39m
[36m 
############################ FEATURES PREPROCESSING ############################ [39m
ADMITTED SAMPLES VALUES:
	--> 43 samples with a label lower than 1000
	--> 50 samples with a label bigger than 3000
[36m 
############################## FEATURES SELECTION ############################## [39m
VARIANCE SELECTION:
	--> New Feature Space Dimension: 2000
CORRELATION FILTER:
	--> New Feature Space Dimension: 250
[36m 
############################ TESTING SET MANAGEMENT ############################ [39m
[36m 
################### EXPLORATORY DATA ANALYSIS with RAW DATA #################### [39m
[36m 
############################ FEATURES PREPROCESSING ############################ [39m
ADMITTED SAMPLES VALUES:
	--> 10 samples with a label lower than 1000
	--> 13 samples with a label bigger than 3000
[36m 
############################## FEATURES SELECTION ############################## [39m
TOP FEATURES SELECTION:
	--> New Feature Space Dimension: 250
[36m 
############################### SKLEARN TO TORCH ############################### [39m
[36m 
################################# GRID SEARCH ################################## [39m

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.3874, Validation Loss: 0.4741
	--> Epoch [2/100], Loss: 0.0000, Validation Loss: 0.3106
	--> Epoch [3/100], Loss: 0.0000, Validation Loss: 0.8562
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.3635
	--> Epoch [5/100], Loss: 0.0197, Validation Loss: 0.4837
Early stopping
	--> Training for Fold 1 took 0.19580745697021484 sec, using 5 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.0902, Validation Loss: 0.5285
	--> Epoch [2/100], Loss: 0.0000, Validation Loss: 7.1422
	--> Epoch [3/100], Loss: 0.0000, Validation Loss: 7.6071
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 2.1873
Early stopping
	--> Training for Fold 2 took 0.2040855884552002 sec, using 4 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7592, Validation Loss: 1.5350
	--> Epoch [2/100], Loss: 0.3142, Validation Loss: 0.6436
	--> Epoch [3/100], Loss: 0.0105, Validation Loss: 0.5947
	--> Epoch [4/100], Loss: 0.0005, Validation Loss: 10.6369
	--> Epoch [5/100], Loss: 2.4117, Validation Loss: 6.3176
	--> Epoch [6/100], Loss: 0.0148, Validation Loss: 7.9370
Early stopping
	--> Training for Fold 3 took 0.3074815273284912 sec, using 6 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 2.1239, Validation Loss: 0.5761
	--> Epoch [2/100], Loss: 2.4478, Validation Loss: 3.8229
	--> Epoch [3/100], Loss: 2.0161, Validation Loss: 0.5743
	--> Epoch [4/100], Loss: 3.3333, Validation Loss: 1.2066
	--> Epoch [5/100], Loss: 3.4274, Validation Loss: 1.2823
	--> Epoch [6/100], Loss: 0.0220, Validation Loss: 3.6007
Early stopping
	--> Training for Fold 4 took 0.3200533390045166 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 2.8279, Validation Loss: 1.7901
	--> Epoch [2/100], Loss: 0.0257, Validation Loss: 2.8272
	--> Epoch [3/100], Loss: 0.0727, Validation Loss: 1.5914
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 3.1765
	--> Epoch [5/100], Loss: 0.2130, Validation Loss: 1.7031
	--> Epoch [6/100], Loss: 0.0067, Validation Loss: 1.1731
	--> Epoch [7/100], Loss: 2.0944, Validation Loss: 1.9911
	--> Epoch [8/100], Loss: 0.0572, Validation Loss: 2.0017
	--> Epoch [9/100], Loss: 0.0618, Validation Loss: 0.7267
	--> Epoch [10/100], Loss: 0.0723, Validation Loss: 0.5972
	--> Epoch [11/100], Loss: 5.3925, Validation Loss: 1.7065
	--> Epoch [12/100], Loss: 0.0385, Validation Loss: 0.4351
	--> Epoch [13/100], Loss: 0.0540, Validation Loss: 1.4805
	--> Epoch [14/100], Loss: 0.0861, Validation Loss: 0.4838
	--> Epoch [15/100], Loss: 1.3851, Validation Loss: 0.7011
Early stopping
	--> Training for Fold 5 took 0.8548336029052734 sec, using 15 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 9.5434
	--> Final training Epoch [2/6], Loss: 4.0642
	--> Final training Epoch [3/6], Loss: 2.1140
	--> Final training Epoch [4/6], Loss: 0.1771
	--> Final training Epoch [5/6], Loss: 0.0132
	--> Final training Epoch [6/6], Loss: 0.0032

Final training took 0.4635465145111084 sec

TESTING
	--> Testing took 0.0106 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.5042
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8076, Validation Loss: 1.7787,  Current Best Accuracy: 0.8076,  Current Best Validation Loss: 1.7787
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7608, Validation Loss: 2.2216,  Current Best Accuracy: 0.8076,  Current Best Validation Loss: 1.7787
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7427, Validation Loss: 3.6950,  Current Best Accuracy: 0.8076,  Current Best Validation Loss: 1.7787

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5004, Validation Loss: 0.2449
	--> Epoch [2/100], Loss: 0.9790, Validation Loss: 0.7594
	--> Epoch [3/100], Loss: 12.3879, Validation Loss: 0.2886
	--> Epoch [4/100], Loss: 0.3049, Validation Loss: 0.5328
Early stopping
	--> Training for Fold 1 took 0.2795066833496094 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.4257, Validation Loss: 2.8542
	--> Epoch [2/100], Loss: 11.5614, Validation Loss: 1.2229
	--> Epoch [3/100], Loss: 0.0195, Validation Loss: 0.6081
	--> Epoch [4/100], Loss: 0.1331, Validation Loss: 0.4196
	--> Epoch [5/100], Loss: 0.1355, Validation Loss: 0.6955
	--> Epoch [6/100], Loss: 0.0001, Validation Loss: 6.2846
	--> Epoch [7/100], Loss: 0.1412, Validation Loss: 5.1489
Early stopping
	--> Training for Fold 2 took 0.4247467517852783 sec, using 7 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 2.8275, Validation Loss: 4.5389
	--> Epoch [2/100], Loss: 0.1878, Validation Loss: 0.9031
	--> Epoch [3/100], Loss: 4.3043, Validation Loss: 2.4482
	--> Epoch [4/100], Loss: 0.0235, Validation Loss: 2.9457
	--> Epoch [5/100], Loss: 0.0979, Validation Loss: 1.8599
Early stopping
	--> Training for Fold 3 took 0.31568241119384766 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 2.0021, Validation Loss: 1.7524
	--> Epoch [2/100], Loss: 0.2595, Validation Loss: 1.2404
	--> Epoch [3/100], Loss: 0.1621, Validation Loss: 2.2779
	--> Epoch [4/100], Loss: 0.1082, Validation Loss: 4.9852
	--> Epoch [5/100], Loss: 0.1623, Validation Loss: 1.6081
Early stopping
	--> Training for Fold 4 took 0.3355579376220703 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4542, Validation Loss: 0.5552
	--> Epoch [2/100], Loss: 4.3077, Validation Loss: 0.3569
	--> Epoch [3/100], Loss: 0.3301, Validation Loss: 4.0456
	--> Epoch [4/100], Loss: 0.0233, Validation Loss: 2.1067
	--> Epoch [5/100], Loss: 0.0080, Validation Loss: 0.9381
Early stopping
	--> Training for Fold 5 took 0.31790781021118164 sec, using 5 epochs

Median number of epochs used: 5 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/5], Loss: 0.6766
	--> Final training Epoch [2/5], Loss: 0.9488
	--> Final training Epoch [3/5], Loss: 0.7152
	--> Final training Epoch [4/5], Loss: 0.1951
	--> Final training Epoch [5/5], Loss: 0.3047

Final training took 0.4513571262359619 sec

TESTING
	--> Testing took 0.0178 sec
	--> Final Accuracy: 0.4783
	--> Final Loss: 4.5785
	--> Final Precision: 0.5455
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5000
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7327, Validation Loss: 1.2790,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7544, Validation Loss: 3.8014,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7965, Validation Loss: 3.4808,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5883, Validation Loss: 4.0848,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7310, Validation Loss: 2.4896,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7193, Validation Loss: 3.0395,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6743, Validation Loss: 4.7675,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 2.1086,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 2.3906,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6579, Validation Loss: 2.0475,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6544, Validation Loss: 3.5589,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6006, Validation Loss: 4.7097,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6632, Validation Loss: 4.0054,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7544, Validation Loss: 6.8127,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7193, Validation Loss: 5.1672,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7421, Validation Loss: 3.8345,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8064, Validation Loss: 4.3270,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 2.7276,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.0224, Validation Loss: 0.4603
	--> Epoch [2/100], Loss: 0.3875, Validation Loss: 0.2308
	--> Epoch [3/100], Loss: 0.0001, Validation Loss: 0.8524
	--> Epoch [4/100], Loss: 0.2034, Validation Loss: 1.8237
	--> Epoch [5/100], Loss: 0.0357, Validation Loss: 3.7037
Early stopping
	--> Training for Fold 1 took 0.24410510063171387 sec, using 5 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 3.5149, Validation Loss: 2.5414
	--> Epoch [2/100], Loss: 0.0019, Validation Loss: 2.0388
	--> Epoch [3/100], Loss: 26.6326, Validation Loss: 4.5862
	--> Epoch [4/100], Loss: 0.6602, Validation Loss: 15.8181
	--> Epoch [5/100], Loss: 0.0837, Validation Loss: 2.3233
Early stopping
	--> Training for Fold 2 took 0.22856688499450684 sec, using 5 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4077, Validation Loss: 3.0164
	--> Epoch [2/100], Loss: 10.0287, Validation Loss: 0.6227
	--> Epoch [3/100], Loss: 0.4400, Validation Loss: 2.7295
	--> Epoch [4/100], Loss: 0.3512, Validation Loss: 0.9129
	--> Epoch [5/100], Loss: 0.2999, Validation Loss: 2.7794
Early stopping
	--> Training for Fold 3 took 0.23814606666564941 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.0310, Validation Loss: 1.3779
	--> Epoch [2/100], Loss: 1.7737, Validation Loss: 1.7283
	--> Epoch [3/100], Loss: 2.0724, Validation Loss: 6.5791
	--> Epoch [4/100], Loss: 0.6359, Validation Loss: 1.2934
	--> Epoch [5/100], Loss: 0.1231, Validation Loss: 3.1164
	--> Epoch [6/100], Loss: 0.0665, Validation Loss: 1.7314
	--> Epoch [7/100], Loss: 0.1115, Validation Loss: 1.6757
Early stopping
	--> Training for Fold 4 took 0.3612358570098877 sec, using 7 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 1.4959, Validation Loss: 0.7091
	--> Epoch [2/100], Loss: 2.7643, Validation Loss: 0.4176
	--> Epoch [3/100], Loss: 0.0454, Validation Loss: 2.5836
	--> Epoch [4/100], Loss: 0.0422, Validation Loss: 0.9366
	--> Epoch [5/100], Loss: 0.0379, Validation Loss: 0.7307
Early stopping
	--> Training for Fold 5 took 0.26818156242370605 sec, using 5 epochs

Median number of epochs used: 5 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/5], Loss: 0.9723
	--> Final training Epoch [2/5], Loss: 0.9923
	--> Final training Epoch [3/5], Loss: 0.1340
	--> Final training Epoch [4/5], Loss: 0.1918
	--> Final training Epoch [5/5], Loss: 0.9669

Final training took 0.2949957847595215 sec

TESTING
	--> Testing took 0.0094 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 6.5333
	--> Final Precision: 0.8750
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7205, Validation Loss: 1.1382,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6421, Validation Loss: 4.2033,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7725, Validation Loss: 3.2228,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7187, Validation Loss: 3.0058,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7298, Validation Loss: 2.8215,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6854, Validation Loss: 5.2351,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6895, Validation Loss: 5.0003,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7327, Validation Loss: 3.3332,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 2.9983,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7731, Validation Loss: 2.4701,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 2.7607,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7620, Validation Loss: 1.9445,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7053, Validation Loss: 4.1615,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7532, Validation Loss: 3.9406,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6351, Validation Loss: 9.4727,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7392, Validation Loss: 4.3998,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 4.9774,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 2.4035,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6573, Validation Loss: 6.8039,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6865, Validation Loss: 3.9106,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7404, Validation Loss: 4.3783,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6211, Validation Loss: 4.6127,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6889, Validation Loss: 6.0942,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7632, Validation Loss: 2.4557,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7725, Validation Loss: 1.6448,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7532, Validation Loss: 3.2839,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 1.5214, Validation Loss: 1.6487
	--> Epoch [2/100], Loss: 0.8239, Validation Loss: 0.4689
	--> Epoch [3/100], Loss: 0.0082, Validation Loss: 0.4728
	--> Epoch [4/100], Loss: 0.4028, Validation Loss: 0.4590
	--> Epoch [5/100], Loss: 0.0074, Validation Loss: 0.4883
	--> Epoch [6/100], Loss: 0.0008, Validation Loss: 1.9539
	--> Epoch [7/100], Loss: 0.0455, Validation Loss: 0.5652
Early stopping
	--> Training for Fold 1 took 0.15714192390441895 sec, using 7 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.0393, Validation Loss: 1.3233
	--> Epoch [2/100], Loss: 3.2700, Validation Loss: 0.5901
	--> Epoch [3/100], Loss: 0.3814, Validation Loss: 7.4849
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.9090
	--> Epoch [5/100], Loss: 0.0000, Validation Loss: 0.3200
	--> Epoch [6/100], Loss: 0.0000, Validation Loss: 0.8844
	--> Epoch [7/100], Loss: 0.1346, Validation Loss: 1.9245
	--> Epoch [8/100], Loss: 0.0000, Validation Loss: 7.3458
Early stopping
	--> Training for Fold 2 took 0.18671441078186035 sec, using 8 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.0590, Validation Loss: 1.1629
	--> Epoch [2/100], Loss: 0.1756, Validation Loss: 1.0297
	--> Epoch [3/100], Loss: 0.0000, Validation Loss: 4.7036
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 2.7390
	--> Epoch [5/100], Loss: 0.0001, Validation Loss: 2.8763
Early stopping
	--> Training for Fold 3 took 0.12207746505737305 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.4598, Validation Loss: 1.6709
	--> Epoch [2/100], Loss: 1.0442, Validation Loss: 1.5433
	--> Epoch [3/100], Loss: 0.3030, Validation Loss: 2.8375
	--> Epoch [4/100], Loss: 0.2577, Validation Loss: 1.7928
	--> Epoch [5/100], Loss: 0.4111, Validation Loss: 3.0442
Early stopping
	--> Training for Fold 4 took 0.15590906143188477 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.0117, Validation Loss: 1.0812
	--> Epoch [2/100], Loss: 0.1521, Validation Loss: 2.6256
	--> Epoch [3/100], Loss: 0.0032, Validation Loss: 0.5147
	--> Epoch [4/100], Loss: 0.3089, Validation Loss: 3.8999
	--> Epoch [5/100], Loss: 0.1499, Validation Loss: 3.1187
	--> Epoch [6/100], Loss: 0.1417, Validation Loss: 3.9007
Early stopping
	--> Training for Fold 5 took 0.14947175979614258 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.3683
	--> Final training Epoch [2/6], Loss: 0.1937
	--> Final training Epoch [3/6], Loss: 0.0005
	--> Final training Epoch [4/6], Loss: 0.0001
	--> Final training Epoch [5/6], Loss: 0.0000
	--> Final training Epoch [6/6], Loss: 0.0553

Final training took 0.1667497158050537 sec

TESTING
	--> Testing took 0.0074 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 5.9403
	--> Final Precision: 0.6923
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6923
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7959, Validation Loss: 1.2371,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7626, Validation Loss: 1.4618,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 1.4646,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7287, Validation Loss: 3.1127,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7088, Validation Loss: 2.4299,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7175, Validation Loss: 1.9966,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6421, Validation Loss: 2.0483,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 2.4265,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8070, Validation Loss: 1.4345,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7088, Validation Loss: 2.0649,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 3.8038, Validation Loss: 0.4874
	--> Epoch [2/100], Loss: 1.0448, Validation Loss: 0.7356
	--> Epoch [3/100], Loss: 4.9783, Validation Loss: 0.5997
	--> Epoch [4/100], Loss: 0.1394, Validation Loss: 0.2591
	--> Epoch [5/100], Loss: 0.1964, Validation Loss: 0.2255
	--> Epoch [6/100], Loss: 0.1160, Validation Loss: 0.3499
	--> Epoch [7/100], Loss: 0.2264, Validation Loss: 0.1191
	--> Epoch [8/100], Loss: 0.2771, Validation Loss: 1.3934
	--> Epoch [9/100], Loss: 0.0890, Validation Loss: 3.3922
	--> Epoch [10/100], Loss: 0.0593, Validation Loss: 1.8827
Early stopping
	--> Training for Fold 1 took 0.22598910331726074 sec, using 10 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 3.4195, Validation Loss: 0.9661
	--> Epoch [2/100], Loss: 3.5133, Validation Loss: 0.6118
	--> Epoch [3/100], Loss: 3.6146, Validation Loss: 0.9096
	--> Epoch [4/100], Loss: 0.1733, Validation Loss: 0.7992
	--> Epoch [5/100], Loss: 0.1929, Validation Loss: 0.8991
Early stopping
	--> Training for Fold 2 took 0.11872720718383789 sec, using 5 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.0035, Validation Loss: 0.8249
	--> Epoch [2/100], Loss: 1.8060, Validation Loss: 0.5858
	--> Epoch [3/100], Loss: 0.0983, Validation Loss: 1.1805
	--> Epoch [4/100], Loss: 0.0004, Validation Loss: 0.6772
	--> Epoch [5/100], Loss: 0.0000, Validation Loss: 2.4763
Early stopping
	--> Training for Fold 3 took 0.11793994903564453 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.1131, Validation Loss: 1.7658
	--> Epoch [2/100], Loss: 0.2109, Validation Loss: 0.6784
	--> Epoch [3/100], Loss: 0.5347, Validation Loss: 1.0836
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.2864
	--> Epoch [5/100], Loss: 0.2128, Validation Loss: 1.1486
	--> Epoch [6/100], Loss: 0.2111, Validation Loss: 0.9650
	--> Epoch [7/100], Loss: 0.6329, Validation Loss: 1.0002
Early stopping
	--> Training for Fold 4 took 0.16623687744140625 sec, using 7 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4209, Validation Loss: 0.7624
	--> Epoch [2/100], Loss: 0.2082, Validation Loss: 1.0753
	--> Epoch [3/100], Loss: 0.2137, Validation Loss: 0.6751
	--> Epoch [4/100], Loss: 0.1003, Validation Loss: 1.3174
	--> Epoch [5/100], Loss: 0.3231, Validation Loss: 1.4733
	--> Epoch [6/100], Loss: 0.2262, Validation Loss: 1.9993
Early stopping
	--> Training for Fold 5 took 0.1417980194091797 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 1.0149
	--> Final training Epoch [2/6], Loss: 0.3621
	--> Final training Epoch [3/6], Loss: 0.0000
	--> Final training Epoch [4/6], Loss: 1.8185
	--> Final training Epoch [5/6], Loss: 0.4707
	--> Final training Epoch [6/6], Loss: 0.0001

Final training took 0.16875123977661133 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 4.4124
	--> Final Precision: 0.7143
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7407
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 1.1605,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7404, Validation Loss: 1.4521,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7094, Validation Loss: 2.5578,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6105, Validation Loss: 2.3424,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8076, Validation Loss: 1.9728,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7632, Validation Loss: 1.5482,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7965, Validation Loss: 1.6292,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 1.4097,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7515, Validation Loss: 1.5333,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6801, Validation Loss: 1.6042,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7936, Validation Loss: 1.4973,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8058, Validation Loss: 2.2893,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6994, Validation Loss: 2.3784,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6333, Validation Loss: 2.0308,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6982, Validation Loss: 2.2767,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 2.4802, Validation Loss: 0.7210
	--> Epoch [2/100], Loss: 0.2514, Validation Loss: 0.7032
	--> Epoch [3/100], Loss: 0.0024, Validation Loss: 0.1572
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.0834
	--> Epoch [5/100], Loss: 0.7159, Validation Loss: 0.2379
	--> Epoch [6/100], Loss: 0.2654, Validation Loss: 0.8493
	--> Epoch [7/100], Loss: 0.6802, Validation Loss: 0.2337
Early stopping
	--> Training for Fold 1 took 0.16176581382751465 sec, using 7 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.0305, Validation Loss: 1.0702
	--> Epoch [2/100], Loss: 0.1629, Validation Loss: 0.4605
	--> Epoch [3/100], Loss: 0.3275, Validation Loss: 0.2520
	--> Epoch [4/100], Loss: 0.0240, Validation Loss: 0.2859
	--> Epoch [5/100], Loss: 0.0001, Validation Loss: 0.2336
	--> Epoch [6/100], Loss: 0.3540, Validation Loss: 1.2847
	--> Epoch [7/100], Loss: 0.0441, Validation Loss: 0.1638
	--> Epoch [8/100], Loss: 0.2268, Validation Loss: 0.6105
	--> Epoch [9/100], Loss: 0.0000, Validation Loss: 0.3563
	--> Epoch [10/100], Loss: 0.0000, Validation Loss: 0.9009
Early stopping
	--> Training for Fold 2 took 0.2273404598236084 sec, using 10 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 2.5895, Validation Loss: 0.6852
	--> Epoch [2/100], Loss: 0.0183, Validation Loss: 0.9347
	--> Epoch [3/100], Loss: 0.0033, Validation Loss: 1.3791
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.6129
	--> Epoch [5/100], Loss: 0.3170, Validation Loss: 0.9532
	--> Epoch [6/100], Loss: 0.0002, Validation Loss: 1.7398
	--> Epoch [7/100], Loss: 0.0000, Validation Loss: 1.2813
Early stopping
	--> Training for Fold 3 took 0.1687183380126953 sec, using 7 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.2364, Validation Loss: 0.2777
	--> Epoch [2/100], Loss: 0.0684, Validation Loss: 0.7004
	--> Epoch [3/100], Loss: 0.3930, Validation Loss: 0.8189
	--> Epoch [4/100], Loss: 0.0555, Validation Loss: 1.1044
Early stopping
	--> Training for Fold 4 took 0.0938408374786377 sec, using 4 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.2795, Validation Loss: 0.5597
	--> Epoch [2/100], Loss: 0.2018, Validation Loss: 1.0797
	--> Epoch [3/100], Loss: 0.0478, Validation Loss: 1.1925
	--> Epoch [4/100], Loss: 0.0003, Validation Loss: 1.0585
Early stopping
	--> Training for Fold 5 took 0.09415864944458008 sec, using 4 epochs

Median number of epochs used: 7 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/7], Loss: 0.5866
	--> Final training Epoch [2/7], Loss: 0.2317
	--> Final training Epoch [3/7], Loss: 0.9263
	--> Final training Epoch [4/7], Loss: 0.0450
	--> Final training Epoch [5/7], Loss: 0.0003
	--> Final training Epoch [6/7], Loss: 0.0056
	--> Final training Epoch [7/7], Loss: 0.0000

Final training took 0.18835735321044922 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 3.0536
	--> Final Precision: 0.6429
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7427, Validation Loss: 1.0579,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 2.3615,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8181, Validation Loss: 1.1579,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6632, Validation Loss: 2.1880,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7310, Validation Loss: 3.0750,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7538, Validation Loss: 2.6075,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6860, Validation Loss: 3.4810,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7433, Validation Loss: 2.7527,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7860, Validation Loss: 1.8797,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7433, Validation Loss: 1.6440,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7626, Validation Loss: 1.7875,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8801, Validation Loss: 1.7298,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7737, Validation Loss: 2.6816,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 1.2643,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7515, Validation Loss: 1.4759,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6023, Validation Loss: 2.6110,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7509, Validation Loss: 3.3647,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6760, Validation Loss: 3.7766,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8047, Validation Loss: 1.6880,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.3115, Validation Loss: 0.3689
	--> Epoch [2/100], Loss: 0.4054, Validation Loss: 0.2073
	--> Epoch [3/100], Loss: 0.1665, Validation Loss: 0.1373
	--> Epoch [4/100], Loss: 0.1181, Validation Loss: 0.1722
	--> Epoch [5/100], Loss: 0.4486, Validation Loss: 0.5944
	--> Epoch [6/100], Loss: 0.2650, Validation Loss: 0.5178
Early stopping
	--> Training for Fold 1 took 0.08009004592895508 sec, using 6 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.2886, Validation Loss: 1.7204
	--> Epoch [2/100], Loss: 0.9396, Validation Loss: 1.5827
	--> Epoch [3/100], Loss: 0.1963, Validation Loss: 0.5077
	--> Epoch [4/100], Loss: 0.2089, Validation Loss: 0.9690
	--> Epoch [5/100], Loss: 0.0275, Validation Loss: 0.7389
	--> Epoch [6/100], Loss: 0.0004, Validation Loss: 0.3346
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.4244
	--> Epoch [8/100], Loss: 0.0000, Validation Loss: 0.4490
	--> Epoch [9/100], Loss: 0.1535, Validation Loss: 0.2961
	--> Epoch [10/100], Loss: 0.1294, Validation Loss: 0.5688
	--> Epoch [11/100], Loss: 0.0746, Validation Loss: 0.4970
	--> Epoch [12/100], Loss: 0.0056, Validation Loss: 0.7171
Early stopping
	--> Training for Fold 2 took 0.19916939735412598 sec, using 12 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8194, Validation Loss: 1.4800
	--> Epoch [2/100], Loss: 0.0580, Validation Loss: 0.5166
	--> Epoch [3/100], Loss: 0.2563, Validation Loss: 0.6894
	--> Epoch [4/100], Loss: 0.0869, Validation Loss: 1.2013
	--> Epoch [5/100], Loss: 0.0003, Validation Loss: 0.9452
Early stopping
	--> Training for Fold 3 took 0.06463956832885742 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6989, Validation Loss: 0.5399
	--> Epoch [2/100], Loss: 0.8195, Validation Loss: 1.6071
	--> Epoch [3/100], Loss: 0.3134, Validation Loss: 0.5333
	--> Epoch [4/100], Loss: 0.1489, Validation Loss: 1.4462
	--> Epoch [5/100], Loss: 0.0163, Validation Loss: 1.5854
	--> Epoch [6/100], Loss: 0.1285, Validation Loss: 0.9514
Early stopping
	--> Training for Fold 4 took 0.07752346992492676 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4713, Validation Loss: 1.1495
	--> Epoch [2/100], Loss: 1.0011, Validation Loss: 1.3532
	--> Epoch [3/100], Loss: 0.0203, Validation Loss: 1.1232
	--> Epoch [4/100], Loss: 0.0952, Validation Loss: 1.0796
	--> Epoch [5/100], Loss: 0.4626, Validation Loss: 0.3225
	--> Epoch [6/100], Loss: 0.0393, Validation Loss: 1.1556
	--> Epoch [7/100], Loss: 2.6920, Validation Loss: 2.8041
	--> Epoch [8/100], Loss: 0.1419, Validation Loss: 2.3106
Early stopping
	--> Training for Fold 5 took 0.10433459281921387 sec, using 8 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 1.0219
	--> Final training Epoch [2/6], Loss: 1.0038
	--> Final training Epoch [3/6], Loss: 0.2641
	--> Final training Epoch [4/6], Loss: 0.1422
	--> Final training Epoch [5/6], Loss: 1.2881
	--> Final training Epoch [6/6], Loss: 0.5201

Final training took 0.09768819808959961 sec

TESTING
	--> Testing took 0.0111 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 7.0296
	--> Final Precision: 0.6923
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6923
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 1.1197,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1197

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.2339, Validation Loss: 0.4214
	--> Epoch [2/100], Loss: 0.1437, Validation Loss: 1.9264
	--> Epoch [3/100], Loss: 0.0370, Validation Loss: 0.5229
	--> Epoch [4/100], Loss: 0.5446, Validation Loss: 0.1430
	--> Epoch [5/100], Loss: 0.3036, Validation Loss: 0.5558
	--> Epoch [6/100], Loss: 1.3027, Validation Loss: 1.4667
	--> Epoch [7/100], Loss: 0.4014, Validation Loss: 0.5343
Early stopping
	--> Training for Fold 1 took 0.08533501625061035 sec, using 7 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 1.4515, Validation Loss: 1.5933
	--> Epoch [2/100], Loss: 1.0752, Validation Loss: 1.7281
	--> Epoch [3/100], Loss: 0.2911, Validation Loss: 0.6961
	--> Epoch [4/100], Loss: 1.0662, Validation Loss: 0.6540
	--> Epoch [5/100], Loss: 0.1429, Validation Loss: 0.3252
	--> Epoch [6/100], Loss: 0.3702, Validation Loss: 0.6460
	--> Epoch [7/100], Loss: 0.2883, Validation Loss: 0.3410
	--> Epoch [8/100], Loss: 0.2857, Validation Loss: 0.3729
Early stopping
	--> Training for Fold 2 took 0.09595155715942383 sec, using 8 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8302, Validation Loss: 1.1944
	--> Epoch [2/100], Loss: 0.8715, Validation Loss: 0.3790
	--> Epoch [3/100], Loss: 0.0927, Validation Loss: 0.5633
	--> Epoch [4/100], Loss: 0.0558, Validation Loss: 0.6426
	--> Epoch [5/100], Loss: 0.0763, Validation Loss: 0.6236
Early stopping
	--> Training for Fold 3 took 0.06740832328796387 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.6277, Validation Loss: 1.4560
	--> Epoch [2/100], Loss: 0.1512, Validation Loss: 0.7388
	--> Epoch [3/100], Loss: 0.3638, Validation Loss: 0.6457
	--> Epoch [4/100], Loss: 0.0401, Validation Loss: 0.9939
	--> Epoch [5/100], Loss: 0.5451, Validation Loss: 1.5902
	--> Epoch [6/100], Loss: 0.0000, Validation Loss: 0.7003
Early stopping
	--> Training for Fold 4 took 0.08592915534973145 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7416, Validation Loss: 1.6531
	--> Epoch [2/100], Loss: 0.2705, Validation Loss: 0.6617
	--> Epoch [3/100], Loss: 0.0858, Validation Loss: 0.6899
	--> Epoch [4/100], Loss: 0.1635, Validation Loss: 1.8195
	--> Epoch [5/100], Loss: 0.3463, Validation Loss: 4.1054
Early stopping
	--> Training for Fold 5 took 0.09352803230285645 sec, using 5 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.2936
	--> Final training Epoch [2/6], Loss: 1.5158
	--> Final training Epoch [3/6], Loss: 2.4752
	--> Final training Epoch [4/6], Loss: 0.2115
	--> Final training Epoch [5/6], Loss: 0.6042
	--> Final training Epoch [6/6], Loss: 0.2800

Final training took 0.0929555892944336 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.4783
	--> Final Loss: 1.7581
	--> Final Precision: 0.5556
	--> Final Recall: 0.3846
	--> Final F1 Score: 0.4545
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8175, Validation Loss: 1.1188,  Current Best Accuracy: 0.8175,  Current Best Validation Loss: 1.1188

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8542, Validation Loss: 0.8969
	--> Epoch [2/100], Loss: 0.5817, Validation Loss: 0.7305
	--> Epoch [3/100], Loss: 0.8219, Validation Loss: 0.1341
	--> Epoch [4/100], Loss: 0.2416, Validation Loss: 0.1862
	--> Epoch [5/100], Loss: 0.0867, Validation Loss: 0.1683
	--> Epoch [6/100], Loss: 0.1689, Validation Loss: 0.1151
	--> Epoch [7/100], Loss: 0.2734, Validation Loss: 0.4240
	--> Epoch [8/100], Loss: 0.0319, Validation Loss: 0.3193
	--> Epoch [9/100], Loss: 0.2849, Validation Loss: 0.2976
Early stopping
	--> Training for Fold 1 took 0.10994887351989746 sec, using 9 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 2.0177, Validation Loss: 0.8178
	--> Epoch [2/100], Loss: 0.9105, Validation Loss: 1.7469
	--> Epoch [3/100], Loss: 0.3086, Validation Loss: 0.2287
	--> Epoch [4/100], Loss: 0.4241, Validation Loss: 0.5238
	--> Epoch [5/100], Loss: 0.0802, Validation Loss: 0.3108
	--> Epoch [6/100], Loss: 0.6438, Validation Loss: 0.1852
	--> Epoch [7/100], Loss: 0.0745, Validation Loss: 0.6032
	--> Epoch [8/100], Loss: 0.1663, Validation Loss: 0.5058
	--> Epoch [9/100], Loss: 0.2929, Validation Loss: 0.5416
Early stopping
	--> Training for Fold 2 took 0.13295722007751465 sec, using 9 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 1.0469, Validation Loss: 0.9991
	--> Epoch [2/100], Loss: 0.2251, Validation Loss: 0.7306
	--> Epoch [3/100], Loss: 0.1083, Validation Loss: 0.6686
	--> Epoch [4/100], Loss: 0.8869, Validation Loss: 0.8452
	--> Epoch [5/100], Loss: 0.2354, Validation Loss: 0.6302
	--> Epoch [6/100], Loss: 0.1635, Validation Loss: 0.5979
	--> Epoch [7/100], Loss: 0.1765, Validation Loss: 1.0213
	--> Epoch [8/100], Loss: 0.2082, Validation Loss: 0.5989
	--> Epoch [9/100], Loss: 0.2102, Validation Loss: 0.4256
	--> Epoch [10/100], Loss: 0.1404, Validation Loss: 1.0827
	--> Epoch [11/100], Loss: 0.1924, Validation Loss: 1.4249
	--> Epoch [12/100], Loss: 0.0001, Validation Loss: 1.0630
Early stopping
	--> Training for Fold 3 took 0.1529688835144043 sec, using 12 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.3098, Validation Loss: 1.1914
	--> Epoch [2/100], Loss: 0.7341, Validation Loss: 0.5391
	--> Epoch [3/100], Loss: 2.3868, Validation Loss: 3.4308
	--> Epoch [4/100], Loss: 0.7157, Validation Loss: 1.0338
	--> Epoch [5/100], Loss: 1.8870, Validation Loss: 1.6745
Early stopping
	--> Training for Fold 4 took 0.07029294967651367 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 1.0902, Validation Loss: 2.3529
	--> Epoch [2/100], Loss: 0.5164, Validation Loss: 0.6144
	--> Epoch [3/100], Loss: 0.4647, Validation Loss: 0.9010
	--> Epoch [4/100], Loss: 1.1228, Validation Loss: 0.9428
	--> Epoch [5/100], Loss: 0.3114, Validation Loss: 1.4345
Early stopping
	--> Training for Fold 5 took 0.05958390235900879 sec, using 5 epochs

Median number of epochs used: 9 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/9], Loss: 1.6741
	--> Final training Epoch [2/9], Loss: 0.5513
	--> Final training Epoch [3/9], Loss: 0.5144
	--> Final training Epoch [4/9], Loss: 0.8321
	--> Final training Epoch [5/9], Loss: 0.6216
	--> Final training Epoch [6/9], Loss: 0.1489
	--> Final training Epoch [7/9], Loss: 0.0833
	--> Final training Epoch [8/9], Loss: 0.1739
	--> Final training Epoch [9/9], Loss: 0.1073

Final training took 0.13803458213806152 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.5217
	--> Final Loss: 3.7302
	--> Final Precision: 0.7500
	--> Final Recall: 0.2308
	--> Final F1 Score: 0.3529
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.6032,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 1.0196,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7643, Validation Loss: 0.7890,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6871, Validation Loss: 2.0207,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7129, Validation Loss: 1.1306,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6304, Validation Loss: 2.4182,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.9998,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.7304,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 1.0877,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 1.1446,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7848, Validation Loss: 1.0613,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7181, Validation Loss: 1.5775,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6871, Validation Loss: 2.3622,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7105, Validation Loss: 2.2896,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7626, Validation Loss: 1.6788,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7842, Validation Loss: 0.7426,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8175, Validation Loss: 1.1368,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8064, Validation Loss: 1.1497,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8164, Validation Loss: 0.8762,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7731, Validation Loss: 1.0136,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.7986,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7292, Validation Loss: 0.9010,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6883, Validation Loss: 1.6487,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7737, Validation Loss: 1.5316,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7602, Validation Loss: 1.9003,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.9312,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7509, Validation Loss: 2.4422,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7310, Validation Loss: 0.8819,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6649, Validation Loss: 1.6344,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7842, Validation Loss: 0.7131,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6988, Validation Loss: 1.1487,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6006, Validation Loss: 2.0578,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7743, Validation Loss: 0.9939,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 1.3317, Validation Loss: 1.1672
	--> Epoch [2/100], Loss: 0.4726, Validation Loss: 0.2167
	--> Epoch [3/100], Loss: 0.2439, Validation Loss: 0.1738
	--> Epoch [4/100], Loss: 0.1552, Validation Loss: 0.1688
	--> Epoch [5/100], Loss: 0.2329, Validation Loss: 0.1999
	--> Epoch [6/100], Loss: 0.3295, Validation Loss: 0.1032
	--> Epoch [7/100], Loss: 0.1146, Validation Loss: 0.1238
	--> Epoch [8/100], Loss: 0.1646, Validation Loss: 0.1159
	--> Epoch [9/100], Loss: 0.1032, Validation Loss: 0.0695
	--> Epoch [10/100], Loss: 0.1911, Validation Loss: 0.1404
	--> Epoch [11/100], Loss: 0.0001, Validation Loss: 0.0504
	--> Epoch [12/100], Loss: 0.4225, Validation Loss: 0.0733
	--> Epoch [13/100], Loss: 0.0113, Validation Loss: 0.0941
	--> Epoch [14/100], Loss: 0.0024, Validation Loss: 0.0416
	--> Epoch [15/100], Loss: 0.0011, Validation Loss: 0.6257
	--> Epoch [16/100], Loss: 0.0002, Validation Loss: 0.1923
	--> Epoch [17/100], Loss: 0.0050, Validation Loss: 0.1549
Early stopping
	--> Training for Fold 1 took 0.2031998634338379 sec, using 17 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 3.1750, Validation Loss: 2.4510
	--> Epoch [2/100], Loss: 0.2611, Validation Loss: 0.3694
	--> Epoch [3/100], Loss: 0.1553, Validation Loss: 0.3966
	--> Epoch [4/100], Loss: 0.8033, Validation Loss: 0.4060
	--> Epoch [5/100], Loss: 0.1086, Validation Loss: 0.1885
	--> Epoch [6/100], Loss: 0.3402, Validation Loss: 0.1755
	--> Epoch [7/100], Loss: 0.3843, Validation Loss: 0.2016
	--> Epoch [8/100], Loss: 0.1194, Validation Loss: 0.2740
	--> Epoch [9/100], Loss: 0.4130, Validation Loss: 0.4750
Early stopping
	--> Training for Fold 2 took 0.15242791175842285 sec, using 9 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 1.0646, Validation Loss: 1.2839
	--> Epoch [2/100], Loss: 1.3267, Validation Loss: 0.7689
	--> Epoch [3/100], Loss: 0.6578, Validation Loss: 1.3782
	--> Epoch [4/100], Loss: 0.4142, Validation Loss: 0.8388
	--> Epoch [5/100], Loss: 0.1460, Validation Loss: 0.7495
	--> Epoch [6/100], Loss: 0.2494, Validation Loss: 0.6376
	--> Epoch [7/100], Loss: 0.0990, Validation Loss: 0.5380
	--> Epoch [8/100], Loss: 0.2079, Validation Loss: 0.6848
	--> Epoch [9/100], Loss: 0.1437, Validation Loss: 0.7953
	--> Epoch [10/100], Loss: 0.0962, Validation Loss: 0.7658
Early stopping
	--> Training for Fold 3 took 0.14372563362121582 sec, using 10 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.0972, Validation Loss: 0.7138
	--> Epoch [2/100], Loss: 1.7010, Validation Loss: 1.0634
	--> Epoch [3/100], Loss: 0.0700, Validation Loss: 0.6161
	--> Epoch [4/100], Loss: 0.0473, Validation Loss: 0.5758
	--> Epoch [5/100], Loss: 0.0174, Validation Loss: 0.5379
	--> Epoch [6/100], Loss: 0.0007, Validation Loss: 0.4924
	--> Epoch [7/100], Loss: 0.0098, Validation Loss: 0.4233
	--> Epoch [8/100], Loss: 0.0093, Validation Loss: 0.6844
	--> Epoch [9/100], Loss: 1.7888, Validation Loss: 1.1704
	--> Epoch [10/100], Loss: 0.7532, Validation Loss: 3.0121
Early stopping
	--> Training for Fold 4 took 0.12256813049316406 sec, using 10 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4361, Validation Loss: 1.4882
	--> Epoch [2/100], Loss: 0.1996, Validation Loss: 0.6770
	--> Epoch [3/100], Loss: 0.1652, Validation Loss: 0.7780
	--> Epoch [4/100], Loss: 0.0547, Validation Loss: 0.7164
	--> Epoch [5/100], Loss: 0.0804, Validation Loss: 0.6584
	--> Epoch [6/100], Loss: 0.0045, Validation Loss: 0.4215
	--> Epoch [7/100], Loss: 0.1140, Validation Loss: 0.4687
	--> Epoch [8/100], Loss: 0.0474, Validation Loss: 0.5668
	--> Epoch [9/100], Loss: 0.0209, Validation Loss: 0.7382
Early stopping
	--> Training for Fold 5 took 0.1130828857421875 sec, using 9 epochs

Median number of epochs used: 10 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/10], Loss: 0.5079
	--> Final training Epoch [2/10], Loss: 1.6783
	--> Final training Epoch [3/10], Loss: 0.3505
	--> Final training Epoch [4/10], Loss: 0.1380
	--> Final training Epoch [5/10], Loss: 0.1221
	--> Final training Epoch [6/10], Loss: 0.1654
	--> Final training Epoch [7/10], Loss: 0.3422
	--> Final training Epoch [8/10], Loss: 0.1435
	--> Final training Epoch [9/10], Loss: 0.5479
	--> Final training Epoch [10/10], Loss: 0.4285

Final training took 0.14211153984069824 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 3.9780
	--> Final Precision: 0.8000
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6957
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8269, Validation Loss: 0.4209,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7649, Validation Loss: 1.8898,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8058, Validation Loss: 1.0794,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7842, Validation Loss: 0.6857,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7386, Validation Loss: 1.5194,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7409, Validation Loss: 1.3874,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7427, Validation Loss: 1.1168,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6345, Validation Loss: 1.4120,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7310, Validation Loss: 1.6141,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7947, Validation Loss: 0.6496,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.5490,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.6114,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7374, Validation Loss: 0.5073,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7643, Validation Loss: 0.8142,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8158, Validation Loss: 0.8155,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7632, Validation Loss: 0.8013,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7848, Validation Loss: 0.8397,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7310, Validation Loss: 0.7651,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7187, Validation Loss: 1.0032,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.7812,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.6737,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7415, Validation Loss: 1.0281,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7614, Validation Loss: 0.9750,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7304, Validation Loss: 0.6854,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6404, Validation Loss: 1.3883,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7439, Validation Loss: 1.2658,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7111, Validation Loss: 1.1450,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7936, Validation Loss: 0.7190,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 0.8736,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8187, Validation Loss: 0.7201,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7532, Validation Loss: 0.5596,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8064, Validation Loss: 0.7290,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6643, Validation Loss: 1.9300,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6222, Validation Loss: 1.6013,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6673, Validation Loss: 1.1112,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6310, Validation Loss: 1.5173,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8690, Validation Loss: 0.5493,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7947, Validation Loss: 0.6827,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7532, Validation Loss: 0.9595,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8175, Validation Loss: 0.5423,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.6148,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7854, Validation Loss: 0.5928,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6439, Validation Loss: 1.6972,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6637, Validation Loss: 2.0602,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7421, Validation Loss: 0.7284,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.5866,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.7987,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7942, Validation Loss: 0.9777,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8076, Validation Loss: 0.6051,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7298, Validation Loss: 1.0250,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7503, Validation Loss: 1.1648,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6023, Validation Loss: 1.1313,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7842, Validation Loss: 0.7265,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6795, Validation Loss: 1.0849,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.4715, Validation Loss: 1.0186
	--> Epoch [2/100], Loss: 0.5768, Validation Loss: 0.6840
	--> Epoch [3/100], Loss: 0.0057, Validation Loss: 0.1500
	--> Epoch [4/100], Loss: 0.0173, Validation Loss: 0.1654
	--> Epoch [5/100], Loss: 0.2749, Validation Loss: 0.1154
	--> Epoch [6/100], Loss: 0.0005, Validation Loss: 0.1150
	--> Epoch [7/100], Loss: 0.0006, Validation Loss: 0.1292
	--> Epoch [8/100], Loss: 0.0011, Validation Loss: 0.1229
	--> Epoch [9/100], Loss: 0.0059, Validation Loss: 0.1260
Early stopping
	--> Training for Fold 1 took 0.06523990631103516 sec, using 9 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.2689, Validation Loss: 0.5276
	--> Epoch [2/100], Loss: 1.3595, Validation Loss: 0.1100
	--> Epoch [3/100], Loss: 0.0499, Validation Loss: 0.1351
	--> Epoch [4/100], Loss: 0.0337, Validation Loss: 0.2466
	--> Epoch [5/100], Loss: 0.1398, Validation Loss: 0.1797
Early stopping
	--> Training for Fold 2 took 0.0307769775390625 sec, using 5 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 1.2821, Validation Loss: 0.8225
	--> Epoch [2/100], Loss: 0.2195, Validation Loss: 0.4152
	--> Epoch [3/100], Loss: 1.2951, Validation Loss: 0.4165
	--> Epoch [4/100], Loss: 0.1586, Validation Loss: 0.4203
	--> Epoch [5/100], Loss: 0.2329, Validation Loss: 0.3071
	--> Epoch [6/100], Loss: 0.1655, Validation Loss: 0.3740
	--> Epoch [7/100], Loss: 0.1588, Validation Loss: 0.3838
	--> Epoch [8/100], Loss: 0.1527, Validation Loss: 0.3752
Early stopping
	--> Training for Fold 3 took 0.052700042724609375 sec, using 8 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.4242, Validation Loss: 2.1848
	--> Epoch [2/100], Loss: 1.1732, Validation Loss: 0.3978
	--> Epoch [3/100], Loss: 0.1198, Validation Loss: 0.4844
	--> Epoch [4/100], Loss: 0.1468, Validation Loss: 0.4729
	--> Epoch [5/100], Loss: 0.0596, Validation Loss: 0.4773
Early stopping
	--> Training for Fold 4 took 0.03291034698486328 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5206, Validation Loss: 1.3615
	--> Epoch [2/100], Loss: 0.7931, Validation Loss: 1.3384
	--> Epoch [3/100], Loss: 0.2331, Validation Loss: 1.0302
	--> Epoch [4/100], Loss: 0.1181, Validation Loss: 1.4012
	--> Epoch [5/100], Loss: 0.0718, Validation Loss: 1.3537
	--> Epoch [6/100], Loss: 0.0647, Validation Loss: 1.2551
Early stopping
	--> Training for Fold 5 took 0.038573265075683594 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.5143
	--> Final training Epoch [2/6], Loss: 0.7233
	--> Final training Epoch [3/6], Loss: 0.8170
	--> Final training Epoch [4/6], Loss: 0.1491
	--> Final training Epoch [5/6], Loss: 0.1129
	--> Final training Epoch [6/6], Loss: 0.0641

Final training took 0.03825545310974121 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 2.0735
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8585, Validation Loss: 0.4018,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.4018
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7614, Validation Loss: 1.0496,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.4018

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 1.2583, Validation Loss: 0.3558
	--> Epoch [2/100], Loss: 0.2908, Validation Loss: 0.9290
	--> Epoch [3/100], Loss: 0.0540, Validation Loss: 0.4987
	--> Epoch [4/100], Loss: 0.0096, Validation Loss: 0.3818
Early stopping
	--> Training for Fold 1 took 0.025847673416137695 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8196, Validation Loss: 0.3743
	--> Epoch [2/100], Loss: 0.1015, Validation Loss: 0.0624
	--> Epoch [3/100], Loss: 0.8890, Validation Loss: 0.8000
	--> Epoch [4/100], Loss: 0.0140, Validation Loss: 0.1803
	--> Epoch [5/100], Loss: 0.0028, Validation Loss: 0.1268
Early stopping
	--> Training for Fold 2 took 0.030321836471557617 sec, using 5 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.3717, Validation Loss: 1.6268
	--> Epoch [2/100], Loss: 0.3434, Validation Loss: 0.5391
	--> Epoch [3/100], Loss: 1.2500, Validation Loss: 0.4444
	--> Epoch [4/100], Loss: 0.0724, Validation Loss: 0.4648
	--> Epoch [5/100], Loss: 0.1147, Validation Loss: 0.3848
	--> Epoch [6/100], Loss: 0.1732, Validation Loss: 0.4167
	--> Epoch [7/100], Loss: 0.1445, Validation Loss: 0.3282
	--> Epoch [8/100], Loss: 0.1452, Validation Loss: 0.5471
	--> Epoch [9/100], Loss: 0.0643, Validation Loss: 0.5336
	--> Epoch [10/100], Loss: 0.1392, Validation Loss: 0.5089
Early stopping
	--> Training for Fold 3 took 0.05836915969848633 sec, using 10 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5231, Validation Loss: 3.0389
	--> Epoch [2/100], Loss: 0.2627, Validation Loss: 0.3119
	--> Epoch [3/100], Loss: 0.0718, Validation Loss: 0.3522
	--> Epoch [4/100], Loss: 0.0385, Validation Loss: 0.3696
	--> Epoch [5/100], Loss: 0.0358, Validation Loss: 0.2732
	--> Epoch [6/100], Loss: 0.0014, Validation Loss: 0.2825
	--> Epoch [7/100], Loss: 0.0188, Validation Loss: 0.2757
	--> Epoch [8/100], Loss: 0.0474, Validation Loss: 0.2542
	--> Epoch [9/100], Loss: 0.0693, Validation Loss: 0.1839
	--> Epoch [10/100], Loss: 0.0014, Validation Loss: 0.1969
	--> Epoch [11/100], Loss: 0.0006, Validation Loss: 0.2701
	--> Epoch [12/100], Loss: 0.0075, Validation Loss: 0.2580
Early stopping
	--> Training for Fold 4 took 0.07880806922912598 sec, using 12 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6747, Validation Loss: 0.4549
	--> Epoch [2/100], Loss: 0.4217, Validation Loss: 0.7513
	--> Epoch [3/100], Loss: 0.6891, Validation Loss: 0.9268
	--> Epoch [4/100], Loss: 0.2632, Validation Loss: 0.5878
Early stopping
	--> Training for Fold 5 took 0.0399937629699707 sec, using 4 epochs

Median number of epochs used: 5 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/5], Loss: 0.7313
	--> Final training Epoch [2/5], Loss: 0.4002
	--> Final training Epoch [3/5], Loss: 0.1321
	--> Final training Epoch [4/5], Loss: 0.3413
	--> Final training Epoch [5/5], Loss: 0.2762

Final training took 0.04085969924926758 sec

TESTING
	--> Testing took 0.0110 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.4285
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8906, Validation Loss: 0.3639,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8579, Validation Loss: 0.6252,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7836, Validation Loss: 0.7966,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7936, Validation Loss: 0.7110,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7398, Validation Loss: 0.5683,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6649, Validation Loss: 0.8866,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6784, Validation Loss: 0.9577,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8690, Validation Loss: 0.4525,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8591, Validation Loss: 0.4289,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8807, Validation Loss: 0.4804,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.9448,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.8061,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8146, Validation Loss: 0.8478,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6784, Validation Loss: 1.0076,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6965, Validation Loss: 0.7692,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7614, Validation Loss: 1.1458,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7503, Validation Loss: 0.5819,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.4751,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8807, Validation Loss: 0.4711,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8579, Validation Loss: 0.4188,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7117, Validation Loss: 1.1902,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.5551,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.4746,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6234, Validation Loss: 1.1847,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5579, Validation Loss: 1.5372,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8801, Validation Loss: 0.4364,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7830, Validation Loss: 1.4354,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7690, Validation Loss: 1.3710,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8690, Validation Loss: 0.5076,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7708, Validation Loss: 0.6817,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.6990,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5614, Validation Loss: 1.4166,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6345, Validation Loss: 1.4058,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6345, Validation Loss: 0.8327,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8801, Validation Loss: 0.8287,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 0.6302,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.8431,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6421, Validation Loss: 1.0026,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7620, Validation Loss: 0.9119,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 0.7719,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7181, Validation Loss: 0.7349,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7415, Validation Loss: 1.3198,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5591, Validation Loss: 1.7664,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.4564,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8386, Validation Loss: 0.4335,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7445, Validation Loss: 0.1941
	--> Epoch [2/100], Loss: 0.3790, Validation Loss: 0.2525
	--> Epoch [3/100], Loss: 0.2591, Validation Loss: 0.2228
	--> Epoch [4/100], Loss: 0.1232, Validation Loss: 0.3536
Early stopping
	--> Training for Fold 1 took 0.01530313491821289 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6936, Validation Loss: 0.5586
	--> Epoch [2/100], Loss: 0.5061, Validation Loss: 0.3749
	--> Epoch [3/100], Loss: 0.2555, Validation Loss: 0.4662
	--> Epoch [4/100], Loss: 0.1902, Validation Loss: 0.3836
	--> Epoch [5/100], Loss: 0.1150, Validation Loss: 0.3073
	--> Epoch [6/100], Loss: 0.0878, Validation Loss: 0.2800
	--> Epoch [7/100], Loss: 0.2896, Validation Loss: 0.4948
	--> Epoch [8/100], Loss: 0.1798, Validation Loss: 0.4871
	--> Epoch [9/100], Loss: 0.0980, Validation Loss: 1.0067
Early stopping
	--> Training for Fold 2 took 0.03474283218383789 sec, using 9 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6980, Validation Loss: 0.5327
	--> Epoch [2/100], Loss: 0.4100, Validation Loss: 0.5452
	--> Epoch [3/100], Loss: 0.2443, Validation Loss: 0.3747
	--> Epoch [4/100], Loss: 0.1922, Validation Loss: 0.4870
	--> Epoch [5/100], Loss: 0.1194, Validation Loss: 0.3651
	--> Epoch [6/100], Loss: 0.0983, Validation Loss: 0.3925
	--> Epoch [7/100], Loss: 0.0393, Validation Loss: 0.4105
	--> Epoch [8/100], Loss: 0.1012, Validation Loss: 0.4636
Early stopping
	--> Training for Fold 3 took 0.02875375747680664 sec, using 8 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6956, Validation Loss: 0.3897
	--> Epoch [2/100], Loss: 0.3363, Validation Loss: 0.7404
	--> Epoch [3/100], Loss: 0.2624, Validation Loss: 0.7082
	--> Epoch [4/100], Loss: 0.1724, Validation Loss: 1.3124
Early stopping
	--> Training for Fold 4 took 0.01896047592163086 sec, using 4 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6794, Validation Loss: 0.6007
	--> Epoch [2/100], Loss: 0.3208, Validation Loss: 0.7075
	--> Epoch [3/100], Loss: 0.1422, Validation Loss: 0.5801
	--> Epoch [4/100], Loss: 0.1047, Validation Loss: 0.7931
	--> Epoch [5/100], Loss: 0.0764, Validation Loss: 0.7813
	--> Epoch [6/100], Loss: 0.0553, Validation Loss: 0.8055
Early stopping
	--> Training for Fold 5 took 0.023682832717895508 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.7318
	--> Final training Epoch [2/6], Loss: 0.4132
	--> Final training Epoch [3/6], Loss: 0.3473
	--> Final training Epoch [4/6], Loss: 0.1877
	--> Final training Epoch [5/6], Loss: 0.1606
	--> Final training Epoch [6/6], Loss: 0.1457

Final training took 0.022202730178833008 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.5217
	--> Final Loss: 1.4056
	--> Final Precision: 0.6000
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5217
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3344,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.6419,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.5204,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4067,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7439, Validation Loss: 0.6167,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8287, Validation Loss: 0.4555,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7199, Validation Loss: 0.5617,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8807, Validation Loss: 0.4591,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.6273,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7272, Validation Loss: 0.2592
	--> Epoch [2/100], Loss: 0.4135, Validation Loss: 0.2754
	--> Epoch [3/100], Loss: 0.3731, Validation Loss: 0.3420
	--> Epoch [4/100], Loss: 0.4289, Validation Loss: 0.6407
Early stopping
	--> Training for Fold 1 took 0.013511419296264648 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6909, Validation Loss: 0.9567
	--> Epoch [2/100], Loss: 0.7907, Validation Loss: 0.4144
	--> Epoch [3/100], Loss: 0.5607, Validation Loss: 0.4430
	--> Epoch [4/100], Loss: 0.2531, Validation Loss: 0.2665
	--> Epoch [5/100], Loss: 0.1445, Validation Loss: 0.2918
	--> Epoch [6/100], Loss: 0.1832, Validation Loss: 0.2221
	--> Epoch [7/100], Loss: 0.1492, Validation Loss: 0.4202
	--> Epoch [8/100], Loss: 0.1722, Validation Loss: 0.4820
	--> Epoch [9/100], Loss: 0.1178, Validation Loss: 0.3392
Early stopping
	--> Training for Fold 2 took 0.03244924545288086 sec, using 9 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7861, Validation Loss: 0.4721
	--> Epoch [2/100], Loss: 0.3865, Validation Loss: 0.3623
	--> Epoch [3/100], Loss: 0.2621, Validation Loss: 0.5516
	--> Epoch [4/100], Loss: 0.1497, Validation Loss: 0.5629
	--> Epoch [5/100], Loss: 0.2010, Validation Loss: 0.3265
	--> Epoch [6/100], Loss: 0.1294, Validation Loss: 0.4088
	--> Epoch [7/100], Loss: 0.1126, Validation Loss: 0.3413
	--> Epoch [8/100], Loss: 0.0888, Validation Loss: 0.6708
Early stopping
	--> Training for Fold 3 took 0.02849292755126953 sec, using 8 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7135, Validation Loss: 0.9223
	--> Epoch [2/100], Loss: 0.7674, Validation Loss: 0.3459
	--> Epoch [3/100], Loss: 0.3963, Validation Loss: 0.3519
	--> Epoch [4/100], Loss: 0.1324, Validation Loss: 0.3664
	--> Epoch [5/100], Loss: 0.1732, Validation Loss: 0.4500
Early stopping
	--> Training for Fold 4 took 0.01655864715576172 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6392, Validation Loss: 0.7349
	--> Epoch [2/100], Loss: 0.4187, Validation Loss: 0.5334
	--> Epoch [3/100], Loss: 0.3286, Validation Loss: 0.4055
	--> Epoch [4/100], Loss: 0.1011, Validation Loss: 0.4706
	--> Epoch [5/100], Loss: 0.0450, Validation Loss: 0.5636
	--> Epoch [6/100], Loss: 0.0446, Validation Loss: 0.6074
Early stopping
	--> Training for Fold 5 took 0.022005319595336914 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.7086
	--> Final training Epoch [2/6], Loss: 0.3720
	--> Final training Epoch [3/6], Loss: 0.1998
	--> Final training Epoch [4/6], Loss: 0.1482
	--> Final training Epoch [5/6], Loss: 0.0953
	--> Final training Epoch [6/6], Loss: 0.0744

Final training took 0.021317005157470703 sec

TESTING
	--> Testing took 0.0075 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.5274
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.4008,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4791,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.4723,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.4018,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7117, Validation Loss: 0.5484,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7404, Validation Loss: 0.4870,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.5198,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8064, Validation Loss: 0.5459,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.4240,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.4448,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.4208,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7168, Validation Loss: 0.2717
	--> Epoch [2/100], Loss: 0.3563, Validation Loss: 0.3106
	--> Epoch [3/100], Loss: 0.6087, Validation Loss: 0.5568
	--> Epoch [4/100], Loss: 0.4988, Validation Loss: 0.8084
Early stopping
	--> Training for Fold 1 took 0.016593456268310547 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7541, Validation Loss: 0.4393
	--> Epoch [2/100], Loss: 0.5731, Validation Loss: 0.4067
	--> Epoch [3/100], Loss: 0.9380, Validation Loss: 0.3988
	--> Epoch [4/100], Loss: 0.5556, Validation Loss: 0.2205
	--> Epoch [5/100], Loss: 0.3236, Validation Loss: 0.1829
	--> Epoch [6/100], Loss: 0.2823, Validation Loss: 0.4914
	--> Epoch [7/100], Loss: 0.3192, Validation Loss: 0.3474
	--> Epoch [8/100], Loss: 0.1823, Validation Loss: 0.6416
Early stopping
	--> Training for Fold 2 took 0.030186176300048828 sec, using 8 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7362, Validation Loss: 0.6072
	--> Epoch [2/100], Loss: 1.0426, Validation Loss: 0.3601
	--> Epoch [3/100], Loss: 0.4145, Validation Loss: 0.2339
	--> Epoch [4/100], Loss: 0.2296, Validation Loss: 0.4680
	--> Epoch [5/100], Loss: 0.4386, Validation Loss: 0.3167
	--> Epoch [6/100], Loss: 0.2697, Validation Loss: 0.2925
Early stopping
	--> Training for Fold 3 took 0.021658897399902344 sec, using 6 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7209, Validation Loss: 0.3623
	--> Epoch [2/100], Loss: 0.5447, Validation Loss: 0.4010
	--> Epoch [3/100], Loss: 0.3081, Validation Loss: 0.3620
	--> Epoch [4/100], Loss: 0.2420, Validation Loss: 0.2812
	--> Epoch [5/100], Loss: 0.2665, Validation Loss: 0.2857
	--> Epoch [6/100], Loss: 0.3411, Validation Loss: 0.4157
	--> Epoch [7/100], Loss: 0.2057, Validation Loss: 0.5205
Early stopping
	--> Training for Fold 4 took 0.026825428009033203 sec, using 7 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7414, Validation Loss: 0.5564
	--> Epoch [2/100], Loss: 0.6011, Validation Loss: 0.6716
	--> Epoch [3/100], Loss: 0.3494, Validation Loss: 0.3957
	--> Epoch [4/100], Loss: 0.2711, Validation Loss: 0.3704
	--> Epoch [5/100], Loss: 0.2729, Validation Loss: 0.4248
	--> Epoch [6/100], Loss: 0.1872, Validation Loss: 0.6508
	--> Epoch [7/100], Loss: 0.1497, Validation Loss: 0.6445
Early stopping
	--> Training for Fold 5 took 0.024566173553466797 sec, using 7 epochs

Median number of epochs used: 7 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/7], Loss: 0.7261
	--> Final training Epoch [2/7], Loss: 0.6651
	--> Final training Epoch [3/7], Loss: 0.5226
	--> Final training Epoch [4/7], Loss: 0.2549
	--> Final training Epoch [5/7], Loss: 0.2382
	--> Final training Epoch [6/7], Loss: 0.2592
	--> Final training Epoch [7/7], Loss: 0.2279

Final training took 0.023348569869995117 sec

TESTING
	--> Testing took 0.0080 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.5606
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8819, Validation Loss: 0.3425,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7977, Validation Loss: 0.5055,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.5950,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7269, Validation Loss: 0.5430,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7327, Validation Loss: 0.6386,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.4172,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6765, Validation Loss: 0.3033
	--> Epoch [2/100], Loss: 0.3461, Validation Loss: 0.7549
	--> Epoch [3/100], Loss: 0.4887, Validation Loss: 0.3468
	--> Epoch [4/100], Loss: 0.2957, Validation Loss: 0.2913
	--> Epoch [5/100], Loss: 0.1531, Validation Loss: 0.2306
	--> Epoch [6/100], Loss: 0.2235, Validation Loss: 0.3763
	--> Epoch [7/100], Loss: 0.1406, Validation Loss: 0.3469
	--> Epoch [8/100], Loss: 0.1203, Validation Loss: 0.3190
Early stopping
	--> Training for Fold 1 took 0.031252384185791016 sec, using 8 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6745, Validation Loss: 0.2897
	--> Epoch [2/100], Loss: 0.3858, Validation Loss: 0.1384
	--> Epoch [3/100], Loss: 0.2992, Validation Loss: 0.5228
	--> Epoch [4/100], Loss: 0.4283, Validation Loss: 0.1000
	--> Epoch [5/100], Loss: 0.2682, Validation Loss: 0.3628
	--> Epoch [6/100], Loss: 0.1957, Validation Loss: 0.2871
	--> Epoch [7/100], Loss: 0.1323, Validation Loss: 0.5086
Early stopping
	--> Training for Fold 2 took 0.028832197189331055 sec, using 7 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6715, Validation Loss: 0.7974
	--> Epoch [2/100], Loss: 0.5698, Validation Loss: 0.3885
	--> Epoch [3/100], Loss: 0.3973, Validation Loss: 0.2724
	--> Epoch [4/100], Loss: 0.2838, Validation Loss: 0.4469
	--> Epoch [5/100], Loss: 0.1388, Validation Loss: 0.2836
	--> Epoch [6/100], Loss: 0.0928, Validation Loss: 0.2683
	--> Epoch [7/100], Loss: 0.0781, Validation Loss: 0.3262
	--> Epoch [8/100], Loss: 0.0510, Validation Loss: 0.3278
	--> Epoch [9/100], Loss: 0.0466, Validation Loss: 0.3178
Early stopping
	--> Training for Fold 3 took 0.035547494888305664 sec, using 9 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6883, Validation Loss: 0.9045
	--> Epoch [2/100], Loss: 0.5359, Validation Loss: 0.2986
	--> Epoch [3/100], Loss: 0.3200, Validation Loss: 0.7683
	--> Epoch [4/100], Loss: 0.1480, Validation Loss: 0.6194
	--> Epoch [5/100], Loss: 0.1936, Validation Loss: 0.7489
Early stopping
	--> Training for Fold 4 took 0.02044677734375 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7135, Validation Loss: 0.8327
	--> Epoch [2/100], Loss: 0.4268, Validation Loss: 1.0469
	--> Epoch [3/100], Loss: 0.2309, Validation Loss: 0.1595
	--> Epoch [4/100], Loss: 0.2658, Validation Loss: 1.3395
	--> Epoch [5/100], Loss: 0.1393, Validation Loss: 0.7444
	--> Epoch [6/100], Loss: 0.0907, Validation Loss: 0.9672
Early stopping
	--> Training for Fold 5 took 0.022871732711791992 sec, using 6 epochs

Median number of epochs used: 7 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/7], Loss: 0.7121
	--> Final training Epoch [2/7], Loss: 0.5476
	--> Final training Epoch [3/7], Loss: 0.7490
	--> Final training Epoch [4/7], Loss: 0.3138
	--> Final training Epoch [5/7], Loss: 0.1434
	--> Final training Epoch [6/7], Loss: 0.0777
	--> Final training Epoch [7/7], Loss: 0.0352

Final training took 0.02300572395324707 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 1.5137
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8912, Validation Loss: 0.2968,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.4377,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4643,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8386, Validation Loss: 0.4067,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7959, Validation Loss: 0.5020,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8181, Validation Loss: 0.5590,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7298, Validation Loss: 0.5941,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7848, Validation Loss: 0.5609,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.4201,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.4032,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.4134,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.4965,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7649, Validation Loss: 0.5676,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.4887,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7211, Validation Loss: 0.5402,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8170, Validation Loss: 0.4175,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7310, Validation Loss: 0.5168,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.4380,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.3175,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3925,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3897,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 0.3879,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8064, Validation Loss: 0.4741,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4154,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3844,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7971, Validation Loss: 0.4125,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3973,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8374, Validation Loss: 0.4473,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3839,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8480, Validation Loss: 0.4221,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3925,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.3745,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3610,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.3852,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.4162,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3444,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3859,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.4560,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3948,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8374, Validation Loss: 0.3937,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4052,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7848, Validation Loss: 0.4594,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3494,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7947, Validation Loss: 0.4308,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8269, Validation Loss: 0.3742,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 0.4597,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8368, Validation Loss: 0.4283,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3818,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.3837,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.3852,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7942, Validation Loss: 0.4363,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7836, Validation Loss: 0.3802,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.3991,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8807, Validation Loss: 0.3326,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.4028,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8807, Validation Loss: 0.4168,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3657,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3353,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.4396,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8585, Validation Loss: 0.3722,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.4264,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8158, Validation Loss: 0.3717,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3598,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3530,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8374, Validation Loss: 0.3628,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4262,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.4096,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 0.3989,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7637, Validation Loss: 0.4557,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3814,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 1.0061, Validation Loss: 0.5719
	--> Epoch [2/100], Loss: 0.3746, Validation Loss: 0.5727
	--> Epoch [3/100], Loss: 0.2726, Validation Loss: 0.5295
	--> Epoch [4/100], Loss: 0.2591, Validation Loss: 0.4878
	--> Epoch [5/100], Loss: 0.3614, Validation Loss: 0.4025
	--> Epoch [6/100], Loss: 0.7250, Validation Loss: 0.3365
	--> Epoch [7/100], Loss: 0.2505, Validation Loss: 0.3395
	--> Epoch [8/100], Loss: 0.2175, Validation Loss: 0.3180
	--> Epoch [9/100], Loss: 0.5476, Validation Loss: 0.3438
	--> Epoch [10/100], Loss: 0.7456, Validation Loss: 0.3752
	--> Epoch [11/100], Loss: 0.2050, Validation Loss: 0.3766
Early stopping
	--> Training for Fold 1 took 0.2708885669708252 sec, using 11 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7208, Validation Loss: 0.4164
	--> Epoch [2/100], Loss: 0.6403, Validation Loss: 0.3561
	--> Epoch [3/100], Loss: 0.3195, Validation Loss: 0.3072
	--> Epoch [4/100], Loss: 0.3095, Validation Loss: 0.2375
	--> Epoch [5/100], Loss: 0.2489, Validation Loss: 0.2057
	--> Epoch [6/100], Loss: 0.7065, Validation Loss: 0.1698
	--> Epoch [7/100], Loss: 0.0010, Validation Loss: 0.1633
	--> Epoch [8/100], Loss: 0.0310, Validation Loss: 0.1991
	--> Epoch [9/100], Loss: 0.0579, Validation Loss: 0.1950
	--> Epoch [10/100], Loss: 0.2386, Validation Loss: 0.2055
Early stopping
	--> Training for Fold 2 took 0.2909047603607178 sec, using 10 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4846, Validation Loss: 0.5454
	--> Epoch [2/100], Loss: 0.3862, Validation Loss: 0.4717
	--> Epoch [3/100], Loss: 0.6944, Validation Loss: 0.4459
	--> Epoch [4/100], Loss: 0.0723, Validation Loss: 0.4185
	--> Epoch [5/100], Loss: 0.6958, Validation Loss: 0.3888
	--> Epoch [6/100], Loss: 0.0041, Validation Loss: 0.3781
	--> Epoch [7/100], Loss: 0.3719, Validation Loss: 0.3898
	--> Epoch [8/100], Loss: 0.0038, Validation Loss: 0.3418
	--> Epoch [9/100], Loss: 0.0013, Validation Loss: 0.3336
	--> Epoch [10/100], Loss: 0.0025, Validation Loss: 0.3152
	--> Epoch [11/100], Loss: 0.3062, Validation Loss: 0.3441
	--> Epoch [12/100], Loss: 0.0191, Validation Loss: 0.3488
	--> Epoch [13/100], Loss: 0.2764, Validation Loss: 0.3566
Early stopping
	--> Training for Fold 3 took 0.3950228691101074 sec, using 13 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.4946, Validation Loss: 0.4675
	--> Epoch [2/100], Loss: 0.4348, Validation Loss: 0.4047
	--> Epoch [3/100], Loss: 0.6759, Validation Loss: 0.4772
	--> Epoch [4/100], Loss: 0.1912, Validation Loss: 0.3381
	--> Epoch [5/100], Loss: 0.5459, Validation Loss: 0.2787
	--> Epoch [6/100], Loss: 0.3275, Validation Loss: 0.4058
	--> Epoch [7/100], Loss: 0.4816, Validation Loss: 0.3496
	--> Epoch [8/100], Loss: 0.1671, Validation Loss: 0.3660
Early stopping
	--> Training for Fold 4 took 0.23089051246643066 sec, using 8 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.2165, Validation Loss: 0.6306
	--> Epoch [2/100], Loss: 0.1807, Validation Loss: 0.5920
	--> Epoch [3/100], Loss: 0.3719, Validation Loss: 0.5541
	--> Epoch [4/100], Loss: 0.1872, Validation Loss: 0.5487
	--> Epoch [5/100], Loss: 0.3650, Validation Loss: 0.5268
	--> Epoch [6/100], Loss: 0.2732, Validation Loss: 0.4955
	--> Epoch [7/100], Loss: 0.3484, Validation Loss: 0.5332
	--> Epoch [8/100], Loss: 0.0341, Validation Loss: 0.5272
	--> Epoch [9/100], Loss: 0.0242, Validation Loss: 0.4884
	--> Epoch [10/100], Loss: 0.0032, Validation Loss: 0.4984
	--> Epoch [11/100], Loss: 0.2025, Validation Loss: 0.4892
	--> Epoch [12/100], Loss: 0.0387, Validation Loss: 0.5007
Early stopping
	--> Training for Fold 5 took 0.33445072174072266 sec, using 12 epochs

Median number of epochs used: 11 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/11], Loss: 0.4297
	--> Final training Epoch [2/11], Loss: 0.3589
	--> Final training Epoch [3/11], Loss: 0.1553
	--> Final training Epoch [4/11], Loss: 0.2650
	--> Final training Epoch [5/11], Loss: 0.1583
	--> Final training Epoch [6/11], Loss: 0.2994
	--> Final training Epoch [7/11], Loss: 0.2835
	--> Final training Epoch [8/11], Loss: 0.1821
	--> Final training Epoch [9/11], Loss: 0.2360
	--> Final training Epoch [10/11], Loss: 0.0601
	--> Final training Epoch [11/11], Loss: 0.2867

Final training took 0.37847471237182617 sec

TESTING
	--> Testing took 0.0099 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8992
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.2909,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8076, Validation Loss: 0.4300,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.4766,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3685,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4070,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8366, Validation Loss: 0.4769
	--> Epoch [2/100], Loss: 0.2516, Validation Loss: 0.3494
	--> Epoch [3/100], Loss: 0.0937, Validation Loss: 0.2610
	--> Epoch [4/100], Loss: 0.0320, Validation Loss: 0.2412
	--> Epoch [5/100], Loss: 0.0055, Validation Loss: 0.2281
	--> Epoch [6/100], Loss: 0.0118, Validation Loss: 0.2253
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.2279
	--> Epoch [8/100], Loss: 0.0010, Validation Loss: 0.2145
	--> Epoch [9/100], Loss: 0.0030, Validation Loss: 0.2123
	--> Epoch [10/100], Loss: 0.0016, Validation Loss: 0.2019
	--> Epoch [11/100], Loss: 0.1578, Validation Loss: 0.2174
	--> Epoch [12/100], Loss: 0.0022, Validation Loss: 0.1909
	--> Epoch [13/100], Loss: 0.1456, Validation Loss: 0.1942
	--> Epoch [14/100], Loss: 0.0002, Validation Loss: 0.1655
	--> Epoch [15/100], Loss: 0.0000, Validation Loss: 0.1603
	--> Epoch [16/100], Loss: 0.0006, Validation Loss: 0.1492
	--> Epoch [17/100], Loss: 0.0001, Validation Loss: 0.1737
	--> Epoch [18/100], Loss: 0.0034, Validation Loss: 0.1673
	--> Epoch [19/100], Loss: 0.0001, Validation Loss: 0.1861
Early stopping
	--> Training for Fold 1 took 0.5203313827514648 sec, using 19 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5276, Validation Loss: 0.3896
	--> Epoch [2/100], Loss: 0.1568, Validation Loss: 0.3533
	--> Epoch [3/100], Loss: 0.3784, Validation Loss: 0.2926
	--> Epoch [4/100], Loss: 0.3798, Validation Loss: 0.2696
	--> Epoch [5/100], Loss: 0.0289, Validation Loss: 0.1808
	--> Epoch [6/100], Loss: 0.0351, Validation Loss: 0.1765
	--> Epoch [7/100], Loss: 0.3108, Validation Loss: 0.1360
	--> Epoch [8/100], Loss: 0.0005, Validation Loss: 0.1155
	--> Epoch [9/100], Loss: 0.2949, Validation Loss: 0.1416
	--> Epoch [10/100], Loss: 0.2836, Validation Loss: 0.0993
	--> Epoch [11/100], Loss: 0.0002, Validation Loss: 0.1130
	--> Epoch [12/100], Loss: 0.0000, Validation Loss: 0.1505
	--> Epoch [13/100], Loss: 0.0000, Validation Loss: 0.2196
Early stopping
	--> Training for Fold 2 took 0.3726322650909424 sec, using 13 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.3893, Validation Loss: 0.6699
	--> Epoch [2/100], Loss: 0.3319, Validation Loss: 0.6294
	--> Epoch [3/100], Loss: 0.2954, Validation Loss: 0.6289
	--> Epoch [4/100], Loss: 0.2598, Validation Loss: 0.6153
	--> Epoch [5/100], Loss: 0.2319, Validation Loss: 0.6118
	--> Epoch [6/100], Loss: 0.2096, Validation Loss: 0.5836
	--> Epoch [7/100], Loss: 0.1872, Validation Loss: 0.6255
	--> Epoch [8/100], Loss: 0.1717, Validation Loss: 0.5998
	--> Epoch [9/100], Loss: 0.1690, Validation Loss: 0.6074
Early stopping
	--> Training for Fold 3 took 0.2703697681427002 sec, using 9 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.4495, Validation Loss: 0.4177
	--> Epoch [2/100], Loss: 0.3174, Validation Loss: 0.4659
	--> Epoch [3/100], Loss: 0.0233, Validation Loss: 0.3540
	--> Epoch [4/100], Loss: 0.2160, Validation Loss: 0.2961
	--> Epoch [5/100], Loss: 0.3151, Validation Loss: 0.2827
	--> Epoch [6/100], Loss: 0.0145, Validation Loss: 0.2655
	--> Epoch [7/100], Loss: 0.0005, Validation Loss: 0.3240
	--> Epoch [8/100], Loss: 0.4742, Validation Loss: 0.3508
	--> Epoch [9/100], Loss: 0.1765, Validation Loss: 0.3826
Early stopping
	--> Training for Fold 4 took 0.2665097713470459 sec, using 9 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4797, Validation Loss: 0.7503
	--> Epoch [2/100], Loss: 0.1315, Validation Loss: 0.6064
	--> Epoch [3/100], Loss: 0.3986, Validation Loss: 0.6339
	--> Epoch [4/100], Loss: 0.0139, Validation Loss: 0.5821
	--> Epoch [5/100], Loss: 0.0008, Validation Loss: 0.6633
	--> Epoch [6/100], Loss: 0.2021, Validation Loss: 0.5737
	--> Epoch [7/100], Loss: 0.0214, Validation Loss: 0.5937
	--> Epoch [8/100], Loss: 0.0001, Validation Loss: 0.5550
	--> Epoch [9/100], Loss: 0.0004, Validation Loss: 0.4947
	--> Epoch [10/100], Loss: 0.0022, Validation Loss: 0.5707
	--> Epoch [11/100], Loss: 0.0000, Validation Loss: 0.6038
	--> Epoch [12/100], Loss: 0.0003, Validation Loss: 0.5695
Early stopping
	--> Training for Fold 5 took 0.3681309223175049 sec, using 12 epochs

Median number of epochs used: 12 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/12], Loss: 0.4583
	--> Final training Epoch [2/12], Loss: 0.2795
	--> Final training Epoch [3/12], Loss: 0.0335
	--> Final training Epoch [4/12], Loss: 0.1017
	--> Final training Epoch [5/12], Loss: 0.0746
	--> Final training Epoch [6/12], Loss: 0.1024
	--> Final training Epoch [7/12], Loss: 0.0014
	--> Final training Epoch [8/12], Loss: 0.1012
	--> Final training Epoch [9/12], Loss: 0.0932
	--> Final training Epoch [10/12], Loss: 0.0094
	--> Final training Epoch [11/12], Loss: 0.0747
	--> Final training Epoch [12/12], Loss: 0.1140

Final training took 0.42096829414367676 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 1.5963
	--> Final Precision: 0.6667
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5455
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3515,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3736,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8287, Validation Loss: 0.3830,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7953, Validation Loss: 0.3885,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3535,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3749,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.4112,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3627,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3859,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8480, Validation Loss: 0.3875,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3834,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.3590,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3819,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.3889,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.3411, Validation Loss: 0.4097
	--> Epoch [2/100], Loss: 0.0732, Validation Loss: 0.3109
	--> Epoch [3/100], Loss: 0.3685, Validation Loss: 0.3390
	--> Epoch [4/100], Loss: 0.0217, Validation Loss: 0.3488
	--> Epoch [5/100], Loss: 0.0074, Validation Loss: 0.3277
Early stopping
	--> Training for Fold 1 took 0.11365652084350586 sec, using 5 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.3708, Validation Loss: 0.4695
	--> Epoch [2/100], Loss: 0.0338, Validation Loss: 0.3418
	--> Epoch [3/100], Loss: 0.0087, Validation Loss: 0.3116
	--> Epoch [4/100], Loss: 0.0033, Validation Loss: 0.2910
	--> Epoch [5/100], Loss: 0.0013, Validation Loss: 0.2373
	--> Epoch [6/100], Loss: 0.0115, Validation Loss: 0.2296
	--> Epoch [7/100], Loss: 0.0081, Validation Loss: 0.2511
	--> Epoch [8/100], Loss: 0.2700, Validation Loss: 0.2205
	--> Epoch [9/100], Loss: 0.0002, Validation Loss: 0.2041
	--> Epoch [10/100], Loss: 0.0000, Validation Loss: 0.1542
	--> Epoch [11/100], Loss: 0.0018, Validation Loss: 0.1585
	--> Epoch [12/100], Loss: 0.0172, Validation Loss: 0.1460
	--> Epoch [13/100], Loss: 0.0001, Validation Loss: 0.1552
	--> Epoch [14/100], Loss: 0.0000, Validation Loss: 0.1615
	--> Epoch [15/100], Loss: 0.0001, Validation Loss: 0.1149
	--> Epoch [16/100], Loss: 0.0074, Validation Loss: 0.1065
	--> Epoch [17/100], Loss: 0.0012, Validation Loss: 0.1574
	--> Epoch [18/100], Loss: 0.0124, Validation Loss: 0.1603
	--> Epoch [19/100], Loss: 0.0000, Validation Loss: 0.1553
Early stopping
	--> Training for Fold 2 took 0.5137357711791992 sec, using 19 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4560, Validation Loss: 0.4436
	--> Epoch [2/100], Loss: 0.0164, Validation Loss: 0.3431
	--> Epoch [3/100], Loss: 0.0614, Validation Loss: 0.3390
	--> Epoch [4/100], Loss: 0.0484, Validation Loss: 0.3088
	--> Epoch [5/100], Loss: 0.0002, Validation Loss: 0.2725
	--> Epoch [6/100], Loss: 0.0026, Validation Loss: 0.2589
	--> Epoch [7/100], Loss: 0.0031, Validation Loss: 0.2869
	--> Epoch [8/100], Loss: 0.0001, Validation Loss: 0.2612
	--> Epoch [9/100], Loss: 0.3265, Validation Loss: 0.2624
Early stopping
	--> Training for Fold 3 took 0.25231122970581055 sec, using 9 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.4053, Validation Loss: 0.4346
	--> Epoch [2/100], Loss: 0.1574, Validation Loss: 0.3547
	--> Epoch [3/100], Loss: 0.0231, Validation Loss: 0.2597
	--> Epoch [4/100], Loss: 0.0537, Validation Loss: 0.2663
	--> Epoch [5/100], Loss: 0.0027, Validation Loss: 0.2289
	--> Epoch [6/100], Loss: 0.0004, Validation Loss: 0.2122
	--> Epoch [7/100], Loss: 0.0019, Validation Loss: 0.2844
	--> Epoch [8/100], Loss: 0.0006, Validation Loss: 0.3265
	--> Epoch [9/100], Loss: 0.0004, Validation Loss: 0.3757
Early stopping
	--> Training for Fold 4 took 0.2698028087615967 sec, using 9 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.1633, Validation Loss: 0.6292
	--> Epoch [2/100], Loss: 0.0104, Validation Loss: 0.6225
	--> Epoch [3/100], Loss: 0.0169, Validation Loss: 0.5661
	--> Epoch [4/100], Loss: 0.1439, Validation Loss: 0.6189
	--> Epoch [5/100], Loss: 0.0192, Validation Loss: 0.6148
	--> Epoch [6/100], Loss: 0.0336, Validation Loss: 0.5870
Early stopping
	--> Training for Fold 5 took 0.16640233993530273 sec, using 6 epochs

Median number of epochs used: 9 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/9], Loss: 0.2402
	--> Final training Epoch [2/9], Loss: 0.1617
	--> Final training Epoch [3/9], Loss: 0.1734
	--> Final training Epoch [4/9], Loss: 0.0108
	--> Final training Epoch [5/9], Loss: 0.0122
	--> Final training Epoch [6/9], Loss: 0.0090
	--> Final training Epoch [7/9], Loss: 0.0616
	--> Final training Epoch [8/9], Loss: 0.1394
	--> Final training Epoch [9/9], Loss: 0.0029

Final training took 0.30916285514831543 sec

TESTING
	--> Testing took 0.0073 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.1980
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8807, Validation Loss: 0.3698,  Current Best Accuracy: 0.8807,  Current Best Validation Loss: 0.3698

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7872, Validation Loss: 0.4746
	--> Epoch [2/100], Loss: 0.0936, Validation Loss: 0.3507
	--> Epoch [3/100], Loss: 0.0275, Validation Loss: 0.3351
	--> Epoch [4/100], Loss: 0.0145, Validation Loss: 0.3232
	--> Epoch [5/100], Loss: 0.0192, Validation Loss: 0.2902
	--> Epoch [6/100], Loss: 0.0473, Validation Loss: 0.2746
	--> Epoch [7/100], Loss: 0.3361, Validation Loss: 0.2746
	--> Epoch [8/100], Loss: 0.0016, Validation Loss: 0.2787
	--> Epoch [9/100], Loss: 0.0000, Validation Loss: 0.2600
	--> Epoch [10/100], Loss: 0.0000, Validation Loss: 0.2705
	--> Epoch [11/100], Loss: 0.0004, Validation Loss: 0.2277
	--> Epoch [12/100], Loss: 0.0010, Validation Loss: 0.2287
	--> Epoch [13/100], Loss: 0.0001, Validation Loss: 0.2168
	--> Epoch [14/100], Loss: 0.2334, Validation Loss: 0.2374
	--> Epoch [15/100], Loss: 0.0002, Validation Loss: 0.2886
	--> Epoch [16/100], Loss: 0.0000, Validation Loss: 0.2732
Early stopping
	--> Training for Fold 1 took 0.40215253829956055 sec, using 16 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.3650, Validation Loss: 0.4481
	--> Epoch [2/100], Loss: 0.0087, Validation Loss: 0.3015
	--> Epoch [3/100], Loss: 0.0318, Validation Loss: 0.2113
	--> Epoch [4/100], Loss: 0.0080, Validation Loss: 0.1703
	--> Epoch [5/100], Loss: 0.0046, Validation Loss: 0.1432
	--> Epoch [6/100], Loss: 0.5241, Validation Loss: 0.1691
	--> Epoch [7/100], Loss: 0.0052, Validation Loss: 0.1487
	--> Epoch [8/100], Loss: 0.0002, Validation Loss: 0.1420
	--> Epoch [9/100], Loss: 0.0048, Validation Loss: 0.1337
	--> Epoch [10/100], Loss: 0.0197, Validation Loss: 0.1419
	--> Epoch [11/100], Loss: 0.0016, Validation Loss: 0.1655
	--> Epoch [12/100], Loss: 0.0000, Validation Loss: 0.1765
Early stopping
	--> Training for Fold 2 took 0.3446981906890869 sec, using 12 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6016, Validation Loss: 0.5393
	--> Epoch [2/100], Loss: 0.1486, Validation Loss: 0.4648
	--> Epoch [3/100], Loss: 0.0057, Validation Loss: 0.3744
	--> Epoch [4/100], Loss: 0.0003, Validation Loss: 0.3566
	--> Epoch [5/100], Loss: 0.0847, Validation Loss: 0.3326
	--> Epoch [6/100], Loss: 0.0128, Validation Loss: 0.3343
	--> Epoch [7/100], Loss: 0.1502, Validation Loss: 0.4437
	--> Epoch [8/100], Loss: 0.0000, Validation Loss: 0.3508
Early stopping
	--> Training for Fold 3 took 0.23267865180969238 sec, using 8 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5884, Validation Loss: 0.3995
	--> Epoch [2/100], Loss: 0.2019, Validation Loss: 0.3340
	--> Epoch [3/100], Loss: 0.0118, Validation Loss: 0.3123
	--> Epoch [4/100], Loss: 0.0085, Validation Loss: 0.2746
	--> Epoch [5/100], Loss: 0.0029, Validation Loss: 0.2451
	--> Epoch [6/100], Loss: 0.0034, Validation Loss: 0.2879
	--> Epoch [7/100], Loss: 0.0026, Validation Loss: 0.3074
	--> Epoch [8/100], Loss: 0.0010, Validation Loss: 0.2924
Early stopping
	--> Training for Fold 4 took 0.2376718521118164 sec, using 8 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.2771, Validation Loss: 0.8109
	--> Epoch [2/100], Loss: 0.0083, Validation Loss: 0.7750
	--> Epoch [3/100], Loss: 0.0390, Validation Loss: 0.7809
	--> Epoch [4/100], Loss: 0.0040, Validation Loss: 0.7597
	--> Epoch [5/100], Loss: 0.0035, Validation Loss: 0.7932
	--> Epoch [6/100], Loss: 0.0021, Validation Loss: 0.7846
	--> Epoch [7/100], Loss: 0.0219, Validation Loss: 1.0201
Early stopping
	--> Training for Fold 5 took 0.20516133308410645 sec, using 7 epochs

Median number of epochs used: 8 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/8], Loss: 0.4748
	--> Final training Epoch [2/8], Loss: 0.2775
	--> Final training Epoch [3/8], Loss: 0.0100
	--> Final training Epoch [4/8], Loss: 0.1158
	--> Final training Epoch [5/8], Loss: 0.0067
	--> Final training Epoch [6/8], Loss: 0.1980
	--> Final training Epoch [7/8], Loss: 0.0002
	--> Final training Epoch [8/8], Loss: 0.0736

Final training took 0.28839564323425293 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 1.1508
	--> Final Precision: 0.6667
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5455
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8480, Validation Loss: 0.3561,  Current Best Accuracy: 0.8480,  Current Best Validation Loss: 0.3561

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.3481, Validation Loss: 0.4098
	--> Epoch [2/100], Loss: 0.3246, Validation Loss: 0.3432
	--> Epoch [3/100], Loss: 0.3305, Validation Loss: 0.2779
	--> Epoch [4/100], Loss: 0.0207, Validation Loss: 0.2766
	--> Epoch [5/100], Loss: 0.2219, Validation Loss: 0.2238
	--> Epoch [6/100], Loss: 0.0011, Validation Loss: 0.3344
	--> Epoch [7/100], Loss: 0.0006, Validation Loss: 0.3219
	--> Epoch [8/100], Loss: 0.0027, Validation Loss: 0.3094
Early stopping
	--> Training for Fold 1 took 0.1793994903564453 sec, using 8 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6523, Validation Loss: 0.4058
	--> Epoch [2/100], Loss: 0.1361, Validation Loss: 0.3483
	--> Epoch [3/100], Loss: 0.0524, Validation Loss: 0.2682
	--> Epoch [4/100], Loss: 0.0006, Validation Loss: 0.2911
	--> Epoch [5/100], Loss: 0.0003, Validation Loss: 0.2888
	--> Epoch [6/100], Loss: 0.1008, Validation Loss: 0.2284
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.2201
	--> Epoch [8/100], Loss: 0.0117, Validation Loss: 0.2169
	--> Epoch [9/100], Loss: 0.0000, Validation Loss: 0.1960
	--> Epoch [10/100], Loss: 0.0000, Validation Loss: 0.1641
	--> Epoch [11/100], Loss: 0.1156, Validation Loss: 0.1759
	--> Epoch [12/100], Loss: 0.0000, Validation Loss: 0.1739
	--> Epoch [13/100], Loss: 0.0000, Validation Loss: 0.1674
Early stopping
	--> Training for Fold 2 took 0.3771250247955322 sec, using 13 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4409, Validation Loss: 0.4454
	--> Epoch [2/100], Loss: 0.0035, Validation Loss: 0.3689
	--> Epoch [3/100], Loss: 0.0230, Validation Loss: 0.3309
	--> Epoch [4/100], Loss: 0.0161, Validation Loss: 0.3024
	--> Epoch [5/100], Loss: 0.0091, Validation Loss: 0.3284
	--> Epoch [6/100], Loss: 0.0187, Validation Loss: 0.2373
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.2431
	--> Epoch [8/100], Loss: 0.0173, Validation Loss: 0.2249
	--> Epoch [9/100], Loss: 0.0000, Validation Loss: 0.2220
	--> Epoch [10/100], Loss: 0.3137, Validation Loss: 0.2487
	--> Epoch [11/100], Loss: 0.0001, Validation Loss: 0.2720
	--> Epoch [12/100], Loss: 0.0074, Validation Loss: 0.3166
Early stopping
	--> Training for Fold 3 took 0.35239624977111816 sec, using 12 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5437, Validation Loss: 0.7022
	--> Epoch [2/100], Loss: 0.4773, Validation Loss: 0.7055
	--> Epoch [3/100], Loss: 0.4045, Validation Loss: 0.6321
	--> Epoch [4/100], Loss: 0.3922, Validation Loss: 0.6760
	--> Epoch [5/100], Loss: 0.3157, Validation Loss: 0.6218
	--> Epoch [6/100], Loss: 0.2808, Validation Loss: 0.6293
	--> Epoch [7/100], Loss: 0.2647, Validation Loss: 0.5814
	--> Epoch [8/100], Loss: 0.2302, Validation Loss: 0.5859
	--> Epoch [9/100], Loss: 0.2019, Validation Loss: 0.6110
	--> Epoch [10/100], Loss: 0.1843, Validation Loss: 0.6222
Early stopping
	--> Training for Fold 4 took 0.2835259437561035 sec, using 10 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4026, Validation Loss: 0.7589
	--> Epoch [2/100], Loss: 0.0098, Validation Loss: 0.6367
	--> Epoch [3/100], Loss: 0.0042, Validation Loss: 0.6329
	--> Epoch [4/100], Loss: 0.0034, Validation Loss: 0.7039
	--> Epoch [5/100], Loss: 0.9033, Validation Loss: 0.7890
	--> Epoch [6/100], Loss: 0.0031, Validation Loss: 0.7778
Early stopping
	--> Training for Fold 5 took 0.1718616485595703 sec, using 6 epochs

Median number of epochs used: 10 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/10], Loss: 0.3704
	--> Final training Epoch [2/10], Loss: 0.1075
	--> Final training Epoch [3/10], Loss: 0.1128
	--> Final training Epoch [4/10], Loss: 0.0937
	--> Final training Epoch [5/10], Loss: 0.0301
	--> Final training Epoch [6/10], Loss: 0.1580
	--> Final training Epoch [7/10], Loss: 0.0016
	--> Final training Epoch [8/10], Loss: 0.1824
	--> Final training Epoch [9/10], Loss: 0.0245
	--> Final training Epoch [10/10], Loss: 0.0621

Final training took 0.33599209785461426 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.5552
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.2956,  Current Best Accuracy: 0.8497,  Current Best Validation Loss: 0.2956

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.4544, Validation Loss: 0.4727
	--> Epoch [2/100], Loss: 0.1649, Validation Loss: 0.3307
	--> Epoch [3/100], Loss: 0.0090, Validation Loss: 0.2796
	--> Epoch [4/100], Loss: 0.0095, Validation Loss: 0.2603
	--> Epoch [5/100], Loss: 0.0003, Validation Loss: 0.2389
	--> Epoch [6/100], Loss: 0.0555, Validation Loss: 0.2343
	--> Epoch [7/100], Loss: 0.0012, Validation Loss: 0.2361
	--> Epoch [8/100], Loss: 0.0010, Validation Loss: 0.2466
	--> Epoch [9/100], Loss: 0.0146, Validation Loss: 0.2371
Early stopping
	--> Training for Fold 1 took 0.20566129684448242 sec, using 9 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.4578, Validation Loss: 0.5271
	--> Epoch [2/100], Loss: 0.3399, Validation Loss: 0.4036
	--> Epoch [3/100], Loss: 0.3188, Validation Loss: 0.2999
	--> Epoch [4/100], Loss: 0.0286, Validation Loss: 0.3274
	--> Epoch [5/100], Loss: 0.0034, Validation Loss: 0.2858
	--> Epoch [6/100], Loss: 0.0011, Validation Loss: 0.2814
	--> Epoch [7/100], Loss: 0.0009, Validation Loss: 0.2532
	--> Epoch [8/100], Loss: 0.2133, Validation Loss: 0.2381
	--> Epoch [9/100], Loss: 0.2025, Validation Loss: 0.2465
	--> Epoch [10/100], Loss: 0.1881, Validation Loss: 0.2234
	--> Epoch [11/100], Loss: 0.0001, Validation Loss: 0.2143
	--> Epoch [12/100], Loss: 0.1000, Validation Loss: 0.2213
	--> Epoch [13/100], Loss: 0.0000, Validation Loss: 0.2282
	--> Epoch [14/100], Loss: 0.0000, Validation Loss: 0.2269
Early stopping
	--> Training for Fold 2 took 0.41666364669799805 sec, using 14 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4140, Validation Loss: 0.5169
	--> Epoch [2/100], Loss: 0.3871, Validation Loss: 0.4390
	--> Epoch [3/100], Loss: 0.0414, Validation Loss: 0.3766
	--> Epoch [4/100], Loss: 0.2595, Validation Loss: 0.3078
	--> Epoch [5/100], Loss: 0.2285, Validation Loss: 0.3085
	--> Epoch [6/100], Loss: 0.0532, Validation Loss: 0.3156
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.3163
Early stopping
	--> Training for Fold 3 took 0.18801331520080566 sec, using 7 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.3161, Validation Loss: 0.5125
	--> Epoch [2/100], Loss: 0.1211, Validation Loss: 0.4697
	--> Epoch [3/100], Loss: 0.0241, Validation Loss: 0.4547
	--> Epoch [4/100], Loss: 0.2256, Validation Loss: 0.4825
	--> Epoch [5/100], Loss: 0.0083, Validation Loss: 0.5186
	--> Epoch [6/100], Loss: 0.0039, Validation Loss: 0.4040
	--> Epoch [7/100], Loss: 0.0214, Validation Loss: 0.4365
	--> Epoch [8/100], Loss: 0.0036, Validation Loss: 0.4799
	--> Epoch [9/100], Loss: 0.0001, Validation Loss: 0.4946
Early stopping
	--> Training for Fold 4 took 0.25760412216186523 sec, using 9 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.3144, Validation Loss: 0.7327
	--> Epoch [2/100], Loss: 0.3178, Validation Loss: 0.7356
	--> Epoch [3/100], Loss: 0.1212, Validation Loss: 0.6942
	--> Epoch [4/100], Loss: 0.0031, Validation Loss: 0.6283
	--> Epoch [5/100], Loss: 0.0246, Validation Loss: 0.7489
	--> Epoch [6/100], Loss: 0.1817, Validation Loss: 0.7330
	--> Epoch [7/100], Loss: 0.0002, Validation Loss: 0.7917
Early stopping
	--> Training for Fold 5 took 0.1820671558380127 sec, using 7 epochs

Median number of epochs used: 9 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/9], Loss: 0.3769
	--> Final training Epoch [2/9], Loss: 0.2448
	--> Final training Epoch [3/9], Loss: 0.0563
	--> Final training Epoch [4/9], Loss: 0.2600
	--> Final training Epoch [5/9], Loss: 0.0415
	--> Final training Epoch [6/9], Loss: 0.0092
	--> Final training Epoch [7/9], Loss: 0.1509
	--> Final training Epoch [8/9], Loss: 0.2904
	--> Final training Epoch [9/9], Loss: 0.1500

Final training took 0.3169534206390381 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.3118
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3300,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3808,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8608, Validation Loss: 0.3626,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4152,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.3819,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7947, Validation Loss: 0.3892,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5715, Validation Loss: 0.4237
	--> Epoch [2/100], Loss: 0.1497, Validation Loss: 0.3761
	--> Epoch [3/100], Loss: 0.0166, Validation Loss: 0.3281
	--> Epoch [4/100], Loss: 0.0216, Validation Loss: 0.2747
	--> Epoch [5/100], Loss: 0.0012, Validation Loss: 0.2573
	--> Epoch [6/100], Loss: 0.0056, Validation Loss: 0.2483
	--> Epoch [7/100], Loss: 0.0012, Validation Loss: 0.2676
	--> Epoch [8/100], Loss: 0.0037, Validation Loss: 0.2618
	--> Epoch [9/100], Loss: 0.0009, Validation Loss: 0.2812
Early stopping
	--> Training for Fold 1 took 0.20745563507080078 sec, using 9 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.4238, Validation Loss: 0.4705
	--> Epoch [2/100], Loss: 0.0570, Validation Loss: 0.3391
	--> Epoch [3/100], Loss: 0.0080, Validation Loss: 0.2307
	--> Epoch [4/100], Loss: 0.0041, Validation Loss: 0.2318
	--> Epoch [5/100], Loss: 0.0127, Validation Loss: 0.1932
	--> Epoch [6/100], Loss: 0.0009, Validation Loss: 0.1929
	--> Epoch [7/100], Loss: 0.0005, Validation Loss: 0.2069
	--> Epoch [8/100], Loss: 0.0008, Validation Loss: 0.1725
	--> Epoch [9/100], Loss: 0.0008, Validation Loss: 0.1558
	--> Epoch [10/100], Loss: 0.0003, Validation Loss: 0.1689
	--> Epoch [11/100], Loss: 0.0099, Validation Loss: 0.1638
	--> Epoch [12/100], Loss: 0.0001, Validation Loss: 0.1559
Early stopping
	--> Training for Fold 2 took 0.34967041015625 sec, using 12 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.2732, Validation Loss: 0.4639
	--> Epoch [2/100], Loss: 0.0238, Validation Loss: 0.3865
	--> Epoch [3/100], Loss: 0.2974, Validation Loss: 0.3754
	--> Epoch [4/100], Loss: 0.0037, Validation Loss: 0.4227
	--> Epoch [5/100], Loss: 0.0151, Validation Loss: 0.4228
	--> Epoch [6/100], Loss: 0.0117, Validation Loss: 0.4692
Early stopping
	--> Training for Fold 3 took 0.17578721046447754 sec, using 6 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.3700, Validation Loss: 0.4594
	--> Epoch [2/100], Loss: 0.0874, Validation Loss: 0.4137
	--> Epoch [3/100], Loss: 0.0260, Validation Loss: 0.4196
	--> Epoch [4/100], Loss: 0.0200, Validation Loss: 0.3858
	--> Epoch [5/100], Loss: 0.0044, Validation Loss: 0.3756
	--> Epoch [6/100], Loss: 0.0047, Validation Loss: 0.4105
	--> Epoch [7/100], Loss: 0.0045, Validation Loss: 0.3801
	--> Epoch [8/100], Loss: 0.0002, Validation Loss: 0.3754
	--> Epoch [9/100], Loss: 0.0011, Validation Loss: 0.3766
	--> Epoch [10/100], Loss: 0.0267, Validation Loss: 0.4270
	--> Epoch [11/100], Loss: 0.0050, Validation Loss: 0.4292
Early stopping
	--> Training for Fold 4 took 0.3264598846435547 sec, using 11 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.1594, Validation Loss: 0.6972
	--> Epoch [2/100], Loss: 0.2766, Validation Loss: 0.5672
	--> Epoch [3/100], Loss: 0.0012, Validation Loss: 0.6004
	--> Epoch [4/100], Loss: 0.0164, Validation Loss: 0.6176
	--> Epoch [5/100], Loss: 0.0043, Validation Loss: 0.6213
Early stopping
	--> Training for Fold 5 took 0.15617942810058594 sec, using 5 epochs

Median number of epochs used: 9 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/9], Loss: 0.4838
	--> Final training Epoch [2/9], Loss: 0.4208
	--> Final training Epoch [3/9], Loss: 0.0378
	--> Final training Epoch [4/9], Loss: 0.0837
	--> Final training Epoch [5/9], Loss: 0.1424
	--> Final training Epoch [6/9], Loss: 0.0094
	--> Final training Epoch [7/9], Loss: 0.1323
	--> Final training Epoch [8/9], Loss: 0.1282
	--> Final training Epoch [9/9], Loss: 0.0102

Final training took 0.3160858154296875 sec

TESTING
	--> Testing took 0.0119 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 1.2735
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3199,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3378,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8801, Validation Loss: 0.3817,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8713, Validation Loss: 0.3453,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.3781,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3665,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.3846,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7947, Validation Loss: 0.4241,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8152, Validation Loss: 0.4121,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3629,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3476,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3498,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6224, Validation Loss: 0.4730
	--> Epoch [2/100], Loss: 0.3514, Validation Loss: 0.4103
	--> Epoch [3/100], Loss: 0.3161, Validation Loss: 0.3058
	--> Epoch [4/100], Loss: 0.1919, Validation Loss: 0.2978
	--> Epoch [5/100], Loss: 0.2631, Validation Loss: 0.2589
	--> Epoch [6/100], Loss: 0.1888, Validation Loss: 0.2771
	--> Epoch [7/100], Loss: 0.0741, Validation Loss: 0.2654
	--> Epoch [8/100], Loss: 0.0387, Validation Loss: 0.2708
Early stopping
	--> Training for Fold 1 took 0.09170913696289062 sec, using 8 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.4956, Validation Loss: 0.5212
	--> Epoch [2/100], Loss: 0.6903, Validation Loss: 0.3433
	--> Epoch [3/100], Loss: 0.2603, Validation Loss: 0.2575
	--> Epoch [4/100], Loss: 0.3273, Validation Loss: 0.2392
	--> Epoch [5/100], Loss: 0.2472, Validation Loss: 0.2045
	--> Epoch [6/100], Loss: 0.1358, Validation Loss: 0.2022
	--> Epoch [7/100], Loss: 0.2760, Validation Loss: 0.1793
	--> Epoch [8/100], Loss: 0.1485, Validation Loss: 0.1967
	--> Epoch [9/100], Loss: 0.1631, Validation Loss: 0.2004
	--> Epoch [10/100], Loss: 0.0690, Validation Loss: 0.1967
Early stopping
	--> Training for Fold 2 took 0.12308526039123535 sec, using 10 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.3883, Validation Loss: 0.7298
	--> Epoch [2/100], Loss: 0.3242, Validation Loss: 0.6403
	--> Epoch [3/100], Loss: 0.2970, Validation Loss: 0.4906
	--> Epoch [4/100], Loss: 0.2074, Validation Loss: 0.4900
	--> Epoch [5/100], Loss: 0.2072, Validation Loss: 0.4220
	--> Epoch [6/100], Loss: 0.5507, Validation Loss: 0.4023
	--> Epoch [7/100], Loss: 0.1341, Validation Loss: 0.4032
	--> Epoch [8/100], Loss: 0.1452, Validation Loss: 0.3781
	--> Epoch [9/100], Loss: 0.0919, Validation Loss: 0.3940
	--> Epoch [10/100], Loss: 0.1475, Validation Loss: 0.3781
	--> Epoch [11/100], Loss: 0.0746, Validation Loss: 0.3480
	--> Epoch [12/100], Loss: 0.0715, Validation Loss: 0.3468
	--> Epoch [13/100], Loss: 0.1538, Validation Loss: 0.3795
	--> Epoch [14/100], Loss: 0.0649, Validation Loss: 0.3582
	--> Epoch [15/100], Loss: 0.1401, Validation Loss: 0.3869
Early stopping
	--> Training for Fold 3 took 0.19577980041503906 sec, using 15 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6018, Validation Loss: 0.5277
	--> Epoch [2/100], Loss: 0.4170, Validation Loss: 0.3915
	--> Epoch [3/100], Loss: 0.4383, Validation Loss: 0.3900
	--> Epoch [4/100], Loss: 0.1731, Validation Loss: 0.4040
	--> Epoch [5/100], Loss: 0.1394, Validation Loss: 0.4111
	--> Epoch [6/100], Loss: 0.0736, Validation Loss: 0.3989
Early stopping
	--> Training for Fold 4 took 0.07582259178161621 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5785, Validation Loss: 0.6044
	--> Epoch [2/100], Loss: 0.3573, Validation Loss: 0.5493
	--> Epoch [3/100], Loss: 0.1750, Validation Loss: 0.5610
	--> Epoch [4/100], Loss: 0.1449, Validation Loss: 0.5308
	--> Epoch [5/100], Loss: 0.1567, Validation Loss: 0.5830
	--> Epoch [6/100], Loss: 0.3045, Validation Loss: 0.6606
	--> Epoch [7/100], Loss: 0.1538, Validation Loss: 0.6273
Early stopping
	--> Training for Fold 5 took 0.07936263084411621 sec, using 7 epochs

Median number of epochs used: 8 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/8], Loss: 0.6213
	--> Final training Epoch [2/8], Loss: 0.4980
	--> Final training Epoch [3/8], Loss: 0.3007
	--> Final training Epoch [4/8], Loss: 0.3654
	--> Final training Epoch [5/8], Loss: 0.3816
	--> Final training Epoch [6/8], Loss: 0.2410
	--> Final training Epoch [7/8], Loss: 0.1316
	--> Final training Epoch [8/8], Loss: 0.3211

Final training took 0.10863256454467773 sec

TESTING
	--> Testing took 0.0071 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 0.7780
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8918, Validation Loss: 0.2760,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8696, Validation Loss: 0.3413,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8158, Validation Loss: 0.3724,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3627,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.3586,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7947, Validation Loss: 0.4055,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3231,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3187,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3207,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8164, Validation Loss: 0.3669,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8579, Validation Loss: 0.3121,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.3354,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7620, Validation Loss: 0.4154,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8287, Validation Loss: 0.3654,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3600,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3612,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8696, Validation Loss: 0.3147,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3374,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3399,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3562,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8585, Validation Loss: 0.3853,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8585, Validation Loss: 0.3738,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8170, Validation Loss: 0.4244,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3355,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3819,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7166, Validation Loss: 0.4661
	--> Epoch [2/100], Loss: 0.3366, Validation Loss: 0.3073
	--> Epoch [3/100], Loss: 0.1758, Validation Loss: 0.2706
	--> Epoch [4/100], Loss: 0.0933, Validation Loss: 0.2437
	--> Epoch [5/100], Loss: 0.1385, Validation Loss: 0.2345
	--> Epoch [6/100], Loss: 0.0950, Validation Loss: 0.2392
	--> Epoch [7/100], Loss: 0.0873, Validation Loss: 0.2106
	--> Epoch [8/100], Loss: 0.0726, Validation Loss: 0.2378
	--> Epoch [9/100], Loss: 0.0633, Validation Loss: 0.2132
	--> Epoch [10/100], Loss: 0.1665, Validation Loss: 0.2075
	--> Epoch [11/100], Loss: 0.0759, Validation Loss: 0.2182
	--> Epoch [12/100], Loss: 0.0680, Validation Loss: 0.2279
	--> Epoch [13/100], Loss: 0.0596, Validation Loss: 0.2037
	--> Epoch [14/100], Loss: 0.0594, Validation Loss: 0.1997
	--> Epoch [15/100], Loss: 0.0628, Validation Loss: 0.1973
	--> Epoch [16/100], Loss: 0.0622, Validation Loss: 0.1802
	--> Epoch [17/100], Loss: 0.0648, Validation Loss: 0.2071
	--> Epoch [18/100], Loss: 0.1215, Validation Loss: 0.1886
	--> Epoch [19/100], Loss: 0.0612, Validation Loss: 0.1648
	--> Epoch [20/100], Loss: 0.0598, Validation Loss: 0.1734
	--> Epoch [21/100], Loss: 0.0621, Validation Loss: 0.1534
	--> Epoch [22/100], Loss: 0.0641, Validation Loss: 0.1828
	--> Epoch [23/100], Loss: 0.1426, Validation Loss: 0.1750
	--> Epoch [24/100], Loss: 0.0633, Validation Loss: 0.1742
Early stopping
	--> Training for Fold 1 took 0.28949952125549316 sec, using 24 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7901, Validation Loss: 0.3964
	--> Epoch [2/100], Loss: 0.3589, Validation Loss: 0.3189
	--> Epoch [3/100], Loss: 0.1815, Validation Loss: 0.2578
	--> Epoch [4/100], Loss: 0.1393, Validation Loss: 0.2351
	--> Epoch [5/100], Loss: 0.1535, Validation Loss: 0.2200
	--> Epoch [6/100], Loss: 0.1537, Validation Loss: 0.2020
	--> Epoch [7/100], Loss: 0.1282, Validation Loss: 0.1710
	--> Epoch [8/100], Loss: 0.1091, Validation Loss: 0.1566
	--> Epoch [9/100], Loss: 0.1500, Validation Loss: 0.1464
	--> Epoch [10/100], Loss: 0.1758, Validation Loss: 0.1415
	--> Epoch [11/100], Loss: 0.1065, Validation Loss: 0.1426
	--> Epoch [12/100], Loss: 0.1193, Validation Loss: 0.1382
	--> Epoch [13/100], Loss: 0.1067, Validation Loss: 0.1218
	--> Epoch [14/100], Loss: 0.1925, Validation Loss: 0.1179
	--> Epoch [15/100], Loss: 0.1287, Validation Loss: 0.1168
	--> Epoch [16/100], Loss: 0.1106, Validation Loss: 0.1177
	--> Epoch [17/100], Loss: 0.1137, Validation Loss: 0.1489
	--> Epoch [18/100], Loss: 0.1119, Validation Loss: 0.1325
Early stopping
	--> Training for Fold 2 took 0.22784662246704102 sec, using 18 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6347, Validation Loss: 0.5405
	--> Epoch [2/100], Loss: 0.4152, Validation Loss: 0.4624
	--> Epoch [3/100], Loss: 0.2304, Validation Loss: 0.3702
	--> Epoch [4/100], Loss: 0.2046, Validation Loss: 0.3525
	--> Epoch [5/100], Loss: 0.2038, Validation Loss: 0.3647
	--> Epoch [6/100], Loss: 0.1876, Validation Loss: 0.3991
	--> Epoch [7/100], Loss: 0.1737, Validation Loss: 0.4165
Early stopping
	--> Training for Fold 3 took 0.08296799659729004 sec, using 7 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5140, Validation Loss: 0.5780
	--> Epoch [2/100], Loss: 0.3644, Validation Loss: 0.4825
	--> Epoch [3/100], Loss: 0.1345, Validation Loss: 0.3729
	--> Epoch [4/100], Loss: 0.1116, Validation Loss: 0.4683
	--> Epoch [5/100], Loss: 0.0683, Validation Loss: 0.4066
	--> Epoch [6/100], Loss: 0.0121, Validation Loss: 0.4170
Early stopping
	--> Training for Fold 4 took 0.07626128196716309 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5873, Validation Loss: 0.5658
	--> Epoch [2/100], Loss: 0.3704, Validation Loss: 0.5205
	--> Epoch [3/100], Loss: 0.2206, Validation Loss: 0.5157
	--> Epoch [4/100], Loss: 0.1126, Validation Loss: 0.5557
	--> Epoch [5/100], Loss: 0.0874, Validation Loss: 0.6210
	--> Epoch [6/100], Loss: 0.1268, Validation Loss: 0.5399
Early stopping
	--> Training for Fold 5 took 0.07067394256591797 sec, using 6 epochs

Median number of epochs used: 7 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/7], Loss: 0.7212
	--> Final training Epoch [2/7], Loss: 0.3384
	--> Final training Epoch [3/7], Loss: 0.2001
	--> Final training Epoch [4/7], Loss: 0.2077
	--> Final training Epoch [5/7], Loss: 0.2244
	--> Final training Epoch [6/7], Loss: 0.0932
	--> Final training Epoch [7/7], Loss: 0.0331

Final training took 0.1025078296661377 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9642
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.9018, Validation Loss: 0.2951,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3597,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3617,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3150,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3268,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8503, Validation Loss: 0.3780,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3999,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3387,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3952,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3634,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3421,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3141,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3862,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8819, Validation Loss: 0.3190,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 0.4126,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.4019,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8047, Validation Loss: 0.3734,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3369,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3211,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3843,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8713, Validation Loss: 0.3673,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3608,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.3531,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4028,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.4035,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.4493,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8924, Validation Loss: 0.3180,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8918, Validation Loss: 0.3392,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8585, Validation Loss: 0.3679,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8690, Validation Loss: 0.3136,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.3831,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3403,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8474, Validation Loss: 0.3423,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.4039,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7836, Validation Loss: 0.4516,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8924, Validation Loss: 0.3121,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8368, Validation Loss: 0.3719,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8819, Validation Loss: 0.3020,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8053, Validation Loss: 0.4281,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8819, Validation Loss: 0.3133,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3523,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3834,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3402,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3792,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8480, Validation Loss: 0.3278,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3347,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3771,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3670,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8713, Validation Loss: 0.3198,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3613,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.4051,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 0.4174,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8696, Validation Loss: 0.3542,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3437,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8801, Validation Loss: 0.3421,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3889,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3571,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8591, Validation Loss: 0.3455,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3762,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.3540,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.3565,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.4254,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8158, Validation Loss: 0.3486,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3956,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8713, Validation Loss: 0.3600,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8269, Validation Loss: 0.3389,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3980,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3384,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7842, Validation Loss: 0.4324,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8170, Validation Loss: 0.4936,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7836, Validation Loss: 0.4592,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8035, Validation Loss: 0.3501,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3514,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3267,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.4134,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3960,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6492, Validation Loss: 0.5683
	--> Epoch [2/100], Loss: 0.4659, Validation Loss: 0.4757
	--> Epoch [3/100], Loss: 0.3484, Validation Loss: 0.3937
	--> Epoch [4/100], Loss: 0.3227, Validation Loss: 0.3521
	--> Epoch [5/100], Loss: 0.1910, Validation Loss: 0.3613
	--> Epoch [6/100], Loss: 0.0833, Validation Loss: 0.3152
	--> Epoch [7/100], Loss: 0.1224, Validation Loss: 0.2861
	--> Epoch [8/100], Loss: 0.1728, Validation Loss: 0.2865
	--> Epoch [9/100], Loss: 0.0881, Validation Loss: 0.2632
	--> Epoch [10/100], Loss: 0.0226, Validation Loss: 0.2666
	--> Epoch [11/100], Loss: 0.0592, Validation Loss: 0.2649
	--> Epoch [12/100], Loss: 0.0716, Validation Loss: 0.2495
	--> Epoch [13/100], Loss: 0.0799, Validation Loss: 0.2522
	--> Epoch [14/100], Loss: 0.0938, Validation Loss: 0.2457
	--> Epoch [15/100], Loss: 0.0778, Validation Loss: 0.2551
	--> Epoch [16/100], Loss: 0.0170, Validation Loss: 0.2535
	--> Epoch [17/100], Loss: 0.0075, Validation Loss: 0.2570
Early stopping
	--> Training for Fold 1 took 0.09631800651550293 sec, using 17 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6817, Validation Loss: 0.5761
	--> Epoch [2/100], Loss: 0.4921, Validation Loss: 0.5214
	--> Epoch [3/100], Loss: 0.3403, Validation Loss: 0.4358
	--> Epoch [4/100], Loss: 0.2793, Validation Loss: 0.4183
	--> Epoch [5/100], Loss: 0.2535, Validation Loss: 0.3777
	--> Epoch [6/100], Loss: 0.1436, Validation Loss: 0.3373
	--> Epoch [7/100], Loss: 0.2069, Validation Loss: 0.3051
	--> Epoch [8/100], Loss: 0.1510, Validation Loss: 0.2755
	--> Epoch [9/100], Loss: 0.0317, Validation Loss: 0.2579
	--> Epoch [10/100], Loss: 0.1742, Validation Loss: 0.2440
	--> Epoch [11/100], Loss: 0.0090, Validation Loss: 0.2216
	--> Epoch [12/100], Loss: 0.0926, Validation Loss: 0.2174
	--> Epoch [13/100], Loss: 0.1430, Validation Loss: 0.2277
	--> Epoch [14/100], Loss: 0.2174, Validation Loss: 0.2270
	--> Epoch [15/100], Loss: 0.0116, Validation Loss: 0.2280
Early stopping
	--> Training for Fold 2 took 0.08288359642028809 sec, using 15 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4926, Validation Loss: 0.6099
	--> Epoch [2/100], Loss: 0.3523, Validation Loss: 0.6064
	--> Epoch [3/100], Loss: 0.1470, Validation Loss: 0.5301
	--> Epoch [4/100], Loss: 0.2611, Validation Loss: 0.4835
	--> Epoch [5/100], Loss: 0.2709, Validation Loss: 0.4696
	--> Epoch [6/100], Loss: 0.0915, Validation Loss: 0.4634
	--> Epoch [7/100], Loss: 0.1327, Validation Loss: 0.4327
	--> Epoch [8/100], Loss: 0.0923, Validation Loss: 0.4284
	--> Epoch [9/100], Loss: 0.0971, Validation Loss: 0.4122
	--> Epoch [10/100], Loss: 0.2276, Validation Loss: 0.3653
	--> Epoch [11/100], Loss: 0.1233, Validation Loss: 0.3637
	--> Epoch [12/100], Loss: 0.0114, Validation Loss: 0.3564
	--> Epoch [13/100], Loss: 0.1397, Validation Loss: 0.3497
	--> Epoch [14/100], Loss: 0.2622, Validation Loss: 0.3804
	--> Epoch [15/100], Loss: 0.1515, Validation Loss: 0.3696
	--> Epoch [16/100], Loss: 0.0041, Validation Loss: 0.3618
Early stopping
	--> Training for Fold 3 took 0.12740063667297363 sec, using 16 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5355, Validation Loss: 0.6405
	--> Epoch [2/100], Loss: 0.3869, Validation Loss: 0.5667
	--> Epoch [3/100], Loss: 0.2995, Validation Loss: 0.5107
	--> Epoch [4/100], Loss: 0.2871, Validation Loss: 0.5265
	--> Epoch [5/100], Loss: 0.2844, Validation Loss: 0.4478
	--> Epoch [6/100], Loss: 0.1422, Validation Loss: 0.3961
	--> Epoch [7/100], Loss: 0.2600, Validation Loss: 0.3829
	--> Epoch [8/100], Loss: 0.1322, Validation Loss: 0.3647
	--> Epoch [9/100], Loss: 0.1156, Validation Loss: 0.3570
	--> Epoch [10/100], Loss: 0.1749, Validation Loss: 0.3405
	--> Epoch [11/100], Loss: 0.0169, Validation Loss: 0.3345
	--> Epoch [12/100], Loss: 0.0965, Validation Loss: 0.3181
	--> Epoch [13/100], Loss: 0.0997, Validation Loss: 0.3235
	--> Epoch [14/100], Loss: 0.0600, Validation Loss: 0.3005
	--> Epoch [15/100], Loss: 0.0496, Validation Loss: 0.2823
	--> Epoch [16/100], Loss: 0.0027, Validation Loss: 0.2935
	--> Epoch [17/100], Loss: 0.0126, Validation Loss: 0.2971
	--> Epoch [18/100], Loss: 0.1093, Validation Loss: 0.3494
Early stopping
	--> Training for Fold 4 took 0.12421488761901855 sec, using 18 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4786, Validation Loss: 0.6559
	--> Epoch [2/100], Loss: 0.2913, Validation Loss: 0.6522
	--> Epoch [3/100], Loss: 0.2746, Validation Loss: 0.6525
	--> Epoch [4/100], Loss: 0.2125, Validation Loss: 0.5990
	--> Epoch [5/100], Loss: 0.2100, Validation Loss: 0.5358
	--> Epoch [6/100], Loss: 0.1262, Validation Loss: 0.5261
	--> Epoch [7/100], Loss: 0.2404, Validation Loss: 0.5295
	--> Epoch [8/100], Loss: 0.3076, Validation Loss: 0.5535
	--> Epoch [9/100], Loss: 0.2329, Validation Loss: 0.5446
Early stopping
	--> Training for Fold 5 took 0.08517813682556152 sec, using 9 epochs

Median number of epochs used: 16 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/16], Loss: 0.6369
	--> Final training Epoch [2/16], Loss: 0.5338
	--> Final training Epoch [3/16], Loss: 0.3718
	--> Final training Epoch [4/16], Loss: 0.3365
	--> Final training Epoch [5/16], Loss: 0.2721
	--> Final training Epoch [6/16], Loss: 0.2665
	--> Final training Epoch [7/16], Loss: 0.2154
	--> Final training Epoch [8/16], Loss: 0.1897
	--> Final training Epoch [9/16], Loss: 0.1622
	--> Final training Epoch [10/16], Loss: 0.1391
	--> Final training Epoch [11/16], Loss: 0.1393
	--> Final training Epoch [12/16], Loss: 0.1047
	--> Final training Epoch [13/16], Loss: 0.0477
	--> Final training Epoch [14/16], Loss: 0.1005
	--> Final training Epoch [15/16], Loss: 0.1083
	--> Final training Epoch [16/16], Loss: 0.1430

Final training took 0.09762907028198242 sec

TESTING
	--> Testing took 0.0120 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.1375
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8398, Validation Loss: 0.2950,  Current Best Accuracy: 0.8398,  Current Best Validation Loss: 0.2950
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8035, Validation Loss: 0.4599,  Current Best Accuracy: 0.8398,  Current Best Validation Loss: 0.2950
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3862,  Current Best Accuracy: 0.8398,  Current Best Validation Loss: 0.2950
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7959, Validation Loss: 0.4801,  Current Best Accuracy: 0.8398,  Current Best Validation Loss: 0.2950

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6253, Validation Loss: 0.5113
	--> Epoch [2/100], Loss: 0.3533, Validation Loss: 0.3966
	--> Epoch [3/100], Loss: 0.2653, Validation Loss: 0.3265
	--> Epoch [4/100], Loss: 0.1710, Validation Loss: 0.2883
	--> Epoch [5/100], Loss: 0.2166, Validation Loss: 0.2774
	--> Epoch [6/100], Loss: 0.0816, Validation Loss: 0.2583
	--> Epoch [7/100], Loss: 0.0661, Validation Loss: 0.2497
	--> Epoch [8/100], Loss: 0.1117, Validation Loss: 0.2512
	--> Epoch [9/100], Loss: 0.1133, Validation Loss: 0.2394
	--> Epoch [10/100], Loss: 0.0632, Validation Loss: 0.2275
	--> Epoch [11/100], Loss: 0.1651, Validation Loss: 0.2210
	--> Epoch [12/100], Loss: 0.0635, Validation Loss: 0.2228
	--> Epoch [13/100], Loss: 0.1232, Validation Loss: 0.2219
	--> Epoch [14/100], Loss: 0.0782, Validation Loss: 0.2299
Early stopping
	--> Training for Fold 1 took 0.07707071304321289 sec, using 14 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6047, Validation Loss: 0.5221
	--> Epoch [2/100], Loss: 0.4136, Validation Loss: 0.4275
	--> Epoch [3/100], Loss: 0.2530, Validation Loss: 0.3734
	--> Epoch [4/100], Loss: 0.2580, Validation Loss: 0.3331
	--> Epoch [5/100], Loss: 0.1646, Validation Loss: 0.2957
	--> Epoch [6/100], Loss: 0.1660, Validation Loss: 0.2603
	--> Epoch [7/100], Loss: 0.0845, Validation Loss: 0.2408
	--> Epoch [8/100], Loss: 0.1509, Validation Loss: 0.2302
	--> Epoch [9/100], Loss: 0.2036, Validation Loss: 0.2082
	--> Epoch [10/100], Loss: 0.1591, Validation Loss: 0.2180
	--> Epoch [11/100], Loss: 0.1360, Validation Loss: 0.2020
	--> Epoch [12/100], Loss: 0.0804, Validation Loss: 0.1912
	--> Epoch [13/100], Loss: 0.0810, Validation Loss: 0.2007
	--> Epoch [14/100], Loss: 0.1449, Validation Loss: 0.1744
	--> Epoch [15/100], Loss: 0.0627, Validation Loss: 0.1744
	--> Epoch [16/100], Loss: 0.1355, Validation Loss: 0.1757
	--> Epoch [17/100], Loss: 0.0638, Validation Loss: 0.1635
	--> Epoch [18/100], Loss: 0.0650, Validation Loss: 0.1439
	--> Epoch [19/100], Loss: 0.1209, Validation Loss: 0.1472
	--> Epoch [20/100], Loss: 0.0568, Validation Loss: 0.1407
	--> Epoch [21/100], Loss: 0.0585, Validation Loss: 0.1484
	--> Epoch [22/100], Loss: 0.0573, Validation Loss: 0.1463
	--> Epoch [23/100], Loss: 0.0557, Validation Loss: 0.1500
Early stopping
	--> Training for Fold 2 took 0.13334059715270996 sec, using 23 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6591, Validation Loss: 0.6531
	--> Epoch [2/100], Loss: 0.3491, Validation Loss: 0.5660
	--> Epoch [3/100], Loss: 0.2109, Validation Loss: 0.5182
	--> Epoch [4/100], Loss: 0.2069, Validation Loss: 0.4576
	--> Epoch [5/100], Loss: 0.1362, Validation Loss: 0.4313
	--> Epoch [6/100], Loss: 0.1006, Validation Loss: 0.4084
	--> Epoch [7/100], Loss: 0.1262, Validation Loss: 0.3852
	--> Epoch [8/100], Loss: 0.0462, Validation Loss: 0.3891
	--> Epoch [9/100], Loss: 0.1007, Validation Loss: 0.3625
	--> Epoch [10/100], Loss: 0.1304, Validation Loss: 0.3538
	--> Epoch [11/100], Loss: 0.0753, Validation Loss: 0.3236
	--> Epoch [12/100], Loss: 0.0118, Validation Loss: 0.3199
	--> Epoch [13/100], Loss: 0.0580, Validation Loss: 0.3172
	--> Epoch [14/100], Loss: 0.0591, Validation Loss: 0.3162
	--> Epoch [15/100], Loss: 0.0623, Validation Loss: 0.3084
	--> Epoch [16/100], Loss: 0.0546, Validation Loss: 0.3195
	--> Epoch [17/100], Loss: 0.0034, Validation Loss: 0.3268
	--> Epoch [18/100], Loss: 0.0091, Validation Loss: 0.3269
Early stopping
	--> Training for Fold 3 took 0.14599132537841797 sec, using 18 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7374, Validation Loss: 0.5191
	--> Epoch [2/100], Loss: 0.5443, Validation Loss: 0.4826
	--> Epoch [3/100], Loss: 0.2638, Validation Loss: 0.3950
	--> Epoch [4/100], Loss: 0.1467, Validation Loss: 0.3401
	--> Epoch [5/100], Loss: 0.0635, Validation Loss: 0.3404
	--> Epoch [6/100], Loss: 0.0445, Validation Loss: 0.3012
	--> Epoch [7/100], Loss: 0.0426, Validation Loss: 0.2900
	--> Epoch [8/100], Loss: 0.1169, Validation Loss: 0.2876
	--> Epoch [9/100], Loss: 0.1045, Validation Loss: 0.2822
	--> Epoch [10/100], Loss: 0.0122, Validation Loss: 0.2777
	--> Epoch [11/100], Loss: 0.0063, Validation Loss: 0.2676
	--> Epoch [12/100], Loss: 0.0229, Validation Loss: 0.2726
	--> Epoch [13/100], Loss: 0.0162, Validation Loss: 0.2651
	--> Epoch [14/100], Loss: 0.0054, Validation Loss: 0.2662
	--> Epoch [15/100], Loss: 0.0110, Validation Loss: 0.2675
	--> Epoch [16/100], Loss: 0.0684, Validation Loss: 0.2686
Early stopping
	--> Training for Fold 4 took 0.11647796630859375 sec, using 16 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4859, Validation Loss: 0.6877
	--> Epoch [2/100], Loss: 0.2596, Validation Loss: 0.7316
	--> Epoch [3/100], Loss: 0.1700, Validation Loss: 0.7662
	--> Epoch [4/100], Loss: 0.1572, Validation Loss: 0.7933
Early stopping
	--> Training for Fold 5 took 0.036499738693237305 sec, using 4 epochs

Median number of epochs used: 16 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/16], Loss: 0.5881
	--> Final training Epoch [2/16], Loss: 0.4600
	--> Final training Epoch [3/16], Loss: 0.3494
	--> Final training Epoch [4/16], Loss: 0.3429
	--> Final training Epoch [5/16], Loss: 0.2567
	--> Final training Epoch [6/16], Loss: 0.2498
	--> Final training Epoch [7/16], Loss: 0.2038
	--> Final training Epoch [8/16], Loss: 0.2411
	--> Final training Epoch [9/16], Loss: 0.1333
	--> Final training Epoch [10/16], Loss: 0.1385
	--> Final training Epoch [11/16], Loss: 0.2221
	--> Final training Epoch [12/16], Loss: 0.1241
	--> Final training Epoch [13/16], Loss: 0.0890
	--> Final training Epoch [14/16], Loss: 0.0438
	--> Final training Epoch [15/16], Loss: 0.0502
	--> Final training Epoch [16/16], Loss: 0.1762

Final training took 0.09284234046936035 sec

TESTING
	--> Testing took 0.0102 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9957
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3277,  Current Best Accuracy: 0.8591,  Current Best Validation Loss: 0.3277

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7140, Validation Loss: 0.5159
	--> Epoch [2/100], Loss: 0.4063, Validation Loss: 0.4240
	--> Epoch [3/100], Loss: 0.3686, Validation Loss: 0.3394
	--> Epoch [4/100], Loss: 0.2811, Validation Loss: 0.3215
	--> Epoch [5/100], Loss: 0.1295, Validation Loss: 0.2952
	--> Epoch [6/100], Loss: 0.1162, Validation Loss: 0.2832
	--> Epoch [7/100], Loss: 0.1365, Validation Loss: 0.2895
	--> Epoch [8/100], Loss: 0.1045, Validation Loss: 0.2877
	--> Epoch [9/100], Loss: 0.1919, Validation Loss: 0.2651
	--> Epoch [10/100], Loss: 0.1055, Validation Loss: 0.2776
	--> Epoch [11/100], Loss: 0.0782, Validation Loss: 0.2696
	--> Epoch [12/100], Loss: 0.0798, Validation Loss: 0.2579
	--> Epoch [13/100], Loss: 0.0868, Validation Loss: 0.2581
	--> Epoch [14/100], Loss: 0.0839, Validation Loss: 0.2609
	--> Epoch [15/100], Loss: 0.0901, Validation Loss: 0.2792
Early stopping
	--> Training for Fold 1 took 0.08370518684387207 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5526, Validation Loss: 0.4636
	--> Epoch [2/100], Loss: 0.3732, Validation Loss: 0.3972
	--> Epoch [3/100], Loss: 0.2794, Validation Loss: 0.3429
	--> Epoch [4/100], Loss: 0.1276, Validation Loss: 0.3097
	--> Epoch [5/100], Loss: 0.0966, Validation Loss: 0.2786
	--> Epoch [6/100], Loss: 0.0956, Validation Loss: 0.2445
	--> Epoch [7/100], Loss: 0.1307, Validation Loss: 0.2186
	--> Epoch [8/100], Loss: 0.1646, Validation Loss: 0.2132
	--> Epoch [9/100], Loss: 0.1758, Validation Loss: 0.2099
	--> Epoch [10/100], Loss: 0.1007, Validation Loss: 0.1993
	--> Epoch [11/100], Loss: 0.0620, Validation Loss: 0.1974
	--> Epoch [12/100], Loss: 0.0726, Validation Loss: 0.1829
	--> Epoch [13/100], Loss: 0.0634, Validation Loss: 0.1842
	--> Epoch [14/100], Loss: 0.0621, Validation Loss: 0.1741
	--> Epoch [15/100], Loss: 0.0634, Validation Loss: 0.1684
	--> Epoch [16/100], Loss: 0.0591, Validation Loss: 0.1662
	--> Epoch [17/100], Loss: 0.0695, Validation Loss: 0.1680
	--> Epoch [18/100], Loss: 0.0593, Validation Loss: 0.1679
	--> Epoch [19/100], Loss: 0.0640, Validation Loss: 0.1575
	--> Epoch [20/100], Loss: 0.0755, Validation Loss: 0.1493
	--> Epoch [21/100], Loss: 0.0575, Validation Loss: 0.1528
	--> Epoch [22/100], Loss: 0.0605, Validation Loss: 0.1580
	--> Epoch [23/100], Loss: 0.0577, Validation Loss: 0.1504
Early stopping
	--> Training for Fold 2 took 0.13634252548217773 sec, using 23 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6228, Validation Loss: 0.5863
	--> Epoch [2/100], Loss: 0.5234, Validation Loss: 0.5589
	--> Epoch [3/100], Loss: 0.3267, Validation Loss: 0.4931
	--> Epoch [4/100], Loss: 0.1877, Validation Loss: 0.4434
	--> Epoch [5/100], Loss: 0.1866, Validation Loss: 0.4123
	--> Epoch [6/100], Loss: 0.0882, Validation Loss: 0.3890
	--> Epoch [7/100], Loss: 0.1418, Validation Loss: 0.3954
	--> Epoch [8/100], Loss: 0.2225, Validation Loss: 0.3751
	--> Epoch [9/100], Loss: 0.1412, Validation Loss: 0.3505
	--> Epoch [10/100], Loss: 0.1383, Validation Loss: 0.3457
	--> Epoch [11/100], Loss: 0.0792, Validation Loss: 0.3647
	--> Epoch [12/100], Loss: 0.0714, Validation Loss: 0.3645
	--> Epoch [13/100], Loss: 0.0592, Validation Loss: 0.3652
Early stopping
	--> Training for Fold 3 took 0.1101987361907959 sec, using 13 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5807, Validation Loss: 0.5838
	--> Epoch [2/100], Loss: 0.3261, Validation Loss: 0.5652
	--> Epoch [3/100], Loss: 0.2287, Validation Loss: 0.5185
	--> Epoch [4/100], Loss: 0.1160, Validation Loss: 0.4852
	--> Epoch [5/100], Loss: 0.0625, Validation Loss: 0.4570
	--> Epoch [6/100], Loss: 0.1028, Validation Loss: 0.4234
	--> Epoch [7/100], Loss: 0.1181, Validation Loss: 0.4044
	--> Epoch [8/100], Loss: 0.1348, Validation Loss: 0.4585
	--> Epoch [9/100], Loss: 0.1870, Validation Loss: 0.4548
	--> Epoch [10/100], Loss: 0.0582, Validation Loss: 0.4447
Early stopping
	--> Training for Fold 4 took 0.056702613830566406 sec, using 10 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6859, Validation Loss: 0.6014
	--> Epoch [2/100], Loss: 0.5605, Validation Loss: 0.6096
	--> Epoch [3/100], Loss: 0.2875, Validation Loss: 0.5838
	--> Epoch [4/100], Loss: 0.2424, Validation Loss: 0.6020
	--> Epoch [5/100], Loss: 0.2321, Validation Loss: 0.6275
	--> Epoch [6/100], Loss: 0.1423, Validation Loss: 0.6455
Early stopping
	--> Training for Fold 5 took 0.05010795593261719 sec, using 6 epochs

Median number of epochs used: 13 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/13], Loss: 0.5893
	--> Final training Epoch [2/13], Loss: 0.4155
	--> Final training Epoch [3/13], Loss: 0.2819
	--> Final training Epoch [4/13], Loss: 0.2013
	--> Final training Epoch [5/13], Loss: 0.1434
	--> Final training Epoch [6/13], Loss: 0.1139
	--> Final training Epoch [7/13], Loss: 0.0964
	--> Final training Epoch [8/13], Loss: 0.1172
	--> Final training Epoch [9/13], Loss: 0.1347
	--> Final training Epoch [10/13], Loss: 0.0539
	--> Final training Epoch [11/13], Loss: 0.1058
	--> Final training Epoch [12/13], Loss: 0.0546
	--> Final training Epoch [13/13], Loss: 0.0865

Final training took 0.09706711769104004 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 1.0995
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3204,  Current Best Accuracy: 0.8485,  Current Best Validation Loss: 0.3204

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8468, Validation Loss: 0.6185
	--> Epoch [2/100], Loss: 0.5539, Validation Loss: 0.4997
	--> Epoch [3/100], Loss: 0.4731, Validation Loss: 0.4779
	--> Epoch [4/100], Loss: 0.3049, Validation Loss: 0.3770
	--> Epoch [5/100], Loss: 0.2064, Validation Loss: 0.3336
	--> Epoch [6/100], Loss: 0.1172, Validation Loss: 0.3215
	--> Epoch [7/100], Loss: 0.2088, Validation Loss: 0.3230
	--> Epoch [8/100], Loss: 0.2585, Validation Loss: 0.3150
	--> Epoch [9/100], Loss: 0.1137, Validation Loss: 0.3040
	--> Epoch [10/100], Loss: 0.1779, Validation Loss: 0.3337
	--> Epoch [11/100], Loss: 0.0898, Validation Loss: 0.3116
	--> Epoch [12/100], Loss: 0.0891, Validation Loss: 0.3213
Early stopping
	--> Training for Fold 1 took 0.06821060180664062 sec, using 12 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7025, Validation Loss: 0.4888
	--> Epoch [2/100], Loss: 0.5067, Validation Loss: 0.4201
	--> Epoch [3/100], Loss: 0.4869, Validation Loss: 0.3916
	--> Epoch [4/100], Loss: 0.2679, Validation Loss: 0.3450
	--> Epoch [5/100], Loss: 0.2473, Validation Loss: 0.3163
	--> Epoch [6/100], Loss: 0.2191, Validation Loss: 0.2945
	--> Epoch [7/100], Loss: 0.1420, Validation Loss: 0.2729
	--> Epoch [8/100], Loss: 0.1674, Validation Loss: 0.2552
	--> Epoch [9/100], Loss: 0.0860, Validation Loss: 0.2401
	--> Epoch [10/100], Loss: 0.0833, Validation Loss: 0.2289
	--> Epoch [11/100], Loss: 0.0861, Validation Loss: 0.2216
	--> Epoch [12/100], Loss: 0.1455, Validation Loss: 0.2137
	--> Epoch [13/100], Loss: 0.0926, Validation Loss: 0.2132
	--> Epoch [14/100], Loss: 0.2138, Validation Loss: 0.2037
	--> Epoch [15/100], Loss: 0.1358, Validation Loss: 0.1964
	--> Epoch [16/100], Loss: 0.0719, Validation Loss: 0.1857
	--> Epoch [17/100], Loss: 0.0678, Validation Loss: 0.1815
	--> Epoch [18/100], Loss: 0.0666, Validation Loss: 0.1833
	--> Epoch [19/100], Loss: 0.1263, Validation Loss: 0.1736
	--> Epoch [20/100], Loss: 0.0684, Validation Loss: 0.1735
	--> Epoch [21/100], Loss: 0.0630, Validation Loss: 0.1860
	--> Epoch [22/100], Loss: 0.0632, Validation Loss: 0.1845
	--> Epoch [23/100], Loss: 0.0627, Validation Loss: 0.1789
Early stopping
	--> Training for Fold 2 took 0.13103103637695312 sec, using 23 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8311, Validation Loss: 0.5419
	--> Epoch [2/100], Loss: 0.5098, Validation Loss: 0.5078
	--> Epoch [3/100], Loss: 0.2916, Validation Loss: 0.4753
	--> Epoch [4/100], Loss: 0.2807, Validation Loss: 0.4486
	--> Epoch [5/100], Loss: 0.1588, Validation Loss: 0.4415
	--> Epoch [6/100], Loss: 0.0721, Validation Loss: 0.4047
	--> Epoch [7/100], Loss: 0.0247, Validation Loss: 0.4044
	--> Epoch [8/100], Loss: 0.0911, Validation Loss: 0.3873
	--> Epoch [9/100], Loss: 0.0186, Validation Loss: 0.3801
	--> Epoch [10/100], Loss: 0.0399, Validation Loss: 0.3795
	--> Epoch [11/100], Loss: 0.0200, Validation Loss: 0.3720
	--> Epoch [12/100], Loss: 0.0768, Validation Loss: 0.3689
	--> Epoch [13/100], Loss: 0.1664, Validation Loss: 0.3526
	--> Epoch [14/100], Loss: 0.2219, Validation Loss: 0.3555
	--> Epoch [15/100], Loss: 0.0087, Validation Loss: 0.3631
	--> Epoch [16/100], Loss: 0.0134, Validation Loss: 0.3490
	--> Epoch [17/100], Loss: 0.0141, Validation Loss: 0.3752
	--> Epoch [18/100], Loss: 0.0040, Validation Loss: 0.3612
	--> Epoch [19/100], Loss: 0.0939, Validation Loss: 0.3512
Early stopping
	--> Training for Fold 3 took 0.1488802433013916 sec, using 19 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6017, Validation Loss: 0.5541
	--> Epoch [2/100], Loss: 0.3317, Validation Loss: 0.4928
	--> Epoch [3/100], Loss: 0.2536, Validation Loss: 0.4008
	--> Epoch [4/100], Loss: 0.2243, Validation Loss: 0.3527
	--> Epoch [5/100], Loss: 0.1514, Validation Loss: 0.3971
	--> Epoch [6/100], Loss: 0.2606, Validation Loss: 0.3174
	--> Epoch [7/100], Loss: 0.0988, Validation Loss: 0.3050
	--> Epoch [8/100], Loss: 0.0757, Validation Loss: 0.2969
	--> Epoch [9/100], Loss: 0.0867, Validation Loss: 0.3098
	--> Epoch [10/100], Loss: 0.0856, Validation Loss: 0.2854
	--> Epoch [11/100], Loss: 0.1189, Validation Loss: 0.2952
	--> Epoch [12/100], Loss: 0.1225, Validation Loss: 0.3103
	--> Epoch [13/100], Loss: 0.1217, Validation Loss: 0.2861
Early stopping
	--> Training for Fold 4 took 0.08979916572570801 sec, using 13 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5582, Validation Loss: 0.6281
	--> Epoch [2/100], Loss: 0.2449, Validation Loss: 0.5990
	--> Epoch [3/100], Loss: 0.2738, Validation Loss: 0.6079
	--> Epoch [4/100], Loss: 0.1563, Validation Loss: 0.5948
	--> Epoch [5/100], Loss: 0.1849, Validation Loss: 0.6014
	--> Epoch [6/100], Loss: 0.0815, Validation Loss: 0.6301
	--> Epoch [7/100], Loss: 0.0220, Validation Loss: 0.6178
Early stopping
	--> Training for Fold 5 took 0.06893229484558105 sec, using 7 epochs

Median number of epochs used: 13 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/13], Loss: 0.6113
	--> Final training Epoch [2/13], Loss: 0.4111
	--> Final training Epoch [3/13], Loss: 0.3218
	--> Final training Epoch [4/13], Loss: 0.1899
	--> Final training Epoch [5/13], Loss: 0.1553
	--> Final training Epoch [6/13], Loss: 0.1348
	--> Final training Epoch [7/13], Loss: 0.1046
	--> Final training Epoch [8/13], Loss: 0.1347
	--> Final training Epoch [9/13], Loss: 0.1034
	--> Final training Epoch [10/13], Loss: 0.0661
	--> Final training Epoch [11/13], Loss: 0.1056
	--> Final training Epoch [12/13], Loss: 0.0440
	--> Final training Epoch [13/13], Loss: 0.0272

Final training took 0.07598447799682617 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0816
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3399,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3399
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7947, Validation Loss: 0.3769,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3399

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5066, Validation Loss: 0.5231
	--> Epoch [2/100], Loss: 0.4089, Validation Loss: 0.4393
	--> Epoch [3/100], Loss: 0.2241, Validation Loss: 0.4031
	--> Epoch [4/100], Loss: 0.2816, Validation Loss: 0.3813
	--> Epoch [5/100], Loss: 0.4188, Validation Loss: 0.3584
	--> Epoch [6/100], Loss: 0.1124, Validation Loss: 0.3299
	--> Epoch [7/100], Loss: 0.1411, Validation Loss: 0.3141
	--> Epoch [8/100], Loss: 0.0867, Validation Loss: 0.3108
	--> Epoch [9/100], Loss: 0.2896, Validation Loss: 0.3077
	--> Epoch [10/100], Loss: 0.0720, Validation Loss: 0.3210
	--> Epoch [11/100], Loss: 0.2084, Validation Loss: 0.3083
	--> Epoch [12/100], Loss: 0.1271, Validation Loss: 0.3169
Early stopping
	--> Training for Fold 1 took 0.07049703598022461 sec, using 12 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6828, Validation Loss: 0.5801
	--> Epoch [2/100], Loss: 0.5921, Validation Loss: 0.4890
	--> Epoch [3/100], Loss: 0.4305, Validation Loss: 0.4025
	--> Epoch [4/100], Loss: 0.5111, Validation Loss: 0.3589
	--> Epoch [5/100], Loss: 0.4080, Validation Loss: 0.3384
	--> Epoch [6/100], Loss: 0.3853, Validation Loss: 0.2991
	--> Epoch [7/100], Loss: 0.2323, Validation Loss: 0.2777
	--> Epoch [8/100], Loss: 0.3523, Validation Loss: 0.2630
	--> Epoch [9/100], Loss: 0.3639, Validation Loss: 0.2330
	--> Epoch [10/100], Loss: 0.2833, Validation Loss: 0.2173
	--> Epoch [11/100], Loss: 0.2645, Validation Loss: 0.2148
	--> Epoch [12/100], Loss: 0.3767, Validation Loss: 0.1953
	--> Epoch [13/100], Loss: 0.1418, Validation Loss: 0.1925
	--> Epoch [14/100], Loss: 0.3603, Validation Loss: 0.1845
	--> Epoch [15/100], Loss: 0.1882, Validation Loss: 0.1734
	--> Epoch [16/100], Loss: 0.1718, Validation Loss: 0.1657
	--> Epoch [17/100], Loss: 0.2242, Validation Loss: 0.1485
	--> Epoch [18/100], Loss: 0.2217, Validation Loss: 0.1469
	--> Epoch [19/100], Loss: 0.2172, Validation Loss: 0.1440
	--> Epoch [20/100], Loss: 0.1594, Validation Loss: 0.1510
	--> Epoch [21/100], Loss: 0.2574, Validation Loss: 0.1412
	--> Epoch [22/100], Loss: 0.3001, Validation Loss: 0.1382
	--> Epoch [23/100], Loss: 0.1479, Validation Loss: 0.1402
	--> Epoch [24/100], Loss: 0.0968, Validation Loss: 0.1408
	--> Epoch [25/100], Loss: 0.0954, Validation Loss: 0.1443
Early stopping
	--> Training for Fold 2 took 0.1467287540435791 sec, using 25 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5282, Validation Loss: 0.5897
	--> Epoch [2/100], Loss: 0.4688, Validation Loss: 0.5382
	--> Epoch [3/100], Loss: 0.3429, Validation Loss: 0.4991
	--> Epoch [4/100], Loss: 0.2595, Validation Loss: 0.4672
	--> Epoch [5/100], Loss: 0.2781, Validation Loss: 0.4613
	--> Epoch [6/100], Loss: 0.1654, Validation Loss: 0.4486
	--> Epoch [7/100], Loss: 0.1393, Validation Loss: 0.4222
	--> Epoch [8/100], Loss: 0.0700, Validation Loss: 0.4092
	--> Epoch [9/100], Loss: 0.0828, Validation Loss: 0.3886
	--> Epoch [10/100], Loss: 0.1271, Validation Loss: 0.3895
	--> Epoch [11/100], Loss: 0.1665, Validation Loss: 0.3894
	--> Epoch [12/100], Loss: 0.0737, Validation Loss: 0.3733
	--> Epoch [13/100], Loss: 0.0931, Validation Loss: 0.4238
	--> Epoch [14/100], Loss: 0.1563, Validation Loss: 0.4005
	--> Epoch [15/100], Loss: 0.1432, Validation Loss: 0.3751
Early stopping
	--> Training for Fold 3 took 0.12620830535888672 sec, using 15 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6756, Validation Loss: 0.5803
	--> Epoch [2/100], Loss: 0.4505, Validation Loss: 0.4915
	--> Epoch [3/100], Loss: 0.3465, Validation Loss: 0.4384
	--> Epoch [4/100], Loss: 0.3526, Validation Loss: 0.3966
	--> Epoch [5/100], Loss: 0.0973, Validation Loss: 0.3720
	--> Epoch [6/100], Loss: 0.0712, Validation Loss: 0.3368
	--> Epoch [7/100], Loss: 0.0849, Validation Loss: 0.3294
	--> Epoch [8/100], Loss: 0.2046, Validation Loss: 0.3026
	--> Epoch [9/100], Loss: 0.1672, Validation Loss: 0.3132
	--> Epoch [10/100], Loss: 0.0631, Validation Loss: 0.3485
	--> Epoch [11/100], Loss: 0.1565, Validation Loss: 0.3139
Early stopping
	--> Training for Fold 4 took 0.0711050033569336 sec, using 11 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6152, Validation Loss: 0.5694
	--> Epoch [2/100], Loss: 0.4813, Validation Loss: 0.5534
	--> Epoch [3/100], Loss: 0.3503, Validation Loss: 0.5840
	--> Epoch [4/100], Loss: 0.2022, Validation Loss: 0.5807
	--> Epoch [5/100], Loss: 0.1072, Validation Loss: 0.5905
Early stopping
	--> Training for Fold 5 took 0.04916977882385254 sec, using 5 epochs

Median number of epochs used: 12 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/12], Loss: 0.6592
	--> Final training Epoch [2/12], Loss: 0.5313
	--> Final training Epoch [3/12], Loss: 0.4423
	--> Final training Epoch [4/12], Loss: 0.3113
	--> Final training Epoch [5/12], Loss: 0.3666
	--> Final training Epoch [6/12], Loss: 0.2139
	--> Final training Epoch [7/12], Loss: 0.1995
	--> Final training Epoch [8/12], Loss: 0.2141
	--> Final training Epoch [9/12], Loss: 0.1381
	--> Final training Epoch [10/12], Loss: 0.2003
	--> Final training Epoch [11/12], Loss: 0.2306
	--> Final training Epoch [12/12], Loss: 0.1383

Final training took 0.08343124389648438 sec

TESTING
	--> Testing took 0.0073 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 0.8317
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3255,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3671,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4099,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.4357,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 0.4002,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5566, Validation Loss: 0.5020
	--> Epoch [2/100], Loss: 0.3350, Validation Loss: 0.4294
	--> Epoch [3/100], Loss: 0.2119, Validation Loss: 0.3981
	--> Epoch [4/100], Loss: 0.1329, Validation Loss: 0.3355
	--> Epoch [5/100], Loss: 0.0777, Validation Loss: 0.2977
	--> Epoch [6/100], Loss: 0.1070, Validation Loss: 0.2907
	--> Epoch [7/100], Loss: 0.1517, Validation Loss: 0.2698
	--> Epoch [8/100], Loss: 0.0236, Validation Loss: 0.2441
	--> Epoch [9/100], Loss: 0.0675, Validation Loss: 0.2395
	--> Epoch [10/100], Loss: 0.0873, Validation Loss: 0.2349
	--> Epoch [11/100], Loss: 0.0546, Validation Loss: 0.2215
	--> Epoch [12/100], Loss: 0.0570, Validation Loss: 0.2288
	--> Epoch [13/100], Loss: 0.0609, Validation Loss: 0.2366
	--> Epoch [14/100], Loss: 0.0101, Validation Loss: 0.2383
Early stopping
	--> Training for Fold 1 took 0.07781481742858887 sec, using 14 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6419, Validation Loss: 0.5012
	--> Epoch [2/100], Loss: 0.4919, Validation Loss: 0.3945
	--> Epoch [3/100], Loss: 0.3098, Validation Loss: 0.3372
	--> Epoch [4/100], Loss: 0.2616, Validation Loss: 0.3053
	--> Epoch [5/100], Loss: 0.1385, Validation Loss: 0.2869
	--> Epoch [6/100], Loss: 0.2097, Validation Loss: 0.2731
	--> Epoch [7/100], Loss: 0.1839, Validation Loss: 0.2466
	--> Epoch [8/100], Loss: 0.3235, Validation Loss: 0.2297
	--> Epoch [9/100], Loss: 0.1159, Validation Loss: 0.2267
	--> Epoch [10/100], Loss: 0.2335, Validation Loss: 0.2229
	--> Epoch [11/100], Loss: 0.0882, Validation Loss: 0.2165
	--> Epoch [12/100], Loss: 0.0851, Validation Loss: 0.2096
	--> Epoch [13/100], Loss: 0.1531, Validation Loss: 0.2057
	--> Epoch [14/100], Loss: 0.0792, Validation Loss: 0.1985
	--> Epoch [15/100], Loss: 0.1414, Validation Loss: 0.1975
	--> Epoch [16/100], Loss: 0.2739, Validation Loss: 0.2002
	--> Epoch [17/100], Loss: 0.1688, Validation Loss: 0.2026
	--> Epoch [18/100], Loss: 0.0659, Validation Loss: 0.1900
	--> Epoch [19/100], Loss: 0.0932, Validation Loss: 0.1839
	--> Epoch [20/100], Loss: 0.0747, Validation Loss: 0.1713
	--> Epoch [21/100], Loss: 0.1355, Validation Loss: 0.1717
	--> Epoch [22/100], Loss: 0.1263, Validation Loss: 0.1656
	--> Epoch [23/100], Loss: 0.0636, Validation Loss: 0.1651
	--> Epoch [24/100], Loss: 0.1237, Validation Loss: 0.1618
	--> Epoch [25/100], Loss: 0.1786, Validation Loss: 0.1598
	--> Epoch [26/100], Loss: 0.1765, Validation Loss: 0.1584
	--> Epoch [27/100], Loss: 0.0637, Validation Loss: 0.1558
	--> Epoch [28/100], Loss: 0.0637, Validation Loss: 0.1554
	--> Epoch [29/100], Loss: 0.0560, Validation Loss: 0.1511
	--> Epoch [30/100], Loss: 0.1107, Validation Loss: 0.1521
	--> Epoch [31/100], Loss: 0.0673, Validation Loss: 0.1489
	--> Epoch [32/100], Loss: 0.0545, Validation Loss: 0.1454
	--> Epoch [33/100], Loss: 0.0551, Validation Loss: 0.1495
	--> Epoch [34/100], Loss: 0.0550, Validation Loss: 0.1502
	--> Epoch [35/100], Loss: 0.0527, Validation Loss: 0.1460
Early stopping
	--> Training for Fold 2 took 0.24668359756469727 sec, using 35 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6344, Validation Loss: 0.5775
	--> Epoch [2/100], Loss: 0.4609, Validation Loss: 0.5376
	--> Epoch [3/100], Loss: 0.2507, Validation Loss: 0.5147
	--> Epoch [4/100], Loss: 0.1876, Validation Loss: 0.4800
	--> Epoch [5/100], Loss: 0.1549, Validation Loss: 0.4643
	--> Epoch [6/100], Loss: 0.2266, Validation Loss: 0.4508
	--> Epoch [7/100], Loss: 0.0927, Validation Loss: 0.4333
	--> Epoch [8/100], Loss: 0.0819, Validation Loss: 0.4153
	--> Epoch [9/100], Loss: 0.1369, Validation Loss: 0.4335
	--> Epoch [10/100], Loss: 0.1096, Validation Loss: 0.4201
	--> Epoch [11/100], Loss: 0.1722, Validation Loss: 0.4178
Early stopping
	--> Training for Fold 3 took 0.07248377799987793 sec, using 11 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5268, Validation Loss: 0.6219
	--> Epoch [2/100], Loss: 0.2584, Validation Loss: 0.5152
	--> Epoch [3/100], Loss: 0.2579, Validation Loss: 0.5334
	--> Epoch [4/100], Loss: 0.0635, Validation Loss: 0.4436
	--> Epoch [5/100], Loss: 0.1107, Validation Loss: 0.3938
	--> Epoch [6/100], Loss: 0.0645, Validation Loss: 0.4143
	--> Epoch [7/100], Loss: 0.0826, Validation Loss: 0.3761
	--> Epoch [8/100], Loss: 0.1437, Validation Loss: 0.3702
	--> Epoch [9/100], Loss: 0.0552, Validation Loss: 0.3701
	--> Epoch [10/100], Loss: 0.0036, Validation Loss: 0.3650
	--> Epoch [11/100], Loss: 0.0130, Validation Loss: 0.3694
	--> Epoch [12/100], Loss: 0.1270, Validation Loss: 0.3452
	--> Epoch [13/100], Loss: 0.0083, Validation Loss: 0.3085
	--> Epoch [14/100], Loss: 0.0067, Validation Loss: 0.3083
	--> Epoch [15/100], Loss: 0.0594, Validation Loss: 0.3041
	--> Epoch [16/100], Loss: 0.0209, Validation Loss: 0.3017
	--> Epoch [17/100], Loss: 0.0026, Validation Loss: 0.3060
	--> Epoch [18/100], Loss: 0.1424, Validation Loss: 0.3854
	--> Epoch [19/100], Loss: 0.1328, Validation Loss: 0.3753
Early stopping
	--> Training for Fold 4 took 0.17087841033935547 sec, using 19 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6492, Validation Loss: 0.6160
	--> Epoch [2/100], Loss: 0.4638, Validation Loss: 0.6132
	--> Epoch [3/100], Loss: 0.3298, Validation Loss: 0.5816
	--> Epoch [4/100], Loss: 0.2198, Validation Loss: 0.5746
	--> Epoch [5/100], Loss: 0.2122, Validation Loss: 0.5502
	--> Epoch [6/100], Loss: 0.0701, Validation Loss: 0.5393
	--> Epoch [7/100], Loss: 0.1098, Validation Loss: 0.5719
	--> Epoch [8/100], Loss: 0.0443, Validation Loss: 0.5625
	--> Epoch [9/100], Loss: 0.0729, Validation Loss: 0.5466
Early stopping
	--> Training for Fold 5 took 0.07052350044250488 sec, using 9 epochs

Median number of epochs used: 14 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/14], Loss: 0.7403
	--> Final training Epoch [2/14], Loss: 0.5840
	--> Final training Epoch [3/14], Loss: 0.4086
	--> Final training Epoch [4/14], Loss: 0.2910
	--> Final training Epoch [5/14], Loss: 0.2220
	--> Final training Epoch [6/14], Loss: 0.2095
	--> Final training Epoch [7/14], Loss: 0.2057
	--> Final training Epoch [8/14], Loss: 0.2220
	--> Final training Epoch [9/14], Loss: 0.1305
	--> Final training Epoch [10/14], Loss: 0.1701
	--> Final training Epoch [11/14], Loss: 0.1270
	--> Final training Epoch [12/14], Loss: 0.1359
	--> Final training Epoch [13/14], Loss: 0.1465
	--> Final training Epoch [14/14], Loss: 0.1355

Final training took 0.11551952362060547 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.7826
	--> Final Loss: 0.8847
	--> Final Precision: 0.7500
	--> Final Recall: 0.9231
	--> Final F1 Score: 0.8276
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8912, Validation Loss: 0.3367,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3367

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.4693, Validation Loss: 0.4510
	--> Epoch [2/100], Loss: 0.2841, Validation Loss: 0.3886
	--> Epoch [3/100], Loss: 0.2365, Validation Loss: 0.3208
	--> Epoch [4/100], Loss: 0.1087, Validation Loss: 0.2775
	--> Epoch [5/100], Loss: 0.2490, Validation Loss: 0.3010
	--> Epoch [6/100], Loss: 0.0992, Validation Loss: 0.2540
	--> Epoch [7/100], Loss: 0.0859, Validation Loss: 0.2274
	--> Epoch [8/100], Loss: 0.0821, Validation Loss: 0.2178
	--> Epoch [9/100], Loss: 0.0702, Validation Loss: 0.2045
	--> Epoch [10/100], Loss: 0.0698, Validation Loss: 0.2016
	--> Epoch [11/100], Loss: 0.1023, Validation Loss: 0.1844
	--> Epoch [12/100], Loss: 0.0692, Validation Loss: 0.1801
	--> Epoch [13/100], Loss: 0.0742, Validation Loss: 0.1811
	--> Epoch [14/100], Loss: 0.0653, Validation Loss: 0.1784
	--> Epoch [15/100], Loss: 0.0705, Validation Loss: 0.1804
	--> Epoch [16/100], Loss: 0.0651, Validation Loss: 0.1821
	--> Epoch [17/100], Loss: 0.0691, Validation Loss: 0.1884
Early stopping
	--> Training for Fold 1 took 0.09399843215942383 sec, using 17 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7265, Validation Loss: 0.5489
	--> Epoch [2/100], Loss: 0.4987, Validation Loss: 0.4990
	--> Epoch [3/100], Loss: 0.3438, Validation Loss: 0.4603
	--> Epoch [4/100], Loss: 0.2836, Validation Loss: 0.4159
	--> Epoch [5/100], Loss: 0.3072, Validation Loss: 0.3991
	--> Epoch [6/100], Loss: 0.2415, Validation Loss: 0.3492
	--> Epoch [7/100], Loss: 0.2410, Validation Loss: 0.3609
	--> Epoch [8/100], Loss: 0.2718, Validation Loss: 0.3211
	--> Epoch [9/100], Loss: 0.2019, Validation Loss: 0.3277
	--> Epoch [10/100], Loss: 0.2672, Validation Loss: 0.3175
	--> Epoch [11/100], Loss: 0.2678, Validation Loss: 0.3112
	--> Epoch [12/100], Loss: 0.1992, Validation Loss: 0.3105
	--> Epoch [13/100], Loss: 0.2632, Validation Loss: 0.3072
	--> Epoch [14/100], Loss: 0.3556, Validation Loss: 0.3061
	--> Epoch [15/100], Loss: 0.1828, Validation Loss: 0.3085
	--> Epoch [16/100], Loss: 0.1367, Validation Loss: 0.2838
	--> Epoch [17/100], Loss: 0.0869, Validation Loss: 0.2768
	--> Epoch [18/100], Loss: 0.1206, Validation Loss: 0.2742
	--> Epoch [19/100], Loss: 0.0592, Validation Loss: 0.2701
	--> Epoch [20/100], Loss: 0.3414, Validation Loss: 0.2770
	--> Epoch [21/100], Loss: 0.1664, Validation Loss: 0.2681
	--> Epoch [22/100], Loss: 0.1609, Validation Loss: 0.2666
	--> Epoch [23/100], Loss: 0.1069, Validation Loss: 0.2556
	--> Epoch [24/100], Loss: 0.0536, Validation Loss: 0.2956
	--> Epoch [25/100], Loss: 0.1038, Validation Loss: 0.2872
	--> Epoch [26/100], Loss: 0.1026, Validation Loss: 0.2842
Early stopping
	--> Training for Fold 2 took 0.17276382446289062 sec, using 26 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5437, Validation Loss: 0.5988
	--> Epoch [2/100], Loss: 0.5000, Validation Loss: 0.5365
	--> Epoch [3/100], Loss: 0.1840, Validation Loss: 0.4842
	--> Epoch [4/100], Loss: 0.1330, Validation Loss: 0.4670
	--> Epoch [5/100], Loss: 0.1465, Validation Loss: 0.4617
	--> Epoch [6/100], Loss: 0.1061, Validation Loss: 0.4339
	--> Epoch [7/100], Loss: 0.1540, Validation Loss: 0.4153
	--> Epoch [8/100], Loss: 0.0885, Validation Loss: 0.4072
	--> Epoch [9/100], Loss: 0.0843, Validation Loss: 0.4005
	--> Epoch [10/100], Loss: 0.0350, Validation Loss: 0.4100
	--> Epoch [11/100], Loss: 0.2391, Validation Loss: 0.4181
	--> Epoch [12/100], Loss: 0.0111, Validation Loss: 0.4098
Early stopping
	--> Training for Fold 3 took 0.08967328071594238 sec, using 12 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6374, Validation Loss: 0.5166
	--> Epoch [2/100], Loss: 0.3408, Validation Loss: 0.4814
	--> Epoch [3/100], Loss: 0.2313, Validation Loss: 0.4266
	--> Epoch [4/100], Loss: 0.1554, Validation Loss: 0.4019
	--> Epoch [5/100], Loss: 0.0689, Validation Loss: 0.3898
	--> Epoch [6/100], Loss: 0.0337, Validation Loss: 0.3643
	--> Epoch [7/100], Loss: 0.0442, Validation Loss: 0.3505
	--> Epoch [8/100], Loss: 0.0971, Validation Loss: 0.3387
	--> Epoch [9/100], Loss: 0.0294, Validation Loss: 0.3328
	--> Epoch [10/100], Loss: 0.0846, Validation Loss: 0.3777
	--> Epoch [11/100], Loss: 0.0070, Validation Loss: 0.3655
	--> Epoch [12/100], Loss: 0.0297, Validation Loss: 0.3488
Early stopping
	--> Training for Fold 4 took 0.08003520965576172 sec, using 12 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6022, Validation Loss: 0.5658
	--> Epoch [2/100], Loss: 0.3682, Validation Loss: 0.5635
	--> Epoch [3/100], Loss: 0.2595, Validation Loss: 0.5462
	--> Epoch [4/100], Loss: 0.2628, Validation Loss: 0.5697
	--> Epoch [5/100], Loss: 0.0808, Validation Loss: 0.6039
	--> Epoch [6/100], Loss: 0.1094, Validation Loss: 0.5999
Early stopping
	--> Training for Fold 5 took 0.055214881896972656 sec, using 6 epochs

Median number of epochs used: 12 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/12], Loss: 0.6673
	--> Final training Epoch [2/12], Loss: 0.4284
	--> Final training Epoch [3/12], Loss: 0.3929
	--> Final training Epoch [4/12], Loss: 0.3361
	--> Final training Epoch [5/12], Loss: 0.2432
	--> Final training Epoch [6/12], Loss: 0.1975
	--> Final training Epoch [7/12], Loss: 0.1614
	--> Final training Epoch [8/12], Loss: 0.0940
	--> Final training Epoch [9/12], Loss: 0.0461
	--> Final training Epoch [10/12], Loss: 0.0638
	--> Final training Epoch [11/12], Loss: 0.1104
	--> Final training Epoch [12/12], Loss: 0.0346

Final training took 0.0797884464263916 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.9555
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3142,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3475,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3556,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 0.3907,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7947, Validation Loss: 0.3591,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3651,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8474, Validation Loss: 0.3594,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3619,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3677,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3518,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3812,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3591,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.3916,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8374, Validation Loss: 0.3496,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8047, Validation Loss: 0.4110,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8041, Validation Loss: 0.4971,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7830, Validation Loss: 0.4276,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7302, Validation Loss: 0.6201
	--> Epoch [2/100], Loss: 0.6242, Validation Loss: 0.5388
	--> Epoch [3/100], Loss: 0.5085, Validation Loss: 0.4609
	--> Epoch [4/100], Loss: 0.4033, Validation Loss: 0.4144
	--> Epoch [5/100], Loss: 0.3632, Validation Loss: 0.3721
	--> Epoch [6/100], Loss: 0.3053, Validation Loss: 0.3433
	--> Epoch [7/100], Loss: 0.2625, Validation Loss: 0.3176
	--> Epoch [8/100], Loss: 0.2184, Validation Loss: 0.3044
	--> Epoch [9/100], Loss: 0.1729, Validation Loss: 0.2914
	--> Epoch [10/100], Loss: 0.1511, Validation Loss: 0.2892
	--> Epoch [11/100], Loss: 0.1307, Validation Loss: 0.2836
	--> Epoch [12/100], Loss: 0.1162, Validation Loss: 0.2810
	--> Epoch [13/100], Loss: 0.1150, Validation Loss: 0.2748
	--> Epoch [14/100], Loss: 0.1072, Validation Loss: 0.2717
	--> Epoch [15/100], Loss: 0.0800, Validation Loss: 0.2696
	--> Epoch [16/100], Loss: 0.0694, Validation Loss: 0.2646
	--> Epoch [17/100], Loss: 0.0916, Validation Loss: 0.2585
	--> Epoch [18/100], Loss: 0.0941, Validation Loss: 0.2591
	--> Epoch [19/100], Loss: 0.0696, Validation Loss: 0.2503
	--> Epoch [20/100], Loss: 0.0641, Validation Loss: 0.2471
	--> Epoch [21/100], Loss: 0.0541, Validation Loss: 0.2476
	--> Epoch [22/100], Loss: 0.0709, Validation Loss: 0.2454
	--> Epoch [23/100], Loss: 0.0416, Validation Loss: 0.2662
	--> Epoch [24/100], Loss: 0.0481, Validation Loss: 0.2689
	--> Epoch [25/100], Loss: 0.0578, Validation Loss: 0.2652
Early stopping
	--> Training for Fold 1 took 0.1079702377319336 sec, using 25 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7618, Validation Loss: 0.5026
	--> Epoch [2/100], Loss: 0.5524, Validation Loss: 0.4232
	--> Epoch [3/100], Loss: 0.4604, Validation Loss: 0.3676
	--> Epoch [4/100], Loss: 0.3591, Validation Loss: 0.3295
	--> Epoch [5/100], Loss: 0.2846, Validation Loss: 0.3116
	--> Epoch [6/100], Loss: 0.2548, Validation Loss: 0.2863
	--> Epoch [7/100], Loss: 0.2145, Validation Loss: 0.2739
	--> Epoch [8/100], Loss: 0.1753, Validation Loss: 0.2604
	--> Epoch [9/100], Loss: 0.1828, Validation Loss: 0.2627
	--> Epoch [10/100], Loss: 0.1265, Validation Loss: 0.2519
	--> Epoch [11/100], Loss: 0.1137, Validation Loss: 0.2403
	--> Epoch [12/100], Loss: 0.0922, Validation Loss: 0.2230
	--> Epoch [13/100], Loss: 0.1345, Validation Loss: 0.2115
	--> Epoch [14/100], Loss: 0.1116, Validation Loss: 0.2090
	--> Epoch [15/100], Loss: 0.0974, Validation Loss: 0.2026
	--> Epoch [16/100], Loss: 0.0886, Validation Loss: 0.2106
	--> Epoch [17/100], Loss: 0.0856, Validation Loss: 0.2021
	--> Epoch [18/100], Loss: 0.0771, Validation Loss: 0.1987
	--> Epoch [19/100], Loss: 0.1104, Validation Loss: 0.2053
	--> Epoch [20/100], Loss: 0.1284, Validation Loss: 0.2035
	--> Epoch [21/100], Loss: 0.0691, Validation Loss: 0.2005
Early stopping
	--> Training for Fold 2 took 0.10688567161560059 sec, using 21 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7337, Validation Loss: 0.6352
	--> Epoch [2/100], Loss: 0.5436, Validation Loss: 0.5354
	--> Epoch [3/100], Loss: 0.4435, Validation Loss: 0.4649
	--> Epoch [4/100], Loss: 0.3599, Validation Loss: 0.4219
	--> Epoch [5/100], Loss: 0.2792, Validation Loss: 0.3908
	--> Epoch [6/100], Loss: 0.2530, Validation Loss: 0.3603
	--> Epoch [7/100], Loss: 0.2203, Validation Loss: 0.3467
	--> Epoch [8/100], Loss: 0.1712, Validation Loss: 0.3283
	--> Epoch [9/100], Loss: 0.1607, Validation Loss: 0.3233
	--> Epoch [10/100], Loss: 0.1588, Validation Loss: 0.3188
	--> Epoch [11/100], Loss: 0.1642, Validation Loss: 0.3054
	--> Epoch [12/100], Loss: 0.0863, Validation Loss: 0.2968
	--> Epoch [13/100], Loss: 0.1263, Validation Loss: 0.2897
	--> Epoch [14/100], Loss: 0.0987, Validation Loss: 0.2926
	--> Epoch [15/100], Loss: 0.0830, Validation Loss: 0.2973
	--> Epoch [16/100], Loss: 0.0655, Validation Loss: 0.3008
Early stopping
	--> Training for Fold 3 took 0.06491398811340332 sec, using 16 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7157, Validation Loss: 0.6339
	--> Epoch [2/100], Loss: 0.6340, Validation Loss: 0.5812
	--> Epoch [3/100], Loss: 0.5731, Validation Loss: 0.5176
	--> Epoch [4/100], Loss: 0.4759, Validation Loss: 0.4578
	--> Epoch [5/100], Loss: 0.4060, Validation Loss: 0.3956
	--> Epoch [6/100], Loss: 0.3264, Validation Loss: 0.3679
	--> Epoch [7/100], Loss: 0.2450, Validation Loss: 0.3406
	--> Epoch [8/100], Loss: 0.2103, Validation Loss: 0.3087
	--> Epoch [9/100], Loss: 0.1655, Validation Loss: 0.2907
	--> Epoch [10/100], Loss: 0.1375, Validation Loss: 0.2858
	--> Epoch [11/100], Loss: 0.1411, Validation Loss: 0.2774
	--> Epoch [12/100], Loss: 0.1033, Validation Loss: 0.2660
	--> Epoch [13/100], Loss: 0.0921, Validation Loss: 0.2690
	--> Epoch [14/100], Loss: 0.0996, Validation Loss: 0.2645
	--> Epoch [15/100], Loss: 0.1033, Validation Loss: 0.2637
	--> Epoch [16/100], Loss: 0.0895, Validation Loss: 0.2744
	--> Epoch [17/100], Loss: 0.0746, Validation Loss: 0.2829
	--> Epoch [18/100], Loss: 0.0972, Validation Loss: 0.2848
Early stopping
	--> Training for Fold 4 took 0.06699800491333008 sec, using 18 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7423, Validation Loss: 0.6798
	--> Epoch [2/100], Loss: 0.5169, Validation Loss: 0.6336
	--> Epoch [3/100], Loss: 0.4437, Validation Loss: 0.6078
	--> Epoch [4/100], Loss: 0.3323, Validation Loss: 0.5990
	--> Epoch [5/100], Loss: 0.2703, Validation Loss: 0.5796
	--> Epoch [6/100], Loss: 0.2125, Validation Loss: 0.5741
	--> Epoch [7/100], Loss: 0.1876, Validation Loss: 0.5685
	--> Epoch [8/100], Loss: 0.1932, Validation Loss: 0.5762
	--> Epoch [9/100], Loss: 0.1496, Validation Loss: 0.5445
	--> Epoch [10/100], Loss: 0.1549, Validation Loss: 0.5539
	--> Epoch [11/100], Loss: 0.1113, Validation Loss: 0.5307
	--> Epoch [12/100], Loss: 0.1315, Validation Loss: 0.5355
	--> Epoch [13/100], Loss: 0.0849, Validation Loss: 0.5457
	--> Epoch [14/100], Loss: 0.0863, Validation Loss: 0.5350
Early stopping
	--> Training for Fold 5 took 0.049567461013793945 sec, using 14 epochs

Median number of epochs used: 18 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/18], Loss: 0.7187
	--> Final training Epoch [2/18], Loss: 0.5214
	--> Final training Epoch [3/18], Loss: 0.4199
	--> Final training Epoch [4/18], Loss: 0.3424
	--> Final training Epoch [5/18], Loss: 0.2657
	--> Final training Epoch [6/18], Loss: 0.2270
	--> Final training Epoch [7/18], Loss: 0.1919
	--> Final training Epoch [8/18], Loss: 0.1597
	--> Final training Epoch [9/18], Loss: 0.1378
	--> Final training Epoch [10/18], Loss: 0.1103
	--> Final training Epoch [11/18], Loss: 0.1011
	--> Final training Epoch [12/18], Loss: 0.1000
	--> Final training Epoch [13/18], Loss: 0.1098
	--> Final training Epoch [14/18], Loss: 0.0958
	--> Final training Epoch [15/18], Loss: 0.0710
	--> Final training Epoch [16/18], Loss: 0.0612
	--> Final training Epoch [17/18], Loss: 0.0525
	--> Final training Epoch [18/18], Loss: 0.0444

Final training took 0.06632447242736816 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.9620
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8924, Validation Loss: 0.3194,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3194
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3411,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3194

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6716, Validation Loss: 0.5531
	--> Epoch [2/100], Loss: 0.5665, Validation Loss: 0.5011
	--> Epoch [3/100], Loss: 0.5000, Validation Loss: 0.4312
	--> Epoch [4/100], Loss: 0.4207, Validation Loss: 0.3921
	--> Epoch [5/100], Loss: 0.3520, Validation Loss: 0.3551
	--> Epoch [6/100], Loss: 0.2920, Validation Loss: 0.3333
	--> Epoch [7/100], Loss: 0.2622, Validation Loss: 0.3075
	--> Epoch [8/100], Loss: 0.2433, Validation Loss: 0.3026
	--> Epoch [9/100], Loss: 0.1857, Validation Loss: 0.2935
	--> Epoch [10/100], Loss: 0.1713, Validation Loss: 0.2874
	--> Epoch [11/100], Loss: 0.1342, Validation Loss: 0.2913
	--> Epoch [12/100], Loss: 0.1023, Validation Loss: 0.2941
	--> Epoch [13/100], Loss: 0.1181, Validation Loss: 0.2875
Early stopping
	--> Training for Fold 1 took 0.047756195068359375 sec, using 13 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6859, Validation Loss: 0.5180
	--> Epoch [2/100], Loss: 0.5428, Validation Loss: 0.4692
	--> Epoch [3/100], Loss: 0.4589, Validation Loss: 0.4091
	--> Epoch [4/100], Loss: 0.3785, Validation Loss: 0.3911
	--> Epoch [5/100], Loss: 0.2757, Validation Loss: 0.3576
	--> Epoch [6/100], Loss: 0.2334, Validation Loss: 0.3345
	--> Epoch [7/100], Loss: 0.1998, Validation Loss: 0.3188
	--> Epoch [8/100], Loss: 0.1810, Validation Loss: 0.3110
	--> Epoch [9/100], Loss: 0.1731, Validation Loss: 0.3034
	--> Epoch [10/100], Loss: 0.1570, Validation Loss: 0.2673
	--> Epoch [11/100], Loss: 0.1368, Validation Loss: 0.2649
	--> Epoch [12/100], Loss: 0.1146, Validation Loss: 0.2610
	--> Epoch [13/100], Loss: 0.1102, Validation Loss: 0.2580
	--> Epoch [14/100], Loss: 0.1008, Validation Loss: 0.2470
	--> Epoch [15/100], Loss: 0.0835, Validation Loss: 0.2431
	--> Epoch [16/100], Loss: 0.1312, Validation Loss: 0.2555
	--> Epoch [17/100], Loss: 0.1202, Validation Loss: 0.2494
	--> Epoch [18/100], Loss: 0.0863, Validation Loss: 0.2448
Early stopping
	--> Training for Fold 2 took 0.06619048118591309 sec, using 18 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7445, Validation Loss: 0.6875
	--> Epoch [2/100], Loss: 0.5971, Validation Loss: 0.6288
	--> Epoch [3/100], Loss: 0.5047, Validation Loss: 0.5769
	--> Epoch [4/100], Loss: 0.4344, Validation Loss: 0.5234
	--> Epoch [5/100], Loss: 0.3531, Validation Loss: 0.4877
	--> Epoch [6/100], Loss: 0.3035, Validation Loss: 0.4567
	--> Epoch [7/100], Loss: 0.2102, Validation Loss: 0.4299
	--> Epoch [8/100], Loss: 0.2200, Validation Loss: 0.4181
	--> Epoch [9/100], Loss: 0.1921, Validation Loss: 0.3981
	--> Epoch [10/100], Loss: 0.1550, Validation Loss: 0.3885
	--> Epoch [11/100], Loss: 0.1040, Validation Loss: 0.3828
	--> Epoch [12/100], Loss: 0.1410, Validation Loss: 0.3719
	--> Epoch [13/100], Loss: 0.0904, Validation Loss: 0.3591
	--> Epoch [14/100], Loss: 0.1060, Validation Loss: 0.3583
	--> Epoch [15/100], Loss: 0.0877, Validation Loss: 0.3552
	--> Epoch [16/100], Loss: 0.0942, Validation Loss: 0.3502
	--> Epoch [17/100], Loss: 0.0760, Validation Loss: 0.3501
	--> Epoch [18/100], Loss: 0.0740, Validation Loss: 0.3623
	--> Epoch [19/100], Loss: 0.0796, Validation Loss: 0.3558
	--> Epoch [20/100], Loss: 0.1056, Validation Loss: 0.3560
Early stopping
	--> Training for Fold 3 took 0.07459115982055664 sec, using 20 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7133, Validation Loss: 0.5243
	--> Epoch [2/100], Loss: 0.5523, Validation Loss: 0.4647
	--> Epoch [3/100], Loss: 0.4310, Validation Loss: 0.4195
	--> Epoch [4/100], Loss: 0.3623, Validation Loss: 0.3972
	--> Epoch [5/100], Loss: 0.3065, Validation Loss: 0.3735
	--> Epoch [6/100], Loss: 0.2224, Validation Loss: 0.3501
	--> Epoch [7/100], Loss: 0.2174, Validation Loss: 0.3478
	--> Epoch [8/100], Loss: 0.2069, Validation Loss: 0.3287
	--> Epoch [9/100], Loss: 0.1706, Validation Loss: 0.3232
	--> Epoch [10/100], Loss: 0.1603, Validation Loss: 0.3162
	--> Epoch [11/100], Loss: 0.1173, Validation Loss: 0.3118
	--> Epoch [12/100], Loss: 0.1260, Validation Loss: 0.2954
	--> Epoch [13/100], Loss: 0.1311, Validation Loss: 0.3058
	--> Epoch [14/100], Loss: 0.0700, Validation Loss: 0.3093
	--> Epoch [15/100], Loss: 0.1066, Validation Loss: 0.3065
Early stopping
	--> Training for Fold 4 took 0.05877947807312012 sec, using 15 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7768, Validation Loss: 0.6072
	--> Epoch [2/100], Loss: 0.5606, Validation Loss: 0.5750
	--> Epoch [3/100], Loss: 0.4548, Validation Loss: 0.5444
	--> Epoch [4/100], Loss: 0.3722, Validation Loss: 0.5238
	--> Epoch [5/100], Loss: 0.2978, Validation Loss: 0.5194
	--> Epoch [6/100], Loss: 0.2765, Validation Loss: 0.5038
	--> Epoch [7/100], Loss: 0.2312, Validation Loss: 0.5042
	--> Epoch [8/100], Loss: 0.2050, Validation Loss: 0.4999
	--> Epoch [9/100], Loss: 0.1602, Validation Loss: 0.5089
	--> Epoch [10/100], Loss: 0.1646, Validation Loss: 0.5001
	--> Epoch [11/100], Loss: 0.1410, Validation Loss: 0.5090
Early stopping
	--> Training for Fold 5 took 0.04276442527770996 sec, using 11 epochs

Median number of epochs used: 15 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/15], Loss: 0.7574
	--> Final training Epoch [2/15], Loss: 0.5491
	--> Final training Epoch [3/15], Loss: 0.4671
	--> Final training Epoch [4/15], Loss: 0.3870
	--> Final training Epoch [5/15], Loss: 0.3125
	--> Final training Epoch [6/15], Loss: 0.2802
	--> Final training Epoch [7/15], Loss: 0.2250
	--> Final training Epoch [8/15], Loss: 0.1806
	--> Final training Epoch [9/15], Loss: 0.1741
	--> Final training Epoch [10/15], Loss: 0.1189
	--> Final training Epoch [11/15], Loss: 0.1187
	--> Final training Epoch [12/15], Loss: 0.1296
	--> Final training Epoch [13/15], Loss: 0.0949
	--> Final training Epoch [14/15], Loss: 0.0963
	--> Final training Epoch [15/15], Loss: 0.1038

Final training took 0.05049467086791992 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.9208
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8813, Validation Loss: 0.3175,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3546,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.3350,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3791,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 0.3862,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3533,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.3515,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8708, Validation Loss: 0.3314,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.3270,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7268, Validation Loss: 0.5170
	--> Epoch [2/100], Loss: 0.5384, Validation Loss: 0.4499
	--> Epoch [3/100], Loss: 0.4465, Validation Loss: 0.4137
	--> Epoch [4/100], Loss: 0.3625, Validation Loss: 0.3790
	--> Epoch [5/100], Loss: 0.2769, Validation Loss: 0.3424
	--> Epoch [6/100], Loss: 0.2454, Validation Loss: 0.3101
	--> Epoch [7/100], Loss: 0.1976, Validation Loss: 0.2887
	--> Epoch [8/100], Loss: 0.1986, Validation Loss: 0.2586
	--> Epoch [9/100], Loss: 0.1690, Validation Loss: 0.2617
	--> Epoch [10/100], Loss: 0.1509, Validation Loss: 0.2511
	--> Epoch [11/100], Loss: 0.1150, Validation Loss: 0.2359
	--> Epoch [12/100], Loss: 0.1471, Validation Loss: 0.2317
	--> Epoch [13/100], Loss: 0.1207, Validation Loss: 0.2381
	--> Epoch [14/100], Loss: 0.1512, Validation Loss: 0.2335
	--> Epoch [15/100], Loss: 0.0872, Validation Loss: 0.2441
Early stopping
	--> Training for Fold 1 took 0.0532984733581543 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7792, Validation Loss: 0.6289
	--> Epoch [2/100], Loss: 0.5584, Validation Loss: 0.4756
	--> Epoch [3/100], Loss: 0.4630, Validation Loss: 0.3809
	--> Epoch [4/100], Loss: 0.3560, Validation Loss: 0.3388
	--> Epoch [5/100], Loss: 0.3054, Validation Loss: 0.3102
	--> Epoch [6/100], Loss: 0.2830, Validation Loss: 0.2954
	--> Epoch [7/100], Loss: 0.2055, Validation Loss: 0.2986
	--> Epoch [8/100], Loss: 0.1691, Validation Loss: 0.2706
	--> Epoch [9/100], Loss: 0.1540, Validation Loss: 0.2677
	--> Epoch [10/100], Loss: 0.1501, Validation Loss: 0.2538
	--> Epoch [11/100], Loss: 0.1226, Validation Loss: 0.2471
	--> Epoch [12/100], Loss: 0.0912, Validation Loss: 0.2440
	--> Epoch [13/100], Loss: 0.1060, Validation Loss: 0.2342
	--> Epoch [14/100], Loss: 0.0969, Validation Loss: 0.2148
	--> Epoch [15/100], Loss: 0.0884, Validation Loss: 0.2131
	--> Epoch [16/100], Loss: 0.0587, Validation Loss: 0.2088
	--> Epoch [17/100], Loss: 0.0812, Validation Loss: 0.2106
	--> Epoch [18/100], Loss: 0.0721, Validation Loss: 0.2077
	--> Epoch [19/100], Loss: 0.0463, Validation Loss: 0.2102
	--> Epoch [20/100], Loss: 0.0431, Validation Loss: 0.2049
	--> Epoch [21/100], Loss: 0.0300, Validation Loss: 0.2010
	--> Epoch [22/100], Loss: 0.0476, Validation Loss: 0.1847
	--> Epoch [23/100], Loss: 0.0222, Validation Loss: 0.1845
	--> Epoch [24/100], Loss: 0.0742, Validation Loss: 0.1855
	--> Epoch [25/100], Loss: 0.0718, Validation Loss: 0.1794
	--> Epoch [26/100], Loss: 0.0826, Validation Loss: 0.1810
	--> Epoch [27/100], Loss: 0.0651, Validation Loss: 0.1805
	--> Epoch [28/100], Loss: 0.0415, Validation Loss: 0.1859
Early stopping
	--> Training for Fold 2 took 0.1005859375 sec, using 28 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7340, Validation Loss: 0.6282
	--> Epoch [2/100], Loss: 0.5207, Validation Loss: 0.5456
	--> Epoch [3/100], Loss: 0.3991, Validation Loss: 0.4975
	--> Epoch [4/100], Loss: 0.3446, Validation Loss: 0.4663
	--> Epoch [5/100], Loss: 0.2757, Validation Loss: 0.4303
	--> Epoch [6/100], Loss: 0.2290, Validation Loss: 0.4081
	--> Epoch [7/100], Loss: 0.2180, Validation Loss: 0.4000
	--> Epoch [8/100], Loss: 0.1617, Validation Loss: 0.3934
	--> Epoch [9/100], Loss: 0.1448, Validation Loss: 0.3784
	--> Epoch [10/100], Loss: 0.1463, Validation Loss: 0.3668
	--> Epoch [11/100], Loss: 0.1102, Validation Loss: 0.3654
	--> Epoch [12/100], Loss: 0.1646, Validation Loss: 0.3604
	--> Epoch [13/100], Loss: 0.1140, Validation Loss: 0.3483
	--> Epoch [14/100], Loss: 0.1036, Validation Loss: 0.3430
	--> Epoch [15/100], Loss: 0.1078, Validation Loss: 0.3446
	--> Epoch [16/100], Loss: 0.0934, Validation Loss: 0.3434
	--> Epoch [17/100], Loss: 0.1229, Validation Loss: 0.3403
	--> Epoch [18/100], Loss: 0.0758, Validation Loss: 0.3391
	--> Epoch [19/100], Loss: 0.0526, Validation Loss: 0.3374
	--> Epoch [20/100], Loss: 0.0737, Validation Loss: 0.3420
	--> Epoch [21/100], Loss: 0.0708, Validation Loss: 0.3417
	--> Epoch [22/100], Loss: 0.0705, Validation Loss: 0.3351
	--> Epoch [23/100], Loss: 0.0607, Validation Loss: 0.3214
	--> Epoch [24/100], Loss: 0.0611, Validation Loss: 0.3175
	--> Epoch [25/100], Loss: 0.0736, Validation Loss: 0.3154
	--> Epoch [26/100], Loss: 0.0859, Validation Loss: 0.2999
	--> Epoch [27/100], Loss: 0.0746, Validation Loss: 0.2957
	--> Epoch [28/100], Loss: 0.0594, Validation Loss: 0.2917
	--> Epoch [29/100], Loss: 0.0716, Validation Loss: 0.2798
	--> Epoch [30/100], Loss: 0.0786, Validation Loss: 0.3002
	--> Epoch [31/100], Loss: 0.0386, Validation Loss: 0.2949
	--> Epoch [32/100], Loss: 0.0549, Validation Loss: 0.2964
Early stopping
	--> Training for Fold 3 took 0.11905622482299805 sec, using 32 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7221, Validation Loss: 0.4928
	--> Epoch [2/100], Loss: 0.5570, Validation Loss: 0.3856
	--> Epoch [3/100], Loss: 0.5033, Validation Loss: 0.3490
	--> Epoch [4/100], Loss: 0.3819, Validation Loss: 0.3157
	--> Epoch [5/100], Loss: 0.3444, Validation Loss: 0.2820
	--> Epoch [6/100], Loss: 0.2486, Validation Loss: 0.2537
	--> Epoch [7/100], Loss: 0.2468, Validation Loss: 0.2422
	--> Epoch [8/100], Loss: 0.2259, Validation Loss: 0.2382
	--> Epoch [9/100], Loss: 0.1615, Validation Loss: 0.2303
	--> Epoch [10/100], Loss: 0.1653, Validation Loss: 0.2185
	--> Epoch [11/100], Loss: 0.1507, Validation Loss: 0.2083
	--> Epoch [12/100], Loss: 0.1191, Validation Loss: 0.2079
	--> Epoch [13/100], Loss: 0.1168, Validation Loss: 0.2016
	--> Epoch [14/100], Loss: 0.0901, Validation Loss: 0.2009
	--> Epoch [15/100], Loss: 0.0822, Validation Loss: 0.2014
	--> Epoch [16/100], Loss: 0.0737, Validation Loss: 0.1974
	--> Epoch [17/100], Loss: 0.0761, Validation Loss: 0.1945
	--> Epoch [18/100], Loss: 0.0772, Validation Loss: 0.2039
	--> Epoch [19/100], Loss: 0.0828, Validation Loss: 0.1997
	--> Epoch [20/100], Loss: 0.0780, Validation Loss: 0.2024
Early stopping
	--> Training for Fold 4 took 0.09641385078430176 sec, using 20 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7736, Validation Loss: 0.5950
	--> Epoch [2/100], Loss: 0.6408, Validation Loss: 0.5530
	--> Epoch [3/100], Loss: 0.5431, Validation Loss: 0.5271
	--> Epoch [4/100], Loss: 0.4600, Validation Loss: 0.5168
	--> Epoch [5/100], Loss: 0.3954, Validation Loss: 0.4915
	--> Epoch [6/100], Loss: 0.3269, Validation Loss: 0.4800
	--> Epoch [7/100], Loss: 0.2810, Validation Loss: 0.4714
	--> Epoch [8/100], Loss: 0.2358, Validation Loss: 0.4543
	--> Epoch [9/100], Loss: 0.2463, Validation Loss: 0.4555
	--> Epoch [10/100], Loss: 0.2206, Validation Loss: 0.4552
	--> Epoch [11/100], Loss: 0.1684, Validation Loss: 0.4541
	--> Epoch [12/100], Loss: 0.1805, Validation Loss: 0.4651
	--> Epoch [13/100], Loss: 0.1630, Validation Loss: 0.4697
	--> Epoch [14/100], Loss: 0.1559, Validation Loss: 0.4703
Early stopping
	--> Training for Fold 5 took 0.07161474227905273 sec, using 14 epochs

Median number of epochs used: 20 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/20], Loss: 0.7341
	--> Final training Epoch [2/20], Loss: 0.5607
	--> Final training Epoch [3/20], Loss: 0.4347
	--> Final training Epoch [4/20], Loss: 0.3520
	--> Final training Epoch [5/20], Loss: 0.2965
	--> Final training Epoch [6/20], Loss: 0.2442
	--> Final training Epoch [7/20], Loss: 0.2304
	--> Final training Epoch [8/20], Loss: 0.1596
	--> Final training Epoch [9/20], Loss: 0.1790
	--> Final training Epoch [10/20], Loss: 0.1526
	--> Final training Epoch [11/20], Loss: 0.1243
	--> Final training Epoch [12/20], Loss: 0.1168
	--> Final training Epoch [13/20], Loss: 0.0894
	--> Final training Epoch [14/20], Loss: 0.1064
	--> Final training Epoch [15/20], Loss: 0.0892
	--> Final training Epoch [16/20], Loss: 0.0888
	--> Final training Epoch [17/20], Loss: 0.1115
	--> Final training Epoch [18/20], Loss: 0.0617
	--> Final training Epoch [19/20], Loss: 0.0738
	--> Final training Epoch [20/20], Loss: 0.0680

Final training took 0.06960606575012207 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.2442
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8819, Validation Loss: 0.3116,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3116
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8608, Validation Loss: 0.3216,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3116
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8696, Validation Loss: 0.3349,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3116

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7067, Validation Loss: 0.6059
	--> Epoch [2/100], Loss: 0.5366, Validation Loss: 0.5049
	--> Epoch [3/100], Loss: 0.4357, Validation Loss: 0.4673
	--> Epoch [4/100], Loss: 0.4093, Validation Loss: 0.4241
	--> Epoch [5/100], Loss: 0.3273, Validation Loss: 0.3858
	--> Epoch [6/100], Loss: 0.2746, Validation Loss: 0.3559
	--> Epoch [7/100], Loss: 0.2423, Validation Loss: 0.3342
	--> Epoch [8/100], Loss: 0.2963, Validation Loss: 0.3217
	--> Epoch [9/100], Loss: 0.1953, Validation Loss: 0.3251
	--> Epoch [10/100], Loss: 0.2048, Validation Loss: 0.2937
	--> Epoch [11/100], Loss: 0.1941, Validation Loss: 0.2825
	--> Epoch [12/100], Loss: 0.2192, Validation Loss: 0.2762
	--> Epoch [13/100], Loss: 0.2339, Validation Loss: 0.2604
	--> Epoch [14/100], Loss: 0.1292, Validation Loss: 0.2431
	--> Epoch [15/100], Loss: 0.1667, Validation Loss: 0.2299
	--> Epoch [16/100], Loss: 0.1168, Validation Loss: 0.2267
	--> Epoch [17/100], Loss: 0.1277, Validation Loss: 0.2142
	--> Epoch [18/100], Loss: 0.1053, Validation Loss: 0.2114
	--> Epoch [19/100], Loss: 0.1297, Validation Loss: 0.2050
	--> Epoch [20/100], Loss: 0.0922, Validation Loss: 0.2002
	--> Epoch [21/100], Loss: 0.0963, Validation Loss: 0.1902
	--> Epoch [22/100], Loss: 0.0977, Validation Loss: 0.1878
	--> Epoch [23/100], Loss: 0.1316, Validation Loss: 0.1925
	--> Epoch [24/100], Loss: 0.1224, Validation Loss: 0.1936
	--> Epoch [25/100], Loss: 0.0711, Validation Loss: 0.1937
Early stopping
	--> Training for Fold 1 took 0.0992891788482666 sec, using 25 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7433, Validation Loss: 0.5721
	--> Epoch [2/100], Loss: 0.6320, Validation Loss: 0.4824
	--> Epoch [3/100], Loss: 0.4896, Validation Loss: 0.4098
	--> Epoch [4/100], Loss: 0.4352, Validation Loss: 0.3620
	--> Epoch [5/100], Loss: 0.3702, Validation Loss: 0.3202
	--> Epoch [6/100], Loss: 0.3534, Validation Loss: 0.3118
	--> Epoch [7/100], Loss: 0.3261, Validation Loss: 0.3032
	--> Epoch [8/100], Loss: 0.2239, Validation Loss: 0.2870
	--> Epoch [9/100], Loss: 0.2907, Validation Loss: 0.2753
	--> Epoch [10/100], Loss: 0.2431, Validation Loss: 0.2598
	--> Epoch [11/100], Loss: 0.2105, Validation Loss: 0.2470
	--> Epoch [12/100], Loss: 0.2048, Validation Loss: 0.2432
	--> Epoch [13/100], Loss: 0.1774, Validation Loss: 0.2275
	--> Epoch [14/100], Loss: 0.1328, Validation Loss: 0.2193
	--> Epoch [15/100], Loss: 0.1606, Validation Loss: 0.2371
	--> Epoch [16/100], Loss: 0.1602, Validation Loss: 0.2116
	--> Epoch [17/100], Loss: 0.1639, Validation Loss: 0.2076
	--> Epoch [18/100], Loss: 0.1361, Validation Loss: 0.2221
	--> Epoch [19/100], Loss: 0.1366, Validation Loss: 0.2184
	--> Epoch [20/100], Loss: 0.1208, Validation Loss: 0.2138
Early stopping
	--> Training for Fold 2 took 0.07781052589416504 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7862, Validation Loss: 0.6041
	--> Epoch [2/100], Loss: 0.5650, Validation Loss: 0.5331
	--> Epoch [3/100], Loss: 0.4780, Validation Loss: 0.5044
	--> Epoch [4/100], Loss: 0.3973, Validation Loss: 0.4607
	--> Epoch [5/100], Loss: 0.3474, Validation Loss: 0.4195
	--> Epoch [6/100], Loss: 0.2664, Validation Loss: 0.3991
	--> Epoch [7/100], Loss: 0.2215, Validation Loss: 0.3913
	--> Epoch [8/100], Loss: 0.2323, Validation Loss: 0.3652
	--> Epoch [9/100], Loss: 0.2110, Validation Loss: 0.3691
	--> Epoch [10/100], Loss: 0.1999, Validation Loss: 0.3533
	--> Epoch [11/100], Loss: 0.1413, Validation Loss: 0.3397
	--> Epoch [12/100], Loss: 0.1823, Validation Loss: 0.3189
	--> Epoch [13/100], Loss: 0.1551, Validation Loss: 0.3203
	--> Epoch [14/100], Loss: 0.1331, Validation Loss: 0.3282
	--> Epoch [15/100], Loss: 0.1342, Validation Loss: 0.3106
	--> Epoch [16/100], Loss: 0.1194, Validation Loss: 0.2970
	--> Epoch [17/100], Loss: 0.1508, Validation Loss: 0.2954
	--> Epoch [18/100], Loss: 0.1096, Validation Loss: 0.2931
	--> Epoch [19/100], Loss: 0.1160, Validation Loss: 0.2929
	--> Epoch [20/100], Loss: 0.0931, Validation Loss: 0.2844
	--> Epoch [21/100], Loss: 0.1064, Validation Loss: 0.2840
	--> Epoch [22/100], Loss: 0.1259, Validation Loss: 0.2827
	--> Epoch [23/100], Loss: 0.0992, Validation Loss: 0.2818
	--> Epoch [24/100], Loss: 0.1208, Validation Loss: 0.2867
	--> Epoch [25/100], Loss: 0.0680, Validation Loss: 0.2783
	--> Epoch [26/100], Loss: 0.1485, Validation Loss: 0.2795
	--> Epoch [27/100], Loss: 0.1191, Validation Loss: 0.2740
	--> Epoch [28/100], Loss: 0.0856, Validation Loss: 0.2747
	--> Epoch [29/100], Loss: 0.0791, Validation Loss: 0.2798
	--> Epoch [30/100], Loss: 0.0859, Validation Loss: 0.2838
Early stopping
	--> Training for Fold 3 took 0.11116194725036621 sec, using 30 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7014, Validation Loss: 0.6568
	--> Epoch [2/100], Loss: 0.6144, Validation Loss: 0.5540
	--> Epoch [3/100], Loss: 0.5088, Validation Loss: 0.5055
	--> Epoch [4/100], Loss: 0.4751, Validation Loss: 0.4553
	--> Epoch [5/100], Loss: 0.4248, Validation Loss: 0.4307
	--> Epoch [6/100], Loss: 0.3103, Validation Loss: 0.4049
	--> Epoch [7/100], Loss: 0.2697, Validation Loss: 0.3679
	--> Epoch [8/100], Loss: 0.2871, Validation Loss: 0.3789
	--> Epoch [9/100], Loss: 0.1886, Validation Loss: 0.3663
	--> Epoch [10/100], Loss: 0.2455, Validation Loss: 0.3568
	--> Epoch [11/100], Loss: 0.1705, Validation Loss: 0.3323
	--> Epoch [12/100], Loss: 0.1645, Validation Loss: 0.3365
	--> Epoch [13/100], Loss: 0.1532, Validation Loss: 0.3420
	--> Epoch [14/100], Loss: 0.1725, Validation Loss: 0.3363
Early stopping
	--> Training for Fold 4 took 0.04989957809448242 sec, using 14 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7040, Validation Loss: 0.5240
	--> Epoch [2/100], Loss: 0.5126, Validation Loss: 0.5056
	--> Epoch [3/100], Loss: 0.3998, Validation Loss: 0.5029
	--> Epoch [4/100], Loss: 0.3332, Validation Loss: 0.4745
	--> Epoch [5/100], Loss: 0.2948, Validation Loss: 0.4676
	--> Epoch [6/100], Loss: 0.2751, Validation Loss: 0.4708
	--> Epoch [7/100], Loss: 0.1900, Validation Loss: 0.4517
	--> Epoch [8/100], Loss: 0.2003, Validation Loss: 0.4354
	--> Epoch [9/100], Loss: 0.2113, Validation Loss: 0.4521
	--> Epoch [10/100], Loss: 0.1570, Validation Loss: 0.4513
	--> Epoch [11/100], Loss: 0.1821, Validation Loss: 0.4636
Early stopping
	--> Training for Fold 5 took 0.040926456451416016 sec, using 11 epochs

Median number of epochs used: 20 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/20], Loss: 0.6962
	--> Final training Epoch [2/20], Loss: 0.5552
	--> Final training Epoch [3/20], Loss: 0.4594
	--> Final training Epoch [4/20], Loss: 0.4186
	--> Final training Epoch [5/20], Loss: 0.3998
	--> Final training Epoch [6/20], Loss: 0.3047
	--> Final training Epoch [7/20], Loss: 0.2751
	--> Final training Epoch [8/20], Loss: 0.2473
	--> Final training Epoch [9/20], Loss: 0.2274
	--> Final training Epoch [10/20], Loss: 0.2470
	--> Final training Epoch [11/20], Loss: 0.1673
	--> Final training Epoch [12/20], Loss: 0.1827
	--> Final training Epoch [13/20], Loss: 0.1226
	--> Final training Epoch [14/20], Loss: 0.1813
	--> Final training Epoch [15/20], Loss: 0.1198
	--> Final training Epoch [16/20], Loss: 0.1630
	--> Final training Epoch [17/20], Loss: 0.1065
	--> Final training Epoch [18/20], Loss: 0.1199
	--> Final training Epoch [19/20], Loss: 0.1061
	--> Final training Epoch [20/20], Loss: 0.1238

Final training took 0.07093524932861328 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0289
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8918, Validation Loss: 0.3609,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3609

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7116, Validation Loss: 0.6125
	--> Epoch [2/100], Loss: 0.6405, Validation Loss: 0.5466
	--> Epoch [3/100], Loss: 0.5963, Validation Loss: 0.5285
	--> Epoch [4/100], Loss: 0.4969, Validation Loss: 0.4793
	--> Epoch [5/100], Loss: 0.4717, Validation Loss: 0.4357
	--> Epoch [6/100], Loss: 0.4112, Validation Loss: 0.4061
	--> Epoch [7/100], Loss: 0.4202, Validation Loss: 0.3835
	--> Epoch [8/100], Loss: 0.3515, Validation Loss: 0.3671
	--> Epoch [9/100], Loss: 0.3498, Validation Loss: 0.3451
	--> Epoch [10/100], Loss: 0.3243, Validation Loss: 0.3253
	--> Epoch [11/100], Loss: 0.3542, Validation Loss: 0.3203
	--> Epoch [12/100], Loss: 0.2826, Validation Loss: 0.3176
	--> Epoch [13/100], Loss: 0.3075, Validation Loss: 0.3091
	--> Epoch [14/100], Loss: 0.2841, Validation Loss: 0.2996
	--> Epoch [15/100], Loss: 0.2598, Validation Loss: 0.2991
	--> Epoch [16/100], Loss: 0.2942, Validation Loss: 0.2919
	--> Epoch [17/100], Loss: 0.2472, Validation Loss: 0.2883
	--> Epoch [18/100], Loss: 0.1854, Validation Loss: 0.2840
	--> Epoch [19/100], Loss: 0.2839, Validation Loss: 0.2749
	--> Epoch [20/100], Loss: 0.2993, Validation Loss: 0.2819
	--> Epoch [21/100], Loss: 0.2317, Validation Loss: 0.2675
	--> Epoch [22/100], Loss: 0.3208, Validation Loss: 0.2599
	--> Epoch [23/100], Loss: 0.2620, Validation Loss: 0.2520
	--> Epoch [24/100], Loss: 0.2649, Validation Loss: 0.2604
	--> Epoch [25/100], Loss: 0.2450, Validation Loss: 0.2625
	--> Epoch [26/100], Loss: 0.2565, Validation Loss: 0.2592
Early stopping
	--> Training for Fold 1 took 0.09388613700866699 sec, using 26 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7171, Validation Loss: 0.5521
	--> Epoch [2/100], Loss: 0.5878, Validation Loss: 0.4742
	--> Epoch [3/100], Loss: 0.5320, Validation Loss: 0.4443
	--> Epoch [4/100], Loss: 0.5333, Validation Loss: 0.4032
	--> Epoch [5/100], Loss: 0.4457, Validation Loss: 0.3669
	--> Epoch [6/100], Loss: 0.4281, Validation Loss: 0.3325
	--> Epoch [7/100], Loss: 0.3564, Validation Loss: 0.3371
	--> Epoch [8/100], Loss: 0.3931, Validation Loss: 0.3188
	--> Epoch [9/100], Loss: 0.3827, Validation Loss: 0.2913
	--> Epoch [10/100], Loss: 0.3693, Validation Loss: 0.2706
	--> Epoch [11/100], Loss: 0.3295, Validation Loss: 0.2684
	--> Epoch [12/100], Loss: 0.2835, Validation Loss: 0.2622
	--> Epoch [13/100], Loss: 0.2945, Validation Loss: 0.2662
	--> Epoch [14/100], Loss: 0.3333, Validation Loss: 0.2502
	--> Epoch [15/100], Loss: 0.3091, Validation Loss: 0.2451
	--> Epoch [16/100], Loss: 0.2550, Validation Loss: 0.2459
	--> Epoch [17/100], Loss: 0.2506, Validation Loss: 0.2371
	--> Epoch [18/100], Loss: 0.3029, Validation Loss: 0.2207
	--> Epoch [19/100], Loss: 0.1759, Validation Loss: 0.2192
	--> Epoch [20/100], Loss: 0.1784, Validation Loss: 0.2187
	--> Epoch [21/100], Loss: 0.3250, Validation Loss: 0.2168
	--> Epoch [22/100], Loss: 0.2828, Validation Loss: 0.2151
	--> Epoch [23/100], Loss: 0.2891, Validation Loss: 0.2033
	--> Epoch [24/100], Loss: 0.1743, Validation Loss: 0.2022
	--> Epoch [25/100], Loss: 0.2321, Validation Loss: 0.2034
	--> Epoch [26/100], Loss: 0.2417, Validation Loss: 0.2016
	--> Epoch [27/100], Loss: 0.2195, Validation Loss: 0.1988
	--> Epoch [28/100], Loss: 0.2743, Validation Loss: 0.2174
	--> Epoch [29/100], Loss: 0.2540, Validation Loss: 0.2248
	--> Epoch [30/100], Loss: 0.1678, Validation Loss: 0.2235
Early stopping
	--> Training for Fold 2 took 0.11292290687561035 sec, using 30 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7534, Validation Loss: 0.6555
	--> Epoch [2/100], Loss: 0.6623, Validation Loss: 0.5954
	--> Epoch [3/100], Loss: 0.5751, Validation Loss: 0.5724
	--> Epoch [4/100], Loss: 0.5158, Validation Loss: 0.5263
	--> Epoch [5/100], Loss: 0.4495, Validation Loss: 0.5015
	--> Epoch [6/100], Loss: 0.4403, Validation Loss: 0.4590
	--> Epoch [7/100], Loss: 0.4041, Validation Loss: 0.4244
	--> Epoch [8/100], Loss: 0.3380, Validation Loss: 0.4076
	--> Epoch [9/100], Loss: 0.3432, Validation Loss: 0.3865
	--> Epoch [10/100], Loss: 0.3929, Validation Loss: 0.4009
	--> Epoch [11/100], Loss: 0.3513, Validation Loss: 0.3712
	--> Epoch [12/100], Loss: 0.3553, Validation Loss: 0.3616
	--> Epoch [13/100], Loss: 0.3417, Validation Loss: 0.3528
	--> Epoch [14/100], Loss: 0.2798, Validation Loss: 0.3332
	--> Epoch [15/100], Loss: 0.2630, Validation Loss: 0.3139
	--> Epoch [16/100], Loss: 0.2767, Validation Loss: 0.3029
	--> Epoch [17/100], Loss: 0.2848, Validation Loss: 0.3101
	--> Epoch [18/100], Loss: 0.2265, Validation Loss: 0.3004
	--> Epoch [19/100], Loss: 0.2328, Validation Loss: 0.2973
	--> Epoch [20/100], Loss: 0.2380, Validation Loss: 0.2895
	--> Epoch [21/100], Loss: 0.2296, Validation Loss: 0.2823
	--> Epoch [22/100], Loss: 0.2629, Validation Loss: 0.3055
	--> Epoch [23/100], Loss: 0.2000, Validation Loss: 0.2983
	--> Epoch [24/100], Loss: 0.2758, Validation Loss: 0.2959
Early stopping
	--> Training for Fold 3 took 0.09357595443725586 sec, using 24 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8412, Validation Loss: 0.6585
	--> Epoch [2/100], Loss: 0.6116, Validation Loss: 0.5556
	--> Epoch [3/100], Loss: 0.5775, Validation Loss: 0.5555
	--> Epoch [4/100], Loss: 0.4494, Validation Loss: 0.4820
	--> Epoch [5/100], Loss: 0.5153, Validation Loss: 0.4343
	--> Epoch [6/100], Loss: 0.4135, Validation Loss: 0.4071
	--> Epoch [7/100], Loss: 0.3695, Validation Loss: 0.4009
	--> Epoch [8/100], Loss: 0.3686, Validation Loss: 0.3492
	--> Epoch [9/100], Loss: 0.3527, Validation Loss: 0.3383
	--> Epoch [10/100], Loss: 0.3204, Validation Loss: 0.3448
	--> Epoch [11/100], Loss: 0.3005, Validation Loss: 0.3396
	--> Epoch [12/100], Loss: 0.2632, Validation Loss: 0.3325
	--> Epoch [13/100], Loss: 0.3333, Validation Loss: 0.3445
	--> Epoch [14/100], Loss: 0.2765, Validation Loss: 0.3234
	--> Epoch [15/100], Loss: 0.2405, Validation Loss: 0.3474
	--> Epoch [16/100], Loss: 0.2954, Validation Loss: 0.3591
	--> Epoch [17/100], Loss: 0.2412, Validation Loss: 0.3414
Early stopping
	--> Training for Fold 4 took 0.062253475189208984 sec, using 17 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7398, Validation Loss: 0.6338
	--> Epoch [2/100], Loss: 0.5830, Validation Loss: 0.5869
	--> Epoch [3/100], Loss: 0.5324, Validation Loss: 0.5699
	--> Epoch [4/100], Loss: 0.5240, Validation Loss: 0.5548
	--> Epoch [5/100], Loss: 0.4596, Validation Loss: 0.5198
	--> Epoch [6/100], Loss: 0.4380, Validation Loss: 0.5016
	--> Epoch [7/100], Loss: 0.3985, Validation Loss: 0.5042
	--> Epoch [8/100], Loss: 0.3126, Validation Loss: 0.4890
	--> Epoch [9/100], Loss: 0.3352, Validation Loss: 0.4836
	--> Epoch [10/100], Loss: 0.3483, Validation Loss: 0.4776
	--> Epoch [11/100], Loss: 0.2897, Validation Loss: 0.4850
	--> Epoch [12/100], Loss: 0.2810, Validation Loss: 0.4780
	--> Epoch [13/100], Loss: 0.2626, Validation Loss: 0.4520
	--> Epoch [14/100], Loss: 0.2655, Validation Loss: 0.4486
	--> Epoch [15/100], Loss: 0.2317, Validation Loss: 0.4587
	--> Epoch [16/100], Loss: 0.2774, Validation Loss: 0.4251
	--> Epoch [17/100], Loss: 0.2533, Validation Loss: 0.4356
	--> Epoch [18/100], Loss: 0.2949, Validation Loss: 0.4191
	--> Epoch [19/100], Loss: 0.2423, Validation Loss: 0.4200
	--> Epoch [20/100], Loss: 0.2177, Validation Loss: 0.4173
	--> Epoch [21/100], Loss: 0.2559, Validation Loss: 0.4087
	--> Epoch [22/100], Loss: 0.2250, Validation Loss: 0.4171
	--> Epoch [23/100], Loss: 0.2353, Validation Loss: 0.4126
	--> Epoch [24/100], Loss: 0.1976, Validation Loss: 0.4134
Early stopping
	--> Training for Fold 5 took 0.08951663970947266 sec, using 24 epochs

Median number of epochs used: 24 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/24], Loss: 0.7869
	--> Final training Epoch [2/24], Loss: 0.6683
	--> Final training Epoch [3/24], Loss: 0.5689
	--> Final training Epoch [4/24], Loss: 0.5390
	--> Final training Epoch [5/24], Loss: 0.4737
	--> Final training Epoch [6/24], Loss: 0.4665
	--> Final training Epoch [7/24], Loss: 0.4365
	--> Final training Epoch [8/24], Loss: 0.3584
	--> Final training Epoch [9/24], Loss: 0.3447
	--> Final training Epoch [10/24], Loss: 0.3692
	--> Final training Epoch [11/24], Loss: 0.3688
	--> Final training Epoch [12/24], Loss: 0.3326
	--> Final training Epoch [13/24], Loss: 0.2932
	--> Final training Epoch [14/24], Loss: 0.2263
	--> Final training Epoch [15/24], Loss: 0.3194
	--> Final training Epoch [16/24], Loss: 0.2431
	--> Final training Epoch [17/24], Loss: 0.2634
	--> Final training Epoch [18/24], Loss: 0.2148
	--> Final training Epoch [19/24], Loss: 0.2463
	--> Final training Epoch [20/24], Loss: 0.2461
	--> Final training Epoch [21/24], Loss: 0.1864
	--> Final training Epoch [22/24], Loss: 0.2342
	--> Final training Epoch [23/24], Loss: 0.2689
	--> Final training Epoch [24/24], Loss: 0.2273

Final training took 0.07715582847595215 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9361
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3528,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3528
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8480, Validation Loss: 0.3593,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3528
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3573,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3528

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7567, Validation Loss: 0.5691
	--> Epoch [2/100], Loss: 0.5759, Validation Loss: 0.4839
	--> Epoch [3/100], Loss: 0.4541, Validation Loss: 0.4170
	--> Epoch [4/100], Loss: 0.4156, Validation Loss: 0.3709
	--> Epoch [5/100], Loss: 0.3410, Validation Loss: 0.3443
	--> Epoch [6/100], Loss: 0.2831, Validation Loss: 0.3146
	--> Epoch [7/100], Loss: 0.2549, Validation Loss: 0.3058
	--> Epoch [8/100], Loss: 0.2036, Validation Loss: 0.2881
	--> Epoch [9/100], Loss: 0.1805, Validation Loss: 0.2753
	--> Epoch [10/100], Loss: 0.1573, Validation Loss: 0.2623
	--> Epoch [11/100], Loss: 0.1417, Validation Loss: 0.2662
	--> Epoch [12/100], Loss: 0.0990, Validation Loss: 0.2565
	--> Epoch [13/100], Loss: 0.1059, Validation Loss: 0.2499
	--> Epoch [14/100], Loss: 0.0688, Validation Loss: 0.2467
	--> Epoch [15/100], Loss: 0.0558, Validation Loss: 0.2416
	--> Epoch [16/100], Loss: 0.0641, Validation Loss: 0.2409
	--> Epoch [17/100], Loss: 0.0407, Validation Loss: 0.2402
	--> Epoch [18/100], Loss: 0.0418, Validation Loss: 0.2353
	--> Epoch [19/100], Loss: 0.0533, Validation Loss: 0.2477
	--> Epoch [20/100], Loss: 0.0759, Validation Loss: 0.2640
	--> Epoch [21/100], Loss: 0.0809, Validation Loss: 0.2579
Early stopping
	--> Training for Fold 1 took 0.08023190498352051 sec, using 21 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6889, Validation Loss: 0.5160
	--> Epoch [2/100], Loss: 0.5672, Validation Loss: 0.4262
	--> Epoch [3/100], Loss: 0.4574, Validation Loss: 0.3749
	--> Epoch [4/100], Loss: 0.3843, Validation Loss: 0.3338
	--> Epoch [5/100], Loss: 0.2961, Validation Loss: 0.3141
	--> Epoch [6/100], Loss: 0.2822, Validation Loss: 0.2954
	--> Epoch [7/100], Loss: 0.2207, Validation Loss: 0.2754
	--> Epoch [8/100], Loss: 0.1659, Validation Loss: 0.2542
	--> Epoch [9/100], Loss: 0.1366, Validation Loss: 0.2353
	--> Epoch [10/100], Loss: 0.1293, Validation Loss: 0.2549
	--> Epoch [11/100], Loss: 0.1068, Validation Loss: 0.2335
	--> Epoch [12/100], Loss: 0.1474, Validation Loss: 0.2402
	--> Epoch [13/100], Loss: 0.1210, Validation Loss: 0.2305
	--> Epoch [14/100], Loss: 0.0900, Validation Loss: 0.2169
	--> Epoch [15/100], Loss: 0.0788, Validation Loss: 0.2193
	--> Epoch [16/100], Loss: 0.0349, Validation Loss: 0.2062
	--> Epoch [17/100], Loss: 0.0926, Validation Loss: 0.2145
	--> Epoch [18/100], Loss: 0.0396, Validation Loss: 0.2088
	--> Epoch [19/100], Loss: 0.0453, Validation Loss: 0.2134
Early stopping
	--> Training for Fold 2 took 0.06729626655578613 sec, using 19 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7544, Validation Loss: 0.5953
	--> Epoch [2/100], Loss: 0.5478, Validation Loss: 0.5310
	--> Epoch [3/100], Loss: 0.4458, Validation Loss: 0.4932
	--> Epoch [4/100], Loss: 0.3918, Validation Loss: 0.4583
	--> Epoch [5/100], Loss: 0.3135, Validation Loss: 0.4316
	--> Epoch [6/100], Loss: 0.2512, Validation Loss: 0.4126
	--> Epoch [7/100], Loss: 0.2095, Validation Loss: 0.3753
	--> Epoch [8/100], Loss: 0.1621, Validation Loss: 0.3527
	--> Epoch [9/100], Loss: 0.1425, Validation Loss: 0.3385
	--> Epoch [10/100], Loss: 0.1165, Validation Loss: 0.3241
	--> Epoch [11/100], Loss: 0.1064, Validation Loss: 0.3156
	--> Epoch [12/100], Loss: 0.1171, Validation Loss: 0.3009
	--> Epoch [13/100], Loss: 0.1076, Validation Loss: 0.2998
	--> Epoch [14/100], Loss: 0.0924, Validation Loss: 0.2970
	--> Epoch [15/100], Loss: 0.0711, Validation Loss: 0.2934
	--> Epoch [16/100], Loss: 0.0691, Validation Loss: 0.2917
	--> Epoch [17/100], Loss: 0.0591, Validation Loss: 0.2819
	--> Epoch [18/100], Loss: 0.0771, Validation Loss: 0.2879
	--> Epoch [19/100], Loss: 0.0540, Validation Loss: 0.2733
	--> Epoch [20/100], Loss: 0.0535, Validation Loss: 0.2711
	--> Epoch [21/100], Loss: 0.0348, Validation Loss: 0.2675
	--> Epoch [22/100], Loss: 0.0707, Validation Loss: 0.2743
	--> Epoch [23/100], Loss: 0.0346, Validation Loss: 0.2593
	--> Epoch [24/100], Loss: 0.0565, Validation Loss: 0.2494
	--> Epoch [25/100], Loss: 0.0475, Validation Loss: 0.2510
	--> Epoch [26/100], Loss: 0.0339, Validation Loss: 0.2569
	--> Epoch [27/100], Loss: 0.0300, Validation Loss: 0.2576
Early stopping
	--> Training for Fold 3 took 0.10253095626831055 sec, using 27 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7457, Validation Loss: 0.4956
	--> Epoch [2/100], Loss: 0.5787, Validation Loss: 0.4645
	--> Epoch [3/100], Loss: 0.4698, Validation Loss: 0.4248
	--> Epoch [4/100], Loss: 0.4418, Validation Loss: 0.4037
	--> Epoch [5/100], Loss: 0.3884, Validation Loss: 0.3585
	--> Epoch [6/100], Loss: 0.3099, Validation Loss: 0.3686
	--> Epoch [7/100], Loss: 0.2826, Validation Loss: 0.3402
	--> Epoch [8/100], Loss: 0.2603, Validation Loss: 0.3209
	--> Epoch [9/100], Loss: 0.2350, Validation Loss: 0.3157
	--> Epoch [10/100], Loss: 0.2180, Validation Loss: 0.3170
	--> Epoch [11/100], Loss: 0.1980, Validation Loss: 0.3105
	--> Epoch [12/100], Loss: 0.1856, Validation Loss: 0.3000
	--> Epoch [13/100], Loss: 0.1922, Validation Loss: 0.2978
	--> Epoch [14/100], Loss: 0.1660, Validation Loss: 0.2897
	--> Epoch [15/100], Loss: 0.2177, Validation Loss: 0.3041
	--> Epoch [16/100], Loss: 0.1517, Validation Loss: 0.2925
	--> Epoch [17/100], Loss: 0.1773, Validation Loss: 0.3144
Early stopping
	--> Training for Fold 4 took 0.06562304496765137 sec, using 17 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7397, Validation Loss: 0.5818
	--> Epoch [2/100], Loss: 0.5683, Validation Loss: 0.5577
	--> Epoch [3/100], Loss: 0.4453, Validation Loss: 0.5404
	--> Epoch [4/100], Loss: 0.3486, Validation Loss: 0.5279
	--> Epoch [5/100], Loss: 0.3030, Validation Loss: 0.5058
	--> Epoch [6/100], Loss: 0.2616, Validation Loss: 0.4903
	--> Epoch [7/100], Loss: 0.2251, Validation Loss: 0.4906
	--> Epoch [8/100], Loss: 0.2066, Validation Loss: 0.5035
	--> Epoch [9/100], Loss: 0.1676, Validation Loss: 0.4883
	--> Epoch [10/100], Loss: 0.1402, Validation Loss: 0.4826
	--> Epoch [11/100], Loss: 0.0928, Validation Loss: 0.4922
	--> Epoch [12/100], Loss: 0.0928, Validation Loss: 0.5182
	--> Epoch [13/100], Loss: 0.1074, Validation Loss: 0.5248
Early stopping
	--> Training for Fold 5 took 0.05086636543273926 sec, using 13 epochs

Median number of epochs used: 19 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/19], Loss: 0.6700
	--> Final training Epoch [2/19], Loss: 0.5121
	--> Final training Epoch [3/19], Loss: 0.4043
	--> Final training Epoch [4/19], Loss: 0.3256
	--> Final training Epoch [5/19], Loss: 0.2813
	--> Final training Epoch [6/19], Loss: 0.2479
	--> Final training Epoch [7/19], Loss: 0.2180
	--> Final training Epoch [8/19], Loss: 0.1939
	--> Final training Epoch [9/19], Loss: 0.1849
	--> Final training Epoch [10/19], Loss: 0.1454
	--> Final training Epoch [11/19], Loss: 0.1153
	--> Final training Epoch [12/19], Loss: 0.1494
	--> Final training Epoch [13/19], Loss: 0.1255
	--> Final training Epoch [14/19], Loss: 0.1014
	--> Final training Epoch [15/19], Loss: 0.0804
	--> Final training Epoch [16/19], Loss: 0.0967
	--> Final training Epoch [17/19], Loss: 0.1004
	--> Final training Epoch [18/19], Loss: 0.0717
	--> Final training Epoch [19/19], Loss: 0.0791

Final training took 0.07432055473327637 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0571
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3468,  Current Best Accuracy: 0.8275,  Current Best Validation Loss: 0.3468

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7227, Validation Loss: 0.5140
	--> Epoch [2/100], Loss: 0.5712, Validation Loss: 0.4573
	--> Epoch [3/100], Loss: 0.4641, Validation Loss: 0.3983
	--> Epoch [4/100], Loss: 0.3644, Validation Loss: 0.3707
	--> Epoch [5/100], Loss: 0.3326, Validation Loss: 0.3432
	--> Epoch [6/100], Loss: 0.2668, Validation Loss: 0.3025
	--> Epoch [7/100], Loss: 0.2001, Validation Loss: 0.2867
	--> Epoch [8/100], Loss: 0.1663, Validation Loss: 0.2726
	--> Epoch [9/100], Loss: 0.2012, Validation Loss: 0.2600
	--> Epoch [10/100], Loss: 0.1471, Validation Loss: 0.2543
	--> Epoch [11/100], Loss: 0.1394, Validation Loss: 0.2367
	--> Epoch [12/100], Loss: 0.1061, Validation Loss: 0.2330
	--> Epoch [13/100], Loss: 0.0974, Validation Loss: 0.2340
	--> Epoch [14/100], Loss: 0.0899, Validation Loss: 0.2253
	--> Epoch [15/100], Loss: 0.0673, Validation Loss: 0.2127
	--> Epoch [16/100], Loss: 0.0859, Validation Loss: 0.2173
	--> Epoch [17/100], Loss: 0.0756, Validation Loss: 0.2204
	--> Epoch [18/100], Loss: 0.0691, Validation Loss: 0.2255
Early stopping
	--> Training for Fold 1 took 0.07355117797851562 sec, using 18 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7512, Validation Loss: 0.5284
	--> Epoch [2/100], Loss: 0.5848, Validation Loss: 0.4363
	--> Epoch [3/100], Loss: 0.4993, Validation Loss: 0.3782
	--> Epoch [4/100], Loss: 0.3885, Validation Loss: 0.3328
	--> Epoch [5/100], Loss: 0.2980, Validation Loss: 0.3001
	--> Epoch [6/100], Loss: 0.2522, Validation Loss: 0.2829
	--> Epoch [7/100], Loss: 0.2014, Validation Loss: 0.2533
	--> Epoch [8/100], Loss: 0.1846, Validation Loss: 0.2368
	--> Epoch [9/100], Loss: 0.1774, Validation Loss: 0.2380
	--> Epoch [10/100], Loss: 0.1661, Validation Loss: 0.2471
	--> Epoch [11/100], Loss: 0.1165, Validation Loss: 0.2294
	--> Epoch [12/100], Loss: 0.0908, Validation Loss: 0.2157
	--> Epoch [13/100], Loss: 0.1381, Validation Loss: 0.2174
	--> Epoch [14/100], Loss: 0.1083, Validation Loss: 0.2150
	--> Epoch [15/100], Loss: 0.0933, Validation Loss: 0.2120
	--> Epoch [16/100], Loss: 0.0873, Validation Loss: 0.2138
	--> Epoch [17/100], Loss: 0.0712, Validation Loss: 0.1974
	--> Epoch [18/100], Loss: 0.0754, Validation Loss: 0.2052
	--> Epoch [19/100], Loss: 0.0755, Validation Loss: 0.2044
	--> Epoch [20/100], Loss: 0.0803, Validation Loss: 0.1988
Early stopping
	--> Training for Fold 2 took 0.07796239852905273 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7115, Validation Loss: 0.6051
	--> Epoch [2/100], Loss: 0.5055, Validation Loss: 0.5276
	--> Epoch [3/100], Loss: 0.4171, Validation Loss: 0.4712
	--> Epoch [4/100], Loss: 0.2930, Validation Loss: 0.4340
	--> Epoch [5/100], Loss: 0.2733, Validation Loss: 0.3934
	--> Epoch [6/100], Loss: 0.2059, Validation Loss: 0.3731
	--> Epoch [7/100], Loss: 0.1863, Validation Loss: 0.3558
	--> Epoch [8/100], Loss: 0.1673, Validation Loss: 0.3336
	--> Epoch [9/100], Loss: 0.1325, Validation Loss: 0.3273
	--> Epoch [10/100], Loss: 0.1678, Validation Loss: 0.3186
	--> Epoch [11/100], Loss: 0.1015, Validation Loss: 0.3075
	--> Epoch [12/100], Loss: 0.1043, Validation Loss: 0.2781
	--> Epoch [13/100], Loss: 0.1023, Validation Loss: 0.2768
	--> Epoch [14/100], Loss: 0.0693, Validation Loss: 0.2798
	--> Epoch [15/100], Loss: 0.0833, Validation Loss: 0.2687
	--> Epoch [16/100], Loss: 0.0455, Validation Loss: 0.2686
	--> Epoch [17/100], Loss: 0.0545, Validation Loss: 0.2716
	--> Epoch [18/100], Loss: 0.0490, Validation Loss: 0.2606
	--> Epoch [19/100], Loss: 0.0643, Validation Loss: 0.2569
	--> Epoch [20/100], Loss: 0.0473, Validation Loss: 0.2713
	--> Epoch [21/100], Loss: 0.0513, Validation Loss: 0.2696
	--> Epoch [22/100], Loss: 0.0368, Validation Loss: 0.2668
Early stopping
	--> Training for Fold 3 took 0.0857698917388916 sec, using 22 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7146, Validation Loss: 0.5382
	--> Epoch [2/100], Loss: 0.5575, Validation Loss: 0.4945
	--> Epoch [3/100], Loss: 0.4724, Validation Loss: 0.4503
	--> Epoch [4/100], Loss: 0.4143, Validation Loss: 0.4007
	--> Epoch [5/100], Loss: 0.3265, Validation Loss: 0.3716
	--> Epoch [6/100], Loss: 0.3102, Validation Loss: 0.3590
	--> Epoch [7/100], Loss: 0.2698, Validation Loss: 0.3203
	--> Epoch [8/100], Loss: 0.2275, Validation Loss: 0.3215
	--> Epoch [9/100], Loss: 0.1702, Validation Loss: 0.3196
	--> Epoch [10/100], Loss: 0.2146, Validation Loss: 0.2966
	--> Epoch [11/100], Loss: 0.1528, Validation Loss: 0.2946
	--> Epoch [12/100], Loss: 0.1197, Validation Loss: 0.2883
	--> Epoch [13/100], Loss: 0.1413, Validation Loss: 0.2882
	--> Epoch [14/100], Loss: 0.1399, Validation Loss: 0.2920
	--> Epoch [15/100], Loss: 0.1365, Validation Loss: 0.2938
	--> Epoch [16/100], Loss: 0.1055, Validation Loss: 0.2983
Early stopping
	--> Training for Fold 4 took 0.06057548522949219 sec, using 16 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6680, Validation Loss: 0.7020
	--> Epoch [2/100], Loss: 0.5403, Validation Loss: 0.6638
	--> Epoch [3/100], Loss: 0.4524, Validation Loss: 0.6547
	--> Epoch [4/100], Loss: 0.3698, Validation Loss: 0.6153
	--> Epoch [5/100], Loss: 0.2841, Validation Loss: 0.5783
	--> Epoch [6/100], Loss: 0.2678, Validation Loss: 0.5667
	--> Epoch [7/100], Loss: 0.2035, Validation Loss: 0.5700
	--> Epoch [8/100], Loss: 0.1792, Validation Loss: 0.5552
	--> Epoch [9/100], Loss: 0.1959, Validation Loss: 0.5440
	--> Epoch [10/100], Loss: 0.1723, Validation Loss: 0.5484
	--> Epoch [11/100], Loss: 0.1924, Validation Loss: 0.5297
	--> Epoch [12/100], Loss: 0.1501, Validation Loss: 0.5467
	--> Epoch [13/100], Loss: 0.1603, Validation Loss: 0.5593
	--> Epoch [14/100], Loss: 0.1321, Validation Loss: 0.5502
Early stopping
	--> Training for Fold 5 took 0.05195760726928711 sec, using 14 epochs

Median number of epochs used: 18 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/18], Loss: 0.7433
	--> Final training Epoch [2/18], Loss: 0.5281
	--> Final training Epoch [3/18], Loss: 0.4072
	--> Final training Epoch [4/18], Loss: 0.3715
	--> Final training Epoch [5/18], Loss: 0.3167
	--> Final training Epoch [6/18], Loss: 0.2696
	--> Final training Epoch [7/18], Loss: 0.2061
	--> Final training Epoch [8/18], Loss: 0.2053
	--> Final training Epoch [9/18], Loss: 0.1593
	--> Final training Epoch [10/18], Loss: 0.1467
	--> Final training Epoch [11/18], Loss: 0.1294
	--> Final training Epoch [12/18], Loss: 0.1142
	--> Final training Epoch [13/18], Loss: 0.1138
	--> Final training Epoch [14/18], Loss: 0.0853
	--> Final training Epoch [15/18], Loss: 0.0963
	--> Final training Epoch [16/18], Loss: 0.0978
	--> Final training Epoch [17/18], Loss: 0.0691
	--> Final training Epoch [18/18], Loss: 0.0564

Final training took 0.062293052673339844 sec

TESTING
	--> Testing took 0.0080 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0823
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3383,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3383

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8232, Validation Loss: 0.5443
	--> Epoch [2/100], Loss: 0.6277, Validation Loss: 0.4701
	--> Epoch [3/100], Loss: 0.5300, Validation Loss: 0.4147
	--> Epoch [4/100], Loss: 0.4305, Validation Loss: 0.3803
	--> Epoch [5/100], Loss: 0.3766, Validation Loss: 0.3537
	--> Epoch [6/100], Loss: 0.3579, Validation Loss: 0.3146
	--> Epoch [7/100], Loss: 0.2955, Validation Loss: 0.2967
	--> Epoch [8/100], Loss: 0.2425, Validation Loss: 0.2757
	--> Epoch [9/100], Loss: 0.2776, Validation Loss: 0.2776
	--> Epoch [10/100], Loss: 0.1904, Validation Loss: 0.2700
	--> Epoch [11/100], Loss: 0.1985, Validation Loss: 0.2503
	--> Epoch [12/100], Loss: 0.1723, Validation Loss: 0.2384
	--> Epoch [13/100], Loss: 0.1538, Validation Loss: 0.2409
	--> Epoch [14/100], Loss: 0.1484, Validation Loss: 0.2458
	--> Epoch [15/100], Loss: 0.1539, Validation Loss: 0.2528
Early stopping
	--> Training for Fold 1 took 0.05300450325012207 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6931, Validation Loss: 0.5786
	--> Epoch [2/100], Loss: 0.6038, Validation Loss: 0.5220
	--> Epoch [3/100], Loss: 0.5242, Validation Loss: 0.4716
	--> Epoch [4/100], Loss: 0.4545, Validation Loss: 0.4224
	--> Epoch [5/100], Loss: 0.4147, Validation Loss: 0.3865
	--> Epoch [6/100], Loss: 0.3925, Validation Loss: 0.3596
	--> Epoch [7/100], Loss: 0.3409, Validation Loss: 0.3223
	--> Epoch [8/100], Loss: 0.3487, Validation Loss: 0.3044
	--> Epoch [9/100], Loss: 0.2821, Validation Loss: 0.2893
	--> Epoch [10/100], Loss: 0.2495, Validation Loss: 0.2826
	--> Epoch [11/100], Loss: 0.2528, Validation Loss: 0.2742
	--> Epoch [12/100], Loss: 0.1983, Validation Loss: 0.2730
	--> Epoch [13/100], Loss: 0.2186, Validation Loss: 0.2653
	--> Epoch [14/100], Loss: 0.2071, Validation Loss: 0.2562
	--> Epoch [15/100], Loss: 0.2008, Validation Loss: 0.2588
	--> Epoch [16/100], Loss: 0.1965, Validation Loss: 0.2414
	--> Epoch [17/100], Loss: 0.1714, Validation Loss: 0.2366
	--> Epoch [18/100], Loss: 0.1736, Validation Loss: 0.2425
	--> Epoch [19/100], Loss: 0.1381, Validation Loss: 0.2525
	--> Epoch [20/100], Loss: 0.1352, Validation Loss: 0.2442
Early stopping
	--> Training for Fold 2 took 0.06989073753356934 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6852, Validation Loss: 0.6581
	--> Epoch [2/100], Loss: 0.5792, Validation Loss: 0.5826
	--> Epoch [3/100], Loss: 0.4625, Validation Loss: 0.5160
	--> Epoch [4/100], Loss: 0.3714, Validation Loss: 0.4669
	--> Epoch [5/100], Loss: 0.3209, Validation Loss: 0.4366
	--> Epoch [6/100], Loss: 0.2894, Validation Loss: 0.4078
	--> Epoch [7/100], Loss: 0.2388, Validation Loss: 0.3854
	--> Epoch [8/100], Loss: 0.1829, Validation Loss: 0.3699
	--> Epoch [9/100], Loss: 0.1819, Validation Loss: 0.3478
	--> Epoch [10/100], Loss: 0.1679, Validation Loss: 0.3487
	--> Epoch [11/100], Loss: 0.1477, Validation Loss: 0.3213
	--> Epoch [12/100], Loss: 0.0912, Validation Loss: 0.3139
	--> Epoch [13/100], Loss: 0.1160, Validation Loss: 0.3110
	--> Epoch [14/100], Loss: 0.0992, Validation Loss: 0.3099
	--> Epoch [15/100], Loss: 0.0789, Validation Loss: 0.3048
	--> Epoch [16/100], Loss: 0.0998, Validation Loss: 0.2949
	--> Epoch [17/100], Loss: 0.0953, Validation Loss: 0.2943
	--> Epoch [18/100], Loss: 0.0494, Validation Loss: 0.2826
	--> Epoch [19/100], Loss: 0.0636, Validation Loss: 0.2803
	--> Epoch [20/100], Loss: 0.0676, Validation Loss: 0.2779
	--> Epoch [21/100], Loss: 0.0498, Validation Loss: 0.2731
	--> Epoch [22/100], Loss: 0.0680, Validation Loss: 0.2661
	--> Epoch [23/100], Loss: 0.0750, Validation Loss: 0.2752
	--> Epoch [24/100], Loss: 0.0477, Validation Loss: 0.2845
	--> Epoch [25/100], Loss: 0.0459, Validation Loss: 0.2906
Early stopping
	--> Training for Fold 3 took 0.0953817367553711 sec, using 25 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7095, Validation Loss: 0.6979
	--> Epoch [2/100], Loss: 0.5356, Validation Loss: 0.6267
	--> Epoch [3/100], Loss: 0.4781, Validation Loss: 0.5974
	--> Epoch [4/100], Loss: 0.3983, Validation Loss: 0.5129
	--> Epoch [5/100], Loss: 0.3351, Validation Loss: 0.4668
	--> Epoch [6/100], Loss: 0.2665, Validation Loss: 0.4288
	--> Epoch [7/100], Loss: 0.2536, Validation Loss: 0.4114
	--> Epoch [8/100], Loss: 0.1961, Validation Loss: 0.3806
	--> Epoch [9/100], Loss: 0.1952, Validation Loss: 0.3759
	--> Epoch [10/100], Loss: 0.1138, Validation Loss: 0.3620
	--> Epoch [11/100], Loss: 0.1262, Validation Loss: 0.3506
	--> Epoch [12/100], Loss: 0.1014, Validation Loss: 0.3653
	--> Epoch [13/100], Loss: 0.0740, Validation Loss: 0.3537
	--> Epoch [14/100], Loss: 0.0816, Validation Loss: 0.3223
	--> Epoch [15/100], Loss: 0.1047, Validation Loss: 0.3180
	--> Epoch [16/100], Loss: 0.0627, Validation Loss: 0.3182
	--> Epoch [17/100], Loss: 0.0664, Validation Loss: 0.3095
	--> Epoch [18/100], Loss: 0.0952, Validation Loss: 0.3175
	--> Epoch [19/100], Loss: 0.1135, Validation Loss: 0.3126
	--> Epoch [20/100], Loss: 0.0868, Validation Loss: 0.3171
Early stopping
	--> Training for Fold 4 took 0.07519364356994629 sec, using 20 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6828, Validation Loss: 0.6409
	--> Epoch [2/100], Loss: 0.5646, Validation Loss: 0.5832
	--> Epoch [3/100], Loss: 0.4783, Validation Loss: 0.5392
	--> Epoch [4/100], Loss: 0.4249, Validation Loss: 0.5034
	--> Epoch [5/100], Loss: 0.3673, Validation Loss: 0.4792
	--> Epoch [6/100], Loss: 0.3044, Validation Loss: 0.4733
	--> Epoch [7/100], Loss: 0.3005, Validation Loss: 0.4625
	--> Epoch [8/100], Loss: 0.2507, Validation Loss: 0.4495
	--> Epoch [9/100], Loss: 0.2167, Validation Loss: 0.4369
	--> Epoch [10/100], Loss: 0.1973, Validation Loss: 0.4272
	--> Epoch [11/100], Loss: 0.2424, Validation Loss: 0.4265
	--> Epoch [12/100], Loss: 0.2043, Validation Loss: 0.4096
	--> Epoch [13/100], Loss: 0.1351, Validation Loss: 0.4093
	--> Epoch [14/100], Loss: 0.1988, Validation Loss: 0.4208
	--> Epoch [15/100], Loss: 0.1464, Validation Loss: 0.4214
	--> Epoch [16/100], Loss: 0.1731, Validation Loss: 0.4133
Early stopping
	--> Training for Fold 5 took 0.05830526351928711 sec, using 16 epochs

Median number of epochs used: 20 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/20], Loss: 0.6914
	--> Final training Epoch [2/20], Loss: 0.5800
	--> Final training Epoch [3/20], Loss: 0.4842
	--> Final training Epoch [4/20], Loss: 0.3956
	--> Final training Epoch [5/20], Loss: 0.3219
	--> Final training Epoch [6/20], Loss: 0.2721
	--> Final training Epoch [7/20], Loss: 0.2360
	--> Final training Epoch [8/20], Loss: 0.1907
	--> Final training Epoch [9/20], Loss: 0.1492
	--> Final training Epoch [10/20], Loss: 0.1342
	--> Final training Epoch [11/20], Loss: 0.1153
	--> Final training Epoch [12/20], Loss: 0.1348
	--> Final training Epoch [13/20], Loss: 0.1187
	--> Final training Epoch [14/20], Loss: 0.1071
	--> Final training Epoch [15/20], Loss: 0.0962
	--> Final training Epoch [16/20], Loss: 0.0842
	--> Final training Epoch [17/20], Loss: 0.0713
	--> Final training Epoch [18/20], Loss: 0.0739
	--> Final training Epoch [19/20], Loss: 0.0656
	--> Final training Epoch [20/20], Loss: 0.0576

Final training took 0.06766080856323242 sec

TESTING
	--> Testing took 0.0089 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 1.2222
	--> Final Precision: 0.6154
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6154
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8608, Validation Loss: 0.3166,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3166
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3293,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3166
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 0.3970,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3166

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6683, Validation Loss: 0.5920
	--> Epoch [2/100], Loss: 0.5515, Validation Loss: 0.5487
	--> Epoch [3/100], Loss: 0.4916, Validation Loss: 0.5107
	--> Epoch [4/100], Loss: 0.4124, Validation Loss: 0.4621
	--> Epoch [5/100], Loss: 0.3629, Validation Loss: 0.4192
	--> Epoch [6/100], Loss: 0.3199, Validation Loss: 0.4083
	--> Epoch [7/100], Loss: 0.2614, Validation Loss: 0.3940
	--> Epoch [8/100], Loss: 0.2374, Validation Loss: 0.3831
	--> Epoch [9/100], Loss: 0.2337, Validation Loss: 0.3778
	--> Epoch [10/100], Loss: 0.1821, Validation Loss: 0.3464
	--> Epoch [11/100], Loss: 0.1966, Validation Loss: 0.3434
	--> Epoch [12/100], Loss: 0.1293, Validation Loss: 0.3248
	--> Epoch [13/100], Loss: 0.1276, Validation Loss: 0.3388
	--> Epoch [14/100], Loss: 0.1831, Validation Loss: 0.3413
	--> Epoch [15/100], Loss: 0.2164, Validation Loss: 0.3402
Early stopping
	--> Training for Fold 1 took 0.05317258834838867 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7189, Validation Loss: 0.5867
	--> Epoch [2/100], Loss: 0.6131, Validation Loss: 0.4872
	--> Epoch [3/100], Loss: 0.5398, Validation Loss: 0.4241
	--> Epoch [4/100], Loss: 0.4639, Validation Loss: 0.3798
	--> Epoch [5/100], Loss: 0.3895, Validation Loss: 0.3487
	--> Epoch [6/100], Loss: 0.3693, Validation Loss: 0.3372
	--> Epoch [7/100], Loss: 0.2912, Validation Loss: 0.3310
	--> Epoch [8/100], Loss: 0.2658, Validation Loss: 0.2974
	--> Epoch [9/100], Loss: 0.1870, Validation Loss: 0.2873
	--> Epoch [10/100], Loss: 0.1984, Validation Loss: 0.2782
	--> Epoch [11/100], Loss: 0.2085, Validation Loss: 0.2699
	--> Epoch [12/100], Loss: 0.1833, Validation Loss: 0.2627
	--> Epoch [13/100], Loss: 0.1888, Validation Loss: 0.2581
	--> Epoch [14/100], Loss: 0.1591, Validation Loss: 0.2504
	--> Epoch [15/100], Loss: 0.1634, Validation Loss: 0.2347
	--> Epoch [16/100], Loss: 0.0956, Validation Loss: 0.2387
	--> Epoch [17/100], Loss: 0.1253, Validation Loss: 0.2329
	--> Epoch [18/100], Loss: 0.1422, Validation Loss: 0.2377
	--> Epoch [19/100], Loss: 0.1554, Validation Loss: 0.2517
	--> Epoch [20/100], Loss: 0.1245, Validation Loss: 0.2533
Early stopping
	--> Training for Fold 2 took 0.06882023811340332 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7338, Validation Loss: 0.6108
	--> Epoch [2/100], Loss: 0.6137, Validation Loss: 0.5581
	--> Epoch [3/100], Loss: 0.5345, Validation Loss: 0.5149
	--> Epoch [4/100], Loss: 0.4570, Validation Loss: 0.4874
	--> Epoch [5/100], Loss: 0.4102, Validation Loss: 0.4517
	--> Epoch [6/100], Loss: 0.3864, Validation Loss: 0.4144
	--> Epoch [7/100], Loss: 0.2769, Validation Loss: 0.3944
	--> Epoch [8/100], Loss: 0.2903, Validation Loss: 0.3734
	--> Epoch [9/100], Loss: 0.2460, Validation Loss: 0.3594
	--> Epoch [10/100], Loss: 0.2038, Validation Loss: 0.3543
	--> Epoch [11/100], Loss: 0.2177, Validation Loss: 0.3569
	--> Epoch [12/100], Loss: 0.1896, Validation Loss: 0.3416
	--> Epoch [13/100], Loss: 0.2071, Validation Loss: 0.3365
	--> Epoch [14/100], Loss: 0.1933, Validation Loss: 0.3218
	--> Epoch [15/100], Loss: 0.1158, Validation Loss: 0.3060
	--> Epoch [16/100], Loss: 0.1497, Validation Loss: 0.3036
	--> Epoch [17/100], Loss: 0.1589, Validation Loss: 0.3002
	--> Epoch [18/100], Loss: 0.1320, Validation Loss: 0.2993
	--> Epoch [19/100], Loss: 0.1191, Validation Loss: 0.2846
	--> Epoch [20/100], Loss: 0.1168, Validation Loss: 0.2765
	--> Epoch [21/100], Loss: 0.1796, Validation Loss: 0.2779
	--> Epoch [22/100], Loss: 0.1618, Validation Loss: 0.2622
	--> Epoch [23/100], Loss: 0.0814, Validation Loss: 0.2652
	--> Epoch [24/100], Loss: 0.1379, Validation Loss: 0.2648
	--> Epoch [25/100], Loss: 0.0989, Validation Loss: 0.2692
Early stopping
	--> Training for Fold 3 took 0.09320878982543945 sec, using 25 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7340, Validation Loss: 0.5255
	--> Epoch [2/100], Loss: 0.5715, Validation Loss: 0.4807
	--> Epoch [3/100], Loss: 0.4965, Validation Loss: 0.4377
	--> Epoch [4/100], Loss: 0.4411, Validation Loss: 0.3845
	--> Epoch [5/100], Loss: 0.3591, Validation Loss: 0.3632
	--> Epoch [6/100], Loss: 0.3257, Validation Loss: 0.3413
	--> Epoch [7/100], Loss: 0.3052, Validation Loss: 0.3345
	--> Epoch [8/100], Loss: 0.2596, Validation Loss: 0.3259
	--> Epoch [9/100], Loss: 0.2533, Validation Loss: 0.3188
	--> Epoch [10/100], Loss: 0.2065, Validation Loss: 0.3236
	--> Epoch [11/100], Loss: 0.2078, Validation Loss: 0.3097
	--> Epoch [12/100], Loss: 0.1866, Validation Loss: 0.3035
	--> Epoch [13/100], Loss: 0.2294, Validation Loss: 0.2984
	--> Epoch [14/100], Loss: 0.1474, Validation Loss: 0.3289
	--> Epoch [15/100], Loss: 0.1709, Validation Loss: 0.3250
	--> Epoch [16/100], Loss: 0.1582, Validation Loss: 0.3014
Early stopping
	--> Training for Fold 4 took 0.060976505279541016 sec, using 16 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.9053, Validation Loss: 0.5357
	--> Epoch [2/100], Loss: 0.6606, Validation Loss: 0.5244
	--> Epoch [3/100], Loss: 0.5583, Validation Loss: 0.5098
	--> Epoch [4/100], Loss: 0.4686, Validation Loss: 0.5115
	--> Epoch [5/100], Loss: 0.3729, Validation Loss: 0.5174
	--> Epoch [6/100], Loss: 0.3455, Validation Loss: 0.5241
Early stopping
	--> Training for Fold 5 took 0.023244857788085938 sec, using 6 epochs

Median number of epochs used: 16 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/16], Loss: 0.7143
	--> Final training Epoch [2/16], Loss: 0.6090
	--> Final training Epoch [3/16], Loss: 0.5326
	--> Final training Epoch [4/16], Loss: 0.4317
	--> Final training Epoch [5/16], Loss: 0.3773
	--> Final training Epoch [6/16], Loss: 0.3175
	--> Final training Epoch [7/16], Loss: 0.2894
	--> Final training Epoch [8/16], Loss: 0.2540
	--> Final training Epoch [9/16], Loss: 0.2107
	--> Final training Epoch [10/16], Loss: 0.2187
	--> Final training Epoch [11/16], Loss: 0.1943
	--> Final training Epoch [12/16], Loss: 0.1972
	--> Final training Epoch [13/16], Loss: 0.1549
	--> Final training Epoch [14/16], Loss: 0.1652
	--> Final training Epoch [15/16], Loss: 0.1695
	--> Final training Epoch [16/16], Loss: 0.1092

Final training took 0.05369377136230469 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9274
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8918, Validation Loss: 0.3316,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3518,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8591, Validation Loss: 0.3677,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3628,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3444,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.3618,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7103, Validation Loss: 0.6540
	--> Epoch [2/100], Loss: 0.6063, Validation Loss: 0.5925
	--> Epoch [3/100], Loss: 0.5010, Validation Loss: 0.5272
	--> Epoch [4/100], Loss: 0.4410, Validation Loss: 0.4762
	--> Epoch [5/100], Loss: 0.3607, Validation Loss: 0.4322
	--> Epoch [6/100], Loss: 0.3121, Validation Loss: 0.3740
	--> Epoch [7/100], Loss: 0.2676, Validation Loss: 0.3559
	--> Epoch [8/100], Loss: 0.2366, Validation Loss: 0.3202
	--> Epoch [9/100], Loss: 0.2172, Validation Loss: 0.3058
	--> Epoch [10/100], Loss: 0.1416, Validation Loss: 0.2936
	--> Epoch [11/100], Loss: 0.1618, Validation Loss: 0.2796
	--> Epoch [12/100], Loss: 0.1586, Validation Loss: 0.2704
	--> Epoch [13/100], Loss: 0.1308, Validation Loss: 0.2732
	--> Epoch [14/100], Loss: 0.1417, Validation Loss: 0.2638
	--> Epoch [15/100], Loss: 0.1062, Validation Loss: 0.2586
	--> Epoch [16/100], Loss: 0.1438, Validation Loss: 0.2560
	--> Epoch [17/100], Loss: 0.1207, Validation Loss: 0.2524
	--> Epoch [18/100], Loss: 0.0784, Validation Loss: 0.2552
	--> Epoch [19/100], Loss: 0.1018, Validation Loss: 0.2506
	--> Epoch [20/100], Loss: 0.1143, Validation Loss: 0.2553
	--> Epoch [21/100], Loss: 0.0899, Validation Loss: 0.2567
	--> Epoch [22/100], Loss: 0.0830, Validation Loss: 0.2540
Early stopping
	--> Training for Fold 1 took 0.07973718643188477 sec, using 22 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7285, Validation Loss: 0.4837
	--> Epoch [2/100], Loss: 0.5414, Validation Loss: 0.4108
	--> Epoch [3/100], Loss: 0.4268, Validation Loss: 0.3258
	--> Epoch [4/100], Loss: 0.3337, Validation Loss: 0.2921
	--> Epoch [5/100], Loss: 0.2738, Validation Loss: 0.2699
	--> Epoch [6/100], Loss: 0.2256, Validation Loss: 0.2545
	--> Epoch [7/100], Loss: 0.1974, Validation Loss: 0.2419
	--> Epoch [8/100], Loss: 0.1617, Validation Loss: 0.2275
	--> Epoch [9/100], Loss: 0.1479, Validation Loss: 0.2248
	--> Epoch [10/100], Loss: 0.1250, Validation Loss: 0.2226
	--> Epoch [11/100], Loss: 0.1446, Validation Loss: 0.2158
	--> Epoch [12/100], Loss: 0.0759, Validation Loss: 0.2070
	--> Epoch [13/100], Loss: 0.0841, Validation Loss: 0.2010
	--> Epoch [14/100], Loss: 0.0743, Validation Loss: 0.1979
	--> Epoch [15/100], Loss: 0.0739, Validation Loss: 0.2002
	--> Epoch [16/100], Loss: 0.0775, Validation Loss: 0.2055
	--> Epoch [17/100], Loss: 0.0567, Validation Loss: 0.1978
	--> Epoch [18/100], Loss: 0.0514, Validation Loss: 0.2018
	--> Epoch [19/100], Loss: 0.0757, Validation Loss: 0.2106
	--> Epoch [20/100], Loss: 0.0248, Validation Loss: 0.2068
Early stopping
	--> Training for Fold 2 took 0.07395005226135254 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7033, Validation Loss: 0.5780
	--> Epoch [2/100], Loss: 0.5357, Validation Loss: 0.5328
	--> Epoch [3/100], Loss: 0.4327, Validation Loss: 0.4845
	--> Epoch [4/100], Loss: 0.3519, Validation Loss: 0.4365
	--> Epoch [5/100], Loss: 0.2988, Validation Loss: 0.4154
	--> Epoch [6/100], Loss: 0.2457, Validation Loss: 0.3852
	--> Epoch [7/100], Loss: 0.2180, Validation Loss: 0.3750
	--> Epoch [8/100], Loss: 0.1978, Validation Loss: 0.3613
	--> Epoch [9/100], Loss: 0.1337, Validation Loss: 0.3542
	--> Epoch [10/100], Loss: 0.1391, Validation Loss: 0.3479
	--> Epoch [11/100], Loss: 0.1111, Validation Loss: 0.3372
	--> Epoch [12/100], Loss: 0.0837, Validation Loss: 0.3306
	--> Epoch [13/100], Loss: 0.0653, Validation Loss: 0.3195
	--> Epoch [14/100], Loss: 0.0931, Validation Loss: 0.3223
	--> Epoch [15/100], Loss: 0.0848, Validation Loss: 0.3211
	--> Epoch [16/100], Loss: 0.0990, Validation Loss: 0.3137
	--> Epoch [17/100], Loss: 0.0602, Validation Loss: 0.3140
	--> Epoch [18/100], Loss: 0.0683, Validation Loss: 0.3190
	--> Epoch [19/100], Loss: 0.0741, Validation Loss: 0.3268
Early stopping
	--> Training for Fold 3 took 0.07423067092895508 sec, using 19 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7281, Validation Loss: 0.6568
	--> Epoch [2/100], Loss: 0.5394, Validation Loss: 0.5377
	--> Epoch [3/100], Loss: 0.4389, Validation Loss: 0.4727
	--> Epoch [4/100], Loss: 0.3455, Validation Loss: 0.4019
	--> Epoch [5/100], Loss: 0.2877, Validation Loss: 0.3693
	--> Epoch [6/100], Loss: 0.1934, Validation Loss: 0.3614
	--> Epoch [7/100], Loss: 0.1857, Validation Loss: 0.3506
	--> Epoch [8/100], Loss: 0.1445, Validation Loss: 0.3365
	--> Epoch [9/100], Loss: 0.1519, Validation Loss: 0.3165
	--> Epoch [10/100], Loss: 0.1025, Validation Loss: 0.3108
	--> Epoch [11/100], Loss: 0.0926, Validation Loss: 0.3170
	--> Epoch [12/100], Loss: 0.0915, Validation Loss: 0.3136
	--> Epoch [13/100], Loss: 0.0758, Validation Loss: 0.3161
Early stopping
	--> Training for Fold 4 took 0.04864954948425293 sec, using 13 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7490, Validation Loss: 0.8546
	--> Epoch [2/100], Loss: 0.5830, Validation Loss: 0.8192
	--> Epoch [3/100], Loss: 0.4982, Validation Loss: 0.7921
	--> Epoch [4/100], Loss: 0.4231, Validation Loss: 0.7334
	--> Epoch [5/100], Loss: 0.3391, Validation Loss: 0.7043
	--> Epoch [6/100], Loss: 0.2880, Validation Loss: 0.6682
	--> Epoch [7/100], Loss: 0.2701, Validation Loss: 0.6591
	--> Epoch [8/100], Loss: 0.2089, Validation Loss: 0.6595
	--> Epoch [9/100], Loss: 0.2019, Validation Loss: 0.6383
	--> Epoch [10/100], Loss: 0.1793, Validation Loss: 0.6356
	--> Epoch [11/100], Loss: 0.1562, Validation Loss: 0.6305
	--> Epoch [12/100], Loss: 0.1857, Validation Loss: 0.6348
	--> Epoch [13/100], Loss: 0.1750, Validation Loss: 0.6363
	--> Epoch [14/100], Loss: 0.1073, Validation Loss: 0.6558
Early stopping
	--> Training for Fold 5 took 0.05457758903503418 sec, using 14 epochs

Median number of epochs used: 19 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/19], Loss: 0.7145
	--> Final training Epoch [2/19], Loss: 0.5301
	--> Final training Epoch [3/19], Loss: 0.4308
	--> Final training Epoch [4/19], Loss: 0.3569
	--> Final training Epoch [5/19], Loss: 0.3338
	--> Final training Epoch [6/19], Loss: 0.2455
	--> Final training Epoch [7/19], Loss: 0.2111
	--> Final training Epoch [8/19], Loss: 0.1751
	--> Final training Epoch [9/19], Loss: 0.1310
	--> Final training Epoch [10/19], Loss: 0.1379
	--> Final training Epoch [11/19], Loss: 0.1227
	--> Final training Epoch [12/19], Loss: 0.1108
	--> Final training Epoch [13/19], Loss: 0.1074
	--> Final training Epoch [14/19], Loss: 0.1030
	--> Final training Epoch [15/19], Loss: 0.0828
	--> Final training Epoch [16/19], Loss: 0.0962
	--> Final training Epoch [17/19], Loss: 0.0890
	--> Final training Epoch [18/19], Loss: 0.0779
	--> Final training Epoch [19/19], Loss: 0.0576

Final training took 0.05989813804626465 sec

TESTING
	--> Testing took 0.0080 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0479
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3008,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3676,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.3641,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3106,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3692,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8115, Validation Loss: 0.5462
	--> Epoch [2/100], Loss: 0.7870, Validation Loss: 0.4890
	--> Epoch [3/100], Loss: 0.6599, Validation Loss: 0.4341
	--> Epoch [4/100], Loss: 0.5679, Validation Loss: 0.3967
	--> Epoch [5/100], Loss: 0.5244, Validation Loss: 0.3723
	--> Epoch [6/100], Loss: 0.4836, Validation Loss: 0.3612
	--> Epoch [7/100], Loss: 0.4242, Validation Loss: 0.3392
	--> Epoch [8/100], Loss: 0.4365, Validation Loss: 0.3055
	--> Epoch [9/100], Loss: 0.3922, Validation Loss: 0.2966
	--> Epoch [10/100], Loss: 0.3798, Validation Loss: 0.2855
	--> Epoch [11/100], Loss: 0.3714, Validation Loss: 0.2754
	--> Epoch [12/100], Loss: 0.3287, Validation Loss: 0.2655
	--> Epoch [13/100], Loss: 0.4135, Validation Loss: 0.2632
	--> Epoch [14/100], Loss: 0.3489, Validation Loss: 0.2556
	--> Epoch [15/100], Loss: 0.3073, Validation Loss: 0.2524
	--> Epoch [16/100], Loss: 0.3286, Validation Loss: 0.2467
	--> Epoch [17/100], Loss: 0.2972, Validation Loss: 0.2354
	--> Epoch [18/100], Loss: 0.3434, Validation Loss: 0.2295
	--> Epoch [19/100], Loss: 0.2786, Validation Loss: 0.2286
	--> Epoch [20/100], Loss: 0.3117, Validation Loss: 0.2220
	--> Epoch [21/100], Loss: 0.2678, Validation Loss: 0.2148
	--> Epoch [22/100], Loss: 0.3299, Validation Loss: 0.2158
	--> Epoch [23/100], Loss: 0.2915, Validation Loss: 0.2163
	--> Epoch [24/100], Loss: 0.3009, Validation Loss: 0.2152
Early stopping
	--> Training for Fold 1 took 0.08725118637084961 sec, using 24 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7191, Validation Loss: 0.6137
	--> Epoch [2/100], Loss: 0.6403, Validation Loss: 0.5057
	--> Epoch [3/100], Loss: 0.6569, Validation Loss: 0.4755
	--> Epoch [4/100], Loss: 0.5521, Validation Loss: 0.4280
	--> Epoch [5/100], Loss: 0.5112, Validation Loss: 0.4028
	--> Epoch [6/100], Loss: 0.4684, Validation Loss: 0.3907
	--> Epoch [7/100], Loss: 0.4706, Validation Loss: 0.3555
	--> Epoch [8/100], Loss: 0.3999, Validation Loss: 0.3238
	--> Epoch [9/100], Loss: 0.3433, Validation Loss: 0.3102
	--> Epoch [10/100], Loss: 0.3728, Validation Loss: 0.3165
	--> Epoch [11/100], Loss: 0.3392, Validation Loss: 0.3249
	--> Epoch [12/100], Loss: 0.2970, Validation Loss: 0.2972
	--> Epoch [13/100], Loss: 0.3010, Validation Loss: 0.2846
	--> Epoch [14/100], Loss: 0.3394, Validation Loss: 0.2866
	--> Epoch [15/100], Loss: 0.2709, Validation Loss: 0.2777
	--> Epoch [16/100], Loss: 0.3404, Validation Loss: 0.2732
	--> Epoch [17/100], Loss: 0.2311, Validation Loss: 0.2715
	--> Epoch [18/100], Loss: 0.2551, Validation Loss: 0.2387
	--> Epoch [19/100], Loss: 0.2774, Validation Loss: 0.2549
	--> Epoch [20/100], Loss: 0.2223, Validation Loss: 0.2559
	--> Epoch [21/100], Loss: 0.2556, Validation Loss: 0.2518
Early stopping
	--> Training for Fold 2 took 0.07558751106262207 sec, using 21 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6741, Validation Loss: 0.5844
	--> Epoch [2/100], Loss: 0.6044, Validation Loss: 0.5661
	--> Epoch [3/100], Loss: 0.5621, Validation Loss: 0.5211
	--> Epoch [4/100], Loss: 0.5041, Validation Loss: 0.4860
	--> Epoch [5/100], Loss: 0.4619, Validation Loss: 0.4562
	--> Epoch [6/100], Loss: 0.4118, Validation Loss: 0.4389
	--> Epoch [7/100], Loss: 0.4222, Validation Loss: 0.4224
	--> Epoch [8/100], Loss: 0.3246, Validation Loss: 0.3887
	--> Epoch [9/100], Loss: 0.3212, Validation Loss: 0.3805
	--> Epoch [10/100], Loss: 0.3744, Validation Loss: 0.3778
	--> Epoch [11/100], Loss: 0.3280, Validation Loss: 0.3616
	--> Epoch [12/100], Loss: 0.2440, Validation Loss: 0.3460
	--> Epoch [13/100], Loss: 0.2686, Validation Loss: 0.3526
	--> Epoch [14/100], Loss: 0.2955, Validation Loss: 0.3471
	--> Epoch [15/100], Loss: 0.2720, Validation Loss: 0.3556
Early stopping
	--> Training for Fold 3 took 0.05664181709289551 sec, using 15 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7313, Validation Loss: 0.5804
	--> Epoch [2/100], Loss: 0.7298, Validation Loss: 0.5234
	--> Epoch [3/100], Loss: 0.6006, Validation Loss: 0.4856
	--> Epoch [4/100], Loss: 0.5431, Validation Loss: 0.4557
	--> Epoch [5/100], Loss: 0.5312, Validation Loss: 0.4286
	--> Epoch [6/100], Loss: 0.4460, Validation Loss: 0.4198
	--> Epoch [7/100], Loss: 0.4346, Validation Loss: 0.3865
	--> Epoch [8/100], Loss: 0.3763, Validation Loss: 0.3571
	--> Epoch [9/100], Loss: 0.3922, Validation Loss: 0.3620
	--> Epoch [10/100], Loss: 0.3814, Validation Loss: 0.3588
	--> Epoch [11/100], Loss: 0.3378, Validation Loss: 0.3552
	--> Epoch [12/100], Loss: 0.3318, Validation Loss: 0.3430
	--> Epoch [13/100], Loss: 0.3033, Validation Loss: 0.3236
	--> Epoch [14/100], Loss: 0.3431, Validation Loss: 0.3165
	--> Epoch [15/100], Loss: 0.2893, Validation Loss: 0.3123
	--> Epoch [16/100], Loss: 0.2548, Validation Loss: 0.3065
	--> Epoch [17/100], Loss: 0.2399, Validation Loss: 0.2908
	--> Epoch [18/100], Loss: 0.2383, Validation Loss: 0.2813
	--> Epoch [19/100], Loss: 0.2884, Validation Loss: 0.2896
	--> Epoch [20/100], Loss: 0.2230, Validation Loss: 0.2830
	--> Epoch [21/100], Loss: 0.2685, Validation Loss: 0.2881
Early stopping
	--> Training for Fold 4 took 0.07644820213317871 sec, using 21 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7141, Validation Loss: 0.6758
	--> Epoch [2/100], Loss: 0.6706, Validation Loss: 0.6523
	--> Epoch [3/100], Loss: 0.5875, Validation Loss: 0.6515
	--> Epoch [4/100], Loss: 0.5341, Validation Loss: 0.6631
	--> Epoch [5/100], Loss: 0.4819, Validation Loss: 0.6712
	--> Epoch [6/100], Loss: 0.5257, Validation Loss: 0.6540
Early stopping
	--> Training for Fold 5 took 0.020227670669555664 sec, using 6 epochs

Median number of epochs used: 21 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/21], Loss: 0.7290
	--> Final training Epoch [2/21], Loss: 0.5561
	--> Final training Epoch [3/21], Loss: 0.5098
	--> Final training Epoch [4/21], Loss: 0.5361
	--> Final training Epoch [5/21], Loss: 0.4111
	--> Final training Epoch [6/21], Loss: 0.3941
	--> Final training Epoch [7/21], Loss: 0.3642
	--> Final training Epoch [8/21], Loss: 0.3783
	--> Final training Epoch [9/21], Loss: 0.2977
	--> Final training Epoch [10/21], Loss: 0.3474
	--> Final training Epoch [11/21], Loss: 0.2789
	--> Final training Epoch [12/21], Loss: 0.2888
	--> Final training Epoch [13/21], Loss: 0.3279
	--> Final training Epoch [14/21], Loss: 0.2918
	--> Final training Epoch [15/21], Loss: 0.2746
	--> Final training Epoch [16/21], Loss: 0.2313
	--> Final training Epoch [17/21], Loss: 0.2670
	--> Final training Epoch [18/21], Loss: 0.2897
	--> Final training Epoch [19/21], Loss: 0.2703
	--> Final training Epoch [20/21], Loss: 0.3039
	--> Final training Epoch [21/21], Loss: 0.2370

Final training took 0.07116532325744629 sec

TESTING
	--> Testing took 0.0076 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8711
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3225,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3225
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3445,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3225

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7002, Validation Loss: 0.5752
	--> Epoch [2/100], Loss: 0.5396, Validation Loss: 0.4865
	--> Epoch [3/100], Loss: 0.4400, Validation Loss: 0.4285
	--> Epoch [4/100], Loss: 0.3524, Validation Loss: 0.3978
	--> Epoch [5/100], Loss: 0.2893, Validation Loss: 0.3636
	--> Epoch [6/100], Loss: 0.2288, Validation Loss: 0.3586
	--> Epoch [7/100], Loss: 0.2088, Validation Loss: 0.3239
	--> Epoch [8/100], Loss: 0.1789, Validation Loss: 0.3251
	--> Epoch [9/100], Loss: 0.1504, Validation Loss: 0.3041
	--> Epoch [10/100], Loss: 0.1215, Validation Loss: 0.2940
	--> Epoch [11/100], Loss: 0.1128, Validation Loss: 0.2842
	--> Epoch [12/100], Loss: 0.1193, Validation Loss: 0.2832
	--> Epoch [13/100], Loss: 0.1421, Validation Loss: 0.2982
	--> Epoch [14/100], Loss: 0.1182, Validation Loss: 0.2917
	--> Epoch [15/100], Loss: 0.1092, Validation Loss: 0.2880
Early stopping
	--> Training for Fold 1 took 0.0629417896270752 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7214, Validation Loss: 0.6232
	--> Epoch [2/100], Loss: 0.5567, Validation Loss: 0.5491
	--> Epoch [3/100], Loss: 0.5010, Validation Loss: 0.5001
	--> Epoch [4/100], Loss: 0.4256, Validation Loss: 0.4706
	--> Epoch [5/100], Loss: 0.3621, Validation Loss: 0.3944
	--> Epoch [6/100], Loss: 0.3112, Validation Loss: 0.3800
	--> Epoch [7/100], Loss: 0.2599, Validation Loss: 0.3511
	--> Epoch [8/100], Loss: 0.2600, Validation Loss: 0.3341
	--> Epoch [9/100], Loss: 0.2141, Validation Loss: 0.3194
	--> Epoch [10/100], Loss: 0.1978, Validation Loss: 0.3048
	--> Epoch [11/100], Loss: 0.1532, Validation Loss: 0.3083
	--> Epoch [12/100], Loss: 0.2102, Validation Loss: 0.2887
	--> Epoch [13/100], Loss: 0.1806, Validation Loss: 0.2770
	--> Epoch [14/100], Loss: 0.1648, Validation Loss: 0.2833
	--> Epoch [15/100], Loss: 0.1602, Validation Loss: 0.2774
	--> Epoch [16/100], Loss: 0.1593, Validation Loss: 0.2717
	--> Epoch [17/100], Loss: 0.1385, Validation Loss: 0.2572
	--> Epoch [18/100], Loss: 0.1693, Validation Loss: 0.2562
	--> Epoch [19/100], Loss: 0.1116, Validation Loss: 0.2598
	--> Epoch [20/100], Loss: 0.1397, Validation Loss: 0.2471
	--> Epoch [21/100], Loss: 0.1613, Validation Loss: 0.2442
	--> Epoch [22/100], Loss: 0.1463, Validation Loss: 0.2265
	--> Epoch [23/100], Loss: 0.0759, Validation Loss: 0.2379
	--> Epoch [24/100], Loss: 0.1448, Validation Loss: 0.2417
	--> Epoch [25/100], Loss: 0.0994, Validation Loss: 0.2453
Early stopping
	--> Training for Fold 2 took 0.09597897529602051 sec, using 25 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6699, Validation Loss: 0.5659
	--> Epoch [2/100], Loss: 0.5325, Validation Loss: 0.5069
	--> Epoch [3/100], Loss: 0.4624, Validation Loss: 0.4434
	--> Epoch [4/100], Loss: 0.3479, Validation Loss: 0.3937
	--> Epoch [5/100], Loss: 0.2663, Validation Loss: 0.3557
	--> Epoch [6/100], Loss: 0.2515, Validation Loss: 0.3292
	--> Epoch [7/100], Loss: 0.2202, Validation Loss: 0.3044
	--> Epoch [8/100], Loss: 0.1854, Validation Loss: 0.2800
	--> Epoch [9/100], Loss: 0.1329, Validation Loss: 0.2810
	--> Epoch [10/100], Loss: 0.1351, Validation Loss: 0.2797
	--> Epoch [11/100], Loss: 0.1330, Validation Loss: 0.2718
	--> Epoch [12/100], Loss: 0.1215, Validation Loss: 0.2617
	--> Epoch [13/100], Loss: 0.1133, Validation Loss: 0.2600
	--> Epoch [14/100], Loss: 0.1115, Validation Loss: 0.2287
	--> Epoch [15/100], Loss: 0.1162, Validation Loss: 0.2311
	--> Epoch [16/100], Loss: 0.1077, Validation Loss: 0.2342
	--> Epoch [17/100], Loss: 0.0865, Validation Loss: 0.2187
	--> Epoch [18/100], Loss: 0.1050, Validation Loss: 0.2278
	--> Epoch [19/100], Loss: 0.0517, Validation Loss: 0.2265
	--> Epoch [20/100], Loss: 0.0816, Validation Loss: 0.2300
Early stopping
	--> Training for Fold 3 took 0.07751822471618652 sec, using 20 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7115, Validation Loss: 0.6330
	--> Epoch [2/100], Loss: 0.5619, Validation Loss: 0.5414
	--> Epoch [3/100], Loss: 0.4655, Validation Loss: 0.4988
	--> Epoch [4/100], Loss: 0.3665, Validation Loss: 0.4276
	--> Epoch [5/100], Loss: 0.3430, Validation Loss: 0.4094
	--> Epoch [6/100], Loss: 0.3034, Validation Loss: 0.3964
	--> Epoch [7/100], Loss: 0.2298, Validation Loss: 0.3772
	--> Epoch [8/100], Loss: 0.2402, Validation Loss: 0.3580
	--> Epoch [9/100], Loss: 0.1651, Validation Loss: 0.3541
	--> Epoch [10/100], Loss: 0.1401, Validation Loss: 0.3474
	--> Epoch [11/100], Loss: 0.1208, Validation Loss: 0.3380
	--> Epoch [12/100], Loss: 0.1247, Validation Loss: 0.3331
	--> Epoch [13/100], Loss: 0.0902, Validation Loss: 0.3361
	--> Epoch [14/100], Loss: 0.0667, Validation Loss: 0.3366
	--> Epoch [15/100], Loss: 0.0884, Validation Loss: 0.3441
Early stopping
	--> Training for Fold 4 took 0.057772159576416016 sec, using 15 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6746, Validation Loss: 0.7109
	--> Epoch [2/100], Loss: 0.5439, Validation Loss: 0.6797
	--> Epoch [3/100], Loss: 0.4477, Validation Loss: 0.6488
	--> Epoch [4/100], Loss: 0.3726, Validation Loss: 0.6319
	--> Epoch [5/100], Loss: 0.2884, Validation Loss: 0.6088
	--> Epoch [6/100], Loss: 0.2633, Validation Loss: 0.5969
	--> Epoch [7/100], Loss: 0.2281, Validation Loss: 0.5855
	--> Epoch [8/100], Loss: 0.1727, Validation Loss: 0.5791
	--> Epoch [9/100], Loss: 0.1673, Validation Loss: 0.5736
	--> Epoch [10/100], Loss: 0.1616, Validation Loss: 0.5555
	--> Epoch [11/100], Loss: 0.1405, Validation Loss: 0.5717
	--> Epoch [12/100], Loss: 0.1171, Validation Loss: 0.5973
	--> Epoch [13/100], Loss: 0.0907, Validation Loss: 0.6043
Early stopping
	--> Training for Fold 5 took 0.0471651554107666 sec, using 13 epochs

Median number of epochs used: 15 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/15], Loss: 0.7073
	--> Final training Epoch [2/15], Loss: 0.5758
	--> Final training Epoch [3/15], Loss: 0.4438
	--> Final training Epoch [4/15], Loss: 0.3844
	--> Final training Epoch [5/15], Loss: 0.3262
	--> Final training Epoch [6/15], Loss: 0.2786
	--> Final training Epoch [7/15], Loss: 0.2108
	--> Final training Epoch [8/15], Loss: 0.1790
	--> Final training Epoch [9/15], Loss: 0.1589
	--> Final training Epoch [10/15], Loss: 0.1430
	--> Final training Epoch [11/15], Loss: 0.1507
	--> Final training Epoch [12/15], Loss: 0.1358
	--> Final training Epoch [13/15], Loss: 0.1107
	--> Final training Epoch [14/15], Loss: 0.0846
	--> Final training Epoch [15/15], Loss: 0.1033

Final training took 0.04893755912780762 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9631
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8924, Validation Loss: 0.3070,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3121,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.3366,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3539,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8713, Validation Loss: 0.3432,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8696, Validation Loss: 0.3677,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3483,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3583,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3445,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3209,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3532,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3504,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3619,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3190,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3350,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8263, Validation Loss: 0.3252,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8047, Validation Loss: 0.3749,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3888,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8708, Validation Loss: 0.3389,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3186,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.4039,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3209,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 0.3747,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3234,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3234,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 0.3694,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8924, Validation Loss: 0.3596,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.9283, Validation Loss: 0.5745
	--> Epoch [2/100], Loss: 0.7066, Validation Loss: 0.5037
	--> Epoch [3/100], Loss: 0.4351, Validation Loss: 0.4584
	--> Epoch [4/100], Loss: 0.3157, Validation Loss: 0.4239
	--> Epoch [5/100], Loss: 0.4368, Validation Loss: 0.3922
	--> Epoch [6/100], Loss: 0.1816, Validation Loss: 0.3693
	--> Epoch [7/100], Loss: 0.2682, Validation Loss: 0.3521
	--> Epoch [8/100], Loss: 0.1603, Validation Loss: 0.3318
	--> Epoch [9/100], Loss: 0.1578, Validation Loss: 0.3175
	--> Epoch [10/100], Loss: 0.2021, Validation Loss: 0.3094
	--> Epoch [11/100], Loss: 0.3811, Validation Loss: 0.3044
	--> Epoch [12/100], Loss: 0.0239, Validation Loss: 0.2991
	--> Epoch [13/100], Loss: 0.0217, Validation Loss: 0.2939
	--> Epoch [14/100], Loss: 0.1669, Validation Loss: 0.2936
	--> Epoch [15/100], Loss: 0.0135, Validation Loss: 0.2965
	--> Epoch [16/100], Loss: 0.0265, Validation Loss: 0.2962
	--> Epoch [17/100], Loss: 0.0711, Validation Loss: 0.2969
Early stopping
	--> Training for Fold 1 took 0.8361239433288574 sec, using 17 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8613, Validation Loss: 0.6808
	--> Epoch [2/100], Loss: 0.6535, Validation Loss: 0.5735
	--> Epoch [3/100], Loss: 0.5450, Validation Loss: 0.5079
	--> Epoch [4/100], Loss: 0.4978, Validation Loss: 0.4585
	--> Epoch [5/100], Loss: 0.5136, Validation Loss: 0.4190
	--> Epoch [6/100], Loss: 0.1581, Validation Loss: 0.3796
	--> Epoch [7/100], Loss: 0.1057, Validation Loss: 0.3592
	--> Epoch [8/100], Loss: 0.0544, Validation Loss: 0.3405
	--> Epoch [9/100], Loss: 0.2316, Validation Loss: 0.3230
	--> Epoch [10/100], Loss: 0.0604, Validation Loss: 0.3075
	--> Epoch [11/100], Loss: 0.0739, Validation Loss: 0.2935
	--> Epoch [12/100], Loss: 0.2261, Validation Loss: 0.2810
	--> Epoch [13/100], Loss: 0.0116, Validation Loss: 0.2710
	--> Epoch [14/100], Loss: 0.0463, Validation Loss: 0.2624
	--> Epoch [15/100], Loss: 0.1451, Validation Loss: 0.2586
	--> Epoch [16/100], Loss: 0.0562, Validation Loss: 0.2544
	--> Epoch [17/100], Loss: 0.2291, Validation Loss: 0.2484
	--> Epoch [18/100], Loss: 0.0818, Validation Loss: 0.2456
	--> Epoch [19/100], Loss: 0.0653, Validation Loss: 0.2486
	--> Epoch [20/100], Loss: 0.0079, Validation Loss: 0.2424
	--> Epoch [21/100], Loss: 0.0089, Validation Loss: 0.2333
	--> Epoch [22/100], Loss: 0.0036, Validation Loss: 0.2245
	--> Epoch [23/100], Loss: 0.0162, Validation Loss: 0.2259
	--> Epoch [24/100], Loss: 0.0121, Validation Loss: 0.2345
	--> Epoch [25/100], Loss: 0.4137, Validation Loss: 0.2310
Early stopping
	--> Training for Fold 2 took 1.2488622665405273 sec, using 25 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7180, Validation Loss: 0.6392
	--> Epoch [2/100], Loss: 0.6094, Validation Loss: 0.6157
	--> Epoch [3/100], Loss: 0.4843, Validation Loss: 0.5881
	--> Epoch [4/100], Loss: 0.3484, Validation Loss: 0.5577
	--> Epoch [5/100], Loss: 0.2522, Validation Loss: 0.5266
	--> Epoch [6/100], Loss: 0.1997, Validation Loss: 0.4954
	--> Epoch [7/100], Loss: 0.1632, Validation Loss: 0.4678
	--> Epoch [8/100], Loss: 0.2142, Validation Loss: 0.4405
	--> Epoch [9/100], Loss: 0.0851, Validation Loss: 0.4187
	--> Epoch [10/100], Loss: 0.0583, Validation Loss: 0.4025
	--> Epoch [11/100], Loss: 0.1093, Validation Loss: 0.3891
	--> Epoch [12/100], Loss: 0.1115, Validation Loss: 0.3786
	--> Epoch [13/100], Loss: 0.0390, Validation Loss: 0.3657
	--> Epoch [14/100], Loss: 0.0695, Validation Loss: 0.3576
	--> Epoch [15/100], Loss: 0.0047, Validation Loss: 0.3551
	--> Epoch [16/100], Loss: 0.0386, Validation Loss: 0.3530
	--> Epoch [17/100], Loss: 0.0077, Validation Loss: 0.3571
	--> Epoch [18/100], Loss: 0.0166, Validation Loss: 0.3548
	--> Epoch [19/100], Loss: 0.0295, Validation Loss: 0.3478
	--> Epoch [20/100], Loss: 0.0241, Validation Loss: 0.3501
	--> Epoch [21/100], Loss: 0.0138, Validation Loss: 0.3475
	--> Epoch [22/100], Loss: 0.0071, Validation Loss: 0.3442
	--> Epoch [23/100], Loss: 0.0032, Validation Loss: 0.3432
	--> Epoch [24/100], Loss: 0.0021, Validation Loss: 0.3425
	--> Epoch [25/100], Loss: 0.0401, Validation Loss: 0.3440
	--> Epoch [26/100], Loss: 0.0060, Validation Loss: 0.3439
	--> Epoch [27/100], Loss: 0.0119, Validation Loss: 0.3426
Early stopping
	--> Training for Fold 3 took 1.3561620712280273 sec, using 27 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6197, Validation Loss: 0.5880
	--> Epoch [2/100], Loss: 0.5077, Validation Loss: 0.5335
	--> Epoch [3/100], Loss: 0.4300, Validation Loss: 0.4922
	--> Epoch [4/100], Loss: 0.3218, Validation Loss: 0.4610
	--> Epoch [5/100], Loss: 0.2616, Validation Loss: 0.4413
	--> Epoch [6/100], Loss: 0.2448, Validation Loss: 0.4245
	--> Epoch [7/100], Loss: 0.1954, Validation Loss: 0.3996
	--> Epoch [8/100], Loss: 0.1975, Validation Loss: 0.3812
	--> Epoch [9/100], Loss: 0.1496, Validation Loss: 0.3779
	--> Epoch [10/100], Loss: 0.0409, Validation Loss: 0.3618
	--> Epoch [11/100], Loss: 0.0950, Validation Loss: 0.3545
	--> Epoch [12/100], Loss: 0.0799, Validation Loss: 0.3511
	--> Epoch [13/100], Loss: 0.1427, Validation Loss: 0.3488
	--> Epoch [14/100], Loss: 0.0420, Validation Loss: 0.3437
	--> Epoch [15/100], Loss: 0.0166, Validation Loss: 0.3367
	--> Epoch [16/100], Loss: 0.0558, Validation Loss: 0.3366
	--> Epoch [17/100], Loss: 0.0281, Validation Loss: 0.3306
	--> Epoch [18/100], Loss: 0.0099, Validation Loss: 0.3339
	--> Epoch [19/100], Loss: 0.0231, Validation Loss: 0.3274
	--> Epoch [20/100], Loss: 0.0145, Validation Loss: 0.3323
	--> Epoch [21/100], Loss: 0.0795, Validation Loss: 0.3318
	--> Epoch [22/100], Loss: 0.0105, Validation Loss: 0.3372
Early stopping
	--> Training for Fold 4 took 1.0858399868011475 sec, using 22 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5332, Validation Loss: 0.6578
	--> Epoch [2/100], Loss: 0.4573, Validation Loss: 0.6272
	--> Epoch [3/100], Loss: 0.3417, Validation Loss: 0.6082
	--> Epoch [4/100], Loss: 0.3087, Validation Loss: 0.5880
	--> Epoch [5/100], Loss: 0.2169, Validation Loss: 0.5788
	--> Epoch [6/100], Loss: 0.2004, Validation Loss: 0.5756
	--> Epoch [7/100], Loss: 0.1342, Validation Loss: 0.5712
	--> Epoch [8/100], Loss: 0.1173, Validation Loss: 0.5602
	--> Epoch [9/100], Loss: 0.1235, Validation Loss: 0.5556
	--> Epoch [10/100], Loss: 0.1206, Validation Loss: 0.5551
	--> Epoch [11/100], Loss: 0.0251, Validation Loss: 0.5469
	--> Epoch [12/100], Loss: 0.0494, Validation Loss: 0.5510
	--> Epoch [13/100], Loss: 0.0523, Validation Loss: 0.5531
	--> Epoch [14/100], Loss: 0.0996, Validation Loss: 0.5652
Early stopping
	--> Training for Fold 5 took 0.701026201248169 sec, using 14 epochs

Median number of epochs used: 22 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/22], Loss: 0.9972
	--> Final training Epoch [2/22], Loss: 0.7355
	--> Final training Epoch [3/22], Loss: 0.5894
	--> Final training Epoch [4/22], Loss: 0.4658
	--> Final training Epoch [5/22], Loss: 0.3542
	--> Final training Epoch [6/22], Loss: 0.1729
	--> Final training Epoch [7/22], Loss: 0.1095
	--> Final training Epoch [8/22], Loss: 0.3056
	--> Final training Epoch [9/22], Loss: 0.1801
	--> Final training Epoch [10/22], Loss: 0.0202
	--> Final training Epoch [11/22], Loss: 0.1469
	--> Final training Epoch [12/22], Loss: 0.0105
	--> Final training Epoch [13/22], Loss: 0.0081
	--> Final training Epoch [14/22], Loss: 0.7175
	--> Final training Epoch [15/22], Loss: 0.0641
	--> Final training Epoch [16/22], Loss: 0.0039
	--> Final training Epoch [17/22], Loss: 0.0444
	--> Final training Epoch [18/22], Loss: 0.0722
	--> Final training Epoch [19/22], Loss: 0.0019
	--> Final training Epoch [20/22], Loss: 0.0542
	--> Final training Epoch [21/22], Loss: 0.0426
	--> Final training Epoch [22/22], Loss: 0.6720

Final training took 1.314497947692871 sec

TESTING
	--> Testing took 0.0159 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0611
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.9023, Validation Loss: 0.3096,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.3405,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3501,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3568,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3293,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.3743,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8608, Validation Loss: 0.3449,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 0.3864,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.3239,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8480, Validation Loss: 0.3285,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3166,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3430,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8608, Validation Loss: 0.3426,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3463,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.4012,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3432,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.3533,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8175, Validation Loss: 0.3985,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3313,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3348,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3309,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3503,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3350,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.3992,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8708, Validation Loss: 0.3752,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.4332,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3445,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3452,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8374, Validation Loss: 0.3217,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3386,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3361,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7830, Validation Loss: 0.4019,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8819, Validation Loss: 0.3449,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3911,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7959, Validation Loss: 0.3811,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.3703,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7121, Validation Loss: 0.5880
	--> Epoch [2/100], Loss: 0.5727, Validation Loss: 0.5538
	--> Epoch [3/100], Loss: 0.5481, Validation Loss: 0.5293
	--> Epoch [4/100], Loss: 0.3991, Validation Loss: 0.4975
	--> Epoch [5/100], Loss: 0.4998, Validation Loss: 0.4714
	--> Epoch [6/100], Loss: 0.3561, Validation Loss: 0.4496
	--> Epoch [7/100], Loss: 0.2217, Validation Loss: 0.4246
	--> Epoch [8/100], Loss: 0.2233, Validation Loss: 0.4006
	--> Epoch [9/100], Loss: 0.3690, Validation Loss: 0.3881
	--> Epoch [10/100], Loss: 0.4315, Validation Loss: 0.3729
	--> Epoch [11/100], Loss: 0.0946, Validation Loss: 0.3596
	--> Epoch [12/100], Loss: 0.0548, Validation Loss: 0.3518
	--> Epoch [13/100], Loss: 0.0258, Validation Loss: 0.3452
	--> Epoch [14/100], Loss: 0.0558, Validation Loss: 0.3344
	--> Epoch [15/100], Loss: 0.1503, Validation Loss: 0.3267
	--> Epoch [16/100], Loss: 0.0259, Validation Loss: 0.3217
	--> Epoch [17/100], Loss: 0.0095, Validation Loss: 0.3217
	--> Epoch [18/100], Loss: 0.0281, Validation Loss: 0.3199
	--> Epoch [19/100], Loss: 0.0219, Validation Loss: 0.3191
	--> Epoch [20/100], Loss: 0.0163, Validation Loss: 0.3225
	--> Epoch [21/100], Loss: 0.0234, Validation Loss: 0.3244
	--> Epoch [22/100], Loss: 0.0179, Validation Loss: 0.3236
Early stopping
	--> Training for Fold 1 took 0.514739990234375 sec, using 22 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5719, Validation Loss: 0.5587
	--> Epoch [2/100], Loss: 0.6725, Validation Loss: 0.5148
	--> Epoch [3/100], Loss: 0.4276, Validation Loss: 0.4671
	--> Epoch [4/100], Loss: 0.3372, Validation Loss: 0.4263
	--> Epoch [5/100], Loss: 0.2818, Validation Loss: 0.3958
	--> Epoch [6/100], Loss: 0.1861, Validation Loss: 0.3729
	--> Epoch [7/100], Loss: 0.3594, Validation Loss: 0.3560
	--> Epoch [8/100], Loss: 0.3083, Validation Loss: 0.3403
	--> Epoch [9/100], Loss: 0.4165, Validation Loss: 0.3299
	--> Epoch [10/100], Loss: 0.0552, Validation Loss: 0.3179
	--> Epoch [11/100], Loss: 0.0694, Validation Loss: 0.3101
	--> Epoch [12/100], Loss: 0.0725, Validation Loss: 0.3021
	--> Epoch [13/100], Loss: 0.2439, Validation Loss: 0.2942
	--> Epoch [14/100], Loss: 0.0145, Validation Loss: 0.2884
	--> Epoch [15/100], Loss: 0.0145, Validation Loss: 0.2787
	--> Epoch [16/100], Loss: 0.0258, Validation Loss: 0.2782
	--> Epoch [17/100], Loss: 0.0238, Validation Loss: 0.2718
	--> Epoch [18/100], Loss: 0.0070, Validation Loss: 0.2648
	--> Epoch [19/100], Loss: 0.0184, Validation Loss: 0.2596
	--> Epoch [20/100], Loss: 0.0157, Validation Loss: 0.2575
	--> Epoch [21/100], Loss: 0.0408, Validation Loss: 0.2558
	--> Epoch [22/100], Loss: 0.0554, Validation Loss: 0.2459
	--> Epoch [23/100], Loss: 0.0278, Validation Loss: 0.2441
	--> Epoch [24/100], Loss: 0.0027, Validation Loss: 0.2494
	--> Epoch [25/100], Loss: 0.0657, Validation Loss: 0.2453
	--> Epoch [26/100], Loss: 0.0273, Validation Loss: 0.2416
	--> Epoch [27/100], Loss: 0.0208, Validation Loss: 0.2419
	--> Epoch [28/100], Loss: 0.0170, Validation Loss: 0.2399
	--> Epoch [29/100], Loss: 0.0042, Validation Loss: 0.2355
	--> Epoch [30/100], Loss: 0.0081, Validation Loss: 0.2360
	--> Epoch [31/100], Loss: 0.3647, Validation Loss: 0.2296
	--> Epoch [32/100], Loss: 0.0163, Validation Loss: 0.2283
	--> Epoch [33/100], Loss: 0.0089, Validation Loss: 0.2285
	--> Epoch [34/100], Loss: 0.0017, Validation Loss: 0.2255
	--> Epoch [35/100], Loss: 0.0079, Validation Loss: 0.2233
	--> Epoch [36/100], Loss: 0.0010, Validation Loss: 0.2193
	--> Epoch [37/100], Loss: 0.0486, Validation Loss: 0.2205
	--> Epoch [38/100], Loss: 0.1485, Validation Loss: 0.2185
	--> Epoch [39/100], Loss: 0.0028, Validation Loss: 0.2169
	--> Epoch [40/100], Loss: 0.0046, Validation Loss: 0.2142
	--> Epoch [41/100], Loss: 0.0038, Validation Loss: 0.2133
	--> Epoch [42/100], Loss: 0.0004, Validation Loss: 0.2134
	--> Epoch [43/100], Loss: 0.3445, Validation Loss: 0.2113
	--> Epoch [44/100], Loss: 0.0008, Validation Loss: 0.2109
	--> Epoch [45/100], Loss: 0.0204, Validation Loss: 0.2105
	--> Epoch [46/100], Loss: 0.0002, Validation Loss: 0.2070
	--> Epoch [47/100], Loss: 0.0001, Validation Loss: 0.2061
	--> Epoch [48/100], Loss: 0.0398, Validation Loss: 0.2050
	--> Epoch [49/100], Loss: 0.0012, Validation Loss: 0.2068
	--> Epoch [50/100], Loss: 0.0010, Validation Loss: 0.2055
	--> Epoch [51/100], Loss: 0.0017, Validation Loss: 0.2046
	--> Epoch [52/100], Loss: 0.0019, Validation Loss: 0.2043
	--> Epoch [53/100], Loss: 0.0001, Validation Loss: 0.1982
	--> Epoch [54/100], Loss: 0.0021, Validation Loss: 0.1965
	--> Epoch [55/100], Loss: 0.0017, Validation Loss: 0.1916
	--> Epoch [56/100], Loss: 0.0497, Validation Loss: 0.1930
	--> Epoch [57/100], Loss: 0.0006, Validation Loss: 0.1859
	--> Epoch [58/100], Loss: 0.0008, Validation Loss: 0.1822
	--> Epoch [59/100], Loss: 0.0010, Validation Loss: 0.1838
	--> Epoch [60/100], Loss: 0.0006, Validation Loss: 0.1844
	--> Epoch [61/100], Loss: 0.0209, Validation Loss: 0.1844
Early stopping
	--> Training for Fold 2 took 1.46848726272583 sec, using 61 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7535, Validation Loss: 0.6455
	--> Epoch [2/100], Loss: 0.5110, Validation Loss: 0.6169
	--> Epoch [3/100], Loss: 0.2911, Validation Loss: 0.5923
	--> Epoch [4/100], Loss: 0.3700, Validation Loss: 0.5725
	--> Epoch [5/100], Loss: 0.2116, Validation Loss: 0.5554
	--> Epoch [6/100], Loss: 0.2092, Validation Loss: 0.5386
	--> Epoch [7/100], Loss: 0.0890, Validation Loss: 0.5215
	--> Epoch [8/100], Loss: 0.1957, Validation Loss: 0.5078
	--> Epoch [9/100], Loss: 0.0350, Validation Loss: 0.4937
	--> Epoch [10/100], Loss: 0.2732, Validation Loss: 0.4867
	--> Epoch [11/100], Loss: 0.0205, Validation Loss: 0.4709
	--> Epoch [12/100], Loss: 0.1959, Validation Loss: 0.4611
	--> Epoch [13/100], Loss: 0.0818, Validation Loss: 0.4531
	--> Epoch [14/100], Loss: 0.0096, Validation Loss: 0.4478
	--> Epoch [15/100], Loss: 0.0141, Validation Loss: 0.4371
	--> Epoch [16/100], Loss: 0.0182, Validation Loss: 0.4314
	--> Epoch [17/100], Loss: 0.0854, Validation Loss: 0.4251
	--> Epoch [18/100], Loss: 0.0454, Validation Loss: 0.4215
	--> Epoch [19/100], Loss: 0.1700, Validation Loss: 0.4176
	--> Epoch [20/100], Loss: 0.0065, Validation Loss: 0.4139
	--> Epoch [21/100], Loss: 0.0504, Validation Loss: 0.4138
	--> Epoch [22/100], Loss: 0.0333, Validation Loss: 0.4070
	--> Epoch [23/100], Loss: 0.0041, Validation Loss: 0.4048
	--> Epoch [24/100], Loss: 0.0034, Validation Loss: 0.4079
	--> Epoch [25/100], Loss: 0.0393, Validation Loss: 0.4020
	--> Epoch [26/100], Loss: 0.0221, Validation Loss: 0.4000
	--> Epoch [27/100], Loss: 0.0038, Validation Loss: 0.3984
	--> Epoch [28/100], Loss: 0.0875, Validation Loss: 0.3961
	--> Epoch [29/100], Loss: 0.0024, Validation Loss: 0.3972
	--> Epoch [30/100], Loss: 0.0899, Validation Loss: 0.3993
	--> Epoch [31/100], Loss: 0.0800, Validation Loss: 0.3935
	--> Epoch [32/100], Loss: 0.0550, Validation Loss: 0.3966
	--> Epoch [33/100], Loss: 0.0007, Validation Loss: 0.3983
	--> Epoch [34/100], Loss: 0.0080, Validation Loss: 0.3985
Early stopping
	--> Training for Fold 3 took 0.8674445152282715 sec, using 34 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6002, Validation Loss: 0.6515
	--> Epoch [2/100], Loss: 0.6247, Validation Loss: 0.5943
	--> Epoch [3/100], Loss: 0.5481, Validation Loss: 0.5654
	--> Epoch [4/100], Loss: 0.5357, Validation Loss: 0.5336
	--> Epoch [5/100], Loss: 0.3850, Validation Loss: 0.4992
	--> Epoch [6/100], Loss: 0.3153, Validation Loss: 0.4677
	--> Epoch [7/100], Loss: 0.1612, Validation Loss: 0.4386
	--> Epoch [8/100], Loss: 0.1920, Validation Loss: 0.4259
	--> Epoch [9/100], Loss: 0.1901, Validation Loss: 0.4067
	--> Epoch [10/100], Loss: 0.1265, Validation Loss: 0.3967
	--> Epoch [11/100], Loss: 0.0684, Validation Loss: 0.3858
	--> Epoch [12/100], Loss: 0.1401, Validation Loss: 0.3752
	--> Epoch [13/100], Loss: 0.0271, Validation Loss: 0.3712
	--> Epoch [14/100], Loss: 0.1169, Validation Loss: 0.3692
	--> Epoch [15/100], Loss: 0.0131, Validation Loss: 0.3682
	--> Epoch [16/100], Loss: 0.0622, Validation Loss: 0.3677
	--> Epoch [17/100], Loss: 0.0348, Validation Loss: 0.3619
	--> Epoch [18/100], Loss: 0.0763, Validation Loss: 0.3654
	--> Epoch [19/100], Loss: 0.0153, Validation Loss: 0.3667
	--> Epoch [20/100], Loss: 0.0553, Validation Loss: 0.3696
Early stopping
	--> Training for Fold 4 took 0.5409901142120361 sec, using 20 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4159, Validation Loss: 0.7472
	--> Epoch [2/100], Loss: 0.4534, Validation Loss: 0.7288
	--> Epoch [3/100], Loss: 0.5144, Validation Loss: 0.7149
	--> Epoch [4/100], Loss: 0.2342, Validation Loss: 0.7100
	--> Epoch [5/100], Loss: 0.2776, Validation Loss: 0.6982
	--> Epoch [6/100], Loss: 0.1352, Validation Loss: 0.6836
	--> Epoch [7/100], Loss: 0.0874, Validation Loss: 0.6722
	--> Epoch [8/100], Loss: 0.1716, Validation Loss: 0.6591
	--> Epoch [9/100], Loss: 0.1335, Validation Loss: 0.6477
	--> Epoch [10/100], Loss: 0.0942, Validation Loss: 0.6323
	--> Epoch [11/100], Loss: 0.0499, Validation Loss: 0.6245
	--> Epoch [12/100], Loss: 0.0561, Validation Loss: 0.6159
	--> Epoch [13/100], Loss: 0.0609, Validation Loss: 0.6076
	--> Epoch [14/100], Loss: 0.1878, Validation Loss: 0.6082
	--> Epoch [15/100], Loss: 0.0151, Validation Loss: 0.6081
	--> Epoch [16/100], Loss: 0.0258, Validation Loss: 0.6076
Early stopping
	--> Training for Fold 5 took 0.4126718044281006 sec, using 16 epochs

Median number of epochs used: 22 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/22], Loss: 0.5463
	--> Final training Epoch [2/22], Loss: 0.5050
	--> Final training Epoch [3/22], Loss: 0.4064
	--> Final training Epoch [4/22], Loss: 0.4115
	--> Final training Epoch [5/22], Loss: 0.2306
	--> Final training Epoch [6/22], Loss: 0.3842
	--> Final training Epoch [7/22], Loss: 0.2034
	--> Final training Epoch [8/22], Loss: 0.1011
	--> Final training Epoch [9/22], Loss: 0.2328
	--> Final training Epoch [10/22], Loss: 0.0945
	--> Final training Epoch [11/22], Loss: 0.1403
	--> Final training Epoch [12/22], Loss: 0.1328
	--> Final training Epoch [13/22], Loss: 0.2785
	--> Final training Epoch [14/22], Loss: 0.0439
	--> Final training Epoch [15/22], Loss: 0.0501
	--> Final training Epoch [16/22], Loss: 0.2088
	--> Final training Epoch [17/22], Loss: 0.0675
	--> Final training Epoch [18/22], Loss: 0.0299
	--> Final training Epoch [19/22], Loss: 0.1116
	--> Final training Epoch [20/22], Loss: 0.1736
	--> Final training Epoch [21/22], Loss: 0.1656
	--> Final training Epoch [22/22], Loss: 0.0184

Final training took 0.7628252506256104 sec

TESTING
	--> Testing took 0.0096 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.8246
	--> Final Precision: 0.6667
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5455
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.2936,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8175, Validation Loss: 0.3518,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3269,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8047, Validation Loss: 0.3893,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3540,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7942, Validation Loss: 0.4270,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3807,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.4046,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.4120,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3519,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3616,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8374, Validation Loss: 0.3724,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3689,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.3646,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3260,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.3633,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3461,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8035, Validation Loss: 0.4302,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8145, Validation Loss: 0.8484
	--> Epoch [2/100], Loss: 0.7197, Validation Loss: 0.7848
	--> Epoch [3/100], Loss: 0.6003, Validation Loss: 0.7370
	--> Epoch [4/100], Loss: 0.4357, Validation Loss: 0.6976
	--> Epoch [5/100], Loss: 0.4092, Validation Loss: 0.6566
	--> Epoch [6/100], Loss: 0.4021, Validation Loss: 0.6185
	--> Epoch [7/100], Loss: 0.2621, Validation Loss: 0.5904
	--> Epoch [8/100], Loss: 0.4113, Validation Loss: 0.5556
	--> Epoch [9/100], Loss: 0.4380, Validation Loss: 0.5302
	--> Epoch [10/100], Loss: 0.5801, Validation Loss: 0.5061
	--> Epoch [11/100], Loss: 0.1623, Validation Loss: 0.4746
	--> Epoch [12/100], Loss: 0.1295, Validation Loss: 0.4431
	--> Epoch [13/100], Loss: 0.4222, Validation Loss: 0.4259
	--> Epoch [14/100], Loss: 0.4211, Validation Loss: 0.4077
	--> Epoch [15/100], Loss: 0.0766, Validation Loss: 0.3892
	--> Epoch [16/100], Loss: 0.0710, Validation Loss: 0.3757
	--> Epoch [17/100], Loss: 0.0814, Validation Loss: 0.3662
	--> Epoch [18/100], Loss: 0.3782, Validation Loss: 0.3547
	--> Epoch [19/100], Loss: 0.3705, Validation Loss: 0.3438
	--> Epoch [20/100], Loss: 0.0398, Validation Loss: 0.3348
	--> Epoch [21/100], Loss: 0.0342, Validation Loss: 0.3291
	--> Epoch [22/100], Loss: 0.0322, Validation Loss: 0.3224
	--> Epoch [23/100], Loss: 0.3644, Validation Loss: 0.3135
	--> Epoch [24/100], Loss: 0.3601, Validation Loss: 0.3132
	--> Epoch [25/100], Loss: 0.3616, Validation Loss: 0.3097
	--> Epoch [26/100], Loss: 0.0219, Validation Loss: 0.3052
	--> Epoch [27/100], Loss: 0.0245, Validation Loss: 0.2983
	--> Epoch [28/100], Loss: 0.3647, Validation Loss: 0.2923
	--> Epoch [29/100], Loss: 0.0137, Validation Loss: 0.2910
	--> Epoch [30/100], Loss: 0.0123, Validation Loss: 0.2890
	--> Epoch [31/100], Loss: 0.3579, Validation Loss: 0.2805
	--> Epoch [32/100], Loss: 0.3460, Validation Loss: 0.2815
	--> Epoch [33/100], Loss: 0.3508, Validation Loss: 0.2762
	--> Epoch [34/100], Loss: 0.1017, Validation Loss: 0.2766
	--> Epoch [35/100], Loss: 0.0151, Validation Loss: 0.2754
	--> Epoch [36/100], Loss: 0.0087, Validation Loss: 0.2720
	--> Epoch [37/100], Loss: 0.3359, Validation Loss: 0.2704
	--> Epoch [38/100], Loss: 0.3336, Validation Loss: 0.2685
	--> Epoch [39/100], Loss: 0.0862, Validation Loss: 0.2665
	--> Epoch [40/100], Loss: 0.0057, Validation Loss: 0.2633
	--> Epoch [41/100], Loss: 0.0094, Validation Loss: 0.2619
	--> Epoch [42/100], Loss: 0.0087, Validation Loss: 0.2613
	--> Epoch [43/100], Loss: 0.0662, Validation Loss: 0.2615
	--> Epoch [44/100], Loss: 0.0047, Validation Loss: 0.2583
	--> Epoch [45/100], Loss: 0.3664, Validation Loss: 0.2531
	--> Epoch [46/100], Loss: 0.3215, Validation Loss: 0.2573
	--> Epoch [47/100], Loss: 0.0039, Validation Loss: 0.2553
	--> Epoch [48/100], Loss: 0.0035, Validation Loss: 0.2537
Early stopping
	--> Training for Fold 1 took 1.2975263595581055 sec, using 48 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5613, Validation Loss: 0.7023
	--> Epoch [2/100], Loss: 0.4423, Validation Loss: 0.6580
	--> Epoch [3/100], Loss: 0.3907, Validation Loss: 0.6189
	--> Epoch [4/100], Loss: 0.2802, Validation Loss: 0.5784
	--> Epoch [5/100], Loss: 0.4212, Validation Loss: 0.5501
	--> Epoch [6/100], Loss: 0.1397, Validation Loss: 0.5239
	--> Epoch [7/100], Loss: 0.1385, Validation Loss: 0.4916
	--> Epoch [8/100], Loss: 0.0758, Validation Loss: 0.4679
	--> Epoch [9/100], Loss: 0.0701, Validation Loss: 0.4526
	--> Epoch [10/100], Loss: 0.0733, Validation Loss: 0.4346
	--> Epoch [11/100], Loss: 0.1382, Validation Loss: 0.4167
	--> Epoch [12/100], Loss: 0.1745, Validation Loss: 0.4050
	--> Epoch [13/100], Loss: 0.0476, Validation Loss: 0.3933
	--> Epoch [14/100], Loss: 0.0361, Validation Loss: 0.3806
	--> Epoch [15/100], Loss: 0.0761, Validation Loss: 0.3738
	--> Epoch [16/100], Loss: 0.0887, Validation Loss: 0.3705
	--> Epoch [17/100], Loss: 0.0100, Validation Loss: 0.3630
	--> Epoch [18/100], Loss: 0.0724, Validation Loss: 0.3585
	--> Epoch [19/100], Loss: 0.0123, Validation Loss: 0.3504
	--> Epoch [20/100], Loss: 0.1069, Validation Loss: 0.3471
	--> Epoch [21/100], Loss: 0.0141, Validation Loss: 0.3433
	--> Epoch [22/100], Loss: 0.0191, Validation Loss: 0.3390
	--> Epoch [23/100], Loss: 0.0254, Validation Loss: 0.3408
	--> Epoch [24/100], Loss: 0.0080, Validation Loss: 0.3346
	--> Epoch [25/100], Loss: 0.0368, Validation Loss: 0.3293
	--> Epoch [26/100], Loss: 0.0319, Validation Loss: 0.3291
	--> Epoch [27/100], Loss: 0.0225, Validation Loss: 0.3284
	--> Epoch [28/100], Loss: 0.0073, Validation Loss: 0.3200
	--> Epoch [29/100], Loss: 0.0011, Validation Loss: 0.3174
	--> Epoch [30/100], Loss: 0.0017, Validation Loss: 0.3133
	--> Epoch [31/100], Loss: 0.0005, Validation Loss: 0.3082
	--> Epoch [32/100], Loss: 0.0008, Validation Loss: 0.3067
	--> Epoch [33/100], Loss: 0.0092, Validation Loss: 0.3040
	--> Epoch [34/100], Loss: 0.0159, Validation Loss: 0.3007
	--> Epoch [35/100], Loss: 0.0006, Validation Loss: 0.2991
	--> Epoch [36/100], Loss: 0.1566, Validation Loss: 0.2881
	--> Epoch [37/100], Loss: 0.0130, Validation Loss: 0.2776
	--> Epoch [38/100], Loss: 0.0486, Validation Loss: 0.2793
	--> Epoch [39/100], Loss: 0.0177, Validation Loss: 0.2787
	--> Epoch [40/100], Loss: 0.0142, Validation Loss: 0.2747
	--> Epoch [41/100], Loss: 0.0003, Validation Loss: 0.2731
	--> Epoch [42/100], Loss: 0.0009, Validation Loss: 0.2751
	--> Epoch [43/100], Loss: 0.0029, Validation Loss: 0.2717
	--> Epoch [44/100], Loss: 0.0063, Validation Loss: 0.2698
	--> Epoch [45/100], Loss: 0.0002, Validation Loss: 0.2612
	--> Epoch [46/100], Loss: 0.0075, Validation Loss: 0.2606
	--> Epoch [47/100], Loss: 0.0006, Validation Loss: 0.2665
	--> Epoch [48/100], Loss: 0.0080, Validation Loss: 0.2654
	--> Epoch [49/100], Loss: 0.0011, Validation Loss: 0.2588
	--> Epoch [50/100], Loss: 0.0017, Validation Loss: 0.2559
	--> Epoch [51/100], Loss: 0.0017, Validation Loss: 0.2560
	--> Epoch [52/100], Loss: 0.0017, Validation Loss: 0.2546
	--> Epoch [53/100], Loss: 0.0559, Validation Loss: 0.2570
	--> Epoch [54/100], Loss: 0.0000, Validation Loss: 0.2574
	--> Epoch [55/100], Loss: 0.0008, Validation Loss: 0.2570
Early stopping
	--> Training for Fold 2 took 1.5787794589996338 sec, using 55 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4558, Validation Loss: 0.7081
	--> Epoch [2/100], Loss: 0.5041, Validation Loss: 0.6752
	--> Epoch [3/100], Loss: 0.3786, Validation Loss: 0.6502
	--> Epoch [4/100], Loss: 0.2986, Validation Loss: 0.6191
	--> Epoch [5/100], Loss: 0.4047, Validation Loss: 0.5925
	--> Epoch [6/100], Loss: 0.1711, Validation Loss: 0.5673
	--> Epoch [7/100], Loss: 0.1963, Validation Loss: 0.5472
	--> Epoch [8/100], Loss: 0.2563, Validation Loss: 0.5274
	--> Epoch [9/100], Loss: 0.4152, Validation Loss: 0.5171
	--> Epoch [10/100], Loss: 0.1916, Validation Loss: 0.4965
	--> Epoch [11/100], Loss: 0.1737, Validation Loss: 0.4833
	--> Epoch [12/100], Loss: 0.1604, Validation Loss: 0.4713
	--> Epoch [13/100], Loss: 0.0240, Validation Loss: 0.4626
	--> Epoch [14/100], Loss: 0.1337, Validation Loss: 0.4556
	--> Epoch [15/100], Loss: 0.0950, Validation Loss: 0.4491
	--> Epoch [16/100], Loss: 0.0152, Validation Loss: 0.4444
	--> Epoch [17/100], Loss: 0.1224, Validation Loss: 0.4394
	--> Epoch [18/100], Loss: 0.0058, Validation Loss: 0.4331
	--> Epoch [19/100], Loss: 0.0152, Validation Loss: 0.4284
	--> Epoch [20/100], Loss: 0.0134, Validation Loss: 0.4247
	--> Epoch [21/100], Loss: 0.0826, Validation Loss: 0.4204
	--> Epoch [22/100], Loss: 0.0098, Validation Loss: 0.4214
	--> Epoch [23/100], Loss: 0.0197, Validation Loss: 0.4221
	--> Epoch [24/100], Loss: 0.0093, Validation Loss: 0.4221
Early stopping
	--> Training for Fold 3 took 0.7016968727111816 sec, using 24 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8901, Validation Loss: 0.6538
	--> Epoch [2/100], Loss: 0.7987, Validation Loss: 0.6116
	--> Epoch [3/100], Loss: 0.5547, Validation Loss: 0.5700
	--> Epoch [4/100], Loss: 0.5715, Validation Loss: 0.5258
	--> Epoch [5/100], Loss: 0.4522, Validation Loss: 0.4911
	--> Epoch [6/100], Loss: 0.3380, Validation Loss: 0.4702
	--> Epoch [7/100], Loss: 0.2798, Validation Loss: 0.4421
	--> Epoch [8/100], Loss: 0.3553, Validation Loss: 0.4209
	--> Epoch [9/100], Loss: 0.1679, Validation Loss: 0.3977
	--> Epoch [10/100], Loss: 0.3760, Validation Loss: 0.3892
	--> Epoch [11/100], Loss: 0.2125, Validation Loss: 0.3754
	--> Epoch [12/100], Loss: 0.1952, Validation Loss: 0.3633
	--> Epoch [13/100], Loss: 0.1208, Validation Loss: 0.3511
	--> Epoch [14/100], Loss: 0.1372, Validation Loss: 0.3450
	--> Epoch [15/100], Loss: 0.0851, Validation Loss: 0.3364
	--> Epoch [16/100], Loss: 0.3001, Validation Loss: 0.3250
	--> Epoch [17/100], Loss: 0.2147, Validation Loss: 0.3212
	--> Epoch [18/100], Loss: 0.0768, Validation Loss: 0.3166
	--> Epoch [19/100], Loss: 0.1177, Validation Loss: 0.3146
	--> Epoch [20/100], Loss: 0.1029, Validation Loss: 0.3101
	--> Epoch [21/100], Loss: 0.0419, Validation Loss: 0.3073
	--> Epoch [22/100], Loss: 0.1767, Validation Loss: 0.2980
	--> Epoch [23/100], Loss: 0.0930, Validation Loss: 0.2974
	--> Epoch [24/100], Loss: 0.0571, Validation Loss: 0.2937
	--> Epoch [25/100], Loss: 0.0076, Validation Loss: 0.2862
	--> Epoch [26/100], Loss: 0.0403, Validation Loss: 0.2879
	--> Epoch [27/100], Loss: 0.0361, Validation Loss: 0.2860
	--> Epoch [28/100], Loss: 0.2087, Validation Loss: 0.2846
	--> Epoch [29/100], Loss: 0.0223, Validation Loss: 0.2838
	--> Epoch [30/100], Loss: 0.0296, Validation Loss: 0.2845
	--> Epoch [31/100], Loss: 0.0402, Validation Loss: 0.2782
	--> Epoch [32/100], Loss: 0.0283, Validation Loss: 0.2759
	--> Epoch [33/100], Loss: 0.0134, Validation Loss: 0.2783
	--> Epoch [34/100], Loss: 0.2998, Validation Loss: 0.2761
	--> Epoch [35/100], Loss: 0.0193, Validation Loss: 0.2730
	--> Epoch [36/100], Loss: 0.0017, Validation Loss: 0.2731
	--> Epoch [37/100], Loss: 0.0170, Validation Loss: 0.2724
	--> Epoch [38/100], Loss: 0.0205, Validation Loss: 0.2713
	--> Epoch [39/100], Loss: 0.0185, Validation Loss: 0.2721
	--> Epoch [40/100], Loss: 0.0175, Validation Loss: 0.2738
	--> Epoch [41/100], Loss: 0.0264, Validation Loss: 0.2796
Early stopping
	--> Training for Fold 4 took 1.3311150074005127 sec, using 41 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7408, Validation Loss: 0.6512
	--> Epoch [2/100], Loss: 0.7286, Validation Loss: 0.6322
	--> Epoch [3/100], Loss: 0.6943, Validation Loss: 0.6157
	--> Epoch [4/100], Loss: 0.6869, Validation Loss: 0.6014
	--> Epoch [5/100], Loss: 0.6423, Validation Loss: 0.5870
	--> Epoch [6/100], Loss: 0.6737, Validation Loss: 0.5740
	--> Epoch [7/100], Loss: 0.5464, Validation Loss: 0.5687
	--> Epoch [8/100], Loss: 0.5934, Validation Loss: 0.5577
	--> Epoch [9/100], Loss: 0.3667, Validation Loss: 0.5459
	--> Epoch [10/100], Loss: 0.4473, Validation Loss: 0.5386
	--> Epoch [11/100], Loss: 0.3362, Validation Loss: 0.5311
	--> Epoch [12/100], Loss: 0.5353, Validation Loss: 0.5301
	--> Epoch [13/100], Loss: 0.1675, Validation Loss: 0.5273
	--> Epoch [14/100], Loss: 0.1378, Validation Loss: 0.5256
	--> Epoch [15/100], Loss: 0.3028, Validation Loss: 0.5214
	--> Epoch [16/100], Loss: 0.2400, Validation Loss: 0.5173
	--> Epoch [17/100], Loss: 0.2309, Validation Loss: 0.5135
	--> Epoch [18/100], Loss: 0.4155, Validation Loss: 0.5102
	--> Epoch [19/100], Loss: 0.4554, Validation Loss: 0.5054
	--> Epoch [20/100], Loss: 0.5956, Validation Loss: 0.5036
	--> Epoch [21/100], Loss: 0.2465, Validation Loss: 0.5010
	--> Epoch [22/100], Loss: 0.2395, Validation Loss: 0.4980
	--> Epoch [23/100], Loss: 0.2325, Validation Loss: 0.5003
	--> Epoch [24/100], Loss: 0.0404, Validation Loss: 0.4946
	--> Epoch [25/100], Loss: 0.1976, Validation Loss: 0.4915
	--> Epoch [26/100], Loss: 0.0336, Validation Loss: 0.4917
	--> Epoch [27/100], Loss: 0.0307, Validation Loss: 0.4932
	--> Epoch [28/100], Loss: 0.3958, Validation Loss: 0.4877
	--> Epoch [29/100], Loss: 0.2089, Validation Loss: 0.4844
	--> Epoch [30/100], Loss: 0.2054, Validation Loss: 0.4811
	--> Epoch [31/100], Loss: 0.1854, Validation Loss: 0.4824
	--> Epoch [32/100], Loss: 0.1836, Validation Loss: 0.4804
	--> Epoch [33/100], Loss: 0.3582, Validation Loss: 0.4844
	--> Epoch [34/100], Loss: 0.3689, Validation Loss: 0.4851
	--> Epoch [35/100], Loss: 0.1893, Validation Loss: 0.4855
Early stopping
	--> Training for Fold 5 took 1.0966603755950928 sec, using 35 epochs

Median number of epochs used: 41 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/41], Loss: 0.7848
	--> Final training Epoch [2/41], Loss: 0.4748
	--> Final training Epoch [3/41], Loss: 0.4572
	--> Final training Epoch [4/41], Loss: 0.3718
	--> Final training Epoch [5/41], Loss: 0.2566
	--> Final training Epoch [6/41], Loss: 0.3804
	--> Final training Epoch [7/41], Loss: 0.1518
	--> Final training Epoch [8/41], Loss: 0.3065
	--> Final training Epoch [9/41], Loss: 0.0937
	--> Final training Epoch [10/41], Loss: 0.0924
	--> Final training Epoch [11/41], Loss: 0.1386
	--> Final training Epoch [12/41], Loss: 0.1504
	--> Final training Epoch [13/41], Loss: 0.0529
	--> Final training Epoch [14/41], Loss: 0.0792
	--> Final training Epoch [15/41], Loss: 0.0522
	--> Final training Epoch [16/41], Loss: 0.0248
	--> Final training Epoch [17/41], Loss: 0.0476
	--> Final training Epoch [18/41], Loss: 0.0971
	--> Final training Epoch [19/41], Loss: 0.0199
	--> Final training Epoch [20/41], Loss: 0.0093
	--> Final training Epoch [21/41], Loss: 0.0263
	--> Final training Epoch [22/41], Loss: 0.0094
	--> Final training Epoch [23/41], Loss: 0.0430
	--> Final training Epoch [24/41], Loss: 0.0264
	--> Final training Epoch [25/41], Loss: 0.0049
	--> Final training Epoch [26/41], Loss: 0.0037
	--> Final training Epoch [27/41], Loss: 0.0222
	--> Final training Epoch [28/41], Loss: 0.0205
	--> Final training Epoch [29/41], Loss: 0.0080
	--> Final training Epoch [30/41], Loss: 0.0120
	--> Final training Epoch [31/41], Loss: 0.1632
	--> Final training Epoch [32/41], Loss: 0.0096
	--> Final training Epoch [33/41], Loss: 0.0192
	--> Final training Epoch [34/41], Loss: 0.0174
	--> Final training Epoch [35/41], Loss: 0.0253
	--> Final training Epoch [36/41], Loss: 0.0163
	--> Final training Epoch [37/41], Loss: 0.0175
	--> Final training Epoch [38/41], Loss: 0.0097
	--> Final training Epoch [39/41], Loss: 0.0422
	--> Final training Epoch [40/41], Loss: 0.0128
	--> Final training Epoch [41/41], Loss: 0.1271

Final training took 1.4986650943756104 sec

TESTING
	--> Testing took 0.0126 sec
	--> Final Accuracy: 0.8261
	--> Final Loss: 0.8682
	--> Final Precision: 0.8000
	--> Final Recall: 0.9231
	--> Final F1 Score: 0.8571
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8819, Validation Loss: 0.3088,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3253,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.3575,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.3391,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8608, Validation Loss: 0.3782,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7836, Validation Loss: 0.3794,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3677,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7848, Validation Loss: 0.4194,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3543,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3365,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7725, Validation Loss: 0.4002,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.3476,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.3768,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.3493,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.3336,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.4135,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8392, Validation Loss: 0.3721,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6183, Validation Loss: 0.6787
	--> Epoch [2/100], Loss: 0.6632, Validation Loss: 0.6634
	--> Epoch [3/100], Loss: 0.6856, Validation Loss: 0.6496
	--> Epoch [4/100], Loss: 0.6903, Validation Loss: 0.6323
	--> Epoch [5/100], Loss: 0.6893, Validation Loss: 0.6148
	--> Epoch [6/100], Loss: 0.6132, Validation Loss: 0.5944
	--> Epoch [7/100], Loss: 0.4193, Validation Loss: 0.5806
	--> Epoch [8/100], Loss: 0.5324, Validation Loss: 0.5630
	--> Epoch [9/100], Loss: 0.5025, Validation Loss: 0.5465
	--> Epoch [10/100], Loss: 0.5490, Validation Loss: 0.5334
	--> Epoch [11/100], Loss: 0.5159, Validation Loss: 0.5148
	--> Epoch [12/100], Loss: 0.4243, Validation Loss: 0.5068
	--> Epoch [13/100], Loss: 0.4448, Validation Loss: 0.4910
	--> Epoch [14/100], Loss: 0.6944, Validation Loss: 0.4769
	--> Epoch [15/100], Loss: 0.4757, Validation Loss: 0.4646
	--> Epoch [16/100], Loss: 0.3869, Validation Loss: 0.4543
	--> Epoch [17/100], Loss: 0.4401, Validation Loss: 0.4390
	--> Epoch [18/100], Loss: 0.4413, Validation Loss: 0.4287
	--> Epoch [19/100], Loss: 0.1081, Validation Loss: 0.4223
	--> Epoch [20/100], Loss: 0.0897, Validation Loss: 0.4095
	--> Epoch [21/100], Loss: 0.0697, Validation Loss: 0.4002
	--> Epoch [22/100], Loss: 0.1085, Validation Loss: 0.3910
	--> Epoch [23/100], Loss: 0.3472, Validation Loss: 0.3828
	--> Epoch [24/100], Loss: 0.6939, Validation Loss: 0.3784
	--> Epoch [25/100], Loss: 0.1523, Validation Loss: 0.3704
	--> Epoch [26/100], Loss: 0.0573, Validation Loss: 0.3643
	--> Epoch [27/100], Loss: 0.6938, Validation Loss: 0.3597
	--> Epoch [28/100], Loss: 0.3511, Validation Loss: 0.3552
	--> Epoch [29/100], Loss: 0.0234, Validation Loss: 0.3490
	--> Epoch [30/100], Loss: 0.0142, Validation Loss: 0.3460
	--> Epoch [31/100], Loss: 0.2469, Validation Loss: 0.3416
	--> Epoch [32/100], Loss: 0.1328, Validation Loss: 0.3435
	--> Epoch [33/100], Loss: 0.0116, Validation Loss: 0.3452
	--> Epoch [34/100], Loss: 0.3325, Validation Loss: 0.3457
Early stopping
	--> Training for Fold 1 took 0.9109964370727539 sec, using 34 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7608, Validation Loss: 0.6912
	--> Epoch [2/100], Loss: 0.6993, Validation Loss: 0.6467
	--> Epoch [3/100], Loss: 0.3282, Validation Loss: 0.6140
	--> Epoch [4/100], Loss: 0.1843, Validation Loss: 0.5979
	--> Epoch [5/100], Loss: 0.7177, Validation Loss: 0.5858
	--> Epoch [6/100], Loss: 0.4863, Validation Loss: 0.5736
	--> Epoch [7/100], Loss: 0.4901, Validation Loss: 0.5408
	--> Epoch [8/100], Loss: 0.5928, Validation Loss: 0.5204
	--> Epoch [9/100], Loss: 0.2822, Validation Loss: 0.5002
	--> Epoch [10/100], Loss: 0.3399, Validation Loss: 0.4898
	--> Epoch [11/100], Loss: 0.4021, Validation Loss: 0.4677
	--> Epoch [12/100], Loss: 0.3083, Validation Loss: 0.4554
	--> Epoch [13/100], Loss: 0.2906, Validation Loss: 0.4438
	--> Epoch [14/100], Loss: 0.3311, Validation Loss: 0.4386
	--> Epoch [15/100], Loss: 0.1869, Validation Loss: 0.4246
	--> Epoch [16/100], Loss: 0.2970, Validation Loss: 0.4144
	--> Epoch [17/100], Loss: 0.0238, Validation Loss: 0.4080
	--> Epoch [18/100], Loss: 0.0400, Validation Loss: 0.3928
	--> Epoch [19/100], Loss: 0.5327, Validation Loss: 0.3779
	--> Epoch [20/100], Loss: 0.0421, Validation Loss: 0.3707
	--> Epoch [21/100], Loss: 0.4853, Validation Loss: 0.3661
	--> Epoch [22/100], Loss: 0.0018, Validation Loss: 0.3513
	--> Epoch [23/100], Loss: 0.2786, Validation Loss: 0.3521
	--> Epoch [24/100], Loss: 0.4674, Validation Loss: 0.3434
	--> Epoch [25/100], Loss: 0.4138, Validation Loss: 0.3457
	--> Epoch [26/100], Loss: 0.0437, Validation Loss: 0.3448
	--> Epoch [27/100], Loss: 0.4684, Validation Loss: 0.3378
	--> Epoch [28/100], Loss: 0.4070, Validation Loss: 0.3326
	--> Epoch [29/100], Loss: 0.0522, Validation Loss: 0.3207
	--> Epoch [30/100], Loss: 0.4630, Validation Loss: 0.3159
	--> Epoch [31/100], Loss: 0.0002, Validation Loss: 0.3134
	--> Epoch [32/100], Loss: 0.4571, Validation Loss: 0.3113
	--> Epoch [33/100], Loss: 0.0310, Validation Loss: 0.3091
	--> Epoch [34/100], Loss: 0.0347, Validation Loss: 0.3073
	--> Epoch [35/100], Loss: 0.0102, Validation Loss: 0.3042
	--> Epoch [36/100], Loss: 0.0210, Validation Loss: 0.3012
	--> Epoch [37/100], Loss: 0.2580, Validation Loss: 0.3006
	--> Epoch [38/100], Loss: 0.0043, Validation Loss: 0.2961
	--> Epoch [39/100], Loss: 0.0044, Validation Loss: 0.2887
	--> Epoch [40/100], Loss: 0.2546, Validation Loss: 0.2906
	--> Epoch [41/100], Loss: 0.0130, Validation Loss: 0.2802
	--> Epoch [42/100], Loss: 0.0032, Validation Loss: 0.2791
	--> Epoch [43/100], Loss: 0.0028, Validation Loss: 0.2775
	--> Epoch [44/100], Loss: 0.4626, Validation Loss: 0.2751
	--> Epoch [45/100], Loss: 0.0018, Validation Loss: 0.2806
	--> Epoch [46/100], Loss: 0.0045, Validation Loss: 0.2790
	--> Epoch [47/100], Loss: 0.0027, Validation Loss: 0.2816
Early stopping
	--> Training for Fold 2 took 1.302825689315796 sec, using 47 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5437, Validation Loss: 0.6721
	--> Epoch [2/100], Loss: 0.7208, Validation Loss: 0.6490
	--> Epoch [3/100], Loss: 0.4830, Validation Loss: 0.6296
	--> Epoch [4/100], Loss: 0.5144, Validation Loss: 0.6111
	--> Epoch [5/100], Loss: 0.5565, Validation Loss: 0.5919
	--> Epoch [6/100], Loss: 0.5278, Validation Loss: 0.5720
	--> Epoch [7/100], Loss: 0.4208, Validation Loss: 0.5528
	--> Epoch [8/100], Loss: 0.5288, Validation Loss: 0.5368
	--> Epoch [9/100], Loss: 0.1402, Validation Loss: 0.5282
	--> Epoch [10/100], Loss: 0.4080, Validation Loss: 0.5153
	--> Epoch [11/100], Loss: 0.4102, Validation Loss: 0.4927
	--> Epoch [12/100], Loss: 0.3120, Validation Loss: 0.4794
	--> Epoch [13/100], Loss: 0.3229, Validation Loss: 0.4778
	--> Epoch [14/100], Loss: 0.1503, Validation Loss: 0.4634
	--> Epoch [15/100], Loss: 0.3713, Validation Loss: 0.4520
	--> Epoch [16/100], Loss: 0.3069, Validation Loss: 0.4380
	--> Epoch [17/100], Loss: 0.3761, Validation Loss: 0.4334
	--> Epoch [18/100], Loss: 0.4290, Validation Loss: 0.4320
	--> Epoch [19/100], Loss: 0.0373, Validation Loss: 0.4253
	--> Epoch [20/100], Loss: 0.4207, Validation Loss: 0.4131
	--> Epoch [21/100], Loss: 0.3327, Validation Loss: 0.4044
	--> Epoch [22/100], Loss: 0.4093, Validation Loss: 0.4006
	--> Epoch [23/100], Loss: 0.0417, Validation Loss: 0.3922
	--> Epoch [24/100], Loss: 0.0103, Validation Loss: 0.3851
	--> Epoch [25/100], Loss: 0.4129, Validation Loss: 0.3753
	--> Epoch [26/100], Loss: 0.3979, Validation Loss: 0.3712
	--> Epoch [27/100], Loss: 0.3143, Validation Loss: 0.3774
	--> Epoch [28/100], Loss: 0.6979, Validation Loss: 0.3703
	--> Epoch [29/100], Loss: 0.5457, Validation Loss: 0.3645
	--> Epoch [30/100], Loss: 0.3984, Validation Loss: 0.3602
	--> Epoch [31/100], Loss: 0.0716, Validation Loss: 0.3610
	--> Epoch [32/100], Loss: 0.4061, Validation Loss: 0.3576
	--> Epoch [33/100], Loss: 0.0080, Validation Loss: 0.3512
	--> Epoch [34/100], Loss: 0.4067, Validation Loss: 0.3512
	--> Epoch [35/100], Loss: 0.2982, Validation Loss: 0.3481
	--> Epoch [36/100], Loss: 0.0207, Validation Loss: 0.3479
	--> Epoch [37/100], Loss: 0.6989, Validation Loss: 0.3482
	--> Epoch [38/100], Loss: 0.6989, Validation Loss: 0.3462
	--> Epoch [39/100], Loss: 0.2946, Validation Loss: 0.3419
	--> Epoch [40/100], Loss: 0.0364, Validation Loss: 0.3372
	--> Epoch [41/100], Loss: 0.0048, Validation Loss: 0.3344
	--> Epoch [42/100], Loss: 0.0040, Validation Loss: 0.3366
	--> Epoch [43/100], Loss: 0.4054, Validation Loss: 0.3329
	--> Epoch [44/100], Loss: 0.0041, Validation Loss: 0.3308
	--> Epoch [45/100], Loss: 0.0527, Validation Loss: 0.3332
	--> Epoch [46/100], Loss: 0.0031, Validation Loss: 0.3346
	--> Epoch [47/100], Loss: 0.3009, Validation Loss: 0.3324
Early stopping
	--> Training for Fold 3 took 1.388120412826538 sec, using 47 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7355, Validation Loss: 0.7512
	--> Epoch [2/100], Loss: 0.7139, Validation Loss: 0.7283
	--> Epoch [3/100], Loss: 0.6846, Validation Loss: 0.6984
	--> Epoch [4/100], Loss: 0.7881, Validation Loss: 0.6866
	--> Epoch [5/100], Loss: 0.6787, Validation Loss: 0.6618
	--> Epoch [6/100], Loss: 0.6243, Validation Loss: 0.6449
	--> Epoch [7/100], Loss: 0.4806, Validation Loss: 0.6275
	--> Epoch [8/100], Loss: 0.5768, Validation Loss: 0.6130
	--> Epoch [9/100], Loss: 0.6030, Validation Loss: 0.5982
	--> Epoch [10/100], Loss: 0.3764, Validation Loss: 0.5743
	--> Epoch [11/100], Loss: 0.2436, Validation Loss: 0.5464
	--> Epoch [12/100], Loss: 0.3179, Validation Loss: 0.5289
	--> Epoch [13/100], Loss: 0.1664, Validation Loss: 0.5183
	--> Epoch [14/100], Loss: 0.1237, Validation Loss: 0.5076
	--> Epoch [15/100], Loss: 0.4859, Validation Loss: 0.4986
	--> Epoch [16/100], Loss: 0.2452, Validation Loss: 0.4816
	--> Epoch [17/100], Loss: 0.1123, Validation Loss: 0.4675
	--> Epoch [18/100], Loss: 0.1793, Validation Loss: 0.4521
	--> Epoch [19/100], Loss: 0.3291, Validation Loss: 0.4415
	--> Epoch [20/100], Loss: 0.6956, Validation Loss: 0.4307
	--> Epoch [21/100], Loss: 0.2464, Validation Loss: 0.4216
	--> Epoch [22/100], Loss: 0.4729, Validation Loss: 0.4314
	--> Epoch [23/100], Loss: 0.2435, Validation Loss: 0.4282
	--> Epoch [24/100], Loss: 0.4625, Validation Loss: 0.4239
Early stopping
	--> Training for Fold 4 took 0.6895120143890381 sec, using 24 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8990, Validation Loss: 0.6087
	--> Epoch [2/100], Loss: 0.7283, Validation Loss: 0.5939
	--> Epoch [3/100], Loss: 0.6693, Validation Loss: 0.5886
	--> Epoch [4/100], Loss: 0.5450, Validation Loss: 0.5849
	--> Epoch [5/100], Loss: 0.5287, Validation Loss: 0.5818
	--> Epoch [6/100], Loss: 0.6583, Validation Loss: 0.5886
	--> Epoch [7/100], Loss: 0.4129, Validation Loss: 0.5961
	--> Epoch [8/100], Loss: 0.3467, Validation Loss: 0.5997
Early stopping
	--> Training for Fold 5 took 0.2414994239807129 sec, using 8 epochs

Median number of epochs used: 34 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/34], Loss: 0.6049
	--> Final training Epoch [2/34], Loss: 0.5124
	--> Final training Epoch [3/34], Loss: 0.3648
	--> Final training Epoch [4/34], Loss: 0.4868
	--> Final training Epoch [5/34], Loss: 0.6008
	--> Final training Epoch [6/34], Loss: 0.5869
	--> Final training Epoch [7/34], Loss: 0.8877
	--> Final training Epoch [8/34], Loss: 0.3676
	--> Final training Epoch [9/34], Loss: 0.5303
	--> Final training Epoch [10/34], Loss: 0.3309
	--> Final training Epoch [11/34], Loss: 0.5782
	--> Final training Epoch [12/34], Loss: 0.2583
	--> Final training Epoch [13/34], Loss: 0.4235
	--> Final training Epoch [14/34], Loss: 0.2845
	--> Final training Epoch [15/34], Loss: 0.5636
	--> Final training Epoch [16/34], Loss: 0.4607
	--> Final training Epoch [17/34], Loss: 0.4243
	--> Final training Epoch [18/34], Loss: 0.1402
	--> Final training Epoch [19/34], Loss: 0.4169
	--> Final training Epoch [20/34], Loss: 0.5940
	--> Final training Epoch [21/34], Loss: 0.3462
	--> Final training Epoch [22/34], Loss: 0.3966
	--> Final training Epoch [23/34], Loss: 0.3340
	--> Final training Epoch [24/34], Loss: 0.2283
	--> Final training Epoch [25/34], Loss: 0.4055
	--> Final training Epoch [26/34], Loss: 0.3904
	--> Final training Epoch [27/34], Loss: 0.1227
	--> Final training Epoch [28/34], Loss: 0.2661
	--> Final training Epoch [29/34], Loss: 0.3881
	--> Final training Epoch [30/34], Loss: 0.2284
	--> Final training Epoch [31/34], Loss: 0.1903
	--> Final training Epoch [32/34], Loss: 0.2500
	--> Final training Epoch [33/34], Loss: 0.2233
	--> Final training Epoch [34/34], Loss: 0.2315

Final training took 1.1310577392578125 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.7816
	--> Final Precision: 0.7778
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6364
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.9023, Validation Loss: 0.3485,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3485
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 0.4286,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3485

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6262, Validation Loss: 0.6295
	--> Epoch [2/100], Loss: 0.4893, Validation Loss: 0.6021
	--> Epoch [3/100], Loss: 0.5306, Validation Loss: 0.5805
	--> Epoch [4/100], Loss: 0.4171, Validation Loss: 0.5569
	--> Epoch [5/100], Loss: 0.4610, Validation Loss: 0.5360
	--> Epoch [6/100], Loss: 0.5003, Validation Loss: 0.5197
	--> Epoch [7/100], Loss: 0.4298, Validation Loss: 0.5077
	--> Epoch [8/100], Loss: 0.3788, Validation Loss: 0.4938
	--> Epoch [9/100], Loss: 0.3254, Validation Loss: 0.4778
	--> Epoch [10/100], Loss: 0.3568, Validation Loss: 0.4636
	--> Epoch [11/100], Loss: 0.2509, Validation Loss: 0.4500
	--> Epoch [12/100], Loss: 0.3905, Validation Loss: 0.4376
	--> Epoch [13/100], Loss: 0.2025, Validation Loss: 0.4298
	--> Epoch [14/100], Loss: 0.2761, Validation Loss: 0.4228
	--> Epoch [15/100], Loss: 0.3630, Validation Loss: 0.4146
	--> Epoch [16/100], Loss: 0.2973, Validation Loss: 0.4069
	--> Epoch [17/100], Loss: 0.2953, Validation Loss: 0.3966
	--> Epoch [18/100], Loss: 0.2176, Validation Loss: 0.3876
	--> Epoch [19/100], Loss: 0.1870, Validation Loss: 0.3826
	--> Epoch [20/100], Loss: 0.1780, Validation Loss: 0.3759
	--> Epoch [21/100], Loss: 0.1655, Validation Loss: 0.3701
	--> Epoch [22/100], Loss: 0.2775, Validation Loss: 0.3623
	--> Epoch [23/100], Loss: 0.2765, Validation Loss: 0.3562
	--> Epoch [24/100], Loss: 0.2074, Validation Loss: 0.3516
	--> Epoch [25/100], Loss: 0.0879, Validation Loss: 0.3435
	--> Epoch [26/100], Loss: 0.0921, Validation Loss: 0.3377
	--> Epoch [27/100], Loss: 0.0489, Validation Loss: 0.3319
	--> Epoch [28/100], Loss: 0.2942, Validation Loss: 0.3264
	--> Epoch [29/100], Loss: 0.1274, Validation Loss: 0.3251
	--> Epoch [30/100], Loss: 0.1798, Validation Loss: 0.3216
	--> Epoch [31/100], Loss: 0.0653, Validation Loss: 0.3177
	--> Epoch [32/100], Loss: 0.1842, Validation Loss: 0.3133
	--> Epoch [33/100], Loss: 0.1396, Validation Loss: 0.3075
	--> Epoch [34/100], Loss: 0.1570, Validation Loss: 0.3081
	--> Epoch [35/100], Loss: 0.0489, Validation Loss: 0.3054
	--> Epoch [36/100], Loss: 0.0920, Validation Loss: 0.3034
	--> Epoch [37/100], Loss: 0.0268, Validation Loss: 0.3014
	--> Epoch [38/100], Loss: 0.1578, Validation Loss: 0.3011
	--> Epoch [39/100], Loss: 0.1372, Validation Loss: 0.2999
	--> Epoch [40/100], Loss: 0.2016, Validation Loss: 0.2970
	--> Epoch [41/100], Loss: 0.0101, Validation Loss: 0.2968
	--> Epoch [42/100], Loss: 0.1143, Validation Loss: 0.2946
	--> Epoch [43/100], Loss: 0.0711, Validation Loss: 0.2937
	--> Epoch [44/100], Loss: 0.0877, Validation Loss: 0.2936
	--> Epoch [45/100], Loss: 0.0837, Validation Loss: 0.2911
	--> Epoch [46/100], Loss: 0.0477, Validation Loss: 0.2881
	--> Epoch [47/100], Loss: 0.0230, Validation Loss: 0.2863
	--> Epoch [48/100], Loss: 0.0328, Validation Loss: 0.2865
	--> Epoch [49/100], Loss: 0.0380, Validation Loss: 0.2853
	--> Epoch [50/100], Loss: 0.0833, Validation Loss: 0.2834
	--> Epoch [51/100], Loss: 0.0762, Validation Loss: 0.2825
	--> Epoch [52/100], Loss: 0.0331, Validation Loss: 0.2820
	--> Epoch [53/100], Loss: 0.0131, Validation Loss: 0.2809
	--> Epoch [54/100], Loss: 0.0208, Validation Loss: 0.2798
	--> Epoch [55/100], Loss: 0.0539, Validation Loss: 0.2793
	--> Epoch [56/100], Loss: 0.0125, Validation Loss: 0.2735
	--> Epoch [57/100], Loss: 0.0326, Validation Loss: 0.2741
	--> Epoch [58/100], Loss: 0.0081, Validation Loss: 0.2733
	--> Epoch [59/100], Loss: 0.1170, Validation Loss: 0.2715
	--> Epoch [60/100], Loss: 0.0402, Validation Loss: 0.2701
	--> Epoch [61/100], Loss: 0.0079, Validation Loss: 0.2691
	--> Epoch [62/100], Loss: 0.0225, Validation Loss: 0.2664
	--> Epoch [63/100], Loss: 0.0225, Validation Loss: 0.2657
	--> Epoch [64/100], Loss: 0.1045, Validation Loss: 0.2623
	--> Epoch [65/100], Loss: 0.0097, Validation Loss: 0.2609
	--> Epoch [66/100], Loss: 0.0204, Validation Loss: 0.2597
	--> Epoch [67/100], Loss: 0.0107, Validation Loss: 0.2602
	--> Epoch [68/100], Loss: 0.0172, Validation Loss: 0.2581
	--> Epoch [69/100], Loss: 0.0948, Validation Loss: 0.2557
	--> Epoch [70/100], Loss: 0.0204, Validation Loss: 0.2536
	--> Epoch [71/100], Loss: 0.0326, Validation Loss: 0.2533
	--> Epoch [72/100], Loss: 0.1092, Validation Loss: 0.2546
	--> Epoch [73/100], Loss: 0.0057, Validation Loss: 0.2511
	--> Epoch [74/100], Loss: 0.0151, Validation Loss: 0.2506
	--> Epoch [75/100], Loss: 0.0946, Validation Loss: 0.2514
	--> Epoch [76/100], Loss: 0.0042, Validation Loss: 0.2526
	--> Epoch [77/100], Loss: 0.0184, Validation Loss: 0.2534
Early stopping
	--> Training for Fold 1 took 1.0259323120117188 sec, using 77 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8569, Validation Loss: 0.6019
	--> Epoch [2/100], Loss: 0.7822, Validation Loss: 0.5801
	--> Epoch [3/100], Loss: 0.7245, Validation Loss: 0.5590
	--> Epoch [4/100], Loss: 0.6800, Validation Loss: 0.5392
	--> Epoch [5/100], Loss: 0.6787, Validation Loss: 0.5206
	--> Epoch [6/100], Loss: 0.5885, Validation Loss: 0.5011
	--> Epoch [7/100], Loss: 0.5570, Validation Loss: 0.4793
	--> Epoch [8/100], Loss: 0.5434, Validation Loss: 0.4638
	--> Epoch [9/100], Loss: 0.4374, Validation Loss: 0.4429
	--> Epoch [10/100], Loss: 0.4020, Validation Loss: 0.4231
	--> Epoch [11/100], Loss: 0.3773, Validation Loss: 0.4045
	--> Epoch [12/100], Loss: 0.4048, Validation Loss: 0.3878
	--> Epoch [13/100], Loss: 0.2646, Validation Loss: 0.3727
	--> Epoch [14/100], Loss: 0.3346, Validation Loss: 0.3599
	--> Epoch [15/100], Loss: 0.2801, Validation Loss: 0.3496
	--> Epoch [16/100], Loss: 0.2475, Validation Loss: 0.3393
	--> Epoch [17/100], Loss: 0.2249, Validation Loss: 0.3288
	--> Epoch [18/100], Loss: 0.1542, Validation Loss: 0.3162
	--> Epoch [19/100], Loss: 0.2978, Validation Loss: 0.3071
	--> Epoch [20/100], Loss: 0.1906, Validation Loss: 0.2992
	--> Epoch [21/100], Loss: 0.1820, Validation Loss: 0.2900
	--> Epoch [22/100], Loss: 0.1593, Validation Loss: 0.2822
	--> Epoch [23/100], Loss: 0.1105, Validation Loss: 0.2755
	--> Epoch [24/100], Loss: 0.3803, Validation Loss: 0.2692
	--> Epoch [25/100], Loss: 0.1608, Validation Loss: 0.2599
	--> Epoch [26/100], Loss: 0.1325, Validation Loss: 0.2546
	--> Epoch [27/100], Loss: 0.0956, Validation Loss: 0.2506
	--> Epoch [28/100], Loss: 0.0629, Validation Loss: 0.2450
	--> Epoch [29/100], Loss: 0.1774, Validation Loss: 0.2413
	--> Epoch [30/100], Loss: 0.1391, Validation Loss: 0.2352
	--> Epoch [31/100], Loss: 0.1161, Validation Loss: 0.2305
	--> Epoch [32/100], Loss: 0.0569, Validation Loss: 0.2263
	--> Epoch [33/100], Loss: 0.0855, Validation Loss: 0.2210
	--> Epoch [34/100], Loss: 0.0782, Validation Loss: 0.2184
	--> Epoch [35/100], Loss: 0.0992, Validation Loss: 0.2149
	--> Epoch [36/100], Loss: 0.0777, Validation Loss: 0.2096
	--> Epoch [37/100], Loss: 0.1080, Validation Loss: 0.2052
	--> Epoch [38/100], Loss: 0.0646, Validation Loss: 0.2010
	--> Epoch [39/100], Loss: 0.1094, Validation Loss: 0.1955
	--> Epoch [40/100], Loss: 0.1127, Validation Loss: 0.1920
	--> Epoch [41/100], Loss: 0.0589, Validation Loss: 0.1895
	--> Epoch [42/100], Loss: 0.1330, Validation Loss: 0.1866
	--> Epoch [43/100], Loss: 0.0561, Validation Loss: 0.1845
	--> Epoch [44/100], Loss: 0.1256, Validation Loss: 0.1838
	--> Epoch [45/100], Loss: 0.1223, Validation Loss: 0.1825
	--> Epoch [46/100], Loss: 0.1615, Validation Loss: 0.1781
	--> Epoch [47/100], Loss: 0.0487, Validation Loss: 0.1761
	--> Epoch [48/100], Loss: 0.0947, Validation Loss: 0.1761
	--> Epoch [49/100], Loss: 0.0442, Validation Loss: 0.1741
	--> Epoch [50/100], Loss: 0.0490, Validation Loss: 0.1723
	--> Epoch [51/100], Loss: 0.0190, Validation Loss: 0.1717
	--> Epoch [52/100], Loss: 0.0427, Validation Loss: 0.1707
	--> Epoch [53/100], Loss: 0.0184, Validation Loss: 0.1707
	--> Epoch [54/100], Loss: 0.1069, Validation Loss: 0.1695
	--> Epoch [55/100], Loss: 0.0214, Validation Loss: 0.1678
	--> Epoch [56/100], Loss: 0.0323, Validation Loss: 0.1637
	--> Epoch [57/100], Loss: 0.0378, Validation Loss: 0.1616
	--> Epoch [58/100], Loss: 0.0385, Validation Loss: 0.1596
	--> Epoch [59/100], Loss: 0.0792, Validation Loss: 0.1577
	--> Epoch [60/100], Loss: 0.0441, Validation Loss: 0.1589
	--> Epoch [61/100], Loss: 0.0271, Validation Loss: 0.1565
	--> Epoch [62/100], Loss: 0.0297, Validation Loss: 0.1556
	--> Epoch [63/100], Loss: 0.0384, Validation Loss: 0.1547
	--> Epoch [64/100], Loss: 0.0208, Validation Loss: 0.1541
	--> Epoch [65/100], Loss: 0.0898, Validation Loss: 0.1532
	--> Epoch [66/100], Loss: 0.0874, Validation Loss: 0.1530
	--> Epoch [67/100], Loss: 0.1162, Validation Loss: 0.1522
	--> Epoch [68/100], Loss: 0.0101, Validation Loss: 0.1514
	--> Epoch [69/100], Loss: 0.0293, Validation Loss: 0.1509
	--> Epoch [70/100], Loss: 0.0282, Validation Loss: 0.1517
	--> Epoch [71/100], Loss: 0.0235, Validation Loss: 0.1504
	--> Epoch [72/100], Loss: 0.0377, Validation Loss: 0.1478
	--> Epoch [73/100], Loss: 0.0138, Validation Loss: 0.1493
	--> Epoch [74/100], Loss: 0.0200, Validation Loss: 0.1502
	--> Epoch [75/100], Loss: 0.1006, Validation Loss: 0.1495
Early stopping
	--> Training for Fold 2 took 0.9789848327636719 sec, using 75 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7858, Validation Loss: 0.6087
	--> Epoch [2/100], Loss: 0.8016, Validation Loss: 0.5927
	--> Epoch [3/100], Loss: 0.8341, Validation Loss: 0.5819
	--> Epoch [4/100], Loss: 0.7416, Validation Loss: 0.5736
	--> Epoch [5/100], Loss: 0.7338, Validation Loss: 0.5632
	--> Epoch [6/100], Loss: 0.7150, Validation Loss: 0.5519
	--> Epoch [7/100], Loss: 0.6863, Validation Loss: 0.5395
	--> Epoch [8/100], Loss: 0.6972, Validation Loss: 0.5288
	--> Epoch [9/100], Loss: 0.6476, Validation Loss: 0.5182
	--> Epoch [10/100], Loss: 0.5978, Validation Loss: 0.5059
	--> Epoch [11/100], Loss: 0.5766, Validation Loss: 0.4927
	--> Epoch [12/100], Loss: 0.5783, Validation Loss: 0.4817
	--> Epoch [13/100], Loss: 0.5572, Validation Loss: 0.4683
	--> Epoch [14/100], Loss: 0.5159, Validation Loss: 0.4586
	--> Epoch [15/100], Loss: 0.5793, Validation Loss: 0.4506
	--> Epoch [16/100], Loss: 0.5078, Validation Loss: 0.4412
	--> Epoch [17/100], Loss: 0.4067, Validation Loss: 0.4290
	--> Epoch [18/100], Loss: 0.4435, Validation Loss: 0.4187
	--> Epoch [19/100], Loss: 0.4790, Validation Loss: 0.4094
	--> Epoch [20/100], Loss: 0.4314, Validation Loss: 0.4017
	--> Epoch [21/100], Loss: 0.4107, Validation Loss: 0.3944
	--> Epoch [22/100], Loss: 0.3340, Validation Loss: 0.3871
	--> Epoch [23/100], Loss: 0.4325, Validation Loss: 0.3796
	--> Epoch [24/100], Loss: 0.3456, Validation Loss: 0.3718
	--> Epoch [25/100], Loss: 0.3436, Validation Loss: 0.3641
	--> Epoch [26/100], Loss: 0.3310, Validation Loss: 0.3576
	--> Epoch [27/100], Loss: 0.3101, Validation Loss: 0.3513
	--> Epoch [28/100], Loss: 0.3427, Validation Loss: 0.3479
	--> Epoch [29/100], Loss: 0.2796, Validation Loss: 0.3433
	--> Epoch [30/100], Loss: 0.3388, Validation Loss: 0.3415
	--> Epoch [31/100], Loss: 0.3366, Validation Loss: 0.3367
	--> Epoch [32/100], Loss: 0.3366, Validation Loss: 0.3312
	--> Epoch [33/100], Loss: 0.2723, Validation Loss: 0.3257
	--> Epoch [34/100], Loss: 0.3317, Validation Loss: 0.3233
	--> Epoch [35/100], Loss: 0.3221, Validation Loss: 0.3199
	--> Epoch [36/100], Loss: 0.3037, Validation Loss: 0.3160
	--> Epoch [37/100], Loss: 0.2389, Validation Loss: 0.3128
	--> Epoch [38/100], Loss: 0.2296, Validation Loss: 0.3094
	--> Epoch [39/100], Loss: 0.2894, Validation Loss: 0.3080
	--> Epoch [40/100], Loss: 0.0961, Validation Loss: 0.3039
	--> Epoch [41/100], Loss: 0.3211, Validation Loss: 0.3018
	--> Epoch [42/100], Loss: 0.1019, Validation Loss: 0.2991
	--> Epoch [43/100], Loss: 0.2583, Validation Loss: 0.2971
	--> Epoch [44/100], Loss: 0.1283, Validation Loss: 0.2944
	--> Epoch [45/100], Loss: 0.1902, Validation Loss: 0.2937
	--> Epoch [46/100], Loss: 0.1884, Validation Loss: 0.2927
	--> Epoch [47/100], Loss: 0.1749, Validation Loss: 0.2894
	--> Epoch [48/100], Loss: 0.1712, Validation Loss: 0.2885
	--> Epoch [49/100], Loss: 0.2776, Validation Loss: 0.2873
	--> Epoch [50/100], Loss: 0.2164, Validation Loss: 0.2844
	--> Epoch [51/100], Loss: 0.1730, Validation Loss: 0.2842
	--> Epoch [52/100], Loss: 0.0897, Validation Loss: 0.2826
	--> Epoch [53/100], Loss: 0.2983, Validation Loss: 0.2807
	--> Epoch [54/100], Loss: 0.2146, Validation Loss: 0.2807
	--> Epoch [55/100], Loss: 0.2122, Validation Loss: 0.2797
	--> Epoch [56/100], Loss: 0.2076, Validation Loss: 0.2770
	--> Epoch [57/100], Loss: 0.2593, Validation Loss: 0.2761
	--> Epoch [58/100], Loss: 0.2703, Validation Loss: 0.2743
	--> Epoch [59/100], Loss: 0.0422, Validation Loss: 0.2729
	--> Epoch [60/100], Loss: 0.2622, Validation Loss: 0.2724
	--> Epoch [61/100], Loss: 0.1430, Validation Loss: 0.2720
	--> Epoch [62/100], Loss: 0.1445, Validation Loss: 0.2710
	--> Epoch [63/100], Loss: 0.0894, Validation Loss: 0.2700
	--> Epoch [64/100], Loss: 0.0827, Validation Loss: 0.2683
	--> Epoch [65/100], Loss: 0.1386, Validation Loss: 0.2668
	--> Epoch [66/100], Loss: 0.1378, Validation Loss: 0.2662
	--> Epoch [67/100], Loss: 0.0791, Validation Loss: 0.2645
	--> Epoch [68/100], Loss: 0.2465, Validation Loss: 0.2640
	--> Epoch [69/100], Loss: 0.0772, Validation Loss: 0.2645
	--> Epoch [70/100], Loss: 0.1830, Validation Loss: 0.2626
	--> Epoch [71/100], Loss: 0.0741, Validation Loss: 0.2617
	--> Epoch [72/100], Loss: 0.1854, Validation Loss: 0.2609
	--> Epoch [73/100], Loss: 0.1238, Validation Loss: 0.2593
	--> Epoch [74/100], Loss: 0.1792, Validation Loss: 0.2569
	--> Epoch [75/100], Loss: 0.1779, Validation Loss: 0.2559
	--> Epoch [76/100], Loss: 0.1759, Validation Loss: 0.2549
	--> Epoch [77/100], Loss: 0.2905, Validation Loss: 0.2545
	--> Epoch [78/100], Loss: 0.1252, Validation Loss: 0.2535
	--> Epoch [79/100], Loss: 0.1163, Validation Loss: 0.2521
	--> Epoch [80/100], Loss: 0.2310, Validation Loss: 0.2512
	--> Epoch [81/100], Loss: 0.2290, Validation Loss: 0.2514
	--> Epoch [82/100], Loss: 0.1748, Validation Loss: 0.2511
	--> Epoch [83/100], Loss: 0.1740, Validation Loss: 0.2503
	--> Epoch [84/100], Loss: 0.2787, Validation Loss: 0.2501
	--> Epoch [85/100], Loss: 0.1712, Validation Loss: 0.2487
	--> Epoch [86/100], Loss: 0.2473, Validation Loss: 0.2490
	--> Epoch [87/100], Loss: 0.1167, Validation Loss: 0.2490
	--> Epoch [88/100], Loss: 0.1662, Validation Loss: 0.2456
	--> Epoch [89/100], Loss: 0.1154, Validation Loss: 0.2461
	--> Epoch [90/100], Loss: 0.2183, Validation Loss: 0.2480
	--> Epoch [91/100], Loss: 0.0619, Validation Loss: 0.2511
Early stopping
	--> Training for Fold 3 took 1.1792950630187988 sec, using 91 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7096, Validation Loss: 0.6091
	--> Epoch [2/100], Loss: 0.5853, Validation Loss: 0.5774
	--> Epoch [3/100], Loss: 0.5276, Validation Loss: 0.5530
	--> Epoch [4/100], Loss: 0.5179, Validation Loss: 0.5327
	--> Epoch [5/100], Loss: 0.4201, Validation Loss: 0.5070
	--> Epoch [6/100], Loss: 0.4000, Validation Loss: 0.4905
	--> Epoch [7/100], Loss: 0.4749, Validation Loss: 0.4753
	--> Epoch [8/100], Loss: 0.3302, Validation Loss: 0.4611
	--> Epoch [9/100], Loss: 0.2985, Validation Loss: 0.4493
	--> Epoch [10/100], Loss: 0.3094, Validation Loss: 0.4380
	--> Epoch [11/100], Loss: 0.3124, Validation Loss: 0.4271
	--> Epoch [12/100], Loss: 0.2780, Validation Loss: 0.4160
	--> Epoch [13/100], Loss: 0.2886, Validation Loss: 0.4074
	--> Epoch [14/100], Loss: 0.2200, Validation Loss: 0.4019
	--> Epoch [15/100], Loss: 0.2529, Validation Loss: 0.3962
	--> Epoch [16/100], Loss: 0.2989, Validation Loss: 0.3920
	--> Epoch [17/100], Loss: 0.1641, Validation Loss: 0.3839
	--> Epoch [18/100], Loss: 0.1699, Validation Loss: 0.3792
	--> Epoch [19/100], Loss: 0.1577, Validation Loss: 0.3787
	--> Epoch [20/100], Loss: 0.1843, Validation Loss: 0.3736
	--> Epoch [21/100], Loss: 0.2462, Validation Loss: 0.3672
	--> Epoch [22/100], Loss: 0.1621, Validation Loss: 0.3640
	--> Epoch [23/100], Loss: 0.1123, Validation Loss: 0.3592
	--> Epoch [24/100], Loss: 0.1579, Validation Loss: 0.3545
	--> Epoch [25/100], Loss: 0.1305, Validation Loss: 0.3493
	--> Epoch [26/100], Loss: 0.0937, Validation Loss: 0.3474
	--> Epoch [27/100], Loss: 0.2045, Validation Loss: 0.3453
	--> Epoch [28/100], Loss: 0.0832, Validation Loss: 0.3411
	--> Epoch [29/100], Loss: 0.1254, Validation Loss: 0.3426
	--> Epoch [30/100], Loss: 0.1019, Validation Loss: 0.3450
	--> Epoch [31/100], Loss: 0.1192, Validation Loss: 0.3411
	--> Epoch [32/100], Loss: 0.0773, Validation Loss: 0.3401
	--> Epoch [33/100], Loss: 0.1065, Validation Loss: 0.3395
	--> Epoch [34/100], Loss: 0.1141, Validation Loss: 0.3381
	--> Epoch [35/100], Loss: 0.0653, Validation Loss: 0.3389
	--> Epoch [36/100], Loss: 0.1161, Validation Loss: 0.3378
	--> Epoch [37/100], Loss: 0.1133, Validation Loss: 0.3370
	--> Epoch [38/100], Loss: 0.1183, Validation Loss: 0.3359
	--> Epoch [39/100], Loss: 0.0922, Validation Loss: 0.3335
	--> Epoch [40/100], Loss: 0.0949, Validation Loss: 0.3316
	--> Epoch [41/100], Loss: 0.0485, Validation Loss: 0.3316
	--> Epoch [42/100], Loss: 0.0387, Validation Loss: 0.3319
	--> Epoch [43/100], Loss: 0.0742, Validation Loss: 0.3319
	--> Epoch [44/100], Loss: 0.0483, Validation Loss: 0.3313
	--> Epoch [45/100], Loss: 0.0379, Validation Loss: 0.3304
	--> Epoch [46/100], Loss: 0.0485, Validation Loss: 0.3308
	--> Epoch [47/100], Loss: 0.0322, Validation Loss: 0.3313
	--> Epoch [48/100], Loss: 0.1174, Validation Loss: 0.3314
Early stopping
	--> Training for Fold 4 took 0.723726749420166 sec, using 48 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6895, Validation Loss: 0.6074
	--> Epoch [2/100], Loss: 0.6821, Validation Loss: 0.5882
	--> Epoch [3/100], Loss: 0.6385, Validation Loss: 0.5720
	--> Epoch [4/100], Loss: 0.6204, Validation Loss: 0.5587
	--> Epoch [5/100], Loss: 0.6012, Validation Loss: 0.5479
	--> Epoch [6/100], Loss: 0.5689, Validation Loss: 0.5396
	--> Epoch [7/100], Loss: 0.5059, Validation Loss: 0.5308
	--> Epoch [8/100], Loss: 0.4849, Validation Loss: 0.5261
	--> Epoch [9/100], Loss: 0.4400, Validation Loss: 0.5161
	--> Epoch [10/100], Loss: 0.4191, Validation Loss: 0.5116
	--> Epoch [11/100], Loss: 0.4228, Validation Loss: 0.5059
	--> Epoch [12/100], Loss: 0.3999, Validation Loss: 0.5022
	--> Epoch [13/100], Loss: 0.3432, Validation Loss: 0.5012
	--> Epoch [14/100], Loss: 0.3495, Validation Loss: 0.4989
	--> Epoch [15/100], Loss: 0.3858, Validation Loss: 0.4934
	--> Epoch [16/100], Loss: 0.3352, Validation Loss: 0.4927
	--> Epoch [17/100], Loss: 0.2170, Validation Loss: 0.4904
	--> Epoch [18/100], Loss: 0.2579, Validation Loss: 0.4883
	--> Epoch [19/100], Loss: 0.2331, Validation Loss: 0.4899
	--> Epoch [20/100], Loss: 0.2383, Validation Loss: 0.4901
	--> Epoch [21/100], Loss: 0.2021, Validation Loss: 0.4869
	--> Epoch [22/100], Loss: 0.1290, Validation Loss: 0.4825
	--> Epoch [23/100], Loss: 0.1821, Validation Loss: 0.4804
	--> Epoch [24/100], Loss: 0.1922, Validation Loss: 0.4816
	--> Epoch [25/100], Loss: 0.3128, Validation Loss: 0.4806
	--> Epoch [26/100], Loss: 0.1498, Validation Loss: 0.4804
Early stopping
	--> Training for Fold 5 took 0.35732245445251465 sec, using 26 epochs

Median number of epochs used: 75 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/75], Loss: 0.5945
	--> Final training Epoch [2/75], Loss: 0.5628
	--> Final training Epoch [3/75], Loss: 0.5291
	--> Final training Epoch [4/75], Loss: 0.5703
	--> Final training Epoch [5/75], Loss: 0.4793
	--> Final training Epoch [6/75], Loss: 0.5105
	--> Final training Epoch [7/75], Loss: 0.4441
	--> Final training Epoch [8/75], Loss: 0.4226
	--> Final training Epoch [9/75], Loss: 0.3935
	--> Final training Epoch [10/75], Loss: 0.3367
	--> Final training Epoch [11/75], Loss: 0.3157
	--> Final training Epoch [12/75], Loss: 0.2549
	--> Final training Epoch [13/75], Loss: 0.3480
	--> Final training Epoch [14/75], Loss: 0.2446
	--> Final training Epoch [15/75], Loss: 0.2943
	--> Final training Epoch [16/75], Loss: 0.2481
	--> Final training Epoch [17/75], Loss: 0.2263
	--> Final training Epoch [18/75], Loss: 0.2265
	--> Final training Epoch [19/75], Loss: 0.1783
	--> Final training Epoch [20/75], Loss: 0.1290
	--> Final training Epoch [21/75], Loss: 0.1989
	--> Final training Epoch [22/75], Loss: 0.1774
	--> Final training Epoch [23/75], Loss: 0.2035
	--> Final training Epoch [24/75], Loss: 0.1331
	--> Final training Epoch [25/75], Loss: 0.0834
	--> Final training Epoch [26/75], Loss: 0.0904
	--> Final training Epoch [27/75], Loss: 0.0970
	--> Final training Epoch [28/75], Loss: 0.1473
	--> Final training Epoch [29/75], Loss: 0.0457
	--> Final training Epoch [30/75], Loss: 0.1414
	--> Final training Epoch [31/75], Loss: 0.1174
	--> Final training Epoch [32/75], Loss: 0.0673
	--> Final training Epoch [33/75], Loss: 0.0524
	--> Final training Epoch [34/75], Loss: 0.0925
	--> Final training Epoch [35/75], Loss: 0.0381
	--> Final training Epoch [36/75], Loss: 0.1292
	--> Final training Epoch [37/75], Loss: 0.1167
	--> Final training Epoch [38/75], Loss: 0.0387
	--> Final training Epoch [39/75], Loss: 0.0647
	--> Final training Epoch [40/75], Loss: 0.0289
	--> Final training Epoch [41/75], Loss: 0.1036
	--> Final training Epoch [42/75], Loss: 0.0210
	--> Final training Epoch [43/75], Loss: 0.0669
	--> Final training Epoch [44/75], Loss: 0.0316
	--> Final training Epoch [45/75], Loss: 0.1674
	--> Final training Epoch [46/75], Loss: 0.0636
	--> Final training Epoch [47/75], Loss: 0.0934
	--> Final training Epoch [48/75], Loss: 0.0171
	--> Final training Epoch [49/75], Loss: 0.0890
	--> Final training Epoch [50/75], Loss: 0.0717
	--> Final training Epoch [51/75], Loss: 0.0139
	--> Final training Epoch [52/75], Loss: 0.0702
	--> Final training Epoch [53/75], Loss: 0.0705
	--> Final training Epoch [54/75], Loss: 0.0259
	--> Final training Epoch [55/75], Loss: 0.0836
	--> Final training Epoch [56/75], Loss: 0.0688
	--> Final training Epoch [57/75], Loss: 0.0352
	--> Final training Epoch [58/75], Loss: 0.0882
	--> Final training Epoch [59/75], Loss: 0.0369
	--> Final training Epoch [60/75], Loss: 0.0149
	--> Final training Epoch [61/75], Loss: 0.0695
	--> Final training Epoch [62/75], Loss: 0.0922
	--> Final training Epoch [63/75], Loss: 0.2032
	--> Final training Epoch [64/75], Loss: 0.0143
	--> Final training Epoch [65/75], Loss: 0.0691
	--> Final training Epoch [66/75], Loss: 0.0636
	--> Final training Epoch [67/75], Loss: 0.0134
	--> Final training Epoch [68/75], Loss: 0.0229
	--> Final training Epoch [69/75], Loss: 0.0333
	--> Final training Epoch [70/75], Loss: 0.0640
	--> Final training Epoch [71/75], Loss: 0.0632
	--> Final training Epoch [72/75], Loss: 0.1103
	--> Final training Epoch [73/75], Loss: 0.0086
	--> Final training Epoch [74/75], Loss: 0.0701
	--> Final training Epoch [75/75], Loss: 0.0126

Final training took 1.2040281295776367 sec

TESTING
	--> Testing took 0.0105 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.0455
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3211,  Current Best Accuracy: 0.8485,  Current Best Validation Loss: 0.3211
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.3762,  Current Best Accuracy: 0.8485,  Current Best Validation Loss: 0.3211

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8484, Validation Loss: 0.7541
	--> Epoch [2/100], Loss: 0.9597, Validation Loss: 0.7304
	--> Epoch [3/100], Loss: 0.7799, Validation Loss: 0.7035
	--> Epoch [4/100], Loss: 0.8148, Validation Loss: 0.6835
	--> Epoch [5/100], Loss: 0.7403, Validation Loss: 0.6600
	--> Epoch [6/100], Loss: 0.7052, Validation Loss: 0.6422
	--> Epoch [7/100], Loss: 0.6271, Validation Loss: 0.6222
	--> Epoch [8/100], Loss: 0.6187, Validation Loss: 0.6102
	--> Epoch [9/100], Loss: 0.5512, Validation Loss: 0.5949
	--> Epoch [10/100], Loss: 0.6207, Validation Loss: 0.5791
	--> Epoch [11/100], Loss: 0.5021, Validation Loss: 0.5601
	--> Epoch [12/100], Loss: 0.5509, Validation Loss: 0.5482
	--> Epoch [13/100], Loss: 0.4308, Validation Loss: 0.5329
	--> Epoch [14/100], Loss: 0.5132, Validation Loss: 0.5237
	--> Epoch [15/100], Loss: 0.6184, Validation Loss: 0.5155
	--> Epoch [16/100], Loss: 0.4740, Validation Loss: 0.5070
	--> Epoch [17/100], Loss: 0.4427, Validation Loss: 0.4958
	--> Epoch [18/100], Loss: 0.4854, Validation Loss: 0.4855
	--> Epoch [19/100], Loss: 0.3637, Validation Loss: 0.4737
	--> Epoch [20/100], Loss: 0.3907, Validation Loss: 0.4658
	--> Epoch [21/100], Loss: 0.6099, Validation Loss: 0.4583
	--> Epoch [22/100], Loss: 0.3322, Validation Loss: 0.4488
	--> Epoch [23/100], Loss: 0.4588, Validation Loss: 0.4408
	--> Epoch [24/100], Loss: 0.4407, Validation Loss: 0.4332
	--> Epoch [25/100], Loss: 0.5702, Validation Loss: 0.4337
	--> Epoch [26/100], Loss: 0.3489, Validation Loss: 0.4227
	--> Epoch [27/100], Loss: 0.3610, Validation Loss: 0.4183
	--> Epoch [28/100], Loss: 0.4682, Validation Loss: 0.4147
	--> Epoch [29/100], Loss: 0.4303, Validation Loss: 0.4089
	--> Epoch [30/100], Loss: 0.3556, Validation Loss: 0.4043
	--> Epoch [31/100], Loss: 0.3372, Validation Loss: 0.3988
	--> Epoch [32/100], Loss: 0.3604, Validation Loss: 0.3950
	--> Epoch [33/100], Loss: 0.2040, Validation Loss: 0.3946
	--> Epoch [34/100], Loss: 0.4055, Validation Loss: 0.3922
	--> Epoch [35/100], Loss: 0.3514, Validation Loss: 0.3851
	--> Epoch [36/100], Loss: 0.3577, Validation Loss: 0.3762
	--> Epoch [37/100], Loss: 0.2006, Validation Loss: 0.3726
	--> Epoch [38/100], Loss: 0.4628, Validation Loss: 0.3667
	--> Epoch [39/100], Loss: 0.4820, Validation Loss: 0.3617
	--> Epoch [40/100], Loss: 0.1887, Validation Loss: 0.3561
	--> Epoch [41/100], Loss: 0.1970, Validation Loss: 0.3587
	--> Epoch [42/100], Loss: 0.3037, Validation Loss: 0.3504
	--> Epoch [43/100], Loss: 0.3288, Validation Loss: 0.3473
	--> Epoch [44/100], Loss: 0.3392, Validation Loss: 0.3412
	--> Epoch [45/100], Loss: 0.2580, Validation Loss: 0.3390
	--> Epoch [46/100], Loss: 0.3812, Validation Loss: 0.3369
	--> Epoch [47/100], Loss: 0.2412, Validation Loss: 0.3338
	--> Epoch [48/100], Loss: 0.1081, Validation Loss: 0.3298
	--> Epoch [49/100], Loss: 0.1966, Validation Loss: 0.3245
	--> Epoch [50/100], Loss: 0.2525, Validation Loss: 0.3240
	--> Epoch [51/100], Loss: 0.3122, Validation Loss: 0.3247
	--> Epoch [52/100], Loss: 0.2582, Validation Loss: 0.3216
	--> Epoch [53/100], Loss: 0.2306, Validation Loss: 0.3209
	--> Epoch [54/100], Loss: 0.3814, Validation Loss: 0.3184
	--> Epoch [55/100], Loss: 0.4562, Validation Loss: 0.3160
	--> Epoch [56/100], Loss: 0.3151, Validation Loss: 0.3132
	--> Epoch [57/100], Loss: 0.3607, Validation Loss: 0.3117
	--> Epoch [58/100], Loss: 0.2957, Validation Loss: 0.3101
	--> Epoch [59/100], Loss: 0.2950, Validation Loss: 0.3050
	--> Epoch [60/100], Loss: 0.0924, Validation Loss: 0.3012
	--> Epoch [61/100], Loss: 0.3528, Validation Loss: 0.2992
	--> Epoch [62/100], Loss: 0.2850, Validation Loss: 0.3011
	--> Epoch [63/100], Loss: 0.3553, Validation Loss: 0.2981
	--> Epoch [64/100], Loss: 0.2219, Validation Loss: 0.2954
	--> Epoch [65/100], Loss: 0.2191, Validation Loss: 0.2918
	--> Epoch [66/100], Loss: 0.2806, Validation Loss: 0.2907
	--> Epoch [67/100], Loss: 0.2853, Validation Loss: 0.2907
	--> Epoch [68/100], Loss: 0.2783, Validation Loss: 0.2888
	--> Epoch [69/100], Loss: 0.1462, Validation Loss: 0.2895
	--> Epoch [70/100], Loss: 0.1556, Validation Loss: 0.2861
	--> Epoch [71/100], Loss: 0.4055, Validation Loss: 0.2840
	--> Epoch [72/100], Loss: 0.2220, Validation Loss: 0.2807
	--> Epoch [73/100], Loss: 0.2063, Validation Loss: 0.2864
	--> Epoch [74/100], Loss: 0.3317, Validation Loss: 0.2881
	--> Epoch [75/100], Loss: 0.2024, Validation Loss: 0.2889
Early stopping
	--> Training for Fold 1 took 1.078887701034546 sec, using 75 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5752, Validation Loss: 0.7488
	--> Epoch [2/100], Loss: 0.5449, Validation Loss: 0.7046
	--> Epoch [3/100], Loss: 0.4733, Validation Loss: 0.6766
	--> Epoch [4/100], Loss: 0.4404, Validation Loss: 0.6516
	--> Epoch [5/100], Loss: 0.3986, Validation Loss: 0.6183
	--> Epoch [6/100], Loss: 0.4755, Validation Loss: 0.5998
	--> Epoch [7/100], Loss: 0.4594, Validation Loss: 0.5824
	--> Epoch [8/100], Loss: 0.3764, Validation Loss: 0.5688
	--> Epoch [9/100], Loss: 0.3123, Validation Loss: 0.5469
	--> Epoch [10/100], Loss: 0.3651, Validation Loss: 0.5288
	--> Epoch [11/100], Loss: 0.2819, Validation Loss: 0.5097
	--> Epoch [12/100], Loss: 0.3329, Validation Loss: 0.4882
	--> Epoch [13/100], Loss: 0.3399, Validation Loss: 0.4686
	--> Epoch [14/100], Loss: 0.2291, Validation Loss: 0.4515
	--> Epoch [15/100], Loss: 0.3804, Validation Loss: 0.4337
	--> Epoch [16/100], Loss: 0.3489, Validation Loss: 0.4235
	--> Epoch [17/100], Loss: 0.1879, Validation Loss: 0.4130
	--> Epoch [18/100], Loss: 0.1700, Validation Loss: 0.4001
	--> Epoch [19/100], Loss: 0.1453, Validation Loss: 0.3857
	--> Epoch [20/100], Loss: 0.0971, Validation Loss: 0.3729
	--> Epoch [21/100], Loss: 0.2959, Validation Loss: 0.3635
	--> Epoch [22/100], Loss: 0.1428, Validation Loss: 0.3573
	--> Epoch [23/100], Loss: 0.2592, Validation Loss: 0.3461
	--> Epoch [24/100], Loss: 0.1343, Validation Loss: 0.3360
	--> Epoch [25/100], Loss: 0.2684, Validation Loss: 0.3287
	--> Epoch [26/100], Loss: 0.1527, Validation Loss: 0.3228
	--> Epoch [27/100], Loss: 0.0739, Validation Loss: 0.3164
	--> Epoch [28/100], Loss: 0.1237, Validation Loss: 0.3134
	--> Epoch [29/100], Loss: 0.2514, Validation Loss: 0.3079
	--> Epoch [30/100], Loss: 0.0716, Validation Loss: 0.3075
	--> Epoch [31/100], Loss: 0.1069, Validation Loss: 0.2998
	--> Epoch [32/100], Loss: 0.1463, Validation Loss: 0.2963
	--> Epoch [33/100], Loss: 0.0661, Validation Loss: 0.2888
	--> Epoch [34/100], Loss: 0.1115, Validation Loss: 0.2867
	--> Epoch [35/100], Loss: 0.1853, Validation Loss: 0.2866
	--> Epoch [36/100], Loss: 0.1770, Validation Loss: 0.2858
	--> Epoch [37/100], Loss: 0.1298, Validation Loss: 0.2846
	--> Epoch [38/100], Loss: 0.1375, Validation Loss: 0.2816
	--> Epoch [39/100], Loss: 0.1642, Validation Loss: 0.2747
	--> Epoch [40/100], Loss: 0.1539, Validation Loss: 0.2713
	--> Epoch [41/100], Loss: 0.0537, Validation Loss: 0.2696
	--> Epoch [42/100], Loss: 0.0945, Validation Loss: 0.2664
	--> Epoch [43/100], Loss: 0.0539, Validation Loss: 0.2627
	--> Epoch [44/100], Loss: 0.0511, Validation Loss: 0.2590
	--> Epoch [45/100], Loss: 0.0183, Validation Loss: 0.2572
	--> Epoch [46/100], Loss: 0.2364, Validation Loss: 0.2555
	--> Epoch [47/100], Loss: 0.1079, Validation Loss: 0.2552
	--> Epoch [48/100], Loss: 0.0860, Validation Loss: 0.2545
	--> Epoch [49/100], Loss: 0.0893, Validation Loss: 0.2532
	--> Epoch [50/100], Loss: 0.1240, Validation Loss: 0.2530
	--> Epoch [51/100], Loss: 0.0942, Validation Loss: 0.2532
	--> Epoch [52/100], Loss: 0.0363, Validation Loss: 0.2510
	--> Epoch [53/100], Loss: 0.3264, Validation Loss: 0.2522
	--> Epoch [54/100], Loss: 0.1209, Validation Loss: 0.2482
	--> Epoch [55/100], Loss: 0.1083, Validation Loss: 0.2466
	--> Epoch [56/100], Loss: 0.2407, Validation Loss: 0.2451
	--> Epoch [57/100], Loss: 0.1625, Validation Loss: 0.2402
	--> Epoch [58/100], Loss: 0.0093, Validation Loss: 0.2397
	--> Epoch [59/100], Loss: 0.1003, Validation Loss: 0.2389
	--> Epoch [60/100], Loss: 0.0920, Validation Loss: 0.2342
	--> Epoch [61/100], Loss: 0.0687, Validation Loss: 0.2373
	--> Epoch [62/100], Loss: 0.2342, Validation Loss: 0.2367
	--> Epoch [63/100], Loss: 0.0988, Validation Loss: 0.2343
Early stopping
	--> Training for Fold 2 took 0.8020987510681152 sec, using 63 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7813, Validation Loss: 0.6583
	--> Epoch [2/100], Loss: 0.8422, Validation Loss: 0.6402
	--> Epoch [3/100], Loss: 0.7481, Validation Loss: 0.6239
	--> Epoch [4/100], Loss: 0.6741, Validation Loss: 0.6106
	--> Epoch [5/100], Loss: 0.6940, Validation Loss: 0.6021
	--> Epoch [6/100], Loss: 0.7055, Validation Loss: 0.5896
	--> Epoch [7/100], Loss: 0.5607, Validation Loss: 0.5778
	--> Epoch [8/100], Loss: 0.5375, Validation Loss: 0.5677
	--> Epoch [9/100], Loss: 0.6572, Validation Loss: 0.5528
	--> Epoch [10/100], Loss: 0.5462, Validation Loss: 0.5423
	--> Epoch [11/100], Loss: 0.5298, Validation Loss: 0.5321
	--> Epoch [12/100], Loss: 0.3929, Validation Loss: 0.5215
	--> Epoch [13/100], Loss: 0.4415, Validation Loss: 0.5070
	--> Epoch [14/100], Loss: 0.5102, Validation Loss: 0.4991
	--> Epoch [15/100], Loss: 0.3755, Validation Loss: 0.4917
	--> Epoch [16/100], Loss: 0.3970, Validation Loss: 0.4799
	--> Epoch [17/100], Loss: 0.2146, Validation Loss: 0.4679
	--> Epoch [18/100], Loss: 0.3259, Validation Loss: 0.4607
	--> Epoch [19/100], Loss: 0.3932, Validation Loss: 0.4501
	--> Epoch [20/100], Loss: 0.2751, Validation Loss: 0.4430
	--> Epoch [21/100], Loss: 0.4122, Validation Loss: 0.4337
	--> Epoch [22/100], Loss: 0.3703, Validation Loss: 0.4300
	--> Epoch [23/100], Loss: 0.4119, Validation Loss: 0.4227
	--> Epoch [24/100], Loss: 0.1443, Validation Loss: 0.4154
	--> Epoch [25/100], Loss: 0.3928, Validation Loss: 0.4118
	--> Epoch [26/100], Loss: 0.2619, Validation Loss: 0.4046
	--> Epoch [27/100], Loss: 0.2744, Validation Loss: 0.3977
	--> Epoch [28/100], Loss: 0.2251, Validation Loss: 0.3917
	--> Epoch [29/100], Loss: 0.3068, Validation Loss: 0.3912
	--> Epoch [30/100], Loss: 0.1700, Validation Loss: 0.3841
	--> Epoch [31/100], Loss: 0.2473, Validation Loss: 0.3818
	--> Epoch [32/100], Loss: 0.1771, Validation Loss: 0.3748
	--> Epoch [33/100], Loss: 0.2471, Validation Loss: 0.3681
	--> Epoch [34/100], Loss: 0.1858, Validation Loss: 0.3642
	--> Epoch [35/100], Loss: 0.1466, Validation Loss: 0.3625
	--> Epoch [36/100], Loss: 0.4113, Validation Loss: 0.3594
	--> Epoch [37/100], Loss: 0.2707, Validation Loss: 0.3560
	--> Epoch [38/100], Loss: 0.1858, Validation Loss: 0.3541
	--> Epoch [39/100], Loss: 0.1665, Validation Loss: 0.3477
	--> Epoch [40/100], Loss: 0.1258, Validation Loss: 0.3447
	--> Epoch [41/100], Loss: 0.1877, Validation Loss: 0.3437
	--> Epoch [42/100], Loss: 0.1805, Validation Loss: 0.3409
	--> Epoch [43/100], Loss: 0.2175, Validation Loss: 0.3361
	--> Epoch [44/100], Loss: 0.0878, Validation Loss: 0.3336
	--> Epoch [45/100], Loss: 0.1734, Validation Loss: 0.3326
	--> Epoch [46/100], Loss: 0.2281, Validation Loss: 0.3306
	--> Epoch [47/100], Loss: 0.1650, Validation Loss: 0.3316
	--> Epoch [48/100], Loss: 0.2607, Validation Loss: 0.3314
	--> Epoch [49/100], Loss: 0.2485, Validation Loss: 0.3292
	--> Epoch [50/100], Loss: 0.2340, Validation Loss: 0.3272
	--> Epoch [51/100], Loss: 0.1563, Validation Loss: 0.3250
	--> Epoch [52/100], Loss: 0.1567, Validation Loss: 0.3232
	--> Epoch [53/100], Loss: 0.1509, Validation Loss: 0.3201
	--> Epoch [54/100], Loss: 0.2332, Validation Loss: 0.3214
	--> Epoch [55/100], Loss: 0.2227, Validation Loss: 0.3242
	--> Epoch [56/100], Loss: 0.2874, Validation Loss: 0.3208
Early stopping
	--> Training for Fold 3 took 0.698153018951416 sec, using 56 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7068, Validation Loss: 0.7295
	--> Epoch [2/100], Loss: 0.6381, Validation Loss: 0.6843
	--> Epoch [3/100], Loss: 0.5815, Validation Loss: 0.6573
	--> Epoch [4/100], Loss: 0.5630, Validation Loss: 0.6329
	--> Epoch [5/100], Loss: 0.4057, Validation Loss: 0.6128
	--> Epoch [6/100], Loss: 0.5274, Validation Loss: 0.5983
	--> Epoch [7/100], Loss: 0.3648, Validation Loss: 0.5735
	--> Epoch [8/100], Loss: 0.4617, Validation Loss: 0.5576
	--> Epoch [9/100], Loss: 0.3580, Validation Loss: 0.5413
	--> Epoch [10/100], Loss: 0.3654, Validation Loss: 0.5342
	--> Epoch [11/100], Loss: 0.3688, Validation Loss: 0.5191
	--> Epoch [12/100], Loss: 0.3379, Validation Loss: 0.5068
	--> Epoch [13/100], Loss: 0.3724, Validation Loss: 0.4877
	--> Epoch [14/100], Loss: 0.2113, Validation Loss: 0.4726
	--> Epoch [15/100], Loss: 0.3661, Validation Loss: 0.4641
	--> Epoch [16/100], Loss: 0.2389, Validation Loss: 0.4471
	--> Epoch [17/100], Loss: 0.2993, Validation Loss: 0.4387
	--> Epoch [18/100], Loss: 0.2267, Validation Loss: 0.4259
	--> Epoch [19/100], Loss: 0.2568, Validation Loss: 0.4115
	--> Epoch [20/100], Loss: 0.1747, Validation Loss: 0.3973
	--> Epoch [21/100], Loss: 0.1627, Validation Loss: 0.3862
	--> Epoch [22/100], Loss: 0.2392, Validation Loss: 0.3747
	--> Epoch [23/100], Loss: 0.2391, Validation Loss: 0.3749
	--> Epoch [24/100], Loss: 0.2174, Validation Loss: 0.3726
	--> Epoch [25/100], Loss: 0.2271, Validation Loss: 0.3627
	--> Epoch [26/100], Loss: 0.1055, Validation Loss: 0.3559
	--> Epoch [27/100], Loss: 0.1918, Validation Loss: 0.3502
	--> Epoch [28/100], Loss: 0.2602, Validation Loss: 0.3540
	--> Epoch [29/100], Loss: 0.1473, Validation Loss: 0.3430
	--> Epoch [30/100], Loss: 0.1639, Validation Loss: 0.3385
	--> Epoch [31/100], Loss: 0.1452, Validation Loss: 0.3319
	--> Epoch [32/100], Loss: 0.0644, Validation Loss: 0.3284
	--> Epoch [33/100], Loss: 0.0778, Validation Loss: 0.3235
	--> Epoch [34/100], Loss: 0.1933, Validation Loss: 0.3176
	--> Epoch [35/100], Loss: 0.1312, Validation Loss: 0.3157
	--> Epoch [36/100], Loss: 0.0650, Validation Loss: 0.3135
	--> Epoch [37/100], Loss: 0.1922, Validation Loss: 0.3157
	--> Epoch [38/100], Loss: 0.1213, Validation Loss: 0.3127
	--> Epoch [39/100], Loss: 0.0599, Validation Loss: 0.3083
	--> Epoch [40/100], Loss: 0.1683, Validation Loss: 0.3142
	--> Epoch [41/100], Loss: 0.1274, Validation Loss: 0.3112
	--> Epoch [42/100], Loss: 0.1825, Validation Loss: 0.3088
Early stopping
	--> Training for Fold 4 took 0.5215268135070801 sec, using 42 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7434, Validation Loss: 0.6380
	--> Epoch [2/100], Loss: 0.6223, Validation Loss: 0.6205
	--> Epoch [3/100], Loss: 0.6410, Validation Loss: 0.6069
	--> Epoch [4/100], Loss: 0.4539, Validation Loss: 0.5918
	--> Epoch [5/100], Loss: 0.5301, Validation Loss: 0.5821
	--> Epoch [6/100], Loss: 0.5558, Validation Loss: 0.5751
	--> Epoch [7/100], Loss: 0.4866, Validation Loss: 0.5669
	--> Epoch [8/100], Loss: 0.5872, Validation Loss: 0.5625
	--> Epoch [9/100], Loss: 0.3975, Validation Loss: 0.5572
	--> Epoch [10/100], Loss: 0.5382, Validation Loss: 0.5469
	--> Epoch [11/100], Loss: 0.5071, Validation Loss: 0.5443
	--> Epoch [12/100], Loss: 0.5095, Validation Loss: 0.5350
	--> Epoch [13/100], Loss: 0.4328, Validation Loss: 0.5305
	--> Epoch [14/100], Loss: 0.5362, Validation Loss: 0.5269
	--> Epoch [15/100], Loss: 0.3493, Validation Loss: 0.5294
	--> Epoch [16/100], Loss: 0.4215, Validation Loss: 0.5258
	--> Epoch [17/100], Loss: 0.4798, Validation Loss: 0.5211
	--> Epoch [18/100], Loss: 0.4050, Validation Loss: 0.5219
	--> Epoch [19/100], Loss: 0.5148, Validation Loss: 0.5161
	--> Epoch [20/100], Loss: 0.3330, Validation Loss: 0.5154
	--> Epoch [21/100], Loss: 0.4172, Validation Loss: 0.5125
	--> Epoch [22/100], Loss: 0.3694, Validation Loss: 0.5094
	--> Epoch [23/100], Loss: 0.3094, Validation Loss: 0.5071
	--> Epoch [24/100], Loss: 0.4367, Validation Loss: 0.5061
	--> Epoch [25/100], Loss: 0.3475, Validation Loss: 0.5032
	--> Epoch [26/100], Loss: 0.3976, Validation Loss: 0.4997
	--> Epoch [27/100], Loss: 0.2997, Validation Loss: 0.5015
	--> Epoch [28/100], Loss: 0.3300, Validation Loss: 0.5011
	--> Epoch [29/100], Loss: 0.3278, Validation Loss: 0.5048
Early stopping
	--> Training for Fold 5 took 0.37317371368408203 sec, using 29 epochs

Median number of epochs used: 56 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/56], Loss: 0.7375
	--> Final training Epoch [2/56], Loss: 0.7222
	--> Final training Epoch [3/56], Loss: 0.6063
	--> Final training Epoch [4/56], Loss: 0.6268
	--> Final training Epoch [5/56], Loss: 0.5061
	--> Final training Epoch [6/56], Loss: 0.5235
	--> Final training Epoch [7/56], Loss: 0.5023
	--> Final training Epoch [8/56], Loss: 0.4230
	--> Final training Epoch [9/56], Loss: 0.3068
	--> Final training Epoch [10/56], Loss: 0.4338
	--> Final training Epoch [11/56], Loss: 0.3679
	--> Final training Epoch [12/56], Loss: 0.3356
	--> Final training Epoch [13/56], Loss: 0.3404
	--> Final training Epoch [14/56], Loss: 0.2811
	--> Final training Epoch [15/56], Loss: 0.2435
	--> Final training Epoch [16/56], Loss: 0.3096
	--> Final training Epoch [17/56], Loss: 0.2773
	--> Final training Epoch [18/56], Loss: 0.2731
	--> Final training Epoch [19/56], Loss: 0.3522
	--> Final training Epoch [20/56], Loss: 0.2130
	--> Final training Epoch [21/56], Loss: 0.2445
	--> Final training Epoch [22/56], Loss: 0.3137
	--> Final training Epoch [23/56], Loss: 0.2879
	--> Final training Epoch [24/56], Loss: 0.1821
	--> Final training Epoch [25/56], Loss: 0.2633
	--> Final training Epoch [26/56], Loss: 0.1710
	--> Final training Epoch [27/56], Loss: 0.0969
	--> Final training Epoch [28/56], Loss: 0.1885
	--> Final training Epoch [29/56], Loss: 0.1568
	--> Final training Epoch [30/56], Loss: 0.2177
	--> Final training Epoch [31/56], Loss: 0.1779
	--> Final training Epoch [32/56], Loss: 0.0844
	--> Final training Epoch [33/56], Loss: 0.1579
	--> Final training Epoch [34/56], Loss: 0.2175
	--> Final training Epoch [35/56], Loss: 0.1565
	--> Final training Epoch [36/56], Loss: 0.1921
	--> Final training Epoch [37/56], Loss: 0.2667
	--> Final training Epoch [38/56], Loss: 0.0952
	--> Final training Epoch [39/56], Loss: 0.1708
	--> Final training Epoch [40/56], Loss: 0.2342
	--> Final training Epoch [41/56], Loss: 0.1301
	--> Final training Epoch [42/56], Loss: 0.2337
	--> Final training Epoch [43/56], Loss: 0.1182
	--> Final training Epoch [44/56], Loss: 0.1527
	--> Final training Epoch [45/56], Loss: 0.2133
	--> Final training Epoch [46/56], Loss: 0.0419
	--> Final training Epoch [47/56], Loss: 0.1793
	--> Final training Epoch [48/56], Loss: 0.1905
	--> Final training Epoch [49/56], Loss: 0.1227
	--> Final training Epoch [50/56], Loss: 0.1036
	--> Final training Epoch [51/56], Loss: 0.1250
	--> Final training Epoch [52/56], Loss: 0.0304
	--> Final training Epoch [53/56], Loss: 0.1272
	--> Final training Epoch [54/56], Loss: 0.1581
	--> Final training Epoch [55/56], Loss: 0.1610
	--> Final training Epoch [56/56], Loss: 0.0681

Final training took 0.794818639755249 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8612
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3592,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3592
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3965,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3592
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8251, Validation Loss: 0.3838,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3592

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7472, Validation Loss: 0.6555
	--> Epoch [2/100], Loss: 0.7846, Validation Loss: 0.6306
	--> Epoch [3/100], Loss: 0.8077, Validation Loss: 0.5989
	--> Epoch [4/100], Loss: 0.5937, Validation Loss: 0.5857
	--> Epoch [5/100], Loss: 0.6781, Validation Loss: 0.5746
	--> Epoch [6/100], Loss: 0.5941, Validation Loss: 0.5625
	--> Epoch [7/100], Loss: 0.4392, Validation Loss: 0.5503
	--> Epoch [8/100], Loss: 0.6889, Validation Loss: 0.5375
	--> Epoch [9/100], Loss: 0.5332, Validation Loss: 0.5235
	--> Epoch [10/100], Loss: 0.4989, Validation Loss: 0.5135
	--> Epoch [11/100], Loss: 0.5801, Validation Loss: 0.5006
	--> Epoch [12/100], Loss: 0.5529, Validation Loss: 0.4915
	--> Epoch [13/100], Loss: 0.5602, Validation Loss: 0.4804
	--> Epoch [14/100], Loss: 0.4791, Validation Loss: 0.4684
	--> Epoch [15/100], Loss: 0.5172, Validation Loss: 0.4582
	--> Epoch [16/100], Loss: 0.6470, Validation Loss: 0.4517
	--> Epoch [17/100], Loss: 0.4822, Validation Loss: 0.4423
	--> Epoch [18/100], Loss: 0.3664, Validation Loss: 0.4359
	--> Epoch [19/100], Loss: 0.3927, Validation Loss: 0.4255
	--> Epoch [20/100], Loss: 0.3855, Validation Loss: 0.4126
	--> Epoch [21/100], Loss: 0.4365, Validation Loss: 0.4052
	--> Epoch [22/100], Loss: 0.5472, Validation Loss: 0.3992
	--> Epoch [23/100], Loss: 0.3495, Validation Loss: 0.3906
	--> Epoch [24/100], Loss: 0.3734, Validation Loss: 0.3860
	--> Epoch [25/100], Loss: 0.3034, Validation Loss: 0.3828
	--> Epoch [26/100], Loss: 0.4056, Validation Loss: 0.3762
	--> Epoch [27/100], Loss: 0.4250, Validation Loss: 0.3701
	--> Epoch [28/100], Loss: 0.2516, Validation Loss: 0.3680
	--> Epoch [29/100], Loss: 0.4333, Validation Loss: 0.3622
	--> Epoch [30/100], Loss: 0.4543, Validation Loss: 0.3604
	--> Epoch [31/100], Loss: 0.3151, Validation Loss: 0.3527
	--> Epoch [32/100], Loss: 0.2452, Validation Loss: 0.3483
	--> Epoch [33/100], Loss: 0.3153, Validation Loss: 0.3441
	--> Epoch [34/100], Loss: 0.3664, Validation Loss: 0.3386
	--> Epoch [35/100], Loss: 0.3475, Validation Loss: 0.3376
	--> Epoch [36/100], Loss: 0.3822, Validation Loss: 0.3382
	--> Epoch [37/100], Loss: 0.3188, Validation Loss: 0.3328
	--> Epoch [38/100], Loss: 0.3616, Validation Loss: 0.3296
	--> Epoch [39/100], Loss: 0.3813, Validation Loss: 0.3263
	--> Epoch [40/100], Loss: 0.3730, Validation Loss: 0.3224
	--> Epoch [41/100], Loss: 0.2385, Validation Loss: 0.3188
	--> Epoch [42/100], Loss: 0.2349, Validation Loss: 0.3152
	--> Epoch [43/100], Loss: 0.2427, Validation Loss: 0.3150
	--> Epoch [44/100], Loss: 0.3747, Validation Loss: 0.3124
	--> Epoch [45/100], Loss: 0.3174, Validation Loss: 0.3079
	--> Epoch [46/100], Loss: 0.2191, Validation Loss: 0.3057
	--> Epoch [47/100], Loss: 0.1055, Validation Loss: 0.3054
	--> Epoch [48/100], Loss: 0.3449, Validation Loss: 0.3036
	--> Epoch [49/100], Loss: 0.1822, Validation Loss: 0.3025
	--> Epoch [50/100], Loss: 0.3660, Validation Loss: 0.3028
	--> Epoch [51/100], Loss: 0.2446, Validation Loss: 0.3004
	--> Epoch [52/100], Loss: 0.3483, Validation Loss: 0.3000
	--> Epoch [53/100], Loss: 0.0550, Validation Loss: 0.2976
	--> Epoch [54/100], Loss: 0.2714, Validation Loss: 0.2942
	--> Epoch [55/100], Loss: 0.1759, Validation Loss: 0.2930
	--> Epoch [56/100], Loss: 0.2862, Validation Loss: 0.2873
	--> Epoch [57/100], Loss: 0.2934, Validation Loss: 0.2860
	--> Epoch [58/100], Loss: 0.2165, Validation Loss: 0.2834
	--> Epoch [59/100], Loss: 0.2440, Validation Loss: 0.2858
	--> Epoch [60/100], Loss: 0.3616, Validation Loss: 0.2867
	--> Epoch [61/100], Loss: 0.1517, Validation Loss: 0.2845
Early stopping
	--> Training for Fold 1 took 0.8147168159484863 sec, using 61 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6780, Validation Loss: 0.7412
	--> Epoch [2/100], Loss: 0.6805, Validation Loss: 0.6899
	--> Epoch [3/100], Loss: 0.6084, Validation Loss: 0.6508
	--> Epoch [4/100], Loss: 0.5848, Validation Loss: 0.6227
	--> Epoch [5/100], Loss: 0.5271, Validation Loss: 0.6085
	--> Epoch [6/100], Loss: 0.5167, Validation Loss: 0.5921
	--> Epoch [7/100], Loss: 0.5402, Validation Loss: 0.5814
	--> Epoch [8/100], Loss: 0.4728, Validation Loss: 0.5699
	--> Epoch [9/100], Loss: 0.3808, Validation Loss: 0.5540
	--> Epoch [10/100], Loss: 0.4909, Validation Loss: 0.5394
	--> Epoch [11/100], Loss: 0.4319, Validation Loss: 0.5248
	--> Epoch [12/100], Loss: 0.4368, Validation Loss: 0.5132
	--> Epoch [13/100], Loss: 0.4202, Validation Loss: 0.4963
	--> Epoch [14/100], Loss: 0.4077, Validation Loss: 0.4833
	--> Epoch [15/100], Loss: 0.3021, Validation Loss: 0.4697
	--> Epoch [16/100], Loss: 0.3620, Validation Loss: 0.4565
	--> Epoch [17/100], Loss: 0.3053, Validation Loss: 0.4444
	--> Epoch [18/100], Loss: 0.2835, Validation Loss: 0.4337
	--> Epoch [19/100], Loss: 0.4195, Validation Loss: 0.4288
	--> Epoch [20/100], Loss: 0.2887, Validation Loss: 0.4196
	--> Epoch [21/100], Loss: 0.2466, Validation Loss: 0.4151
	--> Epoch [22/100], Loss: 0.3032, Validation Loss: 0.4078
	--> Epoch [23/100], Loss: 0.4686, Validation Loss: 0.4015
	--> Epoch [24/100], Loss: 0.2847, Validation Loss: 0.3976
	--> Epoch [25/100], Loss: 0.2287, Validation Loss: 0.3902
	--> Epoch [26/100], Loss: 0.4078, Validation Loss: 0.3844
	--> Epoch [27/100], Loss: 0.2726, Validation Loss: 0.3813
	--> Epoch [28/100], Loss: 0.3483, Validation Loss: 0.3720
	--> Epoch [29/100], Loss: 0.2006, Validation Loss: 0.3665
	--> Epoch [30/100], Loss: 0.3384, Validation Loss: 0.3599
	--> Epoch [31/100], Loss: 0.3668, Validation Loss: 0.3555
	--> Epoch [32/100], Loss: 0.1680, Validation Loss: 0.3524
	--> Epoch [33/100], Loss: 0.3502, Validation Loss: 0.3463
	--> Epoch [34/100], Loss: 0.2850, Validation Loss: 0.3429
	--> Epoch [35/100], Loss: 0.2792, Validation Loss: 0.3357
	--> Epoch [36/100], Loss: 0.2709, Validation Loss: 0.3312
	--> Epoch [37/100], Loss: 0.2498, Validation Loss: 0.3288
	--> Epoch [38/100], Loss: 0.1907, Validation Loss: 0.3256
	--> Epoch [39/100], Loss: 0.2633, Validation Loss: 0.3245
	--> Epoch [40/100], Loss: 0.2028, Validation Loss: 0.3204
	--> Epoch [41/100], Loss: 0.2617, Validation Loss: 0.3191
	--> Epoch [42/100], Loss: 0.1563, Validation Loss: 0.3144
	--> Epoch [43/100], Loss: 0.1428, Validation Loss: 0.3142
	--> Epoch [44/100], Loss: 0.3315, Validation Loss: 0.3111
	--> Epoch [45/100], Loss: 0.3276, Validation Loss: 0.3120
	--> Epoch [46/100], Loss: 0.1467, Validation Loss: 0.3155
	--> Epoch [47/100], Loss: 0.3334, Validation Loss: 0.3037
	--> Epoch [48/100], Loss: 0.3324, Validation Loss: 0.3032
	--> Epoch [49/100], Loss: 0.0800, Validation Loss: 0.3014
	--> Epoch [50/100], Loss: 0.1940, Validation Loss: 0.2981
	--> Epoch [51/100], Loss: 0.1305, Validation Loss: 0.2950
	--> Epoch [52/100], Loss: 0.2685, Validation Loss: 0.2928
	--> Epoch [53/100], Loss: 0.1227, Validation Loss: 0.2926
	--> Epoch [54/100], Loss: 0.0740, Validation Loss: 0.2935
	--> Epoch [55/100], Loss: 0.1909, Validation Loss: 0.2937
	--> Epoch [56/100], Loss: 0.1457, Validation Loss: 0.2880
	--> Epoch [57/100], Loss: 0.2711, Validation Loss: 0.2849
	--> Epoch [58/100], Loss: 0.2660, Validation Loss: 0.2864
	--> Epoch [59/100], Loss: 0.3012, Validation Loss: 0.2837
	--> Epoch [60/100], Loss: 0.2662, Validation Loss: 0.2841
	--> Epoch [61/100], Loss: 0.1799, Validation Loss: 0.2800
	--> Epoch [62/100], Loss: 0.1278, Validation Loss: 0.2779
	--> Epoch [63/100], Loss: 0.2621, Validation Loss: 0.2768
	--> Epoch [64/100], Loss: 0.1273, Validation Loss: 0.2767
	--> Epoch [65/100], Loss: 0.2613, Validation Loss: 0.2693
	--> Epoch [66/100], Loss: 0.1260, Validation Loss: 0.2655
	--> Epoch [67/100], Loss: 0.3224, Validation Loss: 0.2670
	--> Epoch [68/100], Loss: 0.1784, Validation Loss: 0.2680
	--> Epoch [69/100], Loss: 0.4562, Validation Loss: 0.2657
Early stopping
	--> Training for Fold 2 took 0.9163801670074463 sec, using 69 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6430, Validation Loss: 0.7297
	--> Epoch [2/100], Loss: 0.6207, Validation Loss: 0.7156
	--> Epoch [3/100], Loss: 0.5716, Validation Loss: 0.7022
	--> Epoch [4/100], Loss: 0.6053, Validation Loss: 0.6916
	--> Epoch [5/100], Loss: 0.5616, Validation Loss: 0.6824
	--> Epoch [6/100], Loss: 0.5005, Validation Loss: 0.6760
	--> Epoch [7/100], Loss: 0.5190, Validation Loss: 0.6700
	--> Epoch [8/100], Loss: 0.5109, Validation Loss: 0.6628
	--> Epoch [9/100], Loss: 0.4301, Validation Loss: 0.6563
	--> Epoch [10/100], Loss: 0.4808, Validation Loss: 0.6498
	--> Epoch [11/100], Loss: 0.6005, Validation Loss: 0.6428
	--> Epoch [12/100], Loss: 0.4158, Validation Loss: 0.6387
	--> Epoch [13/100], Loss: 0.5401, Validation Loss: 0.6330
	--> Epoch [14/100], Loss: 0.3596, Validation Loss: 0.6241
	--> Epoch [15/100], Loss: 0.3565, Validation Loss: 0.6191
	--> Epoch [16/100], Loss: 0.3938, Validation Loss: 0.6154
	--> Epoch [17/100], Loss: 0.3792, Validation Loss: 0.6095
	--> Epoch [18/100], Loss: 0.3269, Validation Loss: 0.6012
	--> Epoch [19/100], Loss: 0.2858, Validation Loss: 0.5978
	--> Epoch [20/100], Loss: 0.4446, Validation Loss: 0.5916
	--> Epoch [21/100], Loss: 0.3815, Validation Loss: 0.5913
	--> Epoch [22/100], Loss: 0.1642, Validation Loss: 0.5849
	--> Epoch [23/100], Loss: 0.3346, Validation Loss: 0.5779
	--> Epoch [24/100], Loss: 0.3784, Validation Loss: 0.5744
	--> Epoch [25/100], Loss: 0.2282, Validation Loss: 0.5707
	--> Epoch [26/100], Loss: 0.3258, Validation Loss: 0.5691
	--> Epoch [27/100], Loss: 0.0594, Validation Loss: 0.5621
	--> Epoch [28/100], Loss: 0.1359, Validation Loss: 0.5536
	--> Epoch [29/100], Loss: 0.2571, Validation Loss: 0.5496
	--> Epoch [30/100], Loss: 0.3675, Validation Loss: 0.5513
	--> Epoch [31/100], Loss: 0.1848, Validation Loss: 0.5496
	--> Epoch [32/100], Loss: 0.3875, Validation Loss: 0.5500
Early stopping
	--> Training for Fold 3 took 0.4261312484741211 sec, using 32 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8259, Validation Loss: 0.5870
	--> Epoch [2/100], Loss: 0.8266, Validation Loss: 0.5699
	--> Epoch [3/100], Loss: 0.6714, Validation Loss: 0.5530
	--> Epoch [4/100], Loss: 0.7932, Validation Loss: 0.5368
	--> Epoch [5/100], Loss: 0.7940, Validation Loss: 0.5209
	--> Epoch [6/100], Loss: 0.7899, Validation Loss: 0.5092
	--> Epoch [7/100], Loss: 0.8303, Validation Loss: 0.5187
	--> Epoch [8/100], Loss: 0.6461, Validation Loss: 0.5203
	--> Epoch [9/100], Loss: 0.5692, Validation Loss: 0.5090
	--> Epoch [10/100], Loss: 0.5937, Validation Loss: 0.4969
	--> Epoch [11/100], Loss: 0.4681, Validation Loss: 0.4845
	--> Epoch [12/100], Loss: 0.6440, Validation Loss: 0.4865
	--> Epoch [13/100], Loss: 0.6510, Validation Loss: 0.4818
	--> Epoch [14/100], Loss: 0.4794, Validation Loss: 0.4745
	--> Epoch [15/100], Loss: 0.4729, Validation Loss: 0.4633
	--> Epoch [16/100], Loss: 0.5336, Validation Loss: 0.4534
	--> Epoch [17/100], Loss: 0.4985, Validation Loss: 0.4483
	--> Epoch [18/100], Loss: 0.4961, Validation Loss: 0.4476
	--> Epoch [19/100], Loss: 0.4046, Validation Loss: 0.4403
	--> Epoch [20/100], Loss: 0.4708, Validation Loss: 0.4363
	--> Epoch [21/100], Loss: 0.4088, Validation Loss: 0.4302
	--> Epoch [22/100], Loss: 0.3679, Validation Loss: 0.4208
	--> Epoch [23/100], Loss: 0.5554, Validation Loss: 0.4198
	--> Epoch [24/100], Loss: 0.4846, Validation Loss: 0.4177
	--> Epoch [25/100], Loss: 0.5381, Validation Loss: 0.4121
	--> Epoch [26/100], Loss: 0.3609, Validation Loss: 0.4066
	--> Epoch [27/100], Loss: 0.3236, Validation Loss: 0.4048
	--> Epoch [28/100], Loss: 0.4679, Validation Loss: 0.4015
	--> Epoch [29/100], Loss: 0.3892, Validation Loss: 0.3954
	--> Epoch [30/100], Loss: 0.3063, Validation Loss: 0.3899
	--> Epoch [31/100], Loss: 0.3761, Validation Loss: 0.3832
	--> Epoch [32/100], Loss: 0.4307, Validation Loss: 0.3757
	--> Epoch [33/100], Loss: 0.2665, Validation Loss: 0.3730
	--> Epoch [34/100], Loss: 0.3989, Validation Loss: 0.3700
	--> Epoch [35/100], Loss: 0.4740, Validation Loss: 0.3639
	--> Epoch [36/100], Loss: 0.3912, Validation Loss: 0.3625
	--> Epoch [37/100], Loss: 0.4691, Validation Loss: 0.3601
	--> Epoch [38/100], Loss: 0.7269, Validation Loss: 0.3602
	--> Epoch [39/100], Loss: 0.4117, Validation Loss: 0.3554
	--> Epoch [40/100], Loss: 0.2973, Validation Loss: 0.3535
	--> Epoch [41/100], Loss: 0.3930, Validation Loss: 0.3479
	--> Epoch [42/100], Loss: 0.2910, Validation Loss: 0.3449
	--> Epoch [43/100], Loss: 0.3655, Validation Loss: 0.3398
	--> Epoch [44/100], Loss: 0.4488, Validation Loss: 0.3377
	--> Epoch [45/100], Loss: 0.2663, Validation Loss: 0.3394
	--> Epoch [46/100], Loss: 0.3322, Validation Loss: 0.3382
	--> Epoch [47/100], Loss: 0.3995, Validation Loss: 0.3355
	--> Epoch [48/100], Loss: 0.3252, Validation Loss: 0.3339
	--> Epoch [49/100], Loss: 0.3389, Validation Loss: 0.3339
	--> Epoch [50/100], Loss: 0.2674, Validation Loss: 0.3336
	--> Epoch [51/100], Loss: 0.4392, Validation Loss: 0.3377
	--> Epoch [52/100], Loss: 0.3310, Validation Loss: 0.3323
	--> Epoch [53/100], Loss: 0.4605, Validation Loss: 0.3319
	--> Epoch [54/100], Loss: 0.2487, Validation Loss: 0.3299
	--> Epoch [55/100], Loss: 0.2401, Validation Loss: 0.3278
	--> Epoch [56/100], Loss: 0.3260, Validation Loss: 0.3256
	--> Epoch [57/100], Loss: 0.3228, Validation Loss: 0.3238
	--> Epoch [58/100], Loss: 0.4533, Validation Loss: 0.3216
	--> Epoch [59/100], Loss: 0.3414, Validation Loss: 0.3192
	--> Epoch [60/100], Loss: 0.4691, Validation Loss: 0.3178
	--> Epoch [61/100], Loss: 0.3634, Validation Loss: 0.3170
	--> Epoch [62/100], Loss: 0.2357, Validation Loss: 0.3181
	--> Epoch [63/100], Loss: 0.3325, Validation Loss: 0.3156
	--> Epoch [64/100], Loss: 0.2475, Validation Loss: 0.3137
	--> Epoch [65/100], Loss: 0.2440, Validation Loss: 0.3076
	--> Epoch [66/100], Loss: 0.2482, Validation Loss: 0.3112
	--> Epoch [67/100], Loss: 0.3690, Validation Loss: 0.3101
	--> Epoch [68/100], Loss: 0.2181, Validation Loss: 0.3102
Early stopping
	--> Training for Fold 4 took 0.9699699878692627 sec, using 68 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7545, Validation Loss: 0.6929
	--> Epoch [2/100], Loss: 0.7605, Validation Loss: 0.6762
	--> Epoch [3/100], Loss: 0.6420, Validation Loss: 0.6673
	--> Epoch [4/100], Loss: 0.5778, Validation Loss: 0.6573
	--> Epoch [5/100], Loss: 0.7054, Validation Loss: 0.6486
	--> Epoch [6/100], Loss: 0.5686, Validation Loss: 0.6340
	--> Epoch [7/100], Loss: 0.6049, Validation Loss: 0.6201
	--> Epoch [8/100], Loss: 0.6165, Validation Loss: 0.6149
	--> Epoch [9/100], Loss: 0.6058, Validation Loss: 0.6087
	--> Epoch [10/100], Loss: 0.5320, Validation Loss: 0.6054
	--> Epoch [11/100], Loss: 0.6214, Validation Loss: 0.6000
	--> Epoch [12/100], Loss: 0.3952, Validation Loss: 0.5948
	--> Epoch [13/100], Loss: 0.3996, Validation Loss: 0.5889
	--> Epoch [14/100], Loss: 0.4798, Validation Loss: 0.5855
	--> Epoch [15/100], Loss: 0.4924, Validation Loss: 0.5802
	--> Epoch [16/100], Loss: 0.4390, Validation Loss: 0.5754
	--> Epoch [17/100], Loss: 0.3986, Validation Loss: 0.5679
	--> Epoch [18/100], Loss: 0.4345, Validation Loss: 0.5626
	--> Epoch [19/100], Loss: 0.3576, Validation Loss: 0.5578
	--> Epoch [20/100], Loss: 0.3345, Validation Loss: 0.5527
	--> Epoch [21/100], Loss: 0.4909, Validation Loss: 0.5459
	--> Epoch [22/100], Loss: 0.3896, Validation Loss: 0.5412
	--> Epoch [23/100], Loss: 0.3587, Validation Loss: 0.5349
	--> Epoch [24/100], Loss: 0.4287, Validation Loss: 0.5292
	--> Epoch [25/100], Loss: 0.2031, Validation Loss: 0.5259
	--> Epoch [26/100], Loss: 0.3209, Validation Loss: 0.5196
	--> Epoch [27/100], Loss: 0.3041, Validation Loss: 0.5127
	--> Epoch [28/100], Loss: 0.3503, Validation Loss: 0.5099
	--> Epoch [29/100], Loss: 0.2498, Validation Loss: 0.5054
	--> Epoch [30/100], Loss: 0.4334, Validation Loss: 0.5010
	--> Epoch [31/100], Loss: 0.3749, Validation Loss: 0.4970
	--> Epoch [32/100], Loss: 0.2557, Validation Loss: 0.4980
	--> Epoch [33/100], Loss: 0.4306, Validation Loss: 0.4908
	--> Epoch [34/100], Loss: 0.2953, Validation Loss: 0.4902
	--> Epoch [35/100], Loss: 0.3102, Validation Loss: 0.4892
	--> Epoch [36/100], Loss: 0.2683, Validation Loss: 0.4878
	--> Epoch [37/100], Loss: 0.2968, Validation Loss: 0.4867
	--> Epoch [38/100], Loss: 0.3776, Validation Loss: 0.4850
	--> Epoch [39/100], Loss: 0.3578, Validation Loss: 0.4802
	--> Epoch [40/100], Loss: 0.3106, Validation Loss: 0.4754
	--> Epoch [41/100], Loss: 0.2568, Validation Loss: 0.4726
	--> Epoch [42/100], Loss: 0.3438, Validation Loss: 0.4692
	--> Epoch [43/100], Loss: 0.2977, Validation Loss: 0.4678
	--> Epoch [44/100], Loss: 0.2045, Validation Loss: 0.4648
	--> Epoch [45/100], Loss: 0.2321, Validation Loss: 0.4640
	--> Epoch [46/100], Loss: 0.2499, Validation Loss: 0.4595
	--> Epoch [47/100], Loss: 0.2777, Validation Loss: 0.4602
	--> Epoch [48/100], Loss: 0.1866, Validation Loss: 0.4606
	--> Epoch [49/100], Loss: 0.1330, Validation Loss: 0.4619
Early stopping
	--> Training for Fold 5 took 0.6477313041687012 sec, using 49 epochs

Median number of epochs used: 61 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/61], Loss: 0.5907
	--> Final training Epoch [2/61], Loss: 0.6778
	--> Final training Epoch [3/61], Loss: 0.5873
	--> Final training Epoch [4/61], Loss: 0.5707
	--> Final training Epoch [5/61], Loss: 0.5338
	--> Final training Epoch [6/61], Loss: 0.5373
	--> Final training Epoch [7/61], Loss: 0.4877
	--> Final training Epoch [8/61], Loss: 0.5164
	--> Final training Epoch [9/61], Loss: 0.4346
	--> Final training Epoch [10/61], Loss: 0.4395
	--> Final training Epoch [11/61], Loss: 0.4396
	--> Final training Epoch [12/61], Loss: 0.3625
	--> Final training Epoch [13/61], Loss: 0.3316
	--> Final training Epoch [14/61], Loss: 0.3537
	--> Final training Epoch [15/61], Loss: 0.4305
	--> Final training Epoch [16/61], Loss: 0.3964
	--> Final training Epoch [17/61], Loss: 0.4098
	--> Final training Epoch [18/61], Loss: 0.3359
	--> Final training Epoch [19/61], Loss: 0.2875
	--> Final training Epoch [20/61], Loss: 0.4700
	--> Final training Epoch [21/61], Loss: 0.2647
	--> Final training Epoch [22/61], Loss: 0.2615
	--> Final training Epoch [23/61], Loss: 0.3629
	--> Final training Epoch [24/61], Loss: 0.2547
	--> Final training Epoch [25/61], Loss: 0.2754
	--> Final training Epoch [26/61], Loss: 0.3552
	--> Final training Epoch [27/61], Loss: 0.1691
	--> Final training Epoch [28/61], Loss: 0.2201
	--> Final training Epoch [29/61], Loss: 0.2566
	--> Final training Epoch [30/61], Loss: 0.2981
	--> Final training Epoch [31/61], Loss: 0.3036
	--> Final training Epoch [32/61], Loss: 0.3032
	--> Final training Epoch [33/61], Loss: 0.2008
	--> Final training Epoch [34/61], Loss: 0.1795
	--> Final training Epoch [35/61], Loss: 0.2597
	--> Final training Epoch [36/61], Loss: 0.1937
	--> Final training Epoch [37/61], Loss: 0.2449
	--> Final training Epoch [38/61], Loss: 0.4715
	--> Final training Epoch [39/61], Loss: 0.2646
	--> Final training Epoch [40/61], Loss: 0.2375
	--> Final training Epoch [41/61], Loss: 0.1372
	--> Final training Epoch [42/61], Loss: 0.2802
	--> Final training Epoch [43/61], Loss: 0.2773
	--> Final training Epoch [44/61], Loss: 0.1378
	--> Final training Epoch [45/61], Loss: 0.2434
	--> Final training Epoch [46/61], Loss: 0.1598
	--> Final training Epoch [47/61], Loss: 0.3683
	--> Final training Epoch [48/61], Loss: 0.2249
	--> Final training Epoch [49/61], Loss: 0.1400
	--> Final training Epoch [50/61], Loss: 0.2417
	--> Final training Epoch [51/61], Loss: 0.2842
	--> Final training Epoch [52/61], Loss: 0.3621
	--> Final training Epoch [53/61], Loss: 0.1790
	--> Final training Epoch [54/61], Loss: 0.3040
	--> Final training Epoch [55/61], Loss: 0.1330
	--> Final training Epoch [56/61], Loss: 0.2632
	--> Final training Epoch [57/61], Loss: 0.1833
	--> Final training Epoch [58/61], Loss: 0.2973
	--> Final training Epoch [59/61], Loss: 0.2059
	--> Final training Epoch [60/61], Loss: 0.3384
	--> Final training Epoch [61/61], Loss: 0.3453

Final training took 0.9547460079193115 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.8864
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3409,  Current Best Accuracy: 0.8275,  Current Best Validation Loss: 0.3409

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7668, Validation Loss: 0.8066
	--> Epoch [2/100], Loss: 0.6767, Validation Loss: 0.7610
	--> Epoch [3/100], Loss: 0.7564, Validation Loss: 0.7448
	--> Epoch [4/100], Loss: 0.6788, Validation Loss: 0.7285
	--> Epoch [5/100], Loss: 0.6931, Validation Loss: 0.7102
	--> Epoch [6/100], Loss: 0.7229, Validation Loss: 0.6874
	--> Epoch [7/100], Loss: 0.7047, Validation Loss: 0.6665
	--> Epoch [8/100], Loss: 0.5390, Validation Loss: 0.6529
	--> Epoch [9/100], Loss: 0.6105, Validation Loss: 0.6297
	--> Epoch [10/100], Loss: 0.4947, Validation Loss: 0.6162
	--> Epoch [11/100], Loss: 0.6341, Validation Loss: 0.6068
	--> Epoch [12/100], Loss: 0.5600, Validation Loss: 0.5868
	--> Epoch [13/100], Loss: 0.5036, Validation Loss: 0.5759
	--> Epoch [14/100], Loss: 0.4583, Validation Loss: 0.5646
	--> Epoch [15/100], Loss: 0.3997, Validation Loss: 0.5562
	--> Epoch [16/100], Loss: 0.4729, Validation Loss: 0.5525
	--> Epoch [17/100], Loss: 0.5002, Validation Loss: 0.5459
	--> Epoch [18/100], Loss: 0.4808, Validation Loss: 0.5442
	--> Epoch [19/100], Loss: 0.5314, Validation Loss: 0.5380
	--> Epoch [20/100], Loss: 0.3701, Validation Loss: 0.5312
	--> Epoch [21/100], Loss: 0.3383, Validation Loss: 0.5258
	--> Epoch [22/100], Loss: 0.3576, Validation Loss: 0.5176
	--> Epoch [23/100], Loss: 0.3809, Validation Loss: 0.5064
	--> Epoch [24/100], Loss: 0.5520, Validation Loss: 0.4989
	--> Epoch [25/100], Loss: 0.5418, Validation Loss: 0.4908
	--> Epoch [26/100], Loss: 0.2500, Validation Loss: 0.4863
	--> Epoch [27/100], Loss: 0.3713, Validation Loss: 0.4829
	--> Epoch [28/100], Loss: 0.4505, Validation Loss: 0.4744
	--> Epoch [29/100], Loss: 0.5737, Validation Loss: 0.4707
	--> Epoch [30/100], Loss: 0.2330, Validation Loss: 0.4646
	--> Epoch [31/100], Loss: 0.4508, Validation Loss: 0.4669
	--> Epoch [32/100], Loss: 0.3228, Validation Loss: 0.4580
	--> Epoch [33/100], Loss: 0.3619, Validation Loss: 0.4561
	--> Epoch [34/100], Loss: 0.5246, Validation Loss: 0.4557
	--> Epoch [35/100], Loss: 0.2006, Validation Loss: 0.4481
	--> Epoch [36/100], Loss: 0.4376, Validation Loss: 0.4446
	--> Epoch [37/100], Loss: 0.2401, Validation Loss: 0.4419
	--> Epoch [38/100], Loss: 0.2626, Validation Loss: 0.4387
	--> Epoch [39/100], Loss: 0.2588, Validation Loss: 0.4329
	--> Epoch [40/100], Loss: 0.2426, Validation Loss: 0.4283
	--> Epoch [41/100], Loss: 0.1766, Validation Loss: 0.4257
	--> Epoch [42/100], Loss: 0.2966, Validation Loss: 0.4223
	--> Epoch [43/100], Loss: 0.2924, Validation Loss: 0.4194
	--> Epoch [44/100], Loss: 0.4291, Validation Loss: 0.4144
	--> Epoch [45/100], Loss: 0.2205, Validation Loss: 0.4112
	--> Epoch [46/100], Loss: 0.1873, Validation Loss: 0.4113
	--> Epoch [47/100], Loss: 0.1186, Validation Loss: 0.4075
	--> Epoch [48/100], Loss: 0.3505, Validation Loss: 0.4022
	--> Epoch [49/100], Loss: 0.3748, Validation Loss: 0.3990
	--> Epoch [50/100], Loss: 0.2452, Validation Loss: 0.3978
	--> Epoch [51/100], Loss: 0.3215, Validation Loss: 0.3976
	--> Epoch [52/100], Loss: 0.3606, Validation Loss: 0.3925
	--> Epoch [53/100], Loss: 0.2692, Validation Loss: 0.3880
	--> Epoch [54/100], Loss: 0.1168, Validation Loss: 0.3894
	--> Epoch [55/100], Loss: 0.3543, Validation Loss: 0.3877
	--> Epoch [56/100], Loss: 0.3170, Validation Loss: 0.3862
	--> Epoch [57/100], Loss: 0.3034, Validation Loss: 0.3864
	--> Epoch [58/100], Loss: 0.4037, Validation Loss: 0.3855
	--> Epoch [59/100], Loss: 0.2205, Validation Loss: 0.3846
	--> Epoch [60/100], Loss: 0.3967, Validation Loss: 0.3820
	--> Epoch [61/100], Loss: 0.1125, Validation Loss: 0.3794
	--> Epoch [62/100], Loss: 0.1388, Validation Loss: 0.3748
	--> Epoch [63/100], Loss: 0.3895, Validation Loss: 0.3752
	--> Epoch [64/100], Loss: 0.2644, Validation Loss: 0.3786
	--> Epoch [65/100], Loss: 0.2790, Validation Loss: 0.3709
	--> Epoch [66/100], Loss: 0.4996, Validation Loss: 0.3723
	--> Epoch [67/100], Loss: 0.2995, Validation Loss: 0.3696
	--> Epoch [68/100], Loss: 0.4469, Validation Loss: 0.3700
	--> Epoch [69/100], Loss: 0.1577, Validation Loss: 0.3649
	--> Epoch [70/100], Loss: 0.2079, Validation Loss: 0.3614
	--> Epoch [71/100], Loss: 0.2089, Validation Loss: 0.3591
	--> Epoch [72/100], Loss: 0.1137, Validation Loss: 0.3577
	--> Epoch [73/100], Loss: 0.1052, Validation Loss: 0.3572
	--> Epoch [74/100], Loss: 0.2054, Validation Loss: 0.3575
	--> Epoch [75/100], Loss: 0.3050, Validation Loss: 0.3582
	--> Epoch [76/100], Loss: 0.1183, Validation Loss: 0.3592
Early stopping
	--> Training for Fold 1 took 0.9742743968963623 sec, using 76 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7782, Validation Loss: 0.6685
	--> Epoch [2/100], Loss: 0.6834, Validation Loss: 0.6383
	--> Epoch [3/100], Loss: 0.6626, Validation Loss: 0.6195
	--> Epoch [4/100], Loss: 0.6155, Validation Loss: 0.6016
	--> Epoch [5/100], Loss: 0.5963, Validation Loss: 0.5876
	--> Epoch [6/100], Loss: 0.6665, Validation Loss: 0.5768
	--> Epoch [7/100], Loss: 0.5160, Validation Loss: 0.5667
	--> Epoch [8/100], Loss: 0.5655, Validation Loss: 0.5591
	--> Epoch [9/100], Loss: 0.5717, Validation Loss: 0.5466
	--> Epoch [10/100], Loss: 0.5070, Validation Loss: 0.5326
	--> Epoch [11/100], Loss: 0.5752, Validation Loss: 0.5231
	--> Epoch [12/100], Loss: 0.5138, Validation Loss: 0.5151
	--> Epoch [13/100], Loss: 0.4305, Validation Loss: 0.5063
	--> Epoch [14/100], Loss: 0.5356, Validation Loss: 0.4934
	--> Epoch [15/100], Loss: 0.3926, Validation Loss: 0.4836
	--> Epoch [16/100], Loss: 0.2793, Validation Loss: 0.4753
	--> Epoch [17/100], Loss: 0.5348, Validation Loss: 0.4638
	--> Epoch [18/100], Loss: 0.5324, Validation Loss: 0.4540
	--> Epoch [19/100], Loss: 0.2707, Validation Loss: 0.4422
	--> Epoch [20/100], Loss: 0.3714, Validation Loss: 0.4284
	--> Epoch [21/100], Loss: 0.3409, Validation Loss: 0.4209
	--> Epoch [22/100], Loss: 0.6583, Validation Loss: 0.4149
	--> Epoch [23/100], Loss: 0.3230, Validation Loss: 0.4075
	--> Epoch [24/100], Loss: 0.2471, Validation Loss: 0.3991
	--> Epoch [25/100], Loss: 0.2502, Validation Loss: 0.3929
	--> Epoch [26/100], Loss: 0.2859, Validation Loss: 0.3842
	--> Epoch [27/100], Loss: 0.2186, Validation Loss: 0.3788
	--> Epoch [28/100], Loss: 0.3589, Validation Loss: 0.3741
	--> Epoch [29/100], Loss: 0.3865, Validation Loss: 0.3671
	--> Epoch [30/100], Loss: 0.2806, Validation Loss: 0.3584
	--> Epoch [31/100], Loss: 0.2393, Validation Loss: 0.3547
	--> Epoch [32/100], Loss: 0.3736, Validation Loss: 0.3500
	--> Epoch [33/100], Loss: 0.3051, Validation Loss: 0.3433
	--> Epoch [34/100], Loss: 0.2585, Validation Loss: 0.3376
	--> Epoch [35/100], Loss: 0.2041, Validation Loss: 0.3359
	--> Epoch [36/100], Loss: 0.3365, Validation Loss: 0.3331
	--> Epoch [37/100], Loss: 0.2070, Validation Loss: 0.3313
	--> Epoch [38/100], Loss: 0.3596, Validation Loss: 0.3253
	--> Epoch [39/100], Loss: 0.2573, Validation Loss: 0.3230
	--> Epoch [40/100], Loss: 0.2755, Validation Loss: 0.3234
	--> Epoch [41/100], Loss: 0.3258, Validation Loss: 0.3221
	--> Epoch [42/100], Loss: 0.3723, Validation Loss: 0.3177
	--> Epoch [43/100], Loss: 0.1376, Validation Loss: 0.3144
	--> Epoch [44/100], Loss: 0.2478, Validation Loss: 0.3081
	--> Epoch [45/100], Loss: 0.1761, Validation Loss: 0.3059
	--> Epoch [46/100], Loss: 0.3167, Validation Loss: 0.3038
	--> Epoch [47/100], Loss: 0.2479, Validation Loss: 0.3015
	--> Epoch [48/100], Loss: 0.4077, Validation Loss: 0.2994
	--> Epoch [49/100], Loss: 0.3902, Validation Loss: 0.2974
	--> Epoch [50/100], Loss: 0.2435, Validation Loss: 0.2976
	--> Epoch [51/100], Loss: 0.3124, Validation Loss: 0.2968
	--> Epoch [52/100], Loss: 0.1870, Validation Loss: 0.2959
	--> Epoch [53/100], Loss: 0.4009, Validation Loss: 0.2955
	--> Epoch [54/100], Loss: 0.1702, Validation Loss: 0.2972
	--> Epoch [55/100], Loss: 0.1963, Validation Loss: 0.2984
	--> Epoch [56/100], Loss: 0.3250, Validation Loss: 0.2996
Early stopping
	--> Training for Fold 2 took 0.7289249897003174 sec, using 56 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7099, Validation Loss: 0.6451
	--> Epoch [2/100], Loss: 0.5622, Validation Loss: 0.6286
	--> Epoch [3/100], Loss: 0.7572, Validation Loss: 0.6160
	--> Epoch [4/100], Loss: 0.5549, Validation Loss: 0.6082
	--> Epoch [5/100], Loss: 0.6791, Validation Loss: 0.5959
	--> Epoch [6/100], Loss: 0.6508, Validation Loss: 0.5863
	--> Epoch [7/100], Loss: 0.5051, Validation Loss: 0.5785
	--> Epoch [8/100], Loss: 0.5609, Validation Loss: 0.5702
	--> Epoch [9/100], Loss: 0.5675, Validation Loss: 0.5646
	--> Epoch [10/100], Loss: 0.4559, Validation Loss: 0.5575
	--> Epoch [11/100], Loss: 0.4029, Validation Loss: 0.5522
	--> Epoch [12/100], Loss: 0.4866, Validation Loss: 0.5454
	--> Epoch [13/100], Loss: 0.5107, Validation Loss: 0.5358
	--> Epoch [14/100], Loss: 0.3808, Validation Loss: 0.5279
	--> Epoch [15/100], Loss: 0.5986, Validation Loss: 0.5210
	--> Epoch [16/100], Loss: 0.4608, Validation Loss: 0.5127
	--> Epoch [17/100], Loss: 0.4178, Validation Loss: 0.5073
	--> Epoch [18/100], Loss: 0.4975, Validation Loss: 0.5011
	--> Epoch [19/100], Loss: 0.2458, Validation Loss: 0.4908
	--> Epoch [20/100], Loss: 0.4106, Validation Loss: 0.4834
	--> Epoch [21/100], Loss: 0.4701, Validation Loss: 0.4776
	--> Epoch [22/100], Loss: 0.3911, Validation Loss: 0.4726
	--> Epoch [23/100], Loss: 0.4068, Validation Loss: 0.4636
	--> Epoch [24/100], Loss: 0.3332, Validation Loss: 0.4553
	--> Epoch [25/100], Loss: 0.2784, Validation Loss: 0.4497
	--> Epoch [26/100], Loss: 0.2567, Validation Loss: 0.4445
	--> Epoch [27/100], Loss: 0.3660, Validation Loss: 0.4381
	--> Epoch [28/100], Loss: 0.1869, Validation Loss: 0.4302
	--> Epoch [29/100], Loss: 0.4008, Validation Loss: 0.4276
	--> Epoch [30/100], Loss: 0.1956, Validation Loss: 0.4231
	--> Epoch [31/100], Loss: 0.3635, Validation Loss: 0.4182
	--> Epoch [32/100], Loss: 0.3213, Validation Loss: 0.4143
	--> Epoch [33/100], Loss: 0.2271, Validation Loss: 0.4081
	--> Epoch [34/100], Loss: 0.3528, Validation Loss: 0.4053
	--> Epoch [35/100], Loss: 0.3573, Validation Loss: 0.3989
	--> Epoch [36/100], Loss: 0.3525, Validation Loss: 0.3914
	--> Epoch [37/100], Loss: 0.1947, Validation Loss: 0.3832
	--> Epoch [38/100], Loss: 0.1437, Validation Loss: 0.3793
	--> Epoch [39/100], Loss: 0.1162, Validation Loss: 0.3789
	--> Epoch [40/100], Loss: 0.1564, Validation Loss: 0.3743
	--> Epoch [41/100], Loss: 0.3808, Validation Loss: 0.3709
	--> Epoch [42/100], Loss: 0.2309, Validation Loss: 0.3636
	--> Epoch [43/100], Loss: 0.4369, Validation Loss: 0.3610
	--> Epoch [44/100], Loss: 0.3909, Validation Loss: 0.3585
	--> Epoch [45/100], Loss: 0.2429, Validation Loss: 0.3565
	--> Epoch [46/100], Loss: 0.2512, Validation Loss: 0.3525
	--> Epoch [47/100], Loss: 0.3120, Validation Loss: 0.3478
	--> Epoch [48/100], Loss: 0.3819, Validation Loss: 0.3489
	--> Epoch [49/100], Loss: 0.3783, Validation Loss: 0.3483
	--> Epoch [50/100], Loss: 0.3947, Validation Loss: 0.3469
	--> Epoch [51/100], Loss: 0.2382, Validation Loss: 0.3434
	--> Epoch [52/100], Loss: 0.3152, Validation Loss: 0.3428
	--> Epoch [53/100], Loss: 0.2619, Validation Loss: 0.3386
	--> Epoch [54/100], Loss: 0.1024, Validation Loss: 0.3352
	--> Epoch [55/100], Loss: 0.1793, Validation Loss: 0.3333
	--> Epoch [56/100], Loss: 0.4136, Validation Loss: 0.3298
	--> Epoch [57/100], Loss: 0.1389, Validation Loss: 0.3292
	--> Epoch [58/100], Loss: 0.3901, Validation Loss: 0.3236
	--> Epoch [59/100], Loss: 0.1088, Validation Loss: 0.3187
	--> Epoch [60/100], Loss: 0.3173, Validation Loss: 0.3197
	--> Epoch [61/100], Loss: 0.5060, Validation Loss: 0.3175
	--> Epoch [62/100], Loss: 0.3186, Validation Loss: 0.3170
	--> Epoch [63/100], Loss: 0.1691, Validation Loss: 0.3155
	--> Epoch [64/100], Loss: 0.2996, Validation Loss: 0.3153
	--> Epoch [65/100], Loss: 0.1694, Validation Loss: 0.3133
	--> Epoch [66/100], Loss: 0.3093, Validation Loss: 0.3117
	--> Epoch [67/100], Loss: 0.3008, Validation Loss: 0.3116
	--> Epoch [68/100], Loss: 0.3146, Validation Loss: 0.3100
	--> Epoch [69/100], Loss: 0.2180, Validation Loss: 0.3075
	--> Epoch [70/100], Loss: 0.3062, Validation Loss: 0.3080
	--> Epoch [71/100], Loss: 0.3075, Validation Loss: 0.3079
	--> Epoch [72/100], Loss: 0.3077, Validation Loss: 0.3052
	--> Epoch [73/100], Loss: 0.3707, Validation Loss: 0.3042
	--> Epoch [74/100], Loss: 0.3709, Validation Loss: 0.3036
	--> Epoch [75/100], Loss: 0.1653, Validation Loss: 0.2997
	--> Epoch [76/100], Loss: 0.3013, Validation Loss: 0.2996
	--> Epoch [77/100], Loss: 0.5103, Validation Loss: 0.2993
	--> Epoch [78/100], Loss: 0.1517, Validation Loss: 0.2993
	--> Epoch [79/100], Loss: 0.1606, Validation Loss: 0.2993
	--> Epoch [80/100], Loss: 0.1567, Validation Loss: 0.2977
	--> Epoch [81/100], Loss: 0.2152, Validation Loss: 0.2976
	--> Epoch [82/100], Loss: 0.1523, Validation Loss: 0.2983
	--> Epoch [83/100], Loss: 0.1727, Validation Loss: 0.2975
	--> Epoch [84/100], Loss: 0.0797, Validation Loss: 0.2978
	--> Epoch [85/100], Loss: 0.3683, Validation Loss: 0.2965
	--> Epoch [86/100], Loss: 0.1589, Validation Loss: 0.2992
	--> Epoch [87/100], Loss: 0.1527, Validation Loss: 0.3003
	--> Epoch [88/100], Loss: 0.2219, Validation Loss: 0.2984
Early stopping
	--> Training for Fold 3 took 1.139631986618042 sec, using 88 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.9051, Validation Loss: 0.5715
	--> Epoch [2/100], Loss: 0.7304, Validation Loss: 0.5581
	--> Epoch [3/100], Loss: 0.7522, Validation Loss: 0.5484
	--> Epoch [4/100], Loss: 0.9072, Validation Loss: 0.5448
	--> Epoch [5/100], Loss: 0.7216, Validation Loss: 0.5380
	--> Epoch [6/100], Loss: 0.6256, Validation Loss: 0.5246
	--> Epoch [7/100], Loss: 0.7103, Validation Loss: 0.5161
	--> Epoch [8/100], Loss: 0.6357, Validation Loss: 0.5071
	--> Epoch [9/100], Loss: 0.6400, Validation Loss: 0.4985
	--> Epoch [10/100], Loss: 0.5930, Validation Loss: 0.4878
	--> Epoch [11/100], Loss: 0.5442, Validation Loss: 0.4779
	--> Epoch [12/100], Loss: 0.6283, Validation Loss: 0.4724
	--> Epoch [13/100], Loss: 0.6281, Validation Loss: 0.4646
	--> Epoch [14/100], Loss: 0.5843, Validation Loss: 0.4566
	--> Epoch [15/100], Loss: 0.6009, Validation Loss: 0.4514
	--> Epoch [16/100], Loss: 0.4450, Validation Loss: 0.4409
	--> Epoch [17/100], Loss: 0.5241, Validation Loss: 0.4363
	--> Epoch [18/100], Loss: 0.3641, Validation Loss: 0.4274
	--> Epoch [19/100], Loss: 0.5730, Validation Loss: 0.4223
	--> Epoch [20/100], Loss: 0.3645, Validation Loss: 0.4160
	--> Epoch [21/100], Loss: 0.5648, Validation Loss: 0.4200
	--> Epoch [22/100], Loss: 0.4511, Validation Loss: 0.4154
	--> Epoch [23/100], Loss: 0.4109, Validation Loss: 0.4102
	--> Epoch [24/100], Loss: 0.6282, Validation Loss: 0.4097
	--> Epoch [25/100], Loss: 0.3935, Validation Loss: 0.4068
	--> Epoch [26/100], Loss: 0.4593, Validation Loss: 0.4042
	--> Epoch [27/100], Loss: 0.3818, Validation Loss: 0.3979
	--> Epoch [28/100], Loss: 0.2788, Validation Loss: 0.3901
	--> Epoch [29/100], Loss: 0.3497, Validation Loss: 0.3843
	--> Epoch [30/100], Loss: 0.3254, Validation Loss: 0.3868
	--> Epoch [31/100], Loss: 0.4686, Validation Loss: 0.3796
	--> Epoch [32/100], Loss: 0.3553, Validation Loss: 0.3745
	--> Epoch [33/100], Loss: 0.2903, Validation Loss: 0.3706
	--> Epoch [34/100], Loss: 0.3759, Validation Loss: 0.3675
	--> Epoch [35/100], Loss: 0.4298, Validation Loss: 0.3636
	--> Epoch [36/100], Loss: 0.4523, Validation Loss: 0.3614
	--> Epoch [37/100], Loss: 0.4126, Validation Loss: 0.3602
	--> Epoch [38/100], Loss: 0.5281, Validation Loss: 0.3633
	--> Epoch [39/100], Loss: 0.3284, Validation Loss: 0.3696
	--> Epoch [40/100], Loss: 0.3870, Validation Loss: 0.3708
Early stopping
	--> Training for Fold 4 took 0.5308756828308105 sec, using 40 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6246, Validation Loss: 0.7651
	--> Epoch [2/100], Loss: 0.5715, Validation Loss: 0.7430
	--> Epoch [3/100], Loss: 0.5951, Validation Loss: 0.7275
	--> Epoch [4/100], Loss: 0.6106, Validation Loss: 0.7167
	--> Epoch [5/100], Loss: 0.5042, Validation Loss: 0.7052
	--> Epoch [6/100], Loss: 0.5125, Validation Loss: 0.6988
	--> Epoch [7/100], Loss: 0.4502, Validation Loss: 0.6927
	--> Epoch [8/100], Loss: 0.5228, Validation Loss: 0.6861
	--> Epoch [9/100], Loss: 0.3423, Validation Loss: 0.6832
	--> Epoch [10/100], Loss: 0.3927, Validation Loss: 0.6769
	--> Epoch [11/100], Loss: 0.3245, Validation Loss: 0.6749
	--> Epoch [12/100], Loss: 0.3299, Validation Loss: 0.6774
	--> Epoch [13/100], Loss: 0.3156, Validation Loss: 0.6755
	--> Epoch [14/100], Loss: 0.4920, Validation Loss: 0.6721
	--> Epoch [15/100], Loss: 0.3407, Validation Loss: 0.6689
	--> Epoch [16/100], Loss: 0.3086, Validation Loss: 0.6661
	--> Epoch [17/100], Loss: 0.3071, Validation Loss: 0.6662
	--> Epoch [18/100], Loss: 0.3656, Validation Loss: 0.6647
	--> Epoch [19/100], Loss: 0.3544, Validation Loss: 0.6670
	--> Epoch [20/100], Loss: 0.3422, Validation Loss: 0.6689
	--> Epoch [21/100], Loss: 0.2959, Validation Loss: 0.6710
Early stopping
	--> Training for Fold 5 took 0.26596498489379883 sec, using 21 epochs

Median number of epochs used: 56 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/56], Loss: 0.7937
	--> Final training Epoch [2/56], Loss: 0.8562
	--> Final training Epoch [3/56], Loss: 0.7250
	--> Final training Epoch [4/56], Loss: 0.7005
	--> Final training Epoch [5/56], Loss: 0.7655
	--> Final training Epoch [6/56], Loss: 0.7519
	--> Final training Epoch [7/56], Loss: 0.6135
	--> Final training Epoch [8/56], Loss: 0.4839
	--> Final training Epoch [9/56], Loss: 0.7026
	--> Final training Epoch [10/56], Loss: 0.6565
	--> Final training Epoch [11/56], Loss: 0.5767
	--> Final training Epoch [12/56], Loss: 0.6469
	--> Final training Epoch [13/56], Loss: 0.4457
	--> Final training Epoch [14/56], Loss: 0.5888
	--> Final training Epoch [15/56], Loss: 0.6616
	--> Final training Epoch [16/56], Loss: 0.5092
	--> Final training Epoch [17/56], Loss: 0.5145
	--> Final training Epoch [18/56], Loss: 0.6158
	--> Final training Epoch [19/56], Loss: 0.5309
	--> Final training Epoch [20/56], Loss: 0.4941
	--> Final training Epoch [21/56], Loss: 0.4151
	--> Final training Epoch [22/56], Loss: 0.4502
	--> Final training Epoch [23/56], Loss: 0.4230
	--> Final training Epoch [24/56], Loss: 0.5197
	--> Final training Epoch [25/56], Loss: 0.4104
	--> Final training Epoch [26/56], Loss: 0.4592
	--> Final training Epoch [27/56], Loss: 0.4408
	--> Final training Epoch [28/56], Loss: 0.3596
	--> Final training Epoch [29/56], Loss: 0.3672
	--> Final training Epoch [30/56], Loss: 0.3982
	--> Final training Epoch [31/56], Loss: 0.4681
	--> Final training Epoch [32/56], Loss: 0.3088
	--> Final training Epoch [33/56], Loss: 0.3312
	--> Final training Epoch [34/56], Loss: 0.2103
	--> Final training Epoch [35/56], Loss: 0.4618
	--> Final training Epoch [36/56], Loss: 0.2745
	--> Final training Epoch [37/56], Loss: 0.4379
	--> Final training Epoch [38/56], Loss: 0.2294
	--> Final training Epoch [39/56], Loss: 0.2652
	--> Final training Epoch [40/56], Loss: 0.3552
	--> Final training Epoch [41/56], Loss: 0.2976
	--> Final training Epoch [42/56], Loss: 0.2314
	--> Final training Epoch [43/56], Loss: 0.3054
	--> Final training Epoch [44/56], Loss: 0.3246
	--> Final training Epoch [45/56], Loss: 0.2354
	--> Final training Epoch [46/56], Loss: 0.3238
	--> Final training Epoch [47/56], Loss: 0.4117
	--> Final training Epoch [48/56], Loss: 0.2865
	--> Final training Epoch [49/56], Loss: 0.4571
	--> Final training Epoch [50/56], Loss: 0.3570
	--> Final training Epoch [51/56], Loss: 0.3710
	--> Final training Epoch [52/56], Loss: 0.3077
	--> Final training Epoch [53/56], Loss: 0.3064
	--> Final training Epoch [54/56], Loss: 0.3288
	--> Final training Epoch [55/56], Loss: 0.2681
	--> Final training Epoch [56/56], Loss: 0.3590

Final training took 0.8599183559417725 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8028
	--> Final Precision: 0.6923
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6923
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8374, Validation Loss: 0.3575,  Current Best Accuracy: 0.8374,  Current Best Validation Loss: 0.3575

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6354, Validation Loss: 0.6375
	--> Epoch [2/100], Loss: 0.6676, Validation Loss: 0.5849
	--> Epoch [3/100], Loss: 0.5198, Validation Loss: 0.5429
	--> Epoch [4/100], Loss: 0.5808, Validation Loss: 0.5142
	--> Epoch [5/100], Loss: 0.5299, Validation Loss: 0.5017
	--> Epoch [6/100], Loss: 0.5385, Validation Loss: 0.4877
	--> Epoch [7/100], Loss: 0.4455, Validation Loss: 0.4743
	--> Epoch [8/100], Loss: 0.2722, Validation Loss: 0.4610
	--> Epoch [9/100], Loss: 0.3302, Validation Loss: 0.4445
	--> Epoch [10/100], Loss: 0.4210, Validation Loss: 0.4353
	--> Epoch [11/100], Loss: 0.4634, Validation Loss: 0.4252
	--> Epoch [12/100], Loss: 0.4358, Validation Loss: 0.4151
	--> Epoch [13/100], Loss: 0.4370, Validation Loss: 0.4093
	--> Epoch [14/100], Loss: 0.3700, Validation Loss: 0.4104
	--> Epoch [15/100], Loss: 0.2826, Validation Loss: 0.4041
	--> Epoch [16/100], Loss: 0.5334, Validation Loss: 0.3968
	--> Epoch [17/100], Loss: 0.2853, Validation Loss: 0.3913
	--> Epoch [18/100], Loss: 0.3801, Validation Loss: 0.3848
	--> Epoch [19/100], Loss: 0.2506, Validation Loss: 0.3798
	--> Epoch [20/100], Loss: 0.3657, Validation Loss: 0.3732
	--> Epoch [21/100], Loss: 0.2688, Validation Loss: 0.3701
	--> Epoch [22/100], Loss: 0.2993, Validation Loss: 0.3666
	--> Epoch [23/100], Loss: 0.3087, Validation Loss: 0.3621
	--> Epoch [24/100], Loss: 0.4543, Validation Loss: 0.3625
	--> Epoch [25/100], Loss: 0.4175, Validation Loss: 0.3557
	--> Epoch [26/100], Loss: 0.3851, Validation Loss: 0.3512
	--> Epoch [27/100], Loss: 0.2188, Validation Loss: 0.3469
	--> Epoch [28/100], Loss: 0.2972, Validation Loss: 0.3445
	--> Epoch [29/100], Loss: 0.2537, Validation Loss: 0.3381
	--> Epoch [30/100], Loss: 0.3296, Validation Loss: 0.3366
	--> Epoch [31/100], Loss: 0.2443, Validation Loss: 0.3349
	--> Epoch [32/100], Loss: 0.3625, Validation Loss: 0.3300
	--> Epoch [33/100], Loss: 0.1207, Validation Loss: 0.3268
	--> Epoch [34/100], Loss: 0.4673, Validation Loss: 0.3225
	--> Epoch [35/100], Loss: 0.2051, Validation Loss: 0.3180
	--> Epoch [36/100], Loss: 0.2665, Validation Loss: 0.3175
	--> Epoch [37/100], Loss: 0.2388, Validation Loss: 0.3135
	--> Epoch [38/100], Loss: 0.3785, Validation Loss: 0.3112
	--> Epoch [39/100], Loss: 0.2342, Validation Loss: 0.3102
	--> Epoch [40/100], Loss: 0.3065, Validation Loss: 0.3096
	--> Epoch [41/100], Loss: 0.2251, Validation Loss: 0.3107
	--> Epoch [42/100], Loss: 0.2187, Validation Loss: 0.3080
	--> Epoch [43/100], Loss: 0.1488, Validation Loss: 0.3054
	--> Epoch [44/100], Loss: 0.2809, Validation Loss: 0.3044
	--> Epoch [45/100], Loss: 0.4495, Validation Loss: 0.3030
	--> Epoch [46/100], Loss: 0.2177, Validation Loss: 0.3010
	--> Epoch [47/100], Loss: 0.1959, Validation Loss: 0.2990
	--> Epoch [48/100], Loss: 0.2272, Validation Loss: 0.2956
	--> Epoch [49/100], Loss: 0.3464, Validation Loss: 0.2946
	--> Epoch [50/100], Loss: 0.3952, Validation Loss: 0.2966
	--> Epoch [51/100], Loss: 0.2387, Validation Loss: 0.2936
	--> Epoch [52/100], Loss: 0.2860, Validation Loss: 0.2927
	--> Epoch [53/100], Loss: 0.2954, Validation Loss: 0.2915
	--> Epoch [54/100], Loss: 0.2156, Validation Loss: 0.2895
	--> Epoch [55/100], Loss: 0.2449, Validation Loss: 0.2904
	--> Epoch [56/100], Loss: 0.2820, Validation Loss: 0.2896
	--> Epoch [57/100], Loss: 0.2301, Validation Loss: 0.2869
	--> Epoch [58/100], Loss: 0.0993, Validation Loss: 0.2867
	--> Epoch [59/100], Loss: 0.1632, Validation Loss: 0.2855
	--> Epoch [60/100], Loss: 0.3073, Validation Loss: 0.2840
	--> Epoch [61/100], Loss: 0.1473, Validation Loss: 0.2843
	--> Epoch [62/100], Loss: 0.3519, Validation Loss: 0.2845
	--> Epoch [63/100], Loss: 0.3674, Validation Loss: 0.2812
	--> Epoch [64/100], Loss: 0.1497, Validation Loss: 0.2804
	--> Epoch [65/100], Loss: 0.2870, Validation Loss: 0.2788
	--> Epoch [66/100], Loss: 0.1725, Validation Loss: 0.2799
	--> Epoch [67/100], Loss: 0.2258, Validation Loss: 0.2745
	--> Epoch [68/100], Loss: 0.3082, Validation Loss: 0.2757
	--> Epoch [69/100], Loss: 0.3589, Validation Loss: 0.2728
	--> Epoch [70/100], Loss: 0.2147, Validation Loss: 0.2716
	--> Epoch [71/100], Loss: 0.0806, Validation Loss: 0.2722
	--> Epoch [72/100], Loss: 0.1607, Validation Loss: 0.2721
	--> Epoch [73/100], Loss: 0.1545, Validation Loss: 0.2718
Early stopping
	--> Training for Fold 1 took 0.9231939315795898 sec, using 73 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6530, Validation Loss: 0.6431
	--> Epoch [2/100], Loss: 0.8239, Validation Loss: 0.6291
	--> Epoch [3/100], Loss: 0.7590, Validation Loss: 0.6129
	--> Epoch [4/100], Loss: 0.7027, Validation Loss: 0.6013
	--> Epoch [5/100], Loss: 0.5577, Validation Loss: 0.5817
	--> Epoch [6/100], Loss: 0.6547, Validation Loss: 0.5680
	--> Epoch [7/100], Loss: 0.4873, Validation Loss: 0.5586
	--> Epoch [8/100], Loss: 0.7060, Validation Loss: 0.5435
	--> Epoch [9/100], Loss: 0.6080, Validation Loss: 0.5282
	--> Epoch [10/100], Loss: 0.6430, Validation Loss: 0.5145
	--> Epoch [11/100], Loss: 0.6498, Validation Loss: 0.5065
	--> Epoch [12/100], Loss: 0.4897, Validation Loss: 0.4943
	--> Epoch [13/100], Loss: 0.5705, Validation Loss: 0.4840
	--> Epoch [14/100], Loss: 0.6403, Validation Loss: 0.4732
	--> Epoch [15/100], Loss: 0.5555, Validation Loss: 0.4620
	--> Epoch [16/100], Loss: 0.6377, Validation Loss: 0.4528
	--> Epoch [17/100], Loss: 0.4227, Validation Loss: 0.4433
	--> Epoch [18/100], Loss: 0.5275, Validation Loss: 0.4341
	--> Epoch [19/100], Loss: 0.6257, Validation Loss: 0.4259
	--> Epoch [20/100], Loss: 0.4440, Validation Loss: 0.4170
	--> Epoch [21/100], Loss: 0.5058, Validation Loss: 0.4083
	--> Epoch [22/100], Loss: 0.6607, Validation Loss: 0.4006
	--> Epoch [23/100], Loss: 0.3999, Validation Loss: 0.3931
	--> Epoch [24/100], Loss: 0.4044, Validation Loss: 0.3855
	--> Epoch [25/100], Loss: 0.2983, Validation Loss: 0.3785
	--> Epoch [26/100], Loss: 0.2926, Validation Loss: 0.3746
	--> Epoch [27/100], Loss: 0.6799, Validation Loss: 0.3690
	--> Epoch [28/100], Loss: 0.2854, Validation Loss: 0.3622
	--> Epoch [29/100], Loss: 0.4549, Validation Loss: 0.3575
	--> Epoch [30/100], Loss: 0.4255, Validation Loss: 0.3525
	--> Epoch [31/100], Loss: 0.3676, Validation Loss: 0.3500
	--> Epoch [32/100], Loss: 0.3672, Validation Loss: 0.3433
	--> Epoch [33/100], Loss: 0.1997, Validation Loss: 0.3395
	--> Epoch [34/100], Loss: 0.2979, Validation Loss: 0.3357
	--> Epoch [35/100], Loss: 0.1902, Validation Loss: 0.3310
	--> Epoch [36/100], Loss: 0.3352, Validation Loss: 0.3261
	--> Epoch [37/100], Loss: 0.2929, Validation Loss: 0.3239
	--> Epoch [38/100], Loss: 0.3665, Validation Loss: 0.3220
	--> Epoch [39/100], Loss: 0.3506, Validation Loss: 0.3166
	--> Epoch [40/100], Loss: 0.2964, Validation Loss: 0.3167
	--> Epoch [41/100], Loss: 0.2520, Validation Loss: 0.3116
	--> Epoch [42/100], Loss: 0.2844, Validation Loss: 0.3090
	--> Epoch [43/100], Loss: 0.2983, Validation Loss: 0.3097
	--> Epoch [44/100], Loss: 0.2239, Validation Loss: 0.3047
	--> Epoch [45/100], Loss: 0.1932, Validation Loss: 0.3007
	--> Epoch [46/100], Loss: 0.2458, Validation Loss: 0.3009
	--> Epoch [47/100], Loss: 0.4387, Validation Loss: 0.2978
	--> Epoch [48/100], Loss: 0.2969, Validation Loss: 0.2941
	--> Epoch [49/100], Loss: 0.2708, Validation Loss: 0.2928
	--> Epoch [50/100], Loss: 0.1931, Validation Loss: 0.2880
	--> Epoch [51/100], Loss: 0.2529, Validation Loss: 0.2844
	--> Epoch [52/100], Loss: 0.1856, Validation Loss: 0.2850
	--> Epoch [53/100], Loss: 0.1892, Validation Loss: 0.2824
	--> Epoch [54/100], Loss: 0.3390, Validation Loss: 0.2798
	--> Epoch [55/100], Loss: 0.1738, Validation Loss: 0.2750
	--> Epoch [56/100], Loss: 0.4577, Validation Loss: 0.2708
	--> Epoch [57/100], Loss: 0.1244, Validation Loss: 0.2703
	--> Epoch [58/100], Loss: 0.2502, Validation Loss: 0.2693
	--> Epoch [59/100], Loss: 0.3169, Validation Loss: 0.2664
	--> Epoch [60/100], Loss: 0.2270, Validation Loss: 0.2642
	--> Epoch [61/100], Loss: 0.1990, Validation Loss: 0.2649
	--> Epoch [62/100], Loss: 0.1659, Validation Loss: 0.2659
	--> Epoch [63/100], Loss: 0.3956, Validation Loss: 0.2641
	--> Epoch [64/100], Loss: 0.3686, Validation Loss: 0.2641
	--> Epoch [65/100], Loss: 0.0926, Validation Loss: 0.2645
	--> Epoch [66/100], Loss: 0.4646, Validation Loss: 0.2664
Early stopping
	--> Training for Fold 2 took 0.8640942573547363 sec, using 66 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8206, Validation Loss: 0.6361
	--> Epoch [2/100], Loss: 0.8480, Validation Loss: 0.6318
	--> Epoch [3/100], Loss: 0.7886, Validation Loss: 0.6238
	--> Epoch [4/100], Loss: 0.6498, Validation Loss: 0.6141
	--> Epoch [5/100], Loss: 0.7393, Validation Loss: 0.6080
	--> Epoch [6/100], Loss: 0.7200, Validation Loss: 0.6030
	--> Epoch [7/100], Loss: 0.7109, Validation Loss: 0.5994
	--> Epoch [8/100], Loss: 0.6385, Validation Loss: 0.5978
	--> Epoch [9/100], Loss: 0.6793, Validation Loss: 0.5945
	--> Epoch [10/100], Loss: 0.7243, Validation Loss: 0.5861
	--> Epoch [11/100], Loss: 0.7543, Validation Loss: 0.5839
	--> Epoch [12/100], Loss: 0.6411, Validation Loss: 0.5775
	--> Epoch [13/100], Loss: 0.6379, Validation Loss: 0.5734
	--> Epoch [14/100], Loss: 0.6210, Validation Loss: 0.5688
	--> Epoch [15/100], Loss: 0.6224, Validation Loss: 0.5646
	--> Epoch [16/100], Loss: 0.4996, Validation Loss: 0.5609
	--> Epoch [17/100], Loss: 0.5215, Validation Loss: 0.5538
	--> Epoch [18/100], Loss: 0.6421, Validation Loss: 0.5407
	--> Epoch [19/100], Loss: 0.5426, Validation Loss: 0.5349
	--> Epoch [20/100], Loss: 0.3707, Validation Loss: 0.5289
	--> Epoch [21/100], Loss: 0.5122, Validation Loss: 0.5226
	--> Epoch [22/100], Loss: 0.5382, Validation Loss: 0.5165
	--> Epoch [23/100], Loss: 0.4288, Validation Loss: 0.5094
	--> Epoch [24/100], Loss: 0.4119, Validation Loss: 0.5014
	--> Epoch [25/100], Loss: 0.4115, Validation Loss: 0.4945
	--> Epoch [26/100], Loss: 0.3893, Validation Loss: 0.4892
	--> Epoch [27/100], Loss: 0.5353, Validation Loss: 0.4836
	--> Epoch [28/100], Loss: 0.4510, Validation Loss: 0.4785
	--> Epoch [29/100], Loss: 0.4486, Validation Loss: 0.4694
	--> Epoch [30/100], Loss: 0.3773, Validation Loss: 0.4637
	--> Epoch [31/100], Loss: 0.4481, Validation Loss: 0.4599
	--> Epoch [32/100], Loss: 0.3640, Validation Loss: 0.4533
	--> Epoch [33/100], Loss: 0.4601, Validation Loss: 0.4478
	--> Epoch [34/100], Loss: 0.4494, Validation Loss: 0.4475
	--> Epoch [35/100], Loss: 0.3808, Validation Loss: 0.4429
	--> Epoch [36/100], Loss: 0.3147, Validation Loss: 0.4403
	--> Epoch [37/100], Loss: 0.2769, Validation Loss: 0.4378
	--> Epoch [38/100], Loss: 0.3378, Validation Loss: 0.4330
	--> Epoch [39/100], Loss: 0.4054, Validation Loss: 0.4290
	--> Epoch [40/100], Loss: 0.4675, Validation Loss: 0.4267
	--> Epoch [41/100], Loss: 0.3419, Validation Loss: 0.4250
	--> Epoch [42/100], Loss: 0.5036, Validation Loss: 0.4223
	--> Epoch [43/100], Loss: 0.5031, Validation Loss: 0.4182
	--> Epoch [44/100], Loss: 0.5668, Validation Loss: 0.4133
	--> Epoch [45/100], Loss: 0.4965, Validation Loss: 0.4091
	--> Epoch [46/100], Loss: 0.3966, Validation Loss: 0.4054
	--> Epoch [47/100], Loss: 0.0977, Validation Loss: 0.4027
	--> Epoch [48/100], Loss: 0.4599, Validation Loss: 0.4014
	--> Epoch [49/100], Loss: 0.3914, Validation Loss: 0.3986
	--> Epoch [50/100], Loss: 0.4026, Validation Loss: 0.3962
	--> Epoch [51/100], Loss: 0.4137, Validation Loss: 0.3945
	--> Epoch [52/100], Loss: 0.2558, Validation Loss: 0.3985
	--> Epoch [53/100], Loss: 0.2392, Validation Loss: 0.3935
	--> Epoch [54/100], Loss: 0.3144, Validation Loss: 0.3874
	--> Epoch [55/100], Loss: 0.3822, Validation Loss: 0.3880
	--> Epoch [56/100], Loss: 0.2896, Validation Loss: 0.3833
	--> Epoch [57/100], Loss: 0.5891, Validation Loss: 0.3787
	--> Epoch [58/100], Loss: 0.3099, Validation Loss: 0.3777
	--> Epoch [59/100], Loss: 0.3942, Validation Loss: 0.3735
	--> Epoch [60/100], Loss: 0.3561, Validation Loss: 0.3706
	--> Epoch [61/100], Loss: 0.3795, Validation Loss: 0.3686
	--> Epoch [62/100], Loss: 0.4641, Validation Loss: 0.3658
	--> Epoch [63/100], Loss: 0.3016, Validation Loss: 0.3666
	--> Epoch [64/100], Loss: 0.3768, Validation Loss: 0.3644
	--> Epoch [65/100], Loss: 0.3041, Validation Loss: 0.3613
	--> Epoch [66/100], Loss: 0.3189, Validation Loss: 0.3591
	--> Epoch [67/100], Loss: 0.2562, Validation Loss: 0.3581
	--> Epoch [68/100], Loss: 0.1053, Validation Loss: 0.3559
	--> Epoch [69/100], Loss: 0.3648, Validation Loss: 0.3539
	--> Epoch [70/100], Loss: 0.5070, Validation Loss: 0.3533
	--> Epoch [71/100], Loss: 0.3148, Validation Loss: 0.3519
	--> Epoch [72/100], Loss: 0.3700, Validation Loss: 0.3526
	--> Epoch [73/100], Loss: 0.0899, Validation Loss: 0.3505
	--> Epoch [74/100], Loss: 0.3032, Validation Loss: 0.3478
	--> Epoch [75/100], Loss: 0.2157, Validation Loss: 0.3471
	--> Epoch [76/100], Loss: 0.3585, Validation Loss: 0.3443
	--> Epoch [77/100], Loss: 0.3566, Validation Loss: 0.3433
	--> Epoch [78/100], Loss: 0.4328, Validation Loss: 0.3437
	--> Epoch [79/100], Loss: 0.2938, Validation Loss: 0.3437
	--> Epoch [80/100], Loss: 0.1500, Validation Loss: 0.3426
	--> Epoch [81/100], Loss: 0.2834, Validation Loss: 0.3416
	--> Epoch [82/100], Loss: 0.2880, Validation Loss: 0.3418
	--> Epoch [83/100], Loss: 0.2207, Validation Loss: 0.3409
	--> Epoch [84/100], Loss: 0.2294, Validation Loss: 0.3406
	--> Epoch [85/100], Loss: 0.3590, Validation Loss: 0.3415
	--> Epoch [86/100], Loss: 0.1501, Validation Loss: 0.3404
	--> Epoch [87/100], Loss: 0.2889, Validation Loss: 0.3381
	--> Epoch [88/100], Loss: 0.1510, Validation Loss: 0.3408
	--> Epoch [89/100], Loss: 0.3555, Validation Loss: 0.3365
	--> Epoch [90/100], Loss: 0.2828, Validation Loss: 0.3346
	--> Epoch [91/100], Loss: 0.2091, Validation Loss: 0.3334
	--> Epoch [92/100], Loss: 0.2760, Validation Loss: 0.3320
	--> Epoch [93/100], Loss: 0.1426, Validation Loss: 0.3280
	--> Epoch [94/100], Loss: 0.2775, Validation Loss: 0.3240
	--> Epoch [95/100], Loss: 0.2139, Validation Loss: 0.3229
	--> Epoch [96/100], Loss: 0.2795, Validation Loss: 0.3255
	--> Epoch [97/100], Loss: 0.2750, Validation Loss: 0.3279
	--> Epoch [98/100], Loss: 0.2802, Validation Loss: 0.3277
Early stopping
	--> Training for Fold 3 took 1.2639408111572266 sec, using 98 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6081, Validation Loss: 0.7253
	--> Epoch [2/100], Loss: 0.6246, Validation Loss: 0.7064
	--> Epoch [3/100], Loss: 0.6066, Validation Loss: 0.6874
	--> Epoch [4/100], Loss: 0.5624, Validation Loss: 0.6676
	--> Epoch [5/100], Loss: 0.6005, Validation Loss: 0.6416
	--> Epoch [6/100], Loss: 0.5668, Validation Loss: 0.6207
	--> Epoch [7/100], Loss: 0.5137, Validation Loss: 0.6082
	--> Epoch [8/100], Loss: 0.5596, Validation Loss: 0.5931
	--> Epoch [9/100], Loss: 0.4377, Validation Loss: 0.5753
	--> Epoch [10/100], Loss: 0.7111, Validation Loss: 0.5653
	--> Epoch [11/100], Loss: 0.4993, Validation Loss: 0.5534
	--> Epoch [12/100], Loss: 0.3890, Validation Loss: 0.5373
	--> Epoch [13/100], Loss: 0.4845, Validation Loss: 0.5339
	--> Epoch [14/100], Loss: 0.3925, Validation Loss: 0.5243
	--> Epoch [15/100], Loss: 0.4096, Validation Loss: 0.5050
	--> Epoch [16/100], Loss: 0.4457, Validation Loss: 0.4975
	--> Epoch [17/100], Loss: 0.3885, Validation Loss: 0.4795
	--> Epoch [18/100], Loss: 0.2520, Validation Loss: 0.4651
	--> Epoch [19/100], Loss: 0.3999, Validation Loss: 0.4564
	--> Epoch [20/100], Loss: 0.4481, Validation Loss: 0.4455
	--> Epoch [21/100], Loss: 0.2846, Validation Loss: 0.4395
	--> Epoch [22/100], Loss: 0.3653, Validation Loss: 0.4299
	--> Epoch [23/100], Loss: 0.3007, Validation Loss: 0.4235
	--> Epoch [24/100], Loss: 0.4328, Validation Loss: 0.4188
	--> Epoch [25/100], Loss: 0.2322, Validation Loss: 0.4118
	--> Epoch [26/100], Loss: 0.3036, Validation Loss: 0.4070
	--> Epoch [27/100], Loss: 0.3177, Validation Loss: 0.4046
	--> Epoch [28/100], Loss: 0.3255, Validation Loss: 0.3978
	--> Epoch [29/100], Loss: 0.2281, Validation Loss: 0.3906
	--> Epoch [30/100], Loss: 0.2148, Validation Loss: 0.3874
	--> Epoch [31/100], Loss: 0.1759, Validation Loss: 0.3843
	--> Epoch [32/100], Loss: 0.3442, Validation Loss: 0.3793
	--> Epoch [33/100], Loss: 0.2915, Validation Loss: 0.3730
	--> Epoch [34/100], Loss: 0.2280, Validation Loss: 0.3711
	--> Epoch [35/100], Loss: 0.3363, Validation Loss: 0.3678
	--> Epoch [36/100], Loss: 0.3593, Validation Loss: 0.3675
	--> Epoch [37/100], Loss: 0.4218, Validation Loss: 0.3639
	--> Epoch [38/100], Loss: 0.2995, Validation Loss: 0.3597
	--> Epoch [39/100], Loss: 0.2183, Validation Loss: 0.3601
	--> Epoch [40/100], Loss: 0.1830, Validation Loss: 0.3511
	--> Epoch [41/100], Loss: 0.3337, Validation Loss: 0.3464
	--> Epoch [42/100], Loss: 0.2905, Validation Loss: 0.3399
	--> Epoch [43/100], Loss: 0.1321, Validation Loss: 0.3374
	--> Epoch [44/100], Loss: 0.2666, Validation Loss: 0.3362
	--> Epoch [45/100], Loss: 0.1259, Validation Loss: 0.3327
	--> Epoch [46/100], Loss: 0.1823, Validation Loss: 0.3294
	--> Epoch [47/100], Loss: 0.1762, Validation Loss: 0.3253
	--> Epoch [48/100], Loss: 0.2915, Validation Loss: 0.3230
	--> Epoch [49/100], Loss: 0.2125, Validation Loss: 0.3225
	--> Epoch [50/100], Loss: 0.2136, Validation Loss: 0.3201
	--> Epoch [51/100], Loss: 0.2077, Validation Loss: 0.3201
	--> Epoch [52/100], Loss: 0.1700, Validation Loss: 0.3181
	--> Epoch [53/100], Loss: 0.2353, Validation Loss: 0.3149
	--> Epoch [54/100], Loss: 0.2893, Validation Loss: 0.3159
	--> Epoch [55/100], Loss: 0.1087, Validation Loss: 0.3137
	--> Epoch [56/100], Loss: 0.1318, Validation Loss: 0.3110
	--> Epoch [57/100], Loss: 0.2496, Validation Loss: 0.3112
	--> Epoch [58/100], Loss: 0.2314, Validation Loss: 0.3090
	--> Epoch [59/100], Loss: 0.4101, Validation Loss: 0.3075
	--> Epoch [60/100], Loss: 0.3294, Validation Loss: 0.3065
	--> Epoch [61/100], Loss: 0.2730, Validation Loss: 0.3045
	--> Epoch [62/100], Loss: 0.2801, Validation Loss: 0.3052
	--> Epoch [63/100], Loss: 0.1524, Validation Loss: 0.3073
	--> Epoch [64/100], Loss: 0.1927, Validation Loss: 0.3042
	--> Epoch [65/100], Loss: 0.3394, Validation Loss: 0.3040
	--> Epoch [66/100], Loss: 0.0660, Validation Loss: 0.3002
	--> Epoch [67/100], Loss: 0.1054, Validation Loss: 0.3000
	--> Epoch [68/100], Loss: 0.2953, Validation Loss: 0.2988
	--> Epoch [69/100], Loss: 0.2694, Validation Loss: 0.2990
	--> Epoch [70/100], Loss: 0.2377, Validation Loss: 0.2994
	--> Epoch [71/100], Loss: 0.1528, Validation Loss: 0.2974
	--> Epoch [72/100], Loss: 0.1029, Validation Loss: 0.2973
	--> Epoch [73/100], Loss: 0.1399, Validation Loss: 0.2981
	--> Epoch [74/100], Loss: 0.2606, Validation Loss: 0.2959
	--> Epoch [75/100], Loss: 0.3129, Validation Loss: 0.2977
	--> Epoch [76/100], Loss: 0.1488, Validation Loss: 0.2997
	--> Epoch [77/100], Loss: 0.2250, Validation Loss: 0.2991
Early stopping
	--> Training for Fold 4 took 1.0073778629302979 sec, using 77 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8305, Validation Loss: 0.6688
	--> Epoch [2/100], Loss: 0.7484, Validation Loss: 0.6544
	--> Epoch [3/100], Loss: 0.7029, Validation Loss: 0.6450
	--> Epoch [4/100], Loss: 0.6307, Validation Loss: 0.6390
	--> Epoch [5/100], Loss: 0.5632, Validation Loss: 0.6324
	--> Epoch [6/100], Loss: 0.5980, Validation Loss: 0.6270
	--> Epoch [7/100], Loss: 0.6200, Validation Loss: 0.6221
	--> Epoch [8/100], Loss: 0.5766, Validation Loss: 0.6183
	--> Epoch [9/100], Loss: 0.6157, Validation Loss: 0.6123
	--> Epoch [10/100], Loss: 0.4433, Validation Loss: 0.6072
	--> Epoch [11/100], Loss: 0.3400, Validation Loss: 0.6048
	--> Epoch [12/100], Loss: 0.4375, Validation Loss: 0.6013
	--> Epoch [13/100], Loss: 0.4831, Validation Loss: 0.5947
	--> Epoch [14/100], Loss: 0.4290, Validation Loss: 0.5943
	--> Epoch [15/100], Loss: 0.4352, Validation Loss: 0.5940
	--> Epoch [16/100], Loss: 0.2874, Validation Loss: 0.5950
	--> Epoch [17/100], Loss: 0.3835, Validation Loss: 0.5976
	--> Epoch [18/100], Loss: 0.3521, Validation Loss: 0.5981
Early stopping
	--> Training for Fold 5 took 0.22418689727783203 sec, using 18 epochs

Median number of epochs used: 73 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/73], Loss: 0.5927
	--> Final training Epoch [2/73], Loss: 0.5772
	--> Final training Epoch [3/73], Loss: 0.5536
	--> Final training Epoch [4/73], Loss: 0.5677
	--> Final training Epoch [5/73], Loss: 0.5807
	--> Final training Epoch [6/73], Loss: 0.5628
	--> Final training Epoch [7/73], Loss: 0.5953
	--> Final training Epoch [8/73], Loss: 0.4881
	--> Final training Epoch [9/73], Loss: 0.4713
	--> Final training Epoch [10/73], Loss: 0.4570
	--> Final training Epoch [11/73], Loss: 0.4398
	--> Final training Epoch [12/73], Loss: 0.5309
	--> Final training Epoch [13/73], Loss: 0.5236
	--> Final training Epoch [14/73], Loss: 0.3929
	--> Final training Epoch [15/73], Loss: 0.5541
	--> Final training Epoch [16/73], Loss: 0.3889
	--> Final training Epoch [17/73], Loss: 0.4518
	--> Final training Epoch [18/73], Loss: 0.5307
	--> Final training Epoch [19/73], Loss: 0.4779
	--> Final training Epoch [20/73], Loss: 0.4279
	--> Final training Epoch [21/73], Loss: 0.3747
	--> Final training Epoch [22/73], Loss: 0.4692
	--> Final training Epoch [23/73], Loss: 0.3888
	--> Final training Epoch [24/73], Loss: 0.3193
	--> Final training Epoch [25/73], Loss: 0.3918
	--> Final training Epoch [26/73], Loss: 0.3766
	--> Final training Epoch [27/73], Loss: 0.4184
	--> Final training Epoch [28/73], Loss: 0.3930
	--> Final training Epoch [29/73], Loss: 0.3462
	--> Final training Epoch [30/73], Loss: 0.2549
	--> Final training Epoch [31/73], Loss: 0.3764
	--> Final training Epoch [32/73], Loss: 0.3913
	--> Final training Epoch [33/73], Loss: 0.2544
	--> Final training Epoch [34/73], Loss: 0.3538
	--> Final training Epoch [35/73], Loss: 0.3457
	--> Final training Epoch [36/73], Loss: 0.3502
	--> Final training Epoch [37/73], Loss: 0.2667
	--> Final training Epoch [38/73], Loss: 0.2286
	--> Final training Epoch [39/73], Loss: 0.2754
	--> Final training Epoch [40/73], Loss: 0.1826
	--> Final training Epoch [41/73], Loss: 0.2019
	--> Final training Epoch [42/73], Loss: 0.1895
	--> Final training Epoch [43/73], Loss: 0.3305
	--> Final training Epoch [44/73], Loss: 0.1167
	--> Final training Epoch [45/73], Loss: 0.1772
	--> Final training Epoch [46/73], Loss: 0.1892
	--> Final training Epoch [47/73], Loss: 0.2551
	--> Final training Epoch [48/73], Loss: 0.2901
	--> Final training Epoch [49/73], Loss: 0.2813
	--> Final training Epoch [50/73], Loss: 0.2456
	--> Final training Epoch [51/73], Loss: 0.1502
	--> Final training Epoch [52/73], Loss: 0.1558
	--> Final training Epoch [53/73], Loss: 0.2153
	--> Final training Epoch [54/73], Loss: 0.3053
	--> Final training Epoch [55/73], Loss: 0.1021
	--> Final training Epoch [56/73], Loss: 0.2401
	--> Final training Epoch [57/73], Loss: 0.1562
	--> Final training Epoch [58/73], Loss: 0.1646
	--> Final training Epoch [59/73], Loss: 0.0963
	--> Final training Epoch [60/73], Loss: 0.1608
	--> Final training Epoch [61/73], Loss: 0.2461
	--> Final training Epoch [62/73], Loss: 0.2286
	--> Final training Epoch [63/73], Loss: 0.0887
	--> Final training Epoch [64/73], Loss: 0.2125
	--> Final training Epoch [65/73], Loss: 0.2010
	--> Final training Epoch [66/73], Loss: 0.1935
	--> Final training Epoch [67/73], Loss: 0.2663
	--> Final training Epoch [68/73], Loss: 0.1593
	--> Final training Epoch [69/73], Loss: 0.3461
	--> Final training Epoch [70/73], Loss: 0.1312
	--> Final training Epoch [71/73], Loss: 0.3747
	--> Final training Epoch [72/73], Loss: 0.1692
	--> Final training Epoch [73/73], Loss: 0.2059

Final training took 1.054262399673462 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9822
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3793,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3793

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8206, Validation Loss: 0.7216
	--> Epoch [2/100], Loss: 0.6150, Validation Loss: 0.6845
	--> Epoch [3/100], Loss: 0.6286, Validation Loss: 0.6533
	--> Epoch [4/100], Loss: 0.5128, Validation Loss: 0.6196
	--> Epoch [5/100], Loss: 0.5435, Validation Loss: 0.5920
	--> Epoch [6/100], Loss: 0.4383, Validation Loss: 0.5686
	--> Epoch [7/100], Loss: 0.4377, Validation Loss: 0.5498
	--> Epoch [8/100], Loss: 0.3958, Validation Loss: 0.5304
	--> Epoch [9/100], Loss: 0.3077, Validation Loss: 0.5173
	--> Epoch [10/100], Loss: 0.3652, Validation Loss: 0.4970
	--> Epoch [11/100], Loss: 0.3657, Validation Loss: 0.4818
	--> Epoch [12/100], Loss: 0.2402, Validation Loss: 0.4672
	--> Epoch [13/100], Loss: 0.3112, Validation Loss: 0.4540
	--> Epoch [14/100], Loss: 0.2642, Validation Loss: 0.4362
	--> Epoch [15/100], Loss: 0.2941, Validation Loss: 0.4248
	--> Epoch [16/100], Loss: 0.2244, Validation Loss: 0.4097
	--> Epoch [17/100], Loss: 0.2828, Validation Loss: 0.4005
	--> Epoch [18/100], Loss: 0.2754, Validation Loss: 0.3906
	--> Epoch [19/100], Loss: 0.1562, Validation Loss: 0.3787
	--> Epoch [20/100], Loss: 0.1856, Validation Loss: 0.3737
	--> Epoch [21/100], Loss: 0.2167, Validation Loss: 0.3670
	--> Epoch [22/100], Loss: 0.1378, Validation Loss: 0.3611
	--> Epoch [23/100], Loss: 0.1966, Validation Loss: 0.3602
	--> Epoch [24/100], Loss: 0.2305, Validation Loss: 0.3571
	--> Epoch [25/100], Loss: 0.1849, Validation Loss: 0.3541
	--> Epoch [26/100], Loss: 0.2015, Validation Loss: 0.3495
	--> Epoch [27/100], Loss: 0.1096, Validation Loss: 0.3489
	--> Epoch [28/100], Loss: 0.1554, Validation Loss: 0.3430
	--> Epoch [29/100], Loss: 0.2058, Validation Loss: 0.3412
	--> Epoch [30/100], Loss: 0.0816, Validation Loss: 0.3375
	--> Epoch [31/100], Loss: 0.1128, Validation Loss: 0.3370
	--> Epoch [32/100], Loss: 0.0980, Validation Loss: 0.3346
	--> Epoch [33/100], Loss: 0.0628, Validation Loss: 0.3284
	--> Epoch [34/100], Loss: 0.1370, Validation Loss: 0.3245
	--> Epoch [35/100], Loss: 0.1285, Validation Loss: 0.3279
	--> Epoch [36/100], Loss: 0.2309, Validation Loss: 0.3277
	--> Epoch [37/100], Loss: 0.0614, Validation Loss: 0.3267
Early stopping
	--> Training for Fold 1 took 0.49274230003356934 sec, using 37 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6793, Validation Loss: 0.6373
	--> Epoch [2/100], Loss: 0.6304, Validation Loss: 0.5888
	--> Epoch [3/100], Loss: 0.5433, Validation Loss: 0.5512
	--> Epoch [4/100], Loss: 0.5141, Validation Loss: 0.5268
	--> Epoch [5/100], Loss: 0.4836, Validation Loss: 0.5036
	--> Epoch [6/100], Loss: 0.4339, Validation Loss: 0.4865
	--> Epoch [7/100], Loss: 0.5112, Validation Loss: 0.4676
	--> Epoch [8/100], Loss: 0.4135, Validation Loss: 0.4539
	--> Epoch [9/100], Loss: 0.3767, Validation Loss: 0.4365
	--> Epoch [10/100], Loss: 0.3720, Validation Loss: 0.4187
	--> Epoch [11/100], Loss: 0.4443, Validation Loss: 0.4056
	--> Epoch [12/100], Loss: 0.4099, Validation Loss: 0.3913
	--> Epoch [13/100], Loss: 0.3491, Validation Loss: 0.3774
	--> Epoch [14/100], Loss: 0.3215, Validation Loss: 0.3664
	--> Epoch [15/100], Loss: 0.2411, Validation Loss: 0.3591
	--> Epoch [16/100], Loss: 0.3413, Validation Loss: 0.3515
	--> Epoch [17/100], Loss: 0.4180, Validation Loss: 0.3395
	--> Epoch [18/100], Loss: 0.2131, Validation Loss: 0.3314
	--> Epoch [19/100], Loss: 0.2188, Validation Loss: 0.3248
	--> Epoch [20/100], Loss: 0.2113, Validation Loss: 0.3197
	--> Epoch [21/100], Loss: 0.2264, Validation Loss: 0.3149
	--> Epoch [22/100], Loss: 0.2327, Validation Loss: 0.3107
	--> Epoch [23/100], Loss: 0.1904, Validation Loss: 0.3077
	--> Epoch [24/100], Loss: 0.1671, Validation Loss: 0.3026
	--> Epoch [25/100], Loss: 0.1492, Validation Loss: 0.2985
	--> Epoch [26/100], Loss: 0.1272, Validation Loss: 0.2968
	--> Epoch [27/100], Loss: 0.1322, Validation Loss: 0.2933
	--> Epoch [28/100], Loss: 0.1132, Validation Loss: 0.2909
	--> Epoch [29/100], Loss: 0.1545, Validation Loss: 0.2880
	--> Epoch [30/100], Loss: 0.1325, Validation Loss: 0.2841
	--> Epoch [31/100], Loss: 0.1720, Validation Loss: 0.2803
	--> Epoch [32/100], Loss: 0.1854, Validation Loss: 0.2795
	--> Epoch [33/100], Loss: 0.1375, Validation Loss: 0.2750
	--> Epoch [34/100], Loss: 0.1546, Validation Loss: 0.2781
	--> Epoch [35/100], Loss: 0.1200, Validation Loss: 0.2756
	--> Epoch [36/100], Loss: 0.1357, Validation Loss: 0.2721
	--> Epoch [37/100], Loss: 0.1764, Validation Loss: 0.2683
	--> Epoch [38/100], Loss: 0.1074, Validation Loss: 0.2686
	--> Epoch [39/100], Loss: 0.1976, Validation Loss: 0.2678
	--> Epoch [40/100], Loss: 0.1133, Validation Loss: 0.2676
	--> Epoch [41/100], Loss: 0.1869, Validation Loss: 0.2669
	--> Epoch [42/100], Loss: 0.1737, Validation Loss: 0.2645
	--> Epoch [43/100], Loss: 0.1522, Validation Loss: 0.2634
	--> Epoch [44/100], Loss: 0.0835, Validation Loss: 0.2644
	--> Epoch [45/100], Loss: 0.0934, Validation Loss: 0.2616
	--> Epoch [46/100], Loss: 0.1854, Validation Loss: 0.2634
	--> Epoch [47/100], Loss: 0.0910, Validation Loss: 0.2648
	--> Epoch [48/100], Loss: 0.1125, Validation Loss: 0.2647
Early stopping
	--> Training for Fold 2 took 0.5968754291534424 sec, using 48 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8796, Validation Loss: 0.6226
	--> Epoch [2/100], Loss: 0.9072, Validation Loss: 0.5961
	--> Epoch [3/100], Loss: 0.6711, Validation Loss: 0.5838
	--> Epoch [4/100], Loss: 0.6848, Validation Loss: 0.5685
	--> Epoch [5/100], Loss: 0.5956, Validation Loss: 0.5562
	--> Epoch [6/100], Loss: 0.5505, Validation Loss: 0.5445
	--> Epoch [7/100], Loss: 0.3968, Validation Loss: 0.5342
	--> Epoch [8/100], Loss: 0.4072, Validation Loss: 0.5224
	--> Epoch [9/100], Loss: 0.4353, Validation Loss: 0.5107
	--> Epoch [10/100], Loss: 0.3183, Validation Loss: 0.5001
	--> Epoch [11/100], Loss: 0.2784, Validation Loss: 0.4885
	--> Epoch [12/100], Loss: 0.1651, Validation Loss: 0.4813
	--> Epoch [13/100], Loss: 0.2485, Validation Loss: 0.4723
	--> Epoch [14/100], Loss: 0.1786, Validation Loss: 0.4645
	--> Epoch [15/100], Loss: 0.2199, Validation Loss: 0.4558
	--> Epoch [16/100], Loss: 0.3320, Validation Loss: 0.4519
	--> Epoch [17/100], Loss: 0.2830, Validation Loss: 0.4465
	--> Epoch [18/100], Loss: 0.1712, Validation Loss: 0.4430
	--> Epoch [19/100], Loss: 0.1846, Validation Loss: 0.4376
	--> Epoch [20/100], Loss: 0.1790, Validation Loss: 0.4287
	--> Epoch [21/100], Loss: 0.1513, Validation Loss: 0.4239
	--> Epoch [22/100], Loss: 0.1218, Validation Loss: 0.4184
	--> Epoch [23/100], Loss: 0.0657, Validation Loss: 0.4134
	--> Epoch [24/100], Loss: 0.2509, Validation Loss: 0.4080
	--> Epoch [25/100], Loss: 0.0816, Validation Loss: 0.4070
	--> Epoch [26/100], Loss: 0.1183, Validation Loss: 0.4034
	--> Epoch [27/100], Loss: 0.1323, Validation Loss: 0.3983
	--> Epoch [28/100], Loss: 0.1264, Validation Loss: 0.3971
	--> Epoch [29/100], Loss: 0.0756, Validation Loss: 0.3940
	--> Epoch [30/100], Loss: 0.1246, Validation Loss: 0.3883
	--> Epoch [31/100], Loss: 0.1378, Validation Loss: 0.3851
	--> Epoch [32/100], Loss: 0.1722, Validation Loss: 0.3822
	--> Epoch [33/100], Loss: 0.0750, Validation Loss: 0.3770
	--> Epoch [34/100], Loss: 0.0759, Validation Loss: 0.3719
	--> Epoch [35/100], Loss: 0.1201, Validation Loss: 0.3706
	--> Epoch [36/100], Loss: 0.0517, Validation Loss: 0.3632
	--> Epoch [37/100], Loss: 0.0642, Validation Loss: 0.3614
	--> Epoch [38/100], Loss: 0.0654, Validation Loss: 0.3652
	--> Epoch [39/100], Loss: 0.0344, Validation Loss: 0.3627
	--> Epoch [40/100], Loss: 0.0387, Validation Loss: 0.3614
	--> Epoch [41/100], Loss: 0.0345, Validation Loss: 0.3613
	--> Epoch [42/100], Loss: 0.1325, Validation Loss: 0.3601
	--> Epoch [43/100], Loss: 0.0405, Validation Loss: 0.3607
	--> Epoch [44/100], Loss: 0.0369, Validation Loss: 0.3594
	--> Epoch [45/100], Loss: 0.0164, Validation Loss: 0.3597
	--> Epoch [46/100], Loss: 0.0656, Validation Loss: 0.3557
	--> Epoch [47/100], Loss: 0.0839, Validation Loss: 0.3564
	--> Epoch [48/100], Loss: 0.1139, Validation Loss: 0.3563
	--> Epoch [49/100], Loss: 0.0228, Validation Loss: 0.3551
	--> Epoch [50/100], Loss: 0.1005, Validation Loss: 0.3539
	--> Epoch [51/100], Loss: 0.0256, Validation Loss: 0.3507
	--> Epoch [52/100], Loss: 0.0140, Validation Loss: 0.3485
	--> Epoch [53/100], Loss: 0.0134, Validation Loss: 0.3476
	--> Epoch [54/100], Loss: 0.0250, Validation Loss: 0.3460
	--> Epoch [55/100], Loss: 0.0302, Validation Loss: 0.3458
	--> Epoch [56/100], Loss: 0.0220, Validation Loss: 0.3456
	--> Epoch [57/100], Loss: 0.0194, Validation Loss: 0.3462
	--> Epoch [58/100], Loss: 0.0358, Validation Loss: 0.3444
	--> Epoch [59/100], Loss: 0.0083, Validation Loss: 0.3417
	--> Epoch [60/100], Loss: 0.0974, Validation Loss: 0.3397
	--> Epoch [61/100], Loss: 0.1118, Validation Loss: 0.3384
	--> Epoch [62/100], Loss: 0.0877, Validation Loss: 0.3380
	--> Epoch [63/100], Loss: 0.0081, Validation Loss: 0.3359
	--> Epoch [64/100], Loss: 0.0180, Validation Loss: 0.3353
	--> Epoch [65/100], Loss: 0.0840, Validation Loss: 0.3329
	--> Epoch [66/100], Loss: 0.0139, Validation Loss: 0.3319
	--> Epoch [67/100], Loss: 0.1134, Validation Loss: 0.3343
	--> Epoch [68/100], Loss: 0.0850, Validation Loss: 0.3347
	--> Epoch [69/100], Loss: 0.0125, Validation Loss: 0.3369
Early stopping
	--> Training for Fold 3 took 0.8592202663421631 sec, using 69 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6836, Validation Loss: 0.5746
	--> Epoch [2/100], Loss: 0.6199, Validation Loss: 0.5430
	--> Epoch [3/100], Loss: 0.4877, Validation Loss: 0.5192
	--> Epoch [4/100], Loss: 0.5103, Validation Loss: 0.5036
	--> Epoch [5/100], Loss: 0.4339, Validation Loss: 0.4850
	--> Epoch [6/100], Loss: 0.4719, Validation Loss: 0.4751
	--> Epoch [7/100], Loss: 0.4437, Validation Loss: 0.4589
	--> Epoch [8/100], Loss: 0.3467, Validation Loss: 0.4425
	--> Epoch [9/100], Loss: 0.3188, Validation Loss: 0.4328
	--> Epoch [10/100], Loss: 0.2916, Validation Loss: 0.4247
	--> Epoch [11/100], Loss: 0.2530, Validation Loss: 0.4143
	--> Epoch [12/100], Loss: 0.2499, Validation Loss: 0.4079
	--> Epoch [13/100], Loss: 0.2538, Validation Loss: 0.4013
	--> Epoch [14/100], Loss: 0.1805, Validation Loss: 0.3954
	--> Epoch [15/100], Loss: 0.2816, Validation Loss: 0.3893
	--> Epoch [16/100], Loss: 0.1952, Validation Loss: 0.3812
	--> Epoch [17/100], Loss: 0.1896, Validation Loss: 0.3752
	--> Epoch [18/100], Loss: 0.2123, Validation Loss: 0.3667
	--> Epoch [19/100], Loss: 0.0943, Validation Loss: 0.3649
	--> Epoch [20/100], Loss: 0.2034, Validation Loss: 0.3588
	--> Epoch [21/100], Loss: 0.2390, Validation Loss: 0.3531
	--> Epoch [22/100], Loss: 0.1563, Validation Loss: 0.3481
	--> Epoch [23/100], Loss: 0.1262, Validation Loss: 0.3550
	--> Epoch [24/100], Loss: 0.1252, Validation Loss: 0.3470
	--> Epoch [25/100], Loss: 0.1811, Validation Loss: 0.3401
	--> Epoch [26/100], Loss: 0.2572, Validation Loss: 0.3398
	--> Epoch [27/100], Loss: 0.1623, Validation Loss: 0.3394
	--> Epoch [28/100], Loss: 0.1230, Validation Loss: 0.3364
	--> Epoch [29/100], Loss: 0.1662, Validation Loss: 0.3365
	--> Epoch [30/100], Loss: 0.1193, Validation Loss: 0.3306
	--> Epoch [31/100], Loss: 0.1190, Validation Loss: 0.3266
	--> Epoch [32/100], Loss: 0.2143, Validation Loss: 0.3249
	--> Epoch [33/100], Loss: 0.0695, Validation Loss: 0.3264
	--> Epoch [34/100], Loss: 0.0284, Validation Loss: 0.3287
	--> Epoch [35/100], Loss: 0.0914, Validation Loss: 0.3247
	--> Epoch [36/100], Loss: 0.0454, Validation Loss: 0.3284
	--> Epoch [37/100], Loss: 0.0531, Validation Loss: 0.3261
	--> Epoch [38/100], Loss: 0.1452, Validation Loss: 0.3268
Early stopping
	--> Training for Fold 4 took 0.47697877883911133 sec, using 38 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8072, Validation Loss: 0.6495
	--> Epoch [2/100], Loss: 0.7441, Validation Loss: 0.6357
	--> Epoch [3/100], Loss: 0.6854, Validation Loss: 0.6226
	--> Epoch [4/100], Loss: 0.5921, Validation Loss: 0.6125
	--> Epoch [5/100], Loss: 0.5424, Validation Loss: 0.6049
	--> Epoch [6/100], Loss: 0.5123, Validation Loss: 0.5960
	--> Epoch [7/100], Loss: 0.4958, Validation Loss: 0.5910
	--> Epoch [8/100], Loss: 0.4475, Validation Loss: 0.5860
	--> Epoch [9/100], Loss: 0.4774, Validation Loss: 0.5804
	--> Epoch [10/100], Loss: 0.3454, Validation Loss: 0.5747
	--> Epoch [11/100], Loss: 0.3450, Validation Loss: 0.5730
	--> Epoch [12/100], Loss: 0.3143, Validation Loss: 0.5718
	--> Epoch [13/100], Loss: 0.2879, Validation Loss: 0.5671
	--> Epoch [14/100], Loss: 0.2854, Validation Loss: 0.5662
	--> Epoch [15/100], Loss: 0.2597, Validation Loss: 0.5621
	--> Epoch [16/100], Loss: 0.2342, Validation Loss: 0.5592
	--> Epoch [17/100], Loss: 0.1713, Validation Loss: 0.5569
	--> Epoch [18/100], Loss: 0.2032, Validation Loss: 0.5508
	--> Epoch [19/100], Loss: 0.2538, Validation Loss: 0.5483
	--> Epoch [20/100], Loss: 0.1989, Validation Loss: 0.5446
	--> Epoch [21/100], Loss: 0.1958, Validation Loss: 0.5412
	--> Epoch [22/100], Loss: 0.1966, Validation Loss: 0.5405
	--> Epoch [23/100], Loss: 0.1978, Validation Loss: 0.5351
	--> Epoch [24/100], Loss: 0.1289, Validation Loss: 0.5308
	--> Epoch [25/100], Loss: 0.3414, Validation Loss: 0.5326
	--> Epoch [26/100], Loss: 0.2056, Validation Loss: 0.5371
	--> Epoch [27/100], Loss: 0.1283, Validation Loss: 0.5391
Early stopping
	--> Training for Fold 5 took 0.34016990661621094 sec, using 27 epochs

Median number of epochs used: 38 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/38], Loss: 0.8154
	--> Final training Epoch [2/38], Loss: 0.7549
	--> Final training Epoch [3/38], Loss: 0.7141
	--> Final training Epoch [4/38], Loss: 0.6571
	--> Final training Epoch [5/38], Loss: 0.6223
	--> Final training Epoch [6/38], Loss: 0.6255
	--> Final training Epoch [7/38], Loss: 0.6161
	--> Final training Epoch [8/38], Loss: 0.5280
	--> Final training Epoch [9/38], Loss: 0.5017
	--> Final training Epoch [10/38], Loss: 0.4017
	--> Final training Epoch [11/38], Loss: 0.4465
	--> Final training Epoch [12/38], Loss: 0.3952
	--> Final training Epoch [13/38], Loss: 0.4342
	--> Final training Epoch [14/38], Loss: 0.3138
	--> Final training Epoch [15/38], Loss: 0.4183
	--> Final training Epoch [16/38], Loss: 0.4145
	--> Final training Epoch [17/38], Loss: 0.3359
	--> Final training Epoch [18/38], Loss: 0.3432
	--> Final training Epoch [19/38], Loss: 0.2536
	--> Final training Epoch [20/38], Loss: 0.2330
	--> Final training Epoch [21/38], Loss: 0.2029
	--> Final training Epoch [22/38], Loss: 0.2360
	--> Final training Epoch [23/38], Loss: 0.3199
	--> Final training Epoch [24/38], Loss: 0.2105
	--> Final training Epoch [25/38], Loss: 0.1662
	--> Final training Epoch [26/38], Loss: 0.2441
	--> Final training Epoch [27/38], Loss: 0.2152
	--> Final training Epoch [28/38], Loss: 0.2373
	--> Final training Epoch [29/38], Loss: 0.1856
	--> Final training Epoch [30/38], Loss: 0.1543
	--> Final training Epoch [31/38], Loss: 0.2246
	--> Final training Epoch [32/38], Loss: 0.2401
	--> Final training Epoch [33/38], Loss: 0.2063
	--> Final training Epoch [34/38], Loss: 0.1979
	--> Final training Epoch [35/38], Loss: 0.1204
	--> Final training Epoch [36/38], Loss: 0.1661
	--> Final training Epoch [37/38], Loss: 0.1148
	--> Final training Epoch [38/38], Loss: 0.1011

Final training took 0.5407190322875977 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.8214
	--> Final Precision: 0.6154
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6154
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3632,  Current Best Accuracy: 0.8485,  Current Best Validation Loss: 0.3632

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6752, Validation Loss: 0.6269
	--> Epoch [2/100], Loss: 0.5909, Validation Loss: 0.5989
	--> Epoch [3/100], Loss: 0.5561, Validation Loss: 0.5751
	--> Epoch [4/100], Loss: 0.5078, Validation Loss: 0.5556
	--> Epoch [5/100], Loss: 0.4451, Validation Loss: 0.5318
	--> Epoch [6/100], Loss: 0.4437, Validation Loss: 0.5086
	--> Epoch [7/100], Loss: 0.3933, Validation Loss: 0.4828
	--> Epoch [8/100], Loss: 0.4112, Validation Loss: 0.4604
	--> Epoch [9/100], Loss: 0.3882, Validation Loss: 0.4440
	--> Epoch [10/100], Loss: 0.3157, Validation Loss: 0.4241
	--> Epoch [11/100], Loss: 0.3549, Validation Loss: 0.4097
	--> Epoch [12/100], Loss: 0.2916, Validation Loss: 0.3924
	--> Epoch [13/100], Loss: 0.2764, Validation Loss: 0.3756
	--> Epoch [14/100], Loss: 0.3294, Validation Loss: 0.3602
	--> Epoch [15/100], Loss: 0.2745, Validation Loss: 0.3487
	--> Epoch [16/100], Loss: 0.2524, Validation Loss: 0.3383
	--> Epoch [17/100], Loss: 0.1977, Validation Loss: 0.3297
	--> Epoch [18/100], Loss: 0.2265, Validation Loss: 0.3210
	--> Epoch [19/100], Loss: 0.2339, Validation Loss: 0.3108
	--> Epoch [20/100], Loss: 0.1947, Validation Loss: 0.3038
	--> Epoch [21/100], Loss: 0.1653, Validation Loss: 0.2969
	--> Epoch [22/100], Loss: 0.1678, Validation Loss: 0.2876
	--> Epoch [23/100], Loss: 0.1208, Validation Loss: 0.2807
	--> Epoch [24/100], Loss: 0.1873, Validation Loss: 0.2745
	--> Epoch [25/100], Loss: 0.1198, Validation Loss: 0.2697
	--> Epoch [26/100], Loss: 0.1124, Validation Loss: 0.2655
	--> Epoch [27/100], Loss: 0.1916, Validation Loss: 0.2618
	--> Epoch [28/100], Loss: 0.0737, Validation Loss: 0.2579
	--> Epoch [29/100], Loss: 0.0466, Validation Loss: 0.2555
	--> Epoch [30/100], Loss: 0.0867, Validation Loss: 0.2533
	--> Epoch [31/100], Loss: 0.1397, Validation Loss: 0.2471
	--> Epoch [32/100], Loss: 0.1190, Validation Loss: 0.2459
	--> Epoch [33/100], Loss: 0.1310, Validation Loss: 0.2444
	--> Epoch [34/100], Loss: 0.1027, Validation Loss: 0.2397
	--> Epoch [35/100], Loss: 0.2156, Validation Loss: 0.2346
	--> Epoch [36/100], Loss: 0.0528, Validation Loss: 0.2349
	--> Epoch [37/100], Loss: 0.1351, Validation Loss: 0.2317
	--> Epoch [38/100], Loss: 0.0409, Validation Loss: 0.2292
	--> Epoch [39/100], Loss: 0.0572, Validation Loss: 0.2279
	--> Epoch [40/100], Loss: 0.1001, Validation Loss: 0.2264
	--> Epoch [41/100], Loss: 0.0370, Validation Loss: 0.2246
	--> Epoch [42/100], Loss: 0.1816, Validation Loss: 0.2235
	--> Epoch [43/100], Loss: 0.1305, Validation Loss: 0.2209
	--> Epoch [44/100], Loss: 0.0406, Validation Loss: 0.2199
	--> Epoch [45/100], Loss: 0.0799, Validation Loss: 0.2199
	--> Epoch [46/100], Loss: 0.0220, Validation Loss: 0.2185
	--> Epoch [47/100], Loss: 0.1081, Validation Loss: 0.2166
	--> Epoch [48/100], Loss: 0.0241, Validation Loss: 0.2149
	--> Epoch [49/100], Loss: 0.0805, Validation Loss: 0.2152
	--> Epoch [50/100], Loss: 0.0900, Validation Loss: 0.2139
	--> Epoch [51/100], Loss: 0.2227, Validation Loss: 0.2146
	--> Epoch [52/100], Loss: 0.0407, Validation Loss: 0.2148
	--> Epoch [53/100], Loss: 0.0134, Validation Loss: 0.2129
	--> Epoch [54/100], Loss: 0.0375, Validation Loss: 0.2118
	--> Epoch [55/100], Loss: 0.1018, Validation Loss: 0.2130
	--> Epoch [56/100], Loss: 0.0134, Validation Loss: 0.2129
	--> Epoch [57/100], Loss: 0.1551, Validation Loss: 0.2124
Early stopping
	--> Training for Fold 1 took 0.7082700729370117 sec, using 57 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7613, Validation Loss: 0.5880
	--> Epoch [2/100], Loss: 0.6487, Validation Loss: 0.5534
	--> Epoch [3/100], Loss: 0.5900, Validation Loss: 0.5233
	--> Epoch [4/100], Loss: 0.5349, Validation Loss: 0.5046
	--> Epoch [5/100], Loss: 0.4459, Validation Loss: 0.4849
	--> Epoch [6/100], Loss: 0.4297, Validation Loss: 0.4730
	--> Epoch [7/100], Loss: 0.4680, Validation Loss: 0.4574
	--> Epoch [8/100], Loss: 0.4457, Validation Loss: 0.4427
	--> Epoch [9/100], Loss: 0.3969, Validation Loss: 0.4261
	--> Epoch [10/100], Loss: 0.3864, Validation Loss: 0.4099
	--> Epoch [11/100], Loss: 0.3261, Validation Loss: 0.3923
	--> Epoch [12/100], Loss: 0.3235, Validation Loss: 0.3785
	--> Epoch [13/100], Loss: 0.2737, Validation Loss: 0.3624
	--> Epoch [14/100], Loss: 0.2535, Validation Loss: 0.3494
	--> Epoch [15/100], Loss: 0.3156, Validation Loss: 0.3392
	--> Epoch [16/100], Loss: 0.2422, Validation Loss: 0.3268
	--> Epoch [17/100], Loss: 0.2057, Validation Loss: 0.3137
	--> Epoch [18/100], Loss: 0.3082, Validation Loss: 0.3057
	--> Epoch [19/100], Loss: 0.1659, Validation Loss: 0.2966
	--> Epoch [20/100], Loss: 0.1803, Validation Loss: 0.2887
	--> Epoch [21/100], Loss: 0.1724, Validation Loss: 0.2799
	--> Epoch [22/100], Loss: 0.1654, Validation Loss: 0.2713
	--> Epoch [23/100], Loss: 0.1590, Validation Loss: 0.2678
	--> Epoch [24/100], Loss: 0.1370, Validation Loss: 0.2625
	--> Epoch [25/100], Loss: 0.1496, Validation Loss: 0.2585
	--> Epoch [26/100], Loss: 0.1469, Validation Loss: 0.2519
	--> Epoch [27/100], Loss: 0.1665, Validation Loss: 0.2463
	--> Epoch [28/100], Loss: 0.1644, Validation Loss: 0.2402
	--> Epoch [29/100], Loss: 0.1368, Validation Loss: 0.2367
	--> Epoch [30/100], Loss: 0.1372, Validation Loss: 0.2329
	--> Epoch [31/100], Loss: 0.1523, Validation Loss: 0.2278
	--> Epoch [32/100], Loss: 0.1682, Validation Loss: 0.2264
	--> Epoch [33/100], Loss: 0.1693, Validation Loss: 0.2223
	--> Epoch [34/100], Loss: 0.1198, Validation Loss: 0.2189
	--> Epoch [35/100], Loss: 0.1389, Validation Loss: 0.2180
	--> Epoch [36/100], Loss: 0.1418, Validation Loss: 0.2162
	--> Epoch [37/100], Loss: 0.1995, Validation Loss: 0.2113
	--> Epoch [38/100], Loss: 0.1355, Validation Loss: 0.2077
	--> Epoch [39/100], Loss: 0.1152, Validation Loss: 0.2059
	--> Epoch [40/100], Loss: 0.0940, Validation Loss: 0.2041
	--> Epoch [41/100], Loss: 0.1239, Validation Loss: 0.2036
	--> Epoch [42/100], Loss: 0.1108, Validation Loss: 0.1987
	--> Epoch [43/100], Loss: 0.1427, Validation Loss: 0.1975
	--> Epoch [44/100], Loss: 0.1839, Validation Loss: 0.1966
	--> Epoch [45/100], Loss: 0.1170, Validation Loss: 0.1924
	--> Epoch [46/100], Loss: 0.1139, Validation Loss: 0.1904
	--> Epoch [47/100], Loss: 0.1151, Validation Loss: 0.1902
	--> Epoch [48/100], Loss: 0.0994, Validation Loss: 0.1886
	--> Epoch [49/100], Loss: 0.1451, Validation Loss: 0.1892
	--> Epoch [50/100], Loss: 0.1155, Validation Loss: 0.1862
	--> Epoch [51/100], Loss: 0.1121, Validation Loss: 0.1855
	--> Epoch [52/100], Loss: 0.1048, Validation Loss: 0.1815
	--> Epoch [53/100], Loss: 0.1511, Validation Loss: 0.1813
	--> Epoch [54/100], Loss: 0.1022, Validation Loss: 0.1799
	--> Epoch [55/100], Loss: 0.1500, Validation Loss: 0.1793
	--> Epoch [56/100], Loss: 0.0904, Validation Loss: 0.1792
	--> Epoch [57/100], Loss: 0.1126, Validation Loss: 0.1759
	--> Epoch [58/100], Loss: 0.0891, Validation Loss: 0.1735
	--> Epoch [59/100], Loss: 0.0945, Validation Loss: 0.1720
	--> Epoch [60/100], Loss: 0.0936, Validation Loss: 0.1708
	--> Epoch [61/100], Loss: 0.1220, Validation Loss: 0.1703
	--> Epoch [62/100], Loss: 0.0974, Validation Loss: 0.1697
	--> Epoch [63/100], Loss: 0.0904, Validation Loss: 0.1685
	--> Epoch [64/100], Loss: 0.0999, Validation Loss: 0.1664
	--> Epoch [65/100], Loss: 0.1142, Validation Loss: 0.1649
	--> Epoch [66/100], Loss: 0.1532, Validation Loss: 0.1633
	--> Epoch [67/100], Loss: 0.1138, Validation Loss: 0.1641
	--> Epoch [68/100], Loss: 0.1074, Validation Loss: 0.1652
	--> Epoch [69/100], Loss: 0.1135, Validation Loss: 0.1646
Early stopping
	--> Training for Fold 2 took 0.8521802425384521 sec, using 69 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7244, Validation Loss: 0.6761
	--> Epoch [2/100], Loss: 0.6771, Validation Loss: 0.6502
	--> Epoch [3/100], Loss: 0.5787, Validation Loss: 0.6302
	--> Epoch [4/100], Loss: 0.5485, Validation Loss: 0.6143
	--> Epoch [5/100], Loss: 0.5423, Validation Loss: 0.5986
	--> Epoch [6/100], Loss: 0.4486, Validation Loss: 0.5825
	--> Epoch [7/100], Loss: 0.3880, Validation Loss: 0.5687
	--> Epoch [8/100], Loss: 0.3232, Validation Loss: 0.5490
	--> Epoch [9/100], Loss: 0.4215, Validation Loss: 0.5315
	--> Epoch [10/100], Loss: 0.3634, Validation Loss: 0.5178
	--> Epoch [11/100], Loss: 0.3327, Validation Loss: 0.5030
	--> Epoch [12/100], Loss: 0.2930, Validation Loss: 0.4890
	--> Epoch [13/100], Loss: 0.3353, Validation Loss: 0.4763
	--> Epoch [14/100], Loss: 0.2176, Validation Loss: 0.4636
	--> Epoch [15/100], Loss: 0.1834, Validation Loss: 0.4525
	--> Epoch [16/100], Loss: 0.2038, Validation Loss: 0.4436
	--> Epoch [17/100], Loss: 0.1855, Validation Loss: 0.4345
	--> Epoch [18/100], Loss: 0.1606, Validation Loss: 0.4248
	--> Epoch [19/100], Loss: 0.2053, Validation Loss: 0.4171
	--> Epoch [20/100], Loss: 0.1909, Validation Loss: 0.4091
	--> Epoch [21/100], Loss: 0.1681, Validation Loss: 0.3993
	--> Epoch [22/100], Loss: 0.1770, Validation Loss: 0.3950
	--> Epoch [23/100], Loss: 0.1529, Validation Loss: 0.3901
	--> Epoch [24/100], Loss: 0.1231, Validation Loss: 0.3845
	--> Epoch [25/100], Loss: 0.1300, Validation Loss: 0.3819
	--> Epoch [26/100], Loss: 0.1795, Validation Loss: 0.3767
	--> Epoch [27/100], Loss: 0.1505, Validation Loss: 0.3733
	--> Epoch [28/100], Loss: 0.1205, Validation Loss: 0.3682
	--> Epoch [29/100], Loss: 0.1268, Validation Loss: 0.3637
	--> Epoch [30/100], Loss: 0.1254, Validation Loss: 0.3602
	--> Epoch [31/100], Loss: 0.1062, Validation Loss: 0.3581
	--> Epoch [32/100], Loss: 0.1240, Validation Loss: 0.3532
	--> Epoch [33/100], Loss: 0.1153, Validation Loss: 0.3497
	--> Epoch [34/100], Loss: 0.1067, Validation Loss: 0.3456
	--> Epoch [35/100], Loss: 0.1305, Validation Loss: 0.3416
	--> Epoch [36/100], Loss: 0.1022, Validation Loss: 0.3411
	--> Epoch [37/100], Loss: 0.1026, Validation Loss: 0.3376
	--> Epoch [38/100], Loss: 0.1565, Validation Loss: 0.3367
	--> Epoch [39/100], Loss: 0.0952, Validation Loss: 0.3356
	--> Epoch [40/100], Loss: 0.1150, Validation Loss: 0.3353
	--> Epoch [41/100], Loss: 0.1100, Validation Loss: 0.3323
	--> Epoch [42/100], Loss: 0.0843, Validation Loss: 0.3316
	--> Epoch [43/100], Loss: 0.0838, Validation Loss: 0.3285
	--> Epoch [44/100], Loss: 0.0943, Validation Loss: 0.3261
	--> Epoch [45/100], Loss: 0.0845, Validation Loss: 0.3268
	--> Epoch [46/100], Loss: 0.1895, Validation Loss: 0.3240
	--> Epoch [47/100], Loss: 0.1839, Validation Loss: 0.3215
	--> Epoch [48/100], Loss: 0.0859, Validation Loss: 0.3193
	--> Epoch [49/100], Loss: 0.1001, Validation Loss: 0.3189
	--> Epoch [50/100], Loss: 0.0996, Validation Loss: 0.3167
	--> Epoch [51/100], Loss: 0.0931, Validation Loss: 0.3169
	--> Epoch [52/100], Loss: 0.0882, Validation Loss: 0.3153
	--> Epoch [53/100], Loss: 0.1068, Validation Loss: 0.3166
	--> Epoch [54/100], Loss: 0.0938, Validation Loss: 0.3170
	--> Epoch [55/100], Loss: 0.0918, Validation Loss: 0.3166
Early stopping
	--> Training for Fold 3 took 0.6909084320068359 sec, using 55 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7155, Validation Loss: 0.6310
	--> Epoch [2/100], Loss: 0.6828, Validation Loss: 0.6050
	--> Epoch [3/100], Loss: 0.6008, Validation Loss: 0.5710
	--> Epoch [4/100], Loss: 0.5156, Validation Loss: 0.5378
	--> Epoch [5/100], Loss: 0.5036, Validation Loss: 0.5177
	--> Epoch [6/100], Loss: 0.4721, Validation Loss: 0.4981
	--> Epoch [7/100], Loss: 0.4656, Validation Loss: 0.4817
	--> Epoch [8/100], Loss: 0.4709, Validation Loss: 0.4547
	--> Epoch [9/100], Loss: 0.3838, Validation Loss: 0.4308
	--> Epoch [10/100], Loss: 0.3612, Validation Loss: 0.4134
	--> Epoch [11/100], Loss: 0.3729, Validation Loss: 0.4037
	--> Epoch [12/100], Loss: 0.3959, Validation Loss: 0.3949
	--> Epoch [13/100], Loss: 0.2822, Validation Loss: 0.3814
	--> Epoch [14/100], Loss: 0.3459, Validation Loss: 0.3717
	--> Epoch [15/100], Loss: 0.2748, Validation Loss: 0.3603
	--> Epoch [16/100], Loss: 0.2202, Validation Loss: 0.3468
	--> Epoch [17/100], Loss: 0.2656, Validation Loss: 0.3422
	--> Epoch [18/100], Loss: 0.2064, Validation Loss: 0.3343
	--> Epoch [19/100], Loss: 0.2551, Validation Loss: 0.3264
	--> Epoch [20/100], Loss: 0.2517, Validation Loss: 0.3240
	--> Epoch [21/100], Loss: 0.2209, Validation Loss: 0.3240
	--> Epoch [22/100], Loss: 0.1383, Validation Loss: 0.3209
	--> Epoch [23/100], Loss: 0.1613, Validation Loss: 0.3171
	--> Epoch [24/100], Loss: 0.1636, Validation Loss: 0.3129
	--> Epoch [25/100], Loss: 0.1716, Validation Loss: 0.3083
	--> Epoch [26/100], Loss: 0.2612, Validation Loss: 0.3048
	--> Epoch [27/100], Loss: 0.1390, Validation Loss: 0.3052
	--> Epoch [28/100], Loss: 0.1097, Validation Loss: 0.3008
	--> Epoch [29/100], Loss: 0.1287, Validation Loss: 0.2984
	--> Epoch [30/100], Loss: 0.1078, Validation Loss: 0.2986
	--> Epoch [31/100], Loss: 0.1132, Validation Loss: 0.2962
	--> Epoch [32/100], Loss: 0.0728, Validation Loss: 0.2960
	--> Epoch [33/100], Loss: 0.1156, Validation Loss: 0.2941
	--> Epoch [34/100], Loss: 0.1320, Validation Loss: 0.2954
	--> Epoch [35/100], Loss: 0.1915, Validation Loss: 0.2900
	--> Epoch [36/100], Loss: 0.0652, Validation Loss: 0.2904
	--> Epoch [37/100], Loss: 0.1035, Validation Loss: 0.2900
	--> Epoch [38/100], Loss: 0.1045, Validation Loss: 0.2904
	--> Epoch [39/100], Loss: 0.1238, Validation Loss: 0.2881
	--> Epoch [40/100], Loss: 0.0976, Validation Loss: 0.2866
	--> Epoch [41/100], Loss: 0.0362, Validation Loss: 0.2861
	--> Epoch [42/100], Loss: 0.0939, Validation Loss: 0.2845
	--> Epoch [43/100], Loss: 0.0323, Validation Loss: 0.2876
	--> Epoch [44/100], Loss: 0.0348, Validation Loss: 0.2879
	--> Epoch [45/100], Loss: 0.1016, Validation Loss: 0.2895
Early stopping
	--> Training for Fold 4 took 0.5708377361297607 sec, using 45 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6827, Validation Loss: 0.6654
	--> Epoch [2/100], Loss: 0.6236, Validation Loss: 0.6460
	--> Epoch [3/100], Loss: 0.5078, Validation Loss: 0.6331
	--> Epoch [4/100], Loss: 0.5120, Validation Loss: 0.6210
	--> Epoch [5/100], Loss: 0.5138, Validation Loss: 0.6113
	--> Epoch [6/100], Loss: 0.4415, Validation Loss: 0.6037
	--> Epoch [7/100], Loss: 0.3835, Validation Loss: 0.5972
	--> Epoch [8/100], Loss: 0.4130, Validation Loss: 0.5857
	--> Epoch [9/100], Loss: 0.3472, Validation Loss: 0.5808
	--> Epoch [10/100], Loss: 0.3783, Validation Loss: 0.5736
	--> Epoch [11/100], Loss: 0.3016, Validation Loss: 0.5616
	--> Epoch [12/100], Loss: 0.2485, Validation Loss: 0.5494
	--> Epoch [13/100], Loss: 0.2308, Validation Loss: 0.5435
	--> Epoch [14/100], Loss: 0.2774, Validation Loss: 0.5328
	--> Epoch [15/100], Loss: 0.2775, Validation Loss: 0.5225
	--> Epoch [16/100], Loss: 0.2093, Validation Loss: 0.5123
	--> Epoch [17/100], Loss: 0.1591, Validation Loss: 0.5025
	--> Epoch [18/100], Loss: 0.1379, Validation Loss: 0.4965
	--> Epoch [19/100], Loss: 0.1153, Validation Loss: 0.4882
	--> Epoch [20/100], Loss: 0.1058, Validation Loss: 0.4856
	--> Epoch [21/100], Loss: 0.1400, Validation Loss: 0.4841
	--> Epoch [22/100], Loss: 0.1966, Validation Loss: 0.4828
	--> Epoch [23/100], Loss: 0.1705, Validation Loss: 0.4805
	--> Epoch [24/100], Loss: 0.1404, Validation Loss: 0.4817
	--> Epoch [25/100], Loss: 0.1329, Validation Loss: 0.4799
	--> Epoch [26/100], Loss: 0.0998, Validation Loss: 0.4762
	--> Epoch [27/100], Loss: 0.0829, Validation Loss: 0.4760
	--> Epoch [28/100], Loss: 0.1558, Validation Loss: 0.4777
	--> Epoch [29/100], Loss: 0.1068, Validation Loss: 0.4815
	--> Epoch [30/100], Loss: 0.0929, Validation Loss: 0.4785
Early stopping
	--> Training for Fold 5 took 0.3668811321258545 sec, using 30 epochs

Median number of epochs used: 55 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/55], Loss: 0.6382
	--> Final training Epoch [2/55], Loss: 0.6130
	--> Final training Epoch [3/55], Loss: 0.5415
	--> Final training Epoch [4/55], Loss: 0.5195
	--> Final training Epoch [5/55], Loss: 0.4608
	--> Final training Epoch [6/55], Loss: 0.5130
	--> Final training Epoch [7/55], Loss: 0.4273
	--> Final training Epoch [8/55], Loss: 0.4144
	--> Final training Epoch [9/55], Loss: 0.3675
	--> Final training Epoch [10/55], Loss: 0.3458
	--> Final training Epoch [11/55], Loss: 0.4054
	--> Final training Epoch [12/55], Loss: 0.2660
	--> Final training Epoch [13/55], Loss: 0.3164
	--> Final training Epoch [14/55], Loss: 0.2544
	--> Final training Epoch [15/55], Loss: 0.3315
	--> Final training Epoch [16/55], Loss: 0.3013
	--> Final training Epoch [17/55], Loss: 0.2118
	--> Final training Epoch [18/55], Loss: 0.2111
	--> Final training Epoch [19/55], Loss: 0.2092
	--> Final training Epoch [20/55], Loss: 0.2383
	--> Final training Epoch [21/55], Loss: 0.2409
	--> Final training Epoch [22/55], Loss: 0.2184
	--> Final training Epoch [23/55], Loss: 0.2016
	--> Final training Epoch [24/55], Loss: 0.1953
	--> Final training Epoch [25/55], Loss: 0.2102
	--> Final training Epoch [26/55], Loss: 0.1793
	--> Final training Epoch [27/55], Loss: 0.1194
	--> Final training Epoch [28/55], Loss: 0.1616
	--> Final training Epoch [29/55], Loss: 0.1146
	--> Final training Epoch [30/55], Loss: 0.1299
	--> Final training Epoch [31/55], Loss: 0.1765
	--> Final training Epoch [32/55], Loss: 0.1511
	--> Final training Epoch [33/55], Loss: 0.1689
	--> Final training Epoch [34/55], Loss: 0.1129
	--> Final training Epoch [35/55], Loss: 0.0786
	--> Final training Epoch [36/55], Loss: 0.0851
	--> Final training Epoch [37/55], Loss: 0.1176
	--> Final training Epoch [38/55], Loss: 0.1200
	--> Final training Epoch [39/55], Loss: 0.2096
	--> Final training Epoch [40/55], Loss: 0.0795
	--> Final training Epoch [41/55], Loss: 0.1643
	--> Final training Epoch [42/55], Loss: 0.1425
	--> Final training Epoch [43/55], Loss: 0.1005
	--> Final training Epoch [44/55], Loss: 0.0818
	--> Final training Epoch [45/55], Loss: 0.1910
	--> Final training Epoch [46/55], Loss: 0.1030
	--> Final training Epoch [47/55], Loss: 0.1270
	--> Final training Epoch [48/55], Loss: 0.1127
	--> Final training Epoch [49/55], Loss: 0.0636
	--> Final training Epoch [50/55], Loss: 0.0572
	--> Final training Epoch [51/55], Loss: 0.0617
	--> Final training Epoch [52/55], Loss: 0.0856
	--> Final training Epoch [53/55], Loss: 0.0498
	--> Final training Epoch [54/55], Loss: 0.0348
	--> Final training Epoch [55/55], Loss: 0.1246

Final training took 0.7999885082244873 sec

TESTING
	--> Testing took 0.0073 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.0669
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3247,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3339,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3428,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3387,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3480,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.3472,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.3735,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3946,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8187, Validation Loss: 0.3721,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3247

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8336, Validation Loss: 0.7103
	--> Epoch [2/100], Loss: 0.8375, Validation Loss: 0.6775
	--> Epoch [3/100], Loss: 0.7435, Validation Loss: 0.6465
	--> Epoch [4/100], Loss: 0.7148, Validation Loss: 0.6156
	--> Epoch [5/100], Loss: 0.6799, Validation Loss: 0.5879
	--> Epoch [6/100], Loss: 0.6188, Validation Loss: 0.5570
	--> Epoch [7/100], Loss: 0.4699, Validation Loss: 0.5292
	--> Epoch [8/100], Loss: 0.4992, Validation Loss: 0.5066
	--> Epoch [9/100], Loss: 0.4821, Validation Loss: 0.4818
	--> Epoch [10/100], Loss: 0.4628, Validation Loss: 0.4599
	--> Epoch [11/100], Loss: 0.3874, Validation Loss: 0.4399
	--> Epoch [12/100], Loss: 0.3818, Validation Loss: 0.4167
	--> Epoch [13/100], Loss: 0.4022, Validation Loss: 0.3985
	--> Epoch [14/100], Loss: 0.3248, Validation Loss: 0.3851
	--> Epoch [15/100], Loss: 0.3443, Validation Loss: 0.3723
	--> Epoch [16/100], Loss: 0.3371, Validation Loss: 0.3612
	--> Epoch [17/100], Loss: 0.1862, Validation Loss: 0.3479
	--> Epoch [18/100], Loss: 0.2903, Validation Loss: 0.3358
	--> Epoch [19/100], Loss: 0.2222, Validation Loss: 0.3251
	--> Epoch [20/100], Loss: 0.1777, Validation Loss: 0.3148
	--> Epoch [21/100], Loss: 0.1277, Validation Loss: 0.3042
	--> Epoch [22/100], Loss: 0.1191, Validation Loss: 0.2959
	--> Epoch [23/100], Loss: 0.2082, Validation Loss: 0.2873
	--> Epoch [24/100], Loss: 0.2009, Validation Loss: 0.2801
	--> Epoch [25/100], Loss: 0.0814, Validation Loss: 0.2766
	--> Epoch [26/100], Loss: 0.0713, Validation Loss: 0.2694
	--> Epoch [27/100], Loss: 0.1534, Validation Loss: 0.2647
	--> Epoch [28/100], Loss: 0.1831, Validation Loss: 0.2592
	--> Epoch [29/100], Loss: 0.1551, Validation Loss: 0.2543
	--> Epoch [30/100], Loss: 0.1339, Validation Loss: 0.2485
	--> Epoch [31/100], Loss: 0.1211, Validation Loss: 0.2448
	--> Epoch [32/100], Loss: 0.1425, Validation Loss: 0.2435
	--> Epoch [33/100], Loss: 0.1168, Validation Loss: 0.2412
	--> Epoch [34/100], Loss: 0.0762, Validation Loss: 0.2390
	--> Epoch [35/100], Loss: 0.0705, Validation Loss: 0.2366
	--> Epoch [36/100], Loss: 0.0681, Validation Loss: 0.2348
	--> Epoch [37/100], Loss: 0.0998, Validation Loss: 0.2348
	--> Epoch [38/100], Loss: 0.0788, Validation Loss: 0.2328
	--> Epoch [39/100], Loss: 0.1041, Validation Loss: 0.2328
	--> Epoch [40/100], Loss: 0.1066, Validation Loss: 0.2321
	--> Epoch [41/100], Loss: 0.0272, Validation Loss: 0.2295
	--> Epoch [42/100], Loss: 0.0531, Validation Loss: 0.2285
	--> Epoch [43/100], Loss: 0.0800, Validation Loss: 0.2281
	--> Epoch [44/100], Loss: 0.0506, Validation Loss: 0.2260
	--> Epoch [45/100], Loss: 0.1979, Validation Loss: 0.2246
	--> Epoch [46/100], Loss: 0.0267, Validation Loss: 0.2233
	--> Epoch [47/100], Loss: 0.0286, Validation Loss: 0.2227
	--> Epoch [48/100], Loss: 0.0425, Validation Loss: 0.2238
	--> Epoch [49/100], Loss: 0.1011, Validation Loss: 0.2224
	--> Epoch [50/100], Loss: 0.0239, Validation Loss: 0.2197
	--> Epoch [51/100], Loss: 0.0530, Validation Loss: 0.2203
	--> Epoch [52/100], Loss: 0.0171, Validation Loss: 0.2218
	--> Epoch [53/100], Loss: 0.0863, Validation Loss: 0.2205
Early stopping
	--> Training for Fold 1 took 0.8421382904052734 sec, using 53 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5885, Validation Loss: 0.7093
	--> Epoch [2/100], Loss: 0.5507, Validation Loss: 0.6774
	--> Epoch [3/100], Loss: 0.5245, Validation Loss: 0.6565
	--> Epoch [4/100], Loss: 0.5214, Validation Loss: 0.6405
	--> Epoch [5/100], Loss: 0.4136, Validation Loss: 0.6258
	--> Epoch [6/100], Loss: 0.4022, Validation Loss: 0.6096
	--> Epoch [7/100], Loss: 0.4172, Validation Loss: 0.6009
	--> Epoch [8/100], Loss: 0.4317, Validation Loss: 0.5861
	--> Epoch [9/100], Loss: 0.3798, Validation Loss: 0.5725
	--> Epoch [10/100], Loss: 0.2575, Validation Loss: 0.5577
	--> Epoch [11/100], Loss: 0.3120, Validation Loss: 0.5458
	--> Epoch [12/100], Loss: 0.2845, Validation Loss: 0.5296
	--> Epoch [13/100], Loss: 0.2612, Validation Loss: 0.5152
	--> Epoch [14/100], Loss: 0.2250, Validation Loss: 0.5019
	--> Epoch [15/100], Loss: 0.2087, Validation Loss: 0.4820
	--> Epoch [16/100], Loss: 0.2773, Validation Loss: 0.4728
	--> Epoch [17/100], Loss: 0.2614, Validation Loss: 0.4628
	--> Epoch [18/100], Loss: 0.2310, Validation Loss: 0.4458
	--> Epoch [19/100], Loss: 0.2386, Validation Loss: 0.4375
	--> Epoch [20/100], Loss: 0.1881, Validation Loss: 0.4282
	--> Epoch [21/100], Loss: 0.1052, Validation Loss: 0.4168
	--> Epoch [22/100], Loss: 0.1664, Validation Loss: 0.4076
	--> Epoch [23/100], Loss: 0.1879, Validation Loss: 0.4000
	--> Epoch [24/100], Loss: 0.1452, Validation Loss: 0.3912
	--> Epoch [25/100], Loss: 0.0960, Validation Loss: 0.3835
	--> Epoch [26/100], Loss: 0.1383, Validation Loss: 0.3794
	--> Epoch [27/100], Loss: 0.1283, Validation Loss: 0.3719
	--> Epoch [28/100], Loss: 0.1113, Validation Loss: 0.3671
	--> Epoch [29/100], Loss: 0.0915, Validation Loss: 0.3582
	--> Epoch [30/100], Loss: 0.0871, Validation Loss: 0.3522
	--> Epoch [31/100], Loss: 0.1604, Validation Loss: 0.3470
	--> Epoch [32/100], Loss: 0.0457, Validation Loss: 0.3439
	--> Epoch [33/100], Loss: 0.0936, Validation Loss: 0.3390
	--> Epoch [34/100], Loss: 0.1144, Validation Loss: 0.3317
	--> Epoch [35/100], Loss: 0.1626, Validation Loss: 0.3259
	--> Epoch [36/100], Loss: 0.1597, Validation Loss: 0.3214
	--> Epoch [37/100], Loss: 0.0288, Validation Loss: 0.3204
	--> Epoch [38/100], Loss: 0.0997, Validation Loss: 0.3177
	--> Epoch [39/100], Loss: 0.1264, Validation Loss: 0.3110
	--> Epoch [40/100], Loss: 0.0359, Validation Loss: 0.3061
	--> Epoch [41/100], Loss: 0.1001, Validation Loss: 0.3038
	--> Epoch [42/100], Loss: 0.0433, Validation Loss: 0.3018
	--> Epoch [43/100], Loss: 0.0939, Validation Loss: 0.2984
	--> Epoch [44/100], Loss: 0.1380, Validation Loss: 0.2946
	--> Epoch [45/100], Loss: 0.1025, Validation Loss: 0.2932
	--> Epoch [46/100], Loss: 0.0913, Validation Loss: 0.2917
	--> Epoch [47/100], Loss: 0.0626, Validation Loss: 0.2913
	--> Epoch [48/100], Loss: 0.0355, Validation Loss: 0.2862
	--> Epoch [49/100], Loss: 0.0770, Validation Loss: 0.2852
	--> Epoch [50/100], Loss: 0.0352, Validation Loss: 0.2840
	--> Epoch [51/100], Loss: 0.0861, Validation Loss: 0.2821
	--> Epoch [52/100], Loss: 0.0681, Validation Loss: 0.2804
	--> Epoch [53/100], Loss: 0.0948, Validation Loss: 0.2768
	--> Epoch [54/100], Loss: 0.0622, Validation Loss: 0.2767
	--> Epoch [55/100], Loss: 0.0622, Validation Loss: 0.2697
	--> Epoch [56/100], Loss: 0.0631, Validation Loss: 0.2697
	--> Epoch [57/100], Loss: 0.2073, Validation Loss: 0.2692
	--> Epoch [58/100], Loss: 0.0737, Validation Loss: 0.2674
	--> Epoch [59/100], Loss: 0.0895, Validation Loss: 0.2640
	--> Epoch [60/100], Loss: 0.0618, Validation Loss: 0.2616
	--> Epoch [61/100], Loss: 0.0065, Validation Loss: 0.2608
	--> Epoch [62/100], Loss: 0.0624, Validation Loss: 0.2583
	--> Epoch [63/100], Loss: 0.0134, Validation Loss: 0.2573
	--> Epoch [64/100], Loss: 0.0598, Validation Loss: 0.2555
	--> Epoch [65/100], Loss: 0.0622, Validation Loss: 0.2543
	--> Epoch [66/100], Loss: 0.0628, Validation Loss: 0.2537
	--> Epoch [67/100], Loss: 0.0165, Validation Loss: 0.2506
	--> Epoch [68/100], Loss: 0.1146, Validation Loss: 0.2478
	--> Epoch [69/100], Loss: 0.0103, Validation Loss: 0.2469
	--> Epoch [70/100], Loss: 0.0208, Validation Loss: 0.2455
	--> Epoch [71/100], Loss: 0.0592, Validation Loss: 0.2417
	--> Epoch [72/100], Loss: 0.1060, Validation Loss: 0.2417
	--> Epoch [73/100], Loss: 0.0059, Validation Loss: 0.2402
	--> Epoch [74/100], Loss: 0.0534, Validation Loss: 0.2423
	--> Epoch [75/100], Loss: 0.0244, Validation Loss: 0.2404
	--> Epoch [76/100], Loss: 0.0561, Validation Loss: 0.2402
Early stopping
	--> Training for Fold 2 took 1.1167938709259033 sec, using 76 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7405, Validation Loss: 0.7426
	--> Epoch [2/100], Loss: 0.6499, Validation Loss: 0.7136
	--> Epoch [3/100], Loss: 0.5940, Validation Loss: 0.6942
	--> Epoch [4/100], Loss: 0.5850, Validation Loss: 0.6747
	--> Epoch [5/100], Loss: 0.4840, Validation Loss: 0.6490
	--> Epoch [6/100], Loss: 0.4132, Validation Loss: 0.6280
	--> Epoch [7/100], Loss: 0.3370, Validation Loss: 0.6036
	--> Epoch [8/100], Loss: 0.4141, Validation Loss: 0.5836
	--> Epoch [9/100], Loss: 0.3627, Validation Loss: 0.5673
	--> Epoch [10/100], Loss: 0.4025, Validation Loss: 0.5518
	--> Epoch [11/100], Loss: 0.3830, Validation Loss: 0.5389
	--> Epoch [12/100], Loss: 0.3284, Validation Loss: 0.5251
	--> Epoch [13/100], Loss: 0.3698, Validation Loss: 0.5142
	--> Epoch [14/100], Loss: 0.2928, Validation Loss: 0.5035
	--> Epoch [15/100], Loss: 0.2160, Validation Loss: 0.4877
	--> Epoch [16/100], Loss: 0.2323, Validation Loss: 0.4779
	--> Epoch [17/100], Loss: 0.1528, Validation Loss: 0.4678
	--> Epoch [18/100], Loss: 0.3321, Validation Loss: 0.4602
	--> Epoch [19/100], Loss: 0.2908, Validation Loss: 0.4552
	--> Epoch [20/100], Loss: 0.1725, Validation Loss: 0.4458
	--> Epoch [21/100], Loss: 0.1923, Validation Loss: 0.4387
	--> Epoch [22/100], Loss: 0.1681, Validation Loss: 0.4348
	--> Epoch [23/100], Loss: 0.1020, Validation Loss: 0.4304
	--> Epoch [24/100], Loss: 0.2484, Validation Loss: 0.4264
	--> Epoch [25/100], Loss: 0.1408, Validation Loss: 0.4256
	--> Epoch [26/100], Loss: 0.0672, Validation Loss: 0.4239
	--> Epoch [27/100], Loss: 0.1204, Validation Loss: 0.4189
	--> Epoch [28/100], Loss: 0.2077, Validation Loss: 0.4163
	--> Epoch [29/100], Loss: 0.1876, Validation Loss: 0.4161
	--> Epoch [30/100], Loss: 0.0610, Validation Loss: 0.4120
	--> Epoch [31/100], Loss: 0.1500, Validation Loss: 0.4078
	--> Epoch [32/100], Loss: 0.1311, Validation Loss: 0.4054
	--> Epoch [33/100], Loss: 0.1651, Validation Loss: 0.4014
	--> Epoch [34/100], Loss: 0.1374, Validation Loss: 0.3981
	--> Epoch [35/100], Loss: 0.0928, Validation Loss: 0.3969
	--> Epoch [36/100], Loss: 0.0357, Validation Loss: 0.3943
	--> Epoch [37/100], Loss: 0.0579, Validation Loss: 0.3934
	--> Epoch [38/100], Loss: 0.0567, Validation Loss: 0.3913
	--> Epoch [39/100], Loss: 0.0497, Validation Loss: 0.3886
	--> Epoch [40/100], Loss: 0.0776, Validation Loss: 0.3895
	--> Epoch [41/100], Loss: 0.0941, Validation Loss: 0.3858
	--> Epoch [42/100], Loss: 0.0938, Validation Loss: 0.3849
	--> Epoch [43/100], Loss: 0.1386, Validation Loss: 0.3833
	--> Epoch [44/100], Loss: 0.0299, Validation Loss: 0.3822
	--> Epoch [45/100], Loss: 0.0245, Validation Loss: 0.3818
	--> Epoch [46/100], Loss: 0.0695, Validation Loss: 0.3815
	--> Epoch [47/100], Loss: 0.0907, Validation Loss: 0.3815
	--> Epoch [48/100], Loss: 0.0782, Validation Loss: 0.3805
	--> Epoch [49/100], Loss: 0.0768, Validation Loss: 0.3791
	--> Epoch [50/100], Loss: 0.0226, Validation Loss: 0.3797
	--> Epoch [51/100], Loss: 0.0178, Validation Loss: 0.3791
	--> Epoch [52/100], Loss: 0.0184, Validation Loss: 0.3777
	--> Epoch [53/100], Loss: 0.0702, Validation Loss: 0.3767
	--> Epoch [54/100], Loss: 0.0280, Validation Loss: 0.3712
	--> Epoch [55/100], Loss: 0.0369, Validation Loss: 0.3696
	--> Epoch [56/100], Loss: 0.0182, Validation Loss: 0.3710
	--> Epoch [57/100], Loss: 0.0836, Validation Loss: 0.3693
	--> Epoch [58/100], Loss: 0.1496, Validation Loss: 0.3683
	--> Epoch [59/100], Loss: 0.0829, Validation Loss: 0.3675
	--> Epoch [60/100], Loss: 0.0931, Validation Loss: 0.3634
	--> Epoch [61/100], Loss: 0.0129, Validation Loss: 0.3616
	--> Epoch [62/100], Loss: 0.0092, Validation Loss: 0.3628
	--> Epoch [63/100], Loss: 0.0761, Validation Loss: 0.3638
	--> Epoch [64/100], Loss: 0.0725, Validation Loss: 0.3615
	--> Epoch [65/100], Loss: 0.0422, Validation Loss: 0.3612
	--> Epoch [66/100], Loss: 0.1200, Validation Loss: 0.3614
	--> Epoch [67/100], Loss: 0.1269, Validation Loss: 0.3556
	--> Epoch [68/100], Loss: 0.1262, Validation Loss: 0.3591
	--> Epoch [69/100], Loss: 0.0766, Validation Loss: 0.3582
	--> Epoch [70/100], Loss: 0.0168, Validation Loss: 0.3605
Early stopping
	--> Training for Fold 3 took 1.2651257514953613 sec, using 70 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8215, Validation Loss: 0.6492
	--> Epoch [2/100], Loss: 0.6961, Validation Loss: 0.6066
	--> Epoch [3/100], Loss: 0.6902, Validation Loss: 0.5659
	--> Epoch [4/100], Loss: 0.6491, Validation Loss: 0.5412
	--> Epoch [5/100], Loss: 0.5727, Validation Loss: 0.5167
	--> Epoch [6/100], Loss: 0.5772, Validation Loss: 0.4990
	--> Epoch [7/100], Loss: 0.4680, Validation Loss: 0.4786
	--> Epoch [8/100], Loss: 0.4623, Validation Loss: 0.4636
	--> Epoch [9/100], Loss: 0.4673, Validation Loss: 0.4503
	--> Epoch [10/100], Loss: 0.4539, Validation Loss: 0.4382
	--> Epoch [11/100], Loss: 0.4424, Validation Loss: 0.4308
	--> Epoch [12/100], Loss: 0.3737, Validation Loss: 0.4237
	--> Epoch [13/100], Loss: 0.4569, Validation Loss: 0.4191
	--> Epoch [14/100], Loss: 0.2765, Validation Loss: 0.4142
	--> Epoch [15/100], Loss: 0.2343, Validation Loss: 0.4120
	--> Epoch [16/100], Loss: 0.3205, Validation Loss: 0.4098
	--> Epoch [17/100], Loss: 0.2409, Validation Loss: 0.4054
	--> Epoch [18/100], Loss: 0.2483, Validation Loss: 0.4015
	--> Epoch [19/100], Loss: 0.1913, Validation Loss: 0.3953
	--> Epoch [20/100], Loss: 0.2079, Validation Loss: 0.3940
	--> Epoch [21/100], Loss: 0.2198, Validation Loss: 0.3912
	--> Epoch [22/100], Loss: 0.1875, Validation Loss: 0.3911
	--> Epoch [23/100], Loss: 0.1247, Validation Loss: 0.3923
	--> Epoch [24/100], Loss: 0.1166, Validation Loss: 0.3934
	--> Epoch [25/100], Loss: 0.1273, Validation Loss: 0.3899
	--> Epoch [26/100], Loss: 0.0840, Validation Loss: 0.3882
	--> Epoch [27/100], Loss: 0.1983, Validation Loss: 0.3882
	--> Epoch [28/100], Loss: 0.1365, Validation Loss: 0.3887
	--> Epoch [29/100], Loss: 0.1664, Validation Loss: 0.3870
	--> Epoch [30/100], Loss: 0.1378, Validation Loss: 0.3864
	--> Epoch [31/100], Loss: 0.0991, Validation Loss: 0.3847
	--> Epoch [32/100], Loss: 0.1213, Validation Loss: 0.3869
	--> Epoch [33/100], Loss: 0.3093, Validation Loss: 0.3902
	--> Epoch [34/100], Loss: 0.0690, Validation Loss: 0.3887
Early stopping
	--> Training for Fold 4 took 0.4429142475128174 sec, using 34 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8088, Validation Loss: 0.6271
	--> Epoch [2/100], Loss: 0.7771, Validation Loss: 0.6032
	--> Epoch [3/100], Loss: 0.6586, Validation Loss: 0.5842
	--> Epoch [4/100], Loss: 0.6220, Validation Loss: 0.5654
	--> Epoch [5/100], Loss: 0.5911, Validation Loss: 0.5527
	--> Epoch [6/100], Loss: 0.5260, Validation Loss: 0.5395
	--> Epoch [7/100], Loss: 0.4990, Validation Loss: 0.5300
	--> Epoch [8/100], Loss: 0.4925, Validation Loss: 0.5198
	--> Epoch [9/100], Loss: 0.4854, Validation Loss: 0.5127
	--> Epoch [10/100], Loss: 0.4068, Validation Loss: 0.5057
	--> Epoch [11/100], Loss: 0.4122, Validation Loss: 0.4983
	--> Epoch [12/100], Loss: 0.3530, Validation Loss: 0.4913
	--> Epoch [13/100], Loss: 0.3327, Validation Loss: 0.4868
	--> Epoch [14/100], Loss: 0.3660, Validation Loss: 0.4813
	--> Epoch [15/100], Loss: 0.3748, Validation Loss: 0.4758
	--> Epoch [16/100], Loss: 0.2927, Validation Loss: 0.4697
	--> Epoch [17/100], Loss: 0.3032, Validation Loss: 0.4660
	--> Epoch [18/100], Loss: 0.2224, Validation Loss: 0.4632
	--> Epoch [19/100], Loss: 0.2732, Validation Loss: 0.4584
	--> Epoch [20/100], Loss: 0.2023, Validation Loss: 0.4552
	--> Epoch [21/100], Loss: 0.2099, Validation Loss: 0.4553
	--> Epoch [22/100], Loss: 0.2414, Validation Loss: 0.4520
	--> Epoch [23/100], Loss: 0.1728, Validation Loss: 0.4486
	--> Epoch [24/100], Loss: 0.2230, Validation Loss: 0.4488
	--> Epoch [25/100], Loss: 0.1199, Validation Loss: 0.4482
	--> Epoch [26/100], Loss: 0.1760, Validation Loss: 0.4463
	--> Epoch [27/100], Loss: 0.1237, Validation Loss: 0.4426
	--> Epoch [28/100], Loss: 0.2397, Validation Loss: 0.4418
	--> Epoch [29/100], Loss: 0.0938, Validation Loss: 0.4389
	--> Epoch [30/100], Loss: 0.1093, Validation Loss: 0.4376
	--> Epoch [31/100], Loss: 0.1586, Validation Loss: 0.4387
	--> Epoch [32/100], Loss: 0.2385, Validation Loss: 0.4387
	--> Epoch [33/100], Loss: 0.0762, Validation Loss: 0.4364
	--> Epoch [34/100], Loss: 0.1453, Validation Loss: 0.4364
	--> Epoch [35/100], Loss: 0.0724, Validation Loss: 0.4349
	--> Epoch [36/100], Loss: 0.1298, Validation Loss: 0.4341
	--> Epoch [37/100], Loss: 0.0942, Validation Loss: 0.4347
	--> Epoch [38/100], Loss: 0.1186, Validation Loss: 0.4363
	--> Epoch [39/100], Loss: 0.1639, Validation Loss: 0.4376
Early stopping
	--> Training for Fold 5 took 0.5148618221282959 sec, using 39 epochs

Median number of epochs used: 53 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/53], Loss: 0.7854
	--> Final training Epoch [2/53], Loss: 0.7369
	--> Final training Epoch [3/53], Loss: 0.7160
	--> Final training Epoch [4/53], Loss: 0.6582
	--> Final training Epoch [5/53], Loss: 0.6536
	--> Final training Epoch [6/53], Loss: 0.5936
	--> Final training Epoch [7/53], Loss: 0.5686
	--> Final training Epoch [8/53], Loss: 0.4719
	--> Final training Epoch [9/53], Loss: 0.4445
	--> Final training Epoch [10/53], Loss: 0.4416
	--> Final training Epoch [11/53], Loss: 0.4283
	--> Final training Epoch [12/53], Loss: 0.3772
	--> Final training Epoch [13/53], Loss: 0.3273
	--> Final training Epoch [14/53], Loss: 0.3499
	--> Final training Epoch [15/53], Loss: 0.3227
	--> Final training Epoch [16/53], Loss: 0.3179
	--> Final training Epoch [17/53], Loss: 0.2174
	--> Final training Epoch [18/53], Loss: 0.2372
	--> Final training Epoch [19/53], Loss: 0.1819
	--> Final training Epoch [20/53], Loss: 0.1749
	--> Final training Epoch [21/53], Loss: 0.1455
	--> Final training Epoch [22/53], Loss: 0.2232
	--> Final training Epoch [23/53], Loss: 0.2124
	--> Final training Epoch [24/53], Loss: 0.1654
	--> Final training Epoch [25/53], Loss: 0.2239
	--> Final training Epoch [26/53], Loss: 0.1620
	--> Final training Epoch [27/53], Loss: 0.2158
	--> Final training Epoch [28/53], Loss: 0.1169
	--> Final training Epoch [29/53], Loss: 0.1344
	--> Final training Epoch [30/53], Loss: 0.1980
	--> Final training Epoch [31/53], Loss: 0.1507
	--> Final training Epoch [32/53], Loss: 0.2131
	--> Final training Epoch [33/53], Loss: 0.1345
	--> Final training Epoch [34/53], Loss: 0.1851
	--> Final training Epoch [35/53], Loss: 0.1191
	--> Final training Epoch [36/53], Loss: 0.0958
	--> Final training Epoch [37/53], Loss: 0.0523
	--> Final training Epoch [38/53], Loss: 0.1591
	--> Final training Epoch [39/53], Loss: 0.1426
	--> Final training Epoch [40/53], Loss: 0.1182
	--> Final training Epoch [41/53], Loss: 0.1179
	--> Final training Epoch [42/53], Loss: 0.0517
	--> Final training Epoch [43/53], Loss: 0.0254
	--> Final training Epoch [44/53], Loss: 0.0959
	--> Final training Epoch [45/53], Loss: 0.1834
	--> Final training Epoch [46/53], Loss: 0.1786
	--> Final training Epoch [47/53], Loss: 0.0350
	--> Final training Epoch [48/53], Loss: 0.1562
	--> Final training Epoch [49/53], Loss: 0.0224
	--> Final training Epoch [50/53], Loss: 0.1482
	--> Final training Epoch [51/53], Loss: 0.0274
	--> Final training Epoch [52/53], Loss: 0.1018
	--> Final training Epoch [53/53], Loss: 0.0405

Final training took 0.9183981418609619 sec

TESTING
	--> Testing took 0.0097 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9445
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.9029, Validation Loss: 0.3247,  Current Best Accuracy: 0.9029,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.3570,  Current Best Accuracy: 0.9029,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3723,  Current Best Accuracy: 0.9029,  Current Best Validation Loss: 0.3247

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6706, Validation Loss: 0.6830
	--> Epoch [2/100], Loss: 0.5814, Validation Loss: 0.6547
	--> Epoch [3/100], Loss: 0.5627, Validation Loss: 0.6248
	--> Epoch [4/100], Loss: 0.5638, Validation Loss: 0.6012
	--> Epoch [5/100], Loss: 0.6191, Validation Loss: 0.5759
	--> Epoch [6/100], Loss: 0.5197, Validation Loss: 0.5509
	--> Epoch [7/100], Loss: 0.5448, Validation Loss: 0.5350
	--> Epoch [8/100], Loss: 0.4379, Validation Loss: 0.5109
	--> Epoch [9/100], Loss: 0.4198, Validation Loss: 0.4966
	--> Epoch [10/100], Loss: 0.4044, Validation Loss: 0.4852
	--> Epoch [11/100], Loss: 0.4820, Validation Loss: 0.4678
	--> Epoch [12/100], Loss: 0.4178, Validation Loss: 0.4538
	--> Epoch [13/100], Loss: 0.3048, Validation Loss: 0.4416
	--> Epoch [14/100], Loss: 0.3791, Validation Loss: 0.4326
	--> Epoch [15/100], Loss: 0.3798, Validation Loss: 0.4198
	--> Epoch [16/100], Loss: 0.1961, Validation Loss: 0.4082
	--> Epoch [17/100], Loss: 0.2001, Validation Loss: 0.3977
	--> Epoch [18/100], Loss: 0.2469, Validation Loss: 0.3888
	--> Epoch [19/100], Loss: 0.3263, Validation Loss: 0.3798
	--> Epoch [20/100], Loss: 0.2110, Validation Loss: 0.3710
	--> Epoch [21/100], Loss: 0.1948, Validation Loss: 0.3644
	--> Epoch [22/100], Loss: 0.2566, Validation Loss: 0.3537
	--> Epoch [23/100], Loss: 0.1680, Validation Loss: 0.3479
	--> Epoch [24/100], Loss: 0.2521, Validation Loss: 0.3430
	--> Epoch [25/100], Loss: 0.2928, Validation Loss: 0.3402
	--> Epoch [26/100], Loss: 0.1313, Validation Loss: 0.3329
	--> Epoch [27/100], Loss: 0.1570, Validation Loss: 0.3303
	--> Epoch [28/100], Loss: 0.2464, Validation Loss: 0.3265
	--> Epoch [29/100], Loss: 0.2183, Validation Loss: 0.3183
	--> Epoch [30/100], Loss: 0.1847, Validation Loss: 0.3086
	--> Epoch [31/100], Loss: 0.1099, Validation Loss: 0.3050
	--> Epoch [32/100], Loss: 0.2120, Validation Loss: 0.3005
	--> Epoch [33/100], Loss: 0.0780, Validation Loss: 0.2995
	--> Epoch [34/100], Loss: 0.1124, Validation Loss: 0.2961
	--> Epoch [35/100], Loss: 0.2061, Validation Loss: 0.2926
	--> Epoch [36/100], Loss: 0.1503, Validation Loss: 0.2878
	--> Epoch [37/100], Loss: 0.1600, Validation Loss: 0.2844
	--> Epoch [38/100], Loss: 0.1100, Validation Loss: 0.2808
	--> Epoch [39/100], Loss: 0.2156, Validation Loss: 0.2753
	--> Epoch [40/100], Loss: 0.0611, Validation Loss: 0.2739
	--> Epoch [41/100], Loss: 0.1780, Validation Loss: 0.2717
	--> Epoch [42/100], Loss: 0.1363, Validation Loss: 0.2681
	--> Epoch [43/100], Loss: 0.2016, Validation Loss: 0.2634
	--> Epoch [44/100], Loss: 0.0689, Validation Loss: 0.2603
	--> Epoch [45/100], Loss: 0.1632, Validation Loss: 0.2603
	--> Epoch [46/100], Loss: 0.0556, Validation Loss: 0.2587
	--> Epoch [47/100], Loss: 0.0295, Validation Loss: 0.2587
	--> Epoch [48/100], Loss: 0.1223, Validation Loss: 0.2614
	--> Epoch [49/100], Loss: 0.1006, Validation Loss: 0.2588
	--> Epoch [50/100], Loss: 0.0801, Validation Loss: 0.2568
	--> Epoch [51/100], Loss: 0.2348, Validation Loss: 0.2543
	--> Epoch [52/100], Loss: 0.1011, Validation Loss: 0.2511
	--> Epoch [53/100], Loss: 0.2098, Validation Loss: 0.2515
	--> Epoch [54/100], Loss: 0.0896, Validation Loss: 0.2518
	--> Epoch [55/100], Loss: 0.2421, Validation Loss: 0.2522
Early stopping
	--> Training for Fold 1 took 0.7059996128082275 sec, using 55 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8451, Validation Loss: 0.5953
	--> Epoch [2/100], Loss: 0.6055, Validation Loss: 0.5606
	--> Epoch [3/100], Loss: 0.6948, Validation Loss: 0.5343
	--> Epoch [4/100], Loss: 0.5524, Validation Loss: 0.5084
	--> Epoch [5/100], Loss: 0.5884, Validation Loss: 0.4831
	--> Epoch [6/100], Loss: 0.4320, Validation Loss: 0.4645
	--> Epoch [7/100], Loss: 0.4783, Validation Loss: 0.4458
	--> Epoch [8/100], Loss: 0.3630, Validation Loss: 0.4342
	--> Epoch [9/100], Loss: 0.4583, Validation Loss: 0.4195
	--> Epoch [10/100], Loss: 0.3198, Validation Loss: 0.4066
	--> Epoch [11/100], Loss: 0.2882, Validation Loss: 0.3923
	--> Epoch [12/100], Loss: 0.5521, Validation Loss: 0.3883
	--> Epoch [13/100], Loss: 0.2032, Validation Loss: 0.3794
	--> Epoch [14/100], Loss: 0.3786, Validation Loss: 0.3761
	--> Epoch [15/100], Loss: 0.2014, Validation Loss: 0.3639
	--> Epoch [16/100], Loss: 0.3548, Validation Loss: 0.3574
	--> Epoch [17/100], Loss: 0.3544, Validation Loss: 0.3482
	--> Epoch [18/100], Loss: 0.1236, Validation Loss: 0.3390
	--> Epoch [19/100], Loss: 0.3108, Validation Loss: 0.3299
	--> Epoch [20/100], Loss: 0.2696, Validation Loss: 0.3245
	--> Epoch [21/100], Loss: 0.1719, Validation Loss: 0.3191
	--> Epoch [22/100], Loss: 0.4326, Validation Loss: 0.3138
	--> Epoch [23/100], Loss: 0.2393, Validation Loss: 0.3086
	--> Epoch [24/100], Loss: 0.1639, Validation Loss: 0.3052
	--> Epoch [25/100], Loss: 0.1019, Validation Loss: 0.2986
	--> Epoch [26/100], Loss: 0.2486, Validation Loss: 0.2934
	--> Epoch [27/100], Loss: 0.1020, Validation Loss: 0.2902
	--> Epoch [28/100], Loss: 0.1064, Validation Loss: 0.2873
	--> Epoch [29/100], Loss: 0.2333, Validation Loss: 0.2832
	--> Epoch [30/100], Loss: 0.3172, Validation Loss: 0.2823
	--> Epoch [31/100], Loss: 0.1281, Validation Loss: 0.2782
	--> Epoch [32/100], Loss: 0.0586, Validation Loss: 0.2763
	--> Epoch [33/100], Loss: 0.1813, Validation Loss: 0.2727
	--> Epoch [34/100], Loss: 0.1474, Validation Loss: 0.2696
	--> Epoch [35/100], Loss: 0.1854, Validation Loss: 0.2665
	--> Epoch [36/100], Loss: 0.1728, Validation Loss: 0.2635
	--> Epoch [37/100], Loss: 0.1807, Validation Loss: 0.2597
	--> Epoch [38/100], Loss: 0.2332, Validation Loss: 0.2583
	--> Epoch [39/100], Loss: 0.2043, Validation Loss: 0.2555
	--> Epoch [40/100], Loss: 0.1687, Validation Loss: 0.2546
	--> Epoch [41/100], Loss: 0.0432, Validation Loss: 0.2539
	--> Epoch [42/100], Loss: 0.2388, Validation Loss: 0.2512
	--> Epoch [43/100], Loss: 0.0636, Validation Loss: 0.2489
	--> Epoch [44/100], Loss: 0.1602, Validation Loss: 0.2459
	--> Epoch [45/100], Loss: 0.0967, Validation Loss: 0.2448
	--> Epoch [46/100], Loss: 0.1799, Validation Loss: 0.2432
	--> Epoch [47/100], Loss: 0.1228, Validation Loss: 0.2456
	--> Epoch [48/100], Loss: 0.1827, Validation Loss: 0.2438
	--> Epoch [49/100], Loss: 0.0161, Validation Loss: 0.2405
	--> Epoch [50/100], Loss: 0.1208, Validation Loss: 0.2373
	--> Epoch [51/100], Loss: 0.1820, Validation Loss: 0.2371
	--> Epoch [52/100], Loss: 0.1730, Validation Loss: 0.2340
	--> Epoch [53/100], Loss: 0.1083, Validation Loss: 0.2345
	--> Epoch [54/100], Loss: 0.0335, Validation Loss: 0.2326
	--> Epoch [55/100], Loss: 0.0452, Validation Loss: 0.2313
	--> Epoch [56/100], Loss: 0.1782, Validation Loss: 0.2326
	--> Epoch [57/100], Loss: 0.0763, Validation Loss: 0.2361
	--> Epoch [58/100], Loss: 0.0874, Validation Loss: 0.2333
Early stopping
	--> Training for Fold 2 took 0.7625954151153564 sec, using 58 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7826, Validation Loss: 0.6312
	--> Epoch [2/100], Loss: 0.7515, Validation Loss: 0.6106
	--> Epoch [3/100], Loss: 0.7236, Validation Loss: 0.5927
	--> Epoch [4/100], Loss: 0.6002, Validation Loss: 0.5735
	--> Epoch [5/100], Loss: 0.5489, Validation Loss: 0.5566
	--> Epoch [6/100], Loss: 0.4869, Validation Loss: 0.5434
	--> Epoch [7/100], Loss: 0.4983, Validation Loss: 0.5296
	--> Epoch [8/100], Loss: 0.5182, Validation Loss: 0.5136
	--> Epoch [9/100], Loss: 0.3095, Validation Loss: 0.5016
	--> Epoch [10/100], Loss: 0.5252, Validation Loss: 0.4903
	--> Epoch [11/100], Loss: 0.3629, Validation Loss: 0.4800
	--> Epoch [12/100], Loss: 0.3088, Validation Loss: 0.4681
	--> Epoch [13/100], Loss: 0.4412, Validation Loss: 0.4607
	--> Epoch [14/100], Loss: 0.2750, Validation Loss: 0.4531
	--> Epoch [15/100], Loss: 0.3571, Validation Loss: 0.4489
	--> Epoch [16/100], Loss: 0.2155, Validation Loss: 0.4409
	--> Epoch [17/100], Loss: 0.3851, Validation Loss: 0.4320
	--> Epoch [18/100], Loss: 0.2663, Validation Loss: 0.4207
	--> Epoch [19/100], Loss: 0.2018, Validation Loss: 0.4161
	--> Epoch [20/100], Loss: 0.0886, Validation Loss: 0.4123
	--> Epoch [21/100], Loss: 0.2842, Validation Loss: 0.4039
	--> Epoch [22/100], Loss: 0.1621, Validation Loss: 0.3972
	--> Epoch [23/100], Loss: 0.0879, Validation Loss: 0.3898
	--> Epoch [24/100], Loss: 0.1691, Validation Loss: 0.3839
	--> Epoch [25/100], Loss: 0.2736, Validation Loss: 0.3841
	--> Epoch [26/100], Loss: 0.2841, Validation Loss: 0.3788
	--> Epoch [27/100], Loss: 0.1201, Validation Loss: 0.3775
	--> Epoch [28/100], Loss: 0.1755, Validation Loss: 0.3737
	--> Epoch [29/100], Loss: 0.1941, Validation Loss: 0.3728
	--> Epoch [30/100], Loss: 0.1231, Validation Loss: 0.3719
	--> Epoch [31/100], Loss: 0.1460, Validation Loss: 0.3687
	--> Epoch [32/100], Loss: 0.0661, Validation Loss: 0.3661
	--> Epoch [33/100], Loss: 0.1041, Validation Loss: 0.3662
	--> Epoch [34/100], Loss: 0.1223, Validation Loss: 0.3615
	--> Epoch [35/100], Loss: 0.2112, Validation Loss: 0.3626
	--> Epoch [36/100], Loss: 0.2384, Validation Loss: 0.3583
	--> Epoch [37/100], Loss: 0.2196, Validation Loss: 0.3559
	--> Epoch [38/100], Loss: 0.1843, Validation Loss: 0.3551
	--> Epoch [39/100], Loss: 0.1612, Validation Loss: 0.3541
	--> Epoch [40/100], Loss: 0.0611, Validation Loss: 0.3524
	--> Epoch [41/100], Loss: 0.0369, Validation Loss: 0.3538
	--> Epoch [42/100], Loss: 0.4106, Validation Loss: 0.3532
	--> Epoch [43/100], Loss: 0.1210, Validation Loss: 0.3532
Early stopping
	--> Training for Fold 3 took 0.6655230522155762 sec, using 43 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6845, Validation Loss: 0.7173
	--> Epoch [2/100], Loss: 0.6118, Validation Loss: 0.6914
	--> Epoch [3/100], Loss: 0.6141, Validation Loss: 0.6671
	--> Epoch [4/100], Loss: 0.5733, Validation Loss: 0.6497
	--> Epoch [5/100], Loss: 0.5457, Validation Loss: 0.6212
	--> Epoch [6/100], Loss: 0.5540, Validation Loss: 0.5976
	--> Epoch [7/100], Loss: 0.4878, Validation Loss: 0.5831
	--> Epoch [8/100], Loss: 0.5073, Validation Loss: 0.5577
	--> Epoch [9/100], Loss: 0.5076, Validation Loss: 0.5399
	--> Epoch [10/100], Loss: 0.4930, Validation Loss: 0.5206
	--> Epoch [11/100], Loss: 0.4686, Validation Loss: 0.5088
	--> Epoch [12/100], Loss: 0.4072, Validation Loss: 0.4961
	--> Epoch [13/100], Loss: 0.5486, Validation Loss: 0.4803
	--> Epoch [14/100], Loss: 0.4147, Validation Loss: 0.4700
	--> Epoch [15/100], Loss: 0.3510, Validation Loss: 0.4575
	--> Epoch [16/100], Loss: 0.3660, Validation Loss: 0.4454
	--> Epoch [17/100], Loss: 0.3604, Validation Loss: 0.4358
	--> Epoch [18/100], Loss: 0.4037, Validation Loss: 0.4286
	--> Epoch [19/100], Loss: 0.2887, Validation Loss: 0.4298
	--> Epoch [20/100], Loss: 0.3050, Validation Loss: 0.4234
	--> Epoch [21/100], Loss: 0.2788, Validation Loss: 0.4115
	--> Epoch [22/100], Loss: 0.2953, Validation Loss: 0.4071
	--> Epoch [23/100], Loss: 0.2875, Validation Loss: 0.4051
	--> Epoch [24/100], Loss: 0.3426, Validation Loss: 0.4026
	--> Epoch [25/100], Loss: 0.3433, Validation Loss: 0.3983
	--> Epoch [26/100], Loss: 0.2765, Validation Loss: 0.3953
	--> Epoch [27/100], Loss: 0.3057, Validation Loss: 0.3890
	--> Epoch [28/100], Loss: 0.3404, Validation Loss: 0.3871
	--> Epoch [29/100], Loss: 0.2992, Validation Loss: 0.3856
	--> Epoch [30/100], Loss: 0.2593, Validation Loss: 0.3866
	--> Epoch [31/100], Loss: 0.2365, Validation Loss: 0.3845
	--> Epoch [32/100], Loss: 0.2264, Validation Loss: 0.3787
	--> Epoch [33/100], Loss: 0.3511, Validation Loss: 0.3774
	--> Epoch [34/100], Loss: 0.3215, Validation Loss: 0.3763
	--> Epoch [35/100], Loss: 0.3115, Validation Loss: 0.3760
	--> Epoch [36/100], Loss: 0.1714, Validation Loss: 0.3747
	--> Epoch [37/100], Loss: 0.2730, Validation Loss: 0.3717
	--> Epoch [38/100], Loss: 0.2041, Validation Loss: 0.3687
	--> Epoch [39/100], Loss: 0.1899, Validation Loss: 0.3689
	--> Epoch [40/100], Loss: 0.3071, Validation Loss: 0.3677
	--> Epoch [41/100], Loss: 0.2817, Validation Loss: 0.3652
	--> Epoch [42/100], Loss: 0.2332, Validation Loss: 0.3689
	--> Epoch [43/100], Loss: 0.2611, Validation Loss: 0.3614
	--> Epoch [44/100], Loss: 0.2586, Validation Loss: 0.3583
	--> Epoch [45/100], Loss: 0.3543, Validation Loss: 0.3589
	--> Epoch [46/100], Loss: 0.2717, Validation Loss: 0.3582
	--> Epoch [47/100], Loss: 0.1709, Validation Loss: 0.3579
	--> Epoch [48/100], Loss: 0.2370, Validation Loss: 0.3578
	--> Epoch [49/100], Loss: 0.2912, Validation Loss: 0.3598
	--> Epoch [50/100], Loss: 0.1742, Validation Loss: 0.3602
	--> Epoch [51/100], Loss: 0.2365, Validation Loss: 0.3587
Early stopping
	--> Training for Fold 4 took 0.6864087581634521 sec, using 51 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7559, Validation Loss: 0.6576
	--> Epoch [2/100], Loss: 0.7280, Validation Loss: 0.6465
	--> Epoch [3/100], Loss: 0.6493, Validation Loss: 0.6433
	--> Epoch [4/100], Loss: 0.6493, Validation Loss: 0.6405
	--> Epoch [5/100], Loss: 0.4880, Validation Loss: 0.6425
	--> Epoch [6/100], Loss: 0.5758, Validation Loss: 0.6386
	--> Epoch [7/100], Loss: 0.5496, Validation Loss: 0.6351
	--> Epoch [8/100], Loss: 0.5382, Validation Loss: 0.6299
	--> Epoch [9/100], Loss: 0.4719, Validation Loss: 0.6287
	--> Epoch [10/100], Loss: 0.5349, Validation Loss: 0.6207
	--> Epoch [11/100], Loss: 0.3940, Validation Loss: 0.6165
	--> Epoch [12/100], Loss: 0.3001, Validation Loss: 0.6086
	--> Epoch [13/100], Loss: 0.3484, Validation Loss: 0.6063
	--> Epoch [14/100], Loss: 0.3390, Validation Loss: 0.6066
	--> Epoch [15/100], Loss: 0.2940, Validation Loss: 0.6010
	--> Epoch [16/100], Loss: 0.2794, Validation Loss: 0.5986
	--> Epoch [17/100], Loss: 0.3421, Validation Loss: 0.5966
	--> Epoch [18/100], Loss: 0.3274, Validation Loss: 0.5940
	--> Epoch [19/100], Loss: 0.2816, Validation Loss: 0.5901
	--> Epoch [20/100], Loss: 0.2390, Validation Loss: 0.5832
	--> Epoch [21/100], Loss: 0.2443, Validation Loss: 0.5807
	--> Epoch [22/100], Loss: 0.2052, Validation Loss: 0.5804
	--> Epoch [23/100], Loss: 0.2774, Validation Loss: 0.5734
	--> Epoch [24/100], Loss: 0.2133, Validation Loss: 0.5718
	--> Epoch [25/100], Loss: 0.1308, Validation Loss: 0.5738
	--> Epoch [26/100], Loss: 0.2334, Validation Loss: 0.5796
	--> Epoch [27/100], Loss: 0.1540, Validation Loss: 0.5825
Early stopping
	--> Training for Fold 5 took 0.3648078441619873 sec, using 27 epochs

Median number of epochs used: 51 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/51], Loss: 0.7848
	--> Final training Epoch [2/51], Loss: 0.7294
	--> Final training Epoch [3/51], Loss: 0.6796
	--> Final training Epoch [4/51], Loss: 0.5952
	--> Final training Epoch [5/51], Loss: 0.5420
	--> Final training Epoch [6/51], Loss: 0.5437
	--> Final training Epoch [7/51], Loss: 0.4518
	--> Final training Epoch [8/51], Loss: 0.4535
	--> Final training Epoch [9/51], Loss: 0.4336
	--> Final training Epoch [10/51], Loss: 0.3867
	--> Final training Epoch [11/51], Loss: 0.3595
	--> Final training Epoch [12/51], Loss: 0.3906
	--> Final training Epoch [13/51], Loss: 0.3631
	--> Final training Epoch [14/51], Loss: 0.5073
	--> Final training Epoch [15/51], Loss: 0.3872
	--> Final training Epoch [16/51], Loss: 0.2817
	--> Final training Epoch [17/51], Loss: 0.2857
	--> Final training Epoch [18/51], Loss: 0.3215
	--> Final training Epoch [19/51], Loss: 0.2938
	--> Final training Epoch [20/51], Loss: 0.2026
	--> Final training Epoch [21/51], Loss: 0.3125
	--> Final training Epoch [22/51], Loss: 0.1864
	--> Final training Epoch [23/51], Loss: 0.2179
	--> Final training Epoch [24/51], Loss: 0.1678
	--> Final training Epoch [25/51], Loss: 0.1835
	--> Final training Epoch [26/51], Loss: 0.1357
	--> Final training Epoch [27/51], Loss: 0.2452
	--> Final training Epoch [28/51], Loss: 0.2373
	--> Final training Epoch [29/51], Loss: 0.2326
	--> Final training Epoch [30/51], Loss: 0.2199
	--> Final training Epoch [31/51], Loss: 0.2868
	--> Final training Epoch [32/51], Loss: 0.1348
	--> Final training Epoch [33/51], Loss: 0.1052
	--> Final training Epoch [34/51], Loss: 0.1488
	--> Final training Epoch [35/51], Loss: 0.2007
	--> Final training Epoch [36/51], Loss: 0.1862
	--> Final training Epoch [37/51], Loss: 0.1324
	--> Final training Epoch [38/51], Loss: 0.1261
	--> Final training Epoch [39/51], Loss: 0.1160
	--> Final training Epoch [40/51], Loss: 0.1162
	--> Final training Epoch [41/51], Loss: 0.1368
	--> Final training Epoch [42/51], Loss: 0.1265
	--> Final training Epoch [43/51], Loss: 0.1492
	--> Final training Epoch [44/51], Loss: 0.1015
	--> Final training Epoch [45/51], Loss: 0.0857
	--> Final training Epoch [46/51], Loss: 0.1798
	--> Final training Epoch [47/51], Loss: 0.1094
	--> Final training Epoch [48/51], Loss: 0.2150
	--> Final training Epoch [49/51], Loss: 0.1962
	--> Final training Epoch [50/51], Loss: 0.1594
	--> Final training Epoch [51/51], Loss: 0.0812

Final training took 0.8108963966369629 sec

TESTING
	--> Testing took 0.0094 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.9259
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3246,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3246
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3486,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3246
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3740,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3246
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7842, Validation Loss: 0.4026,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3246
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.4009,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3246
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8708, Validation Loss: 0.3442,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3246

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5786, Validation Loss: 0.6099
	--> Epoch [2/100], Loss: 0.5919, Validation Loss: 0.5885
	--> Epoch [3/100], Loss: 0.4404, Validation Loss: 0.5669
	--> Epoch [4/100], Loss: 0.4639, Validation Loss: 0.5437
	--> Epoch [5/100], Loss: 0.5033, Validation Loss: 0.5267
	--> Epoch [6/100], Loss: 0.3434, Validation Loss: 0.5088
	--> Epoch [7/100], Loss: 0.3875, Validation Loss: 0.4960
	--> Epoch [8/100], Loss: 0.4358, Validation Loss: 0.4817
	--> Epoch [9/100], Loss: 0.3598, Validation Loss: 0.4663
	--> Epoch [10/100], Loss: 0.3691, Validation Loss: 0.4526
	--> Epoch [11/100], Loss: 0.3654, Validation Loss: 0.4428
	--> Epoch [12/100], Loss: 0.3169, Validation Loss: 0.4316
	--> Epoch [13/100], Loss: 0.2613, Validation Loss: 0.4214
	--> Epoch [14/100], Loss: 0.2302, Validation Loss: 0.4116
	--> Epoch [15/100], Loss: 0.2086, Validation Loss: 0.4029
	--> Epoch [16/100], Loss: 0.1365, Validation Loss: 0.3942
	--> Epoch [17/100], Loss: 0.2363, Validation Loss: 0.3872
	--> Epoch [18/100], Loss: 0.2109, Validation Loss: 0.3802
	--> Epoch [19/100], Loss: 0.1797, Validation Loss: 0.3740
	--> Epoch [20/100], Loss: 0.1291, Validation Loss: 0.3717
	--> Epoch [21/100], Loss: 0.1688, Validation Loss: 0.3621
	--> Epoch [22/100], Loss: 0.1688, Validation Loss: 0.3593
	--> Epoch [23/100], Loss: 0.1285, Validation Loss: 0.3508
	--> Epoch [24/100], Loss: 0.2041, Validation Loss: 0.3474
	--> Epoch [25/100], Loss: 0.1474, Validation Loss: 0.3435
	--> Epoch [26/100], Loss: 0.0911, Validation Loss: 0.3409
	--> Epoch [27/100], Loss: 0.2110, Validation Loss: 0.3384
	--> Epoch [28/100], Loss: 0.0605, Validation Loss: 0.3349
	--> Epoch [29/100], Loss: 0.2075, Validation Loss: 0.3329
	--> Epoch [30/100], Loss: 0.1037, Validation Loss: 0.3336
	--> Epoch [31/100], Loss: 0.0418, Validation Loss: 0.3316
	--> Epoch [32/100], Loss: 0.1001, Validation Loss: 0.3275
	--> Epoch [33/100], Loss: 0.0540, Validation Loss: 0.3237
	--> Epoch [34/100], Loss: 0.0507, Validation Loss: 0.3225
	--> Epoch [35/100], Loss: 0.0668, Validation Loss: 0.3223
	--> Epoch [36/100], Loss: 0.0382, Validation Loss: 0.3203
	--> Epoch [37/100], Loss: 0.1242, Validation Loss: 0.3200
	--> Epoch [38/100], Loss: 0.0986, Validation Loss: 0.3190
	--> Epoch [39/100], Loss: 0.0379, Validation Loss: 0.3203
	--> Epoch [40/100], Loss: 0.0529, Validation Loss: 0.3171
	--> Epoch [41/100], Loss: 0.0359, Validation Loss: 0.3195
	--> Epoch [42/100], Loss: 0.0951, Validation Loss: 0.3172
	--> Epoch [43/100], Loss: 0.0825, Validation Loss: 0.3135
	--> Epoch [44/100], Loss: 0.0698, Validation Loss: 0.3108
	--> Epoch [45/100], Loss: 0.0331, Validation Loss: 0.3099
	--> Epoch [46/100], Loss: 0.1296, Validation Loss: 0.3086
	--> Epoch [47/100], Loss: 0.0438, Validation Loss: 0.3094
	--> Epoch [48/100], Loss: 0.0998, Validation Loss: 0.3071
	--> Epoch [49/100], Loss: 0.0240, Validation Loss: 0.3086
	--> Epoch [50/100], Loss: 0.0190, Validation Loss: 0.3081
	--> Epoch [51/100], Loss: 0.0334, Validation Loss: 0.3044
	--> Epoch [52/100], Loss: 0.1028, Validation Loss: 0.3026
	--> Epoch [53/100], Loss: 0.0089, Validation Loss: 0.3044
	--> Epoch [54/100], Loss: 0.0077, Validation Loss: 0.3048
	--> Epoch [55/100], Loss: 0.0253, Validation Loss: 0.3040
Early stopping
	--> Training for Fold 1 took 0.6910946369171143 sec, using 55 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8465, Validation Loss: 0.6337
	--> Epoch [2/100], Loss: 0.8346, Validation Loss: 0.6075
	--> Epoch [3/100], Loss: 0.7873, Validation Loss: 0.5850
	--> Epoch [4/100], Loss: 0.7019, Validation Loss: 0.5650
	--> Epoch [5/100], Loss: 0.7099, Validation Loss: 0.5507
	--> Epoch [6/100], Loss: 0.6361, Validation Loss: 0.5340
	--> Epoch [7/100], Loss: 0.6888, Validation Loss: 0.5194
	--> Epoch [8/100], Loss: 0.5964, Validation Loss: 0.5033
	--> Epoch [9/100], Loss: 0.4597, Validation Loss: 0.4873
	--> Epoch [10/100], Loss: 0.5225, Validation Loss: 0.4723
	--> Epoch [11/100], Loss: 0.5106, Validation Loss: 0.4585
	--> Epoch [12/100], Loss: 0.3771, Validation Loss: 0.4459
	--> Epoch [13/100], Loss: 0.4811, Validation Loss: 0.4337
	--> Epoch [14/100], Loss: 0.4245, Validation Loss: 0.4210
	--> Epoch [15/100], Loss: 0.3221, Validation Loss: 0.4109
	--> Epoch [16/100], Loss: 0.3552, Validation Loss: 0.4031
	--> Epoch [17/100], Loss: 0.3519, Validation Loss: 0.3915
	--> Epoch [18/100], Loss: 0.4274, Validation Loss: 0.3830
	--> Epoch [19/100], Loss: 0.2310, Validation Loss: 0.3765
	--> Epoch [20/100], Loss: 0.3307, Validation Loss: 0.3675
	--> Epoch [21/100], Loss: 0.3480, Validation Loss: 0.3600
	--> Epoch [22/100], Loss: 0.2899, Validation Loss: 0.3528
	--> Epoch [23/100], Loss: 0.3166, Validation Loss: 0.3448
	--> Epoch [24/100], Loss: 0.1854, Validation Loss: 0.3387
	--> Epoch [25/100], Loss: 0.3198, Validation Loss: 0.3336
	--> Epoch [26/100], Loss: 0.3129, Validation Loss: 0.3274
	--> Epoch [27/100], Loss: 0.1938, Validation Loss: 0.3225
	--> Epoch [28/100], Loss: 0.2228, Validation Loss: 0.3179
	--> Epoch [29/100], Loss: 0.3236, Validation Loss: 0.3127
	--> Epoch [30/100], Loss: 0.3354, Validation Loss: 0.3088
	--> Epoch [31/100], Loss: 0.1691, Validation Loss: 0.3008
	--> Epoch [32/100], Loss: 0.2021, Validation Loss: 0.2978
	--> Epoch [33/100], Loss: 0.1893, Validation Loss: 0.2919
	--> Epoch [34/100], Loss: 0.2262, Validation Loss: 0.2886
	--> Epoch [35/100], Loss: 0.2101, Validation Loss: 0.2857
	--> Epoch [36/100], Loss: 0.2984, Validation Loss: 0.2813
	--> Epoch [37/100], Loss: 0.1214, Validation Loss: 0.2792
	--> Epoch [38/100], Loss: 0.1939, Validation Loss: 0.2746
	--> Epoch [39/100], Loss: 0.3115, Validation Loss: 0.2705
	--> Epoch [40/100], Loss: 0.2349, Validation Loss: 0.2675
	--> Epoch [41/100], Loss: 0.2688, Validation Loss: 0.2655
	--> Epoch [42/100], Loss: 0.1681, Validation Loss: 0.2608
	--> Epoch [43/100], Loss: 0.1064, Validation Loss: 0.2562
	--> Epoch [44/100], Loss: 0.1358, Validation Loss: 0.2538
	--> Epoch [45/100], Loss: 0.1957, Validation Loss: 0.2512
	--> Epoch [46/100], Loss: 0.1232, Validation Loss: 0.2478
	--> Epoch [47/100], Loss: 0.2034, Validation Loss: 0.2450
	--> Epoch [48/100], Loss: 0.2199, Validation Loss: 0.2436
	--> Epoch [49/100], Loss: 0.2799, Validation Loss: 0.2396
	--> Epoch [50/100], Loss: 0.1941, Validation Loss: 0.2405
	--> Epoch [51/100], Loss: 0.1100, Validation Loss: 0.2423
	--> Epoch [52/100], Loss: 0.1120, Validation Loss: 0.2398
Early stopping
	--> Training for Fold 2 took 0.6589813232421875 sec, using 52 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6222, Validation Loss: 0.6992
	--> Epoch [2/100], Loss: 0.6032, Validation Loss: 0.6813
	--> Epoch [3/100], Loss: 0.5220, Validation Loss: 0.6634
	--> Epoch [4/100], Loss: 0.5131, Validation Loss: 0.6491
	--> Epoch [5/100], Loss: 0.4158, Validation Loss: 0.6334
	--> Epoch [6/100], Loss: 0.5055, Validation Loss: 0.6188
	--> Epoch [7/100], Loss: 0.3595, Validation Loss: 0.6031
	--> Epoch [8/100], Loss: 0.3383, Validation Loss: 0.5860
	--> Epoch [9/100], Loss: 0.3746, Validation Loss: 0.5716
	--> Epoch [10/100], Loss: 0.3740, Validation Loss: 0.5587
	--> Epoch [11/100], Loss: 0.3952, Validation Loss: 0.5411
	--> Epoch [12/100], Loss: 0.3061, Validation Loss: 0.5248
	--> Epoch [13/100], Loss: 0.2487, Validation Loss: 0.5087
	--> Epoch [14/100], Loss: 0.2556, Validation Loss: 0.4983
	--> Epoch [15/100], Loss: 0.2687, Validation Loss: 0.4893
	--> Epoch [16/100], Loss: 0.2629, Validation Loss: 0.4767
	--> Epoch [17/100], Loss: 0.1501, Validation Loss: 0.4647
	--> Epoch [18/100], Loss: 0.2073, Validation Loss: 0.4555
	--> Epoch [19/100], Loss: 0.1768, Validation Loss: 0.4509
	--> Epoch [20/100], Loss: 0.1248, Validation Loss: 0.4412
	--> Epoch [21/100], Loss: 0.1502, Validation Loss: 0.4337
	--> Epoch [22/100], Loss: 0.1287, Validation Loss: 0.4252
	--> Epoch [23/100], Loss: 0.1297, Validation Loss: 0.4139
	--> Epoch [24/100], Loss: 0.1032, Validation Loss: 0.4067
	--> Epoch [25/100], Loss: 0.1275, Validation Loss: 0.3998
	--> Epoch [26/100], Loss: 0.0864, Validation Loss: 0.3952
	--> Epoch [27/100], Loss: 0.0856, Validation Loss: 0.3884
	--> Epoch [28/100], Loss: 0.0708, Validation Loss: 0.3836
	--> Epoch [29/100], Loss: 0.1756, Validation Loss: 0.3805
	--> Epoch [30/100], Loss: 0.1420, Validation Loss: 0.3760
	--> Epoch [31/100], Loss: 0.0715, Validation Loss: 0.3725
	--> Epoch [32/100], Loss: 0.2199, Validation Loss: 0.3705
	--> Epoch [33/100], Loss: 0.0725, Validation Loss: 0.3663
	--> Epoch [34/100], Loss: 0.1550, Validation Loss: 0.3644
	--> Epoch [35/100], Loss: 0.0633, Validation Loss: 0.3593
	--> Epoch [36/100], Loss: 0.1352, Validation Loss: 0.3606
	--> Epoch [37/100], Loss: 0.0858, Validation Loss: 0.3575
	--> Epoch [38/100], Loss: 0.0350, Validation Loss: 0.3529
	--> Epoch [39/100], Loss: 0.0265, Validation Loss: 0.3512
	--> Epoch [40/100], Loss: 0.0475, Validation Loss: 0.3483
	--> Epoch [41/100], Loss: 0.0311, Validation Loss: 0.3468
	--> Epoch [42/100], Loss: 0.0824, Validation Loss: 0.3462
	--> Epoch [43/100], Loss: 0.1036, Validation Loss: 0.3470
	--> Epoch [44/100], Loss: 0.0207, Validation Loss: 0.3432
	--> Epoch [45/100], Loss: 0.0346, Validation Loss: 0.3426
	--> Epoch [46/100], Loss: 0.1027, Validation Loss: 0.3412
	--> Epoch [47/100], Loss: 0.1004, Validation Loss: 0.3438
	--> Epoch [48/100], Loss: 0.0207, Validation Loss: 0.3413
	--> Epoch [49/100], Loss: 0.0316, Validation Loss: 0.3399
	--> Epoch [50/100], Loss: 0.0290, Validation Loss: 0.3395
	--> Epoch [51/100], Loss: 0.0186, Validation Loss: 0.3381
	--> Epoch [52/100], Loss: 0.0813, Validation Loss: 0.3371
	--> Epoch [53/100], Loss: 0.0169, Validation Loss: 0.3374
	--> Epoch [54/100], Loss: 0.0826, Validation Loss: 0.3376
	--> Epoch [55/100], Loss: 0.0162, Validation Loss: 0.3379
Early stopping
	--> Training for Fold 3 took 0.6905035972595215 sec, using 55 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6781, Validation Loss: 0.6781
	--> Epoch [2/100], Loss: 0.5681, Validation Loss: 0.6419
	--> Epoch [3/100], Loss: 0.5380, Validation Loss: 0.6090
	--> Epoch [4/100], Loss: 0.4790, Validation Loss: 0.5871
	--> Epoch [5/100], Loss: 0.4710, Validation Loss: 0.5646
	--> Epoch [6/100], Loss: 0.4411, Validation Loss: 0.5403
	--> Epoch [7/100], Loss: 0.4298, Validation Loss: 0.5245
	--> Epoch [8/100], Loss: 0.4412, Validation Loss: 0.5013
	--> Epoch [9/100], Loss: 0.3700, Validation Loss: 0.4820
	--> Epoch [10/100], Loss: 0.3168, Validation Loss: 0.4661
	--> Epoch [11/100], Loss: 0.3368, Validation Loss: 0.4533
	--> Epoch [12/100], Loss: 0.2890, Validation Loss: 0.4403
	--> Epoch [13/100], Loss: 0.2825, Validation Loss: 0.4290
	--> Epoch [14/100], Loss: 0.2687, Validation Loss: 0.4153
	--> Epoch [15/100], Loss: 0.2281, Validation Loss: 0.4051
	--> Epoch [16/100], Loss: 0.2219, Validation Loss: 0.3949
	--> Epoch [17/100], Loss: 0.2281, Validation Loss: 0.3907
	--> Epoch [18/100], Loss: 0.2043, Validation Loss: 0.3839
	--> Epoch [19/100], Loss: 0.2258, Validation Loss: 0.3788
	--> Epoch [20/100], Loss: 0.1826, Validation Loss: 0.3761
	--> Epoch [21/100], Loss: 0.2029, Validation Loss: 0.3690
	--> Epoch [22/100], Loss: 0.1900, Validation Loss: 0.3656
	--> Epoch [23/100], Loss: 0.1760, Validation Loss: 0.3638
	--> Epoch [24/100], Loss: 0.1424, Validation Loss: 0.3608
	--> Epoch [25/100], Loss: 0.2385, Validation Loss: 0.3605
	--> Epoch [26/100], Loss: 0.2143, Validation Loss: 0.3584
	--> Epoch [27/100], Loss: 0.0964, Validation Loss: 0.3551
	--> Epoch [28/100], Loss: 0.1618, Validation Loss: 0.3541
	--> Epoch [29/100], Loss: 0.2178, Validation Loss: 0.3520
	--> Epoch [30/100], Loss: 0.1192, Validation Loss: 0.3487
	--> Epoch [31/100], Loss: 0.0816, Validation Loss: 0.3488
	--> Epoch [32/100], Loss: 0.1550, Validation Loss: 0.3491
	--> Epoch [33/100], Loss: 0.1625, Validation Loss: 0.3479
	--> Epoch [34/100], Loss: 0.1570, Validation Loss: 0.3450
	--> Epoch [35/100], Loss: 0.1500, Validation Loss: 0.3469
	--> Epoch [36/100], Loss: 0.0820, Validation Loss: 0.3458
	--> Epoch [37/100], Loss: 0.1875, Validation Loss: 0.3496
Early stopping
	--> Training for Fold 4 took 0.4574582576751709 sec, using 37 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8704, Validation Loss: 0.6286
	--> Epoch [2/100], Loss: 0.7370, Validation Loss: 0.6137
	--> Epoch [3/100], Loss: 0.6962, Validation Loss: 0.5999
	--> Epoch [4/100], Loss: 0.7083, Validation Loss: 0.5862
	--> Epoch [5/100], Loss: 0.6512, Validation Loss: 0.5741
	--> Epoch [6/100], Loss: 0.5411, Validation Loss: 0.5677
	--> Epoch [7/100], Loss: 0.4763, Validation Loss: 0.5627
	--> Epoch [8/100], Loss: 0.4654, Validation Loss: 0.5579
	--> Epoch [9/100], Loss: 0.4238, Validation Loss: 0.5562
	--> Epoch [10/100], Loss: 0.3467, Validation Loss: 0.5528
	--> Epoch [11/100], Loss: 0.2974, Validation Loss: 0.5507
	--> Epoch [12/100], Loss: 0.3049, Validation Loss: 0.5481
	--> Epoch [13/100], Loss: 0.2692, Validation Loss: 0.5478
	--> Epoch [14/100], Loss: 0.3279, Validation Loss: 0.5462
	--> Epoch [15/100], Loss: 0.2622, Validation Loss: 0.5427
	--> Epoch [16/100], Loss: 0.2301, Validation Loss: 0.5412
	--> Epoch [17/100], Loss: 0.2718, Validation Loss: 0.5425
	--> Epoch [18/100], Loss: 0.2180, Validation Loss: 0.5428
	--> Epoch [19/100], Loss: 0.1902, Validation Loss: 0.5421
Early stopping
	--> Training for Fold 5 took 0.2420334815979004 sec, using 19 epochs

Median number of epochs used: 52 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/52], Loss: 0.5173
	--> Final training Epoch [2/52], Loss: 0.5190
	--> Final training Epoch [3/52], Loss: 0.4792
	--> Final training Epoch [4/52], Loss: 0.4736
	--> Final training Epoch [5/52], Loss: 0.4236
	--> Final training Epoch [6/52], Loss: 0.3659
	--> Final training Epoch [7/52], Loss: 0.4217
	--> Final training Epoch [8/52], Loss: 0.4058
	--> Final training Epoch [9/52], Loss: 0.3360
	--> Final training Epoch [10/52], Loss: 0.3081
	--> Final training Epoch [11/52], Loss: 0.2816
	--> Final training Epoch [12/52], Loss: 0.2352
	--> Final training Epoch [13/52], Loss: 0.2602
	--> Final training Epoch [14/52], Loss: 0.1886
	--> Final training Epoch [15/52], Loss: 0.2351
	--> Final training Epoch [16/52], Loss: 0.2222
	--> Final training Epoch [17/52], Loss: 0.1751
	--> Final training Epoch [18/52], Loss: 0.2236
	--> Final training Epoch [19/52], Loss: 0.1872
	--> Final training Epoch [20/52], Loss: 0.1951
	--> Final training Epoch [21/52], Loss: 0.1269
	--> Final training Epoch [22/52], Loss: 0.1089
	--> Final training Epoch [23/52], Loss: 0.0767
	--> Final training Epoch [24/52], Loss: 0.2073
	--> Final training Epoch [25/52], Loss: 0.1429
	--> Final training Epoch [26/52], Loss: 0.1827
	--> Final training Epoch [27/52], Loss: 0.1432
	--> Final training Epoch [28/52], Loss: 0.1096
	--> Final training Epoch [29/52], Loss: 0.1745
	--> Final training Epoch [30/52], Loss: 0.0993
	--> Final training Epoch [31/52], Loss: 0.0874
	--> Final training Epoch [32/52], Loss: 0.1182
	--> Final training Epoch [33/52], Loss: 0.0781
	--> Final training Epoch [34/52], Loss: 0.0470
	--> Final training Epoch [35/52], Loss: 0.1402
	--> Final training Epoch [36/52], Loss: 0.1684
	--> Final training Epoch [37/52], Loss: 0.0330
	--> Final training Epoch [38/52], Loss: 0.0772
	--> Final training Epoch [39/52], Loss: 0.0663
	--> Final training Epoch [40/52], Loss: 0.0269
	--> Final training Epoch [41/52], Loss: 0.0352
	--> Final training Epoch [42/52], Loss: 0.0958
	--> Final training Epoch [43/52], Loss: 0.0303
	--> Final training Epoch [44/52], Loss: 0.1010
	--> Final training Epoch [45/52], Loss: 0.0458
	--> Final training Epoch [46/52], Loss: 0.0321
	--> Final training Epoch [47/52], Loss: 0.0237
	--> Final training Epoch [48/52], Loss: 0.0896
	--> Final training Epoch [49/52], Loss: 0.0392
	--> Final training Epoch [50/52], Loss: 0.0230
	--> Final training Epoch [51/52], Loss: 0.0374
	--> Final training Epoch [52/52], Loss: 0.0098

Final training took 0.7567751407623291 sec

TESTING
	--> Testing took 0.0073 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.1901
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3144,  Current Best Accuracy: 0.8380,  Current Best Validation Loss: 0.3144
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3547,  Current Best Accuracy: 0.8380,  Current Best Validation Loss: 0.3144

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8499, Validation Loss: 0.7545
	--> Epoch [2/100], Loss: 0.7646, Validation Loss: 0.7239
	--> Epoch [3/100], Loss: 0.7325, Validation Loss: 0.6964
	--> Epoch [4/100], Loss: 0.7210, Validation Loss: 0.6705
	--> Epoch [5/100], Loss: 0.7944, Validation Loss: 0.6497
	--> Epoch [6/100], Loss: 0.5798, Validation Loss: 0.6245
	--> Epoch [7/100], Loss: 0.5582, Validation Loss: 0.6017
	--> Epoch [8/100], Loss: 0.6507, Validation Loss: 0.5788
	--> Epoch [9/100], Loss: 0.6328, Validation Loss: 0.5609
	--> Epoch [10/100], Loss: 0.4964, Validation Loss: 0.5430
	--> Epoch [11/100], Loss: 0.5484, Validation Loss: 0.5262
	--> Epoch [12/100], Loss: 0.5568, Validation Loss: 0.5131
	--> Epoch [13/100], Loss: 0.5690, Validation Loss: 0.5015
	--> Epoch [14/100], Loss: 0.4966, Validation Loss: 0.4960
	--> Epoch [15/100], Loss: 0.3801, Validation Loss: 0.4779
	--> Epoch [16/100], Loss: 0.3129, Validation Loss: 0.4613
	--> Epoch [17/100], Loss: 0.3543, Validation Loss: 0.4504
	--> Epoch [18/100], Loss: 0.2793, Validation Loss: 0.4358
	--> Epoch [19/100], Loss: 0.4707, Validation Loss: 0.4184
	--> Epoch [20/100], Loss: 0.2444, Validation Loss: 0.4067
	--> Epoch [21/100], Loss: 0.3513, Validation Loss: 0.3987
	--> Epoch [22/100], Loss: 0.2421, Validation Loss: 0.3865
	--> Epoch [23/100], Loss: 0.3619, Validation Loss: 0.3800
	--> Epoch [24/100], Loss: 0.1283, Validation Loss: 0.3728
	--> Epoch [25/100], Loss: 0.3866, Validation Loss: 0.3620
	--> Epoch [26/100], Loss: 0.3483, Validation Loss: 0.3555
	--> Epoch [27/100], Loss: 0.2584, Validation Loss: 0.3500
	--> Epoch [28/100], Loss: 0.1308, Validation Loss: 0.3460
	--> Epoch [29/100], Loss: 0.1833, Validation Loss: 0.3410
	--> Epoch [30/100], Loss: 0.0398, Validation Loss: 0.3350
	--> Epoch [31/100], Loss: 0.2910, Validation Loss: 0.3290
	--> Epoch [32/100], Loss: 0.1908, Validation Loss: 0.3221
	--> Epoch [33/100], Loss: 0.1020, Validation Loss: 0.3183
	--> Epoch [34/100], Loss: 0.0930, Validation Loss: 0.3126
	--> Epoch [35/100], Loss: 0.0302, Validation Loss: 0.3115
	--> Epoch [36/100], Loss: 0.1547, Validation Loss: 0.3094
	--> Epoch [37/100], Loss: 0.1391, Validation Loss: 0.3103
	--> Epoch [38/100], Loss: 0.2952, Validation Loss: 0.3081
	--> Epoch [39/100], Loss: 0.1552, Validation Loss: 0.3046
	--> Epoch [40/100], Loss: 0.0684, Validation Loss: 0.3000
	--> Epoch [41/100], Loss: 0.1341, Validation Loss: 0.2948
	--> Epoch [42/100], Loss: 0.0884, Validation Loss: 0.2965
	--> Epoch [43/100], Loss: 0.1270, Validation Loss: 0.2918
	--> Epoch [44/100], Loss: 0.2611, Validation Loss: 0.2907
	--> Epoch [45/100], Loss: 0.1117, Validation Loss: 0.2927
	--> Epoch [46/100], Loss: 0.3728, Validation Loss: 0.2913
	--> Epoch [47/100], Loss: 0.2340, Validation Loss: 0.2888
	--> Epoch [48/100], Loss: 0.1368, Validation Loss: 0.2879
	--> Epoch [49/100], Loss: 0.2538, Validation Loss: 0.2841
	--> Epoch [50/100], Loss: 0.2299, Validation Loss: 0.2826
	--> Epoch [51/100], Loss: 0.1068, Validation Loss: 0.2803
	--> Epoch [52/100], Loss: 0.0543, Validation Loss: 0.2808
	--> Epoch [53/100], Loss: 0.2491, Validation Loss: 0.2809
	--> Epoch [54/100], Loss: 0.0955, Validation Loss: 0.2820
Early stopping
	--> Training for Fold 1 took 0.6969943046569824 sec, using 54 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6988, Validation Loss: 0.7617
	--> Epoch [2/100], Loss: 0.6260, Validation Loss: 0.7200
	--> Epoch [3/100], Loss: 0.6486, Validation Loss: 0.6829
	--> Epoch [4/100], Loss: 0.5207, Validation Loss: 0.6450
	--> Epoch [5/100], Loss: 0.5533, Validation Loss: 0.6111
	--> Epoch [6/100], Loss: 0.4214, Validation Loss: 0.5727
	--> Epoch [7/100], Loss: 0.4934, Validation Loss: 0.5389
	--> Epoch [8/100], Loss: 0.4243, Validation Loss: 0.5110
	--> Epoch [9/100], Loss: 0.4584, Validation Loss: 0.4917
	--> Epoch [10/100], Loss: 0.3846, Validation Loss: 0.4678
	--> Epoch [11/100], Loss: 0.4580, Validation Loss: 0.4488
	--> Epoch [12/100], Loss: 0.3561, Validation Loss: 0.4373
	--> Epoch [13/100], Loss: 0.3565, Validation Loss: 0.4259
	--> Epoch [14/100], Loss: 0.3482, Validation Loss: 0.4170
	--> Epoch [15/100], Loss: 0.2752, Validation Loss: 0.4030
	--> Epoch [16/100], Loss: 0.4039, Validation Loss: 0.3930
	--> Epoch [17/100], Loss: 0.2135, Validation Loss: 0.3804
	--> Epoch [18/100], Loss: 0.2678, Validation Loss: 0.3758
	--> Epoch [19/100], Loss: 0.3634, Validation Loss: 0.3636
	--> Epoch [20/100], Loss: 0.3001, Validation Loss: 0.3508
	--> Epoch [21/100], Loss: 0.3280, Validation Loss: 0.3467
	--> Epoch [22/100], Loss: 0.1918, Validation Loss: 0.3400
	--> Epoch [23/100], Loss: 0.1577, Validation Loss: 0.3328
	--> Epoch [24/100], Loss: 0.1788, Validation Loss: 0.3261
	--> Epoch [25/100], Loss: 0.1876, Validation Loss: 0.3244
	--> Epoch [26/100], Loss: 0.2189, Validation Loss: 0.3208
	--> Epoch [27/100], Loss: 0.2628, Validation Loss: 0.3167
	--> Epoch [28/100], Loss: 0.2320, Validation Loss: 0.3125
	--> Epoch [29/100], Loss: 0.2579, Validation Loss: 0.3107
	--> Epoch [30/100], Loss: 0.1613, Validation Loss: 0.3067
	--> Epoch [31/100], Loss: 0.1960, Validation Loss: 0.3039
	--> Epoch [32/100], Loss: 0.1485, Validation Loss: 0.2986
	--> Epoch [33/100], Loss: 0.1645, Validation Loss: 0.2968
	--> Epoch [34/100], Loss: 0.2246, Validation Loss: 0.2954
	--> Epoch [35/100], Loss: 0.3209, Validation Loss: 0.2931
	--> Epoch [36/100], Loss: 0.1839, Validation Loss: 0.2901
	--> Epoch [37/100], Loss: 0.2407, Validation Loss: 0.2837
	--> Epoch [38/100], Loss: 0.0821, Validation Loss: 0.2827
	--> Epoch [39/100], Loss: 0.1473, Validation Loss: 0.2827
	--> Epoch [40/100], Loss: 0.1892, Validation Loss: 0.2809
	--> Epoch [41/100], Loss: 0.1527, Validation Loss: 0.2781
	--> Epoch [42/100], Loss: 0.0660, Validation Loss: 0.2744
	--> Epoch [43/100], Loss: 0.1448, Validation Loss: 0.2699
	--> Epoch [44/100], Loss: 0.0908, Validation Loss: 0.2700
	--> Epoch [45/100], Loss: 0.0757, Validation Loss: 0.2681
	--> Epoch [46/100], Loss: 0.0835, Validation Loss: 0.2706
	--> Epoch [47/100], Loss: 0.0818, Validation Loss: 0.2716
	--> Epoch [48/100], Loss: 0.2063, Validation Loss: 0.2712
Early stopping
	--> Training for Fold 2 took 0.6073713302612305 sec, using 48 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8941, Validation Loss: 0.6307
	--> Epoch [2/100], Loss: 0.7889, Validation Loss: 0.6085
	--> Epoch [3/100], Loss: 0.8762, Validation Loss: 0.5888
	--> Epoch [4/100], Loss: 0.6780, Validation Loss: 0.5768
	--> Epoch [5/100], Loss: 0.5666, Validation Loss: 0.5668
	--> Epoch [6/100], Loss: 0.5191, Validation Loss: 0.5534
	--> Epoch [7/100], Loss: 0.5255, Validation Loss: 0.5407
	--> Epoch [8/100], Loss: 0.4535, Validation Loss: 0.5292
	--> Epoch [9/100], Loss: 0.4629, Validation Loss: 0.5161
	--> Epoch [10/100], Loss: 0.4054, Validation Loss: 0.5080
	--> Epoch [11/100], Loss: 0.4258, Validation Loss: 0.4932
	--> Epoch [12/100], Loss: 0.3266, Validation Loss: 0.4803
	--> Epoch [13/100], Loss: 0.4068, Validation Loss: 0.4706
	--> Epoch [14/100], Loss: 0.5451, Validation Loss: 0.4597
	--> Epoch [15/100], Loss: 0.3086, Validation Loss: 0.4484
	--> Epoch [16/100], Loss: 0.2900, Validation Loss: 0.4427
	--> Epoch [17/100], Loss: 0.4844, Validation Loss: 0.4351
	--> Epoch [18/100], Loss: 0.2822, Validation Loss: 0.4298
	--> Epoch [19/100], Loss: 0.2407, Validation Loss: 0.4220
	--> Epoch [20/100], Loss: 0.2578, Validation Loss: 0.4164
	--> Epoch [21/100], Loss: 0.2730, Validation Loss: 0.4049
	--> Epoch [22/100], Loss: 0.2412, Validation Loss: 0.4001
	--> Epoch [23/100], Loss: 0.2717, Validation Loss: 0.3934
	--> Epoch [24/100], Loss: 0.2733, Validation Loss: 0.3861
	--> Epoch [25/100], Loss: 0.4052, Validation Loss: 0.3800
	--> Epoch [26/100], Loss: 0.2123, Validation Loss: 0.3746
	--> Epoch [27/100], Loss: 0.2556, Validation Loss: 0.3699
	--> Epoch [28/100], Loss: 0.1182, Validation Loss: 0.3650
	--> Epoch [29/100], Loss: 0.3091, Validation Loss: 0.3625
	--> Epoch [30/100], Loss: 0.2610, Validation Loss: 0.3565
	--> Epoch [31/100], Loss: 0.2217, Validation Loss: 0.3527
	--> Epoch [32/100], Loss: 0.1607, Validation Loss: 0.3472
	--> Epoch [33/100], Loss: 0.1383, Validation Loss: 0.3409
	--> Epoch [34/100], Loss: 0.2756, Validation Loss: 0.3375
	--> Epoch [35/100], Loss: 0.1497, Validation Loss: 0.3342
	--> Epoch [36/100], Loss: 0.2438, Validation Loss: 0.3318
	--> Epoch [37/100], Loss: 0.1492, Validation Loss: 0.3281
	--> Epoch [38/100], Loss: 0.1343, Validation Loss: 0.3254
	--> Epoch [39/100], Loss: 0.2127, Validation Loss: 0.3212
	--> Epoch [40/100], Loss: 0.2250, Validation Loss: 0.3190
	--> Epoch [41/100], Loss: 0.1254, Validation Loss: 0.3129
	--> Epoch [42/100], Loss: 0.1037, Validation Loss: 0.3092
	--> Epoch [43/100], Loss: 0.1102, Validation Loss: 0.3066
	--> Epoch [44/100], Loss: 0.1103, Validation Loss: 0.3040
	--> Epoch [45/100], Loss: 0.1724, Validation Loss: 0.3029
	--> Epoch [46/100], Loss: 0.1016, Validation Loss: 0.3010
	--> Epoch [47/100], Loss: 0.0376, Validation Loss: 0.2999
	--> Epoch [48/100], Loss: 0.2404, Validation Loss: 0.2980
	--> Epoch [49/100], Loss: 0.1200, Validation Loss: 0.2956
	--> Epoch [50/100], Loss: 0.2461, Validation Loss: 0.2943
	--> Epoch [51/100], Loss: 0.0233, Validation Loss: 0.2948
	--> Epoch [52/100], Loss: 0.2434, Validation Loss: 0.2960
	--> Epoch [53/100], Loss: 0.3014, Validation Loss: 0.2930
	--> Epoch [54/100], Loss: 0.1088, Validation Loss: 0.2912
	--> Epoch [55/100], Loss: 0.0966, Validation Loss: 0.2923
	--> Epoch [56/100], Loss: 0.2468, Validation Loss: 0.2900
	--> Epoch [57/100], Loss: 0.1585, Validation Loss: 0.2914
	--> Epoch [58/100], Loss: 0.0784, Validation Loss: 0.2890
	--> Epoch [59/100], Loss: 0.1037, Validation Loss: 0.2882
	--> Epoch [60/100], Loss: 0.1632, Validation Loss: 0.2875
	--> Epoch [61/100], Loss: 0.0895, Validation Loss: 0.2857
	--> Epoch [62/100], Loss: 0.1594, Validation Loss: 0.2859
	--> Epoch [63/100], Loss: 0.0123, Validation Loss: 0.2855
	--> Epoch [64/100], Loss: 0.0896, Validation Loss: 0.2854
	--> Epoch [65/100], Loss: 0.1570, Validation Loss: 0.2830
	--> Epoch [66/100], Loss: 0.1510, Validation Loss: 0.2851
	--> Epoch [67/100], Loss: 0.1617, Validation Loss: 0.2850
	--> Epoch [68/100], Loss: 0.0991, Validation Loss: 0.2811
	--> Epoch [69/100], Loss: 0.3563, Validation Loss: 0.2807
	--> Epoch [70/100], Loss: 0.2787, Validation Loss: 0.2803
	--> Epoch [71/100], Loss: 0.1432, Validation Loss: 0.2803
	--> Epoch [72/100], Loss: 0.1412, Validation Loss: 0.2790
	--> Epoch [73/100], Loss: 0.3470, Validation Loss: 0.2805
	--> Epoch [74/100], Loss: 0.1436, Validation Loss: 0.2798
	--> Epoch [75/100], Loss: 0.2237, Validation Loss: 0.2794
Early stopping
	--> Training for Fold 3 took 1.09798264503479 sec, using 75 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6568, Validation Loss: 0.6848
	--> Epoch [2/100], Loss: 0.6566, Validation Loss: 0.6588
	--> Epoch [3/100], Loss: 0.5566, Validation Loss: 0.6326
	--> Epoch [4/100], Loss: 0.5597, Validation Loss: 0.6126
	--> Epoch [5/100], Loss: 0.5487, Validation Loss: 0.5973
	--> Epoch [6/100], Loss: 0.4762, Validation Loss: 0.5825
	--> Epoch [7/100], Loss: 0.4110, Validation Loss: 0.5629
	--> Epoch [8/100], Loss: 0.5121, Validation Loss: 0.5441
	--> Epoch [9/100], Loss: 0.4248, Validation Loss: 0.5305
	--> Epoch [10/100], Loss: 0.4346, Validation Loss: 0.5140
	--> Epoch [11/100], Loss: 0.3252, Validation Loss: 0.4930
	--> Epoch [12/100], Loss: 0.4285, Validation Loss: 0.4769
	--> Epoch [13/100], Loss: 0.2938, Validation Loss: 0.4653
	--> Epoch [14/100], Loss: 0.4363, Validation Loss: 0.4512
	--> Epoch [15/100], Loss: 0.3494, Validation Loss: 0.4459
	--> Epoch [16/100], Loss: 0.3581, Validation Loss: 0.4328
	--> Epoch [17/100], Loss: 0.1501, Validation Loss: 0.4172
	--> Epoch [18/100], Loss: 0.2372, Validation Loss: 0.4100
	--> Epoch [19/100], Loss: 0.3190, Validation Loss: 0.4023
	--> Epoch [20/100], Loss: 0.3624, Validation Loss: 0.4020
	--> Epoch [21/100], Loss: 0.3103, Validation Loss: 0.3928
	--> Epoch [22/100], Loss: 0.3379, Validation Loss: 0.3829
	--> Epoch [23/100], Loss: 0.2935, Validation Loss: 0.3779
	--> Epoch [24/100], Loss: 0.2763, Validation Loss: 0.3753
	--> Epoch [25/100], Loss: 0.1949, Validation Loss: 0.3743
	--> Epoch [26/100], Loss: 0.1257, Validation Loss: 0.3692
	--> Epoch [27/100], Loss: 0.1663, Validation Loss: 0.3634
	--> Epoch [28/100], Loss: 0.3159, Validation Loss: 0.3600
	--> Epoch [29/100], Loss: 0.2548, Validation Loss: 0.3561
	--> Epoch [30/100], Loss: 0.2108, Validation Loss: 0.3509
	--> Epoch [31/100], Loss: 0.2777, Validation Loss: 0.3483
	--> Epoch [32/100], Loss: 0.2775, Validation Loss: 0.3455
	--> Epoch [33/100], Loss: 0.2416, Validation Loss: 0.3440
	--> Epoch [34/100], Loss: 0.2157, Validation Loss: 0.3362
	--> Epoch [35/100], Loss: 0.1621, Validation Loss: 0.3336
	--> Epoch [36/100], Loss: 0.2134, Validation Loss: 0.3260
	--> Epoch [37/100], Loss: 0.2022, Validation Loss: 0.3210
	--> Epoch [38/100], Loss: 0.0526, Validation Loss: 0.3185
	--> Epoch [39/100], Loss: 0.1042, Validation Loss: 0.3173
	--> Epoch [40/100], Loss: 0.1340, Validation Loss: 0.3122
	--> Epoch [41/100], Loss: 0.1333, Validation Loss: 0.3104
	--> Epoch [42/100], Loss: 0.1257, Validation Loss: 0.3091
	--> Epoch [43/100], Loss: 0.2306, Validation Loss: 0.3088
	--> Epoch [44/100], Loss: 0.1172, Validation Loss: 0.3049
	--> Epoch [45/100], Loss: 0.1977, Validation Loss: 0.3080
	--> Epoch [46/100], Loss: 0.2222, Validation Loss: 0.3101
	--> Epoch [47/100], Loss: 0.2115, Validation Loss: 0.3104
Early stopping
	--> Training for Fold 4 took 0.687598705291748 sec, using 47 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6477, Validation Loss: 0.6622
	--> Epoch [2/100], Loss: 0.6621, Validation Loss: 0.6547
	--> Epoch [3/100], Loss: 0.5334, Validation Loss: 0.6465
	--> Epoch [4/100], Loss: 0.5382, Validation Loss: 0.6415
	--> Epoch [5/100], Loss: 0.5027, Validation Loss: 0.6364
	--> Epoch [6/100], Loss: 0.4126, Validation Loss: 0.6319
	--> Epoch [7/100], Loss: 0.4580, Validation Loss: 0.6315
	--> Epoch [8/100], Loss: 0.3895, Validation Loss: 0.6241
	--> Epoch [9/100], Loss: 0.4131, Validation Loss: 0.6225
	--> Epoch [10/100], Loss: 0.3604, Validation Loss: 0.6208
	--> Epoch [11/100], Loss: 0.3529, Validation Loss: 0.6174
	--> Epoch [12/100], Loss: 0.2999, Validation Loss: 0.6145
	--> Epoch [13/100], Loss: 0.4187, Validation Loss: 0.6115
	--> Epoch [14/100], Loss: 0.2695, Validation Loss: 0.6121
	--> Epoch [15/100], Loss: 0.2238, Validation Loss: 0.6074
	--> Epoch [16/100], Loss: 0.2237, Validation Loss: 0.6070
	--> Epoch [17/100], Loss: 0.2113, Validation Loss: 0.6051
	--> Epoch [18/100], Loss: 0.2305, Validation Loss: 0.6042
	--> Epoch [19/100], Loss: 0.2040, Validation Loss: 0.6041
	--> Epoch [20/100], Loss: 0.1879, Validation Loss: 0.6055
	--> Epoch [21/100], Loss: 0.2452, Validation Loss: 0.6036
	--> Epoch [22/100], Loss: 0.1581, Validation Loss: 0.6034
	--> Epoch [23/100], Loss: 0.1934, Validation Loss: 0.5950
	--> Epoch [24/100], Loss: 0.2197, Validation Loss: 0.5985
	--> Epoch [25/100], Loss: 0.3182, Validation Loss: 0.6025
	--> Epoch [26/100], Loss: 0.1674, Validation Loss: 0.6072
Early stopping
	--> Training for Fold 5 took 0.3466613292694092 sec, using 26 epochs

Median number of epochs used: 48 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/48], Loss: 0.8364
	--> Final training Epoch [2/48], Loss: 0.7362
	--> Final training Epoch [3/48], Loss: 0.7504
	--> Final training Epoch [4/48], Loss: 0.6712
	--> Final training Epoch [5/48], Loss: 0.6014
	--> Final training Epoch [6/48], Loss: 0.7033
	--> Final training Epoch [7/48], Loss: 0.5354
	--> Final training Epoch [8/48], Loss: 0.5662
	--> Final training Epoch [9/48], Loss: 0.4574
	--> Final training Epoch [10/48], Loss: 0.4829
	--> Final training Epoch [11/48], Loss: 0.3879
	--> Final training Epoch [12/48], Loss: 0.5955
	--> Final training Epoch [13/48], Loss: 0.3771
	--> Final training Epoch [14/48], Loss: 0.4105
	--> Final training Epoch [15/48], Loss: 0.4222
	--> Final training Epoch [16/48], Loss: 0.3585
	--> Final training Epoch [17/48], Loss: 0.4170
	--> Final training Epoch [18/48], Loss: 0.4168
	--> Final training Epoch [19/48], Loss: 0.4337
	--> Final training Epoch [20/48], Loss: 0.3992
	--> Final training Epoch [21/48], Loss: 0.3130
	--> Final training Epoch [22/48], Loss: 0.3386
	--> Final training Epoch [23/48], Loss: 0.3907
	--> Final training Epoch [24/48], Loss: 0.2031
	--> Final training Epoch [25/48], Loss: 0.4187
	--> Final training Epoch [26/48], Loss: 0.2139
	--> Final training Epoch [27/48], Loss: 0.2692
	--> Final training Epoch [28/48], Loss: 0.3135
	--> Final training Epoch [29/48], Loss: 0.2259
	--> Final training Epoch [30/48], Loss: 0.2520
	--> Final training Epoch [31/48], Loss: 0.3238
	--> Final training Epoch [32/48], Loss: 0.2048
	--> Final training Epoch [33/48], Loss: 0.3247
	--> Final training Epoch [34/48], Loss: 0.3246
	--> Final training Epoch [35/48], Loss: 0.2285
	--> Final training Epoch [36/48], Loss: 0.2992
	--> Final training Epoch [37/48], Loss: 0.1955
	--> Final training Epoch [38/48], Loss: 0.2104
	--> Final training Epoch [39/48], Loss: 0.2965
	--> Final training Epoch [40/48], Loss: 0.1422
	--> Final training Epoch [41/48], Loss: 0.2716
	--> Final training Epoch [42/48], Loss: 0.2254
	--> Final training Epoch [43/48], Loss: 0.3949
	--> Final training Epoch [44/48], Loss: 0.1898
	--> Final training Epoch [45/48], Loss: 0.3642
	--> Final training Epoch [46/48], Loss: 0.3997
	--> Final training Epoch [47/48], Loss: 0.1774
	--> Final training Epoch [48/48], Loss: 0.3397

Final training took 0.7679388523101807 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 0.7857
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3434,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3434

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.4254, Validation Loss: 0.6172
	--> Epoch [2/100], Loss: 0.3801, Validation Loss: 0.5822
	--> Epoch [3/100], Loss: 0.3198, Validation Loss: 0.5489
	--> Epoch [4/100], Loss: 0.4025, Validation Loss: 0.5240
	--> Epoch [5/100], Loss: 0.2787, Validation Loss: 0.5020
	--> Epoch [6/100], Loss: 0.3058, Validation Loss: 0.4834
	--> Epoch [7/100], Loss: 0.2802, Validation Loss: 0.4609
	--> Epoch [8/100], Loss: 0.3620, Validation Loss: 0.4410
	--> Epoch [9/100], Loss: 0.2955, Validation Loss: 0.4264
	--> Epoch [10/100], Loss: 0.2541, Validation Loss: 0.4077
	--> Epoch [11/100], Loss: 0.3010, Validation Loss: 0.3936
	--> Epoch [12/100], Loss: 0.3844, Validation Loss: 0.3841
	--> Epoch [13/100], Loss: 0.3228, Validation Loss: 0.3752
	--> Epoch [14/100], Loss: 0.2269, Validation Loss: 0.3647
	--> Epoch [15/100], Loss: 0.1753, Validation Loss: 0.3570
	--> Epoch [16/100], Loss: 0.2391, Validation Loss: 0.3485
	--> Epoch [17/100], Loss: 0.3064, Validation Loss: 0.3404
	--> Epoch [18/100], Loss: 0.2538, Validation Loss: 0.3305
	--> Epoch [19/100], Loss: 0.2400, Validation Loss: 0.3264
	--> Epoch [20/100], Loss: 0.1821, Validation Loss: 0.3192
	--> Epoch [21/100], Loss: 0.2175, Validation Loss: 0.3127
	--> Epoch [22/100], Loss: 0.3141, Validation Loss: 0.3074
	--> Epoch [23/100], Loss: 0.1722, Validation Loss: 0.3021
	--> Epoch [24/100], Loss: 0.1890, Validation Loss: 0.2959
	--> Epoch [25/100], Loss: 0.1863, Validation Loss: 0.2930
	--> Epoch [26/100], Loss: 0.2189, Validation Loss: 0.2882
	--> Epoch [27/100], Loss: 0.1055, Validation Loss: 0.2872
	--> Epoch [28/100], Loss: 0.0709, Validation Loss: 0.2846
	--> Epoch [29/100], Loss: 0.1376, Validation Loss: 0.2816
	--> Epoch [30/100], Loss: 0.0750, Validation Loss: 0.2807
	--> Epoch [31/100], Loss: 0.1161, Validation Loss: 0.2781
	--> Epoch [32/100], Loss: 0.1145, Validation Loss: 0.2762
	--> Epoch [33/100], Loss: 0.1227, Validation Loss: 0.2743
	--> Epoch [34/100], Loss: 0.0497, Validation Loss: 0.2707
	--> Epoch [35/100], Loss: 0.0540, Validation Loss: 0.2694
	--> Epoch [36/100], Loss: 0.2076, Validation Loss: 0.2713
	--> Epoch [37/100], Loss: 0.1301, Validation Loss: 0.2665
	--> Epoch [38/100], Loss: 0.1630, Validation Loss: 0.2616
	--> Epoch [39/100], Loss: 0.0496, Validation Loss: 0.2619
	--> Epoch [40/100], Loss: 0.0643, Validation Loss: 0.2608
	--> Epoch [41/100], Loss: 0.0737, Validation Loss: 0.2584
	--> Epoch [42/100], Loss: 0.0526, Validation Loss: 0.2565
	--> Epoch [43/100], Loss: 0.1642, Validation Loss: 0.2545
	--> Epoch [44/100], Loss: 0.1260, Validation Loss: 0.2538
	--> Epoch [45/100], Loss: 0.0202, Validation Loss: 0.2542
	--> Epoch [46/100], Loss: 0.0686, Validation Loss: 0.2532
	--> Epoch [47/100], Loss: 0.1187, Validation Loss: 0.2522
	--> Epoch [48/100], Loss: 0.1126, Validation Loss: 0.2505
	--> Epoch [49/100], Loss: 0.0655, Validation Loss: 0.2498
	--> Epoch [50/100], Loss: 0.1792, Validation Loss: 0.2481
	--> Epoch [51/100], Loss: 0.0398, Validation Loss: 0.2475
	--> Epoch [52/100], Loss: 0.1298, Validation Loss: 0.2475
	--> Epoch [53/100], Loss: 0.0973, Validation Loss: 0.2459
	--> Epoch [54/100], Loss: 0.0172, Validation Loss: 0.2454
	--> Epoch [55/100], Loss: 0.1000, Validation Loss: 0.2452
	--> Epoch [56/100], Loss: 0.0317, Validation Loss: 0.2459
	--> Epoch [57/100], Loss: 0.0686, Validation Loss: 0.2448
	--> Epoch [58/100], Loss: 0.1020, Validation Loss: 0.2453
	--> Epoch [59/100], Loss: 0.1313, Validation Loss: 0.2485
	--> Epoch [60/100], Loss: 0.1319, Validation Loss: 0.2473
Early stopping
	--> Training for Fold 1 took 0.9512693881988525 sec, using 60 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5930, Validation Loss: 0.7123
	--> Epoch [2/100], Loss: 0.5655, Validation Loss: 0.6347
	--> Epoch [3/100], Loss: 0.4988, Validation Loss: 0.5941
	--> Epoch [4/100], Loss: 0.4072, Validation Loss: 0.5582
	--> Epoch [5/100], Loss: 0.5028, Validation Loss: 0.5195
	--> Epoch [6/100], Loss: 0.4467, Validation Loss: 0.4921
	--> Epoch [7/100], Loss: 0.3638, Validation Loss: 0.4698
	--> Epoch [8/100], Loss: 0.4268, Validation Loss: 0.4499
	--> Epoch [9/100], Loss: 0.4013, Validation Loss: 0.4238
	--> Epoch [10/100], Loss: 0.3547, Validation Loss: 0.4040
	--> Epoch [11/100], Loss: 0.2869, Validation Loss: 0.3893
	--> Epoch [12/100], Loss: 0.2259, Validation Loss: 0.3766
	--> Epoch [13/100], Loss: 0.2640, Validation Loss: 0.3698
	--> Epoch [14/100], Loss: 0.4047, Validation Loss: 0.3530
	--> Epoch [15/100], Loss: 0.2352, Validation Loss: 0.3417
	--> Epoch [16/100], Loss: 0.2279, Validation Loss: 0.3309
	--> Epoch [17/100], Loss: 0.1941, Validation Loss: 0.3249
	--> Epoch [18/100], Loss: 0.2115, Validation Loss: 0.3212
	--> Epoch [19/100], Loss: 0.1604, Validation Loss: 0.3102
	--> Epoch [20/100], Loss: 0.3026, Validation Loss: 0.3042
	--> Epoch [21/100], Loss: 0.2157, Validation Loss: 0.2983
	--> Epoch [22/100], Loss: 0.1465, Validation Loss: 0.2951
	--> Epoch [23/100], Loss: 0.1310, Validation Loss: 0.2871
	--> Epoch [24/100], Loss: 0.3023, Validation Loss: 0.2746
	--> Epoch [25/100], Loss: 0.2038, Validation Loss: 0.2710
	--> Epoch [26/100], Loss: 0.1574, Validation Loss: 0.2552
	--> Epoch [27/100], Loss: 0.1137, Validation Loss: 0.2520
	--> Epoch [28/100], Loss: 0.0843, Validation Loss: 0.2519
	--> Epoch [29/100], Loss: 0.1817, Validation Loss: 0.2446
	--> Epoch [30/100], Loss: 0.0417, Validation Loss: 0.2428
	--> Epoch [31/100], Loss: 0.1869, Validation Loss: 0.2296
	--> Epoch [32/100], Loss: 0.1201, Validation Loss: 0.2240
	--> Epoch [33/100], Loss: 0.1657, Validation Loss: 0.2231
	--> Epoch [34/100], Loss: 0.2265, Validation Loss: 0.2182
	--> Epoch [35/100], Loss: 0.1848, Validation Loss: 0.2165
	--> Epoch [36/100], Loss: 0.1195, Validation Loss: 0.2146
	--> Epoch [37/100], Loss: 0.1789, Validation Loss: 0.2149
	--> Epoch [38/100], Loss: 0.1044, Validation Loss: 0.2136
	--> Epoch [39/100], Loss: 0.0933, Validation Loss: 0.2103
	--> Epoch [40/100], Loss: 0.1650, Validation Loss: 0.2066
	--> Epoch [41/100], Loss: 0.1504, Validation Loss: 0.2043
	--> Epoch [42/100], Loss: 0.0624, Validation Loss: 0.2037
	--> Epoch [43/100], Loss: 0.0846, Validation Loss: 0.1998
	--> Epoch [44/100], Loss: 0.2158, Validation Loss: 0.1972
	--> Epoch [45/100], Loss: 0.1926, Validation Loss: 0.1909
	--> Epoch [46/100], Loss: 0.0884, Validation Loss: 0.1871
	--> Epoch [47/100], Loss: 0.2234, Validation Loss: 0.1879
	--> Epoch [48/100], Loss: 0.1338, Validation Loss: 0.1837
	--> Epoch [49/100], Loss: 0.1135, Validation Loss: 0.1828
	--> Epoch [50/100], Loss: 0.0779, Validation Loss: 0.1814
	--> Epoch [51/100], Loss: 0.1372, Validation Loss: 0.1784
	--> Epoch [52/100], Loss: 0.1654, Validation Loss: 0.1779
	--> Epoch [53/100], Loss: 0.0953, Validation Loss: 0.1764
	--> Epoch [54/100], Loss: 0.0798, Validation Loss: 0.1746
	--> Epoch [55/100], Loss: 0.1364, Validation Loss: 0.1766
	--> Epoch [56/100], Loss: 0.1189, Validation Loss: 0.1755
	--> Epoch [57/100], Loss: 0.1377, Validation Loss: 0.1778
Early stopping
	--> Training for Fold 2 took 0.7647116184234619 sec, using 57 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8624, Validation Loss: 0.6242
	--> Epoch [2/100], Loss: 0.7109, Validation Loss: 0.6043
	--> Epoch [3/100], Loss: 0.6640, Validation Loss: 0.5875
	--> Epoch [4/100], Loss: 0.5912, Validation Loss: 0.5742
	--> Epoch [5/100], Loss: 0.7774, Validation Loss: 0.5635
	--> Epoch [6/100], Loss: 0.6272, Validation Loss: 0.5510
	--> Epoch [7/100], Loss: 0.5240, Validation Loss: 0.5362
	--> Epoch [8/100], Loss: 0.5215, Validation Loss: 0.5242
	--> Epoch [9/100], Loss: 0.5703, Validation Loss: 0.5149
	--> Epoch [10/100], Loss: 0.4834, Validation Loss: 0.5050
	--> Epoch [11/100], Loss: 0.4161, Validation Loss: 0.4961
	--> Epoch [12/100], Loss: 0.4251, Validation Loss: 0.4852
	--> Epoch [13/100], Loss: 0.3468, Validation Loss: 0.4768
	--> Epoch [14/100], Loss: 0.4469, Validation Loss: 0.4676
	--> Epoch [15/100], Loss: 0.2587, Validation Loss: 0.4609
	--> Epoch [16/100], Loss: 0.2444, Validation Loss: 0.4500
	--> Epoch [17/100], Loss: 0.1981, Validation Loss: 0.4410
	--> Epoch [18/100], Loss: 0.2327, Validation Loss: 0.4344
	--> Epoch [19/100], Loss: 0.2434, Validation Loss: 0.4291
	--> Epoch [20/100], Loss: 0.2250, Validation Loss: 0.4245
	--> Epoch [21/100], Loss: 0.2622, Validation Loss: 0.4210
	--> Epoch [22/100], Loss: 0.2868, Validation Loss: 0.4151
	--> Epoch [23/100], Loss: 0.2060, Validation Loss: 0.4137
	--> Epoch [24/100], Loss: 0.1515, Validation Loss: 0.4096
	--> Epoch [25/100], Loss: 0.2489, Validation Loss: 0.4045
	--> Epoch [26/100], Loss: 0.2577, Validation Loss: 0.3950
	--> Epoch [27/100], Loss: 0.2238, Validation Loss: 0.3921
	--> Epoch [28/100], Loss: 0.3595, Validation Loss: 0.3900
	--> Epoch [29/100], Loss: 0.3877, Validation Loss: 0.3852
	--> Epoch [30/100], Loss: 0.2014, Validation Loss: 0.3825
	--> Epoch [31/100], Loss: 0.1708, Validation Loss: 0.3775
	--> Epoch [32/100], Loss: 0.2657, Validation Loss: 0.3743
	--> Epoch [33/100], Loss: 0.1788, Validation Loss: 0.3725
	--> Epoch [34/100], Loss: 0.3973, Validation Loss: 0.3750
	--> Epoch [35/100], Loss: 0.1362, Validation Loss: 0.3705
	--> Epoch [36/100], Loss: 0.2618, Validation Loss: 0.3706
	--> Epoch [37/100], Loss: 0.2288, Validation Loss: 0.3685
	--> Epoch [38/100], Loss: 0.1439, Validation Loss: 0.3643
	--> Epoch [39/100], Loss: 0.1307, Validation Loss: 0.3650
	--> Epoch [40/100], Loss: 0.2835, Validation Loss: 0.3563
	--> Epoch [41/100], Loss: 0.1264, Validation Loss: 0.3566
	--> Epoch [42/100], Loss: 0.2540, Validation Loss: 0.3540
	--> Epoch [43/100], Loss: 0.1296, Validation Loss: 0.3491
	--> Epoch [44/100], Loss: 0.1102, Validation Loss: 0.3477
	--> Epoch [45/100], Loss: 0.2891, Validation Loss: 0.3480
	--> Epoch [46/100], Loss: 0.3233, Validation Loss: 0.3464
	--> Epoch [47/100], Loss: 0.2743, Validation Loss: 0.3488
	--> Epoch [48/100], Loss: 0.2046, Validation Loss: 0.3489
	--> Epoch [49/100], Loss: 0.1374, Validation Loss: 0.3462
	--> Epoch [50/100], Loss: 0.1538, Validation Loss: 0.3452
	--> Epoch [51/100], Loss: 0.1066, Validation Loss: 0.3448
	--> Epoch [52/100], Loss: 0.1946, Validation Loss: 0.3440
	--> Epoch [53/100], Loss: 0.2098, Validation Loss: 0.3416
	--> Epoch [54/100], Loss: 0.0925, Validation Loss: 0.3393
	--> Epoch [55/100], Loss: 0.1883, Validation Loss: 0.3361
	--> Epoch [56/100], Loss: 0.2007, Validation Loss: 0.3314
	--> Epoch [57/100], Loss: 0.1810, Validation Loss: 0.3296
	--> Epoch [58/100], Loss: 0.1236, Validation Loss: 0.3286
	--> Epoch [59/100], Loss: 0.1247, Validation Loss: 0.3284
	--> Epoch [60/100], Loss: 0.1546, Validation Loss: 0.3282
	--> Epoch [61/100], Loss: 0.0922, Validation Loss: 0.3280
	--> Epoch [62/100], Loss: 0.1024, Validation Loss: 0.3273
	--> Epoch [63/100], Loss: 0.2277, Validation Loss: 0.3284
	--> Epoch [64/100], Loss: 0.1025, Validation Loss: 0.3272
	--> Epoch [65/100], Loss: 0.2799, Validation Loss: 0.3251
	--> Epoch [66/100], Loss: 0.1301, Validation Loss: 0.3248
	--> Epoch [67/100], Loss: 0.2762, Validation Loss: 0.3276
	--> Epoch [68/100], Loss: 0.1925, Validation Loss: 0.3270
	--> Epoch [69/100], Loss: 0.1628, Validation Loss: 0.3245
	--> Epoch [70/100], Loss: 0.2150, Validation Loss: 0.3250
	--> Epoch [71/100], Loss: 0.2755, Validation Loss: 0.3238
	--> Epoch [72/100], Loss: 0.0920, Validation Loss: 0.3241
	--> Epoch [73/100], Loss: 0.2013, Validation Loss: 0.3207
	--> Epoch [74/100], Loss: 0.2000, Validation Loss: 0.3248
	--> Epoch [75/100], Loss: 0.1275, Validation Loss: 0.3264
	--> Epoch [76/100], Loss: 0.1543, Validation Loss: 0.3254
Early stopping
	--> Training for Fold 3 took 1.0116615295410156 sec, using 76 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7513, Validation Loss: 0.6566
	--> Epoch [2/100], Loss: 0.7178, Validation Loss: 0.6320
	--> Epoch [3/100], Loss: 0.7142, Validation Loss: 0.6075
	--> Epoch [4/100], Loss: 0.5698, Validation Loss: 0.5764
	--> Epoch [5/100], Loss: 0.6043, Validation Loss: 0.5515
	--> Epoch [6/100], Loss: 0.6309, Validation Loss: 0.5145
	--> Epoch [7/100], Loss: 0.4611, Validation Loss: 0.4975
	--> Epoch [8/100], Loss: 0.5291, Validation Loss: 0.4836
	--> Epoch [9/100], Loss: 0.4523, Validation Loss: 0.4677
	--> Epoch [10/100], Loss: 0.4308, Validation Loss: 0.4536
	--> Epoch [11/100], Loss: 0.4109, Validation Loss: 0.4374
	--> Epoch [12/100], Loss: 0.4127, Validation Loss: 0.4270
	--> Epoch [13/100], Loss: 0.3264, Validation Loss: 0.4146
	--> Epoch [14/100], Loss: 0.4323, Validation Loss: 0.4061
	--> Epoch [15/100], Loss: 0.3463, Validation Loss: 0.3946
	--> Epoch [16/100], Loss: 0.4363, Validation Loss: 0.3855
	--> Epoch [17/100], Loss: 0.3730, Validation Loss: 0.3828
	--> Epoch [18/100], Loss: 0.4183, Validation Loss: 0.3749
	--> Epoch [19/100], Loss: 0.3475, Validation Loss: 0.3689
	--> Epoch [20/100], Loss: 0.4390, Validation Loss: 0.3620
	--> Epoch [21/100], Loss: 0.4294, Validation Loss: 0.3546
	--> Epoch [22/100], Loss: 0.4187, Validation Loss: 0.3520
	--> Epoch [23/100], Loss: 0.3195, Validation Loss: 0.3431
	--> Epoch [24/100], Loss: 0.3076, Validation Loss: 0.3411
	--> Epoch [25/100], Loss: 0.3027, Validation Loss: 0.3389
	--> Epoch [26/100], Loss: 0.1980, Validation Loss: 0.3332
	--> Epoch [27/100], Loss: 0.3789, Validation Loss: 0.3311
	--> Epoch [28/100], Loss: 0.3156, Validation Loss: 0.3227
	--> Epoch [29/100], Loss: 0.3234, Validation Loss: 0.3203
	--> Epoch [30/100], Loss: 0.2571, Validation Loss: 0.3164
	--> Epoch [31/100], Loss: 0.3142, Validation Loss: 0.3152
	--> Epoch [32/100], Loss: 0.2537, Validation Loss: 0.3095
	--> Epoch [33/100], Loss: 0.2549, Validation Loss: 0.3041
	--> Epoch [34/100], Loss: 0.2184, Validation Loss: 0.3022
	--> Epoch [35/100], Loss: 0.2157, Validation Loss: 0.2967
	--> Epoch [36/100], Loss: 0.2614, Validation Loss: 0.2923
	--> Epoch [37/100], Loss: 0.2586, Validation Loss: 0.2909
	--> Epoch [38/100], Loss: 0.2026, Validation Loss: 0.2919
	--> Epoch [39/100], Loss: 0.1635, Validation Loss: 0.2936
	--> Epoch [40/100], Loss: 0.3333, Validation Loss: 0.2935
Early stopping
	--> Training for Fold 4 took 0.5479929447174072 sec, using 40 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5921, Validation Loss: 0.7455
	--> Epoch [2/100], Loss: 0.5411, Validation Loss: 0.7327
	--> Epoch [3/100], Loss: 0.5068, Validation Loss: 0.7269
	--> Epoch [4/100], Loss: 0.4800, Validation Loss: 0.7220
	--> Epoch [5/100], Loss: 0.4161, Validation Loss: 0.7129
	--> Epoch [6/100], Loss: 0.3354, Validation Loss: 0.7082
	--> Epoch [7/100], Loss: 0.3719, Validation Loss: 0.7007
	--> Epoch [8/100], Loss: 0.2977, Validation Loss: 0.6908
	--> Epoch [9/100], Loss: 0.3794, Validation Loss: 0.6909
	--> Epoch [10/100], Loss: 0.2915, Validation Loss: 0.6822
	--> Epoch [11/100], Loss: 0.2748, Validation Loss: 0.6791
	--> Epoch [12/100], Loss: 0.2608, Validation Loss: 0.6751
	--> Epoch [13/100], Loss: 0.2271, Validation Loss: 0.6717
	--> Epoch [14/100], Loss: 0.3067, Validation Loss: 0.6732
	--> Epoch [15/100], Loss: 0.1746, Validation Loss: 0.6682
	--> Epoch [16/100], Loss: 0.2782, Validation Loss: 0.6674
	--> Epoch [17/100], Loss: 0.2683, Validation Loss: 0.6634
	--> Epoch [18/100], Loss: 0.1943, Validation Loss: 0.6618
	--> Epoch [19/100], Loss: 0.1913, Validation Loss: 0.6607
	--> Epoch [20/100], Loss: 0.1444, Validation Loss: 0.6576
	--> Epoch [21/100], Loss: 0.2286, Validation Loss: 0.6500
	--> Epoch [22/100], Loss: 0.3832, Validation Loss: 0.6468
	--> Epoch [23/100], Loss: 0.2006, Validation Loss: 0.6460
	--> Epoch [24/100], Loss: 0.0906, Validation Loss: 0.6388
	--> Epoch [25/100], Loss: 0.1047, Validation Loss: 0.6392
	--> Epoch [26/100], Loss: 0.1029, Validation Loss: 0.6408
	--> Epoch [27/100], Loss: 0.2415, Validation Loss: 0.6368
	--> Epoch [28/100], Loss: 0.0847, Validation Loss: 0.6378
	--> Epoch [29/100], Loss: 0.1825, Validation Loss: 0.6400
	--> Epoch [30/100], Loss: 0.1272, Validation Loss: 0.6367
	--> Epoch [31/100], Loss: 0.1012, Validation Loss: 0.6368
	--> Epoch [32/100], Loss: 0.0690, Validation Loss: 0.6334
	--> Epoch [33/100], Loss: 0.1232, Validation Loss: 0.6327
	--> Epoch [34/100], Loss: 0.1272, Validation Loss: 0.6265
	--> Epoch [35/100], Loss: 0.0825, Validation Loss: 0.6283
	--> Epoch [36/100], Loss: 0.0692, Validation Loss: 0.6237
	--> Epoch [37/100], Loss: 0.0717, Validation Loss: 0.6257
	--> Epoch [38/100], Loss: 0.2331, Validation Loss: 0.6296
	--> Epoch [39/100], Loss: 0.0988, Validation Loss: 0.6301
Early stopping
	--> Training for Fold 5 took 0.6584513187408447 sec, using 39 epochs

Median number of epochs used: 57 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/57], Loss: 0.6647
	--> Final training Epoch [2/57], Loss: 0.7013
	--> Final training Epoch [3/57], Loss: 0.6527
	--> Final training Epoch [4/57], Loss: 0.6170
	--> Final training Epoch [5/57], Loss: 0.6023
	--> Final training Epoch [6/57], Loss: 0.5108
	--> Final training Epoch [7/57], Loss: 0.4905
	--> Final training Epoch [8/57], Loss: 0.5822
	--> Final training Epoch [9/57], Loss: 0.4277
	--> Final training Epoch [10/57], Loss: 0.4474
	--> Final training Epoch [11/57], Loss: 0.3147
	--> Final training Epoch [12/57], Loss: 0.4235
	--> Final training Epoch [13/57], Loss: 0.4548
	--> Final training Epoch [14/57], Loss: 0.3702
	--> Final training Epoch [15/57], Loss: 0.3046
	--> Final training Epoch [16/57], Loss: 0.3418
	--> Final training Epoch [17/57], Loss: 0.3139
	--> Final training Epoch [18/57], Loss: 0.2444
	--> Final training Epoch [19/57], Loss: 0.3249
	--> Final training Epoch [20/57], Loss: 0.3345
	--> Final training Epoch [21/57], Loss: 0.1818
	--> Final training Epoch [22/57], Loss: 0.3758
	--> Final training Epoch [23/57], Loss: 0.1667
	--> Final training Epoch [24/57], Loss: 0.2773
	--> Final training Epoch [25/57], Loss: 0.2447
	--> Final training Epoch [26/57], Loss: 0.1287
	--> Final training Epoch [27/57], Loss: 0.2259
	--> Final training Epoch [28/57], Loss: 0.3529
	--> Final training Epoch [29/57], Loss: 0.2572
	--> Final training Epoch [30/57], Loss: 0.2564
	--> Final training Epoch [31/57], Loss: 0.1620
	--> Final training Epoch [32/57], Loss: 0.2562
	--> Final training Epoch [33/57], Loss: 0.1408
	--> Final training Epoch [34/57], Loss: 0.1312
	--> Final training Epoch [35/57], Loss: 0.1576
	--> Final training Epoch [36/57], Loss: 0.1940
	--> Final training Epoch [37/57], Loss: 0.1964
	--> Final training Epoch [38/57], Loss: 0.2161
	--> Final training Epoch [39/57], Loss: 0.0500
	--> Final training Epoch [40/57], Loss: 0.1881
	--> Final training Epoch [41/57], Loss: 0.1353
	--> Final training Epoch [42/57], Loss: 0.1095
	--> Final training Epoch [43/57], Loss: 0.1463
	--> Final training Epoch [44/57], Loss: 0.1855
	--> Final training Epoch [45/57], Loss: 0.0960
	--> Final training Epoch [46/57], Loss: 0.0652
	--> Final training Epoch [47/57], Loss: 0.1612
	--> Final training Epoch [48/57], Loss: 0.1248
	--> Final training Epoch [49/57], Loss: 0.1160
	--> Final training Epoch [50/57], Loss: 0.2033
	--> Final training Epoch [51/57], Loss: 0.1461
	--> Final training Epoch [52/57], Loss: 0.0952
	--> Final training Epoch [53/57], Loss: 0.0398
	--> Final training Epoch [54/57], Loss: 0.1031
	--> Final training Epoch [55/57], Loss: 0.1930
	--> Final training Epoch [56/57], Loss: 0.1120
	--> Final training Epoch [57/57], Loss: 0.1174

Final training took 1.0843794345855713 sec

TESTING
	--> Testing took 0.0156 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9089
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3481,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3481

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6810, Validation Loss: 0.6482
	--> Epoch [2/100], Loss: 0.6667, Validation Loss: 0.6220
	--> Epoch [3/100], Loss: 0.5976, Validation Loss: 0.5981
	--> Epoch [4/100], Loss: 0.5352, Validation Loss: 0.5737
	--> Epoch [5/100], Loss: 0.5287, Validation Loss: 0.5527
	--> Epoch [6/100], Loss: 0.5294, Validation Loss: 0.5368
	--> Epoch [7/100], Loss: 0.4315, Validation Loss: 0.5203
	--> Epoch [8/100], Loss: 0.4361, Validation Loss: 0.5050
	--> Epoch [9/100], Loss: 0.4220, Validation Loss: 0.4896
	--> Epoch [10/100], Loss: 0.4078, Validation Loss: 0.4728
	--> Epoch [11/100], Loss: 0.4233, Validation Loss: 0.4605
	--> Epoch [12/100], Loss: 0.3850, Validation Loss: 0.4476
	--> Epoch [13/100], Loss: 0.4164, Validation Loss: 0.4327
	--> Epoch [14/100], Loss: 0.3864, Validation Loss: 0.4197
	--> Epoch [15/100], Loss: 0.2458, Validation Loss: 0.4103
	--> Epoch [16/100], Loss: 0.3236, Validation Loss: 0.4026
	--> Epoch [17/100], Loss: 0.3317, Validation Loss: 0.3956
	--> Epoch [18/100], Loss: 0.3065, Validation Loss: 0.3881
	--> Epoch [19/100], Loss: 0.3244, Validation Loss: 0.3811
	--> Epoch [20/100], Loss: 0.3843, Validation Loss: 0.3735
	--> Epoch [21/100], Loss: 0.2508, Validation Loss: 0.3658
	--> Epoch [22/100], Loss: 0.1825, Validation Loss: 0.3598
	--> Epoch [23/100], Loss: 0.2429, Validation Loss: 0.3555
	--> Epoch [24/100], Loss: 0.2013, Validation Loss: 0.3521
	--> Epoch [25/100], Loss: 0.3667, Validation Loss: 0.3457
	--> Epoch [26/100], Loss: 0.1570, Validation Loss: 0.3423
	--> Epoch [27/100], Loss: 0.1419, Validation Loss: 0.3402
	--> Epoch [28/100], Loss: 0.2296, Validation Loss: 0.3379
	--> Epoch [29/100], Loss: 0.2189, Validation Loss: 0.3328
	--> Epoch [30/100], Loss: 0.1037, Validation Loss: 0.3312
	--> Epoch [31/100], Loss: 0.1252, Validation Loss: 0.3265
	--> Epoch [32/100], Loss: 0.1188, Validation Loss: 0.3255
	--> Epoch [33/100], Loss: 0.1347, Validation Loss: 0.3245
	--> Epoch [34/100], Loss: 0.2267, Validation Loss: 0.3212
	--> Epoch [35/100], Loss: 0.1706, Validation Loss: 0.3205
	--> Epoch [36/100], Loss: 0.1532, Validation Loss: 0.3192
	--> Epoch [37/100], Loss: 0.1586, Validation Loss: 0.3179
	--> Epoch [38/100], Loss: 0.0845, Validation Loss: 0.3136
	--> Epoch [39/100], Loss: 0.1930, Validation Loss: 0.3111
	--> Epoch [40/100], Loss: 0.0929, Validation Loss: 0.3110
	--> Epoch [41/100], Loss: 0.2312, Validation Loss: 0.3106
	--> Epoch [42/100], Loss: 0.1757, Validation Loss: 0.3112
	--> Epoch [43/100], Loss: 0.2600, Validation Loss: 0.3099
	--> Epoch [44/100], Loss: 0.1094, Validation Loss: 0.3064
	--> Epoch [45/100], Loss: 0.2149, Validation Loss: 0.3059
	--> Epoch [46/100], Loss: 0.1425, Validation Loss: 0.3068
	--> Epoch [47/100], Loss: 0.1428, Validation Loss: 0.3071
	--> Epoch [48/100], Loss: 0.2176, Validation Loss: 0.3045
	--> Epoch [49/100], Loss: 0.2241, Validation Loss: 0.3068
	--> Epoch [50/100], Loss: 0.0989, Validation Loss: 0.3075
	--> Epoch [51/100], Loss: 0.1202, Validation Loss: 0.3049
Early stopping
	--> Training for Fold 1 took 0.8176510334014893 sec, using 51 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5407, Validation Loss: 0.7763
	--> Epoch [2/100], Loss: 0.5219, Validation Loss: 0.7219
	--> Epoch [3/100], Loss: 0.4499, Validation Loss: 0.6783
	--> Epoch [4/100], Loss: 0.4586, Validation Loss: 0.6506
	--> Epoch [5/100], Loss: 0.4552, Validation Loss: 0.6196
	--> Epoch [6/100], Loss: 0.4799, Validation Loss: 0.5920
	--> Epoch [7/100], Loss: 0.4041, Validation Loss: 0.5688
	--> Epoch [8/100], Loss: 0.3848, Validation Loss: 0.5471
	--> Epoch [9/100], Loss: 0.3361, Validation Loss: 0.5230
	--> Epoch [10/100], Loss: 0.3293, Validation Loss: 0.5049
	--> Epoch [11/100], Loss: 0.3802, Validation Loss: 0.4883
	--> Epoch [12/100], Loss: 0.2590, Validation Loss: 0.4697
	--> Epoch [13/100], Loss: 0.2922, Validation Loss: 0.4541
	--> Epoch [14/100], Loss: 0.3266, Validation Loss: 0.4402
	--> Epoch [15/100], Loss: 0.2373, Validation Loss: 0.4261
	--> Epoch [16/100], Loss: 0.2535, Validation Loss: 0.4115
	--> Epoch [17/100], Loss: 0.2081, Validation Loss: 0.4005
	--> Epoch [18/100], Loss: 0.2259, Validation Loss: 0.3914
	--> Epoch [19/100], Loss: 0.2342, Validation Loss: 0.3827
	--> Epoch [20/100], Loss: 0.1500, Validation Loss: 0.3733
	--> Epoch [21/100], Loss: 0.3969, Validation Loss: 0.3616
	--> Epoch [22/100], Loss: 0.1129, Validation Loss: 0.3540
	--> Epoch [23/100], Loss: 0.1050, Validation Loss: 0.3484
	--> Epoch [24/100], Loss: 0.2135, Validation Loss: 0.3409
	--> Epoch [25/100], Loss: 0.1444, Validation Loss: 0.3354
	--> Epoch [26/100], Loss: 0.1143, Validation Loss: 0.3303
	--> Epoch [27/100], Loss: 0.3314, Validation Loss: 0.3234
	--> Epoch [28/100], Loss: 0.1782, Validation Loss: 0.3147
	--> Epoch [29/100], Loss: 0.1501, Validation Loss: 0.3121
	--> Epoch [30/100], Loss: 0.1333, Validation Loss: 0.3077
	--> Epoch [31/100], Loss: 0.2548, Validation Loss: 0.3029
	--> Epoch [32/100], Loss: 0.1319, Validation Loss: 0.2992
	--> Epoch [33/100], Loss: 0.0841, Validation Loss: 0.2968
	--> Epoch [34/100], Loss: 0.1968, Validation Loss: 0.2951
	--> Epoch [35/100], Loss: 0.0674, Validation Loss: 0.2932
	--> Epoch [36/100], Loss: 0.0369, Validation Loss: 0.2872
	--> Epoch [37/100], Loss: 0.1306, Validation Loss: 0.2840
	--> Epoch [38/100], Loss: 0.1716, Validation Loss: 0.2813
	--> Epoch [39/100], Loss: 0.1615, Validation Loss: 0.2788
	--> Epoch [40/100], Loss: 0.1599, Validation Loss: 0.2778
	--> Epoch [41/100], Loss: 0.0967, Validation Loss: 0.2744
	--> Epoch [42/100], Loss: 0.0499, Validation Loss: 0.2718
	--> Epoch [43/100], Loss: 0.1982, Validation Loss: 0.2648
	--> Epoch [44/100], Loss: 0.1729, Validation Loss: 0.2620
	--> Epoch [45/100], Loss: 0.1504, Validation Loss: 0.2600
	--> Epoch [46/100], Loss: 0.1799, Validation Loss: 0.2572
	--> Epoch [47/100], Loss: 0.2419, Validation Loss: 0.2571
	--> Epoch [48/100], Loss: 0.0368, Validation Loss: 0.2560
	--> Epoch [49/100], Loss: 0.2040, Validation Loss: 0.2546
	--> Epoch [50/100], Loss: 0.1199, Validation Loss: 0.2547
	--> Epoch [51/100], Loss: 0.0161, Validation Loss: 0.2517
	--> Epoch [52/100], Loss: 0.0342, Validation Loss: 0.2554
	--> Epoch [53/100], Loss: 0.0120, Validation Loss: 0.2546
	--> Epoch [54/100], Loss: 0.1196, Validation Loss: 0.2521
Early stopping
	--> Training for Fold 2 took 0.9267351627349854 sec, using 54 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6771, Validation Loss: 0.7326
	--> Epoch [2/100], Loss: 0.6383, Validation Loss: 0.7077
	--> Epoch [3/100], Loss: 0.5408, Validation Loss: 0.6906
	--> Epoch [4/100], Loss: 0.6006, Validation Loss: 0.6735
	--> Epoch [5/100], Loss: 0.5687, Validation Loss: 0.6624
	--> Epoch [6/100], Loss: 0.4895, Validation Loss: 0.6449
	--> Epoch [7/100], Loss: 0.5389, Validation Loss: 0.6295
	--> Epoch [8/100], Loss: 0.3808, Validation Loss: 0.6090
	--> Epoch [9/100], Loss: 0.4614, Validation Loss: 0.5970
	--> Epoch [10/100], Loss: 0.4393, Validation Loss: 0.5832
	--> Epoch [11/100], Loss: 0.3845, Validation Loss: 0.5676
	--> Epoch [12/100], Loss: 0.3477, Validation Loss: 0.5545
	--> Epoch [13/100], Loss: 0.4076, Validation Loss: 0.5430
	--> Epoch [14/100], Loss: 0.4246, Validation Loss: 0.5395
	--> Epoch [15/100], Loss: 0.2834, Validation Loss: 0.5289
	--> Epoch [16/100], Loss: 0.3522, Validation Loss: 0.5210
	--> Epoch [17/100], Loss: 0.2986, Validation Loss: 0.5147
	--> Epoch [18/100], Loss: 0.3283, Validation Loss: 0.5009
	--> Epoch [19/100], Loss: 0.2039, Validation Loss: 0.4932
	--> Epoch [20/100], Loss: 0.2329, Validation Loss: 0.4926
	--> Epoch [21/100], Loss: 0.4081, Validation Loss: 0.4849
	--> Epoch [22/100], Loss: 0.2547, Validation Loss: 0.4775
	--> Epoch [23/100], Loss: 0.2678, Validation Loss: 0.4683
	--> Epoch [24/100], Loss: 0.2235, Validation Loss: 0.4610
	--> Epoch [25/100], Loss: 0.2936, Validation Loss: 0.4539
	--> Epoch [26/100], Loss: 0.1880, Validation Loss: 0.4482
	--> Epoch [27/100], Loss: 0.2329, Validation Loss: 0.4443
	--> Epoch [28/100], Loss: 0.2275, Validation Loss: 0.4375
	--> Epoch [29/100], Loss: 0.1703, Validation Loss: 0.4343
	--> Epoch [30/100], Loss: 0.1717, Validation Loss: 0.4327
	--> Epoch [31/100], Loss: 0.1974, Validation Loss: 0.4273
	--> Epoch [32/100], Loss: 0.3403, Validation Loss: 0.4226
	--> Epoch [33/100], Loss: 0.1537, Validation Loss: 0.4183
	--> Epoch [34/100], Loss: 0.1616, Validation Loss: 0.4140
	--> Epoch [35/100], Loss: 0.2588, Validation Loss: 0.4053
	--> Epoch [36/100], Loss: 0.1269, Validation Loss: 0.4008
	--> Epoch [37/100], Loss: 0.0802, Validation Loss: 0.3960
	--> Epoch [38/100], Loss: 0.1597, Validation Loss: 0.3951
	--> Epoch [39/100], Loss: 0.1208, Validation Loss: 0.3915
	--> Epoch [40/100], Loss: 0.2906, Validation Loss: 0.3891
	--> Epoch [41/100], Loss: 0.2155, Validation Loss: 0.3888
	--> Epoch [42/100], Loss: 0.2517, Validation Loss: 0.3857
	--> Epoch [43/100], Loss: 0.1635, Validation Loss: 0.3836
	--> Epoch [44/100], Loss: 0.1382, Validation Loss: 0.3768
	--> Epoch [45/100], Loss: 0.1844, Validation Loss: 0.3732
	--> Epoch [46/100], Loss: 0.1671, Validation Loss: 0.3717
	--> Epoch [47/100], Loss: 0.0367, Validation Loss: 0.3713
	--> Epoch [48/100], Loss: 0.1238, Validation Loss: 0.3702
	--> Epoch [49/100], Loss: 0.0754, Validation Loss: 0.3683
	--> Epoch [50/100], Loss: 0.0635, Validation Loss: 0.3670
	--> Epoch [51/100], Loss: 0.0798, Validation Loss: 0.3648
	--> Epoch [52/100], Loss: 0.1759, Validation Loss: 0.3636
	--> Epoch [53/100], Loss: 0.1193, Validation Loss: 0.3604
	--> Epoch [54/100], Loss: 0.2652, Validation Loss: 0.3604
	--> Epoch [55/100], Loss: 0.0766, Validation Loss: 0.3609
	--> Epoch [56/100], Loss: 0.1268, Validation Loss: 0.3538
	--> Epoch [57/100], Loss: 0.1746, Validation Loss: 0.3554
	--> Epoch [58/100], Loss: 0.0698, Validation Loss: 0.3559
	--> Epoch [59/100], Loss: 0.2205, Validation Loss: 0.3541
Early stopping
	--> Training for Fold 3 took 1.1177177429199219 sec, using 59 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6633, Validation Loss: 0.7019
	--> Epoch [2/100], Loss: 0.7170, Validation Loss: 0.6736
	--> Epoch [3/100], Loss: 0.5931, Validation Loss: 0.6447
	--> Epoch [4/100], Loss: 0.4225, Validation Loss: 0.6257
	--> Epoch [5/100], Loss: 0.5174, Validation Loss: 0.6006
	--> Epoch [6/100], Loss: 0.3714, Validation Loss: 0.5754
	--> Epoch [7/100], Loss: 0.3385, Validation Loss: 0.5513
	--> Epoch [8/100], Loss: 0.4949, Validation Loss: 0.5337
	--> Epoch [9/100], Loss: 0.4205, Validation Loss: 0.5128
	--> Epoch [10/100], Loss: 0.3456, Validation Loss: 0.4998
	--> Epoch [11/100], Loss: 0.2920, Validation Loss: 0.4805
	--> Epoch [12/100], Loss: 0.2208, Validation Loss: 0.4532
	--> Epoch [13/100], Loss: 0.2793, Validation Loss: 0.4351
	--> Epoch [14/100], Loss: 0.3171, Validation Loss: 0.4279
	--> Epoch [15/100], Loss: 0.3972, Validation Loss: 0.4206
	--> Epoch [16/100], Loss: 0.2840, Validation Loss: 0.4125
	--> Epoch [17/100], Loss: 0.2696, Validation Loss: 0.4044
	--> Epoch [18/100], Loss: 0.2746, Validation Loss: 0.3880
	--> Epoch [19/100], Loss: 0.2469, Validation Loss: 0.3809
	--> Epoch [20/100], Loss: 0.1836, Validation Loss: 0.3630
	--> Epoch [21/100], Loss: 0.2712, Validation Loss: 0.3525
	--> Epoch [22/100], Loss: 0.2864, Validation Loss: 0.3517
	--> Epoch [23/100], Loss: 0.2457, Validation Loss: 0.3380
	--> Epoch [24/100], Loss: 0.2520, Validation Loss: 0.3308
	--> Epoch [25/100], Loss: 0.2397, Validation Loss: 0.3237
	--> Epoch [26/100], Loss: 0.2065, Validation Loss: 0.3243
	--> Epoch [27/100], Loss: 0.1695, Validation Loss: 0.3225
	--> Epoch [28/100], Loss: 0.2246, Validation Loss: 0.3157
	--> Epoch [29/100], Loss: 0.1804, Validation Loss: 0.3082
	--> Epoch [30/100], Loss: 0.2217, Validation Loss: 0.3105
	--> Epoch [31/100], Loss: 0.1754, Validation Loss: 0.3113
	--> Epoch [32/100], Loss: 0.2238, Validation Loss: 0.3127
Early stopping
	--> Training for Fold 4 took 0.5453431606292725 sec, using 32 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6112, Validation Loss: 0.7732
	--> Epoch [2/100], Loss: 0.5058, Validation Loss: 0.7569
	--> Epoch [3/100], Loss: 0.5464, Validation Loss: 0.7352
	--> Epoch [4/100], Loss: 0.4154, Validation Loss: 0.7269
	--> Epoch [5/100], Loss: 0.4868, Validation Loss: 0.7223
	--> Epoch [6/100], Loss: 0.3940, Validation Loss: 0.7130
	--> Epoch [7/100], Loss: 0.4112, Validation Loss: 0.7104
	--> Epoch [8/100], Loss: 0.3544, Validation Loss: 0.7061
	--> Epoch [9/100], Loss: 0.3523, Validation Loss: 0.7001
	--> Epoch [10/100], Loss: 0.2804, Validation Loss: 0.6889
	--> Epoch [11/100], Loss: 0.4125, Validation Loss: 0.6777
	--> Epoch [12/100], Loss: 0.2323, Validation Loss: 0.6746
	--> Epoch [13/100], Loss: 0.2332, Validation Loss: 0.6693
	--> Epoch [14/100], Loss: 0.2926, Validation Loss: 0.6575
	--> Epoch [15/100], Loss: 0.2004, Validation Loss: 0.6503
	--> Epoch [16/100], Loss: 0.2203, Validation Loss: 0.6394
	--> Epoch [17/100], Loss: 0.2828, Validation Loss: 0.6307
	--> Epoch [18/100], Loss: 0.2978, Validation Loss: 0.6265
	--> Epoch [19/100], Loss: 0.2276, Validation Loss: 0.6229
	--> Epoch [20/100], Loss: 0.1829, Validation Loss: 0.6152
	--> Epoch [21/100], Loss: 0.2702, Validation Loss: 0.6082
	--> Epoch [22/100], Loss: 0.1546, Validation Loss: 0.6048
	--> Epoch [23/100], Loss: 0.2572, Validation Loss: 0.5992
	--> Epoch [24/100], Loss: 0.1464, Validation Loss: 0.5978
	--> Epoch [25/100], Loss: 0.2273, Validation Loss: 0.5943
	--> Epoch [26/100], Loss: 0.1648, Validation Loss: 0.5970
	--> Epoch [27/100], Loss: 0.2060, Validation Loss: 0.5867
	--> Epoch [28/100], Loss: 0.1983, Validation Loss: 0.5819
	--> Epoch [29/100], Loss: 0.2267, Validation Loss: 0.5770
	--> Epoch [30/100], Loss: 0.1275, Validation Loss: 0.5691
	--> Epoch [31/100], Loss: 0.1395, Validation Loss: 0.5685
	--> Epoch [32/100], Loss: 0.2112, Validation Loss: 0.5635
	--> Epoch [33/100], Loss: 0.0999, Validation Loss: 0.5595
	--> Epoch [34/100], Loss: 0.1180, Validation Loss: 0.5607
	--> Epoch [35/100], Loss: 0.0980, Validation Loss: 0.5620
	--> Epoch [36/100], Loss: 0.1658, Validation Loss: 0.5597
Early stopping
	--> Training for Fold 5 took 0.6573383808135986 sec, using 36 epochs

Median number of epochs used: 51 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/51], Loss: 0.8242
	--> Final training Epoch [2/51], Loss: 0.7738
	--> Final training Epoch [3/51], Loss: 0.7449
	--> Final training Epoch [4/51], Loss: 0.7276
	--> Final training Epoch [5/51], Loss: 0.7138
	--> Final training Epoch [6/51], Loss: 0.6775
	--> Final training Epoch [7/51], Loss: 0.7117
	--> Final training Epoch [8/51], Loss: 0.5845
	--> Final training Epoch [9/51], Loss: 0.7057
	--> Final training Epoch [10/51], Loss: 0.6358
	--> Final training Epoch [11/51], Loss: 0.6066
	--> Final training Epoch [12/51], Loss: 0.5560
	--> Final training Epoch [13/51], Loss: 0.5348
	--> Final training Epoch [14/51], Loss: 0.5824
	--> Final training Epoch [15/51], Loss: 0.4637
	--> Final training Epoch [16/51], Loss: 0.4593
	--> Final training Epoch [17/51], Loss: 0.5161
	--> Final training Epoch [18/51], Loss: 0.4244
	--> Final training Epoch [19/51], Loss: 0.4251
	--> Final training Epoch [20/51], Loss: 0.4075
	--> Final training Epoch [21/51], Loss: 0.3944
	--> Final training Epoch [22/51], Loss: 0.4184
	--> Final training Epoch [23/51], Loss: 0.4957
	--> Final training Epoch [24/51], Loss: 0.4212
	--> Final training Epoch [25/51], Loss: 0.3212
	--> Final training Epoch [26/51], Loss: 0.4420
	--> Final training Epoch [27/51], Loss: 0.3591
	--> Final training Epoch [28/51], Loss: 0.4665
	--> Final training Epoch [29/51], Loss: 0.4861
	--> Final training Epoch [30/51], Loss: 0.5019
	--> Final training Epoch [31/51], Loss: 0.2731
	--> Final training Epoch [32/51], Loss: 0.3171
	--> Final training Epoch [33/51], Loss: 0.2896
	--> Final training Epoch [34/51], Loss: 0.3648
	--> Final training Epoch [35/51], Loss: 0.2707
	--> Final training Epoch [36/51], Loss: 0.3250
	--> Final training Epoch [37/51], Loss: 0.3139
	--> Final training Epoch [38/51], Loss: 0.4000
	--> Final training Epoch [39/51], Loss: 0.2557
	--> Final training Epoch [40/51], Loss: 0.2973
	--> Final training Epoch [41/51], Loss: 0.3296
	--> Final training Epoch [42/51], Loss: 0.3985
	--> Final training Epoch [43/51], Loss: 0.3275
	--> Final training Epoch [44/51], Loss: 0.4414
	--> Final training Epoch [45/51], Loss: 0.3946
	--> Final training Epoch [46/51], Loss: 0.2415
	--> Final training Epoch [47/51], Loss: 0.2262
	--> Final training Epoch [48/51], Loss: 0.3215
	--> Final training Epoch [49/51], Loss: 0.2330
	--> Final training Epoch [50/51], Loss: 0.4160
	--> Final training Epoch [51/51], Loss: 0.2172

Final training took 1.1929638385772705 sec

TESTING
	--> Testing took 0.0168 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.8893
	--> Final Precision: 0.7143
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7407
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3333,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3333
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8064, Validation Loss: 0.3909,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3333

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6485, Validation Loss: 0.6305
	--> Epoch [2/100], Loss: 0.6707, Validation Loss: 0.6118
	--> Epoch [3/100], Loss: 0.5353, Validation Loss: 0.5943
	--> Epoch [4/100], Loss: 0.4373, Validation Loss: 0.5781
	--> Epoch [5/100], Loss: 0.4192, Validation Loss: 0.5579
	--> Epoch [6/100], Loss: 0.4563, Validation Loss: 0.5371
	--> Epoch [7/100], Loss: 0.4487, Validation Loss: 0.5225
	--> Epoch [8/100], Loss: 0.4661, Validation Loss: 0.5127
	--> Epoch [9/100], Loss: 0.3696, Validation Loss: 0.5021
	--> Epoch [10/100], Loss: 0.5701, Validation Loss: 0.4869
	--> Epoch [11/100], Loss: 0.5049, Validation Loss: 0.4738
	--> Epoch [12/100], Loss: 0.4242, Validation Loss: 0.4590
	--> Epoch [13/100], Loss: 0.4763, Validation Loss: 0.4485
	--> Epoch [14/100], Loss: 0.3441, Validation Loss: 0.4432
	--> Epoch [15/100], Loss: 0.3956, Validation Loss: 0.4386
	--> Epoch [16/100], Loss: 0.2165, Validation Loss: 0.4331
	--> Epoch [17/100], Loss: 0.3299, Validation Loss: 0.4324
	--> Epoch [18/100], Loss: 0.3475, Validation Loss: 0.4251
	--> Epoch [19/100], Loss: 0.3675, Validation Loss: 0.4161
	--> Epoch [20/100], Loss: 0.4399, Validation Loss: 0.4125
	--> Epoch [21/100], Loss: 0.2531, Validation Loss: 0.4042
	--> Epoch [22/100], Loss: 0.2717, Validation Loss: 0.4007
	--> Epoch [23/100], Loss: 0.3658, Validation Loss: 0.3959
	--> Epoch [24/100], Loss: 0.2428, Validation Loss: 0.3913
	--> Epoch [25/100], Loss: 0.2124, Validation Loss: 0.3870
	--> Epoch [26/100], Loss: 0.2405, Validation Loss: 0.3811
	--> Epoch [27/100], Loss: 0.2624, Validation Loss: 0.3767
	--> Epoch [28/100], Loss: 0.3202, Validation Loss: 0.3697
	--> Epoch [29/100], Loss: 0.4460, Validation Loss: 0.3617
	--> Epoch [30/100], Loss: 0.3447, Validation Loss: 0.3617
	--> Epoch [31/100], Loss: 0.3374, Validation Loss: 0.3563
	--> Epoch [32/100], Loss: 0.2074, Validation Loss: 0.3502
	--> Epoch [33/100], Loss: 0.1695, Validation Loss: 0.3473
	--> Epoch [34/100], Loss: 0.2318, Validation Loss: 0.3454
	--> Epoch [35/100], Loss: 0.3530, Validation Loss: 0.3435
	--> Epoch [36/100], Loss: 0.3542, Validation Loss: 0.3366
	--> Epoch [37/100], Loss: 0.1722, Validation Loss: 0.3300
	--> Epoch [38/100], Loss: 0.3537, Validation Loss: 0.3269
	--> Epoch [39/100], Loss: 0.3261, Validation Loss: 0.3274
	--> Epoch [40/100], Loss: 0.3768, Validation Loss: 0.3206
	--> Epoch [41/100], Loss: 0.2915, Validation Loss: 0.3144
	--> Epoch [42/100], Loss: 0.2417, Validation Loss: 0.3106
	--> Epoch [43/100], Loss: 0.3541, Validation Loss: 0.3094
	--> Epoch [44/100], Loss: 0.1943, Validation Loss: 0.3050
	--> Epoch [45/100], Loss: 0.2657, Validation Loss: 0.3024
	--> Epoch [46/100], Loss: 0.2708, Validation Loss: 0.3000
	--> Epoch [47/100], Loss: 0.1392, Validation Loss: 0.2984
	--> Epoch [48/100], Loss: 0.4187, Validation Loss: 0.2969
	--> Epoch [49/100], Loss: 0.2664, Validation Loss: 0.2908
	--> Epoch [50/100], Loss: 0.2182, Validation Loss: 0.2894
	--> Epoch [51/100], Loss: 0.0806, Validation Loss: 0.2858
	--> Epoch [52/100], Loss: 0.3482, Validation Loss: 0.2835
	--> Epoch [53/100], Loss: 0.2590, Validation Loss: 0.2832
	--> Epoch [54/100], Loss: 0.4038, Validation Loss: 0.2836
	--> Epoch [55/100], Loss: 0.1684, Validation Loss: 0.2862
	--> Epoch [56/100], Loss: 0.1415, Validation Loss: 0.2825
	--> Epoch [57/100], Loss: 0.2610, Validation Loss: 0.2790
	--> Epoch [58/100], Loss: 0.1364, Validation Loss: 0.2808
	--> Epoch [59/100], Loss: 0.2750, Validation Loss: 0.2826
	--> Epoch [60/100], Loss: 0.3536, Validation Loss: 0.2777
	--> Epoch [61/100], Loss: 0.1591, Validation Loss: 0.2770
	--> Epoch [62/100], Loss: 0.3176, Validation Loss: 0.2772
	--> Epoch [63/100], Loss: 0.2936, Validation Loss: 0.2762
	--> Epoch [64/100], Loss: 0.1764, Validation Loss: 0.2742
	--> Epoch [65/100], Loss: 0.2653, Validation Loss: 0.2704
	--> Epoch [66/100], Loss: 0.2370, Validation Loss: 0.2707
	--> Epoch [67/100], Loss: 0.1279, Validation Loss: 0.2656
	--> Epoch [68/100], Loss: 0.1273, Validation Loss: 0.2635
	--> Epoch [69/100], Loss: 0.3150, Validation Loss: 0.2633
	--> Epoch [70/100], Loss: 0.2396, Validation Loss: 0.2554
	--> Epoch [71/100], Loss: 0.1867, Validation Loss: 0.2536
	--> Epoch [72/100], Loss: 0.1208, Validation Loss: 0.2528
	--> Epoch [73/100], Loss: 0.2013, Validation Loss: 0.2533
	--> Epoch [74/100], Loss: 0.2080, Validation Loss: 0.2550
	--> Epoch [75/100], Loss: 0.2985, Validation Loss: 0.2544
Early stopping
	--> Training for Fold 1 took 1.3013107776641846 sec, using 75 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6045, Validation Loss: 0.7181
	--> Epoch [2/100], Loss: 0.7047, Validation Loss: 0.6846
	--> Epoch [3/100], Loss: 0.6792, Validation Loss: 0.6536
	--> Epoch [4/100], Loss: 0.5727, Validation Loss: 0.6227
	--> Epoch [5/100], Loss: 0.5041, Validation Loss: 0.5975
	--> Epoch [6/100], Loss: 0.5489, Validation Loss: 0.5768
	--> Epoch [7/100], Loss: 0.4843, Validation Loss: 0.5640
	--> Epoch [8/100], Loss: 0.4829, Validation Loss: 0.5401
	--> Epoch [9/100], Loss: 0.4623, Validation Loss: 0.5287
	--> Epoch [10/100], Loss: 0.5900, Validation Loss: 0.5088
	--> Epoch [11/100], Loss: 0.4820, Validation Loss: 0.4945
	--> Epoch [12/100], Loss: 0.4196, Validation Loss: 0.4774
	--> Epoch [13/100], Loss: 0.4157, Validation Loss: 0.4621
	--> Epoch [14/100], Loss: 0.4508, Validation Loss: 0.4523
	--> Epoch [15/100], Loss: 0.2218, Validation Loss: 0.4356
	--> Epoch [16/100], Loss: 0.3137, Validation Loss: 0.4204
	--> Epoch [17/100], Loss: 0.2835, Validation Loss: 0.4083
	--> Epoch [18/100], Loss: 0.4093, Validation Loss: 0.3982
	--> Epoch [19/100], Loss: 0.3080, Validation Loss: 0.3864
	--> Epoch [20/100], Loss: 0.3476, Validation Loss: 0.3779
	--> Epoch [21/100], Loss: 0.2748, Validation Loss: 0.3756
	--> Epoch [22/100], Loss: 0.3222, Validation Loss: 0.3697
	--> Epoch [23/100], Loss: 0.3298, Validation Loss: 0.3586
	--> Epoch [24/100], Loss: 0.4267, Validation Loss: 0.3580
	--> Epoch [25/100], Loss: 0.2114, Validation Loss: 0.3525
	--> Epoch [26/100], Loss: 0.3411, Validation Loss: 0.3462
	--> Epoch [27/100], Loss: 0.2796, Validation Loss: 0.3379
	--> Epoch [28/100], Loss: 0.4363, Validation Loss: 0.3334
	--> Epoch [29/100], Loss: 0.2694, Validation Loss: 0.3300
	--> Epoch [30/100], Loss: 0.3813, Validation Loss: 0.3191
	--> Epoch [31/100], Loss: 0.2970, Validation Loss: 0.3199
	--> Epoch [32/100], Loss: 0.5374, Validation Loss: 0.3120
	--> Epoch [33/100], Loss: 0.1651, Validation Loss: 0.3092
	--> Epoch [34/100], Loss: 0.3070, Validation Loss: 0.3036
	--> Epoch [35/100], Loss: 0.4433, Validation Loss: 0.3022
	--> Epoch [36/100], Loss: 0.1777, Validation Loss: 0.3000
	--> Epoch [37/100], Loss: 0.2171, Validation Loss: 0.2956
	--> Epoch [38/100], Loss: 0.1757, Validation Loss: 0.2933
	--> Epoch [39/100], Loss: 0.1497, Validation Loss: 0.2920
	--> Epoch [40/100], Loss: 0.2211, Validation Loss: 0.2846
	--> Epoch [41/100], Loss: 0.0876, Validation Loss: 0.2823
	--> Epoch [42/100], Loss: 0.3129, Validation Loss: 0.2778
	--> Epoch [43/100], Loss: 0.2548, Validation Loss: 0.2773
	--> Epoch [44/100], Loss: 0.3462, Validation Loss: 0.2768
	--> Epoch [45/100], Loss: 0.2362, Validation Loss: 0.2757
	--> Epoch [46/100], Loss: 0.2773, Validation Loss: 0.2743
	--> Epoch [47/100], Loss: 0.2016, Validation Loss: 0.2706
	--> Epoch [48/100], Loss: 0.1811, Validation Loss: 0.2722
	--> Epoch [49/100], Loss: 0.2854, Validation Loss: 0.2706
	--> Epoch [50/100], Loss: 0.2502, Validation Loss: 0.2685
	--> Epoch [51/100], Loss: 0.1321, Validation Loss: 0.2653
	--> Epoch [52/100], Loss: 0.3209, Validation Loss: 0.2621
	--> Epoch [53/100], Loss: 0.1300, Validation Loss: 0.2624
	--> Epoch [54/100], Loss: 0.1506, Validation Loss: 0.2617
	--> Epoch [55/100], Loss: 0.2086, Validation Loss: 0.2587
	--> Epoch [56/100], Loss: 0.2734, Validation Loss: 0.2560
	--> Epoch [57/100], Loss: 0.3049, Validation Loss: 0.2506
	--> Epoch [58/100], Loss: 0.3015, Validation Loss: 0.2518
	--> Epoch [59/100], Loss: 0.2005, Validation Loss: 0.2544
	--> Epoch [60/100], Loss: 0.2730, Validation Loss: 0.2500
	--> Epoch [61/100], Loss: 0.1379, Validation Loss: 0.2499
	--> Epoch [62/100], Loss: 0.2549, Validation Loss: 0.2438
	--> Epoch [63/100], Loss: 0.2620, Validation Loss: 0.2323
	--> Epoch [64/100], Loss: 0.1886, Validation Loss: 0.2322
	--> Epoch [65/100], Loss: 0.1807, Validation Loss: 0.2311
	--> Epoch [66/100], Loss: 0.1806, Validation Loss: 0.2316
	--> Epoch [67/100], Loss: 0.2478, Validation Loss: 0.2286
	--> Epoch [68/100], Loss: 0.1802, Validation Loss: 0.2285
	--> Epoch [69/100], Loss: 0.2366, Validation Loss: 0.2266
	--> Epoch [70/100], Loss: 0.3183, Validation Loss: 0.2259
	--> Epoch [71/100], Loss: 0.1237, Validation Loss: 0.2263
	--> Epoch [72/100], Loss: 0.1818, Validation Loss: 0.2255
	--> Epoch [73/100], Loss: 0.2877, Validation Loss: 0.2253
	--> Epoch [74/100], Loss: 0.1869, Validation Loss: 0.2229
	--> Epoch [75/100], Loss: 0.0139, Validation Loss: 0.2216
	--> Epoch [76/100], Loss: 0.1879, Validation Loss: 0.2184
	--> Epoch [77/100], Loss: 0.0668, Validation Loss: 0.2193
	--> Epoch [78/100], Loss: 0.2925, Validation Loss: 0.2179
	--> Epoch [79/100], Loss: 0.2057, Validation Loss: 0.2174
	--> Epoch [80/100], Loss: 0.2294, Validation Loss: 0.2169
	--> Epoch [81/100], Loss: 0.1738, Validation Loss: 0.2173
	--> Epoch [82/100], Loss: 0.2369, Validation Loss: 0.2183
	--> Epoch [83/100], Loss: 0.2572, Validation Loss: 0.2179
Early stopping
	--> Training for Fold 2 took 1.6744706630706787 sec, using 83 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4908, Validation Loss: 0.7954
	--> Epoch [2/100], Loss: 0.4507, Validation Loss: 0.7720
	--> Epoch [3/100], Loss: 0.4981, Validation Loss: 0.7542
	--> Epoch [4/100], Loss: 0.4655, Validation Loss: 0.7290
	--> Epoch [5/100], Loss: 0.4263, Validation Loss: 0.7083
	--> Epoch [6/100], Loss: 0.3942, Validation Loss: 0.6827
	--> Epoch [7/100], Loss: 0.3290, Validation Loss: 0.6677
	--> Epoch [8/100], Loss: 0.4470, Validation Loss: 0.6480
	--> Epoch [9/100], Loss: 0.3478, Validation Loss: 0.6314
	--> Epoch [10/100], Loss: 0.4772, Validation Loss: 0.6193
	--> Epoch [11/100], Loss: 0.4099, Validation Loss: 0.6079
	--> Epoch [12/100], Loss: 0.3607, Validation Loss: 0.5928
	--> Epoch [13/100], Loss: 0.2732, Validation Loss: 0.5809
	--> Epoch [14/100], Loss: 0.4954, Validation Loss: 0.5714
	--> Epoch [15/100], Loss: 0.2541, Validation Loss: 0.5638
	--> Epoch [16/100], Loss: 0.4478, Validation Loss: 0.5561
	--> Epoch [17/100], Loss: 0.3763, Validation Loss: 0.5521
	--> Epoch [18/100], Loss: 0.2368, Validation Loss: 0.5455
	--> Epoch [19/100], Loss: 0.1749, Validation Loss: 0.5331
	--> Epoch [20/100], Loss: 0.2580, Validation Loss: 0.5164
	--> Epoch [21/100], Loss: 0.3331, Validation Loss: 0.4994
	--> Epoch [22/100], Loss: 0.2348, Validation Loss: 0.4928
	--> Epoch [23/100], Loss: 0.2406, Validation Loss: 0.4814
	--> Epoch [24/100], Loss: 0.2082, Validation Loss: 0.4744
	--> Epoch [25/100], Loss: 0.2015, Validation Loss: 0.4690
	--> Epoch [26/100], Loss: 0.2917, Validation Loss: 0.4623
	--> Epoch [27/100], Loss: 0.4143, Validation Loss: 0.4583
	--> Epoch [28/100], Loss: 0.2007, Validation Loss: 0.4572
	--> Epoch [29/100], Loss: 0.2277, Validation Loss: 0.4511
	--> Epoch [30/100], Loss: 0.3171, Validation Loss: 0.4488
	--> Epoch [31/100], Loss: 0.1120, Validation Loss: 0.4437
	--> Epoch [32/100], Loss: 0.3214, Validation Loss: 0.4405
	--> Epoch [33/100], Loss: 0.2564, Validation Loss: 0.4385
	--> Epoch [34/100], Loss: 0.1292, Validation Loss: 0.4354
	--> Epoch [35/100], Loss: 0.2907, Validation Loss: 0.4328
	--> Epoch [36/100], Loss: 0.2136, Validation Loss: 0.4320
	--> Epoch [37/100], Loss: 0.0829, Validation Loss: 0.4267
	--> Epoch [38/100], Loss: 0.3809, Validation Loss: 0.4220
	--> Epoch [39/100], Loss: 0.3417, Validation Loss: 0.4188
	--> Epoch [40/100], Loss: 0.2921, Validation Loss: 0.4133
	--> Epoch [41/100], Loss: 0.1909, Validation Loss: 0.4138
	--> Epoch [42/100], Loss: 0.2009, Validation Loss: 0.4131
	--> Epoch [43/100], Loss: 0.2756, Validation Loss: 0.4102
	--> Epoch [44/100], Loss: 0.3177, Validation Loss: 0.4055
	--> Epoch [45/100], Loss: 0.1726, Validation Loss: 0.4060
	--> Epoch [46/100], Loss: 0.2490, Validation Loss: 0.4043
	--> Epoch [47/100], Loss: 0.3190, Validation Loss: 0.4025
	--> Epoch [48/100], Loss: 0.1745, Validation Loss: 0.4020
	--> Epoch [49/100], Loss: 0.1670, Validation Loss: 0.3997
	--> Epoch [50/100], Loss: 0.0740, Validation Loss: 0.3967
	--> Epoch [51/100], Loss: 0.2560, Validation Loss: 0.3932
	--> Epoch [52/100], Loss: 0.3177, Validation Loss: 0.3928
	--> Epoch [53/100], Loss: 0.3503, Validation Loss: 0.3890
	--> Epoch [54/100], Loss: 0.1188, Validation Loss: 0.3901
	--> Epoch [55/100], Loss: 0.2626, Validation Loss: 0.3853
	--> Epoch [56/100], Loss: 0.1178, Validation Loss: 0.3848
	--> Epoch [57/100], Loss: 0.2080, Validation Loss: 0.3818
	--> Epoch [58/100], Loss: 0.2539, Validation Loss: 0.3809
	--> Epoch [59/100], Loss: 0.3385, Validation Loss: 0.3786
	--> Epoch [60/100], Loss: 0.1530, Validation Loss: 0.3743
	--> Epoch [61/100], Loss: 0.3387, Validation Loss: 0.3712
	--> Epoch [62/100], Loss: 0.2553, Validation Loss: 0.3670
	--> Epoch [63/100], Loss: 0.2615, Validation Loss: 0.3672
	--> Epoch [64/100], Loss: 0.3028, Validation Loss: 0.3660
	--> Epoch [65/100], Loss: 0.1212, Validation Loss: 0.3611
	--> Epoch [66/100], Loss: 0.3048, Validation Loss: 0.3584
	--> Epoch [67/100], Loss: 0.3505, Validation Loss: 0.3579
	--> Epoch [68/100], Loss: 0.3192, Validation Loss: 0.3574
	--> Epoch [69/100], Loss: 0.2000, Validation Loss: 0.3553
	--> Epoch [70/100], Loss: 0.3510, Validation Loss: 0.3515
	--> Epoch [71/100], Loss: 0.2167, Validation Loss: 0.3519
	--> Epoch [72/100], Loss: 0.2155, Validation Loss: 0.3516
	--> Epoch [73/100], Loss: 0.3473, Validation Loss: 0.3513
	--> Epoch [74/100], Loss: 0.2035, Validation Loss: 0.3518
	--> Epoch [75/100], Loss: 0.2055, Validation Loss: 0.3523
	--> Epoch [76/100], Loss: 0.2166, Validation Loss: 0.3518
Early stopping
	--> Training for Fold 3 took 1.419334888458252 sec, using 76 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7823, Validation Loss: 0.5492
	--> Epoch [2/100], Loss: 0.7475, Validation Loss: 0.5419
	--> Epoch [3/100], Loss: 0.8215, Validation Loss: 0.5319
	--> Epoch [4/100], Loss: 0.7289, Validation Loss: 0.5221
	--> Epoch [5/100], Loss: 0.8293, Validation Loss: 0.5166
	--> Epoch [6/100], Loss: 0.6357, Validation Loss: 0.5112
	--> Epoch [7/100], Loss: 0.6074, Validation Loss: 0.5035
	--> Epoch [8/100], Loss: 0.6548, Validation Loss: 0.4999
	--> Epoch [9/100], Loss: 0.6702, Validation Loss: 0.4916
	--> Epoch [10/100], Loss: 0.6583, Validation Loss: 0.4860
	--> Epoch [11/100], Loss: 0.6351, Validation Loss: 0.4727
	--> Epoch [12/100], Loss: 0.6565, Validation Loss: 0.4651
	--> Epoch [13/100], Loss: 0.5658, Validation Loss: 0.4557
	--> Epoch [14/100], Loss: 0.6856, Validation Loss: 0.4480
	--> Epoch [15/100], Loss: 0.5617, Validation Loss: 0.4374
	--> Epoch [16/100], Loss: 0.5868, Validation Loss: 0.4301
	--> Epoch [17/100], Loss: 0.5853, Validation Loss: 0.4236
	--> Epoch [18/100], Loss: 0.5858, Validation Loss: 0.4140
	--> Epoch [19/100], Loss: 0.5504, Validation Loss: 0.4078
	--> Epoch [20/100], Loss: 0.3833, Validation Loss: 0.3991
	--> Epoch [21/100], Loss: 0.5789, Validation Loss: 0.3949
	--> Epoch [22/100], Loss: 0.3900, Validation Loss: 0.3850
	--> Epoch [23/100], Loss: 0.4037, Validation Loss: 0.3794
	--> Epoch [24/100], Loss: 0.5091, Validation Loss: 0.3701
	--> Epoch [25/100], Loss: 0.3022, Validation Loss: 0.3677
	--> Epoch [26/100], Loss: 0.5653, Validation Loss: 0.3651
	--> Epoch [27/100], Loss: 0.5663, Validation Loss: 0.3626
	--> Epoch [28/100], Loss: 0.5346, Validation Loss: 0.3617
	--> Epoch [29/100], Loss: 0.4967, Validation Loss: 0.3553
	--> Epoch [30/100], Loss: 0.4388, Validation Loss: 0.3432
	--> Epoch [31/100], Loss: 0.3776, Validation Loss: 0.3361
	--> Epoch [32/100], Loss: 0.4465, Validation Loss: 0.3280
	--> Epoch [33/100], Loss: 0.4342, Validation Loss: 0.3229
	--> Epoch [34/100], Loss: 0.4273, Validation Loss: 0.3213
	--> Epoch [35/100], Loss: 0.3729, Validation Loss: 0.3191
	--> Epoch [36/100], Loss: 0.3734, Validation Loss: 0.3127
	--> Epoch [37/100], Loss: 0.3787, Validation Loss: 0.3113
	--> Epoch [38/100], Loss: 0.2897, Validation Loss: 0.3075
	--> Epoch [39/100], Loss: 0.5214, Validation Loss: 0.3031
	--> Epoch [40/100], Loss: 0.4269, Validation Loss: 0.2989
	--> Epoch [41/100], Loss: 0.4635, Validation Loss: 0.2982
	--> Epoch [42/100], Loss: 0.5069, Validation Loss: 0.2933
	--> Epoch [43/100], Loss: 0.3551, Validation Loss: 0.2892
	--> Epoch [44/100], Loss: 0.3870, Validation Loss: 0.2876
	--> Epoch [45/100], Loss: 0.4571, Validation Loss: 0.2838
	--> Epoch [46/100], Loss: 0.2234, Validation Loss: 0.2798
	--> Epoch [47/100], Loss: 0.3791, Validation Loss: 0.2778
	--> Epoch [48/100], Loss: 0.3828, Validation Loss: 0.2752
	--> Epoch [49/100], Loss: 0.3676, Validation Loss: 0.2785
	--> Epoch [50/100], Loss: 0.3256, Validation Loss: 0.2787
	--> Epoch [51/100], Loss: 0.3243, Validation Loss: 0.2777
Early stopping
	--> Training for Fold 4 took 0.9577007293701172 sec, using 51 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7986, Validation Loss: 0.6500
	--> Epoch [2/100], Loss: 0.6391, Validation Loss: 0.6417
	--> Epoch [3/100], Loss: 0.6522, Validation Loss: 0.6415
	--> Epoch [4/100], Loss: 0.6290, Validation Loss: 0.6342
	--> Epoch [5/100], Loss: 0.6536, Validation Loss: 0.6255
	--> Epoch [6/100], Loss: 0.5837, Validation Loss: 0.6236
	--> Epoch [7/100], Loss: 0.5424, Validation Loss: 0.6177
	--> Epoch [8/100], Loss: 0.5043, Validation Loss: 0.6130
	--> Epoch [9/100], Loss: 0.5215, Validation Loss: 0.6022
	--> Epoch [10/100], Loss: 0.5201, Validation Loss: 0.6020
	--> Epoch [11/100], Loss: 0.4597, Validation Loss: 0.5933
	--> Epoch [12/100], Loss: 0.4722, Validation Loss: 0.5850
	--> Epoch [13/100], Loss: 0.5417, Validation Loss: 0.5782
	--> Epoch [14/100], Loss: 0.4933, Validation Loss: 0.5706
	--> Epoch [15/100], Loss: 0.4181, Validation Loss: 0.5644
	--> Epoch [16/100], Loss: 0.3692, Validation Loss: 0.5643
	--> Epoch [17/100], Loss: 0.3734, Validation Loss: 0.5626
	--> Epoch [18/100], Loss: 0.3317, Validation Loss: 0.5620
	--> Epoch [19/100], Loss: 0.3091, Validation Loss: 0.5558
	--> Epoch [20/100], Loss: 0.3051, Validation Loss: 0.5521
	--> Epoch [21/100], Loss: 0.3167, Validation Loss: 0.5466
	--> Epoch [22/100], Loss: 0.2181, Validation Loss: 0.5467
	--> Epoch [23/100], Loss: 0.3184, Validation Loss: 0.5425
	--> Epoch [24/100], Loss: 0.2201, Validation Loss: 0.5426
	--> Epoch [25/100], Loss: 0.2450, Validation Loss: 0.5470
	--> Epoch [26/100], Loss: 0.2248, Validation Loss: 0.5461
Early stopping
	--> Training for Fold 5 took 0.4884641170501709 sec, using 26 epochs

Median number of epochs used: 75 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/75], Loss: 1.0697
	--> Final training Epoch [2/75], Loss: 0.9022
	--> Final training Epoch [3/75], Loss: 0.7541
	--> Final training Epoch [4/75], Loss: 0.7838
	--> Final training Epoch [5/75], Loss: 0.6430
	--> Final training Epoch [6/75], Loss: 0.6723
	--> Final training Epoch [7/75], Loss: 0.7297
	--> Final training Epoch [8/75], Loss: 0.7697
	--> Final training Epoch [9/75], Loss: 0.6491
	--> Final training Epoch [10/75], Loss: 0.5664
	--> Final training Epoch [11/75], Loss: 0.6025
	--> Final training Epoch [12/75], Loss: 0.6519
	--> Final training Epoch [13/75], Loss: 0.5089
	--> Final training Epoch [14/75], Loss: 0.5742
	--> Final training Epoch [15/75], Loss: 0.5829
	--> Final training Epoch [16/75], Loss: 0.7179
	--> Final training Epoch [17/75], Loss: 0.5332
	--> Final training Epoch [18/75], Loss: 0.6632
	--> Final training Epoch [19/75], Loss: 0.4398
	--> Final training Epoch [20/75], Loss: 0.4740
	--> Final training Epoch [21/75], Loss: 0.4270
	--> Final training Epoch [22/75], Loss: 0.3689
	--> Final training Epoch [23/75], Loss: 0.4105
	--> Final training Epoch [24/75], Loss: 0.3958
	--> Final training Epoch [25/75], Loss: 0.4764
	--> Final training Epoch [26/75], Loss: 0.3996
	--> Final training Epoch [27/75], Loss: 0.4798
	--> Final training Epoch [28/75], Loss: 0.4302
	--> Final training Epoch [29/75], Loss: 0.4098
	--> Final training Epoch [30/75], Loss: 0.5270
	--> Final training Epoch [31/75], Loss: 0.4746
	--> Final training Epoch [32/75], Loss: 0.4214
	--> Final training Epoch [33/75], Loss: 0.4669
	--> Final training Epoch [34/75], Loss: 0.4138
	--> Final training Epoch [35/75], Loss: 0.4592
	--> Final training Epoch [36/75], Loss: 0.4041
	--> Final training Epoch [37/75], Loss: 0.3784
	--> Final training Epoch [38/75], Loss: 0.3817
	--> Final training Epoch [39/75], Loss: 0.3640
	--> Final training Epoch [40/75], Loss: 0.3020
	--> Final training Epoch [41/75], Loss: 0.2860
	--> Final training Epoch [42/75], Loss: 0.3140
	--> Final training Epoch [43/75], Loss: 0.3262
	--> Final training Epoch [44/75], Loss: 0.4472
	--> Final training Epoch [45/75], Loss: 0.2345
	--> Final training Epoch [46/75], Loss: 0.3385
	--> Final training Epoch [47/75], Loss: 0.3543
	--> Final training Epoch [48/75], Loss: 0.3281
	--> Final training Epoch [49/75], Loss: 0.4156
	--> Final training Epoch [50/75], Loss: 0.3195
	--> Final training Epoch [51/75], Loss: 0.5095
	--> Final training Epoch [52/75], Loss: 0.2627
	--> Final training Epoch [53/75], Loss: 0.4683
	--> Final training Epoch [54/75], Loss: 0.2230
	--> Final training Epoch [55/75], Loss: 0.3020
	--> Final training Epoch [56/75], Loss: 0.3602
	--> Final training Epoch [57/75], Loss: 0.2692
	--> Final training Epoch [58/75], Loss: 0.4676
	--> Final training Epoch [59/75], Loss: 0.3510
	--> Final training Epoch [60/75], Loss: 0.1838
	--> Final training Epoch [61/75], Loss: 0.3091
	--> Final training Epoch [62/75], Loss: 0.2593
	--> Final training Epoch [63/75], Loss: 0.3232
	--> Final training Epoch [64/75], Loss: 0.3018
	--> Final training Epoch [65/75], Loss: 0.2557
	--> Final training Epoch [66/75], Loss: 0.3527
	--> Final training Epoch [67/75], Loss: 0.3426
	--> Final training Epoch [68/75], Loss: 0.2444
	--> Final training Epoch [69/75], Loss: 0.3498
	--> Final training Epoch [70/75], Loss: 0.3260
	--> Final training Epoch [71/75], Loss: 0.4256
	--> Final training Epoch [72/75], Loss: 0.3356
	--> Final training Epoch [73/75], Loss: 0.3037
	--> Final training Epoch [74/75], Loss: 0.3228
	--> Final training Epoch [75/75], Loss: 0.2816

Final training took 1.6524908542633057 sec

TESTING
	--> Testing took 0.0160 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.8759
	--> Final Precision: 0.7143
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7407
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3584,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3584
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3788,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3584

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.9066, Validation Loss: 0.7995
	--> Epoch [2/100], Loss: 0.8281, Validation Loss: 0.7703
	--> Epoch [3/100], Loss: 0.7868, Validation Loss: 0.7382
	--> Epoch [4/100], Loss: 0.7554, Validation Loss: 0.7041
	--> Epoch [5/100], Loss: 0.6704, Validation Loss: 0.6703
	--> Epoch [6/100], Loss: 0.6811, Validation Loss: 0.6339
	--> Epoch [7/100], Loss: 0.5858, Validation Loss: 0.6054
	--> Epoch [8/100], Loss: 0.6840, Validation Loss: 0.5793
	--> Epoch [9/100], Loss: 0.5545, Validation Loss: 0.5599
	--> Epoch [10/100], Loss: 0.4578, Validation Loss: 0.5381
	--> Epoch [11/100], Loss: 0.4176, Validation Loss: 0.5126
	--> Epoch [12/100], Loss: 0.4455, Validation Loss: 0.4909
	--> Epoch [13/100], Loss: 0.3531, Validation Loss: 0.4752
	--> Epoch [14/100], Loss: 0.4128, Validation Loss: 0.4573
	--> Epoch [15/100], Loss: 0.3939, Validation Loss: 0.4427
	--> Epoch [16/100], Loss: 0.3212, Validation Loss: 0.4278
	--> Epoch [17/100], Loss: 0.3474, Validation Loss: 0.4134
	--> Epoch [18/100], Loss: 0.2331, Validation Loss: 0.4026
	--> Epoch [19/100], Loss: 0.3396, Validation Loss: 0.3926
	--> Epoch [20/100], Loss: 0.1837, Validation Loss: 0.3827
	--> Epoch [21/100], Loss: 0.2204, Validation Loss: 0.3711
	--> Epoch [22/100], Loss: 0.1581, Validation Loss: 0.3634
	--> Epoch [23/100], Loss: 0.1426, Validation Loss: 0.3537
	--> Epoch [24/100], Loss: 0.1603, Validation Loss: 0.3490
	--> Epoch [25/100], Loss: 0.1646, Validation Loss: 0.3427
	--> Epoch [26/100], Loss: 0.2149, Validation Loss: 0.3353
	--> Epoch [27/100], Loss: 0.1185, Validation Loss: 0.3272
	--> Epoch [28/100], Loss: 0.2800, Validation Loss: 0.3217
	--> Epoch [29/100], Loss: 0.1452, Validation Loss: 0.3146
	--> Epoch [30/100], Loss: 0.1615, Validation Loss: 0.3119
	--> Epoch [31/100], Loss: 0.1242, Validation Loss: 0.3064
	--> Epoch [32/100], Loss: 0.0997, Validation Loss: 0.3033
	--> Epoch [33/100], Loss: 0.1561, Validation Loss: 0.2994
	--> Epoch [34/100], Loss: 0.1451, Validation Loss: 0.2956
	--> Epoch [35/100], Loss: 0.1411, Validation Loss: 0.2913
	--> Epoch [36/100], Loss: 0.0403, Validation Loss: 0.2872
	--> Epoch [37/100], Loss: 0.0687, Validation Loss: 0.2848
	--> Epoch [38/100], Loss: 0.1868, Validation Loss: 0.2791
	--> Epoch [39/100], Loss: 0.0658, Validation Loss: 0.2772
	--> Epoch [40/100], Loss: 0.0605, Validation Loss: 0.2745
	--> Epoch [41/100], Loss: 0.0584, Validation Loss: 0.2712
	--> Epoch [42/100], Loss: 0.0746, Validation Loss: 0.2675
	--> Epoch [43/100], Loss: 0.0569, Validation Loss: 0.2647
	--> Epoch [44/100], Loss: 0.1821, Validation Loss: 0.2625
	--> Epoch [45/100], Loss: 0.0429, Validation Loss: 0.2595
	--> Epoch [46/100], Loss: 0.1769, Validation Loss: 0.2556
	--> Epoch [47/100], Loss: 0.1458, Validation Loss: 0.2546
	--> Epoch [48/100], Loss: 0.1352, Validation Loss: 0.2516
	--> Epoch [49/100], Loss: 0.0349, Validation Loss: 0.2516
	--> Epoch [50/100], Loss: 0.1289, Validation Loss: 0.2518
	--> Epoch [51/100], Loss: 0.0703, Validation Loss: 0.2492
	--> Epoch [52/100], Loss: 0.0405, Validation Loss: 0.2484
	--> Epoch [53/100], Loss: 0.0256, Validation Loss: 0.2466
	--> Epoch [54/100], Loss: 0.0312, Validation Loss: 0.2445
	--> Epoch [55/100], Loss: 0.1222, Validation Loss: 0.2400
	--> Epoch [56/100], Loss: 0.1375, Validation Loss: 0.2396
	--> Epoch [57/100], Loss: 0.0540, Validation Loss: 0.2394
	--> Epoch [58/100], Loss: 0.1529, Validation Loss: 0.2383
	--> Epoch [59/100], Loss: 0.0429, Validation Loss: 0.2350
	--> Epoch [60/100], Loss: 0.1020, Validation Loss: 0.2349
	--> Epoch [61/100], Loss: 0.0171, Validation Loss: 0.2357
	--> Epoch [62/100], Loss: 0.0230, Validation Loss: 0.2352
	--> Epoch [63/100], Loss: 0.0297, Validation Loss: 0.2349
	--> Epoch [64/100], Loss: 0.0401, Validation Loss: 0.2341
	--> Epoch [65/100], Loss: 0.1999, Validation Loss: 0.2341
	--> Epoch [66/100], Loss: 0.0104, Validation Loss: 0.2335
	--> Epoch [67/100], Loss: 0.0219, Validation Loss: 0.2338
	--> Epoch [68/100], Loss: 0.0107, Validation Loss: 0.2328
	--> Epoch [69/100], Loss: 0.1685, Validation Loss: 0.2330
	--> Epoch [70/100], Loss: 0.0479, Validation Loss: 0.2330
	--> Epoch [71/100], Loss: 0.0131, Validation Loss: 0.2319
	--> Epoch [72/100], Loss: 0.0384, Validation Loss: 0.2313
	--> Epoch [73/100], Loss: 0.0366, Validation Loss: 0.2311
	--> Epoch [74/100], Loss: 0.0330, Validation Loss: 0.2309
	--> Epoch [75/100], Loss: 0.0116, Validation Loss: 0.2311
	--> Epoch [76/100], Loss: 0.1532, Validation Loss: 0.2309
	--> Epoch [77/100], Loss: 0.0178, Validation Loss: 0.2301
	--> Epoch [78/100], Loss: 0.1130, Validation Loss: 0.2303
	--> Epoch [79/100], Loss: 0.0996, Validation Loss: 0.2312
	--> Epoch [80/100], Loss: 0.0160, Validation Loss: 0.2311
Early stopping
	--> Training for Fold 1 took 1.5368568897247314 sec, using 80 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7004, Validation Loss: 0.7893
	--> Epoch [2/100], Loss: 0.6255, Validation Loss: 0.7341
	--> Epoch [3/100], Loss: 0.6042, Validation Loss: 0.6877
	--> Epoch [4/100], Loss: 0.5585, Validation Loss: 0.6474
	--> Epoch [5/100], Loss: 0.4989, Validation Loss: 0.6120
	--> Epoch [6/100], Loss: 0.5438, Validation Loss: 0.5837
	--> Epoch [7/100], Loss: 0.5055, Validation Loss: 0.5515
	--> Epoch [8/100], Loss: 0.5205, Validation Loss: 0.5207
	--> Epoch [9/100], Loss: 0.4414, Validation Loss: 0.4953
	--> Epoch [10/100], Loss: 0.4548, Validation Loss: 0.4746
	--> Epoch [11/100], Loss: 0.4445, Validation Loss: 0.4504
	--> Epoch [12/100], Loss: 0.4079, Validation Loss: 0.4317
	--> Epoch [13/100], Loss: 0.2955, Validation Loss: 0.4104
	--> Epoch [14/100], Loss: 0.3653, Validation Loss: 0.3948
	--> Epoch [15/100], Loss: 0.2866, Validation Loss: 0.3804
	--> Epoch [16/100], Loss: 0.2635, Validation Loss: 0.3673
	--> Epoch [17/100], Loss: 0.1836, Validation Loss: 0.3568
	--> Epoch [18/100], Loss: 0.1791, Validation Loss: 0.3432
	--> Epoch [19/100], Loss: 0.1874, Validation Loss: 0.3319
	--> Epoch [20/100], Loss: 0.2359, Validation Loss: 0.3272
	--> Epoch [21/100], Loss: 0.1542, Validation Loss: 0.3205
	--> Epoch [22/100], Loss: 0.1564, Validation Loss: 0.3122
	--> Epoch [23/100], Loss: 0.1609, Validation Loss: 0.3039
	--> Epoch [24/100], Loss: 0.1682, Validation Loss: 0.2976
	--> Epoch [25/100], Loss: 0.1305, Validation Loss: 0.2923
	--> Epoch [26/100], Loss: 0.1205, Validation Loss: 0.2893
	--> Epoch [27/100], Loss: 0.1311, Validation Loss: 0.2827
	--> Epoch [28/100], Loss: 0.1155, Validation Loss: 0.2806
	--> Epoch [29/100], Loss: 0.1558, Validation Loss: 0.2779
	--> Epoch [30/100], Loss: 0.1524, Validation Loss: 0.2729
	--> Epoch [31/100], Loss: 0.1181, Validation Loss: 0.2699
	--> Epoch [32/100], Loss: 0.1203, Validation Loss: 0.2677
	--> Epoch [33/100], Loss: 0.1755, Validation Loss: 0.2659
	--> Epoch [34/100], Loss: 0.1842, Validation Loss: 0.2651
	--> Epoch [35/100], Loss: 0.0841, Validation Loss: 0.2611
	--> Epoch [36/100], Loss: 0.0923, Validation Loss: 0.2587
	--> Epoch [37/100], Loss: 0.0805, Validation Loss: 0.2560
	--> Epoch [38/100], Loss: 0.0682, Validation Loss: 0.2547
	--> Epoch [39/100], Loss: 0.1051, Validation Loss: 0.2536
	--> Epoch [40/100], Loss: 0.1342, Validation Loss: 0.2492
	--> Epoch [41/100], Loss: 0.0955, Validation Loss: 0.2490
	--> Epoch [42/100], Loss: 0.0674, Validation Loss: 0.2494
	--> Epoch [43/100], Loss: 0.1472, Validation Loss: 0.2479
	--> Epoch [44/100], Loss: 0.0859, Validation Loss: 0.2467
	--> Epoch [45/100], Loss: 0.1202, Validation Loss: 0.2472
	--> Epoch [46/100], Loss: 0.1315, Validation Loss: 0.2453
	--> Epoch [47/100], Loss: 0.1224, Validation Loss: 0.2420
	--> Epoch [48/100], Loss: 0.0762, Validation Loss: 0.2400
	--> Epoch [49/100], Loss: 0.1031, Validation Loss: 0.2393
	--> Epoch [50/100], Loss: 0.0678, Validation Loss: 0.2366
	--> Epoch [51/100], Loss: 0.0583, Validation Loss: 0.2349
	--> Epoch [52/100], Loss: 0.0617, Validation Loss: 0.2363
	--> Epoch [53/100], Loss: 0.0612, Validation Loss: 0.2362
	--> Epoch [54/100], Loss: 0.1188, Validation Loss: 0.2367
Early stopping
	--> Training for Fold 2 took 1.1209626197814941 sec, using 54 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6612, Validation Loss: 0.6794
	--> Epoch [2/100], Loss: 0.6245, Validation Loss: 0.6592
	--> Epoch [3/100], Loss: 0.5476, Validation Loss: 0.6391
	--> Epoch [4/100], Loss: 0.6037, Validation Loss: 0.6249
	--> Epoch [5/100], Loss: 0.5708, Validation Loss: 0.6112
	--> Epoch [6/100], Loss: 0.4158, Validation Loss: 0.5949
	--> Epoch [7/100], Loss: 0.4206, Validation Loss: 0.5823
	--> Epoch [8/100], Loss: 0.4641, Validation Loss: 0.5657
	--> Epoch [9/100], Loss: 0.3269, Validation Loss: 0.5514
	--> Epoch [10/100], Loss: 0.4091, Validation Loss: 0.5397
	--> Epoch [11/100], Loss: 0.3182, Validation Loss: 0.5264
	--> Epoch [12/100], Loss: 0.2995, Validation Loss: 0.5135
	--> Epoch [13/100], Loss: 0.2605, Validation Loss: 0.5031
	--> Epoch [14/100], Loss: 0.2655, Validation Loss: 0.4930
	--> Epoch [15/100], Loss: 0.2627, Validation Loss: 0.4829
	--> Epoch [16/100], Loss: 0.2201, Validation Loss: 0.4728
	--> Epoch [17/100], Loss: 0.1639, Validation Loss: 0.4640
	--> Epoch [18/100], Loss: 0.1860, Validation Loss: 0.4543
	--> Epoch [19/100], Loss: 0.2627, Validation Loss: 0.4495
	--> Epoch [20/100], Loss: 0.2633, Validation Loss: 0.4455
	--> Epoch [21/100], Loss: 0.1524, Validation Loss: 0.4429
	--> Epoch [22/100], Loss: 0.2119, Validation Loss: 0.4382
	--> Epoch [23/100], Loss: 0.1453, Validation Loss: 0.4341
	--> Epoch [24/100], Loss: 0.1989, Validation Loss: 0.4289
	--> Epoch [25/100], Loss: 0.3095, Validation Loss: 0.4229
	--> Epoch [26/100], Loss: 0.1329, Validation Loss: 0.4181
	--> Epoch [27/100], Loss: 0.1335, Validation Loss: 0.4169
	--> Epoch [28/100], Loss: 0.1286, Validation Loss: 0.4142
	--> Epoch [29/100], Loss: 0.1506, Validation Loss: 0.4129
	--> Epoch [30/100], Loss: 0.1728, Validation Loss: 0.4126
	--> Epoch [31/100], Loss: 0.1258, Validation Loss: 0.4100
	--> Epoch [32/100], Loss: 0.1488, Validation Loss: 0.4063
	--> Epoch [33/100], Loss: 0.1715, Validation Loss: 0.4018
	--> Epoch [34/100], Loss: 0.1870, Validation Loss: 0.4028
	--> Epoch [35/100], Loss: 0.1539, Validation Loss: 0.4017
	--> Epoch [36/100], Loss: 0.1239, Validation Loss: 0.3989
	--> Epoch [37/100], Loss: 0.1487, Validation Loss: 0.3976
	--> Epoch [38/100], Loss: 0.1277, Validation Loss: 0.3968
	--> Epoch [39/100], Loss: 0.1026, Validation Loss: 0.3962
	--> Epoch [40/100], Loss: 0.1248, Validation Loss: 0.3977
	--> Epoch [41/100], Loss: 0.1226, Validation Loss: 0.3974
	--> Epoch [42/100], Loss: 0.0936, Validation Loss: 0.3976
Early stopping
	--> Training for Fold 3 took 0.8375673294067383 sec, using 42 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7138, Validation Loss: 0.6656
	--> Epoch [2/100], Loss: 0.6775, Validation Loss: 0.6393
	--> Epoch [3/100], Loss: 0.6182, Validation Loss: 0.6125
	--> Epoch [4/100], Loss: 0.5605, Validation Loss: 0.5880
	--> Epoch [5/100], Loss: 0.5151, Validation Loss: 0.5704
	--> Epoch [6/100], Loss: 0.5548, Validation Loss: 0.5484
	--> Epoch [7/100], Loss: 0.4551, Validation Loss: 0.5317
	--> Epoch [8/100], Loss: 0.4343, Validation Loss: 0.5117
	--> Epoch [9/100], Loss: 0.4272, Validation Loss: 0.4974
	--> Epoch [10/100], Loss: 0.4503, Validation Loss: 0.4828
	--> Epoch [11/100], Loss: 0.2999, Validation Loss: 0.4656
	--> Epoch [12/100], Loss: 0.3766, Validation Loss: 0.4500
	--> Epoch [13/100], Loss: 0.3482, Validation Loss: 0.4325
	--> Epoch [14/100], Loss: 0.3193, Validation Loss: 0.4188
	--> Epoch [15/100], Loss: 0.4144, Validation Loss: 0.4064
	--> Epoch [16/100], Loss: 0.1922, Validation Loss: 0.3948
	--> Epoch [17/100], Loss: 0.2141, Validation Loss: 0.3871
	--> Epoch [18/100], Loss: 0.1724, Validation Loss: 0.3787
	--> Epoch [19/100], Loss: 0.2817, Validation Loss: 0.3712
	--> Epoch [20/100], Loss: 0.1385, Validation Loss: 0.3630
	--> Epoch [21/100], Loss: 0.1192, Validation Loss: 0.3550
	--> Epoch [22/100], Loss: 0.1441, Validation Loss: 0.3481
	--> Epoch [23/100], Loss: 0.0868, Validation Loss: 0.3404
	--> Epoch [24/100], Loss: 0.2035, Validation Loss: 0.3350
	--> Epoch [25/100], Loss: 0.0830, Validation Loss: 0.3316
	--> Epoch [26/100], Loss: 0.0840, Validation Loss: 0.3284
	--> Epoch [27/100], Loss: 0.0904, Validation Loss: 0.3213
	--> Epoch [28/100], Loss: 0.0644, Validation Loss: 0.3199
	--> Epoch [29/100], Loss: 0.0696, Validation Loss: 0.3169
	--> Epoch [30/100], Loss: 0.0961, Validation Loss: 0.3148
	--> Epoch [31/100], Loss: 0.1111, Validation Loss: 0.3142
	--> Epoch [32/100], Loss: 0.2311, Validation Loss: 0.3108
	--> Epoch [33/100], Loss: 0.2523, Validation Loss: 0.3058
	--> Epoch [34/100], Loss: 0.0966, Validation Loss: 0.3032
	--> Epoch [35/100], Loss: 0.0517, Validation Loss: 0.3018
	--> Epoch [36/100], Loss: 0.1655, Validation Loss: 0.2986
	--> Epoch [37/100], Loss: 0.1481, Validation Loss: 0.2994
	--> Epoch [38/100], Loss: 0.0414, Validation Loss: 0.2975
	--> Epoch [39/100], Loss: 0.1163, Validation Loss: 0.2953
	--> Epoch [40/100], Loss: 0.1290, Validation Loss: 0.2884
	--> Epoch [41/100], Loss: 0.1331, Validation Loss: 0.2940
	--> Epoch [42/100], Loss: 0.0891, Validation Loss: 0.2953
	--> Epoch [43/100], Loss: 0.0473, Validation Loss: 0.2918
Early stopping
	--> Training for Fold 4 took 0.8966588973999023 sec, using 43 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6702, Validation Loss: 0.6742
	--> Epoch [2/100], Loss: 0.6411, Validation Loss: 0.6562
	--> Epoch [3/100], Loss: 0.5680, Validation Loss: 0.6375
	--> Epoch [4/100], Loss: 0.5019, Validation Loss: 0.6223
	--> Epoch [5/100], Loss: 0.4512, Validation Loss: 0.6113
	--> Epoch [6/100], Loss: 0.4200, Validation Loss: 0.5967
	--> Epoch [7/100], Loss: 0.3839, Validation Loss: 0.5856
	--> Epoch [8/100], Loss: 0.4231, Validation Loss: 0.5715
	--> Epoch [9/100], Loss: 0.3339, Validation Loss: 0.5604
	--> Epoch [10/100], Loss: 0.3980, Validation Loss: 0.5499
	--> Epoch [11/100], Loss: 0.3588, Validation Loss: 0.5410
	--> Epoch [12/100], Loss: 0.3062, Validation Loss: 0.5324
	--> Epoch [13/100], Loss: 0.2667, Validation Loss: 0.5233
	--> Epoch [14/100], Loss: 0.2056, Validation Loss: 0.5143
	--> Epoch [15/100], Loss: 0.2655, Validation Loss: 0.5104
	--> Epoch [16/100], Loss: 0.2989, Validation Loss: 0.5062
	--> Epoch [17/100], Loss: 0.2109, Validation Loss: 0.5013
	--> Epoch [18/100], Loss: 0.2508, Validation Loss: 0.4996
	--> Epoch [19/100], Loss: 0.1989, Validation Loss: 0.4977
	--> Epoch [20/100], Loss: 0.2049, Validation Loss: 0.4965
	--> Epoch [21/100], Loss: 0.2774, Validation Loss: 0.4958
	--> Epoch [22/100], Loss: 0.2136, Validation Loss: 0.4905
	--> Epoch [23/100], Loss: 0.2889, Validation Loss: 0.4940
	--> Epoch [24/100], Loss: 0.2480, Validation Loss: 0.4911
	--> Epoch [25/100], Loss: 0.0977, Validation Loss: 0.4923
Early stopping
	--> Training for Fold 5 took 0.4963688850402832 sec, using 25 epochs

Median number of epochs used: 43 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/43], Loss: 0.5223
	--> Final training Epoch [2/43], Loss: 0.4967
	--> Final training Epoch [3/43], Loss: 0.4057
	--> Final training Epoch [4/43], Loss: 0.4457
	--> Final training Epoch [5/43], Loss: 0.3693
	--> Final training Epoch [6/43], Loss: 0.3651
	--> Final training Epoch [7/43], Loss: 0.3549
	--> Final training Epoch [8/43], Loss: 0.3413
	--> Final training Epoch [9/43], Loss: 0.3426
	--> Final training Epoch [10/43], Loss: 0.2410
	--> Final training Epoch [11/43], Loss: 0.2726
	--> Final training Epoch [12/43], Loss: 0.2562
	--> Final training Epoch [13/43], Loss: 0.2519
	--> Final training Epoch [14/43], Loss: 0.2617
	--> Final training Epoch [15/43], Loss: 0.1797
	--> Final training Epoch [16/43], Loss: 0.2025
	--> Final training Epoch [17/43], Loss: 0.1583
	--> Final training Epoch [18/43], Loss: 0.1581
	--> Final training Epoch [19/43], Loss: 0.1796
	--> Final training Epoch [20/43], Loss: 0.1455
	--> Final training Epoch [21/43], Loss: 0.2229
	--> Final training Epoch [22/43], Loss: 0.1231
	--> Final training Epoch [23/43], Loss: 0.2191
	--> Final training Epoch [24/43], Loss: 0.0744
	--> Final training Epoch [25/43], Loss: 0.1399
	--> Final training Epoch [26/43], Loss: 0.0801
	--> Final training Epoch [27/43], Loss: 0.1411
	--> Final training Epoch [28/43], Loss: 0.0802
	--> Final training Epoch [29/43], Loss: 0.0850
	--> Final training Epoch [30/43], Loss: 0.0834
	--> Final training Epoch [31/43], Loss: 0.1080
	--> Final training Epoch [32/43], Loss: 0.0836
	--> Final training Epoch [33/43], Loss: 0.0523
	--> Final training Epoch [34/43], Loss: 0.0391
	--> Final training Epoch [35/43], Loss: 0.0766
	--> Final training Epoch [36/43], Loss: 0.0661
	--> Final training Epoch [37/43], Loss: 0.1060
	--> Final training Epoch [38/43], Loss: 0.0631
	--> Final training Epoch [39/43], Loss: 0.0649
	--> Final training Epoch [40/43], Loss: 0.0866
	--> Final training Epoch [41/43], Loss: 0.0502
	--> Final training Epoch [42/43], Loss: 0.0438
	--> Final training Epoch [43/43], Loss: 0.0320

Final training took 0.9829134941101074 sec

TESTING
	--> Testing took 0.0191 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0669
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8175, Validation Loss: 0.3535,  Current Best Accuracy: 0.8175,  Current Best Validation Loss: 0.3535
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7725, Validation Loss: 0.3740,  Current Best Accuracy: 0.8175,  Current Best Validation Loss: 0.3535

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6687, Validation Loss: 0.6621
	--> Epoch [2/100], Loss: 0.6149, Validation Loss: 0.6239
	--> Epoch [3/100], Loss: 0.5060, Validation Loss: 0.5895
	--> Epoch [4/100], Loss: 0.5449, Validation Loss: 0.5617
	--> Epoch [5/100], Loss: 0.4679, Validation Loss: 0.5407
	--> Epoch [6/100], Loss: 0.5282, Validation Loss: 0.5149
	--> Epoch [7/100], Loss: 0.3898, Validation Loss: 0.4901
	--> Epoch [8/100], Loss: 0.3596, Validation Loss: 0.4729
	--> Epoch [9/100], Loss: 0.3933, Validation Loss: 0.4559
	--> Epoch [10/100], Loss: 0.2444, Validation Loss: 0.4373
	--> Epoch [11/100], Loss: 0.2217, Validation Loss: 0.4207
	--> Epoch [12/100], Loss: 0.2420, Validation Loss: 0.4098
	--> Epoch [13/100], Loss: 0.2250, Validation Loss: 0.3914
	--> Epoch [14/100], Loss: 0.2261, Validation Loss: 0.3826
	--> Epoch [15/100], Loss: 0.1390, Validation Loss: 0.3679
	--> Epoch [16/100], Loss: 0.1628, Validation Loss: 0.3579
	--> Epoch [17/100], Loss: 0.1763, Validation Loss: 0.3479
	--> Epoch [18/100], Loss: 0.0870, Validation Loss: 0.3407
	--> Epoch [19/100], Loss: 0.1961, Validation Loss: 0.3290
	--> Epoch [20/100], Loss: 0.0714, Validation Loss: 0.3222
	--> Epoch [21/100], Loss: 0.1968, Validation Loss: 0.3142
	--> Epoch [22/100], Loss: 0.0902, Validation Loss: 0.3101
	--> Epoch [23/100], Loss: 0.1008, Validation Loss: 0.3054
	--> Epoch [24/100], Loss: 0.0667, Validation Loss: 0.2997
	--> Epoch [25/100], Loss: 0.1578, Validation Loss: 0.2923
	--> Epoch [26/100], Loss: 0.0717, Validation Loss: 0.2866
	--> Epoch [27/100], Loss: 0.0886, Validation Loss: 0.2805
	--> Epoch [28/100], Loss: 0.0682, Validation Loss: 0.2787
	--> Epoch [29/100], Loss: 0.0436, Validation Loss: 0.2765
	--> Epoch [30/100], Loss: 0.2099, Validation Loss: 0.2732
	--> Epoch [31/100], Loss: 0.0622, Validation Loss: 0.2671
	--> Epoch [32/100], Loss: 0.1766, Validation Loss: 0.2639
	--> Epoch [33/100], Loss: 0.0470, Validation Loss: 0.2613
	--> Epoch [34/100], Loss: 0.0446, Validation Loss: 0.2600
	--> Epoch [35/100], Loss: 0.0729, Validation Loss: 0.2572
	--> Epoch [36/100], Loss: 0.0113, Validation Loss: 0.2537
	--> Epoch [37/100], Loss: 0.1158, Validation Loss: 0.2530
	--> Epoch [38/100], Loss: 0.0245, Validation Loss: 0.2513
	--> Epoch [39/100], Loss: 0.0464, Validation Loss: 0.2499
	--> Epoch [40/100], Loss: 0.1127, Validation Loss: 0.2467
	--> Epoch [41/100], Loss: 0.0472, Validation Loss: 0.2437
	--> Epoch [42/100], Loss: 0.0938, Validation Loss: 0.2394
	--> Epoch [43/100], Loss: 0.0312, Validation Loss: 0.2383
	--> Epoch [44/100], Loss: 0.0323, Validation Loss: 0.2355
	--> Epoch [45/100], Loss: 0.0103, Validation Loss: 0.2347
	--> Epoch [46/100], Loss: 0.0246, Validation Loss: 0.2330
	--> Epoch [47/100], Loss: 0.0378, Validation Loss: 0.2331
	--> Epoch [48/100], Loss: 0.0195, Validation Loss: 0.2301
	--> Epoch [49/100], Loss: 0.0246, Validation Loss: 0.2311
	--> Epoch [50/100], Loss: 0.0906, Validation Loss: 0.2323
	--> Epoch [51/100], Loss: 0.1192, Validation Loss: 0.2312
Early stopping
	--> Training for Fold 1 took 0.8438229560852051 sec, using 51 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6390, Validation Loss: 0.6343
	--> Epoch [2/100], Loss: 0.5345, Validation Loss: 0.6100
	--> Epoch [3/100], Loss: 0.5281, Validation Loss: 0.5886
	--> Epoch [4/100], Loss: 0.4198, Validation Loss: 0.5649
	--> Epoch [5/100], Loss: 0.3589, Validation Loss: 0.5482
	--> Epoch [6/100], Loss: 0.3725, Validation Loss: 0.5299
	--> Epoch [7/100], Loss: 0.3038, Validation Loss: 0.5120
	--> Epoch [8/100], Loss: 0.3070, Validation Loss: 0.4945
	--> Epoch [9/100], Loss: 0.3911, Validation Loss: 0.4757
	--> Epoch [10/100], Loss: 0.2360, Validation Loss: 0.4631
	--> Epoch [11/100], Loss: 0.1995, Validation Loss: 0.4492
	--> Epoch [12/100], Loss: 0.2628, Validation Loss: 0.4354
	--> Epoch [13/100], Loss: 0.1890, Validation Loss: 0.4238
	--> Epoch [14/100], Loss: 0.2556, Validation Loss: 0.4117
	--> Epoch [15/100], Loss: 0.2424, Validation Loss: 0.4019
	--> Epoch [16/100], Loss: 0.2056, Validation Loss: 0.3906
	--> Epoch [17/100], Loss: 0.2483, Validation Loss: 0.3807
	--> Epoch [18/100], Loss: 0.1596, Validation Loss: 0.3739
	--> Epoch [19/100], Loss: 0.1913, Validation Loss: 0.3639
	--> Epoch [20/100], Loss: 0.1947, Validation Loss: 0.3587
	--> Epoch [21/100], Loss: 0.1505, Validation Loss: 0.3505
	--> Epoch [22/100], Loss: 0.1261, Validation Loss: 0.3426
	--> Epoch [23/100], Loss: 0.1251, Validation Loss: 0.3387
	--> Epoch [24/100], Loss: 0.1379, Validation Loss: 0.3312
	--> Epoch [25/100], Loss: 0.1223, Validation Loss: 0.3219
	--> Epoch [26/100], Loss: 0.1136, Validation Loss: 0.3185
	--> Epoch [27/100], Loss: 0.1985, Validation Loss: 0.3118
	--> Epoch [28/100], Loss: 0.1025, Validation Loss: 0.3085
	--> Epoch [29/100], Loss: 0.1476, Validation Loss: 0.3070
	--> Epoch [30/100], Loss: 0.1648, Validation Loss: 0.3029
	--> Epoch [31/100], Loss: 0.2453, Validation Loss: 0.3004
	--> Epoch [32/100], Loss: 0.1381, Validation Loss: 0.2979
	--> Epoch [33/100], Loss: 0.1184, Validation Loss: 0.2940
	--> Epoch [34/100], Loss: 0.1282, Validation Loss: 0.2932
	--> Epoch [35/100], Loss: 0.1042, Validation Loss: 0.2890
	--> Epoch [36/100], Loss: 0.1161, Validation Loss: 0.2862
	--> Epoch [37/100], Loss: 0.0981, Validation Loss: 0.2850
	--> Epoch [38/100], Loss: 0.0968, Validation Loss: 0.2810
	--> Epoch [39/100], Loss: 0.1128, Validation Loss: 0.2805
	--> Epoch [40/100], Loss: 0.1325, Validation Loss: 0.2811
	--> Epoch [41/100], Loss: 0.1609, Validation Loss: 0.2768
	--> Epoch [42/100], Loss: 0.1230, Validation Loss: 0.2753
	--> Epoch [43/100], Loss: 0.1989, Validation Loss: 0.2733
	--> Epoch [44/100], Loss: 0.1146, Validation Loss: 0.2701
	--> Epoch [45/100], Loss: 0.1716, Validation Loss: 0.2702
	--> Epoch [46/100], Loss: 0.1122, Validation Loss: 0.2676
	--> Epoch [47/100], Loss: 0.0878, Validation Loss: 0.2665
	--> Epoch [48/100], Loss: 0.1166, Validation Loss: 0.2676
	--> Epoch [49/100], Loss: 0.0991, Validation Loss: 0.2662
	--> Epoch [50/100], Loss: 0.0888, Validation Loss: 0.2645
	--> Epoch [51/100], Loss: 0.1110, Validation Loss: 0.2634
	--> Epoch [52/100], Loss: 0.0908, Validation Loss: 0.2626
	--> Epoch [53/100], Loss: 0.2142, Validation Loss: 0.2616
	--> Epoch [54/100], Loss: 0.0914, Validation Loss: 0.2607
	--> Epoch [55/100], Loss: 0.1086, Validation Loss: 0.2598
	--> Epoch [56/100], Loss: 0.0902, Validation Loss: 0.2597
	--> Epoch [57/100], Loss: 0.0978, Validation Loss: 0.2578
	--> Epoch [58/100], Loss: 0.0914, Validation Loss: 0.2547
	--> Epoch [59/100], Loss: 0.0925, Validation Loss: 0.2530
	--> Epoch [60/100], Loss: 0.0907, Validation Loss: 0.2514
	--> Epoch [61/100], Loss: 0.1475, Validation Loss: 0.2517
	--> Epoch [62/100], Loss: 0.0840, Validation Loss: 0.2532
	--> Epoch [63/100], Loss: 0.0947, Validation Loss: 0.2518
Early stopping
	--> Training for Fold 2 took 1.0361156463623047 sec, using 63 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5540, Validation Loss: 0.7056
	--> Epoch [2/100], Loss: 0.4965, Validation Loss: 0.6679
	--> Epoch [3/100], Loss: 0.5096, Validation Loss: 0.6364
	--> Epoch [4/100], Loss: 0.4090, Validation Loss: 0.6043
	--> Epoch [5/100], Loss: 0.3220, Validation Loss: 0.5750
	--> Epoch [6/100], Loss: 0.3614, Validation Loss: 0.5497
	--> Epoch [7/100], Loss: 0.3329, Validation Loss: 0.5255
	--> Epoch [8/100], Loss: 0.3686, Validation Loss: 0.5077
	--> Epoch [9/100], Loss: 0.3112, Validation Loss: 0.4917
	--> Epoch [10/100], Loss: 0.3191, Validation Loss: 0.4750
	--> Epoch [11/100], Loss: 0.2401, Validation Loss: 0.4619
	--> Epoch [12/100], Loss: 0.3195, Validation Loss: 0.4516
	--> Epoch [13/100], Loss: 0.1718, Validation Loss: 0.4379
	--> Epoch [14/100], Loss: 0.1847, Validation Loss: 0.4294
	--> Epoch [15/100], Loss: 0.2077, Validation Loss: 0.4186
	--> Epoch [16/100], Loss: 0.1246, Validation Loss: 0.4062
	--> Epoch [17/100], Loss: 0.2043, Validation Loss: 0.4007
	--> Epoch [18/100], Loss: 0.2348, Validation Loss: 0.3937
	--> Epoch [19/100], Loss: 0.1109, Validation Loss: 0.3858
	--> Epoch [20/100], Loss: 0.2091, Validation Loss: 0.3795
	--> Epoch [21/100], Loss: 0.1443, Validation Loss: 0.3756
	--> Epoch [22/100], Loss: 0.1739, Validation Loss: 0.3701
	--> Epoch [23/100], Loss: 0.0748, Validation Loss: 0.3667
	--> Epoch [24/100], Loss: 0.0948, Validation Loss: 0.3622
	--> Epoch [25/100], Loss: 0.1693, Validation Loss: 0.3601
	--> Epoch [26/100], Loss: 0.1660, Validation Loss: 0.3571
	--> Epoch [27/100], Loss: 0.0606, Validation Loss: 0.3532
	--> Epoch [28/100], Loss: 0.0519, Validation Loss: 0.3492
	--> Epoch [29/100], Loss: 0.1990, Validation Loss: 0.3482
	--> Epoch [30/100], Loss: 0.1193, Validation Loss: 0.3442
	--> Epoch [31/100], Loss: 0.0699, Validation Loss: 0.3427
	--> Epoch [32/100], Loss: 0.0520, Validation Loss: 0.3411
	--> Epoch [33/100], Loss: 0.1176, Validation Loss: 0.3385
	--> Epoch [34/100], Loss: 0.0990, Validation Loss: 0.3377
	--> Epoch [35/100], Loss: 0.1191, Validation Loss: 0.3390
	--> Epoch [36/100], Loss: 0.1895, Validation Loss: 0.3350
	--> Epoch [37/100], Loss: 0.0422, Validation Loss: 0.3338
	--> Epoch [38/100], Loss: 0.0465, Validation Loss: 0.3337
	--> Epoch [39/100], Loss: 0.1542, Validation Loss: 0.3297
	--> Epoch [40/100], Loss: 0.0218, Validation Loss: 0.3276
	--> Epoch [41/100], Loss: 0.0347, Validation Loss: 0.3268
	--> Epoch [42/100], Loss: 0.0545, Validation Loss: 0.3284
	--> Epoch [43/100], Loss: 0.0267, Validation Loss: 0.3255
	--> Epoch [44/100], Loss: 0.0865, Validation Loss: 0.3232
	--> Epoch [45/100], Loss: 0.0217, Validation Loss: 0.3246
	--> Epoch [46/100], Loss: 0.1048, Validation Loss: 0.3258
	--> Epoch [47/100], Loss: 0.0256, Validation Loss: 0.3250
Early stopping
	--> Training for Fold 3 took 0.7701642513275146 sec, using 47 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6539, Validation Loss: 0.7185
	--> Epoch [2/100], Loss: 0.6090, Validation Loss: 0.6884
	--> Epoch [3/100], Loss: 0.5209, Validation Loss: 0.6473
	--> Epoch [4/100], Loss: 0.4806, Validation Loss: 0.6136
	--> Epoch [5/100], Loss: 0.5173, Validation Loss: 0.5755
	--> Epoch [6/100], Loss: 0.4123, Validation Loss: 0.5440
	--> Epoch [7/100], Loss: 0.4609, Validation Loss: 0.5135
	--> Epoch [8/100], Loss: 0.3684, Validation Loss: 0.4804
	--> Epoch [9/100], Loss: 0.3534, Validation Loss: 0.4531
	--> Epoch [10/100], Loss: 0.2497, Validation Loss: 0.4323
	--> Epoch [11/100], Loss: 0.3626, Validation Loss: 0.4145
	--> Epoch [12/100], Loss: 0.2735, Validation Loss: 0.3950
	--> Epoch [13/100], Loss: 0.2965, Validation Loss: 0.3782
	--> Epoch [14/100], Loss: 0.2076, Validation Loss: 0.3633
	--> Epoch [15/100], Loss: 0.1240, Validation Loss: 0.3517
	--> Epoch [16/100], Loss: 0.1684, Validation Loss: 0.3398
	--> Epoch [17/100], Loss: 0.1077, Validation Loss: 0.3282
	--> Epoch [18/100], Loss: 0.2159, Validation Loss: 0.3185
	--> Epoch [19/100], Loss: 0.2095, Validation Loss: 0.3103
	--> Epoch [20/100], Loss: 0.2076, Validation Loss: 0.3062
	--> Epoch [21/100], Loss: 0.1350, Validation Loss: 0.2969
	--> Epoch [22/100], Loss: 0.1903, Validation Loss: 0.2904
	--> Epoch [23/100], Loss: 0.1410, Validation Loss: 0.2833
	--> Epoch [24/100], Loss: 0.1086, Validation Loss: 0.2767
	--> Epoch [25/100], Loss: 0.1111, Validation Loss: 0.2756
	--> Epoch [26/100], Loss: 0.1473, Validation Loss: 0.2736
	--> Epoch [27/100], Loss: 0.1481, Validation Loss: 0.2734
	--> Epoch [28/100], Loss: 0.1473, Validation Loss: 0.2708
	--> Epoch [29/100], Loss: 0.2067, Validation Loss: 0.2669
	--> Epoch [30/100], Loss: 0.0864, Validation Loss: 0.2668
	--> Epoch [31/100], Loss: 0.0408, Validation Loss: 0.2664
	--> Epoch [32/100], Loss: 0.0453, Validation Loss: 0.2627
	--> Epoch [33/100], Loss: 0.1060, Validation Loss: 0.2578
	--> Epoch [34/100], Loss: 0.0397, Validation Loss: 0.2573
	--> Epoch [35/100], Loss: 0.0495, Validation Loss: 0.2561
	--> Epoch [36/100], Loss: 0.0479, Validation Loss: 0.2555
	--> Epoch [37/100], Loss: 0.0615, Validation Loss: 0.2538
	--> Epoch [38/100], Loss: 0.0795, Validation Loss: 0.2518
	--> Epoch [39/100], Loss: 0.0650, Validation Loss: 0.2514
	--> Epoch [40/100], Loss: 0.0806, Validation Loss: 0.2511
	--> Epoch [41/100], Loss: 0.0776, Validation Loss: 0.2530
	--> Epoch [42/100], Loss: 0.0472, Validation Loss: 0.2532
	--> Epoch [43/100], Loss: 0.0972, Validation Loss: 0.2571
Early stopping
	--> Training for Fold 4 took 0.7228982448577881 sec, using 43 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5183, Validation Loss: 0.7813
	--> Epoch [2/100], Loss: 0.5249, Validation Loss: 0.7645
	--> Epoch [3/100], Loss: 0.5301, Validation Loss: 0.7442
	--> Epoch [4/100], Loss: 0.4970, Validation Loss: 0.7221
	--> Epoch [5/100], Loss: 0.4873, Validation Loss: 0.7037
	--> Epoch [6/100], Loss: 0.4422, Validation Loss: 0.6923
	--> Epoch [7/100], Loss: 0.4060, Validation Loss: 0.6791
	--> Epoch [8/100], Loss: 0.3694, Validation Loss: 0.6676
	--> Epoch [9/100], Loss: 0.3592, Validation Loss: 0.6526
	--> Epoch [10/100], Loss: 0.3373, Validation Loss: 0.6360
	--> Epoch [11/100], Loss: 0.3062, Validation Loss: 0.6274
	--> Epoch [12/100], Loss: 0.2782, Validation Loss: 0.6179
	--> Epoch [13/100], Loss: 0.2065, Validation Loss: 0.6081
	--> Epoch [14/100], Loss: 0.2566, Validation Loss: 0.6014
	--> Epoch [15/100], Loss: 0.2534, Validation Loss: 0.5952
	--> Epoch [16/100], Loss: 0.1803, Validation Loss: 0.5864
	--> Epoch [17/100], Loss: 0.2797, Validation Loss: 0.5802
	--> Epoch [18/100], Loss: 0.2499, Validation Loss: 0.5764
	--> Epoch [19/100], Loss: 0.2242, Validation Loss: 0.5709
	--> Epoch [20/100], Loss: 0.1606, Validation Loss: 0.5682
	--> Epoch [21/100], Loss: 0.1937, Validation Loss: 0.5665
	--> Epoch [22/100], Loss: 0.1352, Validation Loss: 0.5612
	--> Epoch [23/100], Loss: 0.1435, Validation Loss: 0.5578
	--> Epoch [24/100], Loss: 0.1410, Validation Loss: 0.5560
	--> Epoch [25/100], Loss: 0.0924, Validation Loss: 0.5528
	--> Epoch [26/100], Loss: 0.1197, Validation Loss: 0.5504
	--> Epoch [27/100], Loss: 0.1299, Validation Loss: 0.5518
	--> Epoch [28/100], Loss: 0.0689, Validation Loss: 0.5464
	--> Epoch [29/100], Loss: 0.1177, Validation Loss: 0.5418
	--> Epoch [30/100], Loss: 0.1008, Validation Loss: 0.5451
	--> Epoch [31/100], Loss: 0.1190, Validation Loss: 0.5461
	--> Epoch [32/100], Loss: 0.0991, Validation Loss: 0.5470
Early stopping
	--> Training for Fold 5 took 0.5455765724182129 sec, using 32 epochs

Median number of epochs used: 47 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/47], Loss: 0.6488
	--> Final training Epoch [2/47], Loss: 0.6353
	--> Final training Epoch [3/47], Loss: 0.5723
	--> Final training Epoch [4/47], Loss: 0.5460
	--> Final training Epoch [5/47], Loss: 0.4879
	--> Final training Epoch [6/47], Loss: 0.4326
	--> Final training Epoch [7/47], Loss: 0.4287
	--> Final training Epoch [8/47], Loss: 0.4245
	--> Final training Epoch [9/47], Loss: 0.4150
	--> Final training Epoch [10/47], Loss: 0.4214
	--> Final training Epoch [11/47], Loss: 0.2452
	--> Final training Epoch [12/47], Loss: 0.2838
	--> Final training Epoch [13/47], Loss: 0.2950
	--> Final training Epoch [14/47], Loss: 0.2641
	--> Final training Epoch [15/47], Loss: 0.1710
	--> Final training Epoch [16/47], Loss: 0.2797
	--> Final training Epoch [17/47], Loss: 0.1750
	--> Final training Epoch [18/47], Loss: 0.1568
	--> Final training Epoch [19/47], Loss: 0.1783
	--> Final training Epoch [20/47], Loss: 0.1919
	--> Final training Epoch [21/47], Loss: 0.1624
	--> Final training Epoch [22/47], Loss: 0.1260
	--> Final training Epoch [23/47], Loss: 0.1229
	--> Final training Epoch [24/47], Loss: 0.1964
	--> Final training Epoch [25/47], Loss: 0.1265
	--> Final training Epoch [26/47], Loss: 0.1467
	--> Final training Epoch [27/47], Loss: 0.1262
	--> Final training Epoch [28/47], Loss: 0.1113
	--> Final training Epoch [29/47], Loss: 0.0698
	--> Final training Epoch [30/47], Loss: 0.0609
	--> Final training Epoch [31/47], Loss: 0.0693
	--> Final training Epoch [32/47], Loss: 0.1046
	--> Final training Epoch [33/47], Loss: 0.0975
	--> Final training Epoch [34/47], Loss: 0.0851
	--> Final training Epoch [35/47], Loss: 0.0435
	--> Final training Epoch [36/47], Loss: 0.0958
	--> Final training Epoch [37/47], Loss: 0.0355
	--> Final training Epoch [38/47], Loss: 0.0544
	--> Final training Epoch [39/47], Loss: 0.1549
	--> Final training Epoch [40/47], Loss: 0.0237
	--> Final training Epoch [41/47], Loss: 0.0561
	--> Final training Epoch [42/47], Loss: 0.0479
	--> Final training Epoch [43/47], Loss: 0.0868
	--> Final training Epoch [44/47], Loss: 0.0318
	--> Final training Epoch [45/47], Loss: 0.0430
	--> Final training Epoch [46/47], Loss: 0.0340
	--> Final training Epoch [47/47], Loss: 0.0848

Final training took 0.8974430561065674 sec

TESTING
	--> Testing took 0.0157 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9376
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3275,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3275
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3869,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3275

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5590, Validation Loss: 0.6006
	--> Epoch [2/100], Loss: 0.5890, Validation Loss: 0.5728
	--> Epoch [3/100], Loss: 0.4838, Validation Loss: 0.5614
	--> Epoch [4/100], Loss: 0.3951, Validation Loss: 0.5458
	--> Epoch [5/100], Loss: 0.4546, Validation Loss: 0.5301
	--> Epoch [6/100], Loss: 0.4436, Validation Loss: 0.5137
	--> Epoch [7/100], Loss: 0.4387, Validation Loss: 0.4966
	--> Epoch [8/100], Loss: 0.4580, Validation Loss: 0.4798
	--> Epoch [9/100], Loss: 0.3867, Validation Loss: 0.4659
	--> Epoch [10/100], Loss: 0.4074, Validation Loss: 0.4521
	--> Epoch [11/100], Loss: 0.3917, Validation Loss: 0.4386
	--> Epoch [12/100], Loss: 0.3936, Validation Loss: 0.4294
	--> Epoch [13/100], Loss: 0.2330, Validation Loss: 0.4130
	--> Epoch [14/100], Loss: 0.3242, Validation Loss: 0.3988
	--> Epoch [15/100], Loss: 0.3690, Validation Loss: 0.3926
	--> Epoch [16/100], Loss: 0.1895, Validation Loss: 0.3817
	--> Epoch [17/100], Loss: 0.3696, Validation Loss: 0.3765
	--> Epoch [18/100], Loss: 0.2391, Validation Loss: 0.3691
	--> Epoch [19/100], Loss: 0.2581, Validation Loss: 0.3590
	--> Epoch [20/100], Loss: 0.4139, Validation Loss: 0.3482
	--> Epoch [21/100], Loss: 0.2085, Validation Loss: 0.3442
	--> Epoch [22/100], Loss: 0.1942, Validation Loss: 0.3393
	--> Epoch [23/100], Loss: 0.2059, Validation Loss: 0.3361
	--> Epoch [24/100], Loss: 0.2650, Validation Loss: 0.3297
	--> Epoch [25/100], Loss: 0.2412, Validation Loss: 0.3254
	--> Epoch [26/100], Loss: 0.2581, Validation Loss: 0.3213
	--> Epoch [27/100], Loss: 0.2962, Validation Loss: 0.3186
	--> Epoch [28/100], Loss: 0.1989, Validation Loss: 0.3155
	--> Epoch [29/100], Loss: 0.1699, Validation Loss: 0.3110
	--> Epoch [30/100], Loss: 0.1762, Validation Loss: 0.3093
	--> Epoch [31/100], Loss: 0.1703, Validation Loss: 0.3072
	--> Epoch [32/100], Loss: 0.2070, Validation Loss: 0.3024
	--> Epoch [33/100], Loss: 0.1825, Validation Loss: 0.2981
	--> Epoch [34/100], Loss: 0.1218, Validation Loss: 0.2956
	--> Epoch [35/100], Loss: 0.0770, Validation Loss: 0.2933
	--> Epoch [36/100], Loss: 0.1464, Validation Loss: 0.2920
	--> Epoch [37/100], Loss: 0.1867, Validation Loss: 0.2897
	--> Epoch [38/100], Loss: 0.0789, Validation Loss: 0.2877
	--> Epoch [39/100], Loss: 0.0789, Validation Loss: 0.2873
	--> Epoch [40/100], Loss: 0.1436, Validation Loss: 0.2862
	--> Epoch [41/100], Loss: 0.2226, Validation Loss: 0.2859
	--> Epoch [42/100], Loss: 0.2050, Validation Loss: 0.2845
	--> Epoch [43/100], Loss: 0.0825, Validation Loss: 0.2846
	--> Epoch [44/100], Loss: 0.1401, Validation Loss: 0.2845
	--> Epoch [45/100], Loss: 0.0315, Validation Loss: 0.2801
	--> Epoch [46/100], Loss: 0.2225, Validation Loss: 0.2797
	--> Epoch [47/100], Loss: 0.0915, Validation Loss: 0.2811
	--> Epoch [48/100], Loss: 0.2478, Validation Loss: 0.2806
	--> Epoch [49/100], Loss: 0.1595, Validation Loss: 0.2796
	--> Epoch [50/100], Loss: 0.2204, Validation Loss: 0.2773
	--> Epoch [51/100], Loss: 0.2027, Validation Loss: 0.2769
	--> Epoch [52/100], Loss: 0.1786, Validation Loss: 0.2775
	--> Epoch [53/100], Loss: 0.0947, Validation Loss: 0.2765
	--> Epoch [54/100], Loss: 0.0237, Validation Loss: 0.2764
	--> Epoch [55/100], Loss: 0.1475, Validation Loss: 0.2775
	--> Epoch [56/100], Loss: 0.1200, Validation Loss: 0.2766
	--> Epoch [57/100], Loss: 0.1094, Validation Loss: 0.2768
Early stopping
	--> Training for Fold 1 took 0.9103648662567139 sec, using 57 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6052, Validation Loss: 0.6925
	--> Epoch [2/100], Loss: 0.6049, Validation Loss: 0.6667
	--> Epoch [3/100], Loss: 0.5532, Validation Loss: 0.6336
	--> Epoch [4/100], Loss: 0.4753, Validation Loss: 0.6040
	--> Epoch [5/100], Loss: 0.5207, Validation Loss: 0.5747
	--> Epoch [6/100], Loss: 0.4981, Validation Loss: 0.5490
	--> Epoch [7/100], Loss: 0.4670, Validation Loss: 0.5189
	--> Epoch [8/100], Loss: 0.3990, Validation Loss: 0.4938
	--> Epoch [9/100], Loss: 0.4777, Validation Loss: 0.4762
	--> Epoch [10/100], Loss: 0.4458, Validation Loss: 0.4601
	--> Epoch [11/100], Loss: 0.4418, Validation Loss: 0.4424
	--> Epoch [12/100], Loss: 0.3921, Validation Loss: 0.4280
	--> Epoch [13/100], Loss: 0.3702, Validation Loss: 0.4136
	--> Epoch [14/100], Loss: 0.2989, Validation Loss: 0.4019
	--> Epoch [15/100], Loss: 0.3434, Validation Loss: 0.3919
	--> Epoch [16/100], Loss: 0.2681, Validation Loss: 0.3829
	--> Epoch [17/100], Loss: 0.2878, Validation Loss: 0.3716
	--> Epoch [18/100], Loss: 0.3616, Validation Loss: 0.3586
	--> Epoch [19/100], Loss: 0.3250, Validation Loss: 0.3502
	--> Epoch [20/100], Loss: 0.2703, Validation Loss: 0.3421
	--> Epoch [21/100], Loss: 0.2547, Validation Loss: 0.3360
	--> Epoch [22/100], Loss: 0.3095, Validation Loss: 0.3265
	--> Epoch [23/100], Loss: 0.2675, Validation Loss: 0.3198
	--> Epoch [24/100], Loss: 0.2153, Validation Loss: 0.3164
	--> Epoch [25/100], Loss: 0.1442, Validation Loss: 0.3068
	--> Epoch [26/100], Loss: 0.3059, Validation Loss: 0.3038
	--> Epoch [27/100], Loss: 0.1881, Validation Loss: 0.3003
	--> Epoch [28/100], Loss: 0.2157, Validation Loss: 0.2959
	--> Epoch [29/100], Loss: 0.1868, Validation Loss: 0.2901
	--> Epoch [30/100], Loss: 0.1423, Validation Loss: 0.2837
	--> Epoch [31/100], Loss: 0.2039, Validation Loss: 0.2799
	--> Epoch [32/100], Loss: 0.1443, Validation Loss: 0.2776
	--> Epoch [33/100], Loss: 0.1154, Validation Loss: 0.2723
	--> Epoch [34/100], Loss: 0.1914, Validation Loss: 0.2670
	--> Epoch [35/100], Loss: 0.1856, Validation Loss: 0.2620
	--> Epoch [36/100], Loss: 0.0586, Validation Loss: 0.2585
	--> Epoch [37/100], Loss: 0.1791, Validation Loss: 0.2567
	--> Epoch [38/100], Loss: 0.0976, Validation Loss: 0.2551
	--> Epoch [39/100], Loss: 0.0945, Validation Loss: 0.2547
	--> Epoch [40/100], Loss: 0.1912, Validation Loss: 0.2529
	--> Epoch [41/100], Loss: 0.0947, Validation Loss: 0.2481
	--> Epoch [42/100], Loss: 0.1473, Validation Loss: 0.2459
	--> Epoch [43/100], Loss: 0.1913, Validation Loss: 0.2430
	--> Epoch [44/100], Loss: 0.0911, Validation Loss: 0.2427
	--> Epoch [45/100], Loss: 0.1538, Validation Loss: 0.2389
	--> Epoch [46/100], Loss: 0.1335, Validation Loss: 0.2375
	--> Epoch [47/100], Loss: 0.2474, Validation Loss: 0.2346
	--> Epoch [48/100], Loss: 0.0878, Validation Loss: 0.2355
	--> Epoch [49/100], Loss: 0.1338, Validation Loss: 0.2331
	--> Epoch [50/100], Loss: 0.1231, Validation Loss: 0.2283
	--> Epoch [51/100], Loss: 0.1263, Validation Loss: 0.2247
	--> Epoch [52/100], Loss: 0.2773, Validation Loss: 0.2225
	--> Epoch [53/100], Loss: 0.1815, Validation Loss: 0.2194
	--> Epoch [54/100], Loss: 0.1066, Validation Loss: 0.2183
	--> Epoch [55/100], Loss: 0.1829, Validation Loss: 0.2133
	--> Epoch [56/100], Loss: 0.1282, Validation Loss: 0.2131
	--> Epoch [57/100], Loss: 0.2302, Validation Loss: 0.2024
	--> Epoch [58/100], Loss: 0.1685, Validation Loss: 0.2028
	--> Epoch [59/100], Loss: 0.1721, Validation Loss: 0.2018
	--> Epoch [60/100], Loss: 0.0181, Validation Loss: 0.2001
	--> Epoch [61/100], Loss: 0.3147, Validation Loss: 0.2007
	--> Epoch [62/100], Loss: 0.2240, Validation Loss: 0.2017
	--> Epoch [63/100], Loss: 0.1656, Validation Loss: 0.2023
Early stopping
	--> Training for Fold 2 took 1.0052495002746582 sec, using 63 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5641, Validation Loss: 0.7887
	--> Epoch [2/100], Loss: 0.4752, Validation Loss: 0.7688
	--> Epoch [3/100], Loss: 0.4775, Validation Loss: 0.7501
	--> Epoch [4/100], Loss: 0.4325, Validation Loss: 0.7331
	--> Epoch [5/100], Loss: 0.3997, Validation Loss: 0.7175
	--> Epoch [6/100], Loss: 0.4618, Validation Loss: 0.7000
	--> Epoch [7/100], Loss: 0.3867, Validation Loss: 0.6827
	--> Epoch [8/100], Loss: 0.4353, Validation Loss: 0.6664
	--> Epoch [9/100], Loss: 0.4021, Validation Loss: 0.6503
	--> Epoch [10/100], Loss: 0.3373, Validation Loss: 0.6339
	--> Epoch [11/100], Loss: 0.3299, Validation Loss: 0.6146
	--> Epoch [12/100], Loss: 0.1905, Validation Loss: 0.5987
	--> Epoch [13/100], Loss: 0.3495, Validation Loss: 0.5839
	--> Epoch [14/100], Loss: 0.3964, Validation Loss: 0.5724
	--> Epoch [15/100], Loss: 0.3446, Validation Loss: 0.5646
	--> Epoch [16/100], Loss: 0.3072, Validation Loss: 0.5518
	--> Epoch [17/100], Loss: 0.2747, Validation Loss: 0.5382
	--> Epoch [18/100], Loss: 0.3375, Validation Loss: 0.5313
	--> Epoch [19/100], Loss: 0.3195, Validation Loss: 0.5235
	--> Epoch [20/100], Loss: 0.2711, Validation Loss: 0.5154
	--> Epoch [21/100], Loss: 0.1705, Validation Loss: 0.5098
	--> Epoch [22/100], Loss: 0.2270, Validation Loss: 0.5016
	--> Epoch [23/100], Loss: 0.1993, Validation Loss: 0.4964
	--> Epoch [24/100], Loss: 0.2006, Validation Loss: 0.4911
	--> Epoch [25/100], Loss: 0.1275, Validation Loss: 0.4835
	--> Epoch [26/100], Loss: 0.1793, Validation Loss: 0.4770
	--> Epoch [27/100], Loss: 0.2060, Validation Loss: 0.4709
	--> Epoch [28/100], Loss: 0.2191, Validation Loss: 0.4630
	--> Epoch [29/100], Loss: 0.1332, Validation Loss: 0.4583
	--> Epoch [30/100], Loss: 0.1017, Validation Loss: 0.4524
	--> Epoch [31/100], Loss: 0.2074, Validation Loss: 0.4502
	--> Epoch [32/100], Loss: 0.2558, Validation Loss: 0.4466
	--> Epoch [33/100], Loss: 0.0929, Validation Loss: 0.4418
	--> Epoch [34/100], Loss: 0.1960, Validation Loss: 0.4363
	--> Epoch [35/100], Loss: 0.1019, Validation Loss: 0.4356
	--> Epoch [36/100], Loss: 0.1713, Validation Loss: 0.4321
	--> Epoch [37/100], Loss: 0.2662, Validation Loss: 0.4280
	--> Epoch [38/100], Loss: 0.0772, Validation Loss: 0.4239
	--> Epoch [39/100], Loss: 0.1481, Validation Loss: 0.4226
	--> Epoch [40/100], Loss: 0.2141, Validation Loss: 0.4209
	--> Epoch [41/100], Loss: 0.0848, Validation Loss: 0.4141
	--> Epoch [42/100], Loss: 0.1576, Validation Loss: 0.4105
	--> Epoch [43/100], Loss: 0.2345, Validation Loss: 0.4065
	--> Epoch [44/100], Loss: 0.2522, Validation Loss: 0.4021
	--> Epoch [45/100], Loss: 0.1809, Validation Loss: 0.4040
	--> Epoch [46/100], Loss: 0.1682, Validation Loss: 0.4022
	--> Epoch [47/100], Loss: 0.1678, Validation Loss: 0.4014
	--> Epoch [48/100], Loss: 0.1653, Validation Loss: 0.4008
	--> Epoch [49/100], Loss: 0.1359, Validation Loss: 0.4042
	--> Epoch [50/100], Loss: 0.1541, Validation Loss: 0.4033
	--> Epoch [51/100], Loss: 0.1718, Validation Loss: 0.4048
Early stopping
	--> Training for Fold 3 took 0.8166146278381348 sec, using 51 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7758, Validation Loss: 0.7848
	--> Epoch [2/100], Loss: 0.7305, Validation Loss: 0.7651
	--> Epoch [3/100], Loss: 0.5913, Validation Loss: 0.7476
	--> Epoch [4/100], Loss: 0.5816, Validation Loss: 0.7101
	--> Epoch [5/100], Loss: 0.5441, Validation Loss: 0.6892
	--> Epoch [6/100], Loss: 0.5414, Validation Loss: 0.6623
	--> Epoch [7/100], Loss: 0.5180, Validation Loss: 0.6471
	--> Epoch [8/100], Loss: 0.4086, Validation Loss: 0.6216
	--> Epoch [9/100], Loss: 0.4277, Validation Loss: 0.6025
	--> Epoch [10/100], Loss: 0.3412, Validation Loss: 0.5874
	--> Epoch [11/100], Loss: 0.3931, Validation Loss: 0.5690
	--> Epoch [12/100], Loss: 0.3843, Validation Loss: 0.5501
	--> Epoch [13/100], Loss: 0.3070, Validation Loss: 0.5269
	--> Epoch [14/100], Loss: 0.3547, Validation Loss: 0.5224
	--> Epoch [15/100], Loss: 0.3210, Validation Loss: 0.5105
	--> Epoch [16/100], Loss: 0.3142, Validation Loss: 0.4973
	--> Epoch [17/100], Loss: 0.2642, Validation Loss: 0.4826
	--> Epoch [18/100], Loss: 0.2949, Validation Loss: 0.4745
	--> Epoch [19/100], Loss: 0.2174, Validation Loss: 0.4599
	--> Epoch [20/100], Loss: 0.2512, Validation Loss: 0.4498
	--> Epoch [21/100], Loss: 0.2357, Validation Loss: 0.4400
	--> Epoch [22/100], Loss: 0.1830, Validation Loss: 0.4399
	--> Epoch [23/100], Loss: 0.1023, Validation Loss: 0.4367
	--> Epoch [24/100], Loss: 0.1356, Validation Loss: 0.4320
	--> Epoch [25/100], Loss: 0.1589, Validation Loss: 0.4236
	--> Epoch [26/100], Loss: 0.2112, Validation Loss: 0.4178
	--> Epoch [27/100], Loss: 0.1676, Validation Loss: 0.4070
	--> Epoch [28/100], Loss: 0.1293, Validation Loss: 0.4042
	--> Epoch [29/100], Loss: 0.0907, Validation Loss: 0.4027
	--> Epoch [30/100], Loss: 0.2457, Validation Loss: 0.3959
	--> Epoch [31/100], Loss: 0.1284, Validation Loss: 0.3902
	--> Epoch [32/100], Loss: 0.1988, Validation Loss: 0.3892
	--> Epoch [33/100], Loss: 0.2391, Validation Loss: 0.3866
	--> Epoch [34/100], Loss: 0.0825, Validation Loss: 0.3824
	--> Epoch [35/100], Loss: 0.1695, Validation Loss: 0.3860
	--> Epoch [36/100], Loss: 0.1144, Validation Loss: 0.3829
	--> Epoch [37/100], Loss: 0.1586, Validation Loss: 0.3796
	--> Epoch [38/100], Loss: 0.2536, Validation Loss: 0.3775
	--> Epoch [39/100], Loss: 0.2188, Validation Loss: 0.3758
	--> Epoch [40/100], Loss: 0.1054, Validation Loss: 0.3723
	--> Epoch [41/100], Loss: 0.1083, Validation Loss: 0.3708
	--> Epoch [42/100], Loss: 0.0598, Validation Loss: 0.3706
	--> Epoch [43/100], Loss: 0.1277, Validation Loss: 0.3724
	--> Epoch [44/100], Loss: 0.1111, Validation Loss: 0.3712
	--> Epoch [45/100], Loss: 0.0184, Validation Loss: 0.3654
	--> Epoch [46/100], Loss: 0.1781, Validation Loss: 0.3641
	--> Epoch [47/100], Loss: 0.1621, Validation Loss: 0.3612
	--> Epoch [48/100], Loss: 0.0436, Validation Loss: 0.3592
	--> Epoch [49/100], Loss: 0.0573, Validation Loss: 0.3535
	--> Epoch [50/100], Loss: 0.1463, Validation Loss: 0.3527
	--> Epoch [51/100], Loss: 0.1155, Validation Loss: 0.3523
	--> Epoch [52/100], Loss: 0.1331, Validation Loss: 0.3584
	--> Epoch [53/100], Loss: 0.0800, Validation Loss: 0.3574
	--> Epoch [54/100], Loss: 0.1528, Validation Loss: 0.3598
Early stopping
	--> Training for Fold 4 took 0.8455865383148193 sec, using 54 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6947, Validation Loss: 0.6514
	--> Epoch [2/100], Loss: 0.7014, Validation Loss: 0.6390
	--> Epoch [3/100], Loss: 0.5703, Validation Loss: 0.6303
	--> Epoch [4/100], Loss: 0.5912, Validation Loss: 0.6195
	--> Epoch [5/100], Loss: 0.5992, Validation Loss: 0.6129
	--> Epoch [6/100], Loss: 0.5507, Validation Loss: 0.6072
	--> Epoch [7/100], Loss: 0.5455, Validation Loss: 0.6028
	--> Epoch [8/100], Loss: 0.4495, Validation Loss: 0.5942
	--> Epoch [9/100], Loss: 0.4761, Validation Loss: 0.5841
	--> Epoch [10/100], Loss: 0.4561, Validation Loss: 0.5776
	--> Epoch [11/100], Loss: 0.3991, Validation Loss: 0.5755
	--> Epoch [12/100], Loss: 0.3618, Validation Loss: 0.5700
	--> Epoch [13/100], Loss: 0.3782, Validation Loss: 0.5649
	--> Epoch [14/100], Loss: 0.2436, Validation Loss: 0.5595
	--> Epoch [15/100], Loss: 0.3341, Validation Loss: 0.5540
	--> Epoch [16/100], Loss: 0.3776, Validation Loss: 0.5472
	--> Epoch [17/100], Loss: 0.3618, Validation Loss: 0.5434
	--> Epoch [18/100], Loss: 0.3165, Validation Loss: 0.5442
	--> Epoch [19/100], Loss: 0.3281, Validation Loss: 0.5375
	--> Epoch [20/100], Loss: 0.2747, Validation Loss: 0.5393
	--> Epoch [21/100], Loss: 0.2585, Validation Loss: 0.5332
	--> Epoch [22/100], Loss: 0.1780, Validation Loss: 0.5299
	--> Epoch [23/100], Loss: 0.1776, Validation Loss: 0.5281
	--> Epoch [24/100], Loss: 0.2075, Validation Loss: 0.5290
	--> Epoch [25/100], Loss: 0.3060, Validation Loss: 0.5319
	--> Epoch [26/100], Loss: 0.1860, Validation Loss: 0.5303
Early stopping
	--> Training for Fold 5 took 0.42647266387939453 sec, using 26 epochs

Median number of epochs used: 54 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/54], Loss: 0.6688
	--> Final training Epoch [2/54], Loss: 0.6779
	--> Final training Epoch [3/54], Loss: 0.6541
	--> Final training Epoch [4/54], Loss: 0.6168
	--> Final training Epoch [5/54], Loss: 0.6354
	--> Final training Epoch [6/54], Loss: 0.5533
	--> Final training Epoch [7/54], Loss: 0.5530
	--> Final training Epoch [8/54], Loss: 0.5514
	--> Final training Epoch [9/54], Loss: 0.5118
	--> Final training Epoch [10/54], Loss: 0.5195
	--> Final training Epoch [11/54], Loss: 0.4465
	--> Final training Epoch [12/54], Loss: 0.3979
	--> Final training Epoch [13/54], Loss: 0.3682
	--> Final training Epoch [14/54], Loss: 0.3738
	--> Final training Epoch [15/54], Loss: 0.3856
	--> Final training Epoch [16/54], Loss: 0.3895
	--> Final training Epoch [17/54], Loss: 0.3463
	--> Final training Epoch [18/54], Loss: 0.3863
	--> Final training Epoch [19/54], Loss: 0.2191
	--> Final training Epoch [20/54], Loss: 0.3007
	--> Final training Epoch [21/54], Loss: 0.3737
	--> Final training Epoch [22/54], Loss: 0.1980
	--> Final training Epoch [23/54], Loss: 0.2599
	--> Final training Epoch [24/54], Loss: 0.3734
	--> Final training Epoch [25/54], Loss: 0.3252
	--> Final training Epoch [26/54], Loss: 0.2166
	--> Final training Epoch [27/54], Loss: 0.1841
	--> Final training Epoch [28/54], Loss: 0.1975
	--> Final training Epoch [29/54], Loss: 0.1443
	--> Final training Epoch [30/54], Loss: 0.2666
	--> Final training Epoch [31/54], Loss: 0.2257
	--> Final training Epoch [32/54], Loss: 0.1357
	--> Final training Epoch [33/54], Loss: 0.1722
	--> Final training Epoch [34/54], Loss: 0.1557
	--> Final training Epoch [35/54], Loss: 0.2063
	--> Final training Epoch [36/54], Loss: 0.2300
	--> Final training Epoch [37/54], Loss: 0.1532
	--> Final training Epoch [38/54], Loss: 0.1304
	--> Final training Epoch [39/54], Loss: 0.2051
	--> Final training Epoch [40/54], Loss: 0.0878
	--> Final training Epoch [41/54], Loss: 0.1666
	--> Final training Epoch [42/54], Loss: 0.1785
	--> Final training Epoch [43/54], Loss: 0.1631
	--> Final training Epoch [44/54], Loss: 0.1905
	--> Final training Epoch [45/54], Loss: 0.1884
	--> Final training Epoch [46/54], Loss: 0.2495
	--> Final training Epoch [47/54], Loss: 0.1981
	--> Final training Epoch [48/54], Loss: 0.2154
	--> Final training Epoch [49/54], Loss: 0.1460
	--> Final training Epoch [50/54], Loss: 0.2031
	--> Final training Epoch [51/54], Loss: 0.2570
	--> Final training Epoch [52/54], Loss: 0.0775
	--> Final training Epoch [53/54], Loss: 0.1633
	--> Final training Epoch [54/54], Loss: 0.1081

Final training took 0.9873936176300049 sec

TESTING
	--> Testing took 0.0157 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8321
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3611,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3611
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3614,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3611
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.3752,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3611

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6685, Validation Loss: 0.7026
	--> Epoch [2/100], Loss: 0.5860, Validation Loss: 0.6800
	--> Epoch [3/100], Loss: 0.7744, Validation Loss: 0.6333
	--> Epoch [4/100], Loss: 0.5485, Validation Loss: 0.6071
	--> Epoch [5/100], Loss: 0.6077, Validation Loss: 0.5861
	--> Epoch [6/100], Loss: 0.5955, Validation Loss: 0.5715
	--> Epoch [7/100], Loss: 0.5002, Validation Loss: 0.5572
	--> Epoch [8/100], Loss: 0.4037, Validation Loss: 0.5370
	--> Epoch [9/100], Loss: 0.4717, Validation Loss: 0.5186
	--> Epoch [10/100], Loss: 0.4099, Validation Loss: 0.5079
	--> Epoch [11/100], Loss: 0.3904, Validation Loss: 0.4959
	--> Epoch [12/100], Loss: 0.5618, Validation Loss: 0.4842
	--> Epoch [13/100], Loss: 0.4730, Validation Loss: 0.4722
	--> Epoch [14/100], Loss: 0.5852, Validation Loss: 0.4653
	--> Epoch [15/100], Loss: 0.4899, Validation Loss: 0.4508
	--> Epoch [16/100], Loss: 0.4750, Validation Loss: 0.4438
	--> Epoch [17/100], Loss: 0.3941, Validation Loss: 0.4346
	--> Epoch [18/100], Loss: 0.5105, Validation Loss: 0.4259
	--> Epoch [19/100], Loss: 0.5265, Validation Loss: 0.4216
	--> Epoch [20/100], Loss: 0.3312, Validation Loss: 0.4142
	--> Epoch [21/100], Loss: 0.3405, Validation Loss: 0.4083
	--> Epoch [22/100], Loss: 0.4449, Validation Loss: 0.4027
	--> Epoch [23/100], Loss: 0.3744, Validation Loss: 0.3954
	--> Epoch [24/100], Loss: 0.3629, Validation Loss: 0.3855
	--> Epoch [25/100], Loss: 0.4438, Validation Loss: 0.3810
	--> Epoch [26/100], Loss: 0.3289, Validation Loss: 0.3745
	--> Epoch [27/100], Loss: 0.4381, Validation Loss: 0.3726
	--> Epoch [28/100], Loss: 0.2914, Validation Loss: 0.3659
	--> Epoch [29/100], Loss: 0.5443, Validation Loss: 0.3618
	--> Epoch [30/100], Loss: 0.3827, Validation Loss: 0.3570
	--> Epoch [31/100], Loss: 0.4825, Validation Loss: 0.3590
	--> Epoch [32/100], Loss: 0.4738, Validation Loss: 0.3516
	--> Epoch [33/100], Loss: 0.1878, Validation Loss: 0.3434
	--> Epoch [34/100], Loss: 0.3365, Validation Loss: 0.3349
	--> Epoch [35/100], Loss: 0.3701, Validation Loss: 0.3292
	--> Epoch [36/100], Loss: 0.3818, Validation Loss: 0.3286
	--> Epoch [37/100], Loss: 0.3319, Validation Loss: 0.3241
	--> Epoch [38/100], Loss: 0.2050, Validation Loss: 0.3175
	--> Epoch [39/100], Loss: 0.4025, Validation Loss: 0.3169
	--> Epoch [40/100], Loss: 0.4054, Validation Loss: 0.3149
	--> Epoch [41/100], Loss: 0.3283, Validation Loss: 0.3108
	--> Epoch [42/100], Loss: 0.3248, Validation Loss: 0.3137
	--> Epoch [43/100], Loss: 0.3945, Validation Loss: 0.3120
	--> Epoch [44/100], Loss: 0.3087, Validation Loss: 0.3070
	--> Epoch [45/100], Loss: 0.3542, Validation Loss: 0.3035
	--> Epoch [46/100], Loss: 0.1542, Validation Loss: 0.2996
	--> Epoch [47/100], Loss: 0.2688, Validation Loss: 0.2908
	--> Epoch [48/100], Loss: 0.3852, Validation Loss: 0.2872
	--> Epoch [49/100], Loss: 0.3551, Validation Loss: 0.2890
	--> Epoch [50/100], Loss: 0.3754, Validation Loss: 0.2851
	--> Epoch [51/100], Loss: 0.2227, Validation Loss: 0.2846
	--> Epoch [52/100], Loss: 0.2532, Validation Loss: 0.2829
	--> Epoch [53/100], Loss: 0.3618, Validation Loss: 0.2811
	--> Epoch [54/100], Loss: 0.2866, Validation Loss: 0.2782
	--> Epoch [55/100], Loss: 0.4051, Validation Loss: 0.2780
	--> Epoch [56/100], Loss: 0.4287, Validation Loss: 0.2786
	--> Epoch [57/100], Loss: 0.3939, Validation Loss: 0.2762
	--> Epoch [58/100], Loss: 0.1925, Validation Loss: 0.2730
	--> Epoch [59/100], Loss: 0.1907, Validation Loss: 0.2714
	--> Epoch [60/100], Loss: 0.1872, Validation Loss: 0.2698
	--> Epoch [61/100], Loss: 0.1957, Validation Loss: 0.2652
	--> Epoch [62/100], Loss: 0.1869, Validation Loss: 0.2644
	--> Epoch [63/100], Loss: 0.1199, Validation Loss: 0.2622
	--> Epoch [64/100], Loss: 0.2726, Validation Loss: 0.2607
	--> Epoch [65/100], Loss: 0.1336, Validation Loss: 0.2569
	--> Epoch [66/100], Loss: 0.3796, Validation Loss: 0.2557
	--> Epoch [67/100], Loss: 0.2398, Validation Loss: 0.2547
	--> Epoch [68/100], Loss: 0.4092, Validation Loss: 0.2548
	--> Epoch [69/100], Loss: 0.2675, Validation Loss: 0.2571
	--> Epoch [70/100], Loss: 0.2417, Validation Loss: 0.2549
Early stopping
	--> Training for Fold 1 took 1.1791176795959473 sec, using 70 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8013, Validation Loss: 0.6820
	--> Epoch [2/100], Loss: 0.7408, Validation Loss: 0.6718
	--> Epoch [3/100], Loss: 0.7123, Validation Loss: 0.6471
	--> Epoch [4/100], Loss: 0.7329, Validation Loss: 0.6234
	--> Epoch [5/100], Loss: 0.7127, Validation Loss: 0.5975
	--> Epoch [6/100], Loss: 0.7170, Validation Loss: 0.5796
	--> Epoch [7/100], Loss: 0.5690, Validation Loss: 0.5645
	--> Epoch [8/100], Loss: 0.6737, Validation Loss: 0.5507
	--> Epoch [9/100], Loss: 0.5986, Validation Loss: 0.5404
	--> Epoch [10/100], Loss: 0.6427, Validation Loss: 0.5249
	--> Epoch [11/100], Loss: 0.6093, Validation Loss: 0.5127
	--> Epoch [12/100], Loss: 0.6062, Validation Loss: 0.4942
	--> Epoch [13/100], Loss: 0.5025, Validation Loss: 0.4790
	--> Epoch [14/100], Loss: 0.4659, Validation Loss: 0.4631
	--> Epoch [15/100], Loss: 0.5133, Validation Loss: 0.4418
	--> Epoch [16/100], Loss: 0.4384, Validation Loss: 0.4328
	--> Epoch [17/100], Loss: 0.7255, Validation Loss: 0.4256
	--> Epoch [18/100], Loss: 0.4117, Validation Loss: 0.4132
	--> Epoch [19/100], Loss: 0.4211, Validation Loss: 0.4030
	--> Epoch [20/100], Loss: 0.3872, Validation Loss: 0.4003
	--> Epoch [21/100], Loss: 0.4559, Validation Loss: 0.3917
	--> Epoch [22/100], Loss: 0.5459, Validation Loss: 0.3824
	--> Epoch [23/100], Loss: 0.6905, Validation Loss: 0.3766
	--> Epoch [24/100], Loss: 0.4768, Validation Loss: 0.3687
	--> Epoch [25/100], Loss: 0.4181, Validation Loss: 0.3633
	--> Epoch [26/100], Loss: 0.4282, Validation Loss: 0.3580
	--> Epoch [27/100], Loss: 0.3575, Validation Loss: 0.3512
	--> Epoch [28/100], Loss: 0.4580, Validation Loss: 0.3476
	--> Epoch [29/100], Loss: 0.3831, Validation Loss: 0.3438
	--> Epoch [30/100], Loss: 0.4621, Validation Loss: 0.3374
	--> Epoch [31/100], Loss: 0.3298, Validation Loss: 0.3322
	--> Epoch [32/100], Loss: 0.4159, Validation Loss: 0.3279
	--> Epoch [33/100], Loss: 0.3975, Validation Loss: 0.3274
	--> Epoch [34/100], Loss: 0.5578, Validation Loss: 0.3228
	--> Epoch [35/100], Loss: 0.2876, Validation Loss: 0.3185
	--> Epoch [36/100], Loss: 0.2656, Validation Loss: 0.3129
	--> Epoch [37/100], Loss: 0.4783, Validation Loss: 0.3095
	--> Epoch [38/100], Loss: 0.2460, Validation Loss: 0.3055
	--> Epoch [39/100], Loss: 0.3296, Validation Loss: 0.3039
	--> Epoch [40/100], Loss: 0.4505, Validation Loss: 0.3003
	--> Epoch [41/100], Loss: 0.2099, Validation Loss: 0.2969
	--> Epoch [42/100], Loss: 0.5728, Validation Loss: 0.2952
	--> Epoch [43/100], Loss: 0.2742, Validation Loss: 0.2931
	--> Epoch [44/100], Loss: 0.3244, Validation Loss: 0.2911
	--> Epoch [45/100], Loss: 0.4736, Validation Loss: 0.2874
	--> Epoch [46/100], Loss: 0.4211, Validation Loss: 0.2871
	--> Epoch [47/100], Loss: 0.4164, Validation Loss: 0.2855
	--> Epoch [48/100], Loss: 0.1974, Validation Loss: 0.2833
	--> Epoch [49/100], Loss: 0.2683, Validation Loss: 0.2823
	--> Epoch [50/100], Loss: 0.4171, Validation Loss: 0.2787
	--> Epoch [51/100], Loss: 0.2880, Validation Loss: 0.2755
	--> Epoch [52/100], Loss: 0.2635, Validation Loss: 0.2749
	--> Epoch [53/100], Loss: 0.3018, Validation Loss: 0.2728
	--> Epoch [54/100], Loss: 0.1947, Validation Loss: 0.2725
	--> Epoch [55/100], Loss: 0.3904, Validation Loss: 0.2697
	--> Epoch [56/100], Loss: 0.3730, Validation Loss: 0.2675
	--> Epoch [57/100], Loss: 0.1710, Validation Loss: 0.2663
	--> Epoch [58/100], Loss: 0.2610, Validation Loss: 0.2657
	--> Epoch [59/100], Loss: 0.3992, Validation Loss: 0.2617
	--> Epoch [60/100], Loss: 0.2036, Validation Loss: 0.2635
	--> Epoch [61/100], Loss: 0.3133, Validation Loss: 0.2601
	--> Epoch [62/100], Loss: 0.2347, Validation Loss: 0.2605
	--> Epoch [63/100], Loss: 0.2858, Validation Loss: 0.2584
	--> Epoch [64/100], Loss: 0.3166, Validation Loss: 0.2576
	--> Epoch [65/100], Loss: 0.1788, Validation Loss: 0.2562
	--> Epoch [66/100], Loss: 0.2353, Validation Loss: 0.2587
	--> Epoch [67/100], Loss: 0.2997, Validation Loss: 0.2591
	--> Epoch [68/100], Loss: 0.3030, Validation Loss: 0.2582
Early stopping
	--> Training for Fold 2 took 1.1093182563781738 sec, using 68 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8778, Validation Loss: 0.6201
	--> Epoch [2/100], Loss: 0.7835, Validation Loss: 0.6087
	--> Epoch [3/100], Loss: 0.8442, Validation Loss: 0.5931
	--> Epoch [4/100], Loss: 0.8345, Validation Loss: 0.5843
	--> Epoch [5/100], Loss: 0.9260, Validation Loss: 0.5793
	--> Epoch [6/100], Loss: 0.7917, Validation Loss: 0.5726
	--> Epoch [7/100], Loss: 0.7336, Validation Loss: 0.5593
	--> Epoch [8/100], Loss: 0.7750, Validation Loss: 0.5491
	--> Epoch [9/100], Loss: 0.7232, Validation Loss: 0.5405
	--> Epoch [10/100], Loss: 0.4517, Validation Loss: 0.5321
	--> Epoch [11/100], Loss: 0.4885, Validation Loss: 0.5227
	--> Epoch [12/100], Loss: 0.4423, Validation Loss: 0.5187
	--> Epoch [13/100], Loss: 0.4778, Validation Loss: 0.5097
	--> Epoch [14/100], Loss: 0.6501, Validation Loss: 0.5028
	--> Epoch [15/100], Loss: 0.6540, Validation Loss: 0.4962
	--> Epoch [16/100], Loss: 0.6624, Validation Loss: 0.4859
	--> Epoch [17/100], Loss: 0.3261, Validation Loss: 0.4782
	--> Epoch [18/100], Loss: 0.5690, Validation Loss: 0.4701
	--> Epoch [19/100], Loss: 0.3029, Validation Loss: 0.4640
	--> Epoch [20/100], Loss: 0.3047, Validation Loss: 0.4570
	--> Epoch [21/100], Loss: 0.2862, Validation Loss: 0.4517
	--> Epoch [22/100], Loss: 0.6612, Validation Loss: 0.4458
	--> Epoch [23/100], Loss: 0.3037, Validation Loss: 0.4416
	--> Epoch [24/100], Loss: 0.4597, Validation Loss: 0.4388
	--> Epoch [25/100], Loss: 0.4110, Validation Loss: 0.4311
	--> Epoch [26/100], Loss: 0.4588, Validation Loss: 0.4231
	--> Epoch [27/100], Loss: 0.5009, Validation Loss: 0.4217
	--> Epoch [28/100], Loss: 0.4568, Validation Loss: 0.4156
	--> Epoch [29/100], Loss: 0.4143, Validation Loss: 0.4090
	--> Epoch [30/100], Loss: 0.5830, Validation Loss: 0.4077
	--> Epoch [31/100], Loss: 0.4798, Validation Loss: 0.4035
	--> Epoch [32/100], Loss: 0.5672, Validation Loss: 0.4021
	--> Epoch [33/100], Loss: 0.5512, Validation Loss: 0.3969
	--> Epoch [34/100], Loss: 0.3626, Validation Loss: 0.3914
	--> Epoch [35/100], Loss: 0.3785, Validation Loss: 0.3898
	--> Epoch [36/100], Loss: 0.3560, Validation Loss: 0.3871
	--> Epoch [37/100], Loss: 0.5226, Validation Loss: 0.3842
	--> Epoch [38/100], Loss: 0.3425, Validation Loss: 0.3807
	--> Epoch [39/100], Loss: 0.4966, Validation Loss: 0.3815
	--> Epoch [40/100], Loss: 0.6393, Validation Loss: 0.3795
	--> Epoch [41/100], Loss: 0.3165, Validation Loss: 0.3769
	--> Epoch [42/100], Loss: 0.2325, Validation Loss: 0.3722
	--> Epoch [43/100], Loss: 0.4976, Validation Loss: 0.3691
	--> Epoch [44/100], Loss: 0.3151, Validation Loss: 0.3663
	--> Epoch [45/100], Loss: 0.2938, Validation Loss: 0.3671
	--> Epoch [46/100], Loss: 0.2189, Validation Loss: 0.3724
	--> Epoch [47/100], Loss: 0.3335, Validation Loss: 0.3693
Early stopping
	--> Training for Fold 3 took 0.7870688438415527 sec, using 47 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8095, Validation Loss: 0.6496
	--> Epoch [2/100], Loss: 0.7508, Validation Loss: 0.6314
	--> Epoch [3/100], Loss: 0.6403, Validation Loss: 0.6204
	--> Epoch [4/100], Loss: 0.8086, Validation Loss: 0.6019
	--> Epoch [5/100], Loss: 0.6271, Validation Loss: 0.5894
	--> Epoch [6/100], Loss: 0.6025, Validation Loss: 0.5749
	--> Epoch [7/100], Loss: 0.6290, Validation Loss: 0.5633
	--> Epoch [8/100], Loss: 0.6046, Validation Loss: 0.5452
	--> Epoch [9/100], Loss: 0.6132, Validation Loss: 0.5366
	--> Epoch [10/100], Loss: 0.5176, Validation Loss: 0.5221
	--> Epoch [11/100], Loss: 0.5962, Validation Loss: 0.5145
	--> Epoch [12/100], Loss: 0.6255, Validation Loss: 0.5048
	--> Epoch [13/100], Loss: 0.4435, Validation Loss: 0.4939
	--> Epoch [14/100], Loss: 0.5675, Validation Loss: 0.4846
	--> Epoch [15/100], Loss: 0.4884, Validation Loss: 0.4716
	--> Epoch [16/100], Loss: 0.4921, Validation Loss: 0.4560
	--> Epoch [17/100], Loss: 0.4926, Validation Loss: 0.4496
	--> Epoch [18/100], Loss: 0.4268, Validation Loss: 0.4444
	--> Epoch [19/100], Loss: 0.4029, Validation Loss: 0.4324
	--> Epoch [20/100], Loss: 0.3969, Validation Loss: 0.4237
	--> Epoch [21/100], Loss: 0.4353, Validation Loss: 0.4197
	--> Epoch [22/100], Loss: 0.3473, Validation Loss: 0.4125
	--> Epoch [23/100], Loss: 0.4076, Validation Loss: 0.4080
	--> Epoch [24/100], Loss: 0.2938, Validation Loss: 0.3976
	--> Epoch [25/100], Loss: 0.3760, Validation Loss: 0.3917
	--> Epoch [26/100], Loss: 0.3085, Validation Loss: 0.3879
	--> Epoch [27/100], Loss: 0.3655, Validation Loss: 0.3807
	--> Epoch [28/100], Loss: 0.4373, Validation Loss: 0.3785
	--> Epoch [29/100], Loss: 0.2830, Validation Loss: 0.3767
	--> Epoch [30/100], Loss: 0.4523, Validation Loss: 0.3709
	--> Epoch [31/100], Loss: 0.3826, Validation Loss: 0.3680
	--> Epoch [32/100], Loss: 0.3374, Validation Loss: 0.3666
	--> Epoch [33/100], Loss: 0.4014, Validation Loss: 0.3571
	--> Epoch [34/100], Loss: 0.2183, Validation Loss: 0.3522
	--> Epoch [35/100], Loss: 0.4464, Validation Loss: 0.3474
	--> Epoch [36/100], Loss: 0.2395, Validation Loss: 0.3426
	--> Epoch [37/100], Loss: 0.4547, Validation Loss: 0.3412
	--> Epoch [38/100], Loss: 0.3403, Validation Loss: 0.3403
	--> Epoch [39/100], Loss: 0.3304, Validation Loss: 0.3363
	--> Epoch [40/100], Loss: 0.3646, Validation Loss: 0.3324
	--> Epoch [41/100], Loss: 0.2882, Validation Loss: 0.3310
	--> Epoch [42/100], Loss: 0.2857, Validation Loss: 0.3311
	--> Epoch [43/100], Loss: 0.2575, Validation Loss: 0.3295
	--> Epoch [44/100], Loss: 0.2408, Validation Loss: 0.3272
	--> Epoch [45/100], Loss: 0.3682, Validation Loss: 0.3249
	--> Epoch [46/100], Loss: 0.2964, Validation Loss: 0.3218
	--> Epoch [47/100], Loss: 0.2349, Validation Loss: 0.3217
	--> Epoch [48/100], Loss: 0.2861, Validation Loss: 0.3188
	--> Epoch [49/100], Loss: 0.3876, Validation Loss: 0.3182
	--> Epoch [50/100], Loss: 0.2815, Validation Loss: 0.3154
	--> Epoch [51/100], Loss: 0.2288, Validation Loss: 0.3148
	--> Epoch [52/100], Loss: 0.3605, Validation Loss: 0.3153
	--> Epoch [53/100], Loss: 0.4741, Validation Loss: 0.3157
	--> Epoch [54/100], Loss: 0.3999, Validation Loss: 0.3149
Early stopping
	--> Training for Fold 4 took 0.7676296234130859 sec, using 54 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5227, Validation Loss: 0.6674
	--> Epoch [2/100], Loss: 0.6435, Validation Loss: 0.6605
	--> Epoch [3/100], Loss: 0.5730, Validation Loss: 0.6524
	--> Epoch [4/100], Loss: 0.5095, Validation Loss: 0.6487
	--> Epoch [5/100], Loss: 0.4564, Validation Loss: 0.6416
	--> Epoch [6/100], Loss: 0.3605, Validation Loss: 0.6383
	--> Epoch [7/100], Loss: 0.4547, Validation Loss: 0.6316
	--> Epoch [8/100], Loss: 0.3273, Validation Loss: 0.6249
	--> Epoch [9/100], Loss: 0.3213, Validation Loss: 0.6265
	--> Epoch [10/100], Loss: 0.4525, Validation Loss: 0.6203
	--> Epoch [11/100], Loss: 0.3829, Validation Loss: 0.6152
	--> Epoch [12/100], Loss: 0.4701, Validation Loss: 0.6090
	--> Epoch [13/100], Loss: 0.3360, Validation Loss: 0.6087
	--> Epoch [14/100], Loss: 0.3085, Validation Loss: 0.6073
	--> Epoch [15/100], Loss: 0.3830, Validation Loss: 0.6068
	--> Epoch [16/100], Loss: 0.2276, Validation Loss: 0.6007
	--> Epoch [17/100], Loss: 0.3519, Validation Loss: 0.5943
	--> Epoch [18/100], Loss: 0.2310, Validation Loss: 0.5909
	--> Epoch [19/100], Loss: 0.3693, Validation Loss: 0.5921
	--> Epoch [20/100], Loss: 0.2192, Validation Loss: 0.5904
	--> Epoch [21/100], Loss: 0.3943, Validation Loss: 0.5833
	--> Epoch [22/100], Loss: 0.2448, Validation Loss: 0.5793
	--> Epoch [23/100], Loss: 0.2411, Validation Loss: 0.5789
	--> Epoch [24/100], Loss: 0.2211, Validation Loss: 0.5859
	--> Epoch [25/100], Loss: 0.2957, Validation Loss: 0.5854
	--> Epoch [26/100], Loss: 0.3848, Validation Loss: 0.5888
Early stopping
	--> Training for Fold 5 took 0.381974458694458 sec, using 26 epochs

Median number of epochs used: 54 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/54], Loss: 0.6208
	--> Final training Epoch [2/54], Loss: 0.6262
	--> Final training Epoch [3/54], Loss: 0.5837
	--> Final training Epoch [4/54], Loss: 0.4748
	--> Final training Epoch [5/54], Loss: 0.5488
	--> Final training Epoch [6/54], Loss: 0.5089
	--> Final training Epoch [7/54], Loss: 0.5314
	--> Final training Epoch [8/54], Loss: 0.6316
	--> Final training Epoch [9/54], Loss: 0.4972
	--> Final training Epoch [10/54], Loss: 0.3834
	--> Final training Epoch [11/54], Loss: 0.5296
	--> Final training Epoch [12/54], Loss: 0.4862
	--> Final training Epoch [13/54], Loss: 0.4523
	--> Final training Epoch [14/54], Loss: 0.4192
	--> Final training Epoch [15/54], Loss: 0.4251
	--> Final training Epoch [16/54], Loss: 0.3475
	--> Final training Epoch [17/54], Loss: 0.4424
	--> Final training Epoch [18/54], Loss: 0.2636
	--> Final training Epoch [19/54], Loss: 0.3715
	--> Final training Epoch [20/54], Loss: 0.4326
	--> Final training Epoch [21/54], Loss: 0.3565
	--> Final training Epoch [22/54], Loss: 0.4004
	--> Final training Epoch [23/54], Loss: 0.3958
	--> Final training Epoch [24/54], Loss: 0.4631
	--> Final training Epoch [25/54], Loss: 0.4224
	--> Final training Epoch [26/54], Loss: 0.2375
	--> Final training Epoch [27/54], Loss: 0.2392
	--> Final training Epoch [28/54], Loss: 0.3028
	--> Final training Epoch [29/54], Loss: 0.3020
	--> Final training Epoch [30/54], Loss: 0.2910
	--> Final training Epoch [31/54], Loss: 0.2989
	--> Final training Epoch [32/54], Loss: 0.1404
	--> Final training Epoch [33/54], Loss: 0.1779
	--> Final training Epoch [34/54], Loss: 0.2674
	--> Final training Epoch [35/54], Loss: 0.2306
	--> Final training Epoch [36/54], Loss: 0.3837
	--> Final training Epoch [37/54], Loss: 0.3042
	--> Final training Epoch [38/54], Loss: 0.2312
	--> Final training Epoch [39/54], Loss: 0.3103
	--> Final training Epoch [40/54], Loss: 0.1377
	--> Final training Epoch [41/54], Loss: 0.4045
	--> Final training Epoch [42/54], Loss: 0.1924
	--> Final training Epoch [43/54], Loss: 0.3282
	--> Final training Epoch [44/54], Loss: 0.0535
	--> Final training Epoch [45/54], Loss: 0.3720
	--> Final training Epoch [46/54], Loss: 0.3254
	--> Final training Epoch [47/54], Loss: 0.2027
	--> Final training Epoch [48/54], Loss: 0.2484
	--> Final training Epoch [49/54], Loss: 0.3119
	--> Final training Epoch [50/54], Loss: 0.2729
	--> Final training Epoch [51/54], Loss: 0.2268
	--> Final training Epoch [52/54], Loss: 0.1968
	--> Final training Epoch [53/54], Loss: 0.1684
	--> Final training Epoch [54/54], Loss: 0.1426

Final training took 0.8116235733032227 sec

TESTING
	--> Testing took 0.0116 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9068
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3682,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3682
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3740,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3682

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6901, Validation Loss: 0.6907
	--> Epoch [2/100], Loss: 0.6182, Validation Loss: 0.6690
	--> Epoch [3/100], Loss: 0.5392, Validation Loss: 0.6499
	--> Epoch [4/100], Loss: 0.5601, Validation Loss: 0.6322
	--> Epoch [5/100], Loss: 0.5433, Validation Loss: 0.6177
	--> Epoch [6/100], Loss: 0.4662, Validation Loss: 0.6037
	--> Epoch [7/100], Loss: 0.5056, Validation Loss: 0.5913
	--> Epoch [8/100], Loss: 0.4530, Validation Loss: 0.5743
	--> Epoch [9/100], Loss: 0.4475, Validation Loss: 0.5602
	--> Epoch [10/100], Loss: 0.4112, Validation Loss: 0.5477
	--> Epoch [11/100], Loss: 0.4490, Validation Loss: 0.5347
	--> Epoch [12/100], Loss: 0.3651, Validation Loss: 0.5242
	--> Epoch [13/100], Loss: 0.4107, Validation Loss: 0.5134
	--> Epoch [14/100], Loss: 0.3192, Validation Loss: 0.5044
	--> Epoch [15/100], Loss: 0.2594, Validation Loss: 0.4940
	--> Epoch [16/100], Loss: 0.3065, Validation Loss: 0.4872
	--> Epoch [17/100], Loss: 0.2801, Validation Loss: 0.4804
	--> Epoch [18/100], Loss: 0.2656, Validation Loss: 0.4745
	--> Epoch [19/100], Loss: 0.2574, Validation Loss: 0.4667
	--> Epoch [20/100], Loss: 0.2889, Validation Loss: 0.4615
	--> Epoch [21/100], Loss: 0.2209, Validation Loss: 0.4566
	--> Epoch [22/100], Loss: 0.2291, Validation Loss: 0.4523
	--> Epoch [23/100], Loss: 0.2324, Validation Loss: 0.4451
	--> Epoch [24/100], Loss: 0.1763, Validation Loss: 0.4395
	--> Epoch [25/100], Loss: 0.2369, Validation Loss: 0.4345
	--> Epoch [26/100], Loss: 0.1943, Validation Loss: 0.4274
	--> Epoch [27/100], Loss: 0.3077, Validation Loss: 0.4216
	--> Epoch [28/100], Loss: 0.1511, Validation Loss: 0.4164
	--> Epoch [29/100], Loss: 0.1525, Validation Loss: 0.4101
	--> Epoch [30/100], Loss: 0.2063, Validation Loss: 0.4091
	--> Epoch [31/100], Loss: 0.2247, Validation Loss: 0.4038
	--> Epoch [32/100], Loss: 0.1589, Validation Loss: 0.4008
	--> Epoch [33/100], Loss: 0.1898, Validation Loss: 0.3991
	--> Epoch [34/100], Loss: 0.2121, Validation Loss: 0.3969
	--> Epoch [35/100], Loss: 0.1470, Validation Loss: 0.3924
	--> Epoch [36/100], Loss: 0.1753, Validation Loss: 0.3906
	--> Epoch [37/100], Loss: 0.2689, Validation Loss: 0.3869
	--> Epoch [38/100], Loss: 0.1701, Validation Loss: 0.3842
	--> Epoch [39/100], Loss: 0.1743, Validation Loss: 0.3817
	--> Epoch [40/100], Loss: 0.2441, Validation Loss: 0.3796
	--> Epoch [41/100], Loss: 0.1259, Validation Loss: 0.3783
	--> Epoch [42/100], Loss: 0.1232, Validation Loss: 0.3771
	--> Epoch [43/100], Loss: 0.1199, Validation Loss: 0.3759
	--> Epoch [44/100], Loss: 0.1627, Validation Loss: 0.3740
	--> Epoch [45/100], Loss: 0.1693, Validation Loss: 0.3707
	--> Epoch [46/100], Loss: 0.1694, Validation Loss: 0.3714
	--> Epoch [47/100], Loss: 0.1726, Validation Loss: 0.3703
	--> Epoch [48/100], Loss: 0.1348, Validation Loss: 0.3674
	--> Epoch [49/100], Loss: 0.1497, Validation Loss: 0.3676
	--> Epoch [50/100], Loss: 0.1838, Validation Loss: 0.3680
	--> Epoch [51/100], Loss: 0.1130, Validation Loss: 0.3687
Early stopping
	--> Training for Fold 1 took 0.4432108402252197 sec, using 51 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.9397, Validation Loss: 0.8371
	--> Epoch [2/100], Loss: 0.8745, Validation Loss: 0.8036
	--> Epoch [3/100], Loss: 0.8020, Validation Loss: 0.7646
	--> Epoch [4/100], Loss: 0.7549, Validation Loss: 0.7315
	--> Epoch [5/100], Loss: 0.7168, Validation Loss: 0.6970
	--> Epoch [6/100], Loss: 0.6755, Validation Loss: 0.6583
	--> Epoch [7/100], Loss: 0.6581, Validation Loss: 0.6306
	--> Epoch [8/100], Loss: 0.7070, Validation Loss: 0.5999
	--> Epoch [9/100], Loss: 0.7118, Validation Loss: 0.5742
	--> Epoch [10/100], Loss: 0.6496, Validation Loss: 0.5475
	--> Epoch [11/100], Loss: 0.5911, Validation Loss: 0.5204
	--> Epoch [12/100], Loss: 0.5627, Validation Loss: 0.5008
	--> Epoch [13/100], Loss: 0.5384, Validation Loss: 0.4788
	--> Epoch [14/100], Loss: 0.5344, Validation Loss: 0.4611
	--> Epoch [15/100], Loss: 0.4819, Validation Loss: 0.4451
	--> Epoch [16/100], Loss: 0.4869, Validation Loss: 0.4361
	--> Epoch [17/100], Loss: 0.5190, Validation Loss: 0.4234
	--> Epoch [18/100], Loss: 0.4054, Validation Loss: 0.4150
	--> Epoch [19/100], Loss: 0.5594, Validation Loss: 0.4083
	--> Epoch [20/100], Loss: 0.4564, Validation Loss: 0.3990
	--> Epoch [21/100], Loss: 0.3826, Validation Loss: 0.3901
	--> Epoch [22/100], Loss: 0.4103, Validation Loss: 0.3845
	--> Epoch [23/100], Loss: 0.3013, Validation Loss: 0.3775
	--> Epoch [24/100], Loss: 0.3955, Validation Loss: 0.3718
	--> Epoch [25/100], Loss: 0.4478, Validation Loss: 0.3652
	--> Epoch [26/100], Loss: 0.4322, Validation Loss: 0.3596
	--> Epoch [27/100], Loss: 0.2367, Validation Loss: 0.3550
	--> Epoch [28/100], Loss: 0.2934, Validation Loss: 0.3499
	--> Epoch [29/100], Loss: 0.3882, Validation Loss: 0.3461
	--> Epoch [30/100], Loss: 0.2797, Validation Loss: 0.3422
	--> Epoch [31/100], Loss: 0.2764, Validation Loss: 0.3382
	--> Epoch [32/100], Loss: 0.2069, Validation Loss: 0.3338
	--> Epoch [33/100], Loss: 0.1717, Validation Loss: 0.3293
	--> Epoch [34/100], Loss: 0.3083, Validation Loss: 0.3261
	--> Epoch [35/100], Loss: 0.4720, Validation Loss: 0.3261
	--> Epoch [36/100], Loss: 0.1755, Validation Loss: 0.3207
	--> Epoch [37/100], Loss: 0.2664, Validation Loss: 0.3175
	--> Epoch [38/100], Loss: 0.2403, Validation Loss: 0.3151
	--> Epoch [39/100], Loss: 0.1799, Validation Loss: 0.3127
	--> Epoch [40/100], Loss: 0.1813, Validation Loss: 0.3101
	--> Epoch [41/100], Loss: 0.2862, Validation Loss: 0.3076
	--> Epoch [42/100], Loss: 0.3063, Validation Loss: 0.3012
	--> Epoch [43/100], Loss: 0.2307, Validation Loss: 0.3003
	--> Epoch [44/100], Loss: 0.1516, Validation Loss: 0.2985
	--> Epoch [45/100], Loss: 0.1509, Validation Loss: 0.2956
	--> Epoch [46/100], Loss: 0.2740, Validation Loss: 0.2935
	--> Epoch [47/100], Loss: 0.2122, Validation Loss: 0.2910
	--> Epoch [48/100], Loss: 0.2106, Validation Loss: 0.2878
	--> Epoch [49/100], Loss: 0.2083, Validation Loss: 0.2854
	--> Epoch [50/100], Loss: 0.2568, Validation Loss: 0.2845
	--> Epoch [51/100], Loss: 0.1160, Validation Loss: 0.2812
	--> Epoch [52/100], Loss: 0.1554, Validation Loss: 0.2789
	--> Epoch [53/100], Loss: 0.0821, Validation Loss: 0.2763
	--> Epoch [54/100], Loss: 0.1561, Validation Loss: 0.2734
	--> Epoch [55/100], Loss: 0.2044, Validation Loss: 0.2699
	--> Epoch [56/100], Loss: 0.1286, Validation Loss: 0.2678
	--> Epoch [57/100], Loss: 0.1889, Validation Loss: 0.2663
	--> Epoch [58/100], Loss: 0.1920, Validation Loss: 0.2659
	--> Epoch [59/100], Loss: 0.0503, Validation Loss: 0.2655
	--> Epoch [60/100], Loss: 0.1751, Validation Loss: 0.2635
	--> Epoch [61/100], Loss: 0.1871, Validation Loss: 0.2622
	--> Epoch [62/100], Loss: 0.0975, Validation Loss: 0.2600
	--> Epoch [63/100], Loss: 0.0689, Validation Loss: 0.2580
	--> Epoch [64/100], Loss: 0.1144, Validation Loss: 0.2566
	--> Epoch [65/100], Loss: 0.1246, Validation Loss: 0.2560
	--> Epoch [66/100], Loss: 0.1623, Validation Loss: 0.2549
	--> Epoch [67/100], Loss: 0.1149, Validation Loss: 0.2534
	--> Epoch [68/100], Loss: 0.3153, Validation Loss: 0.2520
	--> Epoch [69/100], Loss: 0.2301, Validation Loss: 0.2504
	--> Epoch [70/100], Loss: 0.0413, Validation Loss: 0.2500
	--> Epoch [71/100], Loss: 0.2297, Validation Loss: 0.2463
	--> Epoch [72/100], Loss: 0.0361, Validation Loss: 0.2438
	--> Epoch [73/100], Loss: 0.0512, Validation Loss: 0.2427
	--> Epoch [74/100], Loss: 0.0285, Validation Loss: 0.2425
	--> Epoch [75/100], Loss: 0.1246, Validation Loss: 0.2412
	--> Epoch [76/100], Loss: 0.1061, Validation Loss: 0.2409
	--> Epoch [77/100], Loss: 0.2368, Validation Loss: 0.2398
	--> Epoch [78/100], Loss: 0.1648, Validation Loss: 0.2396
	--> Epoch [79/100], Loss: 0.1343, Validation Loss: 0.2371
	--> Epoch [80/100], Loss: 0.1679, Validation Loss: 0.2363
	--> Epoch [81/100], Loss: 0.0913, Validation Loss: 0.2355
	--> Epoch [82/100], Loss: 0.2314, Validation Loss: 0.2348
	--> Epoch [83/100], Loss: 0.0812, Validation Loss: 0.2338
	--> Epoch [84/100], Loss: 0.0892, Validation Loss: 0.2324
	--> Epoch [85/100], Loss: 0.0909, Validation Loss: 0.2314
	--> Epoch [86/100], Loss: 0.1040, Validation Loss: 0.2295
	--> Epoch [87/100], Loss: 0.0171, Validation Loss: 0.2295
	--> Epoch [88/100], Loss: 0.2312, Validation Loss: 0.2269
	--> Epoch [89/100], Loss: 0.1675, Validation Loss: 0.2250
	--> Epoch [90/100], Loss: 0.0119, Validation Loss: 0.2255
	--> Epoch [91/100], Loss: 0.0915, Validation Loss: 0.2260
	--> Epoch [92/100], Loss: 0.3605, Validation Loss: 0.2254
Early stopping
	--> Training for Fold 2 took 0.787520170211792 sec, using 92 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7330, Validation Loss: 0.6377
	--> Epoch [2/100], Loss: 0.6709, Validation Loss: 0.6259
	--> Epoch [3/100], Loss: 0.6322, Validation Loss: 0.6140
	--> Epoch [4/100], Loss: 0.5986, Validation Loss: 0.6045
	--> Epoch [5/100], Loss: 0.5921, Validation Loss: 0.5924
	--> Epoch [6/100], Loss: 0.5519, Validation Loss: 0.5834
	--> Epoch [7/100], Loss: 0.5073, Validation Loss: 0.5707
	--> Epoch [8/100], Loss: 0.5144, Validation Loss: 0.5613
	--> Epoch [9/100], Loss: 0.5291, Validation Loss: 0.5496
	--> Epoch [10/100], Loss: 0.4775, Validation Loss: 0.5416
	--> Epoch [11/100], Loss: 0.3846, Validation Loss: 0.5313
	--> Epoch [12/100], Loss: 0.3806, Validation Loss: 0.5202
	--> Epoch [13/100], Loss: 0.3336, Validation Loss: 0.5135
	--> Epoch [14/100], Loss: 0.2903, Validation Loss: 0.5044
	--> Epoch [15/100], Loss: 0.3716, Validation Loss: 0.4972
	--> Epoch [16/100], Loss: 0.3877, Validation Loss: 0.4904
	--> Epoch [17/100], Loss: 0.3840, Validation Loss: 0.4812
	--> Epoch [18/100], Loss: 0.2912, Validation Loss: 0.4715
	--> Epoch [19/100], Loss: 0.3097, Validation Loss: 0.4641
	--> Epoch [20/100], Loss: 0.2686, Validation Loss: 0.4572
	--> Epoch [21/100], Loss: 0.2477, Validation Loss: 0.4509
	--> Epoch [22/100], Loss: 0.2969, Validation Loss: 0.4414
	--> Epoch [23/100], Loss: 0.2217, Validation Loss: 0.4341
	--> Epoch [24/100], Loss: 0.2556, Validation Loss: 0.4272
	--> Epoch [25/100], Loss: 0.1859, Validation Loss: 0.4200
	--> Epoch [26/100], Loss: 0.2619, Validation Loss: 0.4124
	--> Epoch [27/100], Loss: 0.3329, Validation Loss: 0.4072
	--> Epoch [28/100], Loss: 0.2672, Validation Loss: 0.4017
	--> Epoch [29/100], Loss: 0.2825, Validation Loss: 0.3967
	--> Epoch [30/100], Loss: 0.1764, Validation Loss: 0.3900
	--> Epoch [31/100], Loss: 0.2337, Validation Loss: 0.3869
	--> Epoch [32/100], Loss: 0.2843, Validation Loss: 0.3794
	--> Epoch [33/100], Loss: 0.2386, Validation Loss: 0.3735
	--> Epoch [34/100], Loss: 0.1596, Validation Loss: 0.3708
	--> Epoch [35/100], Loss: 0.2322, Validation Loss: 0.3671
	--> Epoch [36/100], Loss: 0.1842, Validation Loss: 0.3650
	--> Epoch [37/100], Loss: 0.1922, Validation Loss: 0.3602
	--> Epoch [38/100], Loss: 0.1357, Validation Loss: 0.3565
	--> Epoch [39/100], Loss: 0.1347, Validation Loss: 0.3534
	--> Epoch [40/100], Loss: 0.1408, Validation Loss: 0.3511
	--> Epoch [41/100], Loss: 0.2652, Validation Loss: 0.3467
	--> Epoch [42/100], Loss: 0.1425, Validation Loss: 0.3441
	--> Epoch [43/100], Loss: 0.3159, Validation Loss: 0.3415
	--> Epoch [44/100], Loss: 0.1508, Validation Loss: 0.3390
	--> Epoch [45/100], Loss: 0.2003, Validation Loss: 0.3371
	--> Epoch [46/100], Loss: 0.1327, Validation Loss: 0.3337
	--> Epoch [47/100], Loss: 0.1719, Validation Loss: 0.3319
	--> Epoch [48/100], Loss: 0.1851, Validation Loss: 0.3294
	--> Epoch [49/100], Loss: 0.1069, Validation Loss: 0.3278
	--> Epoch [50/100], Loss: 0.1066, Validation Loss: 0.3246
	--> Epoch [51/100], Loss: 0.1084, Validation Loss: 0.3241
	--> Epoch [52/100], Loss: 0.2310, Validation Loss: 0.3235
	--> Epoch [53/100], Loss: 0.1817, Validation Loss: 0.3221
	--> Epoch [54/100], Loss: 0.1325, Validation Loss: 0.3190
	--> Epoch [55/100], Loss: 0.2354, Validation Loss: 0.3185
	--> Epoch [56/100], Loss: 0.1913, Validation Loss: 0.3169
	--> Epoch [57/100], Loss: 0.1125, Validation Loss: 0.3139
	--> Epoch [58/100], Loss: 0.1734, Validation Loss: 0.3124
	--> Epoch [59/100], Loss: 0.1817, Validation Loss: 0.3112
	--> Epoch [60/100], Loss: 0.1631, Validation Loss: 0.3107
	--> Epoch [61/100], Loss: 0.1133, Validation Loss: 0.3085
	--> Epoch [62/100], Loss: 0.1102, Validation Loss: 0.3073
	--> Epoch [63/100], Loss: 0.1203, Validation Loss: 0.3078
	--> Epoch [64/100], Loss: 0.1286, Validation Loss: 0.3083
	--> Epoch [65/100], Loss: 0.1834, Validation Loss: 0.3079
Early stopping
	--> Training for Fold 3 took 0.5350072383880615 sec, using 65 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7239, Validation Loss: 0.6361
	--> Epoch [2/100], Loss: 0.7054, Validation Loss: 0.6237
	--> Epoch [3/100], Loss: 0.6806, Validation Loss: 0.6158
	--> Epoch [4/100], Loss: 0.6539, Validation Loss: 0.6058
	--> Epoch [5/100], Loss: 0.6361, Validation Loss: 0.5984
	--> Epoch [6/100], Loss: 0.5878, Validation Loss: 0.5866
	--> Epoch [7/100], Loss: 0.6125, Validation Loss: 0.5732
	--> Epoch [8/100], Loss: 0.5756, Validation Loss: 0.5538
	--> Epoch [9/100], Loss: 0.5581, Validation Loss: 0.5376
	--> Epoch [10/100], Loss: 0.5426, Validation Loss: 0.5195
	--> Epoch [11/100], Loss: 0.5396, Validation Loss: 0.4985
	--> Epoch [12/100], Loss: 0.4559, Validation Loss: 0.4859
	--> Epoch [13/100], Loss: 0.4881, Validation Loss: 0.4722
	--> Epoch [14/100], Loss: 0.4677, Validation Loss: 0.4516
	--> Epoch [15/100], Loss: 0.4374, Validation Loss: 0.4383
	--> Epoch [16/100], Loss: 0.4303, Validation Loss: 0.4237
	--> Epoch [17/100], Loss: 0.4714, Validation Loss: 0.4089
	--> Epoch [18/100], Loss: 0.4436, Validation Loss: 0.4006
	--> Epoch [19/100], Loss: 0.4327, Validation Loss: 0.3939
	--> Epoch [20/100], Loss: 0.3291, Validation Loss: 0.3810
	--> Epoch [21/100], Loss: 0.2820, Validation Loss: 0.3751
	--> Epoch [22/100], Loss: 0.3133, Validation Loss: 0.3620
	--> Epoch [23/100], Loss: 0.2617, Validation Loss: 0.3538
	--> Epoch [24/100], Loss: 0.2936, Validation Loss: 0.3441
	--> Epoch [25/100], Loss: 0.2442, Validation Loss: 0.3366
	--> Epoch [26/100], Loss: 0.2527, Validation Loss: 0.3309
	--> Epoch [27/100], Loss: 0.2631, Validation Loss: 0.3249
	--> Epoch [28/100], Loss: 0.1953, Validation Loss: 0.3184
	--> Epoch [29/100], Loss: 0.1696, Validation Loss: 0.3128
	--> Epoch [30/100], Loss: 0.2362, Validation Loss: 0.3090
	--> Epoch [31/100], Loss: 0.1727, Validation Loss: 0.3032
	--> Epoch [32/100], Loss: 0.1886, Validation Loss: 0.2972
	--> Epoch [33/100], Loss: 0.1855, Validation Loss: 0.2923
	--> Epoch [34/100], Loss: 0.1598, Validation Loss: 0.2924
	--> Epoch [35/100], Loss: 0.1540, Validation Loss: 0.2881
	--> Epoch [36/100], Loss: 0.2727, Validation Loss: 0.2819
	--> Epoch [37/100], Loss: 0.1849, Validation Loss: 0.2779
	--> Epoch [38/100], Loss: 0.1329, Validation Loss: 0.2733
	--> Epoch [39/100], Loss: 0.2054, Validation Loss: 0.2715
	--> Epoch [40/100], Loss: 0.1106, Validation Loss: 0.2686
	--> Epoch [41/100], Loss: 0.1130, Validation Loss: 0.2646
	--> Epoch [42/100], Loss: 0.1350, Validation Loss: 0.2622
	--> Epoch [43/100], Loss: 0.0978, Validation Loss: 0.2598
	--> Epoch [44/100], Loss: 0.1459, Validation Loss: 0.2577
	--> Epoch [45/100], Loss: 0.1450, Validation Loss: 0.2589
	--> Epoch [46/100], Loss: 0.1498, Validation Loss: 0.2577
	--> Epoch [47/100], Loss: 0.1263, Validation Loss: 0.2586
	--> Epoch [48/100], Loss: 0.1044, Validation Loss: 0.2581
	--> Epoch [49/100], Loss: 0.1188, Validation Loss: 0.2566
	--> Epoch [50/100], Loss: 0.1407, Validation Loss: 0.2558
	--> Epoch [51/100], Loss: 0.0682, Validation Loss: 0.2553
	--> Epoch [52/100], Loss: 0.0980, Validation Loss: 0.2549
	--> Epoch [53/100], Loss: 0.1254, Validation Loss: 0.2549
	--> Epoch [54/100], Loss: 0.1234, Validation Loss: 0.2537
	--> Epoch [55/100], Loss: 0.0641, Validation Loss: 0.2532
	--> Epoch [56/100], Loss: 0.1566, Validation Loss: 0.2522
	--> Epoch [57/100], Loss: 0.1268, Validation Loss: 0.2515
	--> Epoch [58/100], Loss: 0.0544, Validation Loss: 0.2514
	--> Epoch [59/100], Loss: 0.0705, Validation Loss: 0.2503
	--> Epoch [60/100], Loss: 0.1171, Validation Loss: 0.2498
	--> Epoch [61/100], Loss: 0.0466, Validation Loss: 0.2498
	--> Epoch [62/100], Loss: 0.0654, Validation Loss: 0.2491
	--> Epoch [63/100], Loss: 0.1008, Validation Loss: 0.2486
	--> Epoch [64/100], Loss: 0.1028, Validation Loss: 0.2490
	--> Epoch [65/100], Loss: 0.0473, Validation Loss: 0.2499
	--> Epoch [66/100], Loss: 0.1112, Validation Loss: 0.2498
Early stopping
	--> Training for Fold 4 took 0.5507476329803467 sec, using 66 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7989, Validation Loss: 0.6524
	--> Epoch [2/100], Loss: 0.6997, Validation Loss: 0.6413
	--> Epoch [3/100], Loss: 0.7072, Validation Loss: 0.6308
	--> Epoch [4/100], Loss: 0.6085, Validation Loss: 0.6219
	--> Epoch [5/100], Loss: 0.6220, Validation Loss: 0.6160
	--> Epoch [6/100], Loss: 0.5558, Validation Loss: 0.6091
	--> Epoch [7/100], Loss: 0.5441, Validation Loss: 0.6023
	--> Epoch [8/100], Loss: 0.4710, Validation Loss: 0.5974
	--> Epoch [9/100], Loss: 0.4665, Validation Loss: 0.5941
	--> Epoch [10/100], Loss: 0.4173, Validation Loss: 0.5888
	--> Epoch [11/100], Loss: 0.4046, Validation Loss: 0.5842
	--> Epoch [12/100], Loss: 0.3604, Validation Loss: 0.5813
	--> Epoch [13/100], Loss: 0.3528, Validation Loss: 0.5782
	--> Epoch [14/100], Loss: 0.3162, Validation Loss: 0.5754
	--> Epoch [15/100], Loss: 0.3473, Validation Loss: 0.5740
	--> Epoch [16/100], Loss: 0.2933, Validation Loss: 0.5711
	--> Epoch [17/100], Loss: 0.3512, Validation Loss: 0.5695
	--> Epoch [18/100], Loss: 0.2797, Validation Loss: 0.5673
	--> Epoch [19/100], Loss: 0.2572, Validation Loss: 0.5672
	--> Epoch [20/100], Loss: 0.2758, Validation Loss: 0.5689
	--> Epoch [21/100], Loss: 0.1921, Validation Loss: 0.5695
	--> Epoch [22/100], Loss: 0.2146, Validation Loss: 0.5696
Early stopping
	--> Training for Fold 5 took 0.18355846405029297 sec, using 22 epochs

Median number of epochs used: 65 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/65], Loss: 0.6865
	--> Final training Epoch [2/65], Loss: 0.6335
	--> Final training Epoch [3/65], Loss: 0.6033
	--> Final training Epoch [4/65], Loss: 0.5883
	--> Final training Epoch [5/65], Loss: 0.5553
	--> Final training Epoch [6/65], Loss: 0.5213
	--> Final training Epoch [7/65], Loss: 0.4902
	--> Final training Epoch [8/65], Loss: 0.4764
	--> Final training Epoch [9/65], Loss: 0.4764
	--> Final training Epoch [10/65], Loss: 0.4730
	--> Final training Epoch [11/65], Loss: 0.4329
	--> Final training Epoch [12/65], Loss: 0.4051
	--> Final training Epoch [13/65], Loss: 0.3973
	--> Final training Epoch [14/65], Loss: 0.3723
	--> Final training Epoch [15/65], Loss: 0.3391
	--> Final training Epoch [16/65], Loss: 0.3695
	--> Final training Epoch [17/65], Loss: 0.3437
	--> Final training Epoch [18/65], Loss: 0.3361
	--> Final training Epoch [19/65], Loss: 0.2975
	--> Final training Epoch [20/65], Loss: 0.3272
	--> Final training Epoch [21/65], Loss: 0.3050
	--> Final training Epoch [22/65], Loss: 0.2965
	--> Final training Epoch [23/65], Loss: 0.2657
	--> Final training Epoch [24/65], Loss: 0.2517
	--> Final training Epoch [25/65], Loss: 0.2375
	--> Final training Epoch [26/65], Loss: 0.2037
	--> Final training Epoch [27/65], Loss: 0.2647
	--> Final training Epoch [28/65], Loss: 0.1980
	--> Final training Epoch [29/65], Loss: 0.1995
	--> Final training Epoch [30/65], Loss: 0.1904
	--> Final training Epoch [31/65], Loss: 0.2140
	--> Final training Epoch [32/65], Loss: 0.1998
	--> Final training Epoch [33/65], Loss: 0.1784
	--> Final training Epoch [34/65], Loss: 0.2176
	--> Final training Epoch [35/65], Loss: 0.2356
	--> Final training Epoch [36/65], Loss: 0.2220
	--> Final training Epoch [37/65], Loss: 0.2052
	--> Final training Epoch [38/65], Loss: 0.2105
	--> Final training Epoch [39/65], Loss: 0.2147
	--> Final training Epoch [40/65], Loss: 0.1696
	--> Final training Epoch [41/65], Loss: 0.1801
	--> Final training Epoch [42/65], Loss: 0.1406
	--> Final training Epoch [43/65], Loss: 0.1456
	--> Final training Epoch [44/65], Loss: 0.1603
	--> Final training Epoch [45/65], Loss: 0.1748
	--> Final training Epoch [46/65], Loss: 0.1491
	--> Final training Epoch [47/65], Loss: 0.1701
	--> Final training Epoch [48/65], Loss: 0.1478
	--> Final training Epoch [49/65], Loss: 0.1223
	--> Final training Epoch [50/65], Loss: 0.1379
	--> Final training Epoch [51/65], Loss: 0.1596
	--> Final training Epoch [52/65], Loss: 0.0958
	--> Final training Epoch [53/65], Loss: 0.1285
	--> Final training Epoch [54/65], Loss: 0.1212
	--> Final training Epoch [55/65], Loss: 0.1309
	--> Final training Epoch [56/65], Loss: 0.1328
	--> Final training Epoch [57/65], Loss: 0.1491
	--> Final training Epoch [58/65], Loss: 0.0894
	--> Final training Epoch [59/65], Loss: 0.1192
	--> Final training Epoch [60/65], Loss: 0.1172
	--> Final training Epoch [61/65], Loss: 0.0681
	--> Final training Epoch [62/65], Loss: 0.0733
	--> Final training Epoch [63/65], Loss: 0.1026
	--> Final training Epoch [64/65], Loss: 0.1377
	--> Final training Epoch [65/65], Loss: 0.1256

Final training took 0.5221273899078369 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8466
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8708, Validation Loss: 0.3417,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3417
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3949,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3417
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3514,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3417
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8047, Validation Loss: 0.4013,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3417

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6270, Validation Loss: 0.6581
	--> Epoch [2/100], Loss: 0.5502, Validation Loss: 0.6413
	--> Epoch [3/100], Loss: 0.5262, Validation Loss: 0.6262
	--> Epoch [4/100], Loss: 0.4957, Validation Loss: 0.6020
	--> Epoch [5/100], Loss: 0.5029, Validation Loss: 0.5800
	--> Epoch [6/100], Loss: 0.5078, Validation Loss: 0.5680
	--> Epoch [7/100], Loss: 0.4904, Validation Loss: 0.5517
	--> Epoch [8/100], Loss: 0.4764, Validation Loss: 0.5360
	--> Epoch [9/100], Loss: 0.4782, Validation Loss: 0.5230
	--> Epoch [10/100], Loss: 0.4467, Validation Loss: 0.5102
	--> Epoch [11/100], Loss: 0.3535, Validation Loss: 0.4963
	--> Epoch [12/100], Loss: 0.4140, Validation Loss: 0.4866
	--> Epoch [13/100], Loss: 0.4414, Validation Loss: 0.4777
	--> Epoch [14/100], Loss: 0.3413, Validation Loss: 0.4683
	--> Epoch [15/100], Loss: 0.4271, Validation Loss: 0.4623
	--> Epoch [16/100], Loss: 0.3649, Validation Loss: 0.4534
	--> Epoch [17/100], Loss: 0.4436, Validation Loss: 0.4465
	--> Epoch [18/100], Loss: 0.3398, Validation Loss: 0.4400
	--> Epoch [19/100], Loss: 0.3375, Validation Loss: 0.4333
	--> Epoch [20/100], Loss: 0.3372, Validation Loss: 0.4258
	--> Epoch [21/100], Loss: 0.2501, Validation Loss: 0.4186
	--> Epoch [22/100], Loss: 0.3302, Validation Loss: 0.4128
	--> Epoch [23/100], Loss: 0.3670, Validation Loss: 0.4048
	--> Epoch [24/100], Loss: 0.3337, Validation Loss: 0.3986
	--> Epoch [25/100], Loss: 0.3532, Validation Loss: 0.3919
	--> Epoch [26/100], Loss: 0.3814, Validation Loss: 0.3867
	--> Epoch [27/100], Loss: 0.2186, Validation Loss: 0.3803
	--> Epoch [28/100], Loss: 0.2831, Validation Loss: 0.3739
	--> Epoch [29/100], Loss: 0.1980, Validation Loss: 0.3686
	--> Epoch [30/100], Loss: 0.2481, Validation Loss: 0.3671
	--> Epoch [31/100], Loss: 0.2972, Validation Loss: 0.3619
	--> Epoch [32/100], Loss: 0.2707, Validation Loss: 0.3572
	--> Epoch [33/100], Loss: 0.2063, Validation Loss: 0.3525
	--> Epoch [34/100], Loss: 0.3192, Validation Loss: 0.3486
	--> Epoch [35/100], Loss: 0.3233, Validation Loss: 0.3466
	--> Epoch [36/100], Loss: 0.1512, Validation Loss: 0.3433
	--> Epoch [37/100], Loss: 0.2669, Validation Loss: 0.3405
	--> Epoch [38/100], Loss: 0.2318, Validation Loss: 0.3395
	--> Epoch [39/100], Loss: 0.2533, Validation Loss: 0.3371
	--> Epoch [40/100], Loss: 0.2782, Validation Loss: 0.3346
	--> Epoch [41/100], Loss: 0.2276, Validation Loss: 0.3315
	--> Epoch [42/100], Loss: 0.2227, Validation Loss: 0.3295
	--> Epoch [43/100], Loss: 0.2614, Validation Loss: 0.3265
	--> Epoch [44/100], Loss: 0.3265, Validation Loss: 0.3247
	--> Epoch [45/100], Loss: 0.3278, Validation Loss: 0.3203
	--> Epoch [46/100], Loss: 0.3275, Validation Loss: 0.3178
	--> Epoch [47/100], Loss: 0.1819, Validation Loss: 0.3161
	--> Epoch [48/100], Loss: 0.1822, Validation Loss: 0.3156
	--> Epoch [49/100], Loss: 0.2724, Validation Loss: 0.3142
	--> Epoch [50/100], Loss: 0.3678, Validation Loss: 0.3142
	--> Epoch [51/100], Loss: 0.2761, Validation Loss: 0.3150
	--> Epoch [52/100], Loss: 0.2101, Validation Loss: 0.3150
	--> Epoch [53/100], Loss: 0.2654, Validation Loss: 0.3131
	--> Epoch [54/100], Loss: 0.1757, Validation Loss: 0.3103
	--> Epoch [55/100], Loss: 0.2503, Validation Loss: 0.3080
	--> Epoch [56/100], Loss: 0.2581, Validation Loss: 0.3057
	--> Epoch [57/100], Loss: 0.1653, Validation Loss: 0.3047
	--> Epoch [58/100], Loss: 0.2118, Validation Loss: 0.3071
	--> Epoch [59/100], Loss: 0.1758, Validation Loss: 0.3045
	--> Epoch [60/100], Loss: 0.1573, Validation Loss: 0.3037
	--> Epoch [61/100], Loss: 0.2048, Validation Loss: 0.3002
	--> Epoch [62/100], Loss: 0.3000, Validation Loss: 0.2997
	--> Epoch [63/100], Loss: 0.1084, Validation Loss: 0.3001
	--> Epoch [64/100], Loss: 0.3062, Validation Loss: 0.2988
	--> Epoch [65/100], Loss: 0.1706, Validation Loss: 0.2976
	--> Epoch [66/100], Loss: 0.2108, Validation Loss: 0.2990
	--> Epoch [67/100], Loss: 0.1587, Validation Loss: 0.2999
	--> Epoch [68/100], Loss: 0.2536, Validation Loss: 0.2993
Early stopping
	--> Training for Fold 1 took 0.634387731552124 sec, using 68 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6795, Validation Loss: 0.6475
	--> Epoch [2/100], Loss: 0.6598, Validation Loss: 0.6185
	--> Epoch [3/100], Loss: 0.7335, Validation Loss: 0.5943
	--> Epoch [4/100], Loss: 0.6727, Validation Loss: 0.5751
	--> Epoch [5/100], Loss: 0.5217, Validation Loss: 0.5528
	--> Epoch [6/100], Loss: 0.5336, Validation Loss: 0.5331
	--> Epoch [7/100], Loss: 0.4787, Validation Loss: 0.5122
	--> Epoch [8/100], Loss: 0.5355, Validation Loss: 0.5014
	--> Epoch [9/100], Loss: 0.4445, Validation Loss: 0.4866
	--> Epoch [10/100], Loss: 0.4996, Validation Loss: 0.4751
	--> Epoch [11/100], Loss: 0.5333, Validation Loss: 0.4645
	--> Epoch [12/100], Loss: 0.3546, Validation Loss: 0.4509
	--> Epoch [13/100], Loss: 0.2733, Validation Loss: 0.4381
	--> Epoch [14/100], Loss: 0.4296, Validation Loss: 0.4265
	--> Epoch [15/100], Loss: 0.3872, Validation Loss: 0.4151
	--> Epoch [16/100], Loss: 0.3102, Validation Loss: 0.4047
	--> Epoch [17/100], Loss: 0.3787, Validation Loss: 0.3941
	--> Epoch [18/100], Loss: 0.3350, Validation Loss: 0.3835
	--> Epoch [19/100], Loss: 0.2994, Validation Loss: 0.3726
	--> Epoch [20/100], Loss: 0.2588, Validation Loss: 0.3629
	--> Epoch [21/100], Loss: 0.3075, Validation Loss: 0.3513
	--> Epoch [22/100], Loss: 0.2018, Validation Loss: 0.3430
	--> Epoch [23/100], Loss: 0.2105, Validation Loss: 0.3343
	--> Epoch [24/100], Loss: 0.1992, Validation Loss: 0.3258
	--> Epoch [25/100], Loss: 0.3263, Validation Loss: 0.3172
	--> Epoch [26/100], Loss: 0.1567, Validation Loss: 0.3078
	--> Epoch [27/100], Loss: 0.2912, Validation Loss: 0.3015
	--> Epoch [28/100], Loss: 0.2709, Validation Loss: 0.2938
	--> Epoch [29/100], Loss: 0.1581, Validation Loss: 0.2868
	--> Epoch [30/100], Loss: 0.2459, Validation Loss: 0.2829
	--> Epoch [31/100], Loss: 0.1770, Validation Loss: 0.2759
	--> Epoch [32/100], Loss: 0.1922, Validation Loss: 0.2694
	--> Epoch [33/100], Loss: 0.2394, Validation Loss: 0.2653
	--> Epoch [34/100], Loss: 0.1140, Validation Loss: 0.2620
	--> Epoch [35/100], Loss: 0.2600, Validation Loss: 0.2567
	--> Epoch [36/100], Loss: 0.1732, Validation Loss: 0.2518
	--> Epoch [37/100], Loss: 0.1152, Validation Loss: 0.2475
	--> Epoch [38/100], Loss: 0.1216, Validation Loss: 0.2428
	--> Epoch [39/100], Loss: 0.1556, Validation Loss: 0.2402
	--> Epoch [40/100], Loss: 0.2161, Validation Loss: 0.2362
	--> Epoch [41/100], Loss: 0.1968, Validation Loss: 0.2308
	--> Epoch [42/100], Loss: 0.1925, Validation Loss: 0.2267
	--> Epoch [43/100], Loss: 0.0920, Validation Loss: 0.2211
	--> Epoch [44/100], Loss: 0.0968, Validation Loss: 0.2177
	--> Epoch [45/100], Loss: 0.2559, Validation Loss: 0.2139
	--> Epoch [46/100], Loss: 0.1220, Validation Loss: 0.2104
	--> Epoch [47/100], Loss: 0.0797, Validation Loss: 0.2076
	--> Epoch [48/100], Loss: 0.0969, Validation Loss: 0.2045
	--> Epoch [49/100], Loss: 0.0456, Validation Loss: 0.2008
	--> Epoch [50/100], Loss: 0.2129, Validation Loss: 0.1971
	--> Epoch [51/100], Loss: 0.0946, Validation Loss: 0.1961
	--> Epoch [52/100], Loss: 0.1147, Validation Loss: 0.1941
	--> Epoch [53/100], Loss: 0.1044, Validation Loss: 0.1916
	--> Epoch [54/100], Loss: 0.1539, Validation Loss: 0.1873
	--> Epoch [55/100], Loss: 0.2068, Validation Loss: 0.1863
	--> Epoch [56/100], Loss: 0.1333, Validation Loss: 0.1842
	--> Epoch [57/100], Loss: 0.0513, Validation Loss: 0.1842
	--> Epoch [58/100], Loss: 0.0932, Validation Loss: 0.1824
	--> Epoch [59/100], Loss: 0.0863, Validation Loss: 0.1817
	--> Epoch [60/100], Loss: 0.1306, Validation Loss: 0.1795
	--> Epoch [61/100], Loss: 0.2178, Validation Loss: 0.1770
	--> Epoch [62/100], Loss: 0.0835, Validation Loss: 0.1764
	--> Epoch [63/100], Loss: 0.0877, Validation Loss: 0.1762
	--> Epoch [64/100], Loss: 0.1400, Validation Loss: 0.1743
	--> Epoch [65/100], Loss: 0.1090, Validation Loss: 0.1727
	--> Epoch [66/100], Loss: 0.2299, Validation Loss: 0.1717
	--> Epoch [67/100], Loss: 0.0443, Validation Loss: 0.1703
	--> Epoch [68/100], Loss: 0.0751, Validation Loss: 0.1652
	--> Epoch [69/100], Loss: 0.0767, Validation Loss: 0.1638
	--> Epoch [70/100], Loss: 0.1443, Validation Loss: 0.1615
	--> Epoch [71/100], Loss: 0.1247, Validation Loss: 0.1626
	--> Epoch [72/100], Loss: 0.0748, Validation Loss: 0.1621
	--> Epoch [73/100], Loss: 0.1737, Validation Loss: 0.1614
	--> Epoch [74/100], Loss: 0.1105, Validation Loss: 0.1607
	--> Epoch [75/100], Loss: 0.0804, Validation Loss: 0.1588
	--> Epoch [76/100], Loss: 0.0187, Validation Loss: 0.1578
	--> Epoch [77/100], Loss: 0.0820, Validation Loss: 0.1562
	--> Epoch [78/100], Loss: 0.0720, Validation Loss: 0.1540
	--> Epoch [79/100], Loss: 0.1210, Validation Loss: 0.1533
	--> Epoch [80/100], Loss: 0.0343, Validation Loss: 0.1531
	--> Epoch [81/100], Loss: 0.1131, Validation Loss: 0.1518
	--> Epoch [82/100], Loss: 0.0661, Validation Loss: 0.1505
	--> Epoch [83/100], Loss: 0.0742, Validation Loss: 0.1494
	--> Epoch [84/100], Loss: 0.0195, Validation Loss: 0.1478
	--> Epoch [85/100], Loss: 0.1735, Validation Loss: 0.1473
	--> Epoch [86/100], Loss: 0.0932, Validation Loss: 0.1488
	--> Epoch [87/100], Loss: 0.0498, Validation Loss: 0.1454
	--> Epoch [88/100], Loss: 0.0680, Validation Loss: 0.1451
	--> Epoch [89/100], Loss: 0.1695, Validation Loss: 0.1439
	--> Epoch [90/100], Loss: 0.0685, Validation Loss: 0.1445
	--> Epoch [91/100], Loss: 0.1164, Validation Loss: 0.1445
	--> Epoch [92/100], Loss: 0.1221, Validation Loss: 0.1430
	--> Epoch [93/100], Loss: 0.1213, Validation Loss: 0.1413
	--> Epoch [94/100], Loss: 0.1522, Validation Loss: 0.1392
	--> Epoch [95/100], Loss: 0.0721, Validation Loss: 0.1383
	--> Epoch [96/100], Loss: 0.1724, Validation Loss: 0.1360
	--> Epoch [97/100], Loss: 0.1668, Validation Loss: 0.1338
	--> Epoch [98/100], Loss: 0.2241, Validation Loss: 0.1333
	--> Epoch [99/100], Loss: 0.1084, Validation Loss: 0.1337
	--> Epoch [100/100], Loss: 0.0632, Validation Loss: 0.1338
	--> Training for Fold 2 took 0.9113724231719971 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6073, Validation Loss: 0.7704
	--> Epoch [2/100], Loss: 0.5070, Validation Loss: 0.7528
	--> Epoch [3/100], Loss: 0.5085, Validation Loss: 0.7403
	--> Epoch [4/100], Loss: 0.4560, Validation Loss: 0.7316
	--> Epoch [5/100], Loss: 0.4591, Validation Loss: 0.7191
	--> Epoch [6/100], Loss: 0.4148, Validation Loss: 0.7104
	--> Epoch [7/100], Loss: 0.3694, Validation Loss: 0.7012
	--> Epoch [8/100], Loss: 0.4737, Validation Loss: 0.6946
	--> Epoch [9/100], Loss: 0.3966, Validation Loss: 0.6854
	--> Epoch [10/100], Loss: 0.3795, Validation Loss: 0.6756
	--> Epoch [11/100], Loss: 0.3739, Validation Loss: 0.6694
	--> Epoch [12/100], Loss: 0.3314, Validation Loss: 0.6626
	--> Epoch [13/100], Loss: 0.3878, Validation Loss: 0.6563
	--> Epoch [14/100], Loss: 0.2939, Validation Loss: 0.6494
	--> Epoch [15/100], Loss: 0.4204, Validation Loss: 0.6423
	--> Epoch [16/100], Loss: 0.3619, Validation Loss: 0.6350
	--> Epoch [17/100], Loss: 0.3005, Validation Loss: 0.6269
	--> Epoch [18/100], Loss: 0.3142, Validation Loss: 0.6232
	--> Epoch [19/100], Loss: 0.2649, Validation Loss: 0.6164
	--> Epoch [20/100], Loss: 0.2797, Validation Loss: 0.6096
	--> Epoch [21/100], Loss: 0.2281, Validation Loss: 0.6025
	--> Epoch [22/100], Loss: 0.1718, Validation Loss: 0.5948
	--> Epoch [23/100], Loss: 0.2327, Validation Loss: 0.5883
	--> Epoch [24/100], Loss: 0.1134, Validation Loss: 0.5827
	--> Epoch [25/100], Loss: 0.2326, Validation Loss: 0.5774
	--> Epoch [26/100], Loss: 0.2059, Validation Loss: 0.5705
	--> Epoch [27/100], Loss: 0.1952, Validation Loss: 0.5662
	--> Epoch [28/100], Loss: 0.2436, Validation Loss: 0.5627
	--> Epoch [29/100], Loss: 0.3307, Validation Loss: 0.5589
	--> Epoch [30/100], Loss: 0.1548, Validation Loss: 0.5508
	--> Epoch [31/100], Loss: 0.1924, Validation Loss: 0.5455
	--> Epoch [32/100], Loss: 0.0840, Validation Loss: 0.5416
	--> Epoch [33/100], Loss: 0.2583, Validation Loss: 0.5391
	--> Epoch [34/100], Loss: 0.2182, Validation Loss: 0.5371
	--> Epoch [35/100], Loss: 0.1789, Validation Loss: 0.5339
	--> Epoch [36/100], Loss: 0.1392, Validation Loss: 0.5305
	--> Epoch [37/100], Loss: 0.1823, Validation Loss: 0.5253
	--> Epoch [38/100], Loss: 0.1591, Validation Loss: 0.5200
	--> Epoch [39/100], Loss: 0.0908, Validation Loss: 0.5158
	--> Epoch [40/100], Loss: 0.0351, Validation Loss: 0.5117
	--> Epoch [41/100], Loss: 0.1372, Validation Loss: 0.5108
	--> Epoch [42/100], Loss: 0.1073, Validation Loss: 0.5090
	--> Epoch [43/100], Loss: 0.1375, Validation Loss: 0.5066
	--> Epoch [44/100], Loss: 0.1698, Validation Loss: 0.5035
	--> Epoch [45/100], Loss: 0.2497, Validation Loss: 0.5032
	--> Epoch [46/100], Loss: 0.2973, Validation Loss: 0.4993
	--> Epoch [47/100], Loss: 0.1632, Validation Loss: 0.4989
	--> Epoch [48/100], Loss: 0.0639, Validation Loss: 0.4958
	--> Epoch [49/100], Loss: 0.0923, Validation Loss: 0.4931
	--> Epoch [50/100], Loss: 0.0182, Validation Loss: 0.4896
	--> Epoch [51/100], Loss: 0.2410, Validation Loss: 0.4880
	--> Epoch [52/100], Loss: 0.1203, Validation Loss: 0.4877
	--> Epoch [53/100], Loss: 0.0971, Validation Loss: 0.4875
	--> Epoch [54/100], Loss: 0.0788, Validation Loss: 0.4847
	--> Epoch [55/100], Loss: 0.0833, Validation Loss: 0.4823
	--> Epoch [56/100], Loss: 0.1786, Validation Loss: 0.4793
	--> Epoch [57/100], Loss: 0.0868, Validation Loss: 0.4768
	--> Epoch [58/100], Loss: 0.0185, Validation Loss: 0.4749
	--> Epoch [59/100], Loss: 0.1548, Validation Loss: 0.4748
	--> Epoch [60/100], Loss: 0.2822, Validation Loss: 0.4753
	--> Epoch [61/100], Loss: 0.0306, Validation Loss: 0.4734
	--> Epoch [62/100], Loss: 0.1031, Validation Loss: 0.4707
	--> Epoch [63/100], Loss: 0.0746, Validation Loss: 0.4676
	--> Epoch [64/100], Loss: 0.0402, Validation Loss: 0.4686
	--> Epoch [65/100], Loss: 0.1808, Validation Loss: 0.4659
	--> Epoch [66/100], Loss: 0.2270, Validation Loss: 0.4645
	--> Epoch [67/100], Loss: 0.0908, Validation Loss: 0.4632
	--> Epoch [68/100], Loss: 0.2127, Validation Loss: 0.4594
	--> Epoch [69/100], Loss: 0.2958, Validation Loss: 0.4594
	--> Epoch [70/100], Loss: 0.1756, Validation Loss: 0.4610
	--> Epoch [71/100], Loss: 0.1102, Validation Loss: 0.4574
	--> Epoch [72/100], Loss: 0.0176, Validation Loss: 0.4545
	--> Epoch [73/100], Loss: 0.0099, Validation Loss: 0.4512
	--> Epoch [74/100], Loss: 0.2098, Validation Loss: 0.4501
	--> Epoch [75/100], Loss: 0.1408, Validation Loss: 0.4486
	--> Epoch [76/100], Loss: 0.0969, Validation Loss: 0.4450
	--> Epoch [77/100], Loss: 0.1569, Validation Loss: 0.4444
	--> Epoch [78/100], Loss: 0.1721, Validation Loss: 0.4448
	--> Epoch [79/100], Loss: 0.0214, Validation Loss: 0.4460
	--> Epoch [80/100], Loss: 0.1528, Validation Loss: 0.4444
Early stopping
	--> Training for Fold 3 took 0.7262680530548096 sec, using 80 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.9460, Validation Loss: 0.5870
	--> Epoch [2/100], Loss: 0.8678, Validation Loss: 0.5690
	--> Epoch [3/100], Loss: 0.8525, Validation Loss: 0.5568
	--> Epoch [4/100], Loss: 0.8076, Validation Loss: 0.5476
	--> Epoch [5/100], Loss: 0.7696, Validation Loss: 0.5345
	--> Epoch [6/100], Loss: 0.7107, Validation Loss: 0.5233
	--> Epoch [7/100], Loss: 0.6232, Validation Loss: 0.5085
	--> Epoch [8/100], Loss: 0.6483, Validation Loss: 0.4948
	--> Epoch [9/100], Loss: 0.5459, Validation Loss: 0.4852
	--> Epoch [10/100], Loss: 0.5282, Validation Loss: 0.4795
	--> Epoch [11/100], Loss: 0.6762, Validation Loss: 0.4768
	--> Epoch [12/100], Loss: 0.5425, Validation Loss: 0.4710
	--> Epoch [13/100], Loss: 0.5915, Validation Loss: 0.4714
	--> Epoch [14/100], Loss: 0.6598, Validation Loss: 0.4669
	--> Epoch [15/100], Loss: 0.5544, Validation Loss: 0.4635
	--> Epoch [16/100], Loss: 0.4616, Validation Loss: 0.4580
	--> Epoch [17/100], Loss: 0.6171, Validation Loss: 0.4503
	--> Epoch [18/100], Loss: 0.5285, Validation Loss: 0.4466
	--> Epoch [19/100], Loss: 0.4464, Validation Loss: 0.4444
	--> Epoch [20/100], Loss: 0.4905, Validation Loss: 0.4373
	--> Epoch [21/100], Loss: 0.4916, Validation Loss: 0.4323
	--> Epoch [22/100], Loss: 0.5729, Validation Loss: 0.4271
	--> Epoch [23/100], Loss: 0.4436, Validation Loss: 0.4287
	--> Epoch [24/100], Loss: 0.4773, Validation Loss: 0.4193
	--> Epoch [25/100], Loss: 0.3953, Validation Loss: 0.4121
	--> Epoch [26/100], Loss: 0.4368, Validation Loss: 0.4062
	--> Epoch [27/100], Loss: 0.3762, Validation Loss: 0.4028
	--> Epoch [28/100], Loss: 0.4051, Validation Loss: 0.3968
	--> Epoch [29/100], Loss: 0.3172, Validation Loss: 0.3925
	--> Epoch [30/100], Loss: 0.4284, Validation Loss: 0.3866
	--> Epoch [31/100], Loss: 0.3035, Validation Loss: 0.3887
	--> Epoch [32/100], Loss: 0.4017, Validation Loss: 0.3837
	--> Epoch [33/100], Loss: 0.5388, Validation Loss: 0.3769
	--> Epoch [34/100], Loss: 0.4235, Validation Loss: 0.3743
	--> Epoch [35/100], Loss: 0.4202, Validation Loss: 0.3716
	--> Epoch [36/100], Loss: 0.4389, Validation Loss: 0.3678
	--> Epoch [37/100], Loss: 0.4296, Validation Loss: 0.3646
	--> Epoch [38/100], Loss: 0.4185, Validation Loss: 0.3628
	--> Epoch [39/100], Loss: 0.3787, Validation Loss: 0.3587
	--> Epoch [40/100], Loss: 0.4077, Validation Loss: 0.3618
	--> Epoch [41/100], Loss: 0.4404, Validation Loss: 0.3569
	--> Epoch [42/100], Loss: 0.2799, Validation Loss: 0.3492
	--> Epoch [43/100], Loss: 0.5171, Validation Loss: 0.3474
	--> Epoch [44/100], Loss: 0.4105, Validation Loss: 0.3448
	--> Epoch [45/100], Loss: 0.4197, Validation Loss: 0.3431
	--> Epoch [46/100], Loss: 0.4032, Validation Loss: 0.3367
	--> Epoch [47/100], Loss: 0.2709, Validation Loss: 0.3341
	--> Epoch [48/100], Loss: 0.3921, Validation Loss: 0.3316
	--> Epoch [49/100], Loss: 0.3280, Validation Loss: 0.3301
	--> Epoch [50/100], Loss: 0.4031, Validation Loss: 0.3289
	--> Epoch [51/100], Loss: 0.3886, Validation Loss: 0.3256
	--> Epoch [52/100], Loss: 0.3231, Validation Loss: 0.3254
	--> Epoch [53/100], Loss: 0.3773, Validation Loss: 0.3230
	--> Epoch [54/100], Loss: 0.3195, Validation Loss: 0.3201
	--> Epoch [55/100], Loss: 0.3154, Validation Loss: 0.3189
	--> Epoch [56/100], Loss: 0.3813, Validation Loss: 0.3176
	--> Epoch [57/100], Loss: 0.3774, Validation Loss: 0.3142
	--> Epoch [58/100], Loss: 0.4297, Validation Loss: 0.3129
	--> Epoch [59/100], Loss: 0.3689, Validation Loss: 0.3138
	--> Epoch [60/100], Loss: 0.2489, Validation Loss: 0.3122
	--> Epoch [61/100], Loss: 0.4366, Validation Loss: 0.3108
	--> Epoch [62/100], Loss: 0.1924, Validation Loss: 0.3095
	--> Epoch [63/100], Loss: 0.3178, Validation Loss: 0.3088
	--> Epoch [64/100], Loss: 0.3830, Validation Loss: 0.3069
	--> Epoch [65/100], Loss: 0.4182, Validation Loss: 0.3056
	--> Epoch [66/100], Loss: 0.4259, Validation Loss: 0.3117
	--> Epoch [67/100], Loss: 0.2594, Validation Loss: 0.3088
	--> Epoch [68/100], Loss: 0.4236, Validation Loss: 0.3093
Early stopping
	--> Training for Fold 4 took 0.5582003593444824 sec, using 68 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8678, Validation Loss: 0.6073
	--> Epoch [2/100], Loss: 0.7950, Validation Loss: 0.5969
	--> Epoch [3/100], Loss: 0.7923, Validation Loss: 0.5912
	--> Epoch [4/100], Loss: 0.7660, Validation Loss: 0.5857
	--> Epoch [5/100], Loss: 0.7313, Validation Loss: 0.5803
	--> Epoch [6/100], Loss: 0.6899, Validation Loss: 0.5771
	--> Epoch [7/100], Loss: 0.5578, Validation Loss: 0.5752
	--> Epoch [8/100], Loss: 0.5809, Validation Loss: 0.5735
	--> Epoch [9/100], Loss: 0.5575, Validation Loss: 0.5725
	--> Epoch [10/100], Loss: 0.4735, Validation Loss: 0.5713
	--> Epoch [11/100], Loss: 0.4548, Validation Loss: 0.5704
	--> Epoch [12/100], Loss: 0.4136, Validation Loss: 0.5681
	--> Epoch [13/100], Loss: 0.5018, Validation Loss: 0.5685
	--> Epoch [14/100], Loss: 0.3131, Validation Loss: 0.5678
	--> Epoch [15/100], Loss: 0.3074, Validation Loss: 0.5655
	--> Epoch [16/100], Loss: 0.3820, Validation Loss: 0.5653
	--> Epoch [17/100], Loss: 0.3447, Validation Loss: 0.5635
	--> Epoch [18/100], Loss: 0.2095, Validation Loss: 0.5647
	--> Epoch [19/100], Loss: 0.2247, Validation Loss: 0.5667
	--> Epoch [20/100], Loss: 0.3699, Validation Loss: 0.5705
Early stopping
	--> Training for Fold 5 took 0.16787195205688477 sec, using 20 epochs

Median number of epochs used: 68 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/68], Loss: 0.6823
	--> Final training Epoch [2/68], Loss: 0.6335
	--> Final training Epoch [3/68], Loss: 0.6479
	--> Final training Epoch [4/68], Loss: 0.5607
	--> Final training Epoch [5/68], Loss: 0.5436
	--> Final training Epoch [6/68], Loss: 0.6042
	--> Final training Epoch [7/68], Loss: 0.5569
	--> Final training Epoch [8/68], Loss: 0.5301
	--> Final training Epoch [9/68], Loss: 0.5567
	--> Final training Epoch [10/68], Loss: 0.5206
	--> Final training Epoch [11/68], Loss: 0.4408
	--> Final training Epoch [12/68], Loss: 0.4655
	--> Final training Epoch [13/68], Loss: 0.4921
	--> Final training Epoch [14/68], Loss: 0.4409
	--> Final training Epoch [15/68], Loss: 0.4142
	--> Final training Epoch [16/68], Loss: 0.4213
	--> Final training Epoch [17/68], Loss: 0.4030
	--> Final training Epoch [18/68], Loss: 0.4385
	--> Final training Epoch [19/68], Loss: 0.3834
	--> Final training Epoch [20/68], Loss: 0.3230
	--> Final training Epoch [21/68], Loss: 0.3837
	--> Final training Epoch [22/68], Loss: 0.3465
	--> Final training Epoch [23/68], Loss: 0.3557
	--> Final training Epoch [24/68], Loss: 0.3750
	--> Final training Epoch [25/68], Loss: 0.3370
	--> Final training Epoch [26/68], Loss: 0.3154
	--> Final training Epoch [27/68], Loss: 0.3121
	--> Final training Epoch [28/68], Loss: 0.2936
	--> Final training Epoch [29/68], Loss: 0.3837
	--> Final training Epoch [30/68], Loss: 0.2559
	--> Final training Epoch [31/68], Loss: 0.2608
	--> Final training Epoch [32/68], Loss: 0.2646
	--> Final training Epoch [33/68], Loss: 0.3266
	--> Final training Epoch [34/68], Loss: 0.2922
	--> Final training Epoch [35/68], Loss: 0.2454
	--> Final training Epoch [36/68], Loss: 0.2626
	--> Final training Epoch [37/68], Loss: 0.2431
	--> Final training Epoch [38/68], Loss: 0.2126
	--> Final training Epoch [39/68], Loss: 0.2411
	--> Final training Epoch [40/68], Loss: 0.2812
	--> Final training Epoch [41/68], Loss: 0.2704
	--> Final training Epoch [42/68], Loss: 0.2387
	--> Final training Epoch [43/68], Loss: 0.2544
	--> Final training Epoch [44/68], Loss: 0.2506
	--> Final training Epoch [45/68], Loss: 0.2083
	--> Final training Epoch [46/68], Loss: 0.1856
	--> Final training Epoch [47/68], Loss: 0.2124
	--> Final training Epoch [48/68], Loss: 0.2350
	--> Final training Epoch [49/68], Loss: 0.1965
	--> Final training Epoch [50/68], Loss: 0.2335
	--> Final training Epoch [51/68], Loss: 0.2447
	--> Final training Epoch [52/68], Loss: 0.1914
	--> Final training Epoch [53/68], Loss: 0.1680
	--> Final training Epoch [54/68], Loss: 0.1998
	--> Final training Epoch [55/68], Loss: 0.2112
	--> Final training Epoch [56/68], Loss: 0.1726
	--> Final training Epoch [57/68], Loss: 0.2115
	--> Final training Epoch [58/68], Loss: 0.2383
	--> Final training Epoch [59/68], Loss: 0.2675
	--> Final training Epoch [60/68], Loss: 0.3022
	--> Final training Epoch [61/68], Loss: 0.2382
	--> Final training Epoch [62/68], Loss: 0.1859
	--> Final training Epoch [63/68], Loss: 0.1638
	--> Final training Epoch [64/68], Loss: 0.1755
	--> Final training Epoch [65/68], Loss: 0.1443
	--> Final training Epoch [66/68], Loss: 0.1500
	--> Final training Epoch [67/68], Loss: 0.2015
	--> Final training Epoch [68/68], Loss: 0.1718

Final training took 0.5574932098388672 sec

TESTING
	--> Testing took 0.0073 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.7662
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3408,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3408
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.3788,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3408
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8368, Validation Loss: 0.3749,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3408
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.3653,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3408
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8146, Validation Loss: 0.4349,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3408
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3545,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3408
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8287, Validation Loss: 0.3627,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3408

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5315, Validation Loss: 0.6199
	--> Epoch [2/100], Loss: 0.5655, Validation Loss: 0.5865
	--> Epoch [3/100], Loss: 0.4495, Validation Loss: 0.5589
	--> Epoch [4/100], Loss: 0.4517, Validation Loss: 0.5404
	--> Epoch [5/100], Loss: 0.3843, Validation Loss: 0.5226
	--> Epoch [6/100], Loss: 0.4296, Validation Loss: 0.5105
	--> Epoch [7/100], Loss: 0.3443, Validation Loss: 0.4963
	--> Epoch [8/100], Loss: 0.3208, Validation Loss: 0.4816
	--> Epoch [9/100], Loss: 0.2830, Validation Loss: 0.4723
	--> Epoch [10/100], Loss: 0.2576, Validation Loss: 0.4637
	--> Epoch [11/100], Loss: 0.2133, Validation Loss: 0.4541
	--> Epoch [12/100], Loss: 0.2144, Validation Loss: 0.4446
	--> Epoch [13/100], Loss: 0.2992, Validation Loss: 0.4349
	--> Epoch [14/100], Loss: 0.2443, Validation Loss: 0.4252
	--> Epoch [15/100], Loss: 0.1529, Validation Loss: 0.4162
	--> Epoch [16/100], Loss: 0.1723, Validation Loss: 0.4060
	--> Epoch [17/100], Loss: 0.1548, Validation Loss: 0.3965
	--> Epoch [18/100], Loss: 0.1291, Validation Loss: 0.3881
	--> Epoch [19/100], Loss: 0.1991, Validation Loss: 0.3798
	--> Epoch [20/100], Loss: 0.1322, Validation Loss: 0.3734
	--> Epoch [21/100], Loss: 0.1176, Validation Loss: 0.3698
	--> Epoch [22/100], Loss: 0.0940, Validation Loss: 0.3625
	--> Epoch [23/100], Loss: 0.1160, Validation Loss: 0.3557
	--> Epoch [24/100], Loss: 0.2125, Validation Loss: 0.3496
	--> Epoch [25/100], Loss: 0.1095, Validation Loss: 0.3438
	--> Epoch [26/100], Loss: 0.0927, Validation Loss: 0.3393
	--> Epoch [27/100], Loss: 0.0805, Validation Loss: 0.3340
	--> Epoch [28/100], Loss: 0.1033, Validation Loss: 0.3287
	--> Epoch [29/100], Loss: 0.1137, Validation Loss: 0.3230
	--> Epoch [30/100], Loss: 0.1179, Validation Loss: 0.3158
	--> Epoch [31/100], Loss: 0.0846, Validation Loss: 0.3097
	--> Epoch [32/100], Loss: 0.0736, Validation Loss: 0.3071
	--> Epoch [33/100], Loss: 0.0558, Validation Loss: 0.3019
	--> Epoch [34/100], Loss: 0.1525, Validation Loss: 0.2983
	--> Epoch [35/100], Loss: 0.1620, Validation Loss: 0.2945
	--> Epoch [36/100], Loss: 0.0779, Validation Loss: 0.2904
	--> Epoch [37/100], Loss: 0.0536, Validation Loss: 0.2874
	--> Epoch [38/100], Loss: 0.0379, Validation Loss: 0.2854
	--> Epoch [39/100], Loss: 0.0938, Validation Loss: 0.2829
	--> Epoch [40/100], Loss: 0.0741, Validation Loss: 0.2808
	--> Epoch [41/100], Loss: 0.0947, Validation Loss: 0.2792
	--> Epoch [42/100], Loss: 0.0457, Validation Loss: 0.2763
	--> Epoch [43/100], Loss: 0.0521, Validation Loss: 0.2741
	--> Epoch [44/100], Loss: 0.0796, Validation Loss: 0.2713
	--> Epoch [45/100], Loss: 0.0340, Validation Loss: 0.2702
	--> Epoch [46/100], Loss: 0.0443, Validation Loss: 0.2673
	--> Epoch [47/100], Loss: 0.0263, Validation Loss: 0.2647
	--> Epoch [48/100], Loss: 0.0267, Validation Loss: 0.2639
	--> Epoch [49/100], Loss: 0.0223, Validation Loss: 0.2620
	--> Epoch [50/100], Loss: 0.0310, Validation Loss: 0.2582
	--> Epoch [51/100], Loss: 0.0617, Validation Loss: 0.2559
	--> Epoch [52/100], Loss: 0.1624, Validation Loss: 0.2531
	--> Epoch [53/100], Loss: 0.1041, Validation Loss: 0.2502
	--> Epoch [54/100], Loss: 0.0070, Validation Loss: 0.2482
	--> Epoch [55/100], Loss: 0.0087, Validation Loss: 0.2466
	--> Epoch [56/100], Loss: 0.0360, Validation Loss: 0.2455
	--> Epoch [57/100], Loss: 0.0112, Validation Loss: 0.2456
	--> Epoch [58/100], Loss: 0.0088, Validation Loss: 0.2438
	--> Epoch [59/100], Loss: 0.0102, Validation Loss: 0.2410
	--> Epoch [60/100], Loss: 0.0296, Validation Loss: 0.2393
	--> Epoch [61/100], Loss: 0.1112, Validation Loss: 0.2376
	--> Epoch [62/100], Loss: 0.0316, Validation Loss: 0.2373
	--> Epoch [63/100], Loss: 0.0047, Validation Loss: 0.2361
	--> Epoch [64/100], Loss: 0.0484, Validation Loss: 0.2349
	--> Epoch [65/100], Loss: 0.0467, Validation Loss: 0.2323
	--> Epoch [66/100], Loss: 0.0210, Validation Loss: 0.2312
	--> Epoch [67/100], Loss: 0.0874, Validation Loss: 0.2289
	--> Epoch [68/100], Loss: 0.0086, Validation Loss: 0.2276
	--> Epoch [69/100], Loss: 0.0992, Validation Loss: 0.2250
	--> Epoch [70/100], Loss: 0.0795, Validation Loss: 0.2228
	--> Epoch [71/100], Loss: 0.0228, Validation Loss: 0.2215
	--> Epoch [72/100], Loss: 0.0099, Validation Loss: 0.2217
	--> Epoch [73/100], Loss: 0.0123, Validation Loss: 0.2199
	--> Epoch [74/100], Loss: 0.0217, Validation Loss: 0.2191
	--> Epoch [75/100], Loss: 0.0086, Validation Loss: 0.2183
	--> Epoch [76/100], Loss: 0.0198, Validation Loss: 0.2159
	--> Epoch [77/100], Loss: 0.0106, Validation Loss: 0.2152
	--> Epoch [78/100], Loss: 0.0193, Validation Loss: 0.2145
	--> Epoch [79/100], Loss: 0.1066, Validation Loss: 0.2124
	--> Epoch [80/100], Loss: 0.0077, Validation Loss: 0.2121
	--> Epoch [81/100], Loss: 0.0076, Validation Loss: 0.2120
	--> Epoch [82/100], Loss: 0.0874, Validation Loss: 0.2095
	--> Epoch [83/100], Loss: 0.0434, Validation Loss: 0.2092
	--> Epoch [84/100], Loss: 0.0797, Validation Loss: 0.2092
	--> Epoch [85/100], Loss: 0.0105, Validation Loss: 0.2078
	--> Epoch [86/100], Loss: 0.0132, Validation Loss: 0.2094
	--> Epoch [87/100], Loss: 0.1379, Validation Loss: 0.2096
	--> Epoch [88/100], Loss: 0.0241, Validation Loss: 0.2103
Early stopping
	--> Training for Fold 1 took 0.801199197769165 sec, using 88 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8238, Validation Loss: 0.6316
	--> Epoch [2/100], Loss: 0.6595, Validation Loss: 0.6044
	--> Epoch [3/100], Loss: 0.6577, Validation Loss: 0.5843
	--> Epoch [4/100], Loss: 0.6618, Validation Loss: 0.5574
	--> Epoch [5/100], Loss: 0.5703, Validation Loss: 0.5362
	--> Epoch [6/100], Loss: 0.5872, Validation Loss: 0.5169
	--> Epoch [7/100], Loss: 0.4839, Validation Loss: 0.5006
	--> Epoch [8/100], Loss: 0.4241, Validation Loss: 0.4844
	--> Epoch [9/100], Loss: 0.3924, Validation Loss: 0.4676
	--> Epoch [10/100], Loss: 0.3808, Validation Loss: 0.4545
	--> Epoch [11/100], Loss: 0.3831, Validation Loss: 0.4392
	--> Epoch [12/100], Loss: 0.3002, Validation Loss: 0.4268
	--> Epoch [13/100], Loss: 0.2968, Validation Loss: 0.4149
	--> Epoch [14/100], Loss: 0.4491, Validation Loss: 0.4014
	--> Epoch [15/100], Loss: 0.2338, Validation Loss: 0.3900
	--> Epoch [16/100], Loss: 0.3115, Validation Loss: 0.3789
	--> Epoch [17/100], Loss: 0.3527, Validation Loss: 0.3667
	--> Epoch [18/100], Loss: 0.2381, Validation Loss: 0.3558
	--> Epoch [19/100], Loss: 0.2481, Validation Loss: 0.3477
	--> Epoch [20/100], Loss: 0.2315, Validation Loss: 0.3384
	--> Epoch [21/100], Loss: 0.2152, Validation Loss: 0.3290
	--> Epoch [22/100], Loss: 0.1789, Validation Loss: 0.3209
	--> Epoch [23/100], Loss: 0.1095, Validation Loss: 0.3136
	--> Epoch [24/100], Loss: 0.1856, Validation Loss: 0.3062
	--> Epoch [25/100], Loss: 0.2189, Validation Loss: 0.2996
	--> Epoch [26/100], Loss: 0.1736, Validation Loss: 0.2921
	--> Epoch [27/100], Loss: 0.0869, Validation Loss: 0.2850
	--> Epoch [28/100], Loss: 0.0818, Validation Loss: 0.2793
	--> Epoch [29/100], Loss: 0.1411, Validation Loss: 0.2725
	--> Epoch [30/100], Loss: 0.2032, Validation Loss: 0.2664
	--> Epoch [31/100], Loss: 0.1121, Validation Loss: 0.2615
	--> Epoch [32/100], Loss: 0.1438, Validation Loss: 0.2551
	--> Epoch [33/100], Loss: 0.0994, Validation Loss: 0.2492
	--> Epoch [34/100], Loss: 0.1271, Validation Loss: 0.2455
	--> Epoch [35/100], Loss: 0.2358, Validation Loss: 0.2412
	--> Epoch [36/100], Loss: 0.1431, Validation Loss: 0.2362
	--> Epoch [37/100], Loss: 0.1024, Validation Loss: 0.2314
	--> Epoch [38/100], Loss: 0.0896, Validation Loss: 0.2278
	--> Epoch [39/100], Loss: 0.0645, Validation Loss: 0.2248
	--> Epoch [40/100], Loss: 0.0863, Validation Loss: 0.2204
	--> Epoch [41/100], Loss: 0.1216, Validation Loss: 0.2178
	--> Epoch [42/100], Loss: 0.0714, Validation Loss: 0.2122
	--> Epoch [43/100], Loss: 0.0341, Validation Loss: 0.2095
	--> Epoch [44/100], Loss: 0.0476, Validation Loss: 0.2065
	--> Epoch [45/100], Loss: 0.0757, Validation Loss: 0.2041
	--> Epoch [46/100], Loss: 0.0537, Validation Loss: 0.2025
	--> Epoch [47/100], Loss: 0.1107, Validation Loss: 0.1985
	--> Epoch [48/100], Loss: 0.0774, Validation Loss: 0.1943
	--> Epoch [49/100], Loss: 0.0717, Validation Loss: 0.1915
	--> Epoch [50/100], Loss: 0.1332, Validation Loss: 0.1892
	--> Epoch [51/100], Loss: 0.1014, Validation Loss: 0.1867
	--> Epoch [52/100], Loss: 0.0231, Validation Loss: 0.1849
	--> Epoch [53/100], Loss: 0.0505, Validation Loss: 0.1819
	--> Epoch [54/100], Loss: 0.0602, Validation Loss: 0.1786
	--> Epoch [55/100], Loss: 0.0450, Validation Loss: 0.1753
	--> Epoch [56/100], Loss: 0.0285, Validation Loss: 0.1743
	--> Epoch [57/100], Loss: 0.0461, Validation Loss: 0.1715
	--> Epoch [58/100], Loss: 0.0496, Validation Loss: 0.1691
	--> Epoch [59/100], Loss: 0.0344, Validation Loss: 0.1677
	--> Epoch [60/100], Loss: 0.1214, Validation Loss: 0.1660
	--> Epoch [61/100], Loss: 0.0957, Validation Loss: 0.1642
	--> Epoch [62/100], Loss: 0.0344, Validation Loss: 0.1625
	--> Epoch [63/100], Loss: 0.0116, Validation Loss: 0.1617
	--> Epoch [64/100], Loss: 0.0685, Validation Loss: 0.1596
	--> Epoch [65/100], Loss: 0.0986, Validation Loss: 0.1589
	--> Epoch [66/100], Loss: 0.0158, Validation Loss: 0.1581
	--> Epoch [67/100], Loss: 0.0959, Validation Loss: 0.1567
	--> Epoch [68/100], Loss: 0.0160, Validation Loss: 0.1547
	--> Epoch [69/100], Loss: 0.1165, Validation Loss: 0.1530
	--> Epoch [70/100], Loss: 0.1012, Validation Loss: 0.1487
	--> Epoch [71/100], Loss: 0.0140, Validation Loss: 0.1472
	--> Epoch [72/100], Loss: 0.1086, Validation Loss: 0.1476
	--> Epoch [73/100], Loss: 0.0215, Validation Loss: 0.1456
	--> Epoch [74/100], Loss: 0.0352, Validation Loss: 0.1446
	--> Epoch [75/100], Loss: 0.0242, Validation Loss: 0.1441
	--> Epoch [76/100], Loss: 0.0948, Validation Loss: 0.1437
	--> Epoch [77/100], Loss: 0.0504, Validation Loss: 0.1420
	--> Epoch [78/100], Loss: 0.0140, Validation Loss: 0.1412
	--> Epoch [79/100], Loss: 0.0078, Validation Loss: 0.1403
	--> Epoch [80/100], Loss: 0.0126, Validation Loss: 0.1380
	--> Epoch [81/100], Loss: 0.0052, Validation Loss: 0.1371
	--> Epoch [82/100], Loss: 0.1050, Validation Loss: 0.1366
	--> Epoch [83/100], Loss: 0.0319, Validation Loss: 0.1354
	--> Epoch [84/100], Loss: 0.0016, Validation Loss: 0.1360
	--> Epoch [85/100], Loss: 0.0219, Validation Loss: 0.1352
	--> Epoch [86/100], Loss: 0.0115, Validation Loss: 0.1337
	--> Epoch [87/100], Loss: 0.0198, Validation Loss: 0.1322
	--> Epoch [88/100], Loss: 0.0969, Validation Loss: 0.1304
	--> Epoch [89/100], Loss: 0.0206, Validation Loss: 0.1286
	--> Epoch [90/100], Loss: 0.0015, Validation Loss: 0.1284
	--> Epoch [91/100], Loss: 0.0152, Validation Loss: 0.1277
	--> Epoch [92/100], Loss: 0.0300, Validation Loss: 0.1284
	--> Epoch [93/100], Loss: 0.1890, Validation Loss: 0.1259
	--> Epoch [94/100], Loss: 0.0173, Validation Loss: 0.1256
	--> Epoch [95/100], Loss: 0.0146, Validation Loss: 0.1251
	--> Epoch [96/100], Loss: 0.0395, Validation Loss: 0.1241
	--> Epoch [97/100], Loss: 0.0220, Validation Loss: 0.1221
	--> Epoch [98/100], Loss: 0.0109, Validation Loss: 0.1215
	--> Epoch [99/100], Loss: 0.0749, Validation Loss: 0.1210
	--> Epoch [100/100], Loss: 0.0215, Validation Loss: 0.1204
	--> Training for Fold 2 took 0.8167324066162109 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6587, Validation Loss: 0.6936
	--> Epoch [2/100], Loss: 0.6145, Validation Loss: 0.6787
	--> Epoch [3/100], Loss: 0.5866, Validation Loss: 0.6628
	--> Epoch [4/100], Loss: 0.5727, Validation Loss: 0.6508
	--> Epoch [5/100], Loss: 0.5563, Validation Loss: 0.6402
	--> Epoch [6/100], Loss: 0.5053, Validation Loss: 0.6301
	--> Epoch [7/100], Loss: 0.4978, Validation Loss: 0.6187
	--> Epoch [8/100], Loss: 0.5104, Validation Loss: 0.6068
	--> Epoch [9/100], Loss: 0.4381, Validation Loss: 0.5949
	--> Epoch [10/100], Loss: 0.4433, Validation Loss: 0.5831
	--> Epoch [11/100], Loss: 0.3720, Validation Loss: 0.5703
	--> Epoch [12/100], Loss: 0.4026, Validation Loss: 0.5575
	--> Epoch [13/100], Loss: 0.3812, Validation Loss: 0.5457
	--> Epoch [14/100], Loss: 0.3105, Validation Loss: 0.5365
	--> Epoch [15/100], Loss: 0.3229, Validation Loss: 0.5277
	--> Epoch [16/100], Loss: 0.2675, Validation Loss: 0.5161
	--> Epoch [17/100], Loss: 0.2619, Validation Loss: 0.5056
	--> Epoch [18/100], Loss: 0.3423, Validation Loss: 0.4947
	--> Epoch [19/100], Loss: 0.2495, Validation Loss: 0.4863
	--> Epoch [20/100], Loss: 0.2194, Validation Loss: 0.4762
	--> Epoch [21/100], Loss: 0.2024, Validation Loss: 0.4647
	--> Epoch [22/100], Loss: 0.1981, Validation Loss: 0.4572
	--> Epoch [23/100], Loss: 0.1547, Validation Loss: 0.4482
	--> Epoch [24/100], Loss: 0.1692, Validation Loss: 0.4388
	--> Epoch [25/100], Loss: 0.2175, Validation Loss: 0.4300
	--> Epoch [26/100], Loss: 0.1519, Validation Loss: 0.4266
	--> Epoch [27/100], Loss: 0.2651, Validation Loss: 0.4210
	--> Epoch [28/100], Loss: 0.2499, Validation Loss: 0.4150
	--> Epoch [29/100], Loss: 0.1942, Validation Loss: 0.4093
	--> Epoch [30/100], Loss: 0.1839, Validation Loss: 0.4040
	--> Epoch [31/100], Loss: 0.0739, Validation Loss: 0.3994
	--> Epoch [32/100], Loss: 0.1273, Validation Loss: 0.3946
	--> Epoch [33/100], Loss: 0.0627, Validation Loss: 0.3906
	--> Epoch [34/100], Loss: 0.1214, Validation Loss: 0.3854
	--> Epoch [35/100], Loss: 0.1092, Validation Loss: 0.3843
	--> Epoch [36/100], Loss: 0.0869, Validation Loss: 0.3814
	--> Epoch [37/100], Loss: 0.0913, Validation Loss: 0.3795
	--> Epoch [38/100], Loss: 0.0825, Validation Loss: 0.3780
	--> Epoch [39/100], Loss: 0.0491, Validation Loss: 0.3752
	--> Epoch [40/100], Loss: 0.1035, Validation Loss: 0.3762
	--> Epoch [41/100], Loss: 0.0936, Validation Loss: 0.3754
	--> Epoch [42/100], Loss: 0.1037, Validation Loss: 0.3730
	--> Epoch [43/100], Loss: 0.0623, Validation Loss: 0.3707
	--> Epoch [44/100], Loss: 0.0352, Validation Loss: 0.3698
	--> Epoch [45/100], Loss: 0.1179, Validation Loss: 0.3673
	--> Epoch [46/100], Loss: 0.1717, Validation Loss: 0.3658
	--> Epoch [47/100], Loss: 0.0312, Validation Loss: 0.3632
	--> Epoch [48/100], Loss: 0.0384, Validation Loss: 0.3619
	--> Epoch [49/100], Loss: 0.1665, Validation Loss: 0.3632
	--> Epoch [50/100], Loss: 0.0819, Validation Loss: 0.3613
	--> Epoch [51/100], Loss: 0.0991, Validation Loss: 0.3596
	--> Epoch [52/100], Loss: 0.1315, Validation Loss: 0.3555
	--> Epoch [53/100], Loss: 0.0494, Validation Loss: 0.3541
	--> Epoch [54/100], Loss: 0.0167, Validation Loss: 0.3521
	--> Epoch [55/100], Loss: 0.0195, Validation Loss: 0.3511
	--> Epoch [56/100], Loss: 0.0554, Validation Loss: 0.3513
	--> Epoch [57/100], Loss: 0.0979, Validation Loss: 0.3505
	--> Epoch [58/100], Loss: 0.1079, Validation Loss: 0.3498
	--> Epoch [59/100], Loss: 0.1491, Validation Loss: 0.3492
	--> Epoch [60/100], Loss: 0.0612, Validation Loss: 0.3485
	--> Epoch [61/100], Loss: 0.0754, Validation Loss: 0.3477
	--> Epoch [62/100], Loss: 0.0386, Validation Loss: 0.3487
	--> Epoch [63/100], Loss: 0.0751, Validation Loss: 0.3481
	--> Epoch [64/100], Loss: 0.1722, Validation Loss: 0.3468
	--> Epoch [65/100], Loss: 0.0954, Validation Loss: 0.3472
	--> Epoch [66/100], Loss: 0.0120, Validation Loss: 0.3474
	--> Epoch [67/100], Loss: 0.0864, Validation Loss: 0.3482
Early stopping
	--> Training for Fold 3 took 0.5654318332672119 sec, using 67 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7413, Validation Loss: 0.6559
	--> Epoch [2/100], Loss: 0.7722, Validation Loss: 0.6369
	--> Epoch [3/100], Loss: 0.6572, Validation Loss: 0.6211
	--> Epoch [4/100], Loss: 0.6165, Validation Loss: 0.6093
	--> Epoch [5/100], Loss: 0.5638, Validation Loss: 0.5950
	--> Epoch [6/100], Loss: 0.5298, Validation Loss: 0.5884
	--> Epoch [7/100], Loss: 0.4761, Validation Loss: 0.5766
	--> Epoch [8/100], Loss: 0.4688, Validation Loss: 0.5660
	--> Epoch [9/100], Loss: 0.4376, Validation Loss: 0.5541
	--> Epoch [10/100], Loss: 0.5149, Validation Loss: 0.5477
	--> Epoch [11/100], Loss: 0.4067, Validation Loss: 0.5373
	--> Epoch [12/100], Loss: 0.3541, Validation Loss: 0.5226
	--> Epoch [13/100], Loss: 0.3460, Validation Loss: 0.5148
	--> Epoch [14/100], Loss: 0.3070, Validation Loss: 0.5020
	--> Epoch [15/100], Loss: 0.2701, Validation Loss: 0.4923
	--> Epoch [16/100], Loss: 0.4004, Validation Loss: 0.4842
	--> Epoch [17/100], Loss: 0.2864, Validation Loss: 0.4737
	--> Epoch [18/100], Loss: 0.2909, Validation Loss: 0.4674
	--> Epoch [19/100], Loss: 0.2240, Validation Loss: 0.4563
	--> Epoch [20/100], Loss: 0.2235, Validation Loss: 0.4501
	--> Epoch [21/100], Loss: 0.2608, Validation Loss: 0.4411
	--> Epoch [22/100], Loss: 0.1683, Validation Loss: 0.4308
	--> Epoch [23/100], Loss: 0.2643, Validation Loss: 0.4256
	--> Epoch [24/100], Loss: 0.1935, Validation Loss: 0.4160
	--> Epoch [25/100], Loss: 0.1124, Validation Loss: 0.4086
	--> Epoch [26/100], Loss: 0.1038, Validation Loss: 0.4041
	--> Epoch [27/100], Loss: 0.1341, Validation Loss: 0.3968
	--> Epoch [28/100], Loss: 0.2132, Validation Loss: 0.3913
	--> Epoch [29/100], Loss: 0.1448, Validation Loss: 0.3894
	--> Epoch [30/100], Loss: 0.1212, Validation Loss: 0.3840
	--> Epoch [31/100], Loss: 0.1413, Validation Loss: 0.3766
	--> Epoch [32/100], Loss: 0.1040, Validation Loss: 0.3717
	--> Epoch [33/100], Loss: 0.1396, Validation Loss: 0.3670
	--> Epoch [34/100], Loss: 0.1250, Validation Loss: 0.3600
	--> Epoch [35/100], Loss: 0.0636, Validation Loss: 0.3582
	--> Epoch [36/100], Loss: 0.0930, Validation Loss: 0.3560
	--> Epoch [37/100], Loss: 0.0782, Validation Loss: 0.3530
	--> Epoch [38/100], Loss: 0.1073, Validation Loss: 0.3514
	--> Epoch [39/100], Loss: 0.1012, Validation Loss: 0.3479
	--> Epoch [40/100], Loss: 0.1375, Validation Loss: 0.3435
	--> Epoch [41/100], Loss: 0.0251, Validation Loss: 0.3411
	--> Epoch [42/100], Loss: 0.0746, Validation Loss: 0.3400
	--> Epoch [43/100], Loss: 0.0960, Validation Loss: 0.3388
	--> Epoch [44/100], Loss: 0.1216, Validation Loss: 0.3376
	--> Epoch [45/100], Loss: 0.0455, Validation Loss: 0.3359
	--> Epoch [46/100], Loss: 0.0932, Validation Loss: 0.3352
	--> Epoch [47/100], Loss: 0.0451, Validation Loss: 0.3330
	--> Epoch [48/100], Loss: 0.0316, Validation Loss: 0.3305
	--> Epoch [49/100], Loss: 0.0754, Validation Loss: 0.3286
	--> Epoch [50/100], Loss: 0.0749, Validation Loss: 0.3255
	--> Epoch [51/100], Loss: 0.0422, Validation Loss: 0.3262
	--> Epoch [52/100], Loss: 0.1320, Validation Loss: 0.3246
	--> Epoch [53/100], Loss: 0.0541, Validation Loss: 0.3243
	--> Epoch [54/100], Loss: 0.0550, Validation Loss: 0.3205
	--> Epoch [55/100], Loss: 0.1418, Validation Loss: 0.3175
	--> Epoch [56/100], Loss: 0.0900, Validation Loss: 0.3211
	--> Epoch [57/100], Loss: 0.0920, Validation Loss: 0.3215
	--> Epoch [58/100], Loss: 0.0320, Validation Loss: 0.3216
Early stopping
	--> Training for Fold 4 took 0.5421271324157715 sec, using 58 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8970, Validation Loss: 0.6348
	--> Epoch [2/100], Loss: 0.7195, Validation Loss: 0.6244
	--> Epoch [3/100], Loss: 0.7901, Validation Loss: 0.6152
	--> Epoch [4/100], Loss: 0.7040, Validation Loss: 0.6030
	--> Epoch [5/100], Loss: 0.6159, Validation Loss: 0.5967
	--> Epoch [6/100], Loss: 0.6792, Validation Loss: 0.5905
	--> Epoch [7/100], Loss: 0.5465, Validation Loss: 0.5863
	--> Epoch [8/100], Loss: 0.5594, Validation Loss: 0.5800
	--> Epoch [9/100], Loss: 0.4670, Validation Loss: 0.5775
	--> Epoch [10/100], Loss: 0.4032, Validation Loss: 0.5771
	--> Epoch [11/100], Loss: 0.3648, Validation Loss: 0.5773
	--> Epoch [12/100], Loss: 0.4116, Validation Loss: 0.5775
	--> Epoch [13/100], Loss: 0.3267, Validation Loss: 0.5714
	--> Epoch [14/100], Loss: 0.3491, Validation Loss: 0.5702
	--> Epoch [15/100], Loss: 0.2376, Validation Loss: 0.5698
	--> Epoch [16/100], Loss: 0.3388, Validation Loss: 0.5685
	--> Epoch [17/100], Loss: 0.2519, Validation Loss: 0.5688
	--> Epoch [18/100], Loss: 0.2553, Validation Loss: 0.5668
	--> Epoch [19/100], Loss: 0.2113, Validation Loss: 0.5675
	--> Epoch [20/100], Loss: 0.1536, Validation Loss: 0.5661
	--> Epoch [21/100], Loss: 0.2022, Validation Loss: 0.5641
	--> Epoch [22/100], Loss: 0.1422, Validation Loss: 0.5639
	--> Epoch [23/100], Loss: 0.2048, Validation Loss: 0.5672
	--> Epoch [24/100], Loss: 0.1670, Validation Loss: 0.5627
	--> Epoch [25/100], Loss: 0.1311, Validation Loss: 0.5618
	--> Epoch [26/100], Loss: 0.0897, Validation Loss: 0.5607
	--> Epoch [27/100], Loss: 0.1027, Validation Loss: 0.5606
	--> Epoch [28/100], Loss: 0.0879, Validation Loss: 0.5607
	--> Epoch [29/100], Loss: 0.0697, Validation Loss: 0.5612
	--> Epoch [30/100], Loss: 0.1115, Validation Loss: 0.5634
Early stopping
	--> Training for Fold 5 took 0.2427659034729004 sec, using 30 epochs

Median number of epochs used: 67 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/67], Loss: 0.6640
	--> Final training Epoch [2/67], Loss: 0.6470
	--> Final training Epoch [3/67], Loss: 0.6210
	--> Final training Epoch [4/67], Loss: 0.6206
	--> Final training Epoch [5/67], Loss: 0.5719
	--> Final training Epoch [6/67], Loss: 0.5639
	--> Final training Epoch [7/67], Loss: 0.5265
	--> Final training Epoch [8/67], Loss: 0.5196
	--> Final training Epoch [9/67], Loss: 0.4536
	--> Final training Epoch [10/67], Loss: 0.4843
	--> Final training Epoch [11/67], Loss: 0.4675
	--> Final training Epoch [12/67], Loss: 0.4445
	--> Final training Epoch [13/67], Loss: 0.4294
	--> Final training Epoch [14/67], Loss: 0.4211
	--> Final training Epoch [15/67], Loss: 0.3845
	--> Final training Epoch [16/67], Loss: 0.3465
	--> Final training Epoch [17/67], Loss: 0.3526
	--> Final training Epoch [18/67], Loss: 0.3635
	--> Final training Epoch [19/67], Loss: 0.3270
	--> Final training Epoch [20/67], Loss: 0.3313
	--> Final training Epoch [21/67], Loss: 0.3713
	--> Final training Epoch [22/67], Loss: 0.3602
	--> Final training Epoch [23/67], Loss: 0.3274
	--> Final training Epoch [24/67], Loss: 0.2603
	--> Final training Epoch [25/67], Loss: 0.2341
	--> Final training Epoch [26/67], Loss: 0.2472
	--> Final training Epoch [27/67], Loss: 0.2953
	--> Final training Epoch [28/67], Loss: 0.2513
	--> Final training Epoch [29/67], Loss: 0.1862
	--> Final training Epoch [30/67], Loss: 0.2433
	--> Final training Epoch [31/67], Loss: 0.2297
	--> Final training Epoch [32/67], Loss: 0.2139
	--> Final training Epoch [33/67], Loss: 0.1894
	--> Final training Epoch [34/67], Loss: 0.2217
	--> Final training Epoch [35/67], Loss: 0.1775
	--> Final training Epoch [36/67], Loss: 0.2027
	--> Final training Epoch [37/67], Loss: 0.1658
	--> Final training Epoch [38/67], Loss: 0.1855
	--> Final training Epoch [39/67], Loss: 0.1600
	--> Final training Epoch [40/67], Loss: 0.1907
	--> Final training Epoch [41/67], Loss: 0.1558
	--> Final training Epoch [42/67], Loss: 0.1483
	--> Final training Epoch [43/67], Loss: 0.1039
	--> Final training Epoch [44/67], Loss: 0.1605
	--> Final training Epoch [45/67], Loss: 0.1112
	--> Final training Epoch [46/67], Loss: 0.1142
	--> Final training Epoch [47/67], Loss: 0.1393
	--> Final training Epoch [48/67], Loss: 0.1538
	--> Final training Epoch [49/67], Loss: 0.1889
	--> Final training Epoch [50/67], Loss: 0.1434
	--> Final training Epoch [51/67], Loss: 0.1095
	--> Final training Epoch [52/67], Loss: 0.0927
	--> Final training Epoch [53/67], Loss: 0.1129
	--> Final training Epoch [54/67], Loss: 0.1081
	--> Final training Epoch [55/67], Loss: 0.0865
	--> Final training Epoch [56/67], Loss: 0.1441
	--> Final training Epoch [57/67], Loss: 0.1692
	--> Final training Epoch [58/67], Loss: 0.1147
	--> Final training Epoch [59/67], Loss: 0.1089
	--> Final training Epoch [60/67], Loss: 0.0816
	--> Final training Epoch [61/67], Loss: 0.1038
	--> Final training Epoch [62/67], Loss: 0.1442
	--> Final training Epoch [63/67], Loss: 0.1338
	--> Final training Epoch [64/67], Loss: 0.1216
	--> Final training Epoch [65/67], Loss: 0.0755
	--> Final training Epoch [66/67], Loss: 0.1143
	--> Final training Epoch [67/67], Loss: 0.1101

Final training took 0.528660774230957 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.9752
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8585, Validation Loss: 0.3774,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3774

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5498, Validation Loss: 0.6810
	--> Epoch [2/100], Loss: 0.5823, Validation Loss: 0.6503
	--> Epoch [3/100], Loss: 0.5362, Validation Loss: 0.6255
	--> Epoch [4/100], Loss: 0.4829, Validation Loss: 0.6055
	--> Epoch [5/100], Loss: 0.5052, Validation Loss: 0.5895
	--> Epoch [6/100], Loss: 0.4870, Validation Loss: 0.5761
	--> Epoch [7/100], Loss: 0.4979, Validation Loss: 0.5633
	--> Epoch [8/100], Loss: 0.5017, Validation Loss: 0.5519
	--> Epoch [9/100], Loss: 0.3913, Validation Loss: 0.5356
	--> Epoch [10/100], Loss: 0.3668, Validation Loss: 0.5227
	--> Epoch [11/100], Loss: 0.4151, Validation Loss: 0.5157
	--> Epoch [12/100], Loss: 0.3821, Validation Loss: 0.5082
	--> Epoch [13/100], Loss: 0.4550, Validation Loss: 0.4998
	--> Epoch [14/100], Loss: 0.4074, Validation Loss: 0.4911
	--> Epoch [15/100], Loss: 0.3734, Validation Loss: 0.4770
	--> Epoch [16/100], Loss: 0.4614, Validation Loss: 0.4672
	--> Epoch [17/100], Loss: 0.2819, Validation Loss: 0.4584
	--> Epoch [18/100], Loss: 0.2930, Validation Loss: 0.4469
	--> Epoch [19/100], Loss: 0.3505, Validation Loss: 0.4386
	--> Epoch [20/100], Loss: 0.2958, Validation Loss: 0.4317
	--> Epoch [21/100], Loss: 0.2631, Validation Loss: 0.4271
	--> Epoch [22/100], Loss: 0.3543, Validation Loss: 0.4222
	--> Epoch [23/100], Loss: 0.2574, Validation Loss: 0.4193
	--> Epoch [24/100], Loss: 0.2883, Validation Loss: 0.4146
	--> Epoch [25/100], Loss: 0.2006, Validation Loss: 0.4070
	--> Epoch [26/100], Loss: 0.2135, Validation Loss: 0.4022
	--> Epoch [27/100], Loss: 0.3236, Validation Loss: 0.3969
	--> Epoch [28/100], Loss: 0.2226, Validation Loss: 0.3918
	--> Epoch [29/100], Loss: 0.1665, Validation Loss: 0.3870
	--> Epoch [30/100], Loss: 0.1312, Validation Loss: 0.3820
	--> Epoch [31/100], Loss: 0.3229, Validation Loss: 0.3774
	--> Epoch [32/100], Loss: 0.3579, Validation Loss: 0.3748
	--> Epoch [33/100], Loss: 0.2057, Validation Loss: 0.3714
	--> Epoch [34/100], Loss: 0.1773, Validation Loss: 0.3727
	--> Epoch [35/100], Loss: 0.2222, Validation Loss: 0.3701
	--> Epoch [36/100], Loss: 0.1789, Validation Loss: 0.3703
	--> Epoch [37/100], Loss: 0.3047, Validation Loss: 0.3661
	--> Epoch [38/100], Loss: 0.2389, Validation Loss: 0.3642
	--> Epoch [39/100], Loss: 0.1580, Validation Loss: 0.3621
	--> Epoch [40/100], Loss: 0.1865, Validation Loss: 0.3609
	--> Epoch [41/100], Loss: 0.1209, Validation Loss: 0.3525
	--> Epoch [42/100], Loss: 0.3063, Validation Loss: 0.3536
	--> Epoch [43/100], Loss: 0.2778, Validation Loss: 0.3500
	--> Epoch [44/100], Loss: 0.0752, Validation Loss: 0.3478
	--> Epoch [45/100], Loss: 0.1853, Validation Loss: 0.3439
	--> Epoch [46/100], Loss: 0.0956, Validation Loss: 0.3429
	--> Epoch [47/100], Loss: 0.1068, Validation Loss: 0.3423
	--> Epoch [48/100], Loss: 0.0982, Validation Loss: 0.3423
	--> Epoch [49/100], Loss: 0.1517, Validation Loss: 0.3419
	--> Epoch [50/100], Loss: 0.2494, Validation Loss: 0.3400
	--> Epoch [51/100], Loss: 0.1660, Validation Loss: 0.3406
	--> Epoch [52/100], Loss: 0.3133, Validation Loss: 0.3388
	--> Epoch [53/100], Loss: 0.0907, Validation Loss: 0.3354
	--> Epoch [54/100], Loss: 0.2045, Validation Loss: 0.3333
	--> Epoch [55/100], Loss: 0.1121, Validation Loss: 0.3302
	--> Epoch [56/100], Loss: 0.1521, Validation Loss: 0.3345
	--> Epoch [57/100], Loss: 0.0470, Validation Loss: 0.3334
	--> Epoch [58/100], Loss: 0.0732, Validation Loss: 0.3305
Early stopping
	--> Training for Fold 1 took 0.49710750579833984 sec, using 58 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5385, Validation Loss: 0.7287
	--> Epoch [2/100], Loss: 0.5385, Validation Loss: 0.7088
	--> Epoch [3/100], Loss: 0.5364, Validation Loss: 0.6929
	--> Epoch [4/100], Loss: 0.4856, Validation Loss: 0.6704
	--> Epoch [5/100], Loss: 0.5204, Validation Loss: 0.6534
	--> Epoch [6/100], Loss: 0.4373, Validation Loss: 0.6305
	--> Epoch [7/100], Loss: 0.4041, Validation Loss: 0.6108
	--> Epoch [8/100], Loss: 0.4475, Validation Loss: 0.5909
	--> Epoch [9/100], Loss: 0.4470, Validation Loss: 0.5674
	--> Epoch [10/100], Loss: 0.3773, Validation Loss: 0.5460
	--> Epoch [11/100], Loss: 0.3306, Validation Loss: 0.5254
	--> Epoch [12/100], Loss: 0.3117, Validation Loss: 0.5046
	--> Epoch [13/100], Loss: 0.3525, Validation Loss: 0.4839
	--> Epoch [14/100], Loss: 0.5486, Validation Loss: 0.4714
	--> Epoch [15/100], Loss: 0.3356, Validation Loss: 0.4564
	--> Epoch [16/100], Loss: 0.3549, Validation Loss: 0.4429
	--> Epoch [17/100], Loss: 0.2642, Validation Loss: 0.4297
	--> Epoch [18/100], Loss: 0.3735, Validation Loss: 0.4166
	--> Epoch [19/100], Loss: 0.3044, Validation Loss: 0.4023
	--> Epoch [20/100], Loss: 0.3090, Validation Loss: 0.3907
	--> Epoch [21/100], Loss: 0.2505, Validation Loss: 0.3784
	--> Epoch [22/100], Loss: 0.2931, Validation Loss: 0.3698
	--> Epoch [23/100], Loss: 0.2549, Validation Loss: 0.3585
	--> Epoch [24/100], Loss: 0.1989, Validation Loss: 0.3511
	--> Epoch [25/100], Loss: 0.1494, Validation Loss: 0.3419
	--> Epoch [26/100], Loss: 0.1993, Validation Loss: 0.3314
	--> Epoch [27/100], Loss: 0.2004, Validation Loss: 0.3247
	--> Epoch [28/100], Loss: 0.2894, Validation Loss: 0.3191
	--> Epoch [29/100], Loss: 0.3087, Validation Loss: 0.3128
	--> Epoch [30/100], Loss: 0.1984, Validation Loss: 0.3050
	--> Epoch [31/100], Loss: 0.1897, Validation Loss: 0.2978
	--> Epoch [32/100], Loss: 0.2104, Validation Loss: 0.2927
	--> Epoch [33/100], Loss: 0.2258, Validation Loss: 0.2894
	--> Epoch [34/100], Loss: 0.1897, Validation Loss: 0.2854
	--> Epoch [35/100], Loss: 0.2070, Validation Loss: 0.2809
	--> Epoch [36/100], Loss: 0.3277, Validation Loss: 0.2750
	--> Epoch [37/100], Loss: 0.2130, Validation Loss: 0.2697
	--> Epoch [38/100], Loss: 0.0669, Validation Loss: 0.2659
	--> Epoch [39/100], Loss: 0.2114, Validation Loss: 0.2630
	--> Epoch [40/100], Loss: 0.1303, Validation Loss: 0.2588
	--> Epoch [41/100], Loss: 0.1037, Validation Loss: 0.2560
	--> Epoch [42/100], Loss: 0.1282, Validation Loss: 0.2515
	--> Epoch [43/100], Loss: 0.1978, Validation Loss: 0.2496
	--> Epoch [44/100], Loss: 0.1602, Validation Loss: 0.2462
	--> Epoch [45/100], Loss: 0.1894, Validation Loss: 0.2460
	--> Epoch [46/100], Loss: 0.1581, Validation Loss: 0.2423
	--> Epoch [47/100], Loss: 0.0934, Validation Loss: 0.2406
	--> Epoch [48/100], Loss: 0.0914, Validation Loss: 0.2384
	--> Epoch [49/100], Loss: 0.2338, Validation Loss: 0.2358
	--> Epoch [50/100], Loss: 0.2163, Validation Loss: 0.2317
	--> Epoch [51/100], Loss: 0.1591, Validation Loss: 0.2300
	--> Epoch [52/100], Loss: 0.0928, Validation Loss: 0.2284
	--> Epoch [53/100], Loss: 0.0945, Validation Loss: 0.2268
	--> Epoch [54/100], Loss: 0.1089, Validation Loss: 0.2259
	--> Epoch [55/100], Loss: 0.1531, Validation Loss: 0.2224
	--> Epoch [56/100], Loss: 0.1381, Validation Loss: 0.2218
	--> Epoch [57/100], Loss: 0.2130, Validation Loss: 0.2203
	--> Epoch [58/100], Loss: 0.1642, Validation Loss: 0.2191
	--> Epoch [59/100], Loss: 0.1347, Validation Loss: 0.2178
	--> Epoch [60/100], Loss: 0.0828, Validation Loss: 0.2149
	--> Epoch [61/100], Loss: 0.1716, Validation Loss: 0.2128
	--> Epoch [62/100], Loss: 0.1130, Validation Loss: 0.2110
	--> Epoch [63/100], Loss: 0.1398, Validation Loss: 0.2110
	--> Epoch [64/100], Loss: 0.1255, Validation Loss: 0.2090
	--> Epoch [65/100], Loss: 0.0942, Validation Loss: 0.2080
	--> Epoch [66/100], Loss: 0.0366, Validation Loss: 0.2063
	--> Epoch [67/100], Loss: 0.2572, Validation Loss: 0.2045
	--> Epoch [68/100], Loss: 0.3177, Validation Loss: 0.2013
	--> Epoch [69/100], Loss: 0.0230, Validation Loss: 0.2001
	--> Epoch [70/100], Loss: 0.2266, Validation Loss: 0.1992
	--> Epoch [71/100], Loss: 0.1692, Validation Loss: 0.1965
	--> Epoch [72/100], Loss: 0.0758, Validation Loss: 0.1950
	--> Epoch [73/100], Loss: 0.1138, Validation Loss: 0.1948
	--> Epoch [74/100], Loss: 0.2109, Validation Loss: 0.1951
	--> Epoch [75/100], Loss: 0.1358, Validation Loss: 0.1952
	--> Epoch [76/100], Loss: 0.0230, Validation Loss: 0.1912
	--> Epoch [77/100], Loss: 0.0649, Validation Loss: 0.1891
	--> Epoch [78/100], Loss: 0.0221, Validation Loss: 0.1886
	--> Epoch [79/100], Loss: 0.1225, Validation Loss: 0.1879
	--> Epoch [80/100], Loss: 0.0147, Validation Loss: 0.1870
	--> Epoch [81/100], Loss: 0.0618, Validation Loss: 0.1851
	--> Epoch [82/100], Loss: 0.0324, Validation Loss: 0.1829
	--> Epoch [83/100], Loss: 0.0604, Validation Loss: 0.1829
	--> Epoch [84/100], Loss: 0.1268, Validation Loss: 0.1813
	--> Epoch [85/100], Loss: 0.0685, Validation Loss: 0.1803
	--> Epoch [86/100], Loss: 0.0622, Validation Loss: 0.1803
	--> Epoch [87/100], Loss: 0.0168, Validation Loss: 0.1795
	--> Epoch [88/100], Loss: 0.1242, Validation Loss: 0.1784
	--> Epoch [89/100], Loss: 0.1074, Validation Loss: 0.1753
	--> Epoch [90/100], Loss: 0.1091, Validation Loss: 0.1759
	--> Epoch [91/100], Loss: 0.1132, Validation Loss: 0.1721
	--> Epoch [92/100], Loss: 0.0671, Validation Loss: 0.1708
	--> Epoch [93/100], Loss: 0.1678, Validation Loss: 0.1697
	--> Epoch [94/100], Loss: 0.1091, Validation Loss: 0.1695
	--> Epoch [95/100], Loss: 0.0117, Validation Loss: 0.1693
	--> Epoch [96/100], Loss: 0.0717, Validation Loss: 0.1685
	--> Epoch [97/100], Loss: 0.1525, Validation Loss: 0.1670
	--> Epoch [98/100], Loss: 0.1074, Validation Loss: 0.1677
	--> Epoch [99/100], Loss: 0.0651, Validation Loss: 0.1667
	--> Epoch [100/100], Loss: 0.1088, Validation Loss: 0.1661
	--> Training for Fold 2 took 0.8459405899047852 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7550, Validation Loss: 0.6188
	--> Epoch [2/100], Loss: 0.7281, Validation Loss: 0.6073
	--> Epoch [3/100], Loss: 0.7622, Validation Loss: 0.5999
	--> Epoch [4/100], Loss: 0.6454, Validation Loss: 0.5906
	--> Epoch [5/100], Loss: 0.6309, Validation Loss: 0.5757
	--> Epoch [6/100], Loss: 0.7053, Validation Loss: 0.5701
	--> Epoch [7/100], Loss: 0.4848, Validation Loss: 0.5605
	--> Epoch [8/100], Loss: 0.5595, Validation Loss: 0.5544
	--> Epoch [9/100], Loss: 0.5756, Validation Loss: 0.5408
	--> Epoch [10/100], Loss: 0.4965, Validation Loss: 0.5311
	--> Epoch [11/100], Loss: 0.5897, Validation Loss: 0.5239
	--> Epoch [12/100], Loss: 0.4629, Validation Loss: 0.5148
	--> Epoch [13/100], Loss: 0.4315, Validation Loss: 0.5057
	--> Epoch [14/100], Loss: 0.4610, Validation Loss: 0.5000
	--> Epoch [15/100], Loss: 0.4694, Validation Loss: 0.4907
	--> Epoch [16/100], Loss: 0.3694, Validation Loss: 0.4839
	--> Epoch [17/100], Loss: 0.2758, Validation Loss: 0.4758
	--> Epoch [18/100], Loss: 0.2573, Validation Loss: 0.4702
	--> Epoch [19/100], Loss: 0.3372, Validation Loss: 0.4652
	--> Epoch [20/100], Loss: 0.2932, Validation Loss: 0.4603
	--> Epoch [21/100], Loss: 0.2739, Validation Loss: 0.4597
	--> Epoch [22/100], Loss: 0.1508, Validation Loss: 0.4523
	--> Epoch [23/100], Loss: 0.1913, Validation Loss: 0.4448
	--> Epoch [24/100], Loss: 0.2692, Validation Loss: 0.4394
	--> Epoch [25/100], Loss: 0.4221, Validation Loss: 0.4326
	--> Epoch [26/100], Loss: 0.2814, Validation Loss: 0.4272
	--> Epoch [27/100], Loss: 0.1349, Validation Loss: 0.4184
	--> Epoch [28/100], Loss: 0.1483, Validation Loss: 0.4162
	--> Epoch [29/100], Loss: 0.2527, Validation Loss: 0.4115
	--> Epoch [30/100], Loss: 0.1849, Validation Loss: 0.4050
	--> Epoch [31/100], Loss: 0.2115, Validation Loss: 0.4048
	--> Epoch [32/100], Loss: 0.2548, Validation Loss: 0.4015
	--> Epoch [33/100], Loss: 0.1247, Validation Loss: 0.3953
	--> Epoch [34/100], Loss: 0.2075, Validation Loss: 0.3906
	--> Epoch [35/100], Loss: 0.3146, Validation Loss: 0.3893
	--> Epoch [36/100], Loss: 0.2910, Validation Loss: 0.3877
	--> Epoch [37/100], Loss: 0.1611, Validation Loss: 0.3837
	--> Epoch [38/100], Loss: 0.1612, Validation Loss: 0.3791
	--> Epoch [39/100], Loss: 0.1444, Validation Loss: 0.3776
	--> Epoch [40/100], Loss: 0.0806, Validation Loss: 0.3748
	--> Epoch [41/100], Loss: 0.1314, Validation Loss: 0.3701
	--> Epoch [42/100], Loss: 0.2408, Validation Loss: 0.3672
	--> Epoch [43/100], Loss: 0.2526, Validation Loss: 0.3630
	--> Epoch [44/100], Loss: 0.1355, Validation Loss: 0.3610
	--> Epoch [45/100], Loss: 0.0830, Validation Loss: 0.3593
	--> Epoch [46/100], Loss: 0.1308, Validation Loss: 0.3566
	--> Epoch [47/100], Loss: 0.1130, Validation Loss: 0.3554
	--> Epoch [48/100], Loss: 0.3587, Validation Loss: 0.3524
	--> Epoch [49/100], Loss: 0.2641, Validation Loss: 0.3533
	--> Epoch [50/100], Loss: 0.1368, Validation Loss: 0.3512
	--> Epoch [51/100], Loss: 0.1242, Validation Loss: 0.3500
	--> Epoch [52/100], Loss: 0.0732, Validation Loss: 0.3465
	--> Epoch [53/100], Loss: 0.0464, Validation Loss: 0.3459
	--> Epoch [54/100], Loss: 0.2867, Validation Loss: 0.3454
	--> Epoch [55/100], Loss: 0.1329, Validation Loss: 0.3414
	--> Epoch [56/100], Loss: 0.1248, Validation Loss: 0.3401
	--> Epoch [57/100], Loss: 0.0598, Validation Loss: 0.3389
	--> Epoch [58/100], Loss: 0.1818, Validation Loss: 0.3385
	--> Epoch [59/100], Loss: 0.1340, Validation Loss: 0.3377
	--> Epoch [60/100], Loss: 0.0380, Validation Loss: 0.3373
	--> Epoch [61/100], Loss: 0.1326, Validation Loss: 0.3367
	--> Epoch [62/100], Loss: 0.1118, Validation Loss: 0.3361
	--> Epoch [63/100], Loss: 0.1612, Validation Loss: 0.3352
	--> Epoch [64/100], Loss: 0.1296, Validation Loss: 0.3359
	--> Epoch [65/100], Loss: 0.0318, Validation Loss: 0.3369
	--> Epoch [66/100], Loss: 0.1866, Validation Loss: 0.3361
Early stopping
	--> Training for Fold 3 took 0.5459818840026855 sec, using 66 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6742, Validation Loss: 0.6374
	--> Epoch [2/100], Loss: 0.6280, Validation Loss: 0.6244
	--> Epoch [3/100], Loss: 0.6942, Validation Loss: 0.6099
	--> Epoch [4/100], Loss: 0.5693, Validation Loss: 0.6002
	--> Epoch [5/100], Loss: 0.5595, Validation Loss: 0.5825
	--> Epoch [6/100], Loss: 0.5757, Validation Loss: 0.5702
	--> Epoch [7/100], Loss: 0.4832, Validation Loss: 0.5574
	--> Epoch [8/100], Loss: 0.4372, Validation Loss: 0.5457
	--> Epoch [9/100], Loss: 0.4889, Validation Loss: 0.5327
	--> Epoch [10/100], Loss: 0.5894, Validation Loss: 0.5243
	--> Epoch [11/100], Loss: 0.4588, Validation Loss: 0.5085
	--> Epoch [12/100], Loss: 0.3415, Validation Loss: 0.4950
	--> Epoch [13/100], Loss: 0.3911, Validation Loss: 0.4835
	--> Epoch [14/100], Loss: 0.3773, Validation Loss: 0.4733
	--> Epoch [15/100], Loss: 0.4518, Validation Loss: 0.4698
	--> Epoch [16/100], Loss: 0.2619, Validation Loss: 0.4601
	--> Epoch [17/100], Loss: 0.2843, Validation Loss: 0.4512
	--> Epoch [18/100], Loss: 0.3367, Validation Loss: 0.4430
	--> Epoch [19/100], Loss: 0.3475, Validation Loss: 0.4328
	--> Epoch [20/100], Loss: 0.2970, Validation Loss: 0.4266
	--> Epoch [21/100], Loss: 0.2770, Validation Loss: 0.4175
	--> Epoch [22/100], Loss: 0.2395, Validation Loss: 0.4055
	--> Epoch [23/100], Loss: 0.1992, Validation Loss: 0.3975
	--> Epoch [24/100], Loss: 0.3169, Validation Loss: 0.3911
	--> Epoch [25/100], Loss: 0.2785, Validation Loss: 0.3817
	--> Epoch [26/100], Loss: 0.2290, Validation Loss: 0.3736
	--> Epoch [27/100], Loss: 0.1778, Validation Loss: 0.3678
	--> Epoch [28/100], Loss: 0.2543, Validation Loss: 0.3612
	--> Epoch [29/100], Loss: 0.2068, Validation Loss: 0.3555
	--> Epoch [30/100], Loss: 0.1348, Validation Loss: 0.3484
	--> Epoch [31/100], Loss: 0.2680, Validation Loss: 0.3451
	--> Epoch [32/100], Loss: 0.2734, Validation Loss: 0.3418
	--> Epoch [33/100], Loss: 0.2101, Validation Loss: 0.3362
	--> Epoch [34/100], Loss: 0.2017, Validation Loss: 0.3320
	--> Epoch [35/100], Loss: 0.2294, Validation Loss: 0.3265
	--> Epoch [36/100], Loss: 0.2470, Validation Loss: 0.3226
	--> Epoch [37/100], Loss: 0.3092, Validation Loss: 0.3231
	--> Epoch [38/100], Loss: 0.1852, Validation Loss: 0.3188
	--> Epoch [39/100], Loss: 0.2028, Validation Loss: 0.3149
	--> Epoch [40/100], Loss: 0.3243, Validation Loss: 0.3090
	--> Epoch [41/100], Loss: 0.1264, Validation Loss: 0.3049
	--> Epoch [42/100], Loss: 0.1314, Validation Loss: 0.3048
	--> Epoch [43/100], Loss: 0.1089, Validation Loss: 0.3011
	--> Epoch [44/100], Loss: 0.2250, Validation Loss: 0.2972
	--> Epoch [45/100], Loss: 0.0912, Validation Loss: 0.2933
	--> Epoch [46/100], Loss: 0.1608, Validation Loss: 0.2898
	--> Epoch [47/100], Loss: 0.2696, Validation Loss: 0.2857
	--> Epoch [48/100], Loss: 0.2153, Validation Loss: 0.2826
	--> Epoch [49/100], Loss: 0.2221, Validation Loss: 0.2776
	--> Epoch [50/100], Loss: 0.1629, Validation Loss: 0.2755
	--> Epoch [51/100], Loss: 0.2794, Validation Loss: 0.2776
	--> Epoch [52/100], Loss: 0.0871, Validation Loss: 0.2745
	--> Epoch [53/100], Loss: 0.2126, Validation Loss: 0.2756
	--> Epoch [54/100], Loss: 0.1500, Validation Loss: 0.2729
	--> Epoch [55/100], Loss: 0.2143, Validation Loss: 0.2691
	--> Epoch [56/100], Loss: 0.1083, Validation Loss: 0.2664
	--> Epoch [57/100], Loss: 0.2186, Validation Loss: 0.2631
	--> Epoch [58/100], Loss: 0.1515, Validation Loss: 0.2612
	--> Epoch [59/100], Loss: 0.2714, Validation Loss: 0.2596
	--> Epoch [60/100], Loss: 0.2127, Validation Loss: 0.2586
	--> Epoch [61/100], Loss: 0.1564, Validation Loss: 0.2593
	--> Epoch [62/100], Loss: 0.1013, Validation Loss: 0.2568
	--> Epoch [63/100], Loss: 0.0824, Validation Loss: 0.2548
	--> Epoch [64/100], Loss: 0.1561, Validation Loss: 0.2524
	--> Epoch [65/100], Loss: 0.0908, Validation Loss: 0.2504
	--> Epoch [66/100], Loss: 0.2108, Validation Loss: 0.2493
	--> Epoch [67/100], Loss: 0.1827, Validation Loss: 0.2457
	--> Epoch [68/100], Loss: 0.1722, Validation Loss: 0.2447
	--> Epoch [69/100], Loss: 0.0948, Validation Loss: 0.2425
	--> Epoch [70/100], Loss: 0.1974, Validation Loss: 0.2459
	--> Epoch [71/100], Loss: 0.2692, Validation Loss: 0.2446
	--> Epoch [72/100], Loss: 0.1475, Validation Loss: 0.2431
Early stopping
	--> Training for Fold 4 took 0.643092155456543 sec, using 72 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6680, Validation Loss: 0.7074
	--> Epoch [2/100], Loss: 0.6558, Validation Loss: 0.7041
	--> Epoch [3/100], Loss: 0.6688, Validation Loss: 0.7014
	--> Epoch [4/100], Loss: 0.5959, Validation Loss: 0.6943
	--> Epoch [5/100], Loss: 0.6327, Validation Loss: 0.6879
	--> Epoch [6/100], Loss: 0.5567, Validation Loss: 0.6807
	--> Epoch [7/100], Loss: 0.6070, Validation Loss: 0.6758
	--> Epoch [8/100], Loss: 0.5602, Validation Loss: 0.6705
	--> Epoch [9/100], Loss: 0.5114, Validation Loss: 0.6624
	--> Epoch [10/100], Loss: 0.5305, Validation Loss: 0.6562
	--> Epoch [11/100], Loss: 0.4233, Validation Loss: 0.6475
	--> Epoch [12/100], Loss: 0.4584, Validation Loss: 0.6403
	--> Epoch [13/100], Loss: 0.4784, Validation Loss: 0.6342
	--> Epoch [14/100], Loss: 0.4418, Validation Loss: 0.6314
	--> Epoch [15/100], Loss: 0.4480, Validation Loss: 0.6270
	--> Epoch [16/100], Loss: 0.4152, Validation Loss: 0.6222
	--> Epoch [17/100], Loss: 0.4281, Validation Loss: 0.6194
	--> Epoch [18/100], Loss: 0.3463, Validation Loss: 0.6166
	--> Epoch [19/100], Loss: 0.3658, Validation Loss: 0.6139
	--> Epoch [20/100], Loss: 0.2831, Validation Loss: 0.6118
	--> Epoch [21/100], Loss: 0.3169, Validation Loss: 0.6070
	--> Epoch [22/100], Loss: 0.2513, Validation Loss: 0.6038
	--> Epoch [23/100], Loss: 0.2785, Validation Loss: 0.5996
	--> Epoch [24/100], Loss: 0.2073, Validation Loss: 0.5980
	--> Epoch [25/100], Loss: 0.2173, Validation Loss: 0.5958
	--> Epoch [26/100], Loss: 0.2754, Validation Loss: 0.5950
	--> Epoch [27/100], Loss: 0.2317, Validation Loss: 0.5961
	--> Epoch [28/100], Loss: 0.2366, Validation Loss: 0.5971
	--> Epoch [29/100], Loss: 0.2596, Validation Loss: 0.5966
Early stopping
	--> Training for Fold 5 took 0.26748228073120117 sec, using 29 epochs

Median number of epochs used: 66 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/66], Loss: 0.7153
	--> Final training Epoch [2/66], Loss: 0.7139
	--> Final training Epoch [3/66], Loss: 0.6171
	--> Final training Epoch [4/66], Loss: 0.6726
	--> Final training Epoch [5/66], Loss: 0.5674
	--> Final training Epoch [6/66], Loss: 0.5634
	--> Final training Epoch [7/66], Loss: 0.5650
	--> Final training Epoch [8/66], Loss: 0.5219
	--> Final training Epoch [9/66], Loss: 0.4658
	--> Final training Epoch [10/66], Loss: 0.5015
	--> Final training Epoch [11/66], Loss: 0.4821
	--> Final training Epoch [12/66], Loss: 0.4361
	--> Final training Epoch [13/66], Loss: 0.4396
	--> Final training Epoch [14/66], Loss: 0.3468
	--> Final training Epoch [15/66], Loss: 0.3687
	--> Final training Epoch [16/66], Loss: 0.4301
	--> Final training Epoch [17/66], Loss: 0.4216
	--> Final training Epoch [18/66], Loss: 0.3786
	--> Final training Epoch [19/66], Loss: 0.3773
	--> Final training Epoch [20/66], Loss: 0.3105
	--> Final training Epoch [21/66], Loss: 0.3460
	--> Final training Epoch [22/66], Loss: 0.3504
	--> Final training Epoch [23/66], Loss: 0.3226
	--> Final training Epoch [24/66], Loss: 0.3338
	--> Final training Epoch [25/66], Loss: 0.2948
	--> Final training Epoch [26/66], Loss: 0.3594
	--> Final training Epoch [27/66], Loss: 0.3128
	--> Final training Epoch [28/66], Loss: 0.3157
	--> Final training Epoch [29/66], Loss: 0.3172
	--> Final training Epoch [30/66], Loss: 0.2826
	--> Final training Epoch [31/66], Loss: 0.2858
	--> Final training Epoch [32/66], Loss: 0.2868
	--> Final training Epoch [33/66], Loss: 0.2466
	--> Final training Epoch [34/66], Loss: 0.2719
	--> Final training Epoch [35/66], Loss: 0.2886
	--> Final training Epoch [36/66], Loss: 0.2440
	--> Final training Epoch [37/66], Loss: 0.2771
	--> Final training Epoch [38/66], Loss: 0.3019
	--> Final training Epoch [39/66], Loss: 0.2633
	--> Final training Epoch [40/66], Loss: 0.2195
	--> Final training Epoch [41/66], Loss: 0.2086
	--> Final training Epoch [42/66], Loss: 0.1937
	--> Final training Epoch [43/66], Loss: 0.2380
	--> Final training Epoch [44/66], Loss: 0.2816
	--> Final training Epoch [45/66], Loss: 0.2361
	--> Final training Epoch [46/66], Loss: 0.2339
	--> Final training Epoch [47/66], Loss: 0.2701
	--> Final training Epoch [48/66], Loss: 0.2256
	--> Final training Epoch [49/66], Loss: 0.2047
	--> Final training Epoch [50/66], Loss: 0.2416
	--> Final training Epoch [51/66], Loss: 0.2191
	--> Final training Epoch [52/66], Loss: 0.2265
	--> Final training Epoch [53/66], Loss: 0.1514
	--> Final training Epoch [54/66], Loss: 0.1891
	--> Final training Epoch [55/66], Loss: 0.2138
	--> Final training Epoch [56/66], Loss: 0.1565
	--> Final training Epoch [57/66], Loss: 0.2275
	--> Final training Epoch [58/66], Loss: 0.1712
	--> Final training Epoch [59/66], Loss: 0.1949
	--> Final training Epoch [60/66], Loss: 0.2419
	--> Final training Epoch [61/66], Loss: 0.1675
	--> Final training Epoch [62/66], Loss: 0.2110
	--> Final training Epoch [63/66], Loss: 0.1521
	--> Final training Epoch [64/66], Loss: 0.1550
	--> Final training Epoch [65/66], Loss: 0.1407
	--> Final training Epoch [66/66], Loss: 0.2193

Final training took 0.5358626842498779 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.9666
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8807, Validation Loss: 0.3835,  Current Best Accuracy: 0.8807,  Current Best Validation Loss: 0.3835

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7233, Validation Loss: 0.7045
	--> Epoch [2/100], Loss: 0.6768, Validation Loss: 0.6721
	--> Epoch [3/100], Loss: 0.6814, Validation Loss: 0.6435
	--> Epoch [4/100], Loss: 0.5717, Validation Loss: 0.6227
	--> Epoch [5/100], Loss: 0.5685, Validation Loss: 0.6017
	--> Epoch [6/100], Loss: 0.5549, Validation Loss: 0.5860
	--> Epoch [7/100], Loss: 0.5571, Validation Loss: 0.5625
	--> Epoch [8/100], Loss: 0.4438, Validation Loss: 0.5452
	--> Epoch [9/100], Loss: 0.4932, Validation Loss: 0.5292
	--> Epoch [10/100], Loss: 0.4465, Validation Loss: 0.5137
	--> Epoch [11/100], Loss: 0.4261, Validation Loss: 0.4971
	--> Epoch [12/100], Loss: 0.4362, Validation Loss: 0.4856
	--> Epoch [13/100], Loss: 0.4276, Validation Loss: 0.4715
	--> Epoch [14/100], Loss: 0.3249, Validation Loss: 0.4627
	--> Epoch [15/100], Loss: 0.3761, Validation Loss: 0.4523
	--> Epoch [16/100], Loss: 0.3369, Validation Loss: 0.4436
	--> Epoch [17/100], Loss: 0.4262, Validation Loss: 0.4357
	--> Epoch [18/100], Loss: 0.3323, Validation Loss: 0.4239
	--> Epoch [19/100], Loss: 0.4415, Validation Loss: 0.4166
	--> Epoch [20/100], Loss: 0.3332, Validation Loss: 0.4085
	--> Epoch [21/100], Loss: 0.2455, Validation Loss: 0.4020
	--> Epoch [22/100], Loss: 0.2775, Validation Loss: 0.3934
	--> Epoch [23/100], Loss: 0.3446, Validation Loss: 0.3839
	--> Epoch [24/100], Loss: 0.2335, Validation Loss: 0.3784
	--> Epoch [25/100], Loss: 0.2828, Validation Loss: 0.3698
	--> Epoch [26/100], Loss: 0.2880, Validation Loss: 0.3635
	--> Epoch [27/100], Loss: 0.3673, Validation Loss: 0.3598
	--> Epoch [28/100], Loss: 0.1798, Validation Loss: 0.3529
	--> Epoch [29/100], Loss: 0.3111, Validation Loss: 0.3474
	--> Epoch [30/100], Loss: 0.1998, Validation Loss: 0.3414
	--> Epoch [31/100], Loss: 0.3061, Validation Loss: 0.3371
	--> Epoch [32/100], Loss: 0.2806, Validation Loss: 0.3302
	--> Epoch [33/100], Loss: 0.2882, Validation Loss: 0.3274
	--> Epoch [34/100], Loss: 0.2532, Validation Loss: 0.3232
	--> Epoch [35/100], Loss: 0.2715, Validation Loss: 0.3191
	--> Epoch [36/100], Loss: 0.2390, Validation Loss: 0.3168
	--> Epoch [37/100], Loss: 0.1951, Validation Loss: 0.3110
	--> Epoch [38/100], Loss: 0.2427, Validation Loss: 0.3072
	--> Epoch [39/100], Loss: 0.1623, Validation Loss: 0.3038
	--> Epoch [40/100], Loss: 0.1141, Validation Loss: 0.2998
	--> Epoch [41/100], Loss: 0.1645, Validation Loss: 0.2989
	--> Epoch [42/100], Loss: 0.2272, Validation Loss: 0.2967
	--> Epoch [43/100], Loss: 0.1190, Validation Loss: 0.2957
	--> Epoch [44/100], Loss: 0.2394, Validation Loss: 0.2923
	--> Epoch [45/100], Loss: 0.2402, Validation Loss: 0.2868
	--> Epoch [46/100], Loss: 0.2211, Validation Loss: 0.2848
	--> Epoch [47/100], Loss: 0.1544, Validation Loss: 0.2827
	--> Epoch [48/100], Loss: 0.1665, Validation Loss: 0.2817
	--> Epoch [49/100], Loss: 0.0833, Validation Loss: 0.2804
	--> Epoch [50/100], Loss: 0.1025, Validation Loss: 0.2768
	--> Epoch [51/100], Loss: 0.0939, Validation Loss: 0.2745
	--> Epoch [52/100], Loss: 0.2668, Validation Loss: 0.2742
	--> Epoch [53/100], Loss: 0.2124, Validation Loss: 0.2759
	--> Epoch [54/100], Loss: 0.0890, Validation Loss: 0.2754
	--> Epoch [55/100], Loss: 0.1056, Validation Loss: 0.2743
Early stopping
	--> Training for Fold 1 took 0.43592190742492676 sec, using 55 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6151, Validation Loss: 0.6915
	--> Epoch [2/100], Loss: 0.5035, Validation Loss: 0.6571
	--> Epoch [3/100], Loss: 0.4872, Validation Loss: 0.6289
	--> Epoch [4/100], Loss: 0.4086, Validation Loss: 0.6046
	--> Epoch [5/100], Loss: 0.4284, Validation Loss: 0.5885
	--> Epoch [6/100], Loss: 0.4258, Validation Loss: 0.5645
	--> Epoch [7/100], Loss: 0.3957, Validation Loss: 0.5375
	--> Epoch [8/100], Loss: 0.3620, Validation Loss: 0.5216
	--> Epoch [9/100], Loss: 0.3554, Validation Loss: 0.5061
	--> Epoch [10/100], Loss: 0.4261, Validation Loss: 0.4924
	--> Epoch [11/100], Loss: 0.3383, Validation Loss: 0.4737
	--> Epoch [12/100], Loss: 0.3141, Validation Loss: 0.4640
	--> Epoch [13/100], Loss: 0.2916, Validation Loss: 0.4522
	--> Epoch [14/100], Loss: 0.2917, Validation Loss: 0.4406
	--> Epoch [15/100], Loss: 0.2852, Validation Loss: 0.4288
	--> Epoch [16/100], Loss: 0.2145, Validation Loss: 0.4169
	--> Epoch [17/100], Loss: 0.3403, Validation Loss: 0.4071
	--> Epoch [18/100], Loss: 0.1943, Validation Loss: 0.4034
	--> Epoch [19/100], Loss: 0.1814, Validation Loss: 0.3948
	--> Epoch [20/100], Loss: 0.2608, Validation Loss: 0.3892
	--> Epoch [21/100], Loss: 0.2707, Validation Loss: 0.3793
	--> Epoch [22/100], Loss: 0.2608, Validation Loss: 0.3740
	--> Epoch [23/100], Loss: 0.1945, Validation Loss: 0.3672
	--> Epoch [24/100], Loss: 0.1695, Validation Loss: 0.3577
	--> Epoch [25/100], Loss: 0.1271, Validation Loss: 0.3532
	--> Epoch [26/100], Loss: 0.1546, Validation Loss: 0.3489
	--> Epoch [27/100], Loss: 0.2139, Validation Loss: 0.3416
	--> Epoch [28/100], Loss: 0.2148, Validation Loss: 0.3396
	--> Epoch [29/100], Loss: 0.1407, Validation Loss: 0.3366
	--> Epoch [30/100], Loss: 0.1978, Validation Loss: 0.3335
	--> Epoch [31/100], Loss: 0.1662, Validation Loss: 0.3314
	--> Epoch [32/100], Loss: 0.1093, Validation Loss: 0.3274
	--> Epoch [33/100], Loss: 0.1896, Validation Loss: 0.3249
	--> Epoch [34/100], Loss: 0.1085, Validation Loss: 0.3197
	--> Epoch [35/100], Loss: 0.1267, Validation Loss: 0.3172
	--> Epoch [36/100], Loss: 0.1845, Validation Loss: 0.3124
	--> Epoch [37/100], Loss: 0.1807, Validation Loss: 0.3090
	--> Epoch [38/100], Loss: 0.2612, Validation Loss: 0.3042
	--> Epoch [39/100], Loss: 0.2273, Validation Loss: 0.2986
	--> Epoch [40/100], Loss: 0.0991, Validation Loss: 0.2984
	--> Epoch [41/100], Loss: 0.1105, Validation Loss: 0.2970
	--> Epoch [42/100], Loss: 0.1850, Validation Loss: 0.2989
	--> Epoch [43/100], Loss: 0.1633, Validation Loss: 0.2968
	--> Epoch [44/100], Loss: 0.1043, Validation Loss: 0.2961
	--> Epoch [45/100], Loss: 0.0875, Validation Loss: 0.2945
	--> Epoch [46/100], Loss: 0.1551, Validation Loss: 0.2932
	--> Epoch [47/100], Loss: 0.2585, Validation Loss: 0.2928
	--> Epoch [48/100], Loss: 0.1211, Validation Loss: 0.2923
	--> Epoch [49/100], Loss: 0.1821, Validation Loss: 0.2834
	--> Epoch [50/100], Loss: 0.2128, Validation Loss: 0.2796
	--> Epoch [51/100], Loss: 0.1290, Validation Loss: 0.2791
	--> Epoch [52/100], Loss: 0.1171, Validation Loss: 0.2797
	--> Epoch [53/100], Loss: 0.1971, Validation Loss: 0.2771
	--> Epoch [54/100], Loss: 0.0690, Validation Loss: 0.2757
	--> Epoch [55/100], Loss: 0.1668, Validation Loss: 0.2752
	--> Epoch [56/100], Loss: 0.2584, Validation Loss: 0.2740
	--> Epoch [57/100], Loss: 0.0740, Validation Loss: 0.2742
	--> Epoch [58/100], Loss: 0.2122, Validation Loss: 0.2725
	--> Epoch [59/100], Loss: 0.0574, Validation Loss: 0.2730
	--> Epoch [60/100], Loss: 0.1778, Validation Loss: 0.2695
	--> Epoch [61/100], Loss: 0.1309, Validation Loss: 0.2711
	--> Epoch [62/100], Loss: 0.1383, Validation Loss: 0.2682
	--> Epoch [63/100], Loss: 0.0606, Validation Loss: 0.2650
	--> Epoch [64/100], Loss: 0.0826, Validation Loss: 0.2643
	--> Epoch [65/100], Loss: 0.0739, Validation Loss: 0.2640
	--> Epoch [66/100], Loss: 0.2573, Validation Loss: 0.2613
	--> Epoch [67/100], Loss: 0.0787, Validation Loss: 0.2587
	--> Epoch [68/100], Loss: 0.1093, Validation Loss: 0.2595
	--> Epoch [69/100], Loss: 0.1645, Validation Loss: 0.2580
	--> Epoch [70/100], Loss: 0.1111, Validation Loss: 0.2590
	--> Epoch [71/100], Loss: 0.0573, Validation Loss: 0.2592
	--> Epoch [72/100], Loss: 0.1131, Validation Loss: 0.2604
Early stopping
	--> Training for Fold 2 took 0.5840113162994385 sec, using 72 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 1.0016, Validation Loss: 0.6386
	--> Epoch [2/100], Loss: 0.8559, Validation Loss: 0.6264
	--> Epoch [3/100], Loss: 0.9143, Validation Loss: 0.6152
	--> Epoch [4/100], Loss: 0.6176, Validation Loss: 0.6015
	--> Epoch [5/100], Loss: 0.8179, Validation Loss: 0.5904
	--> Epoch [6/100], Loss: 0.6358, Validation Loss: 0.5802
	--> Epoch [7/100], Loss: 0.6038, Validation Loss: 0.5730
	--> Epoch [8/100], Loss: 0.5791, Validation Loss: 0.5652
	--> Epoch [9/100], Loss: 0.5823, Validation Loss: 0.5557
	--> Epoch [10/100], Loss: 0.4643, Validation Loss: 0.5429
	--> Epoch [11/100], Loss: 0.5709, Validation Loss: 0.5363
	--> Epoch [12/100], Loss: 0.3990, Validation Loss: 0.5277
	--> Epoch [13/100], Loss: 0.3907, Validation Loss: 0.5185
	--> Epoch [14/100], Loss: 0.5183, Validation Loss: 0.5089
	--> Epoch [15/100], Loss: 0.6149, Validation Loss: 0.5016
	--> Epoch [16/100], Loss: 0.4378, Validation Loss: 0.4968
	--> Epoch [17/100], Loss: 0.3774, Validation Loss: 0.4932
	--> Epoch [18/100], Loss: 0.3754, Validation Loss: 0.4876
	--> Epoch [19/100], Loss: 0.3304, Validation Loss: 0.4828
	--> Epoch [20/100], Loss: 0.5776, Validation Loss: 0.4748
	--> Epoch [21/100], Loss: 0.3835, Validation Loss: 0.4719
	--> Epoch [22/100], Loss: 0.1968, Validation Loss: 0.4670
	--> Epoch [23/100], Loss: 0.5000, Validation Loss: 0.4631
	--> Epoch [24/100], Loss: 0.5373, Validation Loss: 0.4569
	--> Epoch [25/100], Loss: 0.3400, Validation Loss: 0.4542
	--> Epoch [26/100], Loss: 0.3530, Validation Loss: 0.4501
	--> Epoch [27/100], Loss: 0.5197, Validation Loss: 0.4458
	--> Epoch [28/100], Loss: 0.1556, Validation Loss: 0.4405
	--> Epoch [29/100], Loss: 0.1902, Validation Loss: 0.4400
	--> Epoch [30/100], Loss: 0.4539, Validation Loss: 0.4332
	--> Epoch [31/100], Loss: 0.3647, Validation Loss: 0.4292
	--> Epoch [32/100], Loss: 0.2782, Validation Loss: 0.4258
	--> Epoch [33/100], Loss: 0.4026, Validation Loss: 0.4219
	--> Epoch [34/100], Loss: 0.1749, Validation Loss: 0.4190
	--> Epoch [35/100], Loss: 0.3027, Validation Loss: 0.4160
	--> Epoch [36/100], Loss: 0.0767, Validation Loss: 0.4144
	--> Epoch [37/100], Loss: 0.2506, Validation Loss: 0.4112
	--> Epoch [38/100], Loss: 0.1875, Validation Loss: 0.4107
	--> Epoch [39/100], Loss: 0.1409, Validation Loss: 0.4080
	--> Epoch [40/100], Loss: 0.1547, Validation Loss: 0.4065
	--> Epoch [41/100], Loss: 0.3208, Validation Loss: 0.4052
	--> Epoch [42/100], Loss: 0.1595, Validation Loss: 0.4043
	--> Epoch [43/100], Loss: 0.1332, Validation Loss: 0.4027
	--> Epoch [44/100], Loss: 0.1432, Validation Loss: 0.4008
	--> Epoch [45/100], Loss: 0.2182, Validation Loss: 0.3991
	--> Epoch [46/100], Loss: 0.1773, Validation Loss: 0.3961
	--> Epoch [47/100], Loss: 0.1543, Validation Loss: 0.3955
	--> Epoch [48/100], Loss: 0.2966, Validation Loss: 0.3941
	--> Epoch [49/100], Loss: 0.1372, Validation Loss: 0.3933
	--> Epoch [50/100], Loss: 0.2148, Validation Loss: 0.3907
	--> Epoch [51/100], Loss: 0.1866, Validation Loss: 0.3891
	--> Epoch [52/100], Loss: 0.1514, Validation Loss: 0.3880
	--> Epoch [53/100], Loss: 0.1180, Validation Loss: 0.3852
	--> Epoch [54/100], Loss: 0.1150, Validation Loss: 0.3845
	--> Epoch [55/100], Loss: 0.1133, Validation Loss: 0.3858
	--> Epoch [56/100], Loss: 0.1236, Validation Loss: 0.3868
	--> Epoch [57/100], Loss: 0.1447, Validation Loss: 0.3858
Early stopping
	--> Training for Fold 3 took 0.4745948314666748 sec, using 57 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7469, Validation Loss: 0.5812
	--> Epoch [2/100], Loss: 0.7624, Validation Loss: 0.5689
	--> Epoch [3/100], Loss: 0.7075, Validation Loss: 0.5580
	--> Epoch [4/100], Loss: 0.6744, Validation Loss: 0.5445
	--> Epoch [5/100], Loss: 0.6526, Validation Loss: 0.5364
	--> Epoch [6/100], Loss: 0.6203, Validation Loss: 0.5286
	--> Epoch [7/100], Loss: 0.6389, Validation Loss: 0.5224
	--> Epoch [8/100], Loss: 0.5734, Validation Loss: 0.5154
	--> Epoch [9/100], Loss: 0.6332, Validation Loss: 0.5106
	--> Epoch [10/100], Loss: 0.5440, Validation Loss: 0.5064
	--> Epoch [11/100], Loss: 0.4443, Validation Loss: 0.5018
	--> Epoch [12/100], Loss: 0.5304, Validation Loss: 0.4917
	--> Epoch [13/100], Loss: 0.3818, Validation Loss: 0.4862
	--> Epoch [14/100], Loss: 0.4601, Validation Loss: 0.4794
	--> Epoch [15/100], Loss: 0.4193, Validation Loss: 0.4739
	--> Epoch [16/100], Loss: 0.3949, Validation Loss: 0.4712
	--> Epoch [17/100], Loss: 0.3085, Validation Loss: 0.4644
	--> Epoch [18/100], Loss: 0.3420, Validation Loss: 0.4573
	--> Epoch [19/100], Loss: 0.3959, Validation Loss: 0.4537
	--> Epoch [20/100], Loss: 0.3517, Validation Loss: 0.4508
	--> Epoch [21/100], Loss: 0.2893, Validation Loss: 0.4435
	--> Epoch [22/100], Loss: 0.4055, Validation Loss: 0.4393
	--> Epoch [23/100], Loss: 0.2579, Validation Loss: 0.4346
	--> Epoch [24/100], Loss: 0.3131, Validation Loss: 0.4318
	--> Epoch [25/100], Loss: 0.2078, Validation Loss: 0.4290
	--> Epoch [26/100], Loss: 0.3090, Validation Loss: 0.4248
	--> Epoch [27/100], Loss: 0.2249, Validation Loss: 0.4198
	--> Epoch [28/100], Loss: 0.1837, Validation Loss: 0.4136
	--> Epoch [29/100], Loss: 0.1933, Validation Loss: 0.4102
	--> Epoch [30/100], Loss: 0.1576, Validation Loss: 0.4061
	--> Epoch [31/100], Loss: 0.0988, Validation Loss: 0.4028
	--> Epoch [32/100], Loss: 0.1781, Validation Loss: 0.4022
	--> Epoch [33/100], Loss: 0.0684, Validation Loss: 0.3977
	--> Epoch [34/100], Loss: 0.3260, Validation Loss: 0.3928
	--> Epoch [35/100], Loss: 0.2705, Validation Loss: 0.3911
	--> Epoch [36/100], Loss: 0.1476, Validation Loss: 0.3923
	--> Epoch [37/100], Loss: 0.1733, Validation Loss: 0.3878
	--> Epoch [38/100], Loss: 0.0889, Validation Loss: 0.3857
	--> Epoch [39/100], Loss: 0.0770, Validation Loss: 0.3818
	--> Epoch [40/100], Loss: 0.2400, Validation Loss: 0.3793
	--> Epoch [41/100], Loss: 0.0835, Validation Loss: 0.3811
	--> Epoch [42/100], Loss: 0.1743, Validation Loss: 0.3784
	--> Epoch [43/100], Loss: 0.1278, Validation Loss: 0.3775
	--> Epoch [44/100], Loss: 0.2337, Validation Loss: 0.3766
	--> Epoch [45/100], Loss: 0.2093, Validation Loss: 0.3755
	--> Epoch [46/100], Loss: 0.1975, Validation Loss: 0.3745
	--> Epoch [47/100], Loss: 0.1496, Validation Loss: 0.3706
	--> Epoch [48/100], Loss: 0.1281, Validation Loss: 0.3678
	--> Epoch [49/100], Loss: 0.1049, Validation Loss: 0.3656
	--> Epoch [50/100], Loss: 0.1721, Validation Loss: 0.3641
	--> Epoch [51/100], Loss: 0.1480, Validation Loss: 0.3615
	--> Epoch [52/100], Loss: 0.1567, Validation Loss: 0.3588
	--> Epoch [53/100], Loss: 0.2937, Validation Loss: 0.3583
	--> Epoch [54/100], Loss: 0.1877, Validation Loss: 0.3573
	--> Epoch [55/100], Loss: 0.0292, Validation Loss: 0.3572
	--> Epoch [56/100], Loss: 0.1798, Validation Loss: 0.3597
	--> Epoch [57/100], Loss: 0.0567, Validation Loss: 0.3587
	--> Epoch [58/100], Loss: 0.0546, Validation Loss: 0.3561
	--> Epoch [59/100], Loss: 0.1857, Validation Loss: 0.3531
	--> Epoch [60/100], Loss: 0.0526, Validation Loss: 0.3510
	--> Epoch [61/100], Loss: 0.1055, Validation Loss: 0.3513
	--> Epoch [62/100], Loss: 0.0352, Validation Loss: 0.3481
	--> Epoch [63/100], Loss: 0.1769, Validation Loss: 0.3467
	--> Epoch [64/100], Loss: 0.1050, Validation Loss: 0.3466
	--> Epoch [65/100], Loss: 0.0982, Validation Loss: 0.3439
	--> Epoch [66/100], Loss: 0.1048, Validation Loss: 0.3436
	--> Epoch [67/100], Loss: 0.0240, Validation Loss: 0.3449
	--> Epoch [68/100], Loss: 0.1099, Validation Loss: 0.3511
	--> Epoch [69/100], Loss: 0.1847, Validation Loss: 0.3538
Early stopping
	--> Training for Fold 4 took 0.5819027423858643 sec, using 69 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7558, Validation Loss: 0.6704
	--> Epoch [2/100], Loss: 0.6830, Validation Loss: 0.6600
	--> Epoch [3/100], Loss: 0.5700, Validation Loss: 0.6509
	--> Epoch [4/100], Loss: 0.6191, Validation Loss: 0.6437
	--> Epoch [5/100], Loss: 0.6004, Validation Loss: 0.6348
	--> Epoch [6/100], Loss: 0.4270, Validation Loss: 0.6321
	--> Epoch [7/100], Loss: 0.4190, Validation Loss: 0.6298
	--> Epoch [8/100], Loss: 0.4837, Validation Loss: 0.6270
	--> Epoch [9/100], Loss: 0.4258, Validation Loss: 0.6240
	--> Epoch [10/100], Loss: 0.3493, Validation Loss: 0.6232
	--> Epoch [11/100], Loss: 0.3190, Validation Loss: 0.6214
	--> Epoch [12/100], Loss: 0.4085, Validation Loss: 0.6206
	--> Epoch [13/100], Loss: 0.2899, Validation Loss: 0.6205
	--> Epoch [14/100], Loss: 0.3864, Validation Loss: 0.6215
	--> Epoch [15/100], Loss: 0.2635, Validation Loss: 0.6189
	--> Epoch [16/100], Loss: 0.1837, Validation Loss: 0.6190
	--> Epoch [17/100], Loss: 0.2757, Validation Loss: 0.6172
	--> Epoch [18/100], Loss: 0.2297, Validation Loss: 0.6135
	--> Epoch [19/100], Loss: 0.2244, Validation Loss: 0.6123
	--> Epoch [20/100], Loss: 0.2157, Validation Loss: 0.6153
	--> Epoch [21/100], Loss: 0.2283, Validation Loss: 0.6167
	--> Epoch [22/100], Loss: 0.1935, Validation Loss: 0.6165
Early stopping
	--> Training for Fold 5 took 0.18862438201904297 sec, using 22 epochs

Median number of epochs used: 57 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/57], Loss: 0.6627
	--> Final training Epoch [2/57], Loss: 0.6915
	--> Final training Epoch [3/57], Loss: 0.6368
	--> Final training Epoch [4/57], Loss: 0.6177
	--> Final training Epoch [5/57], Loss: 0.6048
	--> Final training Epoch [6/57], Loss: 0.5817
	--> Final training Epoch [7/57], Loss: 0.5395
	--> Final training Epoch [8/57], Loss: 0.5323
	--> Final training Epoch [9/57], Loss: 0.5485
	--> Final training Epoch [10/57], Loss: 0.4918
	--> Final training Epoch [11/57], Loss: 0.4816
	--> Final training Epoch [12/57], Loss: 0.5289
	--> Final training Epoch [13/57], Loss: 0.4402
	--> Final training Epoch [14/57], Loss: 0.5105
	--> Final training Epoch [15/57], Loss: 0.4835
	--> Final training Epoch [16/57], Loss: 0.4501
	--> Final training Epoch [17/57], Loss: 0.4299
	--> Final training Epoch [18/57], Loss: 0.4326
	--> Final training Epoch [19/57], Loss: 0.3916
	--> Final training Epoch [20/57], Loss: 0.3536
	--> Final training Epoch [21/57], Loss: 0.3699
	--> Final training Epoch [22/57], Loss: 0.3483
	--> Final training Epoch [23/57], Loss: 0.3152
	--> Final training Epoch [24/57], Loss: 0.3477
	--> Final training Epoch [25/57], Loss: 0.3253
	--> Final training Epoch [26/57], Loss: 0.3412
	--> Final training Epoch [27/57], Loss: 0.3294
	--> Final training Epoch [28/57], Loss: 0.2950
	--> Final training Epoch [29/57], Loss: 0.2425
	--> Final training Epoch [30/57], Loss: 0.2586
	--> Final training Epoch [31/57], Loss: 0.2985
	--> Final training Epoch [32/57], Loss: 0.3595
	--> Final training Epoch [33/57], Loss: 0.2681
	--> Final training Epoch [34/57], Loss: 0.2124
	--> Final training Epoch [35/57], Loss: 0.2822
	--> Final training Epoch [36/57], Loss: 0.2815
	--> Final training Epoch [37/57], Loss: 0.2967
	--> Final training Epoch [38/57], Loss: 0.1932
	--> Final training Epoch [39/57], Loss: 0.2419
	--> Final training Epoch [40/57], Loss: 0.2331
	--> Final training Epoch [41/57], Loss: 0.1832
	--> Final training Epoch [42/57], Loss: 0.2734
	--> Final training Epoch [43/57], Loss: 0.1737
	--> Final training Epoch [44/57], Loss: 0.1696
	--> Final training Epoch [45/57], Loss: 0.2234
	--> Final training Epoch [46/57], Loss: 0.1737
	--> Final training Epoch [47/57], Loss: 0.2228
	--> Final training Epoch [48/57], Loss: 0.1550
	--> Final training Epoch [49/57], Loss: 0.2101
	--> Final training Epoch [50/57], Loss: 0.2280
	--> Final training Epoch [51/57], Loss: 0.2371
	--> Final training Epoch [52/57], Loss: 0.1916
	--> Final training Epoch [53/57], Loss: 0.1830
	--> Final training Epoch [54/57], Loss: 0.1654
	--> Final training Epoch [55/57], Loss: 0.1452
	--> Final training Epoch [56/57], Loss: 0.1726
	--> Final training Epoch [57/57], Loss: 0.1592

Final training took 0.47095346450805664 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.7724
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.3829,  Current Best Accuracy: 0.8164,  Current Best Validation Loss: 0.3829

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5783, Validation Loss: 0.6693
	--> Epoch [2/100], Loss: 0.5100, Validation Loss: 0.6487
	--> Epoch [3/100], Loss: 0.5056, Validation Loss: 0.6272
	--> Epoch [4/100], Loss: 0.4460, Validation Loss: 0.6074
	--> Epoch [5/100], Loss: 0.4751, Validation Loss: 0.5929
	--> Epoch [6/100], Loss: 0.3897, Validation Loss: 0.5745
	--> Epoch [7/100], Loss: 0.3923, Validation Loss: 0.5562
	--> Epoch [8/100], Loss: 0.3909, Validation Loss: 0.5418
	--> Epoch [9/100], Loss: 0.4194, Validation Loss: 0.5305
	--> Epoch [10/100], Loss: 0.3385, Validation Loss: 0.5201
	--> Epoch [11/100], Loss: 0.3465, Validation Loss: 0.5105
	--> Epoch [12/100], Loss: 0.3538, Validation Loss: 0.4968
	--> Epoch [13/100], Loss: 0.4213, Validation Loss: 0.4865
	--> Epoch [14/100], Loss: 0.3304, Validation Loss: 0.4743
	--> Epoch [15/100], Loss: 0.4093, Validation Loss: 0.4702
	--> Epoch [16/100], Loss: 0.4080, Validation Loss: 0.4667
	--> Epoch [17/100], Loss: 0.4178, Validation Loss: 0.4589
	--> Epoch [18/100], Loss: 0.3988, Validation Loss: 0.4514
	--> Epoch [19/100], Loss: 0.2746, Validation Loss: 0.4462
	--> Epoch [20/100], Loss: 0.2807, Validation Loss: 0.4388
	--> Epoch [21/100], Loss: 0.2874, Validation Loss: 0.4319
	--> Epoch [22/100], Loss: 0.2486, Validation Loss: 0.4265
	--> Epoch [23/100], Loss: 0.2645, Validation Loss: 0.4149
	--> Epoch [24/100], Loss: 0.3369, Validation Loss: 0.4087
	--> Epoch [25/100], Loss: 0.2756, Validation Loss: 0.4025
	--> Epoch [26/100], Loss: 0.3243, Validation Loss: 0.3981
	--> Epoch [27/100], Loss: 0.2697, Validation Loss: 0.3917
	--> Epoch [28/100], Loss: 0.2729, Validation Loss: 0.3882
	--> Epoch [29/100], Loss: 0.2326, Validation Loss: 0.3819
	--> Epoch [30/100], Loss: 0.2048, Validation Loss: 0.3792
	--> Epoch [31/100], Loss: 0.2309, Validation Loss: 0.3743
	--> Epoch [32/100], Loss: 0.3190, Validation Loss: 0.3705
	--> Epoch [33/100], Loss: 0.3386, Validation Loss: 0.3674
	--> Epoch [34/100], Loss: 0.2278, Validation Loss: 0.3643
	--> Epoch [35/100], Loss: 0.2160, Validation Loss: 0.3603
	--> Epoch [36/100], Loss: 0.1918, Validation Loss: 0.3539
	--> Epoch [37/100], Loss: 0.1674, Validation Loss: 0.3479
	--> Epoch [38/100], Loss: 0.1900, Validation Loss: 0.3436
	--> Epoch [39/100], Loss: 0.2557, Validation Loss: 0.3422
	--> Epoch [40/100], Loss: 0.2716, Validation Loss: 0.3406
	--> Epoch [41/100], Loss: 0.1482, Validation Loss: 0.3352
	--> Epoch [42/100], Loss: 0.2192, Validation Loss: 0.3344
	--> Epoch [43/100], Loss: 0.2270, Validation Loss: 0.3303
	--> Epoch [44/100], Loss: 0.1786, Validation Loss: 0.3269
	--> Epoch [45/100], Loss: 0.2041, Validation Loss: 0.3226
	--> Epoch [46/100], Loss: 0.2789, Validation Loss: 0.3194
	--> Epoch [47/100], Loss: 0.2031, Validation Loss: 0.3154
	--> Epoch [48/100], Loss: 0.1661, Validation Loss: 0.3138
	--> Epoch [49/100], Loss: 0.2159, Validation Loss: 0.3086
	--> Epoch [50/100], Loss: 0.1702, Validation Loss: 0.3080
	--> Epoch [51/100], Loss: 0.2044, Validation Loss: 0.3039
	--> Epoch [52/100], Loss: 0.1056, Validation Loss: 0.3000
	--> Epoch [53/100], Loss: 0.2448, Validation Loss: 0.2964
	--> Epoch [54/100], Loss: 0.2124, Validation Loss: 0.2972
	--> Epoch [55/100], Loss: 0.2256, Validation Loss: 0.2960
	--> Epoch [56/100], Loss: 0.2608, Validation Loss: 0.2932
	--> Epoch [57/100], Loss: 0.1987, Validation Loss: 0.2924
	--> Epoch [58/100], Loss: 0.1262, Validation Loss: 0.2895
	--> Epoch [59/100], Loss: 0.1464, Validation Loss: 0.2890
	--> Epoch [60/100], Loss: 0.2299, Validation Loss: 0.2866
	--> Epoch [61/100], Loss: 0.1885, Validation Loss: 0.2866
	--> Epoch [62/100], Loss: 0.0668, Validation Loss: 0.2863
	--> Epoch [63/100], Loss: 0.1039, Validation Loss: 0.2865
	--> Epoch [64/100], Loss: 0.1000, Validation Loss: 0.2856
	--> Epoch [65/100], Loss: 0.1835, Validation Loss: 0.2839
	--> Epoch [66/100], Loss: 0.1795, Validation Loss: 0.2827
	--> Epoch [67/100], Loss: 0.0695, Validation Loss: 0.2800
	--> Epoch [68/100], Loss: 0.1757, Validation Loss: 0.2779
	--> Epoch [69/100], Loss: 0.2240, Validation Loss: 0.2824
	--> Epoch [70/100], Loss: 0.3178, Validation Loss: 0.2809
	--> Epoch [71/100], Loss: 0.1869, Validation Loss: 0.2813
Early stopping
	--> Training for Fold 1 took 0.5948870182037354 sec, using 71 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7403, Validation Loss: 0.6800
	--> Epoch [2/100], Loss: 0.6976, Validation Loss: 0.6446
	--> Epoch [3/100], Loss: 0.7006, Validation Loss: 0.6215
	--> Epoch [4/100], Loss: 0.6902, Validation Loss: 0.5952
	--> Epoch [5/100], Loss: 0.6297, Validation Loss: 0.5767
	--> Epoch [6/100], Loss: 0.6777, Validation Loss: 0.5572
	--> Epoch [7/100], Loss: 0.5416, Validation Loss: 0.5424
	--> Epoch [8/100], Loss: 0.5055, Validation Loss: 0.5209
	--> Epoch [9/100], Loss: 0.5942, Validation Loss: 0.5057
	--> Epoch [10/100], Loss: 0.5616, Validation Loss: 0.4891
	--> Epoch [11/100], Loss: 0.5828, Validation Loss: 0.4763
	--> Epoch [12/100], Loss: 0.4847, Validation Loss: 0.4658
	--> Epoch [13/100], Loss: 0.4937, Validation Loss: 0.4540
	--> Epoch [14/100], Loss: 0.4342, Validation Loss: 0.4388
	--> Epoch [15/100], Loss: 0.4055, Validation Loss: 0.4279
	--> Epoch [16/100], Loss: 0.2809, Validation Loss: 0.4152
	--> Epoch [17/100], Loss: 0.3856, Validation Loss: 0.4049
	--> Epoch [18/100], Loss: 0.3349, Validation Loss: 0.3957
	--> Epoch [19/100], Loss: 0.3560, Validation Loss: 0.3855
	--> Epoch [20/100], Loss: 0.4050, Validation Loss: 0.3758
	--> Epoch [21/100], Loss: 0.3569, Validation Loss: 0.3655
	--> Epoch [22/100], Loss: 0.2744, Validation Loss: 0.3599
	--> Epoch [23/100], Loss: 0.3502, Validation Loss: 0.3546
	--> Epoch [24/100], Loss: 0.2654, Validation Loss: 0.3462
	--> Epoch [25/100], Loss: 0.3469, Validation Loss: 0.3411
	--> Epoch [26/100], Loss: 0.3806, Validation Loss: 0.3331
	--> Epoch [27/100], Loss: 0.2952, Validation Loss: 0.3264
	--> Epoch [28/100], Loss: 0.3103, Validation Loss: 0.3208
	--> Epoch [29/100], Loss: 0.1693, Validation Loss: 0.3180
	--> Epoch [30/100], Loss: 0.1994, Validation Loss: 0.3131
	--> Epoch [31/100], Loss: 0.1885, Validation Loss: 0.3077
	--> Epoch [32/100], Loss: 0.3009, Validation Loss: 0.3046
	--> Epoch [33/100], Loss: 0.2781, Validation Loss: 0.3015
	--> Epoch [34/100], Loss: 0.3782, Validation Loss: 0.2976
	--> Epoch [35/100], Loss: 0.2538, Validation Loss: 0.2941
	--> Epoch [36/100], Loss: 0.2563, Validation Loss: 0.2910
	--> Epoch [37/100], Loss: 0.1647, Validation Loss: 0.2877
	--> Epoch [38/100], Loss: 0.2705, Validation Loss: 0.2842
	--> Epoch [39/100], Loss: 0.2598, Validation Loss: 0.2821
	--> Epoch [40/100], Loss: 0.1911, Validation Loss: 0.2766
	--> Epoch [41/100], Loss: 0.3033, Validation Loss: 0.2745
	--> Epoch [42/100], Loss: 0.3107, Validation Loss: 0.2715
	--> Epoch [43/100], Loss: 0.1842, Validation Loss: 0.2697
	--> Epoch [44/100], Loss: 0.3767, Validation Loss: 0.2667
	--> Epoch [45/100], Loss: 0.1624, Validation Loss: 0.2655
	--> Epoch [46/100], Loss: 0.0521, Validation Loss: 0.2627
	--> Epoch [47/100], Loss: 0.1298, Validation Loss: 0.2606
	--> Epoch [48/100], Loss: 0.1872, Validation Loss: 0.2580
	--> Epoch [49/100], Loss: 0.1317, Validation Loss: 0.2590
	--> Epoch [50/100], Loss: 0.1809, Validation Loss: 0.2559
	--> Epoch [51/100], Loss: 0.1023, Validation Loss: 0.2527
	--> Epoch [52/100], Loss: 0.2017, Validation Loss: 0.2520
	--> Epoch [53/100], Loss: 0.2242, Validation Loss: 0.2499
	--> Epoch [54/100], Loss: 0.2367, Validation Loss: 0.2445
	--> Epoch [55/100], Loss: 0.2262, Validation Loss: 0.2431
	--> Epoch [56/100], Loss: 0.1628, Validation Loss: 0.2378
	--> Epoch [57/100], Loss: 0.2824, Validation Loss: 0.2356
	--> Epoch [58/100], Loss: 0.1305, Validation Loss: 0.2339
	--> Epoch [59/100], Loss: 0.1688, Validation Loss: 0.2328
	--> Epoch [60/100], Loss: 0.1553, Validation Loss: 0.2316
	--> Epoch [61/100], Loss: 0.0994, Validation Loss: 0.2315
	--> Epoch [62/100], Loss: 0.0281, Validation Loss: 0.2303
	--> Epoch [63/100], Loss: 0.1531, Validation Loss: 0.2298
	--> Epoch [64/100], Loss: 0.2224, Validation Loss: 0.2270
	--> Epoch [65/100], Loss: 0.2822, Validation Loss: 0.2245
	--> Epoch [66/100], Loss: 0.1016, Validation Loss: 0.2250
	--> Epoch [67/100], Loss: 0.1030, Validation Loss: 0.2228
	--> Epoch [68/100], Loss: 0.0418, Validation Loss: 0.2224
	--> Epoch [69/100], Loss: 0.0928, Validation Loss: 0.2214
	--> Epoch [70/100], Loss: 0.2123, Validation Loss: 0.2198
	--> Epoch [71/100], Loss: 0.1638, Validation Loss: 0.2190
	--> Epoch [72/100], Loss: 0.1460, Validation Loss: 0.2172
	--> Epoch [73/100], Loss: 0.3352, Validation Loss: 0.2160
	--> Epoch [74/100], Loss: 0.0095, Validation Loss: 0.2157
	--> Epoch [75/100], Loss: 0.0868, Validation Loss: 0.2127
	--> Epoch [76/100], Loss: 0.2580, Validation Loss: 0.2113
	--> Epoch [77/100], Loss: 0.1870, Validation Loss: 0.2106
	--> Epoch [78/100], Loss: 0.1445, Validation Loss: 0.2105
	--> Epoch [79/100], Loss: 0.1386, Validation Loss: 0.2061
	--> Epoch [80/100], Loss: 0.1507, Validation Loss: 0.2050
	--> Epoch [81/100], Loss: 0.1450, Validation Loss: 0.2048
	--> Epoch [82/100], Loss: 0.1681, Validation Loss: 0.2038
	--> Epoch [83/100], Loss: 0.2052, Validation Loss: 0.1975
	--> Epoch [84/100], Loss: 0.0741, Validation Loss: 0.1961
	--> Epoch [85/100], Loss: 0.2034, Validation Loss: 0.1960
	--> Epoch [86/100], Loss: 0.1366, Validation Loss: 0.1970
	--> Epoch [87/100], Loss: 0.0761, Validation Loss: 0.1977
	--> Epoch [88/100], Loss: 0.1965, Validation Loss: 0.1957
	--> Epoch [89/100], Loss: 0.0778, Validation Loss: 0.1949
	--> Epoch [90/100], Loss: 0.1383, Validation Loss: 0.1950
	--> Epoch [91/100], Loss: 0.1268, Validation Loss: 0.1952
	--> Epoch [92/100], Loss: 0.3348, Validation Loss: 0.1937
	--> Epoch [93/100], Loss: 0.2741, Validation Loss: 0.1951
	--> Epoch [94/100], Loss: 0.2736, Validation Loss: 0.1945
	--> Epoch [95/100], Loss: 0.1150, Validation Loss: 0.1948
Early stopping
	--> Training for Fold 2 took 0.8125169277191162 sec, using 95 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7939, Validation Loss: 0.6857
	--> Epoch [2/100], Loss: 0.7892, Validation Loss: 0.6782
	--> Epoch [3/100], Loss: 0.6996, Validation Loss: 0.6692
	--> Epoch [4/100], Loss: 0.6893, Validation Loss: 0.6611
	--> Epoch [5/100], Loss: 0.6844, Validation Loss: 0.6503
	--> Epoch [6/100], Loss: 0.6874, Validation Loss: 0.6397
	--> Epoch [7/100], Loss: 0.6484, Validation Loss: 0.6281
	--> Epoch [8/100], Loss: 0.4874, Validation Loss: 0.6195
	--> Epoch [9/100], Loss: 0.5648, Validation Loss: 0.6120
	--> Epoch [10/100], Loss: 0.5029, Validation Loss: 0.6042
	--> Epoch [11/100], Loss: 0.5543, Validation Loss: 0.5946
	--> Epoch [12/100], Loss: 0.4607, Validation Loss: 0.5847
	--> Epoch [13/100], Loss: 0.4507, Validation Loss: 0.5741
	--> Epoch [14/100], Loss: 0.5120, Validation Loss: 0.5679
	--> Epoch [15/100], Loss: 0.4924, Validation Loss: 0.5579
	--> Epoch [16/100], Loss: 0.4014, Validation Loss: 0.5474
	--> Epoch [17/100], Loss: 0.4308, Validation Loss: 0.5374
	--> Epoch [18/100], Loss: 0.4234, Validation Loss: 0.5286
	--> Epoch [19/100], Loss: 0.4192, Validation Loss: 0.5216
	--> Epoch [20/100], Loss: 0.5112, Validation Loss: 0.5125
	--> Epoch [21/100], Loss: 0.3790, Validation Loss: 0.5037
	--> Epoch [22/100], Loss: 0.4811, Validation Loss: 0.4965
	--> Epoch [23/100], Loss: 0.4959, Validation Loss: 0.4912
	--> Epoch [24/100], Loss: 0.3311, Validation Loss: 0.4838
	--> Epoch [25/100], Loss: 0.3321, Validation Loss: 0.4767
	--> Epoch [26/100], Loss: 0.4252, Validation Loss: 0.4710
	--> Epoch [27/100], Loss: 0.3580, Validation Loss: 0.4644
	--> Epoch [28/100], Loss: 0.4004, Validation Loss: 0.4616
	--> Epoch [29/100], Loss: 0.2600, Validation Loss: 0.4561
	--> Epoch [30/100], Loss: 0.5011, Validation Loss: 0.4506
	--> Epoch [31/100], Loss: 0.3930, Validation Loss: 0.4446
	--> Epoch [32/100], Loss: 0.4697, Validation Loss: 0.4402
	--> Epoch [33/100], Loss: 0.4437, Validation Loss: 0.4352
	--> Epoch [34/100], Loss: 0.2901, Validation Loss: 0.4296
	--> Epoch [35/100], Loss: 0.2918, Validation Loss: 0.4274
	--> Epoch [36/100], Loss: 0.4096, Validation Loss: 0.4214
	--> Epoch [37/100], Loss: 0.2868, Validation Loss: 0.4155
	--> Epoch [38/100], Loss: 0.2751, Validation Loss: 0.4111
	--> Epoch [39/100], Loss: 0.2453, Validation Loss: 0.4071
	--> Epoch [40/100], Loss: 0.3197, Validation Loss: 0.4028
	--> Epoch [41/100], Loss: 0.2889, Validation Loss: 0.3987
	--> Epoch [42/100], Loss: 0.3265, Validation Loss: 0.3955
	--> Epoch [43/100], Loss: 0.3478, Validation Loss: 0.3914
	--> Epoch [44/100], Loss: 0.2841, Validation Loss: 0.3872
	--> Epoch [45/100], Loss: 0.3051, Validation Loss: 0.3848
	--> Epoch [46/100], Loss: 0.4346, Validation Loss: 0.3819
	--> Epoch [47/100], Loss: 0.2903, Validation Loss: 0.3794
	--> Epoch [48/100], Loss: 0.2249, Validation Loss: 0.3768
	--> Epoch [49/100], Loss: 0.2412, Validation Loss: 0.3743
	--> Epoch [50/100], Loss: 0.3073, Validation Loss: 0.3713
	--> Epoch [51/100], Loss: 0.3754, Validation Loss: 0.3699
	--> Epoch [52/100], Loss: 0.3582, Validation Loss: 0.3677
	--> Epoch [53/100], Loss: 0.1756, Validation Loss: 0.3643
	--> Epoch [54/100], Loss: 0.2325, Validation Loss: 0.3607
	--> Epoch [55/100], Loss: 0.3479, Validation Loss: 0.3580
	--> Epoch [56/100], Loss: 0.4220, Validation Loss: 0.3572
	--> Epoch [57/100], Loss: 0.3623, Validation Loss: 0.3549
	--> Epoch [58/100], Loss: 0.1842, Validation Loss: 0.3539
	--> Epoch [59/100], Loss: 0.2128, Validation Loss: 0.3521
	--> Epoch [60/100], Loss: 0.2902, Validation Loss: 0.3518
	--> Epoch [61/100], Loss: 0.4301, Validation Loss: 0.3499
	--> Epoch [62/100], Loss: 0.4065, Validation Loss: 0.3474
	--> Epoch [63/100], Loss: 0.3271, Validation Loss: 0.3466
	--> Epoch [64/100], Loss: 0.2081, Validation Loss: 0.3462
	--> Epoch [65/100], Loss: 0.2765, Validation Loss: 0.3438
	--> Epoch [66/100], Loss: 0.2087, Validation Loss: 0.3441
	--> Epoch [67/100], Loss: 0.2095, Validation Loss: 0.3434
	--> Epoch [68/100], Loss: 0.2833, Validation Loss: 0.3403
	--> Epoch [69/100], Loss: 0.3355, Validation Loss: 0.3416
	--> Epoch [70/100], Loss: 0.2073, Validation Loss: 0.3403
	--> Epoch [71/100], Loss: 0.3295, Validation Loss: 0.3395
	--> Epoch [72/100], Loss: 0.2051, Validation Loss: 0.3385
	--> Epoch [73/100], Loss: 0.2759, Validation Loss: 0.3383
	--> Epoch [74/100], Loss: 0.2089, Validation Loss: 0.3375
	--> Epoch [75/100], Loss: 0.2650, Validation Loss: 0.3366
	--> Epoch [76/100], Loss: 0.2653, Validation Loss: 0.3352
	--> Epoch [77/100], Loss: 0.2633, Validation Loss: 0.3333
	--> Epoch [78/100], Loss: 0.3240, Validation Loss: 0.3328
	--> Epoch [79/100], Loss: 0.3872, Validation Loss: 0.3324
	--> Epoch [80/100], Loss: 0.2603, Validation Loss: 0.3333
	--> Epoch [81/100], Loss: 0.1962, Validation Loss: 0.3323
	--> Epoch [82/100], Loss: 0.1955, Validation Loss: 0.3335
	--> Epoch [83/100], Loss: 0.3338, Validation Loss: 0.3334
	--> Epoch [84/100], Loss: 0.2107, Validation Loss: 0.3338
Early stopping
	--> Training for Fold 3 took 0.7346081733703613 sec, using 84 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8047, Validation Loss: 0.5966
	--> Epoch [2/100], Loss: 0.8255, Validation Loss: 0.5766
	--> Epoch [3/100], Loss: 0.7118, Validation Loss: 0.5469
	--> Epoch [4/100], Loss: 0.6945, Validation Loss: 0.5328
	--> Epoch [5/100], Loss: 0.6076, Validation Loss: 0.5207
	--> Epoch [6/100], Loss: 0.5888, Validation Loss: 0.5100
	--> Epoch [7/100], Loss: 0.6299, Validation Loss: 0.5013
	--> Epoch [8/100], Loss: 0.6270, Validation Loss: 0.4966
	--> Epoch [9/100], Loss: 0.5857, Validation Loss: 0.4913
	--> Epoch [10/100], Loss: 0.6129, Validation Loss: 0.4854
	--> Epoch [11/100], Loss: 0.5479, Validation Loss: 0.4796
	--> Epoch [12/100], Loss: 0.4894, Validation Loss: 0.4735
	--> Epoch [13/100], Loss: 0.5176, Validation Loss: 0.4653
	--> Epoch [14/100], Loss: 0.4597, Validation Loss: 0.4538
	--> Epoch [15/100], Loss: 0.4631, Validation Loss: 0.4436
	--> Epoch [16/100], Loss: 0.4449, Validation Loss: 0.4353
	--> Epoch [17/100], Loss: 0.3673, Validation Loss: 0.4299
	--> Epoch [18/100], Loss: 0.3807, Validation Loss: 0.4208
	--> Epoch [19/100], Loss: 0.3874, Validation Loss: 0.4159
	--> Epoch [20/100], Loss: 0.4041, Validation Loss: 0.4109
	--> Epoch [21/100], Loss: 0.4868, Validation Loss: 0.4048
	--> Epoch [22/100], Loss: 0.2981, Validation Loss: 0.4010
	--> Epoch [23/100], Loss: 0.3905, Validation Loss: 0.3916
	--> Epoch [24/100], Loss: 0.3351, Validation Loss: 0.3845
	--> Epoch [25/100], Loss: 0.3427, Validation Loss: 0.3756
	--> Epoch [26/100], Loss: 0.3055, Validation Loss: 0.3677
	--> Epoch [27/100], Loss: 0.3506, Validation Loss: 0.3675
	--> Epoch [28/100], Loss: 0.3238, Validation Loss: 0.3637
	--> Epoch [29/100], Loss: 0.2975, Validation Loss: 0.3552
	--> Epoch [30/100], Loss: 0.3593, Validation Loss: 0.3489
	--> Epoch [31/100], Loss: 0.3283, Validation Loss: 0.3442
	--> Epoch [32/100], Loss: 0.3832, Validation Loss: 0.3402
	--> Epoch [33/100], Loss: 0.2564, Validation Loss: 0.3346
	--> Epoch [34/100], Loss: 0.1981, Validation Loss: 0.3312
	--> Epoch [35/100], Loss: 0.2937, Validation Loss: 0.3266
	--> Epoch [36/100], Loss: 0.3000, Validation Loss: 0.3248
	--> Epoch [37/100], Loss: 0.4246, Validation Loss: 0.3217
	--> Epoch [38/100], Loss: 0.3009, Validation Loss: 0.3176
	--> Epoch [39/100], Loss: 0.3238, Validation Loss: 0.3132
	--> Epoch [40/100], Loss: 0.2077, Validation Loss: 0.3098
	--> Epoch [41/100], Loss: 0.3376, Validation Loss: 0.3061
	--> Epoch [42/100], Loss: 0.3151, Validation Loss: 0.3028
	--> Epoch [43/100], Loss: 0.2747, Validation Loss: 0.3020
	--> Epoch [44/100], Loss: 0.3081, Validation Loss: 0.2971
	--> Epoch [45/100], Loss: 0.2233, Validation Loss: 0.2944
	--> Epoch [46/100], Loss: 0.2188, Validation Loss: 0.2910
	--> Epoch [47/100], Loss: 0.2481, Validation Loss: 0.2886
	--> Epoch [48/100], Loss: 0.2696, Validation Loss: 0.2856
	--> Epoch [49/100], Loss: 0.2483, Validation Loss: 0.2837
	--> Epoch [50/100], Loss: 0.2169, Validation Loss: 0.2810
	--> Epoch [51/100], Loss: 0.2822, Validation Loss: 0.2788
	--> Epoch [52/100], Loss: 0.2949, Validation Loss: 0.2785
	--> Epoch [53/100], Loss: 0.1871, Validation Loss: 0.2753
	--> Epoch [54/100], Loss: 0.2898, Validation Loss: 0.2736
	--> Epoch [55/100], Loss: 0.2523, Validation Loss: 0.2727
	--> Epoch [56/100], Loss: 0.1387, Validation Loss: 0.2694
	--> Epoch [57/100], Loss: 0.2307, Validation Loss: 0.2686
	--> Epoch [58/100], Loss: 0.1794, Validation Loss: 0.2691
	--> Epoch [59/100], Loss: 0.3272, Validation Loss: 0.2690
	--> Epoch [60/100], Loss: 0.1440, Validation Loss: 0.2665
	--> Epoch [61/100], Loss: 0.1668, Validation Loss: 0.2700
	--> Epoch [62/100], Loss: 0.1689, Validation Loss: 0.2681
	--> Epoch [63/100], Loss: 0.2130, Validation Loss: 0.2653
	--> Epoch [64/100], Loss: 0.1619, Validation Loss: 0.2654
	--> Epoch [65/100], Loss: 0.2786, Validation Loss: 0.2644
	--> Epoch [66/100], Loss: 0.1671, Validation Loss: 0.2615
	--> Epoch [67/100], Loss: 0.1224, Validation Loss: 0.2587
	--> Epoch [68/100], Loss: 0.2104, Validation Loss: 0.2580
	--> Epoch [69/100], Loss: 0.3037, Validation Loss: 0.2554
	--> Epoch [70/100], Loss: 0.2409, Validation Loss: 0.2546
	--> Epoch [71/100], Loss: 0.2028, Validation Loss: 0.2538
	--> Epoch [72/100], Loss: 0.1640, Validation Loss: 0.2534
	--> Epoch [73/100], Loss: 0.1600, Validation Loss: 0.2518
	--> Epoch [74/100], Loss: 0.2359, Validation Loss: 0.2503
	--> Epoch [75/100], Loss: 0.2432, Validation Loss: 0.2496
	--> Epoch [76/100], Loss: 0.1491, Validation Loss: 0.2485
	--> Epoch [77/100], Loss: 0.2747, Validation Loss: 0.2482
	--> Epoch [78/100], Loss: 0.3350, Validation Loss: 0.2499
	--> Epoch [79/100], Loss: 0.1049, Validation Loss: 0.2460
	--> Epoch [80/100], Loss: 0.3237, Validation Loss: 0.2469
	--> Epoch [81/100], Loss: 0.2852, Validation Loss: 0.2466
	--> Epoch [82/100], Loss: 0.3205, Validation Loss: 0.2448
	--> Epoch [83/100], Loss: 0.1906, Validation Loss: 0.2473
	--> Epoch [84/100], Loss: 0.1930, Validation Loss: 0.2460
	--> Epoch [85/100], Loss: 0.1068, Validation Loss: 0.2451
Early stopping
	--> Training for Fold 4 took 0.709479570388794 sec, using 85 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8130, Validation Loss: 0.6542
	--> Epoch [2/100], Loss: 0.8087, Validation Loss: 0.6375
	--> Epoch [3/100], Loss: 0.8230, Validation Loss: 0.6273
	--> Epoch [4/100], Loss: 0.7403, Validation Loss: 0.6198
	--> Epoch [5/100], Loss: 0.6909, Validation Loss: 0.6129
	--> Epoch [6/100], Loss: 0.7014, Validation Loss: 0.6094
	--> Epoch [7/100], Loss: 0.6464, Validation Loss: 0.6027
	--> Epoch [8/100], Loss: 0.6504, Validation Loss: 0.5953
	--> Epoch [9/100], Loss: 0.5567, Validation Loss: 0.5911
	--> Epoch [10/100], Loss: 0.5875, Validation Loss: 0.5872
	--> Epoch [11/100], Loss: 0.5617, Validation Loss: 0.5833
	--> Epoch [12/100], Loss: 0.5718, Validation Loss: 0.5798
	--> Epoch [13/100], Loss: 0.5236, Validation Loss: 0.5771
	--> Epoch [14/100], Loss: 0.4889, Validation Loss: 0.5746
	--> Epoch [15/100], Loss: 0.3945, Validation Loss: 0.5722
	--> Epoch [16/100], Loss: 0.3656, Validation Loss: 0.5714
	--> Epoch [17/100], Loss: 0.4156, Validation Loss: 0.5687
	--> Epoch [18/100], Loss: 0.4051, Validation Loss: 0.5660
	--> Epoch [19/100], Loss: 0.3129, Validation Loss: 0.5659
	--> Epoch [20/100], Loss: 0.3993, Validation Loss: 0.5664
	--> Epoch [21/100], Loss: 0.3568, Validation Loss: 0.5657
	--> Epoch [22/100], Loss: 0.2890, Validation Loss: 0.5653
	--> Epoch [23/100], Loss: 0.3123, Validation Loss: 0.5649
	--> Epoch [24/100], Loss: 0.2685, Validation Loss: 0.5642
	--> Epoch [25/100], Loss: 0.2960, Validation Loss: 0.5672
	--> Epoch [26/100], Loss: 0.2399, Validation Loss: 0.5649
	--> Epoch [27/100], Loss: 0.2231, Validation Loss: 0.5642
Early stopping
	--> Training for Fold 5 took 0.22928786277770996 sec, using 27 epochs

Median number of epochs used: 84 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/84], Loss: 0.6473
	--> Final training Epoch [2/84], Loss: 0.6687
	--> Final training Epoch [3/84], Loss: 0.6666
	--> Final training Epoch [4/84], Loss: 0.6128
	--> Final training Epoch [5/84], Loss: 0.6387
	--> Final training Epoch [6/84], Loss: 0.5796
	--> Final training Epoch [7/84], Loss: 0.5582
	--> Final training Epoch [8/84], Loss: 0.5560
	--> Final training Epoch [9/84], Loss: 0.5131
	--> Final training Epoch [10/84], Loss: 0.4735
	--> Final training Epoch [11/84], Loss: 0.4444
	--> Final training Epoch [12/84], Loss: 0.4674
	--> Final training Epoch [13/84], Loss: 0.5420
	--> Final training Epoch [14/84], Loss: 0.4462
	--> Final training Epoch [15/84], Loss: 0.4913
	--> Final training Epoch [16/84], Loss: 0.4710
	--> Final training Epoch [17/84], Loss: 0.4005
	--> Final training Epoch [18/84], Loss: 0.4528
	--> Final training Epoch [19/84], Loss: 0.4086
	--> Final training Epoch [20/84], Loss: 0.3934
	--> Final training Epoch [21/84], Loss: 0.3332
	--> Final training Epoch [22/84], Loss: 0.3301
	--> Final training Epoch [23/84], Loss: 0.3256
	--> Final training Epoch [24/84], Loss: 0.3216
	--> Final training Epoch [25/84], Loss: 0.3166
	--> Final training Epoch [26/84], Loss: 0.3556
	--> Final training Epoch [27/84], Loss: 0.3354
	--> Final training Epoch [28/84], Loss: 0.3464
	--> Final training Epoch [29/84], Loss: 0.3451
	--> Final training Epoch [30/84], Loss: 0.2572
	--> Final training Epoch [31/84], Loss: 0.3076
	--> Final training Epoch [32/84], Loss: 0.3176
	--> Final training Epoch [33/84], Loss: 0.3128
	--> Final training Epoch [34/84], Loss: 0.2907
	--> Final training Epoch [35/84], Loss: 0.2530
	--> Final training Epoch [36/84], Loss: 0.2387
	--> Final training Epoch [37/84], Loss: 0.2446
	--> Final training Epoch [38/84], Loss: 0.2577
	--> Final training Epoch [39/84], Loss: 0.2042
	--> Final training Epoch [40/84], Loss: 0.2338
	--> Final training Epoch [41/84], Loss: 0.2597
	--> Final training Epoch [42/84], Loss: 0.2070
	--> Final training Epoch [43/84], Loss: 0.2790
	--> Final training Epoch [44/84], Loss: 0.1446
	--> Final training Epoch [45/84], Loss: 0.1805
	--> Final training Epoch [46/84], Loss: 0.1745
	--> Final training Epoch [47/84], Loss: 0.2967
	--> Final training Epoch [48/84], Loss: 0.1984
	--> Final training Epoch [49/84], Loss: 0.2331
	--> Final training Epoch [50/84], Loss: 0.2151
	--> Final training Epoch [51/84], Loss: 0.2169
	--> Final training Epoch [52/84], Loss: 0.2299
	--> Final training Epoch [53/84], Loss: 0.2157
	--> Final training Epoch [54/84], Loss: 0.1379
	--> Final training Epoch [55/84], Loss: 0.2181
	--> Final training Epoch [56/84], Loss: 0.2071
	--> Final training Epoch [57/84], Loss: 0.1510
	--> Final training Epoch [58/84], Loss: 0.1946
	--> Final training Epoch [59/84], Loss: 0.1455
	--> Final training Epoch [60/84], Loss: 0.2161
	--> Final training Epoch [61/84], Loss: 0.1594
	--> Final training Epoch [62/84], Loss: 0.2092
	--> Final training Epoch [63/84], Loss: 0.2011
	--> Final training Epoch [64/84], Loss: 0.1940
	--> Final training Epoch [65/84], Loss: 0.1336
	--> Final training Epoch [66/84], Loss: 0.2025
	--> Final training Epoch [67/84], Loss: 0.2179
	--> Final training Epoch [68/84], Loss: 0.1085
	--> Final training Epoch [69/84], Loss: 0.1389
	--> Final training Epoch [70/84], Loss: 0.1352
	--> Final training Epoch [71/84], Loss: 0.1921
	--> Final training Epoch [72/84], Loss: 0.0996
	--> Final training Epoch [73/84], Loss: 0.1770
	--> Final training Epoch [74/84], Loss: 0.1778
	--> Final training Epoch [75/84], Loss: 0.2221
	--> Final training Epoch [76/84], Loss: 0.1590
	--> Final training Epoch [77/84], Loss: 0.1742
	--> Final training Epoch [78/84], Loss: 0.1048
	--> Final training Epoch [79/84], Loss: 0.1544
	--> Final training Epoch [80/84], Loss: 0.1411
	--> Final training Epoch [81/84], Loss: 0.1659
	--> Final training Epoch [82/84], Loss: 0.1505
	--> Final training Epoch [83/84], Loss: 0.0685
	--> Final training Epoch [84/84], Loss: 0.1633

Final training took 0.664520263671875 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.0639
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8152, Validation Loss: 0.3511,  Current Best Accuracy: 0.8152,  Current Best Validation Loss: 0.3511

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5622, Validation Loss: 0.6663
	--> Epoch [2/100], Loss: 0.6000, Validation Loss: 0.6362
	--> Epoch [3/100], Loss: 0.5063, Validation Loss: 0.6195
	--> Epoch [4/100], Loss: 0.5847, Validation Loss: 0.6107
	--> Epoch [5/100], Loss: 0.4652, Validation Loss: 0.5881
	--> Epoch [6/100], Loss: 0.6236, Validation Loss: 0.5837
	--> Epoch [7/100], Loss: 0.4300, Validation Loss: 0.5694
	--> Epoch [8/100], Loss: 0.3678, Validation Loss: 0.5619
	--> Epoch [9/100], Loss: 0.4480, Validation Loss: 0.5497
	--> Epoch [10/100], Loss: 0.4152, Validation Loss: 0.5445
	--> Epoch [11/100], Loss: 0.4764, Validation Loss: 0.5378
	--> Epoch [12/100], Loss: 0.3572, Validation Loss: 0.5265
	--> Epoch [13/100], Loss: 0.3858, Validation Loss: 0.5186
	--> Epoch [14/100], Loss: 0.4137, Validation Loss: 0.5159
	--> Epoch [15/100], Loss: 0.3986, Validation Loss: 0.5122
	--> Epoch [16/100], Loss: 0.1989, Validation Loss: 0.5087
	--> Epoch [17/100], Loss: 0.3109, Validation Loss: 0.5012
	--> Epoch [18/100], Loss: 0.4003, Validation Loss: 0.4951
	--> Epoch [19/100], Loss: 0.5563, Validation Loss: 0.4913
	--> Epoch [20/100], Loss: 0.3702, Validation Loss: 0.4804
	--> Epoch [21/100], Loss: 0.5278, Validation Loss: 0.4786
	--> Epoch [22/100], Loss: 0.4159, Validation Loss: 0.4717
	--> Epoch [23/100], Loss: 0.3744, Validation Loss: 0.4650
	--> Epoch [24/100], Loss: 0.2893, Validation Loss: 0.4558
	--> Epoch [25/100], Loss: 0.2895, Validation Loss: 0.4522
	--> Epoch [26/100], Loss: 0.2585, Validation Loss: 0.4480
	--> Epoch [27/100], Loss: 0.4861, Validation Loss: 0.4450
	--> Epoch [28/100], Loss: 0.4383, Validation Loss: 0.4367
	--> Epoch [29/100], Loss: 0.3961, Validation Loss: 0.4317
	--> Epoch [30/100], Loss: 0.3255, Validation Loss: 0.4263
	--> Epoch [31/100], Loss: 0.2745, Validation Loss: 0.4233
	--> Epoch [32/100], Loss: 0.2015, Validation Loss: 0.4184
	--> Epoch [33/100], Loss: 0.3540, Validation Loss: 0.4143
	--> Epoch [34/100], Loss: 0.2176, Validation Loss: 0.4132
	--> Epoch [35/100], Loss: 0.2039, Validation Loss: 0.4066
	--> Epoch [36/100], Loss: 0.1944, Validation Loss: 0.4002
	--> Epoch [37/100], Loss: 0.3220, Validation Loss: 0.3967
	--> Epoch [38/100], Loss: 0.4088, Validation Loss: 0.3921
	--> Epoch [39/100], Loss: 0.2273, Validation Loss: 0.3883
	--> Epoch [40/100], Loss: 0.2887, Validation Loss: 0.3845
	--> Epoch [41/100], Loss: 0.0862, Validation Loss: 0.3806
	--> Epoch [42/100], Loss: 0.2410, Validation Loss: 0.3771
	--> Epoch [43/100], Loss: 0.1378, Validation Loss: 0.3757
	--> Epoch [44/100], Loss: 0.2426, Validation Loss: 0.3729
	--> Epoch [45/100], Loss: 0.0923, Validation Loss: 0.3690
	--> Epoch [46/100], Loss: 0.3127, Validation Loss: 0.3665
	--> Epoch [47/100], Loss: 0.2465, Validation Loss: 0.3641
	--> Epoch [48/100], Loss: 0.1812, Validation Loss: 0.3615
	--> Epoch [49/100], Loss: 0.0301, Validation Loss: 0.3597
	--> Epoch [50/100], Loss: 0.0931, Validation Loss: 0.3579
	--> Epoch [51/100], Loss: 0.2917, Validation Loss: 0.3579
	--> Epoch [52/100], Loss: 0.4024, Validation Loss: 0.3558
	--> Epoch [53/100], Loss: 0.2423, Validation Loss: 0.3544
	--> Epoch [54/100], Loss: 0.2877, Validation Loss: 0.3541
	--> Epoch [55/100], Loss: 0.0829, Validation Loss: 0.3532
	--> Epoch [56/100], Loss: 0.2362, Validation Loss: 0.3490
	--> Epoch [57/100], Loss: 0.2233, Validation Loss: 0.3467
	--> Epoch [58/100], Loss: 0.2843, Validation Loss: 0.3426
	--> Epoch [59/100], Loss: 0.3517, Validation Loss: 0.3411
	--> Epoch [60/100], Loss: 0.2952, Validation Loss: 0.3399
	--> Epoch [61/100], Loss: 0.1581, Validation Loss: 0.3377
	--> Epoch [62/100], Loss: 0.2444, Validation Loss: 0.3368
	--> Epoch [63/100], Loss: 0.1575, Validation Loss: 0.3351
	--> Epoch [64/100], Loss: 0.1079, Validation Loss: 0.3323
	--> Epoch [65/100], Loss: 0.2974, Validation Loss: 0.3306
	--> Epoch [66/100], Loss: 0.2116, Validation Loss: 0.3279
	--> Epoch [67/100], Loss: 0.3531, Validation Loss: 0.3253
	--> Epoch [68/100], Loss: 0.4113, Validation Loss: 0.3238
	--> Epoch [69/100], Loss: 0.1466, Validation Loss: 0.3237
	--> Epoch [70/100], Loss: 0.1605, Validation Loss: 0.3208
	--> Epoch [71/100], Loss: 0.1486, Validation Loss: 0.3192
	--> Epoch [72/100], Loss: 0.2449, Validation Loss: 0.3159
	--> Epoch [73/100], Loss: 0.1609, Validation Loss: 0.3153
	--> Epoch [74/100], Loss: 0.3387, Validation Loss: 0.3155
	--> Epoch [75/100], Loss: 0.2988, Validation Loss: 0.3141
	--> Epoch [76/100], Loss: 0.2691, Validation Loss: 0.3137
	--> Epoch [77/100], Loss: 0.2656, Validation Loss: 0.3126
	--> Epoch [78/100], Loss: 0.2038, Validation Loss: 0.3121
	--> Epoch [79/100], Loss: 0.0259, Validation Loss: 0.3112
	--> Epoch [80/100], Loss: 0.4095, Validation Loss: 0.3106
	--> Epoch [81/100], Loss: 0.2173, Validation Loss: 0.3109
	--> Epoch [82/100], Loss: 0.2736, Validation Loss: 0.3103
	--> Epoch [83/100], Loss: 0.1619, Validation Loss: 0.3137
	--> Epoch [84/100], Loss: 0.2085, Validation Loss: 0.3127
	--> Epoch [85/100], Loss: 0.0222, Validation Loss: 0.3119
Early stopping
	--> Training for Fold 1 took 0.8057656288146973 sec, using 85 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6013, Validation Loss: 0.7189
	--> Epoch [2/100], Loss: 0.6054, Validation Loss: 0.6790
	--> Epoch [3/100], Loss: 0.8882, Validation Loss: 0.6503
	--> Epoch [4/100], Loss: 0.5887, Validation Loss: 0.6353
	--> Epoch [5/100], Loss: 0.7677, Validation Loss: 0.6092
	--> Epoch [6/100], Loss: 0.6071, Validation Loss: 0.5934
	--> Epoch [7/100], Loss: 0.6681, Validation Loss: 0.5792
	--> Epoch [8/100], Loss: 0.4867, Validation Loss: 0.5722
	--> Epoch [9/100], Loss: 0.5483, Validation Loss: 0.5608
	--> Epoch [10/100], Loss: 0.4316, Validation Loss: 0.5436
	--> Epoch [11/100], Loss: 0.5079, Validation Loss: 0.5382
	--> Epoch [12/100], Loss: 0.4913, Validation Loss: 0.5272
	--> Epoch [13/100], Loss: 0.4292, Validation Loss: 0.5166
	--> Epoch [14/100], Loss: 0.4565, Validation Loss: 0.5098
	--> Epoch [15/100], Loss: 0.5187, Validation Loss: 0.5016
	--> Epoch [16/100], Loss: 0.4419, Validation Loss: 0.4946
	--> Epoch [17/100], Loss: 0.4632, Validation Loss: 0.4887
	--> Epoch [18/100], Loss: 0.3500, Validation Loss: 0.4831
	--> Epoch [19/100], Loss: 0.3447, Validation Loss: 0.4776
	--> Epoch [20/100], Loss: 0.5345, Validation Loss: 0.4722
	--> Epoch [21/100], Loss: 0.3868, Validation Loss: 0.4699
	--> Epoch [22/100], Loss: 0.2384, Validation Loss: 0.4630
	--> Epoch [23/100], Loss: 0.3532, Validation Loss: 0.4572
	--> Epoch [24/100], Loss: 0.3650, Validation Loss: 0.4501
	--> Epoch [25/100], Loss: 0.3629, Validation Loss: 0.4451
	--> Epoch [26/100], Loss: 0.3667, Validation Loss: 0.4409
	--> Epoch [27/100], Loss: 0.3790, Validation Loss: 0.4341
	--> Epoch [28/100], Loss: 0.3669, Validation Loss: 0.4278
	--> Epoch [29/100], Loss: 0.4288, Validation Loss: 0.4245
	--> Epoch [30/100], Loss: 0.3942, Validation Loss: 0.4197
	--> Epoch [31/100], Loss: 0.4138, Validation Loss: 0.4152
	--> Epoch [32/100], Loss: 0.3956, Validation Loss: 0.4076
	--> Epoch [33/100], Loss: 0.3931, Validation Loss: 0.4036
	--> Epoch [34/100], Loss: 0.2591, Validation Loss: 0.3990
	--> Epoch [35/100], Loss: 0.2203, Validation Loss: 0.3953
	--> Epoch [36/100], Loss: 0.3291, Validation Loss: 0.3895
	--> Epoch [37/100], Loss: 0.2806, Validation Loss: 0.3861
	--> Epoch [38/100], Loss: 0.4534, Validation Loss: 0.3826
	--> Epoch [39/100], Loss: 0.5211, Validation Loss: 0.3795
	--> Epoch [40/100], Loss: 0.2373, Validation Loss: 0.3764
	--> Epoch [41/100], Loss: 0.3350, Validation Loss: 0.3751
	--> Epoch [42/100], Loss: 0.3455, Validation Loss: 0.3698
	--> Epoch [43/100], Loss: 0.2413, Validation Loss: 0.3642
	--> Epoch [44/100], Loss: 0.2546, Validation Loss: 0.3614
	--> Epoch [45/100], Loss: 0.2948, Validation Loss: 0.3559
	--> Epoch [46/100], Loss: 0.2405, Validation Loss: 0.3527
	--> Epoch [47/100], Loss: 0.1718, Validation Loss: 0.3502
	--> Epoch [48/100], Loss: 0.3357, Validation Loss: 0.3458
	--> Epoch [49/100], Loss: 0.2492, Validation Loss: 0.3428
	--> Epoch [50/100], Loss: 0.3075, Validation Loss: 0.3414
	--> Epoch [51/100], Loss: 0.1138, Validation Loss: 0.3398
	--> Epoch [52/100], Loss: 0.3272, Validation Loss: 0.3382
	--> Epoch [53/100], Loss: 0.1663, Validation Loss: 0.3384
	--> Epoch [54/100], Loss: 0.1598, Validation Loss: 0.3391
	--> Epoch [55/100], Loss: 0.3230, Validation Loss: 0.3363
	--> Epoch [56/100], Loss: 0.2964, Validation Loss: 0.3324
	--> Epoch [57/100], Loss: 0.3663, Validation Loss: 0.3291
	--> Epoch [58/100], Loss: 0.1625, Validation Loss: 0.3271
	--> Epoch [59/100], Loss: 0.3183, Validation Loss: 0.3257
	--> Epoch [60/100], Loss: 0.2325, Validation Loss: 0.3229
	--> Epoch [61/100], Loss: 0.3672, Validation Loss: 0.3206
	--> Epoch [62/100], Loss: 0.3613, Validation Loss: 0.3180
	--> Epoch [63/100], Loss: 0.1569, Validation Loss: 0.3168
	--> Epoch [64/100], Loss: 0.3608, Validation Loss: 0.3165
	--> Epoch [65/100], Loss: 0.3053, Validation Loss: 0.3152
	--> Epoch [66/100], Loss: 0.2971, Validation Loss: 0.3146
	--> Epoch [67/100], Loss: 0.0964, Validation Loss: 0.3131
	--> Epoch [68/100], Loss: 0.1565, Validation Loss: 0.3115
	--> Epoch [69/100], Loss: 0.2383, Validation Loss: 0.3130
	--> Epoch [70/100], Loss: 0.3775, Validation Loss: 0.3103
	--> Epoch [71/100], Loss: 0.5034, Validation Loss: 0.3110
	--> Epoch [72/100], Loss: 0.2279, Validation Loss: 0.3106
	--> Epoch [73/100], Loss: 0.4994, Validation Loss: 0.3073
	--> Epoch [74/100], Loss: 0.3112, Validation Loss: 0.3096
	--> Epoch [75/100], Loss: 0.4323, Validation Loss: 0.3104
	--> Epoch [76/100], Loss: 0.3571, Validation Loss: 0.3108
Early stopping
	--> Training for Fold 2 took 0.7408721446990967 sec, using 76 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6449, Validation Loss: 0.7068
	--> Epoch [2/100], Loss: 0.5879, Validation Loss: 0.7014
	--> Epoch [3/100], Loss: 0.6364, Validation Loss: 0.6961
	--> Epoch [4/100], Loss: 0.6380, Validation Loss: 0.6916
	--> Epoch [5/100], Loss: 0.5547, Validation Loss: 0.6860
	--> Epoch [6/100], Loss: 0.5854, Validation Loss: 0.6797
	--> Epoch [7/100], Loss: 0.5664, Validation Loss: 0.6745
	--> Epoch [8/100], Loss: 0.5506, Validation Loss: 0.6672
	--> Epoch [9/100], Loss: 0.4759, Validation Loss: 0.6630
	--> Epoch [10/100], Loss: 0.5770, Validation Loss: 0.6594
	--> Epoch [11/100], Loss: 0.5398, Validation Loss: 0.6551
	--> Epoch [12/100], Loss: 0.4998, Validation Loss: 0.6508
	--> Epoch [13/100], Loss: 0.4266, Validation Loss: 0.6479
	--> Epoch [14/100], Loss: 0.3780, Validation Loss: 0.6434
	--> Epoch [15/100], Loss: 0.3744, Validation Loss: 0.6395
	--> Epoch [16/100], Loss: 0.4026, Validation Loss: 0.6351
	--> Epoch [17/100], Loss: 0.3316, Validation Loss: 0.6295
	--> Epoch [18/100], Loss: 0.4102, Validation Loss: 0.6258
	--> Epoch [19/100], Loss: 0.4183, Validation Loss: 0.6206
	--> Epoch [20/100], Loss: 0.3962, Validation Loss: 0.6180
	--> Epoch [21/100], Loss: 0.3218, Validation Loss: 0.6135
	--> Epoch [22/100], Loss: 0.3084, Validation Loss: 0.6082
	--> Epoch [23/100], Loss: 0.3196, Validation Loss: 0.6041
	--> Epoch [24/100], Loss: 0.3487, Validation Loss: 0.5990
	--> Epoch [25/100], Loss: 0.4019, Validation Loss: 0.6011
	--> Epoch [26/100], Loss: 0.3491, Validation Loss: 0.5949
	--> Epoch [27/100], Loss: 0.3651, Validation Loss: 0.5948
	--> Epoch [28/100], Loss: 0.2326, Validation Loss: 0.5918
	--> Epoch [29/100], Loss: 0.3777, Validation Loss: 0.5888
	--> Epoch [30/100], Loss: 0.2956, Validation Loss: 0.5858
	--> Epoch [31/100], Loss: 0.2204, Validation Loss: 0.5844
	--> Epoch [32/100], Loss: 0.4317, Validation Loss: 0.5825
	--> Epoch [33/100], Loss: 0.2382, Validation Loss: 0.5776
	--> Epoch [34/100], Loss: 0.2656, Validation Loss: 0.5729
	--> Epoch [35/100], Loss: 0.2729, Validation Loss: 0.5732
	--> Epoch [36/100], Loss: 0.2013, Validation Loss: 0.5686
	--> Epoch [37/100], Loss: 0.2131, Validation Loss: 0.5646
	--> Epoch [38/100], Loss: 0.2370, Validation Loss: 0.5620
	--> Epoch [39/100], Loss: 0.3209, Validation Loss: 0.5610
	--> Epoch [40/100], Loss: 0.2237, Validation Loss: 0.5582
	--> Epoch [41/100], Loss: 0.3224, Validation Loss: 0.5543
	--> Epoch [42/100], Loss: 0.1407, Validation Loss: 0.5553
	--> Epoch [43/100], Loss: 0.3596, Validation Loss: 0.5514
	--> Epoch [44/100], Loss: 0.2349, Validation Loss: 0.5478
	--> Epoch [45/100], Loss: 0.1849, Validation Loss: 0.5452
	--> Epoch [46/100], Loss: 0.2352, Validation Loss: 0.5428
	--> Epoch [47/100], Loss: 0.3788, Validation Loss: 0.5485
	--> Epoch [48/100], Loss: 0.1608, Validation Loss: 0.5434
	--> Epoch [49/100], Loss: 0.2885, Validation Loss: 0.5393
	--> Epoch [50/100], Loss: 0.2891, Validation Loss: 0.5368
	--> Epoch [51/100], Loss: 0.1710, Validation Loss: 0.5309
	--> Epoch [52/100], Loss: 0.1909, Validation Loss: 0.5267
	--> Epoch [53/100], Loss: 0.2048, Validation Loss: 0.5228
	--> Epoch [54/100], Loss: 0.2910, Validation Loss: 0.5231
	--> Epoch [55/100], Loss: 0.2862, Validation Loss: 0.5300
	--> Epoch [56/100], Loss: 0.1789, Validation Loss: 0.5273
Early stopping
	--> Training for Fold 3 took 0.4790468215942383 sec, using 56 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6795, Validation Loss: 0.7110
	--> Epoch [2/100], Loss: 0.6677, Validation Loss: 0.6947
	--> Epoch [3/100], Loss: 0.6885, Validation Loss: 0.6758
	--> Epoch [4/100], Loss: 0.6207, Validation Loss: 0.6594
	--> Epoch [5/100], Loss: 0.6090, Validation Loss: 0.6453
	--> Epoch [6/100], Loss: 0.6156, Validation Loss: 0.6399
	--> Epoch [7/100], Loss: 0.5675, Validation Loss: 0.6276
	--> Epoch [8/100], Loss: 0.4934, Validation Loss: 0.6187
	--> Epoch [9/100], Loss: 0.5646, Validation Loss: 0.6117
	--> Epoch [10/100], Loss: 0.4606, Validation Loss: 0.5993
	--> Epoch [11/100], Loss: 0.4949, Validation Loss: 0.5900
	--> Epoch [12/100], Loss: 0.5420, Validation Loss: 0.5804
	--> Epoch [13/100], Loss: 0.5163, Validation Loss: 0.5677
	--> Epoch [14/100], Loss: 0.4772, Validation Loss: 0.5610
	--> Epoch [15/100], Loss: 0.4250, Validation Loss: 0.5544
	--> Epoch [16/100], Loss: 0.4354, Validation Loss: 0.5454
	--> Epoch [17/100], Loss: 0.4473, Validation Loss: 0.5390
	--> Epoch [18/100], Loss: 0.3456, Validation Loss: 0.5310
	--> Epoch [19/100], Loss: 0.3239, Validation Loss: 0.5250
	--> Epoch [20/100], Loss: 0.3861, Validation Loss: 0.5198
	--> Epoch [21/100], Loss: 0.4060, Validation Loss: 0.5099
	--> Epoch [22/100], Loss: 0.4297, Validation Loss: 0.5070
	--> Epoch [23/100], Loss: 0.4694, Validation Loss: 0.5015
	--> Epoch [24/100], Loss: 0.4251, Validation Loss: 0.4884
	--> Epoch [25/100], Loss: 0.4650, Validation Loss: 0.4850
	--> Epoch [26/100], Loss: 0.3216, Validation Loss: 0.4793
	--> Epoch [27/100], Loss: 0.2254, Validation Loss: 0.4736
	--> Epoch [28/100], Loss: 0.4686, Validation Loss: 0.4686
	--> Epoch [29/100], Loss: 0.4664, Validation Loss: 0.4591
	--> Epoch [30/100], Loss: 0.3229, Validation Loss: 0.4495
	--> Epoch [31/100], Loss: 0.3646, Validation Loss: 0.4388
	--> Epoch [32/100], Loss: 0.3118, Validation Loss: 0.4271
	--> Epoch [33/100], Loss: 0.2812, Validation Loss: 0.4223
	--> Epoch [34/100], Loss: 0.2579, Validation Loss: 0.4136
	--> Epoch [35/100], Loss: 0.2770, Validation Loss: 0.4127
	--> Epoch [36/100], Loss: 0.3058, Validation Loss: 0.4038
	--> Epoch [37/100], Loss: 0.3147, Validation Loss: 0.3985
	--> Epoch [38/100], Loss: 0.3594, Validation Loss: 0.3974
	--> Epoch [39/100], Loss: 0.2868, Validation Loss: 0.3934
	--> Epoch [40/100], Loss: 0.2638, Validation Loss: 0.3983
	--> Epoch [41/100], Loss: 0.1950, Validation Loss: 0.3927
	--> Epoch [42/100], Loss: 0.2417, Validation Loss: 0.3893
	--> Epoch [43/100], Loss: 0.2512, Validation Loss: 0.3822
	--> Epoch [44/100], Loss: 0.3500, Validation Loss: 0.3739
	--> Epoch [45/100], Loss: 0.2032, Validation Loss: 0.3712
	--> Epoch [46/100], Loss: 0.3518, Validation Loss: 0.3682
	--> Epoch [47/100], Loss: 0.2953, Validation Loss: 0.3646
	--> Epoch [48/100], Loss: 0.2966, Validation Loss: 0.3591
	--> Epoch [49/100], Loss: 0.3932, Validation Loss: 0.3544
	--> Epoch [50/100], Loss: 0.3001, Validation Loss: 0.3515
	--> Epoch [51/100], Loss: 0.1031, Validation Loss: 0.3493
	--> Epoch [52/100], Loss: 0.2535, Validation Loss: 0.3467
	--> Epoch [53/100], Loss: 0.2041, Validation Loss: 0.3559
	--> Epoch [54/100], Loss: 0.2995, Validation Loss: 0.3525
	--> Epoch [55/100], Loss: 0.2046, Validation Loss: 0.3491
Early stopping
	--> Training for Fold 4 took 0.46587419509887695 sec, using 55 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7531, Validation Loss: 0.6612
	--> Epoch [2/100], Loss: 0.6953, Validation Loss: 0.6640
	--> Epoch [3/100], Loss: 0.6389, Validation Loss: 0.6600
	--> Epoch [4/100], Loss: 0.5694, Validation Loss: 0.6619
	--> Epoch [5/100], Loss: 0.6289, Validation Loss: 0.6622
	--> Epoch [6/100], Loss: 0.6011, Validation Loss: 0.6643
Early stopping
	--> Training for Fold 5 took 0.055277109146118164 sec, using 6 epochs

Median number of epochs used: 56 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/56], Loss: 0.6450
	--> Final training Epoch [2/56], Loss: 0.6522
	--> Final training Epoch [3/56], Loss: 0.6751
	--> Final training Epoch [4/56], Loss: 0.6274
	--> Final training Epoch [5/56], Loss: 0.5423
	--> Final training Epoch [6/56], Loss: 0.5730
	--> Final training Epoch [7/56], Loss: 0.5067
	--> Final training Epoch [8/56], Loss: 0.5447
	--> Final training Epoch [9/56], Loss: 0.5343
	--> Final training Epoch [10/56], Loss: 0.4659
	--> Final training Epoch [11/56], Loss: 0.4822
	--> Final training Epoch [12/56], Loss: 0.5627
	--> Final training Epoch [13/56], Loss: 0.4938
	--> Final training Epoch [14/56], Loss: 0.5234
	--> Final training Epoch [15/56], Loss: 0.5254
	--> Final training Epoch [16/56], Loss: 0.4860
	--> Final training Epoch [17/56], Loss: 0.5455
	--> Final training Epoch [18/56], Loss: 0.4772
	--> Final training Epoch [19/56], Loss: 0.4382
	--> Final training Epoch [20/56], Loss: 0.4349
	--> Final training Epoch [21/56], Loss: 0.4485
	--> Final training Epoch [22/56], Loss: 0.3759
	--> Final training Epoch [23/56], Loss: 0.5019
	--> Final training Epoch [24/56], Loss: 0.4229
	--> Final training Epoch [25/56], Loss: 0.3721
	--> Final training Epoch [26/56], Loss: 0.3950
	--> Final training Epoch [27/56], Loss: 0.3992
	--> Final training Epoch [28/56], Loss: 0.4653
	--> Final training Epoch [29/56], Loss: 0.3822
	--> Final training Epoch [30/56], Loss: 0.3803
	--> Final training Epoch [31/56], Loss: 0.3612
	--> Final training Epoch [32/56], Loss: 0.3389
	--> Final training Epoch [33/56], Loss: 0.4013
	--> Final training Epoch [34/56], Loss: 0.3405
	--> Final training Epoch [35/56], Loss: 0.3708
	--> Final training Epoch [36/56], Loss: 0.3468
	--> Final training Epoch [37/56], Loss: 0.2814
	--> Final training Epoch [38/56], Loss: 0.3672
	--> Final training Epoch [39/56], Loss: 0.3537
	--> Final training Epoch [40/56], Loss: 0.3659
	--> Final training Epoch [41/56], Loss: 0.2746
	--> Final training Epoch [42/56], Loss: 0.3376
	--> Final training Epoch [43/56], Loss: 0.3219
	--> Final training Epoch [44/56], Loss: 0.3226
	--> Final training Epoch [45/56], Loss: 0.3308
	--> Final training Epoch [46/56], Loss: 0.3161
	--> Final training Epoch [47/56], Loss: 0.2755
	--> Final training Epoch [48/56], Loss: 0.3650
	--> Final training Epoch [49/56], Loss: 0.2307
	--> Final training Epoch [50/56], Loss: 0.3022
	--> Final training Epoch [51/56], Loss: 0.2347
	--> Final training Epoch [52/56], Loss: 0.3075
	--> Final training Epoch [53/56], Loss: 0.3587
	--> Final training Epoch [54/56], Loss: 0.2697
	--> Final training Epoch [55/56], Loss: 0.2403
	--> Final training Epoch [56/56], Loss: 0.2787

Final training took 0.48541855812072754 sec

TESTING
	--> Testing took 0.0094 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.7980
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3659,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3659
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7860, Validation Loss: 0.4343,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3659
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.4224,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3659

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7177, Validation Loss: 0.6537
	--> Epoch [2/100], Loss: 0.6001, Validation Loss: 0.6251
	--> Epoch [3/100], Loss: 0.6303, Validation Loss: 0.5995
	--> Epoch [4/100], Loss: 0.5789, Validation Loss: 0.5817
	--> Epoch [5/100], Loss: 0.5646, Validation Loss: 0.5668
	--> Epoch [6/100], Loss: 0.5121, Validation Loss: 0.5532
	--> Epoch [7/100], Loss: 0.4079, Validation Loss: 0.5466
	--> Epoch [8/100], Loss: 0.4079, Validation Loss: 0.5353
	--> Epoch [9/100], Loss: 0.3988, Validation Loss: 0.5240
	--> Epoch [10/100], Loss: 0.4010, Validation Loss: 0.5152
	--> Epoch [11/100], Loss: 0.3451, Validation Loss: 0.5056
	--> Epoch [12/100], Loss: 0.2670, Validation Loss: 0.4980
	--> Epoch [13/100], Loss: 0.3450, Validation Loss: 0.4884
	--> Epoch [14/100], Loss: 0.2078, Validation Loss: 0.4818
	--> Epoch [15/100], Loss: 0.2677, Validation Loss: 0.4750
	--> Epoch [16/100], Loss: 0.2483, Validation Loss: 0.4680
	--> Epoch [17/100], Loss: 0.2359, Validation Loss: 0.4566
	--> Epoch [18/100], Loss: 0.1187, Validation Loss: 0.4468
	--> Epoch [19/100], Loss: 0.1237, Validation Loss: 0.4388
	--> Epoch [20/100], Loss: 0.2558, Validation Loss: 0.4272
	--> Epoch [21/100], Loss: 0.1414, Validation Loss: 0.4197
	--> Epoch [22/100], Loss: 0.1283, Validation Loss: 0.4151
	--> Epoch [23/100], Loss: 0.1139, Validation Loss: 0.4134
	--> Epoch [24/100], Loss: 0.1066, Validation Loss: 0.4089
	--> Epoch [25/100], Loss: 0.1046, Validation Loss: 0.4040
	--> Epoch [26/100], Loss: 0.0955, Validation Loss: 0.4009
	--> Epoch [27/100], Loss: 0.0788, Validation Loss: 0.3970
	--> Epoch [28/100], Loss: 0.0893, Validation Loss: 0.3911
	--> Epoch [29/100], Loss: 0.0548, Validation Loss: 0.3856
	--> Epoch [30/100], Loss: 0.0465, Validation Loss: 0.3813
	--> Epoch [31/100], Loss: 0.0859, Validation Loss: 0.3764
	--> Epoch [32/100], Loss: 0.2006, Validation Loss: 0.3750
	--> Epoch [33/100], Loss: 0.1447, Validation Loss: 0.3708
	--> Epoch [34/100], Loss: 0.0587, Validation Loss: 0.3684
	--> Epoch [35/100], Loss: 0.0649, Validation Loss: 0.3656
	--> Epoch [36/100], Loss: 0.0697, Validation Loss: 0.3613
	--> Epoch [37/100], Loss: 0.0655, Validation Loss: 0.3577
	--> Epoch [38/100], Loss: 0.1626, Validation Loss: 0.3542
	--> Epoch [39/100], Loss: 0.0804, Validation Loss: 0.3534
	--> Epoch [40/100], Loss: 0.0276, Validation Loss: 0.3524
	--> Epoch [41/100], Loss: 0.0700, Validation Loss: 0.3531
	--> Epoch [42/100], Loss: 0.0972, Validation Loss: 0.3477
	--> Epoch [43/100], Loss: 0.0403, Validation Loss: 0.3476
	--> Epoch [44/100], Loss: 0.0539, Validation Loss: 0.3421
	--> Epoch [45/100], Loss: 0.0284, Validation Loss: 0.3387
	--> Epoch [46/100], Loss: 0.0282, Validation Loss: 0.3367
	--> Epoch [47/100], Loss: 0.0358, Validation Loss: 0.3368
	--> Epoch [48/100], Loss: 0.0280, Validation Loss: 0.3336
	--> Epoch [49/100], Loss: 0.0683, Validation Loss: 0.3314
	--> Epoch [50/100], Loss: 0.0242, Validation Loss: 0.3264
	--> Epoch [51/100], Loss: 0.0220, Validation Loss: 0.3249
	--> Epoch [52/100], Loss: 0.0298, Validation Loss: 0.3228
	--> Epoch [53/100], Loss: 0.0299, Validation Loss: 0.3211
	--> Epoch [54/100], Loss: 0.0527, Validation Loss: 0.3207
	--> Epoch [55/100], Loss: 0.0904, Validation Loss: 0.3239
	--> Epoch [56/100], Loss: 0.0420, Validation Loss: 0.3221
	--> Epoch [57/100], Loss: 0.0664, Validation Loss: 0.3193
	--> Epoch [58/100], Loss: 0.0129, Validation Loss: 0.3158
	--> Epoch [59/100], Loss: 0.1094, Validation Loss: 0.3134
	--> Epoch [60/100], Loss: 0.0104, Validation Loss: 0.3142
	--> Epoch [61/100], Loss: 0.0353, Validation Loss: 0.3133
	--> Epoch [62/100], Loss: 0.0366, Validation Loss: 0.3136
	--> Epoch [63/100], Loss: 0.0562, Validation Loss: 0.3149
	--> Epoch [64/100], Loss: 0.0371, Validation Loss: 0.3136
Early stopping
	--> Training for Fold 1 took 0.615372896194458 sec, using 64 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6890, Validation Loss: 0.7049
	--> Epoch [2/100], Loss: 0.6903, Validation Loss: 0.6902
	--> Epoch [3/100], Loss: 0.6328, Validation Loss: 0.6778
	--> Epoch [4/100], Loss: 0.6096, Validation Loss: 0.6634
	--> Epoch [5/100], Loss: 0.5444, Validation Loss: 0.6411
	--> Epoch [6/100], Loss: 0.4909, Validation Loss: 0.6211
	--> Epoch [7/100], Loss: 0.5122, Validation Loss: 0.6003
	--> Epoch [8/100], Loss: 0.4712, Validation Loss: 0.5824
	--> Epoch [9/100], Loss: 0.4253, Validation Loss: 0.5655
	--> Epoch [10/100], Loss: 0.3707, Validation Loss: 0.5468
	--> Epoch [11/100], Loss: 0.3624, Validation Loss: 0.5261
	--> Epoch [12/100], Loss: 0.3443, Validation Loss: 0.5055
	--> Epoch [13/100], Loss: 0.3307, Validation Loss: 0.4857
	--> Epoch [14/100], Loss: 0.2992, Validation Loss: 0.4693
	--> Epoch [15/100], Loss: 0.2508, Validation Loss: 0.4521
	--> Epoch [16/100], Loss: 0.2703, Validation Loss: 0.4373
	--> Epoch [17/100], Loss: 0.2430, Validation Loss: 0.4243
	--> Epoch [18/100], Loss: 0.2699, Validation Loss: 0.4107
	--> Epoch [19/100], Loss: 0.2471, Validation Loss: 0.3983
	--> Epoch [20/100], Loss: 0.2151, Validation Loss: 0.3859
	--> Epoch [21/100], Loss: 0.1747, Validation Loss: 0.3751
	--> Epoch [22/100], Loss: 0.2481, Validation Loss: 0.3655
	--> Epoch [23/100], Loss: 0.2137, Validation Loss: 0.3561
	--> Epoch [24/100], Loss: 0.1498, Validation Loss: 0.3458
	--> Epoch [25/100], Loss: 0.1678, Validation Loss: 0.3371
	--> Epoch [26/100], Loss: 0.1638, Validation Loss: 0.3290
	--> Epoch [27/100], Loss: 0.1314, Validation Loss: 0.3214
	--> Epoch [28/100], Loss: 0.2541, Validation Loss: 0.3139
	--> Epoch [29/100], Loss: 0.1595, Validation Loss: 0.3092
	--> Epoch [30/100], Loss: 0.1475, Validation Loss: 0.3049
	--> Epoch [31/100], Loss: 0.1731, Validation Loss: 0.2988
	--> Epoch [32/100], Loss: 0.1335, Validation Loss: 0.2940
	--> Epoch [33/100], Loss: 0.2295, Validation Loss: 0.2891
	--> Epoch [34/100], Loss: 0.1694, Validation Loss: 0.2825
	--> Epoch [35/100], Loss: 0.1020, Validation Loss: 0.2788
	--> Epoch [36/100], Loss: 0.1308, Validation Loss: 0.2754
	--> Epoch [37/100], Loss: 0.2018, Validation Loss: 0.2711
	--> Epoch [38/100], Loss: 0.1058, Validation Loss: 0.2659
	--> Epoch [39/100], Loss: 0.1053, Validation Loss: 0.2623
	--> Epoch [40/100], Loss: 0.2248, Validation Loss: 0.2608
	--> Epoch [41/100], Loss: 0.1594, Validation Loss: 0.2576
	--> Epoch [42/100], Loss: 0.1476, Validation Loss: 0.2521
	--> Epoch [43/100], Loss: 0.0857, Validation Loss: 0.2517
	--> Epoch [44/100], Loss: 0.1020, Validation Loss: 0.2482
	--> Epoch [45/100], Loss: 0.1062, Validation Loss: 0.2459
	--> Epoch [46/100], Loss: 0.1305, Validation Loss: 0.2458
	--> Epoch [47/100], Loss: 0.1083, Validation Loss: 0.2428
	--> Epoch [48/100], Loss: 0.0802, Validation Loss: 0.2404
	--> Epoch [49/100], Loss: 0.1138, Validation Loss: 0.2391
	--> Epoch [50/100], Loss: 0.0979, Validation Loss: 0.2377
	--> Epoch [51/100], Loss: 0.0862, Validation Loss: 0.2359
	--> Epoch [52/100], Loss: 0.0767, Validation Loss: 0.2340
	--> Epoch [53/100], Loss: 0.1009, Validation Loss: 0.2335
	--> Epoch [54/100], Loss: 0.0820, Validation Loss: 0.2343
	--> Epoch [55/100], Loss: 0.0670, Validation Loss: 0.2340
	--> Epoch [56/100], Loss: 0.0741, Validation Loss: 0.2308
	--> Epoch [57/100], Loss: 0.1030, Validation Loss: 0.2273
	--> Epoch [58/100], Loss: 0.0782, Validation Loss: 0.2273
	--> Epoch [59/100], Loss: 0.0859, Validation Loss: 0.2251
	--> Epoch [60/100], Loss: 0.0617, Validation Loss: 0.2226
	--> Epoch [61/100], Loss: 0.1098, Validation Loss: 0.2220
	--> Epoch [62/100], Loss: 0.0656, Validation Loss: 0.2212
	--> Epoch [63/100], Loss: 0.0970, Validation Loss: 0.2209
	--> Epoch [64/100], Loss: 0.0692, Validation Loss: 0.2165
	--> Epoch [65/100], Loss: 0.0863, Validation Loss: 0.2171
	--> Epoch [66/100], Loss: 0.0670, Validation Loss: 0.2179
	--> Epoch [67/100], Loss: 0.0732, Validation Loss: 0.2183
Early stopping
	--> Training for Fold 2 took 0.5916943550109863 sec, using 67 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6961, Validation Loss: 0.6319
	--> Epoch [2/100], Loss: 0.6169, Validation Loss: 0.6162
	--> Epoch [3/100], Loss: 0.5702, Validation Loss: 0.5995
	--> Epoch [4/100], Loss: 0.5542, Validation Loss: 0.5848
	--> Epoch [5/100], Loss: 0.4694, Validation Loss: 0.5736
	--> Epoch [6/100], Loss: 0.4839, Validation Loss: 0.5642
	--> Epoch [7/100], Loss: 0.4561, Validation Loss: 0.5558
	--> Epoch [8/100], Loss: 0.4517, Validation Loss: 0.5461
	--> Epoch [9/100], Loss: 0.3222, Validation Loss: 0.5382
	--> Epoch [10/100], Loss: 0.3575, Validation Loss: 0.5294
	--> Epoch [11/100], Loss: 0.2999, Validation Loss: 0.5200
	--> Epoch [12/100], Loss: 0.3192, Validation Loss: 0.5088
	--> Epoch [13/100], Loss: 0.3748, Validation Loss: 0.5018
	--> Epoch [14/100], Loss: 0.3189, Validation Loss: 0.4952
	--> Epoch [15/100], Loss: 0.2926, Validation Loss: 0.4880
	--> Epoch [16/100], Loss: 0.2745, Validation Loss: 0.4813
	--> Epoch [17/100], Loss: 0.2515, Validation Loss: 0.4771
	--> Epoch [18/100], Loss: 0.2226, Validation Loss: 0.4702
	--> Epoch [19/100], Loss: 0.2608, Validation Loss: 0.4645
	--> Epoch [20/100], Loss: 0.2742, Validation Loss: 0.4601
	--> Epoch [21/100], Loss: 0.1460, Validation Loss: 0.4537
	--> Epoch [22/100], Loss: 0.1830, Validation Loss: 0.4463
	--> Epoch [23/100], Loss: 0.4076, Validation Loss: 0.4393
	--> Epoch [24/100], Loss: 0.1414, Validation Loss: 0.4352
	--> Epoch [25/100], Loss: 0.2376, Validation Loss: 0.4308
	--> Epoch [26/100], Loss: 0.1487, Validation Loss: 0.4273
	--> Epoch [27/100], Loss: 0.1852, Validation Loss: 0.4222
	--> Epoch [28/100], Loss: 0.1253, Validation Loss: 0.4162
	--> Epoch [29/100], Loss: 0.1074, Validation Loss: 0.4123
	--> Epoch [30/100], Loss: 0.1353, Validation Loss: 0.4097
	--> Epoch [31/100], Loss: 0.1407, Validation Loss: 0.4045
	--> Epoch [32/100], Loss: 0.1496, Validation Loss: 0.4029
	--> Epoch [33/100], Loss: 0.1950, Validation Loss: 0.4009
	--> Epoch [34/100], Loss: 0.2042, Validation Loss: 0.3967
	--> Epoch [35/100], Loss: 0.1977, Validation Loss: 0.3945
	--> Epoch [36/100], Loss: 0.1847, Validation Loss: 0.3915
	--> Epoch [37/100], Loss: 0.1252, Validation Loss: 0.3897
	--> Epoch [38/100], Loss: 0.0723, Validation Loss: 0.3865
	--> Epoch [39/100], Loss: 0.1153, Validation Loss: 0.3832
	--> Epoch [40/100], Loss: 0.1160, Validation Loss: 0.3807
	--> Epoch [41/100], Loss: 0.0840, Validation Loss: 0.3793
	--> Epoch [42/100], Loss: 0.1066, Validation Loss: 0.3755
	--> Epoch [43/100], Loss: 0.2043, Validation Loss: 0.3728
	--> Epoch [44/100], Loss: 0.1687, Validation Loss: 0.3712
	--> Epoch [45/100], Loss: 0.1647, Validation Loss: 0.3685
	--> Epoch [46/100], Loss: 0.1073, Validation Loss: 0.3684
	--> Epoch [47/100], Loss: 0.1052, Validation Loss: 0.3664
	--> Epoch [48/100], Loss: 0.2465, Validation Loss: 0.3633
	--> Epoch [49/100], Loss: 0.1208, Validation Loss: 0.3636
	--> Epoch [50/100], Loss: 0.1352, Validation Loss: 0.3629
	--> Epoch [51/100], Loss: 0.0692, Validation Loss: 0.3611
	--> Epoch [52/100], Loss: 0.1231, Validation Loss: 0.3594
	--> Epoch [53/100], Loss: 0.0462, Validation Loss: 0.3587
	--> Epoch [54/100], Loss: 0.0920, Validation Loss: 0.3544
	--> Epoch [55/100], Loss: 0.0841, Validation Loss: 0.3541
	--> Epoch [56/100], Loss: 0.0506, Validation Loss: 0.3526
	--> Epoch [57/100], Loss: 0.0367, Validation Loss: 0.3517
	--> Epoch [58/100], Loss: 0.0907, Validation Loss: 0.3503
	--> Epoch [59/100], Loss: 0.0421, Validation Loss: 0.3513
	--> Epoch [60/100], Loss: 0.0341, Validation Loss: 0.3499
	--> Epoch [61/100], Loss: 0.0980, Validation Loss: 0.3494
	--> Epoch [62/100], Loss: 0.1677, Validation Loss: 0.3497
	--> Epoch [63/100], Loss: 0.0329, Validation Loss: 0.3473
	--> Epoch [64/100], Loss: 0.0861, Validation Loss: 0.3454
	--> Epoch [65/100], Loss: 0.1560, Validation Loss: 0.3431
	--> Epoch [66/100], Loss: 0.0822, Validation Loss: 0.3435
	--> Epoch [67/100], Loss: 0.1472, Validation Loss: 0.3420
	--> Epoch [68/100], Loss: 0.0304, Validation Loss: 0.3416
	--> Epoch [69/100], Loss: 0.0314, Validation Loss: 0.3396
	--> Epoch [70/100], Loss: 0.0214, Validation Loss: 0.3393
	--> Epoch [71/100], Loss: 0.0237, Validation Loss: 0.3386
	--> Epoch [72/100], Loss: 0.1766, Validation Loss: 0.3384
	--> Epoch [73/100], Loss: 0.0775, Validation Loss: 0.3386
	--> Epoch [74/100], Loss: 0.0267, Validation Loss: 0.3382
	--> Epoch [75/100], Loss: 0.0826, Validation Loss: 0.3390
	--> Epoch [76/100], Loss: 0.0325, Validation Loss: 0.3392
	--> Epoch [77/100], Loss: 0.0278, Validation Loss: 0.3383
Early stopping
	--> Training for Fold 3 took 0.6568496227264404 sec, using 77 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6957, Validation Loss: 0.7645
	--> Epoch [2/100], Loss: 0.6482, Validation Loss: 0.7306
	--> Epoch [3/100], Loss: 0.5954, Validation Loss: 0.6940
	--> Epoch [4/100], Loss: 0.5927, Validation Loss: 0.6669
	--> Epoch [5/100], Loss: 0.4592, Validation Loss: 0.6414
	--> Epoch [6/100], Loss: 0.4705, Validation Loss: 0.6184
	--> Epoch [7/100], Loss: 0.4227, Validation Loss: 0.5915
	--> Epoch [8/100], Loss: 0.3591, Validation Loss: 0.5677
	--> Epoch [9/100], Loss: 0.3478, Validation Loss: 0.5490
	--> Epoch [10/100], Loss: 0.3318, Validation Loss: 0.5340
	--> Epoch [11/100], Loss: 0.3886, Validation Loss: 0.5192
	--> Epoch [12/100], Loss: 0.3584, Validation Loss: 0.5065
	--> Epoch [13/100], Loss: 0.3038, Validation Loss: 0.4900
	--> Epoch [14/100], Loss: 0.2976, Validation Loss: 0.4758
	--> Epoch [15/100], Loss: 0.3142, Validation Loss: 0.4647
	--> Epoch [16/100], Loss: 0.2537, Validation Loss: 0.4549
	--> Epoch [17/100], Loss: 0.2186, Validation Loss: 0.4435
	--> Epoch [18/100], Loss: 0.1836, Validation Loss: 0.4338
	--> Epoch [19/100], Loss: 0.2802, Validation Loss: 0.4246
	--> Epoch [20/100], Loss: 0.2058, Validation Loss: 0.4171
	--> Epoch [21/100], Loss: 0.1541, Validation Loss: 0.4098
	--> Epoch [22/100], Loss: 0.1519, Validation Loss: 0.4022
	--> Epoch [23/100], Loss: 0.1563, Validation Loss: 0.3985
	--> Epoch [24/100], Loss: 0.1738, Validation Loss: 0.3931
	--> Epoch [25/100], Loss: 0.1604, Validation Loss: 0.3887
	--> Epoch [26/100], Loss: 0.1031, Validation Loss: 0.3818
	--> Epoch [27/100], Loss: 0.3022, Validation Loss: 0.3817
	--> Epoch [28/100], Loss: 0.1486, Validation Loss: 0.3776
	--> Epoch [29/100], Loss: 0.0546, Validation Loss: 0.3721
	--> Epoch [30/100], Loss: 0.1358, Validation Loss: 0.3663
	--> Epoch [31/100], Loss: 0.1452, Validation Loss: 0.3632
	--> Epoch [32/100], Loss: 0.1363, Validation Loss: 0.3571
	--> Epoch [33/100], Loss: 0.1249, Validation Loss: 0.3525
	--> Epoch [34/100], Loss: 0.0822, Validation Loss: 0.3437
	--> Epoch [35/100], Loss: 0.1305, Validation Loss: 0.3400
	--> Epoch [36/100], Loss: 0.0520, Validation Loss: 0.3400
	--> Epoch [37/100], Loss: 0.1283, Validation Loss: 0.3340
	--> Epoch [38/100], Loss: 0.0818, Validation Loss: 0.3327
	--> Epoch [39/100], Loss: 0.1249, Validation Loss: 0.3286
	--> Epoch [40/100], Loss: 0.0992, Validation Loss: 0.3272
	--> Epoch [41/100], Loss: 0.0486, Validation Loss: 0.3246
	--> Epoch [42/100], Loss: 0.0944, Validation Loss: 0.3259
	--> Epoch [43/100], Loss: 0.0307, Validation Loss: 0.3251
	--> Epoch [44/100], Loss: 0.1030, Validation Loss: 0.3236
	--> Epoch [45/100], Loss: 0.0576, Validation Loss: 0.3218
	--> Epoch [46/100], Loss: 0.0834, Validation Loss: 0.3195
	--> Epoch [47/100], Loss: 0.1551, Validation Loss: 0.3177
	--> Epoch [48/100], Loss: 0.0543, Validation Loss: 0.3184
	--> Epoch [49/100], Loss: 0.0943, Validation Loss: 0.3133
	--> Epoch [50/100], Loss: 0.1533, Validation Loss: 0.3105
	--> Epoch [51/100], Loss: 0.0380, Validation Loss: 0.3077
	--> Epoch [52/100], Loss: 0.0678, Validation Loss: 0.3055
	--> Epoch [53/100], Loss: 0.0255, Validation Loss: 0.3041
	--> Epoch [54/100], Loss: 0.0705, Validation Loss: 0.3043
	--> Epoch [55/100], Loss: 0.0343, Validation Loss: 0.3031
	--> Epoch [56/100], Loss: 0.0746, Validation Loss: 0.2962
	--> Epoch [57/100], Loss: 0.1454, Validation Loss: 0.3040
	--> Epoch [58/100], Loss: 0.0967, Validation Loss: 0.3016
	--> Epoch [59/100], Loss: 0.0841, Validation Loss: 0.3019
Early stopping
	--> Training for Fold 4 took 0.4914565086364746 sec, using 59 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6247, Validation Loss: 0.7502
	--> Epoch [2/100], Loss: 0.5506, Validation Loss: 0.7485
	--> Epoch [3/100], Loss: 0.4980, Validation Loss: 0.7431
	--> Epoch [4/100], Loss: 0.4964, Validation Loss: 0.7362
	--> Epoch [5/100], Loss: 0.5158, Validation Loss: 0.7297
	--> Epoch [6/100], Loss: 0.4323, Validation Loss: 0.7267
	--> Epoch [7/100], Loss: 0.4112, Validation Loss: 0.7250
	--> Epoch [8/100], Loss: 0.3779, Validation Loss: 0.7242
	--> Epoch [9/100], Loss: 0.3622, Validation Loss: 0.7218
	--> Epoch [10/100], Loss: 0.3469, Validation Loss: 0.7180
	--> Epoch [11/100], Loss: 0.3313, Validation Loss: 0.7131
	--> Epoch [12/100], Loss: 0.3389, Validation Loss: 0.7107
	--> Epoch [13/100], Loss: 0.2909, Validation Loss: 0.7071
	--> Epoch [14/100], Loss: 0.2911, Validation Loss: 0.6994
	--> Epoch [15/100], Loss: 0.3000, Validation Loss: 0.6956
	--> Epoch [16/100], Loss: 0.2996, Validation Loss: 0.6937
	--> Epoch [17/100], Loss: 0.2648, Validation Loss: 0.6905
	--> Epoch [18/100], Loss: 0.2422, Validation Loss: 0.6865
	--> Epoch [19/100], Loss: 0.1973, Validation Loss: 0.6817
	--> Epoch [20/100], Loss: 0.2190, Validation Loss: 0.6758
	--> Epoch [21/100], Loss: 0.1853, Validation Loss: 0.6750
	--> Epoch [22/100], Loss: 0.2210, Validation Loss: 0.6714
	--> Epoch [23/100], Loss: 0.1990, Validation Loss: 0.6705
	--> Epoch [24/100], Loss: 0.1691, Validation Loss: 0.6642
	--> Epoch [25/100], Loss: 0.1612, Validation Loss: 0.6621
	--> Epoch [26/100], Loss: 0.1608, Validation Loss: 0.6584
	--> Epoch [27/100], Loss: 0.1244, Validation Loss: 0.6552
	--> Epoch [28/100], Loss: 0.1528, Validation Loss: 0.6528
	--> Epoch [29/100], Loss: 0.1353, Validation Loss: 0.6492
	--> Epoch [30/100], Loss: 0.1016, Validation Loss: 0.6480
	--> Epoch [31/100], Loss: 0.1107, Validation Loss: 0.6435
	--> Epoch [32/100], Loss: 0.1033, Validation Loss: 0.6418
	--> Epoch [33/100], Loss: 0.0890, Validation Loss: 0.6405
	--> Epoch [34/100], Loss: 0.1670, Validation Loss: 0.6375
	--> Epoch [35/100], Loss: 0.0905, Validation Loss: 0.6357
	--> Epoch [36/100], Loss: 0.0626, Validation Loss: 0.6316
	--> Epoch [37/100], Loss: 0.1197, Validation Loss: 0.6318
	--> Epoch [38/100], Loss: 0.0991, Validation Loss: 0.6271
	--> Epoch [39/100], Loss: 0.0667, Validation Loss: 0.6253
	--> Epoch [40/100], Loss: 0.1221, Validation Loss: 0.6237
	--> Epoch [41/100], Loss: 0.0692, Validation Loss: 0.6256
	--> Epoch [42/100], Loss: 0.0423, Validation Loss: 0.6213
	--> Epoch [43/100], Loss: 0.0394, Validation Loss: 0.6200
	--> Epoch [44/100], Loss: 0.0402, Validation Loss: 0.6171
	--> Epoch [45/100], Loss: 0.0966, Validation Loss: 0.6204
	--> Epoch [46/100], Loss: 0.0367, Validation Loss: 0.6168
	--> Epoch [47/100], Loss: 0.0706, Validation Loss: 0.6170
	--> Epoch [48/100], Loss: 0.0748, Validation Loss: 0.6109
	--> Epoch [49/100], Loss: 0.0733, Validation Loss: 0.6117
	--> Epoch [50/100], Loss: 0.0568, Validation Loss: 0.6115
	--> Epoch [51/100], Loss: 0.0719, Validation Loss: 0.6109
	--> Epoch [52/100], Loss: 0.0339, Validation Loss: 0.6105
	--> Epoch [53/100], Loss: 0.0374, Validation Loss: 0.6115
	--> Epoch [54/100], Loss: 0.0385, Validation Loss: 0.6108
	--> Epoch [55/100], Loss: 0.0589, Validation Loss: 0.6107
Early stopping
	--> Training for Fold 5 took 0.4640347957611084 sec, using 55 epochs

Median number of epochs used: 64 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/64], Loss: 0.6952
	--> Final training Epoch [2/64], Loss: 0.6375
	--> Final training Epoch [3/64], Loss: 0.5879
	--> Final training Epoch [4/64], Loss: 0.5405
	--> Final training Epoch [5/64], Loss: 0.5427
	--> Final training Epoch [6/64], Loss: 0.4730
	--> Final training Epoch [7/64], Loss: 0.4730
	--> Final training Epoch [8/64], Loss: 0.5073
	--> Final training Epoch [9/64], Loss: 0.4514
	--> Final training Epoch [10/64], Loss: 0.4345
	--> Final training Epoch [11/64], Loss: 0.4015
	--> Final training Epoch [12/64], Loss: 0.4065
	--> Final training Epoch [13/64], Loss: 0.3577
	--> Final training Epoch [14/64], Loss: 0.3514
	--> Final training Epoch [15/64], Loss: 0.3673
	--> Final training Epoch [16/64], Loss: 0.3260
	--> Final training Epoch [17/64], Loss: 0.3108
	--> Final training Epoch [18/64], Loss: 0.3275
	--> Final training Epoch [19/64], Loss: 0.2866
	--> Final training Epoch [20/64], Loss: 0.2879
	--> Final training Epoch [21/64], Loss: 0.3102
	--> Final training Epoch [22/64], Loss: 0.3065
	--> Final training Epoch [23/64], Loss: 0.2620
	--> Final training Epoch [24/64], Loss: 0.2540
	--> Final training Epoch [25/64], Loss: 0.2574
	--> Final training Epoch [26/64], Loss: 0.2286
	--> Final training Epoch [27/64], Loss: 0.1754
	--> Final training Epoch [28/64], Loss: 0.1913
	--> Final training Epoch [29/64], Loss: 0.1419
	--> Final training Epoch [30/64], Loss: 0.2194
	--> Final training Epoch [31/64], Loss: 0.1306
	--> Final training Epoch [32/64], Loss: 0.1830
	--> Final training Epoch [33/64], Loss: 0.1783
	--> Final training Epoch [34/64], Loss: 0.1035
	--> Final training Epoch [35/64], Loss: 0.1510
	--> Final training Epoch [36/64], Loss: 0.1029
	--> Final training Epoch [37/64], Loss: 0.1333
	--> Final training Epoch [38/64], Loss: 0.1407
	--> Final training Epoch [39/64], Loss: 0.1101
	--> Final training Epoch [40/64], Loss: 0.0999
	--> Final training Epoch [41/64], Loss: 0.1457
	--> Final training Epoch [42/64], Loss: 0.0842
	--> Final training Epoch [43/64], Loss: 0.1222
	--> Final training Epoch [44/64], Loss: 0.1681
	--> Final training Epoch [45/64], Loss: 0.1061
	--> Final training Epoch [46/64], Loss: 0.1352
	--> Final training Epoch [47/64], Loss: 0.1119
	--> Final training Epoch [48/64], Loss: 0.1670
	--> Final training Epoch [49/64], Loss: 0.1018
	--> Final training Epoch [50/64], Loss: 0.0932
	--> Final training Epoch [51/64], Loss: 0.0741
	--> Final training Epoch [52/64], Loss: 0.1294
	--> Final training Epoch [53/64], Loss: 0.1548
	--> Final training Epoch [54/64], Loss: 0.0975
	--> Final training Epoch [55/64], Loss: 0.1115
	--> Final training Epoch [56/64], Loss: 0.1062
	--> Final training Epoch [57/64], Loss: 0.0803
	--> Final training Epoch [58/64], Loss: 0.1284
	--> Final training Epoch [59/64], Loss: 0.0578
	--> Final training Epoch [60/64], Loss: 0.0516
	--> Final training Epoch [61/64], Loss: 0.0588
	--> Final training Epoch [62/64], Loss: 0.0937
	--> Final training Epoch [63/64], Loss: 0.0429
	--> Final training Epoch [64/64], Loss: 0.0552

Final training took 0.557018518447876 sec

TESTING
	--> Testing took 0.0103 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9312
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8064, Validation Loss: 0.3528,  Current Best Accuracy: 0.8064,  Current Best Validation Loss: 0.3528

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7510, Validation Loss: 0.6727
	--> Epoch [2/100], Loss: 0.6849, Validation Loss: 0.6397
	--> Epoch [3/100], Loss: 0.6561, Validation Loss: 0.6168
	--> Epoch [4/100], Loss: 0.6371, Validation Loss: 0.5918
	--> Epoch [5/100], Loss: 0.5851, Validation Loss: 0.5741
	--> Epoch [6/100], Loss: 0.5580, Validation Loss: 0.5523
	--> Epoch [7/100], Loss: 0.5275, Validation Loss: 0.5381
	--> Epoch [8/100], Loss: 0.5144, Validation Loss: 0.5235
	--> Epoch [9/100], Loss: 0.4526, Validation Loss: 0.5033
	--> Epoch [10/100], Loss: 0.4896, Validation Loss: 0.4882
	--> Epoch [11/100], Loss: 0.4551, Validation Loss: 0.4785
	--> Epoch [12/100], Loss: 0.3918, Validation Loss: 0.4628
	--> Epoch [13/100], Loss: 0.3606, Validation Loss: 0.4521
	--> Epoch [14/100], Loss: 0.3533, Validation Loss: 0.4422
	--> Epoch [15/100], Loss: 0.3752, Validation Loss: 0.4344
	--> Epoch [16/100], Loss: 0.2595, Validation Loss: 0.4242
	--> Epoch [17/100], Loss: 0.2987, Validation Loss: 0.4182
	--> Epoch [18/100], Loss: 0.2443, Validation Loss: 0.4099
	--> Epoch [19/100], Loss: 0.2534, Validation Loss: 0.4022
	--> Epoch [20/100], Loss: 0.1604, Validation Loss: 0.3934
	--> Epoch [21/100], Loss: 0.2679, Validation Loss: 0.3867
	--> Epoch [22/100], Loss: 0.2119, Validation Loss: 0.3828
	--> Epoch [23/100], Loss: 0.2487, Validation Loss: 0.3774
	--> Epoch [24/100], Loss: 0.2039, Validation Loss: 0.3721
	--> Epoch [25/100], Loss: 0.1659, Validation Loss: 0.3664
	--> Epoch [26/100], Loss: 0.2151, Validation Loss: 0.3611
	--> Epoch [27/100], Loss: 0.1025, Validation Loss: 0.3548
	--> Epoch [28/100], Loss: 0.2362, Validation Loss: 0.3534
	--> Epoch [29/100], Loss: 0.1109, Validation Loss: 0.3503
	--> Epoch [30/100], Loss: 0.1664, Validation Loss: 0.3477
	--> Epoch [31/100], Loss: 0.2135, Validation Loss: 0.3443
	--> Epoch [32/100], Loss: 0.1899, Validation Loss: 0.3405
	--> Epoch [33/100], Loss: 0.0955, Validation Loss: 0.3383
	--> Epoch [34/100], Loss: 0.1898, Validation Loss: 0.3340
	--> Epoch [35/100], Loss: 0.0735, Validation Loss: 0.3302
	--> Epoch [36/100], Loss: 0.0834, Validation Loss: 0.3270
	--> Epoch [37/100], Loss: 0.1245, Validation Loss: 0.3254
	--> Epoch [38/100], Loss: 0.1067, Validation Loss: 0.3223
	--> Epoch [39/100], Loss: 0.1627, Validation Loss: 0.3192
	--> Epoch [40/100], Loss: 0.1683, Validation Loss: 0.3156
	--> Epoch [41/100], Loss: 0.0984, Validation Loss: 0.3140
	--> Epoch [42/100], Loss: 0.1975, Validation Loss: 0.3124
	--> Epoch [43/100], Loss: 0.1379, Validation Loss: 0.3095
	--> Epoch [44/100], Loss: 0.1579, Validation Loss: 0.3072
	--> Epoch [45/100], Loss: 0.1443, Validation Loss: 0.3039
	--> Epoch [46/100], Loss: 0.0620, Validation Loss: 0.3034
	--> Epoch [47/100], Loss: 0.1138, Validation Loss: 0.3021
	--> Epoch [48/100], Loss: 0.1211, Validation Loss: 0.2994
	--> Epoch [49/100], Loss: 0.1237, Validation Loss: 0.2982
	--> Epoch [50/100], Loss: 0.0669, Validation Loss: 0.2950
	--> Epoch [51/100], Loss: 0.1657, Validation Loss: 0.2940
	--> Epoch [52/100], Loss: 0.1332, Validation Loss: 0.2933
	--> Epoch [53/100], Loss: 0.0897, Validation Loss: 0.2899
	--> Epoch [54/100], Loss: 0.1012, Validation Loss: 0.2886
	--> Epoch [55/100], Loss: 0.0886, Validation Loss: 0.2863
	--> Epoch [56/100], Loss: 0.1110, Validation Loss: 0.2833
	--> Epoch [57/100], Loss: 0.1146, Validation Loss: 0.2810
	--> Epoch [58/100], Loss: 0.0446, Validation Loss: 0.2820
	--> Epoch [59/100], Loss: 0.0767, Validation Loss: 0.2802
	--> Epoch [60/100], Loss: 0.1030, Validation Loss: 0.2790
	--> Epoch [61/100], Loss: 0.0323, Validation Loss: 0.2772
	--> Epoch [62/100], Loss: 0.1005, Validation Loss: 0.2749
	--> Epoch [63/100], Loss: 0.0380, Validation Loss: 0.2773
	--> Epoch [64/100], Loss: 0.0316, Validation Loss: 0.2748
	--> Epoch [65/100], Loss: 0.0244, Validation Loss: 0.2750
	--> Epoch [66/100], Loss: 0.1530, Validation Loss: 0.2748
	--> Epoch [67/100], Loss: 0.0679, Validation Loss: 0.2761
Early stopping
	--> Training for Fold 1 took 0.5530657768249512 sec, using 67 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8182, Validation Loss: 0.7051
	--> Epoch [2/100], Loss: 0.8039, Validation Loss: 0.6736
	--> Epoch [3/100], Loss: 0.6778, Validation Loss: 0.6480
	--> Epoch [4/100], Loss: 0.6791, Validation Loss: 0.6162
	--> Epoch [5/100], Loss: 0.5870, Validation Loss: 0.5894
	--> Epoch [6/100], Loss: 0.6146, Validation Loss: 0.5692
	--> Epoch [7/100], Loss: 0.5761, Validation Loss: 0.5503
	--> Epoch [8/100], Loss: 0.5543, Validation Loss: 0.5300
	--> Epoch [9/100], Loss: 0.5797, Validation Loss: 0.5158
	--> Epoch [10/100], Loss: 0.4148, Validation Loss: 0.5030
	--> Epoch [11/100], Loss: 0.4523, Validation Loss: 0.4913
	--> Epoch [12/100], Loss: 0.4520, Validation Loss: 0.4765
	--> Epoch [13/100], Loss: 0.3949, Validation Loss: 0.4658
	--> Epoch [14/100], Loss: 0.3400, Validation Loss: 0.4522
	--> Epoch [15/100], Loss: 0.2923, Validation Loss: 0.4435
	--> Epoch [16/100], Loss: 0.3345, Validation Loss: 0.4305
	--> Epoch [17/100], Loss: 0.2598, Validation Loss: 0.4201
	--> Epoch [18/100], Loss: 0.2623, Validation Loss: 0.4117
	--> Epoch [19/100], Loss: 0.2801, Validation Loss: 0.4002
	--> Epoch [20/100], Loss: 0.2400, Validation Loss: 0.3932
	--> Epoch [21/100], Loss: 0.2710, Validation Loss: 0.3835
	--> Epoch [22/100], Loss: 0.2019, Validation Loss: 0.3745
	--> Epoch [23/100], Loss: 0.1896, Validation Loss: 0.3646
	--> Epoch [24/100], Loss: 0.2317, Validation Loss: 0.3582
	--> Epoch [25/100], Loss: 0.2701, Validation Loss: 0.3500
	--> Epoch [26/100], Loss: 0.2217, Validation Loss: 0.3440
	--> Epoch [27/100], Loss: 0.2478, Validation Loss: 0.3400
	--> Epoch [28/100], Loss: 0.1960, Validation Loss: 0.3343
	--> Epoch [29/100], Loss: 0.1519, Validation Loss: 0.3293
	--> Epoch [30/100], Loss: 0.2434, Validation Loss: 0.3247
	--> Epoch [31/100], Loss: 0.1375, Validation Loss: 0.3192
	--> Epoch [32/100], Loss: 0.1437, Validation Loss: 0.3142
	--> Epoch [33/100], Loss: 0.1608, Validation Loss: 0.3105
	--> Epoch [34/100], Loss: 0.1754, Validation Loss: 0.3048
	--> Epoch [35/100], Loss: 0.2268, Validation Loss: 0.3015
	--> Epoch [36/100], Loss: 0.1661, Validation Loss: 0.2959
	--> Epoch [37/100], Loss: 0.1637, Validation Loss: 0.2931
	--> Epoch [38/100], Loss: 0.1954, Validation Loss: 0.2920
	--> Epoch [39/100], Loss: 0.1591, Validation Loss: 0.2879
	--> Epoch [40/100], Loss: 0.1430, Validation Loss: 0.2841
	--> Epoch [41/100], Loss: 0.2181, Validation Loss: 0.2829
	--> Epoch [42/100], Loss: 0.1324, Validation Loss: 0.2813
	--> Epoch [43/100], Loss: 0.2169, Validation Loss: 0.2782
	--> Epoch [44/100], Loss: 0.1933, Validation Loss: 0.2761
	--> Epoch [45/100], Loss: 0.1204, Validation Loss: 0.2729
	--> Epoch [46/100], Loss: 0.1132, Validation Loss: 0.2711
	--> Epoch [47/100], Loss: 0.1261, Validation Loss: 0.2691
	--> Epoch [48/100], Loss: 0.1256, Validation Loss: 0.2689
	--> Epoch [49/100], Loss: 0.1054, Validation Loss: 0.2673
	--> Epoch [50/100], Loss: 0.1826, Validation Loss: 0.2661
	--> Epoch [51/100], Loss: 0.1461, Validation Loss: 0.2632
	--> Epoch [52/100], Loss: 0.1299, Validation Loss: 0.2617
	--> Epoch [53/100], Loss: 0.1013, Validation Loss: 0.2602
	--> Epoch [54/100], Loss: 0.1255, Validation Loss: 0.2584
	--> Epoch [55/100], Loss: 0.1248, Validation Loss: 0.2558
	--> Epoch [56/100], Loss: 0.0920, Validation Loss: 0.2526
	--> Epoch [57/100], Loss: 0.1239, Validation Loss: 0.2502
	--> Epoch [58/100], Loss: 0.1108, Validation Loss: 0.2493
	--> Epoch [59/100], Loss: 0.2157, Validation Loss: 0.2490
	--> Epoch [60/100], Loss: 0.1125, Validation Loss: 0.2478
	--> Epoch [61/100], Loss: 0.1406, Validation Loss: 0.2461
	--> Epoch [62/100], Loss: 0.1217, Validation Loss: 0.2450
	--> Epoch [63/100], Loss: 0.2752, Validation Loss: 0.2419
	--> Epoch [64/100], Loss: 0.1818, Validation Loss: 0.2414
	--> Epoch [65/100], Loss: 0.1727, Validation Loss: 0.2407
	--> Epoch [66/100], Loss: 0.1021, Validation Loss: 0.2373
	--> Epoch [67/100], Loss: 0.1073, Validation Loss: 0.2357
	--> Epoch [68/100], Loss: 0.1727, Validation Loss: 0.2331
	--> Epoch [69/100], Loss: 0.1329, Validation Loss: 0.2286
	--> Epoch [70/100], Loss: 0.0955, Validation Loss: 0.2286
	--> Epoch [71/100], Loss: 0.1149, Validation Loss: 0.2284
	--> Epoch [72/100], Loss: 0.1957, Validation Loss: 0.2295
	--> Epoch [73/100], Loss: 0.0860, Validation Loss: 0.2293
	--> Epoch [74/100], Loss: 0.0898, Validation Loss: 0.2282
	--> Epoch [75/100], Loss: 0.0905, Validation Loss: 0.2261
	--> Epoch [76/100], Loss: 0.0945, Validation Loss: 0.2247
	--> Epoch [77/100], Loss: 0.0995, Validation Loss: 0.2231
	--> Epoch [78/100], Loss: 0.1504, Validation Loss: 0.2233
	--> Epoch [79/100], Loss: 0.1242, Validation Loss: 0.2232
	--> Epoch [80/100], Loss: 0.1010, Validation Loss: 0.2212
	--> Epoch [81/100], Loss: 0.1016, Validation Loss: 0.2207
	--> Epoch [82/100], Loss: 0.2448, Validation Loss: 0.2203
	--> Epoch [83/100], Loss: 0.1130, Validation Loss: 0.2191
	--> Epoch [84/100], Loss: 0.0837, Validation Loss: 0.2176
	--> Epoch [85/100], Loss: 0.0928, Validation Loss: 0.2161
	--> Epoch [86/100], Loss: 0.1686, Validation Loss: 0.2176
	--> Epoch [87/100], Loss: 0.0949, Validation Loss: 0.2153
	--> Epoch [88/100], Loss: 0.1535, Validation Loss: 0.2160
	--> Epoch [89/100], Loss: 0.1320, Validation Loss: 0.2167
	--> Epoch [90/100], Loss: 0.0879, Validation Loss: 0.2147
	--> Epoch [91/100], Loss: 0.0963, Validation Loss: 0.2155
	--> Epoch [92/100], Loss: 0.0986, Validation Loss: 0.2145
	--> Epoch [93/100], Loss: 0.1102, Validation Loss: 0.2144
	--> Epoch [94/100], Loss: 0.0885, Validation Loss: 0.2128
	--> Epoch [95/100], Loss: 0.0860, Validation Loss: 0.2119
	--> Epoch [96/100], Loss: 0.0859, Validation Loss: 0.2111
	--> Epoch [97/100], Loss: 0.1615, Validation Loss: 0.2100
	--> Epoch [98/100], Loss: 0.1607, Validation Loss: 0.2083
	--> Epoch [99/100], Loss: 0.0859, Validation Loss: 0.2064
	--> Epoch [100/100], Loss: 0.0873, Validation Loss: 0.2047
	--> Training for Fold 2 took 0.8731796741485596 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8424, Validation Loss: 0.6584
	--> Epoch [2/100], Loss: 0.7724, Validation Loss: 0.6475
	--> Epoch [3/100], Loss: 0.6437, Validation Loss: 0.6346
	--> Epoch [4/100], Loss: 0.6376, Validation Loss: 0.6251
	--> Epoch [5/100], Loss: 0.5962, Validation Loss: 0.6142
	--> Epoch [6/100], Loss: 0.5479, Validation Loss: 0.6063
	--> Epoch [7/100], Loss: 0.4854, Validation Loss: 0.5996
	--> Epoch [8/100], Loss: 0.5008, Validation Loss: 0.5920
	--> Epoch [9/100], Loss: 0.5251, Validation Loss: 0.5836
	--> Epoch [10/100], Loss: 0.4933, Validation Loss: 0.5742
	--> Epoch [11/100], Loss: 0.4343, Validation Loss: 0.5676
	--> Epoch [12/100], Loss: 0.4243, Validation Loss: 0.5611
	--> Epoch [13/100], Loss: 0.3255, Validation Loss: 0.5539
	--> Epoch [14/100], Loss: 0.3708, Validation Loss: 0.5470
	--> Epoch [15/100], Loss: 0.3071, Validation Loss: 0.5398
	--> Epoch [16/100], Loss: 0.3223, Validation Loss: 0.5324
	--> Epoch [17/100], Loss: 0.3086, Validation Loss: 0.5246
	--> Epoch [18/100], Loss: 0.2426, Validation Loss: 0.5155
	--> Epoch [19/100], Loss: 0.3426, Validation Loss: 0.5076
	--> Epoch [20/100], Loss: 0.2384, Validation Loss: 0.4993
	--> Epoch [21/100], Loss: 0.4144, Validation Loss: 0.4915
	--> Epoch [22/100], Loss: 0.2190, Validation Loss: 0.4818
	--> Epoch [23/100], Loss: 0.2297, Validation Loss: 0.4739
	--> Epoch [24/100], Loss: 0.2151, Validation Loss: 0.4654
	--> Epoch [25/100], Loss: 0.2941, Validation Loss: 0.4588
	--> Epoch [26/100], Loss: 0.2228, Validation Loss: 0.4525
	--> Epoch [27/100], Loss: 0.1826, Validation Loss: 0.4475
	--> Epoch [28/100], Loss: 0.1723, Validation Loss: 0.4410
	--> Epoch [29/100], Loss: 0.1872, Validation Loss: 0.4343
	--> Epoch [30/100], Loss: 0.1668, Validation Loss: 0.4287
	--> Epoch [31/100], Loss: 0.1613, Validation Loss: 0.4221
	--> Epoch [32/100], Loss: 0.2609, Validation Loss: 0.4166
	--> Epoch [33/100], Loss: 0.1770, Validation Loss: 0.4114
	--> Epoch [34/100], Loss: 0.2709, Validation Loss: 0.4100
	--> Epoch [35/100], Loss: 0.2221, Validation Loss: 0.4059
	--> Epoch [36/100], Loss: 0.1543, Validation Loss: 0.4013
	--> Epoch [37/100], Loss: 0.1598, Validation Loss: 0.3972
	--> Epoch [38/100], Loss: 0.1507, Validation Loss: 0.3927
	--> Epoch [39/100], Loss: 0.1278, Validation Loss: 0.3887
	--> Epoch [40/100], Loss: 0.1448, Validation Loss: 0.3864
	--> Epoch [41/100], Loss: 0.1619, Validation Loss: 0.3813
	--> Epoch [42/100], Loss: 0.1981, Validation Loss: 0.3788
	--> Epoch [43/100], Loss: 0.1565, Validation Loss: 0.3747
	--> Epoch [44/100], Loss: 0.2783, Validation Loss: 0.3724
	--> Epoch [45/100], Loss: 0.2163, Validation Loss: 0.3717
	--> Epoch [46/100], Loss: 0.1299, Validation Loss: 0.3697
	--> Epoch [47/100], Loss: 0.1921, Validation Loss: 0.3698
	--> Epoch [48/100], Loss: 0.1881, Validation Loss: 0.3666
	--> Epoch [49/100], Loss: 0.2048, Validation Loss: 0.3645
	--> Epoch [50/100], Loss: 0.1024, Validation Loss: 0.3634
	--> Epoch [51/100], Loss: 0.1124, Validation Loss: 0.3615
	--> Epoch [52/100], Loss: 0.2164, Validation Loss: 0.3617
	--> Epoch [53/100], Loss: 0.1102, Validation Loss: 0.3610
	--> Epoch [54/100], Loss: 0.1254, Validation Loss: 0.3575
	--> Epoch [55/100], Loss: 0.1370, Validation Loss: 0.3567
	--> Epoch [56/100], Loss: 0.1534, Validation Loss: 0.3556
	--> Epoch [57/100], Loss: 0.1065, Validation Loss: 0.3538
	--> Epoch [58/100], Loss: 0.1088, Validation Loss: 0.3523
	--> Epoch [59/100], Loss: 0.2232, Validation Loss: 0.3527
	--> Epoch [60/100], Loss: 0.1196, Validation Loss: 0.3498
	--> Epoch [61/100], Loss: 0.1933, Validation Loss: 0.3479
	--> Epoch [62/100], Loss: 0.1244, Validation Loss: 0.3489
	--> Epoch [63/100], Loss: 0.0971, Validation Loss: 0.3462
	--> Epoch [64/100], Loss: 0.1031, Validation Loss: 0.3451
	--> Epoch [65/100], Loss: 0.1135, Validation Loss: 0.3440
	--> Epoch [66/100], Loss: 0.2050, Validation Loss: 0.3425
	--> Epoch [67/100], Loss: 0.1817, Validation Loss: 0.3408
	--> Epoch [68/100], Loss: 0.3298, Validation Loss: 0.3395
	--> Epoch [69/100], Loss: 0.1943, Validation Loss: 0.3393
	--> Epoch [70/100], Loss: 0.1532, Validation Loss: 0.3390
	--> Epoch [71/100], Loss: 0.0982, Validation Loss: 0.3372
	--> Epoch [72/100], Loss: 0.2308, Validation Loss: 0.3371
	--> Epoch [73/100], Loss: 0.2020, Validation Loss: 0.3351
	--> Epoch [74/100], Loss: 0.0987, Validation Loss: 0.3349
	--> Epoch [75/100], Loss: 0.1017, Validation Loss: 0.3331
	--> Epoch [76/100], Loss: 0.0971, Validation Loss: 0.3321
	--> Epoch [77/100], Loss: 0.0931, Validation Loss: 0.3309
	--> Epoch [78/100], Loss: 0.0931, Validation Loss: 0.3312
	--> Epoch [79/100], Loss: 0.1251, Validation Loss: 0.3330
	--> Epoch [80/100], Loss: 0.1842, Validation Loss: 0.3329
Early stopping
	--> Training for Fold 3 took 0.6993832588195801 sec, using 80 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6314, Validation Loss: 0.5790
	--> Epoch [2/100], Loss: 0.7354, Validation Loss: 0.5613
	--> Epoch [3/100], Loss: 0.5821, Validation Loss: 0.5445
	--> Epoch [4/100], Loss: 0.6508, Validation Loss: 0.5227
	--> Epoch [5/100], Loss: 0.5700, Validation Loss: 0.5096
	--> Epoch [6/100], Loss: 0.5142, Validation Loss: 0.4942
	--> Epoch [7/100], Loss: 0.4702, Validation Loss: 0.4899
	--> Epoch [8/100], Loss: 0.4976, Validation Loss: 0.4798
	--> Epoch [9/100], Loss: 0.5128, Validation Loss: 0.4720
	--> Epoch [10/100], Loss: 0.5562, Validation Loss: 0.4651
	--> Epoch [11/100], Loss: 0.4111, Validation Loss: 0.4568
	--> Epoch [12/100], Loss: 0.3597, Validation Loss: 0.4556
	--> Epoch [13/100], Loss: 0.3848, Validation Loss: 0.4495
	--> Epoch [14/100], Loss: 0.3293, Validation Loss: 0.4423
	--> Epoch [15/100], Loss: 0.4281, Validation Loss: 0.4376
	--> Epoch [16/100], Loss: 0.3408, Validation Loss: 0.4298
	--> Epoch [17/100], Loss: 0.4354, Validation Loss: 0.4252
	--> Epoch [18/100], Loss: 0.2498, Validation Loss: 0.4189
	--> Epoch [19/100], Loss: 0.2589, Validation Loss: 0.4182
	--> Epoch [20/100], Loss: 0.2700, Validation Loss: 0.4148
	--> Epoch [21/100], Loss: 0.2599, Validation Loss: 0.4082
	--> Epoch [22/100], Loss: 0.2516, Validation Loss: 0.4040
	--> Epoch [23/100], Loss: 0.2393, Validation Loss: 0.3985
	--> Epoch [24/100], Loss: 0.2014, Validation Loss: 0.3936
	--> Epoch [25/100], Loss: 0.2296, Validation Loss: 0.3875
	--> Epoch [26/100], Loss: 0.1721, Validation Loss: 0.3829
	--> Epoch [27/100], Loss: 0.2409, Validation Loss: 0.3796
	--> Epoch [28/100], Loss: 0.1741, Validation Loss: 0.3746
	--> Epoch [29/100], Loss: 0.2391, Validation Loss: 0.3723
	--> Epoch [30/100], Loss: 0.1211, Validation Loss: 0.3714
	--> Epoch [31/100], Loss: 0.1650, Validation Loss: 0.3690
	--> Epoch [32/100], Loss: 0.0931, Validation Loss: 0.3680
	--> Epoch [33/100], Loss: 0.1885, Validation Loss: 0.3665
	--> Epoch [34/100], Loss: 0.1656, Validation Loss: 0.3643
	--> Epoch [35/100], Loss: 0.0822, Validation Loss: 0.3592
	--> Epoch [36/100], Loss: 0.0719, Validation Loss: 0.3621
	--> Epoch [37/100], Loss: 0.0992, Validation Loss: 0.3614
	--> Epoch [38/100], Loss: 0.1142, Validation Loss: 0.3590
	--> Epoch [39/100], Loss: 0.0825, Validation Loss: 0.3548
	--> Epoch [40/100], Loss: 0.0674, Validation Loss: 0.3530
	--> Epoch [41/100], Loss: 0.0802, Validation Loss: 0.3504
	--> Epoch [42/100], Loss: 0.0939, Validation Loss: 0.3509
	--> Epoch [43/100], Loss: 0.1406, Validation Loss: 0.3498
	--> Epoch [44/100], Loss: 0.1798, Validation Loss: 0.3491
	--> Epoch [45/100], Loss: 0.0519, Validation Loss: 0.3482
	--> Epoch [46/100], Loss: 0.0547, Validation Loss: 0.3486
	--> Epoch [47/100], Loss: 0.0526, Validation Loss: 0.3515
	--> Epoch [48/100], Loss: 0.0435, Validation Loss: 0.3490
Early stopping
	--> Training for Fold 4 took 0.3853421211242676 sec, using 48 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5484, Validation Loss: 0.7327
	--> Epoch [2/100], Loss: 0.5930, Validation Loss: 0.7167
	--> Epoch [3/100], Loss: 0.5395, Validation Loss: 0.7028
	--> Epoch [4/100], Loss: 0.4405, Validation Loss: 0.6900
	--> Epoch [5/100], Loss: 0.4327, Validation Loss: 0.6774
	--> Epoch [6/100], Loss: 0.4558, Validation Loss: 0.6648
	--> Epoch [7/100], Loss: 0.4612, Validation Loss: 0.6518
	--> Epoch [8/100], Loss: 0.3965, Validation Loss: 0.6403
	--> Epoch [9/100], Loss: 0.3503, Validation Loss: 0.6340
	--> Epoch [10/100], Loss: 0.3151, Validation Loss: 0.6265
	--> Epoch [11/100], Loss: 0.3683, Validation Loss: 0.6196
	--> Epoch [12/100], Loss: 0.3289, Validation Loss: 0.6143
	--> Epoch [13/100], Loss: 0.2520, Validation Loss: 0.6066
	--> Epoch [14/100], Loss: 0.2522, Validation Loss: 0.6019
	--> Epoch [15/100], Loss: 0.2895, Validation Loss: 0.5959
	--> Epoch [16/100], Loss: 0.2420, Validation Loss: 0.5887
	--> Epoch [17/100], Loss: 0.1777, Validation Loss: 0.5826
	--> Epoch [18/100], Loss: 0.1569, Validation Loss: 0.5795
	--> Epoch [19/100], Loss: 0.1984, Validation Loss: 0.5752
	--> Epoch [20/100], Loss: 0.1524, Validation Loss: 0.5739
	--> Epoch [21/100], Loss: 0.1931, Validation Loss: 0.5734
	--> Epoch [22/100], Loss: 0.1883, Validation Loss: 0.5707
	--> Epoch [23/100], Loss: 0.1494, Validation Loss: 0.5691
	--> Epoch [24/100], Loss: 0.1887, Validation Loss: 0.5655
	--> Epoch [25/100], Loss: 0.1893, Validation Loss: 0.5648
	--> Epoch [26/100], Loss: 0.1380, Validation Loss: 0.5653
	--> Epoch [27/100], Loss: 0.1258, Validation Loss: 0.5652
	--> Epoch [28/100], Loss: 0.0968, Validation Loss: 0.5655
Early stopping
	--> Training for Fold 5 took 0.26035165786743164 sec, using 28 epochs

Median number of epochs used: 67 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/67], Loss: 0.7801
	--> Final training Epoch [2/67], Loss: 0.6916
	--> Final training Epoch [3/67], Loss: 0.6466
	--> Final training Epoch [4/67], Loss: 0.6215
	--> Final training Epoch [5/67], Loss: 0.6183
	--> Final training Epoch [6/67], Loss: 0.5751
	--> Final training Epoch [7/67], Loss: 0.5451
	--> Final training Epoch [8/67], Loss: 0.4671
	--> Final training Epoch [9/67], Loss: 0.4808
	--> Final training Epoch [10/67], Loss: 0.4996
	--> Final training Epoch [11/67], Loss: 0.4689
	--> Final training Epoch [12/67], Loss: 0.4790
	--> Final training Epoch [13/67], Loss: 0.3971
	--> Final training Epoch [14/67], Loss: 0.3663
	--> Final training Epoch [15/67], Loss: 0.3506
	--> Final training Epoch [16/67], Loss: 0.3300
	--> Final training Epoch [17/67], Loss: 0.3124
	--> Final training Epoch [18/67], Loss: 0.3778
	--> Final training Epoch [19/67], Loss: 0.3229
	--> Final training Epoch [20/67], Loss: 0.3417
	--> Final training Epoch [21/67], Loss: 0.3096
	--> Final training Epoch [22/67], Loss: 0.2660
	--> Final training Epoch [23/67], Loss: 0.2521
	--> Final training Epoch [24/67], Loss: 0.2200
	--> Final training Epoch [25/67], Loss: 0.3086
	--> Final training Epoch [26/67], Loss: 0.2219
	--> Final training Epoch [27/67], Loss: 0.2237
	--> Final training Epoch [28/67], Loss: 0.2252
	--> Final training Epoch [29/67], Loss: 0.2118
	--> Final training Epoch [30/67], Loss: 0.2060
	--> Final training Epoch [31/67], Loss: 0.2264
	--> Final training Epoch [32/67], Loss: 0.1846
	--> Final training Epoch [33/67], Loss: 0.1873
	--> Final training Epoch [34/67], Loss: 0.1746
	--> Final training Epoch [35/67], Loss: 0.1924
	--> Final training Epoch [36/67], Loss: 0.1646
	--> Final training Epoch [37/67], Loss: 0.1523
	--> Final training Epoch [38/67], Loss: 0.1446
	--> Final training Epoch [39/67], Loss: 0.0927
	--> Final training Epoch [40/67], Loss: 0.1529
	--> Final training Epoch [41/67], Loss: 0.1492
	--> Final training Epoch [42/67], Loss: 0.1198
	--> Final training Epoch [43/67], Loss: 0.1501
	--> Final training Epoch [44/67], Loss: 0.1337
	--> Final training Epoch [45/67], Loss: 0.0964
	--> Final training Epoch [46/67], Loss: 0.1124
	--> Final training Epoch [47/67], Loss: 0.1012
	--> Final training Epoch [48/67], Loss: 0.1398
	--> Final training Epoch [49/67], Loss: 0.0966
	--> Final training Epoch [50/67], Loss: 0.1492
	--> Final training Epoch [51/67], Loss: 0.1164
	--> Final training Epoch [52/67], Loss: 0.1147
	--> Final training Epoch [53/67], Loss: 0.0748
	--> Final training Epoch [54/67], Loss: 0.0674
	--> Final training Epoch [55/67], Loss: 0.1014
	--> Final training Epoch [56/67], Loss: 0.0585
	--> Final training Epoch [57/67], Loss: 0.1175
	--> Final training Epoch [58/67], Loss: 0.1216
	--> Final training Epoch [59/67], Loss: 0.0742
	--> Final training Epoch [60/67], Loss: 0.0547
	--> Final training Epoch [61/67], Loss: 0.0798
	--> Final training Epoch [62/67], Loss: 0.0616
	--> Final training Epoch [63/67], Loss: 0.0573
	--> Final training Epoch [64/67], Loss: 0.0742
	--> Final training Epoch [65/67], Loss: 0.0549
	--> Final training Epoch [66/67], Loss: 0.0925
	--> Final training Epoch [67/67], Loss: 0.0547

Final training took 0.5626027584075928 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8454
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.3358,  Current Best Accuracy: 0.8152,  Current Best Validation Loss: 0.3358

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.9453, Validation Loss: 0.7726
	--> Epoch [2/100], Loss: 0.9201, Validation Loss: 0.7517
	--> Epoch [3/100], Loss: 0.8657, Validation Loss: 0.7338
	--> Epoch [4/100], Loss: 0.8093, Validation Loss: 0.7126
	--> Epoch [5/100], Loss: 0.7922, Validation Loss: 0.6944
	--> Epoch [6/100], Loss: 0.7712, Validation Loss: 0.6775
	--> Epoch [7/100], Loss: 0.6952, Validation Loss: 0.6567
	--> Epoch [8/100], Loss: 0.6430, Validation Loss: 0.6414
	--> Epoch [9/100], Loss: 0.6898, Validation Loss: 0.6273
	--> Epoch [10/100], Loss: 0.5814, Validation Loss: 0.6109
	--> Epoch [11/100], Loss: 0.6269, Validation Loss: 0.5950
	--> Epoch [12/100], Loss: 0.5539, Validation Loss: 0.5754
	--> Epoch [13/100], Loss: 0.5816, Validation Loss: 0.5584
	--> Epoch [14/100], Loss: 0.4812, Validation Loss: 0.5393
	--> Epoch [15/100], Loss: 0.4360, Validation Loss: 0.5244
	--> Epoch [16/100], Loss: 0.4893, Validation Loss: 0.5105
	--> Epoch [17/100], Loss: 0.3865, Validation Loss: 0.4949
	--> Epoch [18/100], Loss: 0.4215, Validation Loss: 0.4841
	--> Epoch [19/100], Loss: 0.3216, Validation Loss: 0.4711
	--> Epoch [20/100], Loss: 0.4290, Validation Loss: 0.4564
	--> Epoch [21/100], Loss: 0.3426, Validation Loss: 0.4431
	--> Epoch [22/100], Loss: 0.2720, Validation Loss: 0.4316
	--> Epoch [23/100], Loss: 0.2578, Validation Loss: 0.4206
	--> Epoch [24/100], Loss: 0.3525, Validation Loss: 0.4122
	--> Epoch [25/100], Loss: 0.2669, Validation Loss: 0.4011
	--> Epoch [26/100], Loss: 0.2155, Validation Loss: 0.3921
	--> Epoch [27/100], Loss: 0.1864, Validation Loss: 0.3823
	--> Epoch [28/100], Loss: 0.2304, Validation Loss: 0.3744
	--> Epoch [29/100], Loss: 0.1647, Validation Loss: 0.3647
	--> Epoch [30/100], Loss: 0.3175, Validation Loss: 0.3565
	--> Epoch [31/100], Loss: 0.2382, Validation Loss: 0.3516
	--> Epoch [32/100], Loss: 0.3162, Validation Loss: 0.3455
	--> Epoch [33/100], Loss: 0.3310, Validation Loss: 0.3397
	--> Epoch [34/100], Loss: 0.2403, Validation Loss: 0.3343
	--> Epoch [35/100], Loss: 0.1490, Validation Loss: 0.3286
	--> Epoch [36/100], Loss: 0.1677, Validation Loss: 0.3242
	--> Epoch [37/100], Loss: 0.1244, Validation Loss: 0.3183
	--> Epoch [38/100], Loss: 0.0913, Validation Loss: 0.3142
	--> Epoch [39/100], Loss: 0.1654, Validation Loss: 0.3094
	--> Epoch [40/100], Loss: 0.0971, Validation Loss: 0.3033
	--> Epoch [41/100], Loss: 0.1278, Validation Loss: 0.3000
	--> Epoch [42/100], Loss: 0.0408, Validation Loss: 0.2961
	--> Epoch [43/100], Loss: 0.1250, Validation Loss: 0.2905
	--> Epoch [44/100], Loss: 0.1799, Validation Loss: 0.2882
	--> Epoch [45/100], Loss: 0.2059, Validation Loss: 0.2832
	--> Epoch [46/100], Loss: 0.0592, Validation Loss: 0.2806
	--> Epoch [47/100], Loss: 0.0703, Validation Loss: 0.2771
	--> Epoch [48/100], Loss: 0.0611, Validation Loss: 0.2758
	--> Epoch [49/100], Loss: 0.1723, Validation Loss: 0.2734
	--> Epoch [50/100], Loss: 0.0464, Validation Loss: 0.2721
	--> Epoch [51/100], Loss: 0.1373, Validation Loss: 0.2692
	--> Epoch [52/100], Loss: 0.1243, Validation Loss: 0.2677
	--> Epoch [53/100], Loss: 0.0846, Validation Loss: 0.2645
	--> Epoch [54/100], Loss: 0.0553, Validation Loss: 0.2614
	--> Epoch [55/100], Loss: 0.0469, Validation Loss: 0.2601
	--> Epoch [56/100], Loss: 0.0737, Validation Loss: 0.2593
	--> Epoch [57/100], Loss: 0.1133, Validation Loss: 0.2565
	--> Epoch [58/100], Loss: 0.0702, Validation Loss: 0.2552
	--> Epoch [59/100], Loss: 0.0458, Validation Loss: 0.2549
	--> Epoch [60/100], Loss: 0.0373, Validation Loss: 0.2534
	--> Epoch [61/100], Loss: 0.0355, Validation Loss: 0.2512
	--> Epoch [62/100], Loss: 0.0493, Validation Loss: 0.2501
	--> Epoch [63/100], Loss: 0.0869, Validation Loss: 0.2486
	--> Epoch [64/100], Loss: 0.1051, Validation Loss: 0.2480
	--> Epoch [65/100], Loss: 0.0350, Validation Loss: 0.2465
	--> Epoch [66/100], Loss: 0.1716, Validation Loss: 0.2448
	--> Epoch [67/100], Loss: 0.1506, Validation Loss: 0.2446
	--> Epoch [68/100], Loss: 0.0195, Validation Loss: 0.2435
	--> Epoch [69/100], Loss: 0.0234, Validation Loss: 0.2425
	--> Epoch [70/100], Loss: 0.0711, Validation Loss: 0.2436
	--> Epoch [71/100], Loss: 0.0510, Validation Loss: 0.2431
	--> Epoch [72/100], Loss: 0.0129, Validation Loss: 0.2419
	--> Epoch [73/100], Loss: 0.1326, Validation Loss: 0.2407
	--> Epoch [74/100], Loss: 0.0202, Validation Loss: 0.2402
	--> Epoch [75/100], Loss: 0.1165, Validation Loss: 0.2393
	--> Epoch [76/100], Loss: 0.0409, Validation Loss: 0.2375
	--> Epoch [77/100], Loss: 0.0069, Validation Loss: 0.2365
	--> Epoch [78/100], Loss: 0.0438, Validation Loss: 0.2366
	--> Epoch [79/100], Loss: 0.1152, Validation Loss: 0.2369
	--> Epoch [80/100], Loss: 0.0554, Validation Loss: 0.2359
	--> Epoch [81/100], Loss: 0.0395, Validation Loss: 0.2363
	--> Epoch [82/100], Loss: 0.0334, Validation Loss: 0.2366
	--> Epoch [83/100], Loss: 0.0268, Validation Loss: 0.2358
	--> Epoch [84/100], Loss: 0.0527, Validation Loss: 0.2351
	--> Epoch [85/100], Loss: 0.1135, Validation Loss: 0.2358
	--> Epoch [86/100], Loss: 0.0963, Validation Loss: 0.2344
	--> Epoch [87/100], Loss: 0.1898, Validation Loss: 0.2329
	--> Epoch [88/100], Loss: 0.0186, Validation Loss: 0.2318
	--> Epoch [89/100], Loss: 0.1155, Validation Loss: 0.2291
	--> Epoch [90/100], Loss: 0.0084, Validation Loss: 0.2290
	--> Epoch [91/100], Loss: 0.0218, Validation Loss: 0.2280
	--> Epoch [92/100], Loss: 0.0250, Validation Loss: 0.2277
	--> Epoch [93/100], Loss: 0.1126, Validation Loss: 0.2279
	--> Epoch [94/100], Loss: 0.0397, Validation Loss: 0.2265
	--> Epoch [95/100], Loss: 0.0505, Validation Loss: 0.2261
	--> Epoch [96/100], Loss: 0.0440, Validation Loss: 0.2261
	--> Epoch [97/100], Loss: 0.0840, Validation Loss: 0.2246
	--> Epoch [98/100], Loss: 0.0181, Validation Loss: 0.2244
	--> Epoch [99/100], Loss: 0.0159, Validation Loss: 0.2239
	--> Epoch [100/100], Loss: 0.0214, Validation Loss: 0.2232
	--> Training for Fold 1 took 0.8204724788665771 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7713, Validation Loss: 0.6611
	--> Epoch [2/100], Loss: 0.7797, Validation Loss: 0.6356
	--> Epoch [3/100], Loss: 0.7168, Validation Loss: 0.6176
	--> Epoch [4/100], Loss: 0.6274, Validation Loss: 0.5972
	--> Epoch [5/100], Loss: 0.6101, Validation Loss: 0.5861
	--> Epoch [6/100], Loss: 0.5833, Validation Loss: 0.5758
	--> Epoch [7/100], Loss: 0.5596, Validation Loss: 0.5637
	--> Epoch [8/100], Loss: 0.5185, Validation Loss: 0.5487
	--> Epoch [9/100], Loss: 0.4527, Validation Loss: 0.5374
	--> Epoch [10/100], Loss: 0.4210, Validation Loss: 0.5280
	--> Epoch [11/100], Loss: 0.4162, Validation Loss: 0.5205
	--> Epoch [12/100], Loss: 0.4613, Validation Loss: 0.5090
	--> Epoch [13/100], Loss: 0.3624, Validation Loss: 0.4996
	--> Epoch [14/100], Loss: 0.2939, Validation Loss: 0.4892
	--> Epoch [15/100], Loss: 0.3522, Validation Loss: 0.4797
	--> Epoch [16/100], Loss: 0.3139, Validation Loss: 0.4681
	--> Epoch [17/100], Loss: 0.3199, Validation Loss: 0.4584
	--> Epoch [18/100], Loss: 0.2924, Validation Loss: 0.4478
	--> Epoch [19/100], Loss: 0.2970, Validation Loss: 0.4359
	--> Epoch [20/100], Loss: 0.2810, Validation Loss: 0.4241
	--> Epoch [21/100], Loss: 0.2473, Validation Loss: 0.4145
	--> Epoch [22/100], Loss: 0.2207, Validation Loss: 0.4060
	--> Epoch [23/100], Loss: 0.2676, Validation Loss: 0.3958
	--> Epoch [24/100], Loss: 0.2513, Validation Loss: 0.3855
	--> Epoch [25/100], Loss: 0.1300, Validation Loss: 0.3764
	--> Epoch [26/100], Loss: 0.1730, Validation Loss: 0.3680
	--> Epoch [27/100], Loss: 0.2164, Validation Loss: 0.3605
	--> Epoch [28/100], Loss: 0.1632, Validation Loss: 0.3533
	--> Epoch [29/100], Loss: 0.1867, Validation Loss: 0.3462
	--> Epoch [30/100], Loss: 0.0767, Validation Loss: 0.3398
	--> Epoch [31/100], Loss: 0.1640, Validation Loss: 0.3317
	--> Epoch [32/100], Loss: 0.0969, Validation Loss: 0.3242
	--> Epoch [33/100], Loss: 0.2154, Validation Loss: 0.3190
	--> Epoch [34/100], Loss: 0.1123, Validation Loss: 0.3114
	--> Epoch [35/100], Loss: 0.1680, Validation Loss: 0.3061
	--> Epoch [36/100], Loss: 0.1187, Validation Loss: 0.3008
	--> Epoch [37/100], Loss: 0.0704, Validation Loss: 0.2946
	--> Epoch [38/100], Loss: 0.1245, Validation Loss: 0.2923
	--> Epoch [39/100], Loss: 0.1303, Validation Loss: 0.2870
	--> Epoch [40/100], Loss: 0.1464, Validation Loss: 0.2833
	--> Epoch [41/100], Loss: 0.0485, Validation Loss: 0.2806
	--> Epoch [42/100], Loss: 0.1070, Validation Loss: 0.2758
	--> Epoch [43/100], Loss: 0.0970, Validation Loss: 0.2719
	--> Epoch [44/100], Loss: 0.1972, Validation Loss: 0.2701
	--> Epoch [45/100], Loss: 0.0642, Validation Loss: 0.2669
	--> Epoch [46/100], Loss: 0.1276, Validation Loss: 0.2637
	--> Epoch [47/100], Loss: 0.0489, Validation Loss: 0.2601
	--> Epoch [48/100], Loss: 0.1247, Validation Loss: 0.2577
	--> Epoch [49/100], Loss: 0.0367, Validation Loss: 0.2549
	--> Epoch [50/100], Loss: 0.0435, Validation Loss: 0.2529
	--> Epoch [51/100], Loss: 0.0349, Validation Loss: 0.2506
	--> Epoch [52/100], Loss: 0.1585, Validation Loss: 0.2512
	--> Epoch [53/100], Loss: 0.0431, Validation Loss: 0.2481
	--> Epoch [54/100], Loss: 0.1313, Validation Loss: 0.2436
	--> Epoch [55/100], Loss: 0.0423, Validation Loss: 0.2417
	--> Epoch [56/100], Loss: 0.0381, Validation Loss: 0.2409
	--> Epoch [57/100], Loss: 0.0574, Validation Loss: 0.2409
	--> Epoch [58/100], Loss: 0.0245, Validation Loss: 0.2391
	--> Epoch [59/100], Loss: 0.0479, Validation Loss: 0.2386
	--> Epoch [60/100], Loss: 0.0985, Validation Loss: 0.2388
	--> Epoch [61/100], Loss: 0.0228, Validation Loss: 0.2375
	--> Epoch [62/100], Loss: 0.1100, Validation Loss: 0.2352
	--> Epoch [63/100], Loss: 0.0227, Validation Loss: 0.2345
	--> Epoch [64/100], Loss: 0.0161, Validation Loss: 0.2329
	--> Epoch [65/100], Loss: 0.0148, Validation Loss: 0.2299
	--> Epoch [66/100], Loss: 0.0986, Validation Loss: 0.2291
	--> Epoch [67/100], Loss: 0.0269, Validation Loss: 0.2278
	--> Epoch [68/100], Loss: 0.0114, Validation Loss: 0.2258
	--> Epoch [69/100], Loss: 0.0976, Validation Loss: 0.2235
	--> Epoch [70/100], Loss: 0.1098, Validation Loss: 0.2204
	--> Epoch [71/100], Loss: 0.0801, Validation Loss: 0.2195
	--> Epoch [72/100], Loss: 0.0679, Validation Loss: 0.2171
	--> Epoch [73/100], Loss: 0.0159, Validation Loss: 0.2156
	--> Epoch [74/100], Loss: 0.1062, Validation Loss: 0.2168
	--> Epoch [75/100], Loss: 0.1075, Validation Loss: 0.2156
	--> Epoch [76/100], Loss: 0.1351, Validation Loss: 0.2156
	--> Epoch [77/100], Loss: 0.1101, Validation Loss: 0.2156
	--> Epoch [78/100], Loss: 0.0176, Validation Loss: 0.2145
	--> Epoch [79/100], Loss: 0.0123, Validation Loss: 0.2130
	--> Epoch [80/100], Loss: 0.0177, Validation Loss: 0.2129
	--> Epoch [81/100], Loss: 0.0256, Validation Loss: 0.2116
	--> Epoch [82/100], Loss: 0.0085, Validation Loss: 0.2106
	--> Epoch [83/100], Loss: 0.1873, Validation Loss: 0.2106
	--> Epoch [84/100], Loss: 0.0112, Validation Loss: 0.2084
	--> Epoch [85/100], Loss: 0.1040, Validation Loss: 0.2075
	--> Epoch [86/100], Loss: 0.0110, Validation Loss: 0.2075
	--> Epoch [87/100], Loss: 0.0319, Validation Loss: 0.2069
	--> Epoch [88/100], Loss: 0.0310, Validation Loss: 0.2056
	--> Epoch [89/100], Loss: 0.1008, Validation Loss: 0.2040
	--> Epoch [90/100], Loss: 0.0683, Validation Loss: 0.2031
	--> Epoch [91/100], Loss: 0.0924, Validation Loss: 0.2026
	--> Epoch [92/100], Loss: 0.1149, Validation Loss: 0.2021
	--> Epoch [93/100], Loss: 0.0124, Validation Loss: 0.2012
	--> Epoch [94/100], Loss: 0.0254, Validation Loss: 0.2005
	--> Epoch [95/100], Loss: 0.0083, Validation Loss: 0.2001
	--> Epoch [96/100], Loss: 0.0150, Validation Loss: 0.2010
	--> Epoch [97/100], Loss: 0.0918, Validation Loss: 0.1971
	--> Epoch [98/100], Loss: 0.0907, Validation Loss: 0.1955
	--> Epoch [99/100], Loss: 0.0069, Validation Loss: 0.1945
	--> Epoch [100/100], Loss: 0.0110, Validation Loss: 0.1945
	--> Training for Fold 2 took 0.831472635269165 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6766, Validation Loss: 0.7460
	--> Epoch [2/100], Loss: 0.5916, Validation Loss: 0.7276
	--> Epoch [3/100], Loss: 0.5786, Validation Loss: 0.7109
	--> Epoch [4/100], Loss: 0.5094, Validation Loss: 0.6931
	--> Epoch [5/100], Loss: 0.4730, Validation Loss: 0.6843
	--> Epoch [6/100], Loss: 0.4637, Validation Loss: 0.6744
	--> Epoch [7/100], Loss: 0.4177, Validation Loss: 0.6637
	--> Epoch [8/100], Loss: 0.4013, Validation Loss: 0.6556
	--> Epoch [9/100], Loss: 0.4556, Validation Loss: 0.6472
	--> Epoch [10/100], Loss: 0.4027, Validation Loss: 0.6380
	--> Epoch [11/100], Loss: 0.4334, Validation Loss: 0.6300
	--> Epoch [12/100], Loss: 0.3328, Validation Loss: 0.6183
	--> Epoch [13/100], Loss: 0.3373, Validation Loss: 0.6082
	--> Epoch [14/100], Loss: 0.3881, Validation Loss: 0.5993
	--> Epoch [15/100], Loss: 0.2174, Validation Loss: 0.5932
	--> Epoch [16/100], Loss: 0.2485, Validation Loss: 0.5866
	--> Epoch [17/100], Loss: 0.2634, Validation Loss: 0.5824
	--> Epoch [18/100], Loss: 0.1740, Validation Loss: 0.5761
	--> Epoch [19/100], Loss: 0.2254, Validation Loss: 0.5692
	--> Epoch [20/100], Loss: 0.2031, Validation Loss: 0.5642
	--> Epoch [21/100], Loss: 0.1775, Validation Loss: 0.5580
	--> Epoch [22/100], Loss: 0.1592, Validation Loss: 0.5521
	--> Epoch [23/100], Loss: 0.1468, Validation Loss: 0.5485
	--> Epoch [24/100], Loss: 0.1900, Validation Loss: 0.5437
	--> Epoch [25/100], Loss: 0.1315, Validation Loss: 0.5404
	--> Epoch [26/100], Loss: 0.0792, Validation Loss: 0.5350
	--> Epoch [27/100], Loss: 0.0567, Validation Loss: 0.5262
	--> Epoch [28/100], Loss: 0.0803, Validation Loss: 0.5214
	--> Epoch [29/100], Loss: 0.1036, Validation Loss: 0.5186
	--> Epoch [30/100], Loss: 0.0871, Validation Loss: 0.5131
	--> Epoch [31/100], Loss: 0.1200, Validation Loss: 0.5090
	--> Epoch [32/100], Loss: 0.0825, Validation Loss: 0.5034
	--> Epoch [33/100], Loss: 0.0538, Validation Loss: 0.4979
	--> Epoch [34/100], Loss: 0.1387, Validation Loss: 0.4948
	--> Epoch [35/100], Loss: 0.0480, Validation Loss: 0.4926
	--> Epoch [36/100], Loss: 0.0611, Validation Loss: 0.4882
	--> Epoch [37/100], Loss: 0.0996, Validation Loss: 0.4849
	--> Epoch [38/100], Loss: 0.0338, Validation Loss: 0.4791
	--> Epoch [39/100], Loss: 0.1489, Validation Loss: 0.4775
	--> Epoch [40/100], Loss: 0.0739, Validation Loss: 0.4734
	--> Epoch [41/100], Loss: 0.0324, Validation Loss: 0.4709
	--> Epoch [42/100], Loss: 0.0610, Validation Loss: 0.4659
	--> Epoch [43/100], Loss: 0.0659, Validation Loss: 0.4636
	--> Epoch [44/100], Loss: 0.0588, Validation Loss: 0.4616
	--> Epoch [45/100], Loss: 0.0316, Validation Loss: 0.4595
	--> Epoch [46/100], Loss: 0.0502, Validation Loss: 0.4578
	--> Epoch [47/100], Loss: 0.0649, Validation Loss: 0.4562
	--> Epoch [48/100], Loss: 0.0904, Validation Loss: 0.4540
	--> Epoch [49/100], Loss: 0.0388, Validation Loss: 0.4510
	--> Epoch [50/100], Loss: 0.0477, Validation Loss: 0.4479
	--> Epoch [51/100], Loss: 0.0948, Validation Loss: 0.4475
	--> Epoch [52/100], Loss: 0.0176, Validation Loss: 0.4451
	--> Epoch [53/100], Loss: 0.1233, Validation Loss: 0.4428
	--> Epoch [54/100], Loss: 0.0149, Validation Loss: 0.4426
	--> Epoch [55/100], Loss: 0.0347, Validation Loss: 0.4418
	--> Epoch [56/100], Loss: 0.0339, Validation Loss: 0.4377
	--> Epoch [57/100], Loss: 0.0448, Validation Loss: 0.4360
	--> Epoch [58/100], Loss: 0.0832, Validation Loss: 0.4369
	--> Epoch [59/100], Loss: 0.0292, Validation Loss: 0.4347
	--> Epoch [60/100], Loss: 0.0834, Validation Loss: 0.4335
	--> Epoch [61/100], Loss: 0.0118, Validation Loss: 0.4325
	--> Epoch [62/100], Loss: 0.0252, Validation Loss: 0.4318
	--> Epoch [63/100], Loss: 0.0218, Validation Loss: 0.4313
	--> Epoch [64/100], Loss: 0.0278, Validation Loss: 0.4295
	--> Epoch [65/100], Loss: 0.0088, Validation Loss: 0.4275
	--> Epoch [66/100], Loss: 0.1750, Validation Loss: 0.4275
	--> Epoch [67/100], Loss: 0.1084, Validation Loss: 0.4275
	--> Epoch [68/100], Loss: 0.0122, Validation Loss: 0.4249
	--> Epoch [69/100], Loss: 0.0197, Validation Loss: 0.4252
	--> Epoch [70/100], Loss: 0.0264, Validation Loss: 0.4241
	--> Epoch [71/100], Loss: 0.0311, Validation Loss: 0.4248
	--> Epoch [72/100], Loss: 0.0056, Validation Loss: 0.4247
	--> Epoch [73/100], Loss: 0.0522, Validation Loss: 0.4215
	--> Epoch [74/100], Loss: 0.0329, Validation Loss: 0.4213
	--> Epoch [75/100], Loss: 0.0167, Validation Loss: 0.4184
	--> Epoch [76/100], Loss: 0.0190, Validation Loss: 0.4179
	--> Epoch [77/100], Loss: 0.0236, Validation Loss: 0.4147
	--> Epoch [78/100], Loss: 0.0120, Validation Loss: 0.4144
	--> Epoch [79/100], Loss: 0.0152, Validation Loss: 0.4130
	--> Epoch [80/100], Loss: 0.0319, Validation Loss: 0.4135
	--> Epoch [81/100], Loss: 0.0127, Validation Loss: 0.4122
	--> Epoch [82/100], Loss: 0.0669, Validation Loss: 0.4120
	--> Epoch [83/100], Loss: 0.0445, Validation Loss: 0.4114
	--> Epoch [84/100], Loss: 0.0066, Validation Loss: 0.4087
	--> Epoch [85/100], Loss: 0.0178, Validation Loss: 0.4081
	--> Epoch [86/100], Loss: 0.0290, Validation Loss: 0.4103
	--> Epoch [87/100], Loss: 0.0107, Validation Loss: 0.4088
	--> Epoch [88/100], Loss: 0.0204, Validation Loss: 0.4081
Early stopping
	--> Training for Fold 3 took 0.7091405391693115 sec, using 88 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6713, Validation Loss: 0.7606
	--> Epoch [2/100], Loss: 0.5704, Validation Loss: 0.7384
	--> Epoch [3/100], Loss: 0.5749, Validation Loss: 0.7188
	--> Epoch [4/100], Loss: 0.5169, Validation Loss: 0.6991
	--> Epoch [5/100], Loss: 0.5103, Validation Loss: 0.6825
	--> Epoch [6/100], Loss: 0.4751, Validation Loss: 0.6668
	--> Epoch [7/100], Loss: 0.4261, Validation Loss: 0.6451
	--> Epoch [8/100], Loss: 0.4793, Validation Loss: 0.6302
	--> Epoch [9/100], Loss: 0.4387, Validation Loss: 0.6139
	--> Epoch [10/100], Loss: 0.3776, Validation Loss: 0.5946
	--> Epoch [11/100], Loss: 0.4324, Validation Loss: 0.5731
	--> Epoch [12/100], Loss: 0.2807, Validation Loss: 0.5500
	--> Epoch [13/100], Loss: 0.3057, Validation Loss: 0.5323
	--> Epoch [14/100], Loss: 0.2449, Validation Loss: 0.5174
	--> Epoch [15/100], Loss: 0.2275, Validation Loss: 0.5046
	--> Epoch [16/100], Loss: 0.3554, Validation Loss: 0.4882
	--> Epoch [17/100], Loss: 0.2295, Validation Loss: 0.4754
	--> Epoch [18/100], Loss: 0.2049, Validation Loss: 0.4615
	--> Epoch [19/100], Loss: 0.1369, Validation Loss: 0.4498
	--> Epoch [20/100], Loss: 0.2521, Validation Loss: 0.4424
	--> Epoch [21/100], Loss: 0.2364, Validation Loss: 0.4314
	--> Epoch [22/100], Loss: 0.2164, Validation Loss: 0.4277
	--> Epoch [23/100], Loss: 0.1302, Validation Loss: 0.4150
	--> Epoch [24/100], Loss: 0.2046, Validation Loss: 0.4039
	--> Epoch [25/100], Loss: 0.1720, Validation Loss: 0.3975
	--> Epoch [26/100], Loss: 0.1075, Validation Loss: 0.3916
	--> Epoch [27/100], Loss: 0.1262, Validation Loss: 0.3880
	--> Epoch [28/100], Loss: 0.2699, Validation Loss: 0.3826
	--> Epoch [29/100], Loss: 0.2156, Validation Loss: 0.3798
	--> Epoch [30/100], Loss: 0.0912, Validation Loss: 0.3735
	--> Epoch [31/100], Loss: 0.1014, Validation Loss: 0.3716
	--> Epoch [32/100], Loss: 0.2445, Validation Loss: 0.3694
	--> Epoch [33/100], Loss: 0.1045, Validation Loss: 0.3647
	--> Epoch [34/100], Loss: 0.1892, Validation Loss: 0.3609
	--> Epoch [35/100], Loss: 0.0681, Validation Loss: 0.3550
	--> Epoch [36/100], Loss: 0.0601, Validation Loss: 0.3526
	--> Epoch [37/100], Loss: 0.1808, Validation Loss: 0.3531
	--> Epoch [38/100], Loss: 0.0500, Validation Loss: 0.3494
	--> Epoch [39/100], Loss: 0.0451, Validation Loss: 0.3475
	--> Epoch [40/100], Loss: 0.0491, Validation Loss: 0.3453
	--> Epoch [41/100], Loss: 0.0961, Validation Loss: 0.3448
	--> Epoch [42/100], Loss: 0.0427, Validation Loss: 0.3414
	--> Epoch [43/100], Loss: 0.0433, Validation Loss: 0.3412
	--> Epoch [44/100], Loss: 0.0526, Validation Loss: 0.3381
	--> Epoch [45/100], Loss: 0.0358, Validation Loss: 0.3373
	--> Epoch [46/100], Loss: 0.0367, Validation Loss: 0.3362
	--> Epoch [47/100], Loss: 0.0963, Validation Loss: 0.3350
	--> Epoch [48/100], Loss: 0.0525, Validation Loss: 0.3342
	--> Epoch [49/100], Loss: 0.1490, Validation Loss: 0.3322
	--> Epoch [50/100], Loss: 0.0294, Validation Loss: 0.3298
	--> Epoch [51/100], Loss: 0.0224, Validation Loss: 0.3303
	--> Epoch [52/100], Loss: 0.0433, Validation Loss: 0.3287
	--> Epoch [53/100], Loss: 0.1088, Validation Loss: 0.3266
	--> Epoch [54/100], Loss: 0.0642, Validation Loss: 0.3244
	--> Epoch [55/100], Loss: 0.0141, Validation Loss: 0.3237
	--> Epoch [56/100], Loss: 0.0371, Validation Loss: 0.3216
	--> Epoch [57/100], Loss: 0.0690, Validation Loss: 0.3213
	--> Epoch [58/100], Loss: 0.0238, Validation Loss: 0.3216
	--> Epoch [59/100], Loss: 0.0513, Validation Loss: 0.3179
	--> Epoch [60/100], Loss: 0.0147, Validation Loss: 0.3156
	--> Epoch [61/100], Loss: 0.0076, Validation Loss: 0.3178
	--> Epoch [62/100], Loss: 0.0254, Validation Loss: 0.3191
	--> Epoch [63/100], Loss: 0.0287, Validation Loss: 0.3209
Early stopping
	--> Training for Fold 4 took 0.5101892948150635 sec, using 63 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7402, Validation Loss: 0.6761
	--> Epoch [2/100], Loss: 0.6847, Validation Loss: 0.6655
	--> Epoch [3/100], Loss: 0.6217, Validation Loss: 0.6610
	--> Epoch [4/100], Loss: 0.6162, Validation Loss: 0.6571
	--> Epoch [5/100], Loss: 0.5897, Validation Loss: 0.6510
	--> Epoch [6/100], Loss: 0.5239, Validation Loss: 0.6467
	--> Epoch [7/100], Loss: 0.4442, Validation Loss: 0.6432
	--> Epoch [8/100], Loss: 0.4706, Validation Loss: 0.6384
	--> Epoch [9/100], Loss: 0.4710, Validation Loss: 0.6331
	--> Epoch [10/100], Loss: 0.4597, Validation Loss: 0.6297
	--> Epoch [11/100], Loss: 0.3674, Validation Loss: 0.6295
	--> Epoch [12/100], Loss: 0.4900, Validation Loss: 0.6305
	--> Epoch [13/100], Loss: 0.3884, Validation Loss: 0.6307
	--> Epoch [14/100], Loss: 0.3414, Validation Loss: 0.6280
	--> Epoch [15/100], Loss: 0.3468, Validation Loss: 0.6276
	--> Epoch [16/100], Loss: 0.2921, Validation Loss: 0.6276
	--> Epoch [17/100], Loss: 0.2985, Validation Loss: 0.6280
	--> Epoch [18/100], Loss: 0.3084, Validation Loss: 0.6291
	--> Epoch [19/100], Loss: 0.2272, Validation Loss: 0.6291
Early stopping
	--> Training for Fold 5 took 0.15739202499389648 sec, using 19 epochs

Median number of epochs used: 88 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/88], Loss: 0.6688
	--> Final training Epoch [2/88], Loss: 0.6423
	--> Final training Epoch [3/88], Loss: 0.6337
	--> Final training Epoch [4/88], Loss: 0.6435
	--> Final training Epoch [5/88], Loss: 0.5940
	--> Final training Epoch [6/88], Loss: 0.5525
	--> Final training Epoch [7/88], Loss: 0.5627
	--> Final training Epoch [8/88], Loss: 0.5053
	--> Final training Epoch [9/88], Loss: 0.5119
	--> Final training Epoch [10/88], Loss: 0.4767
	--> Final training Epoch [11/88], Loss: 0.4660
	--> Final training Epoch [12/88], Loss: 0.4555
	--> Final training Epoch [13/88], Loss: 0.4332
	--> Final training Epoch [14/88], Loss: 0.4218
	--> Final training Epoch [15/88], Loss: 0.4193
	--> Final training Epoch [16/88], Loss: 0.3861
	--> Final training Epoch [17/88], Loss: 0.3681
	--> Final training Epoch [18/88], Loss: 0.3488
	--> Final training Epoch [19/88], Loss: 0.3355
	--> Final training Epoch [20/88], Loss: 0.3194
	--> Final training Epoch [21/88], Loss: 0.2894
	--> Final training Epoch [22/88], Loss: 0.3251
	--> Final training Epoch [23/88], Loss: 0.2843
	--> Final training Epoch [24/88], Loss: 0.2901
	--> Final training Epoch [25/88], Loss: 0.2281
	--> Final training Epoch [26/88], Loss: 0.2837
	--> Final training Epoch [27/88], Loss: 0.2799
	--> Final training Epoch [28/88], Loss: 0.2359
	--> Final training Epoch [29/88], Loss: 0.2406
	--> Final training Epoch [30/88], Loss: 0.2351
	--> Final training Epoch [31/88], Loss: 0.2349
	--> Final training Epoch [32/88], Loss: 0.1884
	--> Final training Epoch [33/88], Loss: 0.1872
	--> Final training Epoch [34/88], Loss: 0.1842
	--> Final training Epoch [35/88], Loss: 0.1979
	--> Final training Epoch [36/88], Loss: 0.1646
	--> Final training Epoch [37/88], Loss: 0.1796
	--> Final training Epoch [38/88], Loss: 0.1554
	--> Final training Epoch [39/88], Loss: 0.1792
	--> Final training Epoch [40/88], Loss: 0.1659
	--> Final training Epoch [41/88], Loss: 0.1635
	--> Final training Epoch [42/88], Loss: 0.1492
	--> Final training Epoch [43/88], Loss: 0.1967
	--> Final training Epoch [44/88], Loss: 0.1220
	--> Final training Epoch [45/88], Loss: 0.1497
	--> Final training Epoch [46/88], Loss: 0.1206
	--> Final training Epoch [47/88], Loss: 0.1580
	--> Final training Epoch [48/88], Loss: 0.1108
	--> Final training Epoch [49/88], Loss: 0.1199
	--> Final training Epoch [50/88], Loss: 0.1140
	--> Final training Epoch [51/88], Loss: 0.1375
	--> Final training Epoch [52/88], Loss: 0.1089
	--> Final training Epoch [53/88], Loss: 0.0827
	--> Final training Epoch [54/88], Loss: 0.1203
	--> Final training Epoch [55/88], Loss: 0.0776
	--> Final training Epoch [56/88], Loss: 0.1128
	--> Final training Epoch [57/88], Loss: 0.0723
	--> Final training Epoch [58/88], Loss: 0.1306
	--> Final training Epoch [59/88], Loss: 0.1253
	--> Final training Epoch [60/88], Loss: 0.1023
	--> Final training Epoch [61/88], Loss: 0.1297
	--> Final training Epoch [62/88], Loss: 0.0539
	--> Final training Epoch [63/88], Loss: 0.1255
	--> Final training Epoch [64/88], Loss: 0.0858
	--> Final training Epoch [65/88], Loss: 0.0953
	--> Final training Epoch [66/88], Loss: 0.0731
	--> Final training Epoch [67/88], Loss: 0.0904
	--> Final training Epoch [68/88], Loss: 0.0831
	--> Final training Epoch [69/88], Loss: 0.0662
	--> Final training Epoch [70/88], Loss: 0.0603
	--> Final training Epoch [71/88], Loss: 0.0841
	--> Final training Epoch [72/88], Loss: 0.0615
	--> Final training Epoch [73/88], Loss: 0.0602
	--> Final training Epoch [74/88], Loss: 0.0657
	--> Final training Epoch [75/88], Loss: 0.0524
	--> Final training Epoch [76/88], Loss: 0.0962
	--> Final training Epoch [77/88], Loss: 0.1014
	--> Final training Epoch [78/88], Loss: 0.0740
	--> Final training Epoch [79/88], Loss: 0.0550
	--> Final training Epoch [80/88], Loss: 0.0677
	--> Final training Epoch [81/88], Loss: 0.0814
	--> Final training Epoch [82/88], Loss: 0.0845
	--> Final training Epoch [83/88], Loss: 0.0515
	--> Final training Epoch [84/88], Loss: 0.0755
	--> Final training Epoch [85/88], Loss: 0.0905
	--> Final training Epoch [86/88], Loss: 0.0696
	--> Final training Epoch [87/88], Loss: 0.0945
	--> Final training Epoch [88/88], Loss: 0.0618

Final training took 0.6989474296569824 sec

TESTING
	--> Testing took 0.0075 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0254
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3772,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3772

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6253, Validation Loss: 0.6282
	--> Epoch [2/100], Loss: 0.5499, Validation Loss: 0.6148
	--> Epoch [3/100], Loss: 0.5390, Validation Loss: 0.6032
	--> Epoch [4/100], Loss: 0.5389, Validation Loss: 0.5925
	--> Epoch [5/100], Loss: 0.5098, Validation Loss: 0.5854
	--> Epoch [6/100], Loss: 0.5094, Validation Loss: 0.5770
	--> Epoch [7/100], Loss: 0.4760, Validation Loss: 0.5690
	--> Epoch [8/100], Loss: 0.4568, Validation Loss: 0.5605
	--> Epoch [9/100], Loss: 0.4733, Validation Loss: 0.5540
	--> Epoch [10/100], Loss: 0.4257, Validation Loss: 0.5445
	--> Epoch [11/100], Loss: 0.3874, Validation Loss: 0.5348
	--> Epoch [12/100], Loss: 0.4248, Validation Loss: 0.5284
	--> Epoch [13/100], Loss: 0.4583, Validation Loss: 0.5231
	--> Epoch [14/100], Loss: 0.3619, Validation Loss: 0.5131
	--> Epoch [15/100], Loss: 0.4318, Validation Loss: 0.5075
	--> Epoch [16/100], Loss: 0.3933, Validation Loss: 0.5011
	--> Epoch [17/100], Loss: 0.3470, Validation Loss: 0.4940
	--> Epoch [18/100], Loss: 0.3683, Validation Loss: 0.4868
	--> Epoch [19/100], Loss: 0.3402, Validation Loss: 0.4802
	--> Epoch [20/100], Loss: 0.2873, Validation Loss: 0.4738
	--> Epoch [21/100], Loss: 0.2389, Validation Loss: 0.4658
	--> Epoch [22/100], Loss: 0.2814, Validation Loss: 0.4587
	--> Epoch [23/100], Loss: 0.2831, Validation Loss: 0.4527
	--> Epoch [24/100], Loss: 0.3026, Validation Loss: 0.4463
	--> Epoch [25/100], Loss: 0.2915, Validation Loss: 0.4389
	--> Epoch [26/100], Loss: 0.2291, Validation Loss: 0.4338
	--> Epoch [27/100], Loss: 0.2832, Validation Loss: 0.4292
	--> Epoch [28/100], Loss: 0.1944, Validation Loss: 0.4217
	--> Epoch [29/100], Loss: 0.2199, Validation Loss: 0.4164
	--> Epoch [30/100], Loss: 0.2366, Validation Loss: 0.4118
	--> Epoch [31/100], Loss: 0.1581, Validation Loss: 0.4039
	--> Epoch [32/100], Loss: 0.3613, Validation Loss: 0.4000
	--> Epoch [33/100], Loss: 0.1660, Validation Loss: 0.3960
	--> Epoch [34/100], Loss: 0.2797, Validation Loss: 0.3936
	--> Epoch [35/100], Loss: 0.2970, Validation Loss: 0.3917
	--> Epoch [36/100], Loss: 0.1291, Validation Loss: 0.3860
	--> Epoch [37/100], Loss: 0.1656, Validation Loss: 0.3823
	--> Epoch [38/100], Loss: 0.2490, Validation Loss: 0.3778
	--> Epoch [39/100], Loss: 0.2376, Validation Loss: 0.3770
	--> Epoch [40/100], Loss: 0.1076, Validation Loss: 0.3708
	--> Epoch [41/100], Loss: 0.2645, Validation Loss: 0.3680
	--> Epoch [42/100], Loss: 0.0955, Validation Loss: 0.3648
	--> Epoch [43/100], Loss: 0.1269, Validation Loss: 0.3607
	--> Epoch [44/100], Loss: 0.3073, Validation Loss: 0.3593
	--> Epoch [45/100], Loss: 0.0971, Validation Loss: 0.3575
	--> Epoch [46/100], Loss: 0.1924, Validation Loss: 0.3535
	--> Epoch [47/100], Loss: 0.1538, Validation Loss: 0.3519
	--> Epoch [48/100], Loss: 0.0473, Validation Loss: 0.3474
	--> Epoch [49/100], Loss: 0.2211, Validation Loss: 0.3466
	--> Epoch [50/100], Loss: 0.1981, Validation Loss: 0.3456
	--> Epoch [51/100], Loss: 0.2170, Validation Loss: 0.3441
	--> Epoch [52/100], Loss: 0.0354, Validation Loss: 0.3410
	--> Epoch [53/100], Loss: 0.1586, Validation Loss: 0.3396
	--> Epoch [54/100], Loss: 0.1000, Validation Loss: 0.3378
	--> Epoch [55/100], Loss: 0.1333, Validation Loss: 0.3365
	--> Epoch [56/100], Loss: 0.1873, Validation Loss: 0.3340
	--> Epoch [57/100], Loss: 0.0686, Validation Loss: 0.3334
	--> Epoch [58/100], Loss: 0.1185, Validation Loss: 0.3316
	--> Epoch [59/100], Loss: 0.1657, Validation Loss: 0.3293
	--> Epoch [60/100], Loss: 0.2803, Validation Loss: 0.3275
	--> Epoch [61/100], Loss: 0.0822, Validation Loss: 0.3262
	--> Epoch [62/100], Loss: 0.1480, Validation Loss: 0.3246
	--> Epoch [63/100], Loss: 0.1137, Validation Loss: 0.3227
	--> Epoch [64/100], Loss: 0.1719, Validation Loss: 0.3202
	--> Epoch [65/100], Loss: 0.2275, Validation Loss: 0.3195
	--> Epoch [66/100], Loss: 0.0785, Validation Loss: 0.3183
	--> Epoch [67/100], Loss: 0.1660, Validation Loss: 0.3178
	--> Epoch [68/100], Loss: 0.0905, Validation Loss: 0.3154
	--> Epoch [69/100], Loss: 0.2438, Validation Loss: 0.3150
	--> Epoch [70/100], Loss: 0.1550, Validation Loss: 0.3145
	--> Epoch [71/100], Loss: 0.1900, Validation Loss: 0.3138
	--> Epoch [72/100], Loss: 0.2216, Validation Loss: 0.3131
	--> Epoch [73/100], Loss: 0.1516, Validation Loss: 0.3108
	--> Epoch [74/100], Loss: 0.1552, Validation Loss: 0.3109
	--> Epoch [75/100], Loss: 0.2375, Validation Loss: 0.3114
	--> Epoch [76/100], Loss: 0.2638, Validation Loss: 0.3113
Early stopping
	--> Training for Fold 1 took 0.6274917125701904 sec, using 76 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6626, Validation Loss: 0.7297
	--> Epoch [2/100], Loss: 0.5714, Validation Loss: 0.7051
	--> Epoch [3/100], Loss: 0.6035, Validation Loss: 0.6840
	--> Epoch [4/100], Loss: 0.5155, Validation Loss: 0.6576
	--> Epoch [5/100], Loss: 0.4833, Validation Loss: 0.6331
	--> Epoch [6/100], Loss: 0.4115, Validation Loss: 0.6126
	--> Epoch [7/100], Loss: 0.4216, Validation Loss: 0.5867
	--> Epoch [8/100], Loss: 0.4484, Validation Loss: 0.5721
	--> Epoch [9/100], Loss: 0.4507, Validation Loss: 0.5541
	--> Epoch [10/100], Loss: 0.3317, Validation Loss: 0.5355
	--> Epoch [11/100], Loss: 0.3905, Validation Loss: 0.5226
	--> Epoch [12/100], Loss: 0.4201, Validation Loss: 0.5071
	--> Epoch [13/100], Loss: 0.4100, Validation Loss: 0.4957
	--> Epoch [14/100], Loss: 0.3280, Validation Loss: 0.4817
	--> Epoch [15/100], Loss: 0.3590, Validation Loss: 0.4694
	--> Epoch [16/100], Loss: 0.3072, Validation Loss: 0.4623
	--> Epoch [17/100], Loss: 0.2962, Validation Loss: 0.4543
	--> Epoch [18/100], Loss: 0.3045, Validation Loss: 0.4477
	--> Epoch [19/100], Loss: 0.2650, Validation Loss: 0.4389
	--> Epoch [20/100], Loss: 0.2905, Validation Loss: 0.4318
	--> Epoch [21/100], Loss: 0.2326, Validation Loss: 0.4220
	--> Epoch [22/100], Loss: 0.2735, Validation Loss: 0.4142
	--> Epoch [23/100], Loss: 0.1713, Validation Loss: 0.4075
	--> Epoch [24/100], Loss: 0.1829, Validation Loss: 0.4039
	--> Epoch [25/100], Loss: 0.1786, Validation Loss: 0.3963
	--> Epoch [26/100], Loss: 0.2429, Validation Loss: 0.3884
	--> Epoch [27/100], Loss: 0.1925, Validation Loss: 0.3824
	--> Epoch [28/100], Loss: 0.1964, Validation Loss: 0.3789
	--> Epoch [29/100], Loss: 0.2503, Validation Loss: 0.3733
	--> Epoch [30/100], Loss: 0.2281, Validation Loss: 0.3661
	--> Epoch [31/100], Loss: 0.1777, Validation Loss: 0.3613
	--> Epoch [32/100], Loss: 0.2721, Validation Loss: 0.3551
	--> Epoch [33/100], Loss: 0.1984, Validation Loss: 0.3483
	--> Epoch [34/100], Loss: 0.2406, Validation Loss: 0.3436
	--> Epoch [35/100], Loss: 0.2251, Validation Loss: 0.3379
	--> Epoch [36/100], Loss: 0.0889, Validation Loss: 0.3341
	--> Epoch [37/100], Loss: 0.1455, Validation Loss: 0.3309
	--> Epoch [38/100], Loss: 0.1219, Validation Loss: 0.3245
	--> Epoch [39/100], Loss: 0.2105, Validation Loss: 0.3215
	--> Epoch [40/100], Loss: 0.1493, Validation Loss: 0.3173
	--> Epoch [41/100], Loss: 0.2309, Validation Loss: 0.3134
	--> Epoch [42/100], Loss: 0.1502, Validation Loss: 0.3086
	--> Epoch [43/100], Loss: 0.1128, Validation Loss: 0.3027
	--> Epoch [44/100], Loss: 0.1278, Validation Loss: 0.2985
	--> Epoch [45/100], Loss: 0.1012, Validation Loss: 0.2966
	--> Epoch [46/100], Loss: 0.1879, Validation Loss: 0.2936
	--> Epoch [47/100], Loss: 0.1293, Validation Loss: 0.2928
	--> Epoch [48/100], Loss: 0.2194, Validation Loss: 0.2902
	--> Epoch [49/100], Loss: 0.0577, Validation Loss: 0.2865
	--> Epoch [50/100], Loss: 0.1980, Validation Loss: 0.2843
	--> Epoch [51/100], Loss: 0.1070, Validation Loss: 0.2808
	--> Epoch [52/100], Loss: 0.0915, Validation Loss: 0.2786
	--> Epoch [53/100], Loss: 0.1033, Validation Loss: 0.2750
	--> Epoch [54/100], Loss: 0.1314, Validation Loss: 0.2737
	--> Epoch [55/100], Loss: 0.1202, Validation Loss: 0.2739
	--> Epoch [56/100], Loss: 0.0505, Validation Loss: 0.2721
	--> Epoch [57/100], Loss: 0.1107, Validation Loss: 0.2702
	--> Epoch [58/100], Loss: 0.1427, Validation Loss: 0.2700
	--> Epoch [59/100], Loss: 0.1164, Validation Loss: 0.2690
	--> Epoch [60/100], Loss: 0.1045, Validation Loss: 0.2691
	--> Epoch [61/100], Loss: 0.1013, Validation Loss: 0.2680
	--> Epoch [62/100], Loss: 0.0831, Validation Loss: 0.2653
	--> Epoch [63/100], Loss: 0.1383, Validation Loss: 0.2624
	--> Epoch [64/100], Loss: 0.0814, Validation Loss: 0.2593
	--> Epoch [65/100], Loss: 0.0822, Validation Loss: 0.2586
	--> Epoch [66/100], Loss: 0.1097, Validation Loss: 0.2571
	--> Epoch [67/100], Loss: 0.1148, Validation Loss: 0.2541
	--> Epoch [68/100], Loss: 0.0483, Validation Loss: 0.2534
	--> Epoch [69/100], Loss: 0.1624, Validation Loss: 0.2547
	--> Epoch [70/100], Loss: 0.2468, Validation Loss: 0.2560
	--> Epoch [71/100], Loss: 0.0930, Validation Loss: 0.2533
	--> Epoch [72/100], Loss: 0.1046, Validation Loss: 0.2520
	--> Epoch [73/100], Loss: 0.1478, Validation Loss: 0.2515
	--> Epoch [74/100], Loss: 0.0991, Validation Loss: 0.2494
	--> Epoch [75/100], Loss: 0.0904, Validation Loss: 0.2498
	--> Epoch [76/100], Loss: 0.1682, Validation Loss: 0.2491
	--> Epoch [77/100], Loss: 0.0159, Validation Loss: 0.2497
	--> Epoch [78/100], Loss: 0.0879, Validation Loss: 0.2479
	--> Epoch [79/100], Loss: 0.0138, Validation Loss: 0.2477
	--> Epoch [80/100], Loss: 0.0862, Validation Loss: 0.2463
	--> Epoch [81/100], Loss: 0.1611, Validation Loss: 0.2452
	--> Epoch [82/100], Loss: 0.1607, Validation Loss: 0.2432
	--> Epoch [83/100], Loss: 0.0270, Validation Loss: 0.2418
	--> Epoch [84/100], Loss: 0.0822, Validation Loss: 0.2407
	--> Epoch [85/100], Loss: 0.0887, Validation Loss: 0.2405
	--> Epoch [86/100], Loss: 0.0180, Validation Loss: 0.2402
	--> Epoch [87/100], Loss: 0.2213, Validation Loss: 0.2393
	--> Epoch [88/100], Loss: 0.0234, Validation Loss: 0.2392
	--> Epoch [89/100], Loss: 0.0832, Validation Loss: 0.2388
	--> Epoch [90/100], Loss: 0.0713, Validation Loss: 0.2381
	--> Epoch [91/100], Loss: 0.0145, Validation Loss: 0.2380
	--> Epoch [92/100], Loss: 0.0746, Validation Loss: 0.2362
	--> Epoch [93/100], Loss: 0.0155, Validation Loss: 0.2352
	--> Epoch [94/100], Loss: 0.0164, Validation Loss: 0.2329
	--> Epoch [95/100], Loss: 0.0270, Validation Loss: 0.2336
	--> Epoch [96/100], Loss: 0.0096, Validation Loss: 0.2326
	--> Epoch [97/100], Loss: 0.0827, Validation Loss: 0.2318
	--> Epoch [98/100], Loss: 0.0859, Validation Loss: 0.2313
	--> Epoch [99/100], Loss: 0.0208, Validation Loss: 0.2317
	--> Epoch [100/100], Loss: 0.0251, Validation Loss: 0.2293
	--> Training for Fold 2 took 0.8290841579437256 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6703, Validation Loss: 0.7424
	--> Epoch [2/100], Loss: 0.5690, Validation Loss: 0.7344
	--> Epoch [3/100], Loss: 0.5577, Validation Loss: 0.7270
	--> Epoch [4/100], Loss: 0.5145, Validation Loss: 0.7197
	--> Epoch [5/100], Loss: 0.5131, Validation Loss: 0.7098
	--> Epoch [6/100], Loss: 0.4958, Validation Loss: 0.7028
	--> Epoch [7/100], Loss: 0.4245, Validation Loss: 0.6920
	--> Epoch [8/100], Loss: 0.3900, Validation Loss: 0.6783
	--> Epoch [9/100], Loss: 0.3808, Validation Loss: 0.6701
	--> Epoch [10/100], Loss: 0.3418, Validation Loss: 0.6558
	--> Epoch [11/100], Loss: 0.3619, Validation Loss: 0.6442
	--> Epoch [12/100], Loss: 0.3378, Validation Loss: 0.6325
	--> Epoch [13/100], Loss: 0.2620, Validation Loss: 0.6208
	--> Epoch [14/100], Loss: 0.2986, Validation Loss: 0.6072
	--> Epoch [15/100], Loss: 0.3562, Validation Loss: 0.5967
	--> Epoch [16/100], Loss: 0.3555, Validation Loss: 0.5889
	--> Epoch [17/100], Loss: 0.2653, Validation Loss: 0.5834
	--> Epoch [18/100], Loss: 0.3028, Validation Loss: 0.5751
	--> Epoch [19/100], Loss: 0.1696, Validation Loss: 0.5642
	--> Epoch [20/100], Loss: 0.2015, Validation Loss: 0.5543
	--> Epoch [21/100], Loss: 0.2732, Validation Loss: 0.5454
	--> Epoch [22/100], Loss: 0.3020, Validation Loss: 0.5362
	--> Epoch [23/100], Loss: 0.1582, Validation Loss: 0.5284
	--> Epoch [24/100], Loss: 0.2242, Validation Loss: 0.5215
	--> Epoch [25/100], Loss: 0.1488, Validation Loss: 0.5168
	--> Epoch [26/100], Loss: 0.1362, Validation Loss: 0.5082
	--> Epoch [27/100], Loss: 0.2989, Validation Loss: 0.5012
	--> Epoch [28/100], Loss: 0.1851, Validation Loss: 0.4934
	--> Epoch [29/100], Loss: 0.2854, Validation Loss: 0.4863
	--> Epoch [30/100], Loss: 0.1698, Validation Loss: 0.4792
	--> Epoch [31/100], Loss: 0.0877, Validation Loss: 0.4756
	--> Epoch [32/100], Loss: 0.1662, Validation Loss: 0.4716
	--> Epoch [33/100], Loss: 0.1756, Validation Loss: 0.4655
	--> Epoch [34/100], Loss: 0.3340, Validation Loss: 0.4628
	--> Epoch [35/100], Loss: 0.1143, Validation Loss: 0.4593
	--> Epoch [36/100], Loss: 0.2531, Validation Loss: 0.4554
	--> Epoch [37/100], Loss: 0.1228, Validation Loss: 0.4486
	--> Epoch [38/100], Loss: 0.1554, Validation Loss: 0.4434
	--> Epoch [39/100], Loss: 0.1131, Validation Loss: 0.4373
	--> Epoch [40/100], Loss: 0.1361, Validation Loss: 0.4331
	--> Epoch [41/100], Loss: 0.3178, Validation Loss: 0.4287
	--> Epoch [42/100], Loss: 0.2539, Validation Loss: 0.4233
	--> Epoch [43/100], Loss: 0.0751, Validation Loss: 0.4209
	--> Epoch [44/100], Loss: 0.1635, Validation Loss: 0.4179
	--> Epoch [45/100], Loss: 0.0514, Validation Loss: 0.4141
	--> Epoch [46/100], Loss: 0.1592, Validation Loss: 0.4085
	--> Epoch [47/100], Loss: 0.1052, Validation Loss: 0.4074
	--> Epoch [48/100], Loss: 0.1439, Validation Loss: 0.4024
	--> Epoch [49/100], Loss: 0.1340, Validation Loss: 0.3987
	--> Epoch [50/100], Loss: 0.1209, Validation Loss: 0.3957
	--> Epoch [51/100], Loss: 0.0952, Validation Loss: 0.3936
	--> Epoch [52/100], Loss: 0.1421, Validation Loss: 0.3905
	--> Epoch [53/100], Loss: 0.1559, Validation Loss: 0.3885
	--> Epoch [54/100], Loss: 0.1106, Validation Loss: 0.3869
	--> Epoch [55/100], Loss: 0.1318, Validation Loss: 0.3876
	--> Epoch [56/100], Loss: 0.0751, Validation Loss: 0.3857
	--> Epoch [57/100], Loss: 0.0374, Validation Loss: 0.3829
	--> Epoch [58/100], Loss: 0.0393, Validation Loss: 0.3812
	--> Epoch [59/100], Loss: 0.0163, Validation Loss: 0.3759
	--> Epoch [60/100], Loss: 0.1079, Validation Loss: 0.3736
	--> Epoch [61/100], Loss: 0.0474, Validation Loss: 0.3728
	--> Epoch [62/100], Loss: 0.1345, Validation Loss: 0.3687
	--> Epoch [63/100], Loss: 0.0786, Validation Loss: 0.3653
	--> Epoch [64/100], Loss: 0.1174, Validation Loss: 0.3645
	--> Epoch [65/100], Loss: 0.0423, Validation Loss: 0.3614
	--> Epoch [66/100], Loss: 0.0238, Validation Loss: 0.3602
	--> Epoch [67/100], Loss: 0.1541, Validation Loss: 0.3564
	--> Epoch [68/100], Loss: 0.0136, Validation Loss: 0.3559
	--> Epoch [69/100], Loss: 0.0413, Validation Loss: 0.3561
	--> Epoch [70/100], Loss: 0.1571, Validation Loss: 0.3543
	--> Epoch [71/100], Loss: 0.1579, Validation Loss: 0.3511
	--> Epoch [72/100], Loss: 0.0794, Validation Loss: 0.3520
	--> Epoch [73/100], Loss: 0.2021, Validation Loss: 0.3499
	--> Epoch [74/100], Loss: 0.0638, Validation Loss: 0.3477
	--> Epoch [75/100], Loss: 0.0889, Validation Loss: 0.3479
	--> Epoch [76/100], Loss: 0.0694, Validation Loss: 0.3437
	--> Epoch [77/100], Loss: 0.2071, Validation Loss: 0.3411
	--> Epoch [78/100], Loss: 0.1607, Validation Loss: 0.3393
	--> Epoch [79/100], Loss: 0.0717, Validation Loss: 0.3377
	--> Epoch [80/100], Loss: 0.0177, Validation Loss: 0.3377
	--> Epoch [81/100], Loss: 0.0870, Validation Loss: 0.3358
	--> Epoch [82/100], Loss: 0.0960, Validation Loss: 0.3337
	--> Epoch [83/100], Loss: 0.1675, Validation Loss: 0.3329
	--> Epoch [84/100], Loss: 0.0790, Validation Loss: 0.3306
	--> Epoch [85/100], Loss: 0.0778, Validation Loss: 0.3298
	--> Epoch [86/100], Loss: 0.0928, Validation Loss: 0.3285
	--> Epoch [87/100], Loss: 0.0184, Validation Loss: 0.3274
	--> Epoch [88/100], Loss: 0.0918, Validation Loss: 0.3281
	--> Epoch [89/100], Loss: 0.1610, Validation Loss: 0.3254
	--> Epoch [90/100], Loss: 0.1722, Validation Loss: 0.3243
	--> Epoch [91/100], Loss: 0.0721, Validation Loss: 0.3226
	--> Epoch [92/100], Loss: 0.1319, Validation Loss: 0.3219
	--> Epoch [93/100], Loss: 0.0072, Validation Loss: 0.3203
	--> Epoch [94/100], Loss: 0.0057, Validation Loss: 0.3195
	--> Epoch [95/100], Loss: 0.0094, Validation Loss: 0.3188
	--> Epoch [96/100], Loss: 0.0739, Validation Loss: 0.3192
	--> Epoch [97/100], Loss: 0.0894, Validation Loss: 0.3191
	--> Epoch [98/100], Loss: 0.0061, Validation Loss: 0.3164
	--> Epoch [99/100], Loss: 0.0698, Validation Loss: 0.3164
	--> Epoch [100/100], Loss: 0.1525, Validation Loss: 0.3159
	--> Training for Fold 3 took 0.8242712020874023 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6474, Validation Loss: 0.5964
	--> Epoch [2/100], Loss: 0.6128, Validation Loss: 0.5790
	--> Epoch [3/100], Loss: 0.5093, Validation Loss: 0.5594
	--> Epoch [4/100], Loss: 0.5030, Validation Loss: 0.5360
	--> Epoch [5/100], Loss: 0.4871, Validation Loss: 0.5229
	--> Epoch [6/100], Loss: 0.4877, Validation Loss: 0.5097
	--> Epoch [7/100], Loss: 0.5025, Validation Loss: 0.4975
	--> Epoch [8/100], Loss: 0.3821, Validation Loss: 0.4836
	--> Epoch [9/100], Loss: 0.3331, Validation Loss: 0.4673
	--> Epoch [10/100], Loss: 0.4152, Validation Loss: 0.4576
	--> Epoch [11/100], Loss: 0.4295, Validation Loss: 0.4457
	--> Epoch [12/100], Loss: 0.4293, Validation Loss: 0.4327
	--> Epoch [13/100], Loss: 0.3364, Validation Loss: 0.4239
	--> Epoch [14/100], Loss: 0.2950, Validation Loss: 0.4138
	--> Epoch [15/100], Loss: 0.3659, Validation Loss: 0.4025
	--> Epoch [16/100], Loss: 0.2583, Validation Loss: 0.3921
	--> Epoch [17/100], Loss: 0.3300, Validation Loss: 0.3868
	--> Epoch [18/100], Loss: 0.2800, Validation Loss: 0.3807
	--> Epoch [19/100], Loss: 0.3214, Validation Loss: 0.3738
	--> Epoch [20/100], Loss: 0.3480, Validation Loss: 0.3639
	--> Epoch [21/100], Loss: 0.3855, Validation Loss: 0.3586
	--> Epoch [22/100], Loss: 0.1399, Validation Loss: 0.3544
	--> Epoch [23/100], Loss: 0.2404, Validation Loss: 0.3487
	--> Epoch [24/100], Loss: 0.2122, Validation Loss: 0.3500
	--> Epoch [25/100], Loss: 0.2700, Validation Loss: 0.3429
	--> Epoch [26/100], Loss: 0.2278, Validation Loss: 0.3360
	--> Epoch [27/100], Loss: 0.1999, Validation Loss: 0.3298
	--> Epoch [28/100], Loss: 0.2113, Validation Loss: 0.3234
	--> Epoch [29/100], Loss: 0.1518, Validation Loss: 0.3227
	--> Epoch [30/100], Loss: 0.0936, Validation Loss: 0.3189
	--> Epoch [31/100], Loss: 0.1420, Validation Loss: 0.3161
	--> Epoch [32/100], Loss: 0.3560, Validation Loss: 0.3124
	--> Epoch [33/100], Loss: 0.2086, Validation Loss: 0.3104
	--> Epoch [34/100], Loss: 0.0917, Validation Loss: 0.3089
	--> Epoch [35/100], Loss: 0.0689, Validation Loss: 0.3044
	--> Epoch [36/100], Loss: 0.1729, Validation Loss: 0.3022
	--> Epoch [37/100], Loss: 0.1278, Validation Loss: 0.3012
	--> Epoch [38/100], Loss: 0.3325, Validation Loss: 0.3008
	--> Epoch [39/100], Loss: 0.1116, Validation Loss: 0.2995
	--> Epoch [40/100], Loss: 0.1648, Validation Loss: 0.2994
	--> Epoch [41/100], Loss: 0.2242, Validation Loss: 0.2992
	--> Epoch [42/100], Loss: 0.1157, Validation Loss: 0.2948
	--> Epoch [43/100], Loss: 0.1068, Validation Loss: 0.2899
	--> Epoch [44/100], Loss: 0.2124, Validation Loss: 0.2958
	--> Epoch [45/100], Loss: 0.3306, Validation Loss: 0.2907
	--> Epoch [46/100], Loss: 0.1930, Validation Loss: 0.2890
	--> Epoch [47/100], Loss: 0.0775, Validation Loss: 0.2884
	--> Epoch [48/100], Loss: 0.1471, Validation Loss: 0.2875
	--> Epoch [49/100], Loss: 0.1630, Validation Loss: 0.2864
	--> Epoch [50/100], Loss: 0.0553, Validation Loss: 0.2874
	--> Epoch [51/100], Loss: 0.2123, Validation Loss: 0.2867
	--> Epoch [52/100], Loss: 0.0420, Validation Loss: 0.2840
	--> Epoch [53/100], Loss: 0.0955, Validation Loss: 0.2815
	--> Epoch [54/100], Loss: 0.1807, Validation Loss: 0.2798
	--> Epoch [55/100], Loss: 0.1058, Validation Loss: 0.2796
	--> Epoch [56/100], Loss: 0.1062, Validation Loss: 0.2803
	--> Epoch [57/100], Loss: 0.0826, Validation Loss: 0.2789
	--> Epoch [58/100], Loss: 0.2221, Validation Loss: 0.2778
	--> Epoch [59/100], Loss: 0.1456, Validation Loss: 0.2748
	--> Epoch [60/100], Loss: 0.0337, Validation Loss: 0.2740
	--> Epoch [61/100], Loss: 0.2175, Validation Loss: 0.2734
	--> Epoch [62/100], Loss: 0.0841, Validation Loss: 0.2756
	--> Epoch [63/100], Loss: 0.1668, Validation Loss: 0.2734
	--> Epoch [64/100], Loss: 0.1606, Validation Loss: 0.2785
	--> Epoch [65/100], Loss: 0.2067, Validation Loss: 0.2782
	--> Epoch [66/100], Loss: 0.1522, Validation Loss: 0.2788
Early stopping
	--> Training for Fold 4 took 0.533447265625 sec, using 66 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7330, Validation Loss: 0.6534
	--> Epoch [2/100], Loss: 0.7463, Validation Loss: 0.6381
	--> Epoch [3/100], Loss: 0.6713, Validation Loss: 0.6246
	--> Epoch [4/100], Loss: 0.6041, Validation Loss: 0.6155
	--> Epoch [5/100], Loss: 0.6331, Validation Loss: 0.6012
	--> Epoch [6/100], Loss: 0.5721, Validation Loss: 0.5933
	--> Epoch [7/100], Loss: 0.5351, Validation Loss: 0.5848
	--> Epoch [8/100], Loss: 0.6009, Validation Loss: 0.5773
	--> Epoch [9/100], Loss: 0.5697, Validation Loss: 0.5723
	--> Epoch [10/100], Loss: 0.5654, Validation Loss: 0.5703
	--> Epoch [11/100], Loss: 0.4871, Validation Loss: 0.5671
	--> Epoch [12/100], Loss: 0.3731, Validation Loss: 0.5639
	--> Epoch [13/100], Loss: 0.4834, Validation Loss: 0.5606
	--> Epoch [14/100], Loss: 0.4321, Validation Loss: 0.5573
	--> Epoch [15/100], Loss: 0.3435, Validation Loss: 0.5544
	--> Epoch [16/100], Loss: 0.3162, Validation Loss: 0.5517
	--> Epoch [17/100], Loss: 0.3858, Validation Loss: 0.5460
	--> Epoch [18/100], Loss: 0.3488, Validation Loss: 0.5454
	--> Epoch [19/100], Loss: 0.2897, Validation Loss: 0.5392
	--> Epoch [20/100], Loss: 0.3420, Validation Loss: 0.5385
	--> Epoch [21/100], Loss: 0.3548, Validation Loss: 0.5353
	--> Epoch [22/100], Loss: 0.3251, Validation Loss: 0.5341
	--> Epoch [23/100], Loss: 0.3717, Validation Loss: 0.5306
	--> Epoch [24/100], Loss: 0.2093, Validation Loss: 0.5271
	--> Epoch [25/100], Loss: 0.2653, Validation Loss: 0.5218
	--> Epoch [26/100], Loss: 0.2706, Validation Loss: 0.5225
	--> Epoch [27/100], Loss: 0.2417, Validation Loss: 0.5206
	--> Epoch [28/100], Loss: 0.1766, Validation Loss: 0.5165
	--> Epoch [29/100], Loss: 0.1777, Validation Loss: 0.5153
	--> Epoch [30/100], Loss: 0.1944, Validation Loss: 0.5132
	--> Epoch [31/100], Loss: 0.1297, Validation Loss: 0.5119
	--> Epoch [32/100], Loss: 0.2276, Validation Loss: 0.5128
	--> Epoch [33/100], Loss: 0.1805, Validation Loss: 0.5101
	--> Epoch [34/100], Loss: 0.2381, Validation Loss: 0.5106
	--> Epoch [35/100], Loss: 0.3492, Validation Loss: 0.5092
	--> Epoch [36/100], Loss: 0.2664, Validation Loss: 0.5071
	--> Epoch [37/100], Loss: 0.1528, Validation Loss: 0.5064
	--> Epoch [38/100], Loss: 0.0916, Validation Loss: 0.5049
	--> Epoch [39/100], Loss: 0.1951, Validation Loss: 0.5032
	--> Epoch [40/100], Loss: 0.2198, Validation Loss: 0.5017
	--> Epoch [41/100], Loss: 0.2249, Validation Loss: 0.5011
	--> Epoch [42/100], Loss: 0.1358, Validation Loss: 0.5025
	--> Epoch [43/100], Loss: 0.0937, Validation Loss: 0.5035
	--> Epoch [44/100], Loss: 0.0772, Validation Loss: 0.5065
Early stopping
	--> Training for Fold 5 took 0.3563814163208008 sec, using 44 epochs

Median number of epochs used: 76 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/76], Loss: 0.7201
	--> Final training Epoch [2/76], Loss: 0.6900
	--> Final training Epoch [3/76], Loss: 0.6218
	--> Final training Epoch [4/76], Loss: 0.6508
	--> Final training Epoch [5/76], Loss: 0.5709
	--> Final training Epoch [6/76], Loss: 0.6060
	--> Final training Epoch [7/76], Loss: 0.5932
	--> Final training Epoch [8/76], Loss: 0.5272
	--> Final training Epoch [9/76], Loss: 0.4728
	--> Final training Epoch [10/76], Loss: 0.5367
	--> Final training Epoch [11/76], Loss: 0.4961
	--> Final training Epoch [12/76], Loss: 0.4678
	--> Final training Epoch [13/76], Loss: 0.5194
	--> Final training Epoch [14/76], Loss: 0.4526
	--> Final training Epoch [15/76], Loss: 0.3996
	--> Final training Epoch [16/76], Loss: 0.3822
	--> Final training Epoch [17/76], Loss: 0.5031
	--> Final training Epoch [18/76], Loss: 0.4220
	--> Final training Epoch [19/76], Loss: 0.3813
	--> Final training Epoch [20/76], Loss: 0.4047
	--> Final training Epoch [21/76], Loss: 0.3553
	--> Final training Epoch [22/76], Loss: 0.3178
	--> Final training Epoch [23/76], Loss: 0.3213
	--> Final training Epoch [24/76], Loss: 0.2917
	--> Final training Epoch [25/76], Loss: 0.2801
	--> Final training Epoch [26/76], Loss: 0.2919
	--> Final training Epoch [27/76], Loss: 0.3262
	--> Final training Epoch [28/76], Loss: 0.3048
	--> Final training Epoch [29/76], Loss: 0.3358
	--> Final training Epoch [30/76], Loss: 0.2636
	--> Final training Epoch [31/76], Loss: 0.2480
	--> Final training Epoch [32/76], Loss: 0.2567
	--> Final training Epoch [33/76], Loss: 0.2746
	--> Final training Epoch [34/76], Loss: 0.2631
	--> Final training Epoch [35/76], Loss: 0.2424
	--> Final training Epoch [36/76], Loss: 0.2078
	--> Final training Epoch [37/76], Loss: 0.2653
	--> Final training Epoch [38/76], Loss: 0.2478
	--> Final training Epoch [39/76], Loss: 0.3414
	--> Final training Epoch [40/76], Loss: 0.2364
	--> Final training Epoch [41/76], Loss: 0.1827
	--> Final training Epoch [42/76], Loss: 0.2156
	--> Final training Epoch [43/76], Loss: 0.1973
	--> Final training Epoch [44/76], Loss: 0.2306
	--> Final training Epoch [45/76], Loss: 0.2258
	--> Final training Epoch [46/76], Loss: 0.2752
	--> Final training Epoch [47/76], Loss: 0.2733
	--> Final training Epoch [48/76], Loss: 0.1970
	--> Final training Epoch [49/76], Loss: 0.1903
	--> Final training Epoch [50/76], Loss: 0.2226
	--> Final training Epoch [51/76], Loss: 0.1970
	--> Final training Epoch [52/76], Loss: 0.1397
	--> Final training Epoch [53/76], Loss: 0.2112
	--> Final training Epoch [54/76], Loss: 0.2378
	--> Final training Epoch [55/76], Loss: 0.2088
	--> Final training Epoch [56/76], Loss: 0.2580
	--> Final training Epoch [57/76], Loss: 0.1562
	--> Final training Epoch [58/76], Loss: 0.1738
	--> Final training Epoch [59/76], Loss: 0.1689
	--> Final training Epoch [60/76], Loss: 0.2437
	--> Final training Epoch [61/76], Loss: 0.1726
	--> Final training Epoch [62/76], Loss: 0.1551
	--> Final training Epoch [63/76], Loss: 0.1372
	--> Final training Epoch [64/76], Loss: 0.2221
	--> Final training Epoch [65/76], Loss: 0.1659
	--> Final training Epoch [66/76], Loss: 0.1433
	--> Final training Epoch [67/76], Loss: 0.1977
	--> Final training Epoch [68/76], Loss: 0.1365
	--> Final training Epoch [69/76], Loss: 0.2225
	--> Final training Epoch [70/76], Loss: 0.1574
	--> Final training Epoch [71/76], Loss: 0.2270
	--> Final training Epoch [72/76], Loss: 0.1437
	--> Final training Epoch [73/76], Loss: 0.1288
	--> Final training Epoch [74/76], Loss: 0.2560
	--> Final training Epoch [75/76], Loss: 0.1653
	--> Final training Epoch [76/76], Loss: 0.1767

Final training took 0.6645357608795166 sec

TESTING
	--> Testing took 0.0095 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8948
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3667,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.3667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.3991,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.3667

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5510, Validation Loss: 0.5704
	--> Epoch [2/100], Loss: 0.5606, Validation Loss: 0.5541
	--> Epoch [3/100], Loss: 0.4633, Validation Loss: 0.5395
	--> Epoch [4/100], Loss: 0.4670, Validation Loss: 0.5199
	--> Epoch [5/100], Loss: 0.4135, Validation Loss: 0.5072
	--> Epoch [6/100], Loss: 0.4879, Validation Loss: 0.4932
	--> Epoch [7/100], Loss: 0.4600, Validation Loss: 0.4824
	--> Epoch [8/100], Loss: 0.4425, Validation Loss: 0.4732
	--> Epoch [9/100], Loss: 0.3761, Validation Loss: 0.4633
	--> Epoch [10/100], Loss: 0.3288, Validation Loss: 0.4530
	--> Epoch [11/100], Loss: 0.2790, Validation Loss: 0.4447
	--> Epoch [12/100], Loss: 0.4103, Validation Loss: 0.4359
	--> Epoch [13/100], Loss: 0.3199, Validation Loss: 0.4248
	--> Epoch [14/100], Loss: 0.2336, Validation Loss: 0.4139
	--> Epoch [15/100], Loss: 0.3069, Validation Loss: 0.4067
	--> Epoch [16/100], Loss: 0.3844, Validation Loss: 0.3999
	--> Epoch [17/100], Loss: 0.2391, Validation Loss: 0.3905
	--> Epoch [18/100], Loss: 0.2350, Validation Loss: 0.3831
	--> Epoch [19/100], Loss: 0.2636, Validation Loss: 0.3765
	--> Epoch [20/100], Loss: 0.2836, Validation Loss: 0.3686
	--> Epoch [21/100], Loss: 0.1177, Validation Loss: 0.3614
	--> Epoch [22/100], Loss: 0.2209, Validation Loss: 0.3563
	--> Epoch [23/100], Loss: 0.2985, Validation Loss: 0.3485
	--> Epoch [24/100], Loss: 0.1534, Validation Loss: 0.3429
	--> Epoch [25/100], Loss: 0.2268, Validation Loss: 0.3358
	--> Epoch [26/100], Loss: 0.1986, Validation Loss: 0.3277
	--> Epoch [27/100], Loss: 0.0934, Validation Loss: 0.3240
	--> Epoch [28/100], Loss: 0.2710, Validation Loss: 0.3160
	--> Epoch [29/100], Loss: 0.1604, Validation Loss: 0.3121
	--> Epoch [30/100], Loss: 0.1550, Validation Loss: 0.3065
	--> Epoch [31/100], Loss: 0.1949, Validation Loss: 0.3022
	--> Epoch [32/100], Loss: 0.1400, Validation Loss: 0.2972
	--> Epoch [33/100], Loss: 0.1517, Validation Loss: 0.2935
	--> Epoch [34/100], Loss: 0.1326, Validation Loss: 0.2889
	--> Epoch [35/100], Loss: 0.0883, Validation Loss: 0.2842
	--> Epoch [36/100], Loss: 0.1864, Validation Loss: 0.2823
	--> Epoch [37/100], Loss: 0.1657, Validation Loss: 0.2794
	--> Epoch [38/100], Loss: 0.0626, Validation Loss: 0.2751
	--> Epoch [39/100], Loss: 0.2675, Validation Loss: 0.2721
	--> Epoch [40/100], Loss: 0.0527, Validation Loss: 0.2696
	--> Epoch [41/100], Loss: 0.1953, Validation Loss: 0.2664
	--> Epoch [42/100], Loss: 0.2041, Validation Loss: 0.2643
	--> Epoch [43/100], Loss: 0.2118, Validation Loss: 0.2623
	--> Epoch [44/100], Loss: 0.1271, Validation Loss: 0.2590
	--> Epoch [45/100], Loss: 0.0914, Validation Loss: 0.2573
	--> Epoch [46/100], Loss: 0.1334, Validation Loss: 0.2550
	--> Epoch [47/100], Loss: 0.1179, Validation Loss: 0.2536
	--> Epoch [48/100], Loss: 0.1942, Validation Loss: 0.2515
	--> Epoch [49/100], Loss: 0.1153, Validation Loss: 0.2501
	--> Epoch [50/100], Loss: 0.0684, Validation Loss: 0.2475
	--> Epoch [51/100], Loss: 0.2062, Validation Loss: 0.2465
	--> Epoch [52/100], Loss: 0.1481, Validation Loss: 0.2448
	--> Epoch [53/100], Loss: 0.1100, Validation Loss: 0.2414
	--> Epoch [54/100], Loss: 0.0906, Validation Loss: 0.2408
	--> Epoch [55/100], Loss: 0.1216, Validation Loss: 0.2395
	--> Epoch [56/100], Loss: 0.0978, Validation Loss: 0.2389
	--> Epoch [57/100], Loss: 0.0368, Validation Loss: 0.2365
	--> Epoch [58/100], Loss: 0.1067, Validation Loss: 0.2336
	--> Epoch [59/100], Loss: 0.1403, Validation Loss: 0.2324
	--> Epoch [60/100], Loss: 0.0933, Validation Loss: 0.2324
	--> Epoch [61/100], Loss: 0.2134, Validation Loss: 0.2315
	--> Epoch [62/100], Loss: 0.0352, Validation Loss: 0.2301
	--> Epoch [63/100], Loss: 0.1004, Validation Loss: 0.2284
	--> Epoch [64/100], Loss: 0.0881, Validation Loss: 0.2263
	--> Epoch [65/100], Loss: 0.2199, Validation Loss: 0.2245
	--> Epoch [66/100], Loss: 0.1100, Validation Loss: 0.2251
	--> Epoch [67/100], Loss: 0.1789, Validation Loss: 0.2250
	--> Epoch [68/100], Loss: 0.1506, Validation Loss: 0.2231
	--> Epoch [69/100], Loss: 0.0933, Validation Loss: 0.2235
	--> Epoch [70/100], Loss: 0.0267, Validation Loss: 0.2225
	--> Epoch [71/100], Loss: 0.0215, Validation Loss: 0.2213
	--> Epoch [72/100], Loss: 0.2219, Validation Loss: 0.2211
	--> Epoch [73/100], Loss: 0.0158, Validation Loss: 0.2195
	--> Epoch [74/100], Loss: 0.0945, Validation Loss: 0.2188
	--> Epoch [75/100], Loss: 0.0219, Validation Loss: 0.2176
	--> Epoch [76/100], Loss: 0.0306, Validation Loss: 0.2176
	--> Epoch [77/100], Loss: 0.0932, Validation Loss: 0.2177
	--> Epoch [78/100], Loss: 0.0829, Validation Loss: 0.2161
	--> Epoch [79/100], Loss: 0.2269, Validation Loss: 0.2161
	--> Epoch [80/100], Loss: 0.0214, Validation Loss: 0.2138
	--> Epoch [81/100], Loss: 0.2368, Validation Loss: 0.2133
	--> Epoch [82/100], Loss: 0.1834, Validation Loss: 0.2141
	--> Epoch [83/100], Loss: 0.1044, Validation Loss: 0.2141
	--> Epoch [84/100], Loss: 0.0142, Validation Loss: 0.2142
Early stopping
	--> Training for Fold 1 took 0.8899495601654053 sec, using 84 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6160, Validation Loss: 0.6585
	--> Epoch [2/100], Loss: 0.5674, Validation Loss: 0.6403
	--> Epoch [3/100], Loss: 0.6352, Validation Loss: 0.6238
	--> Epoch [4/100], Loss: 0.4650, Validation Loss: 0.6076
	--> Epoch [5/100], Loss: 0.4921, Validation Loss: 0.5939
	--> Epoch [6/100], Loss: 0.4696, Validation Loss: 0.5789
	--> Epoch [7/100], Loss: 0.4516, Validation Loss: 0.5695
	--> Epoch [8/100], Loss: 0.4267, Validation Loss: 0.5590
	--> Epoch [9/100], Loss: 0.4133, Validation Loss: 0.5509
	--> Epoch [10/100], Loss: 0.4160, Validation Loss: 0.5449
	--> Epoch [11/100], Loss: 0.3289, Validation Loss: 0.5379
	--> Epoch [12/100], Loss: 0.4637, Validation Loss: 0.5297
	--> Epoch [13/100], Loss: 0.3409, Validation Loss: 0.5216
	--> Epoch [14/100], Loss: 0.3643, Validation Loss: 0.5144
	--> Epoch [15/100], Loss: 0.2321, Validation Loss: 0.5096
	--> Epoch [16/100], Loss: 0.2592, Validation Loss: 0.5038
	--> Epoch [17/100], Loss: 0.2544, Validation Loss: 0.4938
	--> Epoch [18/100], Loss: 0.2711, Validation Loss: 0.4915
	--> Epoch [19/100], Loss: 0.1618, Validation Loss: 0.4885
	--> Epoch [20/100], Loss: 0.3395, Validation Loss: 0.4845
	--> Epoch [21/100], Loss: 0.2857, Validation Loss: 0.4760
	--> Epoch [22/100], Loss: 0.3499, Validation Loss: 0.4733
	--> Epoch [23/100], Loss: 0.2370, Validation Loss: 0.4711
	--> Epoch [24/100], Loss: 0.2435, Validation Loss: 0.4662
	--> Epoch [25/100], Loss: 0.2307, Validation Loss: 0.4594
	--> Epoch [26/100], Loss: 0.2279, Validation Loss: 0.4541
	--> Epoch [27/100], Loss: 0.2340, Validation Loss: 0.4492
	--> Epoch [28/100], Loss: 0.1350, Validation Loss: 0.4455
	--> Epoch [29/100], Loss: 0.2503, Validation Loss: 0.4416
	--> Epoch [30/100], Loss: 0.2000, Validation Loss: 0.4356
	--> Epoch [31/100], Loss: 0.2054, Validation Loss: 0.4292
	--> Epoch [32/100], Loss: 0.2358, Validation Loss: 0.4233
	--> Epoch [33/100], Loss: 0.1289, Validation Loss: 0.4176
	--> Epoch [34/100], Loss: 0.0788, Validation Loss: 0.4121
	--> Epoch [35/100], Loss: 0.1027, Validation Loss: 0.4101
	--> Epoch [36/100], Loss: 0.2068, Validation Loss: 0.4052
	--> Epoch [37/100], Loss: 0.1999, Validation Loss: 0.4013
	--> Epoch [38/100], Loss: 0.2698, Validation Loss: 0.3945
	--> Epoch [39/100], Loss: 0.1825, Validation Loss: 0.3914
	--> Epoch [40/100], Loss: 0.2371, Validation Loss: 0.3877
	--> Epoch [41/100], Loss: 0.1224, Validation Loss: 0.3857
	--> Epoch [42/100], Loss: 0.1194, Validation Loss: 0.3836
	--> Epoch [43/100], Loss: 0.0548, Validation Loss: 0.3815
	--> Epoch [44/100], Loss: 0.0600, Validation Loss: 0.3780
	--> Epoch [45/100], Loss: 0.1106, Validation Loss: 0.3753
	--> Epoch [46/100], Loss: 0.1713, Validation Loss: 0.3720
	--> Epoch [47/100], Loss: 0.2214, Validation Loss: 0.3705
	--> Epoch [48/100], Loss: 0.2531, Validation Loss: 0.3698
	--> Epoch [49/100], Loss: 0.0899, Validation Loss: 0.3673
	--> Epoch [50/100], Loss: 0.2395, Validation Loss: 0.3660
	--> Epoch [51/100], Loss: 0.1478, Validation Loss: 0.3617
	--> Epoch [52/100], Loss: 0.1912, Validation Loss: 0.3591
	--> Epoch [53/100], Loss: 0.1473, Validation Loss: 0.3547
	--> Epoch [54/100], Loss: 0.0372, Validation Loss: 0.3527
	--> Epoch [55/100], Loss: 0.1468, Validation Loss: 0.3536
	--> Epoch [56/100], Loss: 0.1556, Validation Loss: 0.3497
	--> Epoch [57/100], Loss: 0.0822, Validation Loss: 0.3476
	--> Epoch [58/100], Loss: 0.0881, Validation Loss: 0.3467
	--> Epoch [59/100], Loss: 0.0802, Validation Loss: 0.3450
	--> Epoch [60/100], Loss: 0.1535, Validation Loss: 0.3423
	--> Epoch [61/100], Loss: 0.1578, Validation Loss: 0.3390
	--> Epoch [62/100], Loss: 0.1767, Validation Loss: 0.3365
	--> Epoch [63/100], Loss: 0.1672, Validation Loss: 0.3377
	--> Epoch [64/100], Loss: 0.1631, Validation Loss: 0.3358
	--> Epoch [65/100], Loss: 0.1659, Validation Loss: 0.3349
	--> Epoch [66/100], Loss: 0.0182, Validation Loss: 0.3331
	--> Epoch [67/100], Loss: 0.2365, Validation Loss: 0.3311
	--> Epoch [68/100], Loss: 0.0799, Validation Loss: 0.3291
	--> Epoch [69/100], Loss: 0.0740, Validation Loss: 0.3286
	--> Epoch [70/100], Loss: 0.2218, Validation Loss: 0.3277
	--> Epoch [71/100], Loss: 0.2208, Validation Loss: 0.3271
	--> Epoch [72/100], Loss: 0.1425, Validation Loss: 0.3265
	--> Epoch [73/100], Loss: 0.1540, Validation Loss: 0.3239
	--> Epoch [74/100], Loss: 0.0239, Validation Loss: 0.3235
	--> Epoch [75/100], Loss: 0.1537, Validation Loss: 0.3234
	--> Epoch [76/100], Loss: 0.0218, Validation Loss: 0.3226
	--> Epoch [77/100], Loss: 0.1985, Validation Loss: 0.3227
	--> Epoch [78/100], Loss: 0.2271, Validation Loss: 0.3236
	--> Epoch [79/100], Loss: 0.1510, Validation Loss: 0.3215
	--> Epoch [80/100], Loss: 0.2151, Validation Loss: 0.3151
	--> Epoch [81/100], Loss: 0.0809, Validation Loss: 0.3123
	--> Epoch [82/100], Loss: 0.1699, Validation Loss: 0.3115
	--> Epoch [83/100], Loss: 0.1482, Validation Loss: 0.3102
	--> Epoch [84/100], Loss: 0.0810, Validation Loss: 0.3108
	--> Epoch [85/100], Loss: 0.0720, Validation Loss: 0.3107
	--> Epoch [86/100], Loss: 0.2005, Validation Loss: 0.3122
Early stopping
	--> Training for Fold 2 took 0.906219482421875 sec, using 86 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7238, Validation Loss: 0.7052
	--> Epoch [2/100], Loss: 0.6443, Validation Loss: 0.6816
	--> Epoch [3/100], Loss: 0.5906, Validation Loss: 0.6650
	--> Epoch [4/100], Loss: 0.4921, Validation Loss: 0.6522
	--> Epoch [5/100], Loss: 0.4937, Validation Loss: 0.6375
	--> Epoch [6/100], Loss: 0.5660, Validation Loss: 0.6227
	--> Epoch [7/100], Loss: 0.5741, Validation Loss: 0.6149
	--> Epoch [8/100], Loss: 0.5027, Validation Loss: 0.5997
	--> Epoch [9/100], Loss: 0.5511, Validation Loss: 0.5903
	--> Epoch [10/100], Loss: 0.5446, Validation Loss: 0.5853
	--> Epoch [11/100], Loss: 0.5258, Validation Loss: 0.5774
	--> Epoch [12/100], Loss: 0.4784, Validation Loss: 0.5654
	--> Epoch [13/100], Loss: 0.4094, Validation Loss: 0.5588
	--> Epoch [14/100], Loss: 0.4212, Validation Loss: 0.5526
	--> Epoch [15/100], Loss: 0.4337, Validation Loss: 0.5416
	--> Epoch [16/100], Loss: 0.4113, Validation Loss: 0.5360
	--> Epoch [17/100], Loss: 0.4667, Validation Loss: 0.5271
	--> Epoch [18/100], Loss: 0.3396, Validation Loss: 0.5245
	--> Epoch [19/100], Loss: 0.3344, Validation Loss: 0.5146
	--> Epoch [20/100], Loss: 0.2076, Validation Loss: 0.5038
	--> Epoch [21/100], Loss: 0.2138, Validation Loss: 0.5030
	--> Epoch [22/100], Loss: 0.3193, Validation Loss: 0.4939
	--> Epoch [23/100], Loss: 0.2601, Validation Loss: 0.4860
	--> Epoch [24/100], Loss: 0.2587, Validation Loss: 0.4784
	--> Epoch [25/100], Loss: 0.3651, Validation Loss: 0.4780
	--> Epoch [26/100], Loss: 0.2292, Validation Loss: 0.4766
	--> Epoch [27/100], Loss: 0.2593, Validation Loss: 0.4729
	--> Epoch [28/100], Loss: 0.1930, Validation Loss: 0.4668
	--> Epoch [29/100], Loss: 0.2190, Validation Loss: 0.4625
	--> Epoch [30/100], Loss: 0.3420, Validation Loss: 0.4593
	--> Epoch [31/100], Loss: 0.3168, Validation Loss: 0.4510
	--> Epoch [32/100], Loss: 0.2010, Validation Loss: 0.4456
	--> Epoch [33/100], Loss: 0.1972, Validation Loss: 0.4419
	--> Epoch [34/100], Loss: 0.2071, Validation Loss: 0.4347
	--> Epoch [35/100], Loss: 0.1784, Validation Loss: 0.4306
	--> Epoch [36/100], Loss: 0.2754, Validation Loss: 0.4270
	--> Epoch [37/100], Loss: 0.2326, Validation Loss: 0.4216
	--> Epoch [38/100], Loss: 0.2843, Validation Loss: 0.4174
	--> Epoch [39/100], Loss: 0.2423, Validation Loss: 0.4122
	--> Epoch [40/100], Loss: 0.1615, Validation Loss: 0.4104
	--> Epoch [41/100], Loss: 0.2709, Validation Loss: 0.4051
	--> Epoch [42/100], Loss: 0.2713, Validation Loss: 0.4051
	--> Epoch [43/100], Loss: 0.1732, Validation Loss: 0.4033
	--> Epoch [44/100], Loss: 0.2162, Validation Loss: 0.4030
	--> Epoch [45/100], Loss: 0.1513, Validation Loss: 0.3983
	--> Epoch [46/100], Loss: 0.2398, Validation Loss: 0.3945
	--> Epoch [47/100], Loss: 0.2834, Validation Loss: 0.3905
	--> Epoch [48/100], Loss: 0.3129, Validation Loss: 0.3866
	--> Epoch [49/100], Loss: 0.1379, Validation Loss: 0.3802
	--> Epoch [50/100], Loss: 0.2648, Validation Loss: 0.3776
	--> Epoch [51/100], Loss: 0.2323, Validation Loss: 0.3762
	--> Epoch [52/100], Loss: 0.2299, Validation Loss: 0.3763
	--> Epoch [53/100], Loss: 0.1026, Validation Loss: 0.3755
	--> Epoch [54/100], Loss: 0.1444, Validation Loss: 0.3716
	--> Epoch [55/100], Loss: 0.2096, Validation Loss: 0.3690
	--> Epoch [56/100], Loss: 0.2026, Validation Loss: 0.3674
	--> Epoch [57/100], Loss: 0.1582, Validation Loss: 0.3649
	--> Epoch [58/100], Loss: 0.3112, Validation Loss: 0.3610
	--> Epoch [59/100], Loss: 0.2222, Validation Loss: 0.3673
	--> Epoch [60/100], Loss: 0.2400, Validation Loss: 0.3654
	--> Epoch [61/100], Loss: 0.0847, Validation Loss: 0.3637
Early stopping
	--> Training for Fold 3 took 0.6244034767150879 sec, using 61 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6960, Validation Loss: 0.6516
	--> Epoch [2/100], Loss: 0.6062, Validation Loss: 0.6347
	--> Epoch [3/100], Loss: 0.7375, Validation Loss: 0.6172
	--> Epoch [4/100], Loss: 0.5723, Validation Loss: 0.6036
	--> Epoch [5/100], Loss: 0.5625, Validation Loss: 0.5910
	--> Epoch [6/100], Loss: 0.5608, Validation Loss: 0.5743
	--> Epoch [7/100], Loss: 0.6188, Validation Loss: 0.5648
	--> Epoch [8/100], Loss: 0.4112, Validation Loss: 0.5436
	--> Epoch [9/100], Loss: 0.3841, Validation Loss: 0.5328
	--> Epoch [10/100], Loss: 0.4436, Validation Loss: 0.5149
	--> Epoch [11/100], Loss: 0.4460, Validation Loss: 0.5037
	--> Epoch [12/100], Loss: 0.3911, Validation Loss: 0.5002
	--> Epoch [13/100], Loss: 0.3362, Validation Loss: 0.4938
	--> Epoch [14/100], Loss: 0.4292, Validation Loss: 0.4857
	--> Epoch [15/100], Loss: 0.2824, Validation Loss: 0.4768
	--> Epoch [16/100], Loss: 0.3459, Validation Loss: 0.4781
	--> Epoch [17/100], Loss: 0.2432, Validation Loss: 0.4656
	--> Epoch [18/100], Loss: 0.3282, Validation Loss: 0.4533
	--> Epoch [19/100], Loss: 0.2833, Validation Loss: 0.4459
	--> Epoch [20/100], Loss: 0.3249, Validation Loss: 0.4432
	--> Epoch [21/100], Loss: 0.2901, Validation Loss: 0.4358
	--> Epoch [22/100], Loss: 0.2889, Validation Loss: 0.4258
	--> Epoch [23/100], Loss: 0.2545, Validation Loss: 0.4202
	--> Epoch [24/100], Loss: 0.1837, Validation Loss: 0.4076
	--> Epoch [25/100], Loss: 0.1713, Validation Loss: 0.4053
	--> Epoch [26/100], Loss: 0.2866, Validation Loss: 0.3962
	--> Epoch [27/100], Loss: 0.2764, Validation Loss: 0.3940
	--> Epoch [28/100], Loss: 0.2254, Validation Loss: 0.3877
	--> Epoch [29/100], Loss: 0.1621, Validation Loss: 0.3819
	--> Epoch [30/100], Loss: 0.2805, Validation Loss: 0.3764
	--> Epoch [31/100], Loss: 0.2102, Validation Loss: 0.3708
	--> Epoch [32/100], Loss: 0.2902, Validation Loss: 0.3664
	--> Epoch [33/100], Loss: 0.1667, Validation Loss: 0.3665
	--> Epoch [34/100], Loss: 0.3707, Validation Loss: 0.3666
	--> Epoch [35/100], Loss: 0.0821, Validation Loss: 0.3586
	--> Epoch [36/100], Loss: 0.2271, Validation Loss: 0.3542
	--> Epoch [37/100], Loss: 0.1995, Validation Loss: 0.3479
	--> Epoch [38/100], Loss: 0.2204, Validation Loss: 0.3436
	--> Epoch [39/100], Loss: 0.1668, Validation Loss: 0.3443
	--> Epoch [40/100], Loss: 0.2032, Validation Loss: 0.3383
	--> Epoch [41/100], Loss: 0.2450, Validation Loss: 0.3338
	--> Epoch [42/100], Loss: 0.1399, Validation Loss: 0.3291
	--> Epoch [43/100], Loss: 0.1632, Validation Loss: 0.3277
	--> Epoch [44/100], Loss: 0.1894, Validation Loss: 0.3248
	--> Epoch [45/100], Loss: 0.1895, Validation Loss: 0.3256
	--> Epoch [46/100], Loss: 0.2065, Validation Loss: 0.3222
	--> Epoch [47/100], Loss: 0.1601, Validation Loss: 0.3203
	--> Epoch [48/100], Loss: 0.1412, Validation Loss: 0.3161
	--> Epoch [49/100], Loss: 0.2541, Validation Loss: 0.3173
	--> Epoch [50/100], Loss: 0.3057, Validation Loss: 0.3158
	--> Epoch [51/100], Loss: 0.2372, Validation Loss: 0.3151
	--> Epoch [52/100], Loss: 0.0641, Validation Loss: 0.3093
	--> Epoch [53/100], Loss: 0.1443, Validation Loss: 0.3075
	--> Epoch [54/100], Loss: 0.2271, Validation Loss: 0.3097
	--> Epoch [55/100], Loss: 0.1150, Validation Loss: 0.3047
	--> Epoch [56/100], Loss: 0.1807, Validation Loss: 0.2997
	--> Epoch [57/100], Loss: 0.1139, Validation Loss: 0.3018
	--> Epoch [58/100], Loss: 0.1765, Validation Loss: 0.2965
	--> Epoch [59/100], Loss: 0.0813, Validation Loss: 0.2946
	--> Epoch [60/100], Loss: 0.1386, Validation Loss: 0.2926
	--> Epoch [61/100], Loss: 0.1374, Validation Loss: 0.2897
	--> Epoch [62/100], Loss: 0.1362, Validation Loss: 0.2872
	--> Epoch [63/100], Loss: 0.1272, Validation Loss: 0.2845
	--> Epoch [64/100], Loss: 0.1740, Validation Loss: 0.2830
	--> Epoch [65/100], Loss: 0.1840, Validation Loss: 0.2819
	--> Epoch [66/100], Loss: 0.1791, Validation Loss: 0.2793
	--> Epoch [67/100], Loss: 0.1636, Validation Loss: 0.2772
	--> Epoch [68/100], Loss: 0.1230, Validation Loss: 0.2746
	--> Epoch [69/100], Loss: 0.1437, Validation Loss: 0.2768
	--> Epoch [70/100], Loss: 0.2578, Validation Loss: 0.2733
	--> Epoch [71/100], Loss: 0.1740, Validation Loss: 0.2715
	--> Epoch [72/100], Loss: 0.0886, Validation Loss: 0.2719
	--> Epoch [73/100], Loss: 0.1212, Validation Loss: 0.2799
	--> Epoch [74/100], Loss: 0.1123, Validation Loss: 0.2805
Early stopping
	--> Training for Fold 4 took 0.7683541774749756 sec, using 74 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5928, Validation Loss: 0.8346
	--> Epoch [2/100], Loss: 0.5840, Validation Loss: 0.8218
	--> Epoch [3/100], Loss: 0.5102, Validation Loss: 0.8081
	--> Epoch [4/100], Loss: 0.4520, Validation Loss: 0.7909
	--> Epoch [5/100], Loss: 0.4327, Validation Loss: 0.7797
	--> Epoch [6/100], Loss: 0.4326, Validation Loss: 0.7665
	--> Epoch [7/100], Loss: 0.4204, Validation Loss: 0.7603
	--> Epoch [8/100], Loss: 0.3928, Validation Loss: 0.7518
	--> Epoch [9/100], Loss: 0.3303, Validation Loss: 0.7427
	--> Epoch [10/100], Loss: 0.4637, Validation Loss: 0.7338
	--> Epoch [11/100], Loss: 0.3475, Validation Loss: 0.7269
	--> Epoch [12/100], Loss: 0.3521, Validation Loss: 0.7210
	--> Epoch [13/100], Loss: 0.3390, Validation Loss: 0.7136
	--> Epoch [14/100], Loss: 0.3660, Validation Loss: 0.7080
	--> Epoch [15/100], Loss: 0.2775, Validation Loss: 0.7018
	--> Epoch [16/100], Loss: 0.3429, Validation Loss: 0.6952
	--> Epoch [17/100], Loss: 0.2551, Validation Loss: 0.6902
	--> Epoch [18/100], Loss: 0.2709, Validation Loss: 0.6866
	--> Epoch [19/100], Loss: 0.3526, Validation Loss: 0.6846
	--> Epoch [20/100], Loss: 0.3036, Validation Loss: 0.6772
	--> Epoch [21/100], Loss: 0.3309, Validation Loss: 0.6762
	--> Epoch [22/100], Loss: 0.3107, Validation Loss: 0.6726
	--> Epoch [23/100], Loss: 0.1315, Validation Loss: 0.6673
	--> Epoch [24/100], Loss: 0.1429, Validation Loss: 0.6634
	--> Epoch [25/100], Loss: 0.1778, Validation Loss: 0.6605
	--> Epoch [26/100], Loss: 0.2352, Validation Loss: 0.6577
	--> Epoch [27/100], Loss: 0.1718, Validation Loss: 0.6564
	--> Epoch [28/100], Loss: 0.2163, Validation Loss: 0.6507
	--> Epoch [29/100], Loss: 0.1570, Validation Loss: 0.6509
	--> Epoch [30/100], Loss: 0.3630, Validation Loss: 0.6480
	--> Epoch [31/100], Loss: 0.1807, Validation Loss: 0.6471
	--> Epoch [32/100], Loss: 0.3189, Validation Loss: 0.6406
	--> Epoch [33/100], Loss: 0.1502, Validation Loss: 0.6438
	--> Epoch [34/100], Loss: 0.1618, Validation Loss: 0.6399
	--> Epoch [35/100], Loss: 0.2467, Validation Loss: 0.6453
	--> Epoch [36/100], Loss: 0.1930, Validation Loss: 0.6438
	--> Epoch [37/100], Loss: 0.1335, Validation Loss: 0.6445
Early stopping
	--> Training for Fold 5 took 0.369112491607666 sec, using 37 epochs

Median number of epochs used: 74 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/74], Loss: 0.6173
	--> Final training Epoch [2/74], Loss: 0.6315
	--> Final training Epoch [3/74], Loss: 0.6459
	--> Final training Epoch [4/74], Loss: 0.6151
	--> Final training Epoch [5/74], Loss: 0.6049
	--> Final training Epoch [6/74], Loss: 0.5787
	--> Final training Epoch [7/74], Loss: 0.5743
	--> Final training Epoch [8/74], Loss: 0.5318
	--> Final training Epoch [9/74], Loss: 0.5959
	--> Final training Epoch [10/74], Loss: 0.5198
	--> Final training Epoch [11/74], Loss: 0.5123
	--> Final training Epoch [12/74], Loss: 0.4711
	--> Final training Epoch [13/74], Loss: 0.4247
	--> Final training Epoch [14/74], Loss: 0.4357
	--> Final training Epoch [15/74], Loss: 0.3948
	--> Final training Epoch [16/74], Loss: 0.4267
	--> Final training Epoch [17/74], Loss: 0.3819
	--> Final training Epoch [18/74], Loss: 0.3810
	--> Final training Epoch [19/74], Loss: 0.4210
	--> Final training Epoch [20/74], Loss: 0.3352
	--> Final training Epoch [21/74], Loss: 0.4048
	--> Final training Epoch [22/74], Loss: 0.3791
	--> Final training Epoch [23/74], Loss: 0.3689
	--> Final training Epoch [24/74], Loss: 0.3418
	--> Final training Epoch [25/74], Loss: 0.3207
	--> Final training Epoch [26/74], Loss: 0.3009
	--> Final training Epoch [27/74], Loss: 0.3432
	--> Final training Epoch [28/74], Loss: 0.3185
	--> Final training Epoch [29/74], Loss: 0.2780
	--> Final training Epoch [30/74], Loss: 0.3504
	--> Final training Epoch [31/74], Loss: 0.2442
	--> Final training Epoch [32/74], Loss: 0.2238
	--> Final training Epoch [33/74], Loss: 0.2833
	--> Final training Epoch [34/74], Loss: 0.2732
	--> Final training Epoch [35/74], Loss: 0.2945
	--> Final training Epoch [36/74], Loss: 0.2450
	--> Final training Epoch [37/74], Loss: 0.2112
	--> Final training Epoch [38/74], Loss: 0.2900
	--> Final training Epoch [39/74], Loss: 0.2829
	--> Final training Epoch [40/74], Loss: 0.2738
	--> Final training Epoch [41/74], Loss: 0.2914
	--> Final training Epoch [42/74], Loss: 0.2430
	--> Final training Epoch [43/74], Loss: 0.2478
	--> Final training Epoch [44/74], Loss: 0.2305
	--> Final training Epoch [45/74], Loss: 0.1964
	--> Final training Epoch [46/74], Loss: 0.1465
	--> Final training Epoch [47/74], Loss: 0.2167
	--> Final training Epoch [48/74], Loss: 0.1813
	--> Final training Epoch [49/74], Loss: 0.1849
	--> Final training Epoch [50/74], Loss: 0.1783
	--> Final training Epoch [51/74], Loss: 0.1506
	--> Final training Epoch [52/74], Loss: 0.2052
	--> Final training Epoch [53/74], Loss: 0.2031
	--> Final training Epoch [54/74], Loss: 0.2326
	--> Final training Epoch [55/74], Loss: 0.1951
	--> Final training Epoch [56/74], Loss: 0.2130
	--> Final training Epoch [57/74], Loss: 0.1305
	--> Final training Epoch [58/74], Loss: 0.2202
	--> Final training Epoch [59/74], Loss: 0.2057
	--> Final training Epoch [60/74], Loss: 0.2363
	--> Final training Epoch [61/74], Loss: 0.1483
	--> Final training Epoch [62/74], Loss: 0.1448
	--> Final training Epoch [63/74], Loss: 0.1718
	--> Final training Epoch [64/74], Loss: 0.1620
	--> Final training Epoch [65/74], Loss: 0.2421
	--> Final training Epoch [66/74], Loss: 0.1028
	--> Final training Epoch [67/74], Loss: 0.1358
	--> Final training Epoch [68/74], Loss: 0.1979
	--> Final training Epoch [69/74], Loss: 0.1665
	--> Final training Epoch [70/74], Loss: 0.1101
	--> Final training Epoch [71/74], Loss: 0.1214
	--> Final training Epoch [72/74], Loss: 0.0720
	--> Final training Epoch [73/74], Loss: 0.1098
	--> Final training Epoch [74/74], Loss: 0.1247

Final training took 0.7237203121185303 sec

TESTING
	--> Testing took 0.0094 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9218
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3483,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3483
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8164, Validation Loss: 0.4645,  Current Best Accuracy: 0.8491,  Current Best Validation Loss: 0.3483

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6972, Validation Loss: 0.7125
	--> Epoch [2/100], Loss: 0.7164, Validation Loss: 0.6922
	--> Epoch [3/100], Loss: 0.6542, Validation Loss: 0.6779
	--> Epoch [4/100], Loss: 0.6723, Validation Loss: 0.6577
	--> Epoch [5/100], Loss: 0.5525, Validation Loss: 0.6481
	--> Epoch [6/100], Loss: 0.6011, Validation Loss: 0.6364
	--> Epoch [7/100], Loss: 0.5738, Validation Loss: 0.6265
	--> Epoch [8/100], Loss: 0.4625, Validation Loss: 0.6146
	--> Epoch [9/100], Loss: 0.5110, Validation Loss: 0.6044
	--> Epoch [10/100], Loss: 0.4377, Validation Loss: 0.5897
	--> Epoch [11/100], Loss: 0.7198, Validation Loss: 0.5801
	--> Epoch [12/100], Loss: 0.4263, Validation Loss: 0.5721
	--> Epoch [13/100], Loss: 0.5552, Validation Loss: 0.5631
	--> Epoch [14/100], Loss: 0.5875, Validation Loss: 0.5577
	--> Epoch [15/100], Loss: 0.5204, Validation Loss: 0.5538
	--> Epoch [16/100], Loss: 0.3717, Validation Loss: 0.5464
	--> Epoch [17/100], Loss: 0.5452, Validation Loss: 0.5390
	--> Epoch [18/100], Loss: 0.3684, Validation Loss: 0.5289
	--> Epoch [19/100], Loss: 0.4881, Validation Loss: 0.5268
	--> Epoch [20/100], Loss: 0.3649, Validation Loss: 0.5224
	--> Epoch [21/100], Loss: 0.4127, Validation Loss: 0.5159
	--> Epoch [22/100], Loss: 0.3377, Validation Loss: 0.5024
	--> Epoch [23/100], Loss: 0.3827, Validation Loss: 0.4959
	--> Epoch [24/100], Loss: 0.4741, Validation Loss: 0.4916
	--> Epoch [25/100], Loss: 0.3376, Validation Loss: 0.4884
	--> Epoch [26/100], Loss: 0.3297, Validation Loss: 0.4855
	--> Epoch [27/100], Loss: 0.4333, Validation Loss: 0.4817
	--> Epoch [28/100], Loss: 0.3252, Validation Loss: 0.4750
	--> Epoch [29/100], Loss: 0.3307, Validation Loss: 0.4685
	--> Epoch [30/100], Loss: 0.1933, Validation Loss: 0.4620
	--> Epoch [31/100], Loss: 0.4439, Validation Loss: 0.4607
	--> Epoch [32/100], Loss: 0.3938, Validation Loss: 0.4533
	--> Epoch [33/100], Loss: 0.4047, Validation Loss: 0.4506
	--> Epoch [34/100], Loss: 0.3959, Validation Loss: 0.4479
	--> Epoch [35/100], Loss: 0.2205, Validation Loss: 0.4433
	--> Epoch [36/100], Loss: 0.3052, Validation Loss: 0.4418
	--> Epoch [37/100], Loss: 0.2843, Validation Loss: 0.4335
	--> Epoch [38/100], Loss: 0.3712, Validation Loss: 0.4332
	--> Epoch [39/100], Loss: 0.4312, Validation Loss: 0.4290
	--> Epoch [40/100], Loss: 0.2666, Validation Loss: 0.4251
	--> Epoch [41/100], Loss: 0.3170, Validation Loss: 0.4238
	--> Epoch [42/100], Loss: 0.3572, Validation Loss: 0.4212
	--> Epoch [43/100], Loss: 0.3863, Validation Loss: 0.4142
	--> Epoch [44/100], Loss: 0.4206, Validation Loss: 0.4135
	--> Epoch [45/100], Loss: 0.3978, Validation Loss: 0.4088
	--> Epoch [46/100], Loss: 0.3102, Validation Loss: 0.4063
	--> Epoch [47/100], Loss: 0.3244, Validation Loss: 0.4040
	--> Epoch [48/100], Loss: 0.4756, Validation Loss: 0.4006
	--> Epoch [49/100], Loss: 0.4509, Validation Loss: 0.3975
	--> Epoch [50/100], Loss: 0.2661, Validation Loss: 0.3934
	--> Epoch [51/100], Loss: 0.3283, Validation Loss: 0.3914
	--> Epoch [52/100], Loss: 0.4183, Validation Loss: 0.3885
	--> Epoch [53/100], Loss: 0.3139, Validation Loss: 0.3879
	--> Epoch [54/100], Loss: 0.4169, Validation Loss: 0.3854
	--> Epoch [55/100], Loss: 0.4044, Validation Loss: 0.3817
	--> Epoch [56/100], Loss: 0.2576, Validation Loss: 0.3814
	--> Epoch [57/100], Loss: 0.1560, Validation Loss: 0.3797
	--> Epoch [58/100], Loss: 0.6054, Validation Loss: 0.3777
	--> Epoch [59/100], Loss: 0.4747, Validation Loss: 0.3763
	--> Epoch [60/100], Loss: 0.2905, Validation Loss: 0.3753
	--> Epoch [61/100], Loss: 0.2776, Validation Loss: 0.3727
	--> Epoch [62/100], Loss: 0.2884, Validation Loss: 0.3730
	--> Epoch [63/100], Loss: 0.2826, Validation Loss: 0.3725
	--> Epoch [64/100], Loss: 0.2949, Validation Loss: 0.3723
	--> Epoch [65/100], Loss: 0.2178, Validation Loss: 0.3704
	--> Epoch [66/100], Loss: 0.1035, Validation Loss: 0.3710
	--> Epoch [67/100], Loss: 0.3469, Validation Loss: 0.3688
	--> Epoch [68/100], Loss: 0.2799, Validation Loss: 0.3673
	--> Epoch [69/100], Loss: 0.3668, Validation Loss: 0.3665
	--> Epoch [70/100], Loss: 0.3386, Validation Loss: 0.3662
	--> Epoch [71/100], Loss: 0.4110, Validation Loss: 0.3662
	--> Epoch [72/100], Loss: 0.2940, Validation Loss: 0.3646
	--> Epoch [73/100], Loss: 0.2871, Validation Loss: 0.3619
	--> Epoch [74/100], Loss: 0.2736, Validation Loss: 0.3617
	--> Epoch [75/100], Loss: 0.3996, Validation Loss: 0.3600
	--> Epoch [76/100], Loss: 0.3960, Validation Loss: 0.3554
	--> Epoch [77/100], Loss: 0.2817, Validation Loss: 0.3555
	--> Epoch [78/100], Loss: 0.2611, Validation Loss: 0.3561
	--> Epoch [79/100], Loss: 0.4066, Validation Loss: 0.3559
Early stopping
	--> Training for Fold 1 took 0.7718300819396973 sec, using 79 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7051, Validation Loss: 0.6794
	--> Epoch [2/100], Loss: 0.6453, Validation Loss: 0.6546
	--> Epoch [3/100], Loss: 0.7588, Validation Loss: 0.6418
	--> Epoch [4/100], Loss: 0.6629, Validation Loss: 0.6160
	--> Epoch [5/100], Loss: 0.6215, Validation Loss: 0.6015
	--> Epoch [6/100], Loss: 0.6276, Validation Loss: 0.5897
	--> Epoch [7/100], Loss: 0.6272, Validation Loss: 0.5733
	--> Epoch [8/100], Loss: 0.6049, Validation Loss: 0.5630
	--> Epoch [9/100], Loss: 0.4329, Validation Loss: 0.5502
	--> Epoch [10/100], Loss: 0.6470, Validation Loss: 0.5385
	--> Epoch [11/100], Loss: 0.3838, Validation Loss: 0.5294
	--> Epoch [12/100], Loss: 0.4866, Validation Loss: 0.5179
	--> Epoch [13/100], Loss: 0.6398, Validation Loss: 0.5102
	--> Epoch [14/100], Loss: 0.6245, Validation Loss: 0.5056
	--> Epoch [15/100], Loss: 0.4651, Validation Loss: 0.4970
	--> Epoch [16/100], Loss: 0.4638, Validation Loss: 0.4924
	--> Epoch [17/100], Loss: 0.4107, Validation Loss: 0.4854
	--> Epoch [18/100], Loss: 0.3610, Validation Loss: 0.4769
	--> Epoch [19/100], Loss: 0.5389, Validation Loss: 0.4721
	--> Epoch [20/100], Loss: 0.4277, Validation Loss: 0.4651
	--> Epoch [21/100], Loss: 0.4889, Validation Loss: 0.4601
	--> Epoch [22/100], Loss: 0.3728, Validation Loss: 0.4534
	--> Epoch [23/100], Loss: 0.3793, Validation Loss: 0.4494
	--> Epoch [24/100], Loss: 0.2980, Validation Loss: 0.4437
	--> Epoch [25/100], Loss: 0.3669, Validation Loss: 0.4377
	--> Epoch [26/100], Loss: 0.5001, Validation Loss: 0.4331
	--> Epoch [27/100], Loss: 0.2818, Validation Loss: 0.4276
	--> Epoch [28/100], Loss: 0.3382, Validation Loss: 0.4219
	--> Epoch [29/100], Loss: 0.4634, Validation Loss: 0.4168
	--> Epoch [30/100], Loss: 0.4885, Validation Loss: 0.4153
	--> Epoch [31/100], Loss: 0.3659, Validation Loss: 0.4080
	--> Epoch [32/100], Loss: 0.3000, Validation Loss: 0.4043
	--> Epoch [33/100], Loss: 0.4153, Validation Loss: 0.4012
	--> Epoch [34/100], Loss: 0.4638, Validation Loss: 0.3952
	--> Epoch [35/100], Loss: 0.3345, Validation Loss: 0.3922
	--> Epoch [36/100], Loss: 0.5057, Validation Loss: 0.3865
	--> Epoch [37/100], Loss: 0.2932, Validation Loss: 0.3812
	--> Epoch [38/100], Loss: 0.4266, Validation Loss: 0.3742
	--> Epoch [39/100], Loss: 0.2608, Validation Loss: 0.3735
	--> Epoch [40/100], Loss: 0.3559, Validation Loss: 0.3704
	--> Epoch [41/100], Loss: 0.3300, Validation Loss: 0.3670
	--> Epoch [42/100], Loss: 0.4366, Validation Loss: 0.3668
	--> Epoch [43/100], Loss: 0.5036, Validation Loss: 0.3641
	--> Epoch [44/100], Loss: 0.2454, Validation Loss: 0.3636
	--> Epoch [45/100], Loss: 0.3484, Validation Loss: 0.3614
	--> Epoch [46/100], Loss: 0.2627, Validation Loss: 0.3576
	--> Epoch [47/100], Loss: 0.2554, Validation Loss: 0.3542
	--> Epoch [48/100], Loss: 0.4251, Validation Loss: 0.3499
	--> Epoch [49/100], Loss: 0.3835, Validation Loss: 0.3493
	--> Epoch [50/100], Loss: 0.4040, Validation Loss: 0.3531
	--> Epoch [51/100], Loss: 0.2556, Validation Loss: 0.3505
	--> Epoch [52/100], Loss: 0.1858, Validation Loss: 0.3491
	--> Epoch [53/100], Loss: 0.3055, Validation Loss: 0.3463
	--> Epoch [54/100], Loss: 0.1795, Validation Loss: 0.3466
	--> Epoch [55/100], Loss: 0.2969, Validation Loss: 0.3430
	--> Epoch [56/100], Loss: 0.3663, Validation Loss: 0.3390
	--> Epoch [57/100], Loss: 0.1737, Validation Loss: 0.3385
	--> Epoch [58/100], Loss: 0.2269, Validation Loss: 0.3407
	--> Epoch [59/100], Loss: 0.3053, Validation Loss: 0.3379
	--> Epoch [60/100], Loss: 0.2286, Validation Loss: 0.3363
	--> Epoch [61/100], Loss: 0.2334, Validation Loss: 0.3337
	--> Epoch [62/100], Loss: 0.2957, Validation Loss: 0.3326
	--> Epoch [63/100], Loss: 0.3104, Validation Loss: 0.3310
	--> Epoch [64/100], Loss: 0.3487, Validation Loss: 0.3301
	--> Epoch [65/100], Loss: 0.1849, Validation Loss: 0.3305
	--> Epoch [66/100], Loss: 0.4160, Validation Loss: 0.3296
	--> Epoch [67/100], Loss: 0.2908, Validation Loss: 0.3288
	--> Epoch [68/100], Loss: 0.3503, Validation Loss: 0.3285
	--> Epoch [69/100], Loss: 0.3454, Validation Loss: 0.3266
	--> Epoch [70/100], Loss: 0.2110, Validation Loss: 0.3244
	--> Epoch [71/100], Loss: 0.1607, Validation Loss: 0.3245
	--> Epoch [72/100], Loss: 0.2772, Validation Loss: 0.3240
	--> Epoch [73/100], Loss: 0.0848, Validation Loss: 0.3228
	--> Epoch [74/100], Loss: 0.2266, Validation Loss: 0.3223
	--> Epoch [75/100], Loss: 0.2827, Validation Loss: 0.3175
	--> Epoch [76/100], Loss: 0.2190, Validation Loss: 0.3170
	--> Epoch [77/100], Loss: 0.1459, Validation Loss: 0.3152
	--> Epoch [78/100], Loss: 0.3427, Validation Loss: 0.3154
	--> Epoch [79/100], Loss: 0.3535, Validation Loss: 0.3132
	--> Epoch [80/100], Loss: 0.2736, Validation Loss: 0.3145
	--> Epoch [81/100], Loss: 0.1425, Validation Loss: 0.3143
	--> Epoch [82/100], Loss: 0.2823, Validation Loss: 0.3101
	--> Epoch [83/100], Loss: 0.4109, Validation Loss: 0.3099
	--> Epoch [84/100], Loss: 0.1432, Validation Loss: 0.3070
	--> Epoch [85/100], Loss: 0.1443, Validation Loss: 0.3082
	--> Epoch [86/100], Loss: 0.3376, Validation Loss: 0.3075
	--> Epoch [87/100], Loss: 0.2031, Validation Loss: 0.3042
	--> Epoch [88/100], Loss: 0.4073, Validation Loss: 0.3048
	--> Epoch [89/100], Loss: 0.2658, Validation Loss: 0.3051
	--> Epoch [90/100], Loss: 0.2149, Validation Loss: 0.3050
Early stopping
	--> Training for Fold 2 took 0.9158282279968262 sec, using 90 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6265, Validation Loss: 0.7257
	--> Epoch [2/100], Loss: 0.6516, Validation Loss: 0.7152
	--> Epoch [3/100], Loss: 0.7725, Validation Loss: 0.6977
	--> Epoch [4/100], Loss: 0.5714, Validation Loss: 0.6817
	--> Epoch [5/100], Loss: 0.5791, Validation Loss: 0.6701
	--> Epoch [6/100], Loss: 0.5212, Validation Loss: 0.6613
	--> Epoch [7/100], Loss: 0.6591, Validation Loss: 0.6503
	--> Epoch [8/100], Loss: 0.5600, Validation Loss: 0.6415
	--> Epoch [9/100], Loss: 0.4997, Validation Loss: 0.6346
	--> Epoch [10/100], Loss: 0.4543, Validation Loss: 0.6280
	--> Epoch [11/100], Loss: 0.4773, Validation Loss: 0.6206
	--> Epoch [12/100], Loss: 0.4209, Validation Loss: 0.6160
	--> Epoch [13/100], Loss: 0.4839, Validation Loss: 0.6079
	--> Epoch [14/100], Loss: 0.5497, Validation Loss: 0.5974
	--> Epoch [15/100], Loss: 0.5437, Validation Loss: 0.5894
	--> Epoch [16/100], Loss: 0.4877, Validation Loss: 0.5805
	--> Epoch [17/100], Loss: 0.4989, Validation Loss: 0.5750
	--> Epoch [18/100], Loss: 0.4375, Validation Loss: 0.5651
	--> Epoch [19/100], Loss: 0.4741, Validation Loss: 0.5610
	--> Epoch [20/100], Loss: 0.3628, Validation Loss: 0.5539
	--> Epoch [21/100], Loss: 0.5097, Validation Loss: 0.5497
	--> Epoch [22/100], Loss: 0.4962, Validation Loss: 0.5436
	--> Epoch [23/100], Loss: 0.4796, Validation Loss: 0.5359
	--> Epoch [24/100], Loss: 0.4317, Validation Loss: 0.5302
	--> Epoch [25/100], Loss: 0.4222, Validation Loss: 0.5248
	--> Epoch [26/100], Loss: 0.4701, Validation Loss: 0.5170
	--> Epoch [27/100], Loss: 0.3741, Validation Loss: 0.5106
	--> Epoch [28/100], Loss: 0.3956, Validation Loss: 0.5028
	--> Epoch [29/100], Loss: 0.4737, Validation Loss: 0.4975
	--> Epoch [30/100], Loss: 0.3458, Validation Loss: 0.4925
	--> Epoch [31/100], Loss: 0.2561, Validation Loss: 0.4881
	--> Epoch [32/100], Loss: 0.4377, Validation Loss: 0.4888
	--> Epoch [33/100], Loss: 0.4137, Validation Loss: 0.4847
	--> Epoch [34/100], Loss: 0.3642, Validation Loss: 0.4829
	--> Epoch [35/100], Loss: 0.3444, Validation Loss: 0.4789
	--> Epoch [36/100], Loss: 0.4024, Validation Loss: 0.4757
	--> Epoch [37/100], Loss: 0.2653, Validation Loss: 0.4714
	--> Epoch [38/100], Loss: 0.3231, Validation Loss: 0.4690
	--> Epoch [39/100], Loss: 0.4442, Validation Loss: 0.4632
	--> Epoch [40/100], Loss: 0.2131, Validation Loss: 0.4607
	--> Epoch [41/100], Loss: 0.2304, Validation Loss: 0.4569
	--> Epoch [42/100], Loss: 0.4431, Validation Loss: 0.4511
	--> Epoch [43/100], Loss: 0.2077, Validation Loss: 0.4486
	--> Epoch [44/100], Loss: 0.3689, Validation Loss: 0.4460
	--> Epoch [45/100], Loss: 0.1788, Validation Loss: 0.4463
	--> Epoch [46/100], Loss: 0.2535, Validation Loss: 0.4438
	--> Epoch [47/100], Loss: 0.4516, Validation Loss: 0.4417
	--> Epoch [48/100], Loss: 0.3252, Validation Loss: 0.4407
	--> Epoch [49/100], Loss: 0.3270, Validation Loss: 0.4399
	--> Epoch [50/100], Loss: 0.2202, Validation Loss: 0.4377
	--> Epoch [51/100], Loss: 0.1990, Validation Loss: 0.4359
	--> Epoch [52/100], Loss: 0.3168, Validation Loss: 0.4368
	--> Epoch [53/100], Loss: 0.3994, Validation Loss: 0.4346
	--> Epoch [54/100], Loss: 0.3144, Validation Loss: 0.4346
	--> Epoch [55/100], Loss: 0.2602, Validation Loss: 0.4331
	--> Epoch [56/100], Loss: 0.2703, Validation Loss: 0.4331
	--> Epoch [57/100], Loss: 0.3274, Validation Loss: 0.4323
	--> Epoch [58/100], Loss: 0.3365, Validation Loss: 0.4308
	--> Epoch [59/100], Loss: 0.3478, Validation Loss: 0.4283
	--> Epoch [60/100], Loss: 0.3181, Validation Loss: 0.4277
	--> Epoch [61/100], Loss: 0.4149, Validation Loss: 0.4293
	--> Epoch [62/100], Loss: 0.2184, Validation Loss: 0.4280
	--> Epoch [63/100], Loss: 0.1458, Validation Loss: 0.4266
	--> Epoch [64/100], Loss: 0.2623, Validation Loss: 0.4248
	--> Epoch [65/100], Loss: 0.3277, Validation Loss: 0.4246
	--> Epoch [66/100], Loss: 0.3385, Validation Loss: 0.4225
	--> Epoch [67/100], Loss: 0.2551, Validation Loss: 0.4224
	--> Epoch [68/100], Loss: 0.2206, Validation Loss: 0.4203
	--> Epoch [69/100], Loss: 0.2005, Validation Loss: 0.4199
	--> Epoch [70/100], Loss: 0.3204, Validation Loss: 0.4188
	--> Epoch [71/100], Loss: 0.3284, Validation Loss: 0.4186
	--> Epoch [72/100], Loss: 0.1904, Validation Loss: 0.4177
	--> Epoch [73/100], Loss: 0.2649, Validation Loss: 0.4171
	--> Epoch [74/100], Loss: 0.2455, Validation Loss: 0.4174
	--> Epoch [75/100], Loss: 0.1954, Validation Loss: 0.4164
	--> Epoch [76/100], Loss: 0.3031, Validation Loss: 0.4177
	--> Epoch [77/100], Loss: 0.1474, Validation Loss: 0.4168
	--> Epoch [78/100], Loss: 0.2511, Validation Loss: 0.4181
Early stopping
	--> Training for Fold 3 took 0.8065900802612305 sec, using 78 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6059, Validation Loss: 0.7235
	--> Epoch [2/100], Loss: 0.6695, Validation Loss: 0.7054
	--> Epoch [3/100], Loss: 0.6950, Validation Loss: 0.6831
	--> Epoch [4/100], Loss: 0.5161, Validation Loss: 0.6673
	--> Epoch [5/100], Loss: 0.5513, Validation Loss: 0.6620
	--> Epoch [6/100], Loss: 0.4937, Validation Loss: 0.6565
	--> Epoch [7/100], Loss: 0.7320, Validation Loss: 0.6518
	--> Epoch [8/100], Loss: 0.5662, Validation Loss: 0.6579
	--> Epoch [9/100], Loss: 0.3315, Validation Loss: 0.6569
	--> Epoch [10/100], Loss: 0.5255, Validation Loss: 0.6498
	--> Epoch [11/100], Loss: 0.3480, Validation Loss: 0.6481
	--> Epoch [12/100], Loss: 0.3522, Validation Loss: 0.6470
	--> Epoch [13/100], Loss: 0.3735, Validation Loss: 0.6441
	--> Epoch [14/100], Loss: 0.3528, Validation Loss: 0.6435
	--> Epoch [15/100], Loss: 0.4580, Validation Loss: 0.6455
	--> Epoch [16/100], Loss: 0.4840, Validation Loss: 0.6454
	--> Epoch [17/100], Loss: 0.4215, Validation Loss: 0.6397
	--> Epoch [18/100], Loss: 0.3059, Validation Loss: 0.6435
	--> Epoch [19/100], Loss: 0.4479, Validation Loss: 0.6392
	--> Epoch [20/100], Loss: 0.5104, Validation Loss: 0.6391
	--> Epoch [21/100], Loss: 0.4282, Validation Loss: 0.6388
	--> Epoch [22/100], Loss: 0.2774, Validation Loss: 0.6378
	--> Epoch [23/100], Loss: 0.2538, Validation Loss: 0.6374
	--> Epoch [24/100], Loss: 0.5580, Validation Loss: 0.6391
	--> Epoch [25/100], Loss: 0.2850, Validation Loss: 0.6416
	--> Epoch [26/100], Loss: 0.2905, Validation Loss: 0.6444
Early stopping
	--> Training for Fold 4 took 0.30301737785339355 sec, using 26 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6754, Validation Loss: 0.7222
	--> Epoch [2/100], Loss: 0.6394, Validation Loss: 0.7143
	--> Epoch [3/100], Loss: 0.6415, Validation Loss: 0.7015
	--> Epoch [4/100], Loss: 0.5395, Validation Loss: 0.6869
	--> Epoch [5/100], Loss: 0.5610, Validation Loss: 0.6839
	--> Epoch [6/100], Loss: 0.4766, Validation Loss: 0.6782
	--> Epoch [7/100], Loss: 0.5471, Validation Loss: 0.6746
	--> Epoch [8/100], Loss: 0.4977, Validation Loss: 0.6710
	--> Epoch [9/100], Loss: 0.5134, Validation Loss: 0.6685
	--> Epoch [10/100], Loss: 0.4139, Validation Loss: 0.6667
	--> Epoch [11/100], Loss: 0.4591, Validation Loss: 0.6594
	--> Epoch [12/100], Loss: 0.4864, Validation Loss: 0.6604
	--> Epoch [13/100], Loss: 0.4331, Validation Loss: 0.6613
	--> Epoch [14/100], Loss: 0.3913, Validation Loss: 0.6609
Early stopping
	--> Training for Fold 5 took 0.16073393821716309 sec, using 14 epochs

Median number of epochs used: 78 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/78], Loss: 0.8700
	--> Final training Epoch [2/78], Loss: 0.7460
	--> Final training Epoch [3/78], Loss: 0.6878
	--> Final training Epoch [4/78], Loss: 0.6511
	--> Final training Epoch [5/78], Loss: 0.6825
	--> Final training Epoch [6/78], Loss: 0.6385
	--> Final training Epoch [7/78], Loss: 0.6351
	--> Final training Epoch [8/78], Loss: 0.5223
	--> Final training Epoch [9/78], Loss: 0.5844
	--> Final training Epoch [10/78], Loss: 0.5286
	--> Final training Epoch [11/78], Loss: 0.5463
	--> Final training Epoch [12/78], Loss: 0.5505
	--> Final training Epoch [13/78], Loss: 0.5719
	--> Final training Epoch [14/78], Loss: 0.4811
	--> Final training Epoch [15/78], Loss: 0.5299
	--> Final training Epoch [16/78], Loss: 0.5195
	--> Final training Epoch [17/78], Loss: 0.4834
	--> Final training Epoch [18/78], Loss: 0.4365
	--> Final training Epoch [19/78], Loss: 0.5388
	--> Final training Epoch [20/78], Loss: 0.5467
	--> Final training Epoch [21/78], Loss: 0.4016
	--> Final training Epoch [22/78], Loss: 0.5262
	--> Final training Epoch [23/78], Loss: 0.4968
	--> Final training Epoch [24/78], Loss: 0.5350
	--> Final training Epoch [25/78], Loss: 0.4763
	--> Final training Epoch [26/78], Loss: 0.4019
	--> Final training Epoch [27/78], Loss: 0.3780
	--> Final training Epoch [28/78], Loss: 0.4281
	--> Final training Epoch [29/78], Loss: 0.4816
	--> Final training Epoch [30/78], Loss: 0.3673
	--> Final training Epoch [31/78], Loss: 0.4301
	--> Final training Epoch [32/78], Loss: 0.2773
	--> Final training Epoch [33/78], Loss: 0.4022
	--> Final training Epoch [34/78], Loss: 0.4076
	--> Final training Epoch [35/78], Loss: 0.4066
	--> Final training Epoch [36/78], Loss: 0.3827
	--> Final training Epoch [37/78], Loss: 0.3823
	--> Final training Epoch [38/78], Loss: 0.2870
	--> Final training Epoch [39/78], Loss: 0.4251
	--> Final training Epoch [40/78], Loss: 0.4202
	--> Final training Epoch [41/78], Loss: 0.3397
	--> Final training Epoch [42/78], Loss: 0.4026
	--> Final training Epoch [43/78], Loss: 0.3307
	--> Final training Epoch [44/78], Loss: 0.4276
	--> Final training Epoch [45/78], Loss: 0.3580
	--> Final training Epoch [46/78], Loss: 0.2448
	--> Final training Epoch [47/78], Loss: 0.2563
	--> Final training Epoch [48/78], Loss: 0.3455
	--> Final training Epoch [49/78], Loss: 0.2992
	--> Final training Epoch [50/78], Loss: 0.3241
	--> Final training Epoch [51/78], Loss: 0.2651
	--> Final training Epoch [52/78], Loss: 0.3500
	--> Final training Epoch [53/78], Loss: 0.3585
	--> Final training Epoch [54/78], Loss: 0.2203
	--> Final training Epoch [55/78], Loss: 0.3060
	--> Final training Epoch [56/78], Loss: 0.3792
	--> Final training Epoch [57/78], Loss: 0.2983
	--> Final training Epoch [58/78], Loss: 0.2279
	--> Final training Epoch [59/78], Loss: 0.3294
	--> Final training Epoch [60/78], Loss: 0.4508
	--> Final training Epoch [61/78], Loss: 0.4155
	--> Final training Epoch [62/78], Loss: 0.3234
	--> Final training Epoch [63/78], Loss: 0.3255
	--> Final training Epoch [64/78], Loss: 0.3111
	--> Final training Epoch [65/78], Loss: 0.2832
	--> Final training Epoch [66/78], Loss: 0.3274
	--> Final training Epoch [67/78], Loss: 0.4330
	--> Final training Epoch [68/78], Loss: 0.3487
	--> Final training Epoch [69/78], Loss: 0.3579
	--> Final training Epoch [70/78], Loss: 0.3013
	--> Final training Epoch [71/78], Loss: 0.2678
	--> Final training Epoch [72/78], Loss: 0.3211
	--> Final training Epoch [73/78], Loss: 0.3708
	--> Final training Epoch [74/78], Loss: 0.3352
	--> Final training Epoch [75/78], Loss: 0.3274
	--> Final training Epoch [76/78], Loss: 0.2414
	--> Final training Epoch [77/78], Loss: 0.2167
	--> Final training Epoch [78/78], Loss: 0.2792

Final training took 0.9247457981109619 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.7712
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8918, Validation Loss: 0.3612,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3612
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3754,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3612
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8053, Validation Loss: 0.3872,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3612

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6860, Validation Loss: 0.6956
	--> Epoch [2/100], Loss: 0.6326, Validation Loss: 0.6717
	--> Epoch [3/100], Loss: 0.6124, Validation Loss: 0.6487
	--> Epoch [4/100], Loss: 0.6197, Validation Loss: 0.6293
	--> Epoch [5/100], Loss: 0.5156, Validation Loss: 0.6098
	--> Epoch [6/100], Loss: 0.5386, Validation Loss: 0.5969
	--> Epoch [7/100], Loss: 0.4538, Validation Loss: 0.5812
	--> Epoch [8/100], Loss: 0.4617, Validation Loss: 0.5675
	--> Epoch [9/100], Loss: 0.4865, Validation Loss: 0.5540
	--> Epoch [10/100], Loss: 0.3879, Validation Loss: 0.5377
	--> Epoch [11/100], Loss: 0.3803, Validation Loss: 0.5239
	--> Epoch [12/100], Loss: 0.4110, Validation Loss: 0.5074
	--> Epoch [13/100], Loss: 0.3676, Validation Loss: 0.4950
	--> Epoch [14/100], Loss: 0.3411, Validation Loss: 0.4819
	--> Epoch [15/100], Loss: 0.3595, Validation Loss: 0.4672
	--> Epoch [16/100], Loss: 0.2893, Validation Loss: 0.4541
	--> Epoch [17/100], Loss: 0.3398, Validation Loss: 0.4438
	--> Epoch [18/100], Loss: 0.2041, Validation Loss: 0.4329
	--> Epoch [19/100], Loss: 0.2027, Validation Loss: 0.4235
	--> Epoch [20/100], Loss: 0.2435, Validation Loss: 0.4149
	--> Epoch [21/100], Loss: 0.2312, Validation Loss: 0.4088
	--> Epoch [22/100], Loss: 0.2012, Validation Loss: 0.4014
	--> Epoch [23/100], Loss: 0.1377, Validation Loss: 0.3927
	--> Epoch [24/100], Loss: 0.3007, Validation Loss: 0.3856
	--> Epoch [25/100], Loss: 0.2414, Validation Loss: 0.3779
	--> Epoch [26/100], Loss: 0.1983, Validation Loss: 0.3732
	--> Epoch [27/100], Loss: 0.2097, Validation Loss: 0.3688
	--> Epoch [28/100], Loss: 0.2258, Validation Loss: 0.3652
	--> Epoch [29/100], Loss: 0.2275, Validation Loss: 0.3610
	--> Epoch [30/100], Loss: 0.1445, Validation Loss: 0.3581
	--> Epoch [31/100], Loss: 0.1053, Validation Loss: 0.3526
	--> Epoch [32/100], Loss: 0.1229, Validation Loss: 0.3494
	--> Epoch [33/100], Loss: 0.1813, Validation Loss: 0.3423
	--> Epoch [34/100], Loss: 0.1297, Validation Loss: 0.3391
	--> Epoch [35/100], Loss: 0.1229, Validation Loss: 0.3355
	--> Epoch [36/100], Loss: 0.1262, Validation Loss: 0.3318
	--> Epoch [37/100], Loss: 0.1419, Validation Loss: 0.3264
	--> Epoch [38/100], Loss: 0.1669, Validation Loss: 0.3247
	--> Epoch [39/100], Loss: 0.0978, Validation Loss: 0.3215
	--> Epoch [40/100], Loss: 0.1871, Validation Loss: 0.3196
	--> Epoch [41/100], Loss: 0.1423, Validation Loss: 0.3190
	--> Epoch [42/100], Loss: 0.1400, Validation Loss: 0.3164
	--> Epoch [43/100], Loss: 0.1500, Validation Loss: 0.3138
	--> Epoch [44/100], Loss: 0.1278, Validation Loss: 0.3129
	--> Epoch [45/100], Loss: 0.1104, Validation Loss: 0.3119
	--> Epoch [46/100], Loss: 0.0432, Validation Loss: 0.3116
	--> Epoch [47/100], Loss: 0.1144, Validation Loss: 0.3092
	--> Epoch [48/100], Loss: 0.0596, Validation Loss: 0.3068
	--> Epoch [49/100], Loss: 0.2007, Validation Loss: 0.3049
	--> Epoch [50/100], Loss: 0.0544, Validation Loss: 0.3033
	--> Epoch [51/100], Loss: 0.0566, Validation Loss: 0.3014
	--> Epoch [52/100], Loss: 0.0389, Validation Loss: 0.2994
	--> Epoch [53/100], Loss: 0.0905, Validation Loss: 0.2993
	--> Epoch [54/100], Loss: 0.0521, Validation Loss: 0.2995
	--> Epoch [55/100], Loss: 0.0993, Validation Loss: 0.2981
	--> Epoch [56/100], Loss: 0.0723, Validation Loss: 0.3002
	--> Epoch [57/100], Loss: 0.0292, Validation Loss: 0.2993
	--> Epoch [58/100], Loss: 0.0780, Validation Loss: 0.2996
Early stopping
	--> Training for Fold 1 took 0.562645435333252 sec, using 58 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6428, Validation Loss: 0.6741
	--> Epoch [2/100], Loss: 0.4731, Validation Loss: 0.6351
	--> Epoch [3/100], Loss: 0.5017, Validation Loss: 0.6031
	--> Epoch [4/100], Loss: 0.4202, Validation Loss: 0.5851
	--> Epoch [5/100], Loss: 0.5403, Validation Loss: 0.5617
	--> Epoch [6/100], Loss: 0.3880, Validation Loss: 0.5429
	--> Epoch [7/100], Loss: 0.4246, Validation Loss: 0.5222
	--> Epoch [8/100], Loss: 0.3307, Validation Loss: 0.5031
	--> Epoch [9/100], Loss: 0.3386, Validation Loss: 0.4848
	--> Epoch [10/100], Loss: 0.3352, Validation Loss: 0.4694
	--> Epoch [11/100], Loss: 0.3203, Validation Loss: 0.4539
	--> Epoch [12/100], Loss: 0.2403, Validation Loss: 0.4466
	--> Epoch [13/100], Loss: 0.3168, Validation Loss: 0.4347
	--> Epoch [14/100], Loss: 0.1982, Validation Loss: 0.4230
	--> Epoch [15/100], Loss: 0.2776, Validation Loss: 0.4142
	--> Epoch [16/100], Loss: 0.1798, Validation Loss: 0.4035
	--> Epoch [17/100], Loss: 0.1538, Validation Loss: 0.3930
	--> Epoch [18/100], Loss: 0.2092, Validation Loss: 0.3837
	--> Epoch [19/100], Loss: 0.1884, Validation Loss: 0.3709
	--> Epoch [20/100], Loss: 0.1028, Validation Loss: 0.3631
	--> Epoch [21/100], Loss: 0.2059, Validation Loss: 0.3549
	--> Epoch [22/100], Loss: 0.1018, Validation Loss: 0.3473
	--> Epoch [23/100], Loss: 0.1239, Validation Loss: 0.3391
	--> Epoch [24/100], Loss: 0.1282, Validation Loss: 0.3301
	--> Epoch [25/100], Loss: 0.1786, Validation Loss: 0.3215
	--> Epoch [26/100], Loss: 0.1436, Validation Loss: 0.3166
	--> Epoch [27/100], Loss: 0.1357, Validation Loss: 0.3077
	--> Epoch [28/100], Loss: 0.1376, Validation Loss: 0.3028
	--> Epoch [29/100], Loss: 0.1348, Validation Loss: 0.2969
	--> Epoch [30/100], Loss: 0.1157, Validation Loss: 0.2860
	--> Epoch [31/100], Loss: 0.0815, Validation Loss: 0.2812
	--> Epoch [32/100], Loss: 0.1172, Validation Loss: 0.2754
	--> Epoch [33/100], Loss: 0.1170, Validation Loss: 0.2730
	--> Epoch [34/100], Loss: 0.0776, Validation Loss: 0.2676
	--> Epoch [35/100], Loss: 0.0982, Validation Loss: 0.2632
	--> Epoch [36/100], Loss: 0.1110, Validation Loss: 0.2557
	--> Epoch [37/100], Loss: 0.0619, Validation Loss: 0.2518
	--> Epoch [38/100], Loss: 0.1684, Validation Loss: 0.2491
	--> Epoch [39/100], Loss: 0.0882, Validation Loss: 0.2447
	--> Epoch [40/100], Loss: 0.0423, Validation Loss: 0.2416
	--> Epoch [41/100], Loss: 0.0667, Validation Loss: 0.2404
	--> Epoch [42/100], Loss: 0.0246, Validation Loss: 0.2373
	--> Epoch [43/100], Loss: 0.0252, Validation Loss: 0.2348
	--> Epoch [44/100], Loss: 0.0728, Validation Loss: 0.2300
	--> Epoch [45/100], Loss: 0.0651, Validation Loss: 0.2250
	--> Epoch [46/100], Loss: 0.0346, Validation Loss: 0.2247
	--> Epoch [47/100], Loss: 0.1190, Validation Loss: 0.2228
	--> Epoch [48/100], Loss: 0.0718, Validation Loss: 0.2204
	--> Epoch [49/100], Loss: 0.0923, Validation Loss: 0.2205
	--> Epoch [50/100], Loss: 0.0493, Validation Loss: 0.2189
	--> Epoch [51/100], Loss: 0.0426, Validation Loss: 0.2185
	--> Epoch [52/100], Loss: 0.0145, Validation Loss: 0.2170
	--> Epoch [53/100], Loss: 0.0432, Validation Loss: 0.2177
	--> Epoch [54/100], Loss: 0.0129, Validation Loss: 0.2174
	--> Epoch [55/100], Loss: 0.0108, Validation Loss: 0.2154
	--> Epoch [56/100], Loss: 0.1043, Validation Loss: 0.2115
	--> Epoch [57/100], Loss: 0.0192, Validation Loss: 0.2103
	--> Epoch [58/100], Loss: 0.0194, Validation Loss: 0.2093
	--> Epoch [59/100], Loss: 0.0132, Validation Loss: 0.2090
	--> Epoch [60/100], Loss: 0.0317, Validation Loss: 0.2072
	--> Epoch [61/100], Loss: 0.0357, Validation Loss: 0.2048
	--> Epoch [62/100], Loss: 0.0572, Validation Loss: 0.2025
	--> Epoch [63/100], Loss: 0.0222, Validation Loss: 0.2024
	--> Epoch [64/100], Loss: 0.0377, Validation Loss: 0.2015
	--> Epoch [65/100], Loss: 0.0676, Validation Loss: 0.1981
	--> Epoch [66/100], Loss: 0.0309, Validation Loss: 0.1972
	--> Epoch [67/100], Loss: 0.0219, Validation Loss: 0.1973
	--> Epoch [68/100], Loss: 0.0816, Validation Loss: 0.1967
	--> Epoch [69/100], Loss: 0.0627, Validation Loss: 0.1957
	--> Epoch [70/100], Loss: 0.0187, Validation Loss: 0.1957
	--> Epoch [71/100], Loss: 0.0168, Validation Loss: 0.1964
	--> Epoch [72/100], Loss: 0.0245, Validation Loss: 0.1942
	--> Epoch [73/100], Loss: 0.0292, Validation Loss: 0.1921
	--> Epoch [74/100], Loss: 0.0140, Validation Loss: 0.1932
	--> Epoch [75/100], Loss: 0.0897, Validation Loss: 0.1941
	--> Epoch [76/100], Loss: 0.0596, Validation Loss: 0.1898
	--> Epoch [77/100], Loss: 0.0419, Validation Loss: 0.1910
	--> Epoch [78/100], Loss: 0.0107, Validation Loss: 0.1888
	--> Epoch [79/100], Loss: 0.0208, Validation Loss: 0.1883
	--> Epoch [80/100], Loss: 0.0109, Validation Loss: 0.1882
	--> Epoch [81/100], Loss: 0.0245, Validation Loss: 0.1865
	--> Epoch [82/100], Loss: 0.0053, Validation Loss: 0.1863
	--> Epoch [83/100], Loss: 0.0701, Validation Loss: 0.1863
	--> Epoch [84/100], Loss: 0.0219, Validation Loss: 0.1861
	--> Epoch [85/100], Loss: 0.0741, Validation Loss: 0.1854
	--> Epoch [86/100], Loss: 0.0228, Validation Loss: 0.1834
	--> Epoch [87/100], Loss: 0.0330, Validation Loss: 0.1838
	--> Epoch [88/100], Loss: 0.0143, Validation Loss: 0.1824
	--> Epoch [89/100], Loss: 0.0152, Validation Loss: 0.1819
	--> Epoch [90/100], Loss: 0.0205, Validation Loss: 0.1820
	--> Epoch [91/100], Loss: 0.0928, Validation Loss: 0.1810
	--> Epoch [92/100], Loss: 0.0062, Validation Loss: 0.1801
	--> Epoch [93/100], Loss: 0.0293, Validation Loss: 0.1783
	--> Epoch [94/100], Loss: 0.0198, Validation Loss: 0.1776
	--> Epoch [95/100], Loss: 0.0858, Validation Loss: 0.1756
	--> Epoch [96/100], Loss: 0.0265, Validation Loss: 0.1773
	--> Epoch [97/100], Loss: 0.0120, Validation Loss: 0.1765
	--> Epoch [98/100], Loss: 0.0476, Validation Loss: 0.1762
Early stopping
	--> Training for Fold 2 took 0.9286248683929443 sec, using 98 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7745, Validation Loss: 0.6655
	--> Epoch [2/100], Loss: 0.8091, Validation Loss: 0.6508
	--> Epoch [3/100], Loss: 0.6634, Validation Loss: 0.6355
	--> Epoch [4/100], Loss: 0.6286, Validation Loss: 0.6211
	--> Epoch [5/100], Loss: 0.5754, Validation Loss: 0.6105
	--> Epoch [6/100], Loss: 0.4957, Validation Loss: 0.5956
	--> Epoch [7/100], Loss: 0.5051, Validation Loss: 0.5837
	--> Epoch [8/100], Loss: 0.5075, Validation Loss: 0.5695
	--> Epoch [9/100], Loss: 0.4519, Validation Loss: 0.5609
	--> Epoch [10/100], Loss: 0.3919, Validation Loss: 0.5500
	--> Epoch [11/100], Loss: 0.4064, Validation Loss: 0.5398
	--> Epoch [12/100], Loss: 0.4399, Validation Loss: 0.5275
	--> Epoch [13/100], Loss: 0.3160, Validation Loss: 0.5180
	--> Epoch [14/100], Loss: 0.3765, Validation Loss: 0.5092
	--> Epoch [15/100], Loss: 0.2936, Validation Loss: 0.5007
	--> Epoch [16/100], Loss: 0.2603, Validation Loss: 0.4905
	--> Epoch [17/100], Loss: 0.1995, Validation Loss: 0.4838
	--> Epoch [18/100], Loss: 0.2049, Validation Loss: 0.4744
	--> Epoch [19/100], Loss: 0.1829, Validation Loss: 0.4673
	--> Epoch [20/100], Loss: 0.2501, Validation Loss: 0.4601
	--> Epoch [21/100], Loss: 0.2576, Validation Loss: 0.4546
	--> Epoch [22/100], Loss: 0.1775, Validation Loss: 0.4483
	--> Epoch [23/100], Loss: 0.1360, Validation Loss: 0.4431
	--> Epoch [24/100], Loss: 0.1560, Validation Loss: 0.4374
	--> Epoch [25/100], Loss: 0.1705, Validation Loss: 0.4314
	--> Epoch [26/100], Loss: 0.2685, Validation Loss: 0.4267
	--> Epoch [27/100], Loss: 0.1951, Validation Loss: 0.4213
	--> Epoch [28/100], Loss: 0.1539, Validation Loss: 0.4192
	--> Epoch [29/100], Loss: 0.1809, Validation Loss: 0.4157
	--> Epoch [30/100], Loss: 0.1840, Validation Loss: 0.4090
	--> Epoch [31/100], Loss: 0.1362, Validation Loss: 0.4055
	--> Epoch [32/100], Loss: 0.1179, Validation Loss: 0.4028
	--> Epoch [33/100], Loss: 0.1405, Validation Loss: 0.4007
	--> Epoch [34/100], Loss: 0.0729, Validation Loss: 0.3965
	--> Epoch [35/100], Loss: 0.1164, Validation Loss: 0.3919
	--> Epoch [36/100], Loss: 0.0792, Validation Loss: 0.3878
	--> Epoch [37/100], Loss: 0.0568, Validation Loss: 0.3852
	--> Epoch [38/100], Loss: 0.0582, Validation Loss: 0.3833
	--> Epoch [39/100], Loss: 0.0821, Validation Loss: 0.3820
	--> Epoch [40/100], Loss: 0.1287, Validation Loss: 0.3793
	--> Epoch [41/100], Loss: 0.1258, Validation Loss: 0.3781
	--> Epoch [42/100], Loss: 0.0574, Validation Loss: 0.3755
	--> Epoch [43/100], Loss: 0.0576, Validation Loss: 0.3728
	--> Epoch [44/100], Loss: 0.1063, Validation Loss: 0.3717
	--> Epoch [45/100], Loss: 0.0977, Validation Loss: 0.3718
	--> Epoch [46/100], Loss: 0.1411, Validation Loss: 0.3724
	--> Epoch [47/100], Loss: 0.0385, Validation Loss: 0.3704
	--> Epoch [48/100], Loss: 0.1086, Validation Loss: 0.3701
	--> Epoch [49/100], Loss: 0.0881, Validation Loss: 0.3677
	--> Epoch [50/100], Loss: 0.1372, Validation Loss: 0.3637
	--> Epoch [51/100], Loss: 0.0418, Validation Loss: 0.3636
	--> Epoch [52/100], Loss: 0.0706, Validation Loss: 0.3635
	--> Epoch [53/100], Loss: 0.0432, Validation Loss: 0.3615
	--> Epoch [54/100], Loss: 0.0288, Validation Loss: 0.3595
	--> Epoch [55/100], Loss: 0.1463, Validation Loss: 0.3582
	--> Epoch [56/100], Loss: 0.1993, Validation Loss: 0.3586
	--> Epoch [57/100], Loss: 0.0449, Validation Loss: 0.3586
	--> Epoch [58/100], Loss: 0.0182, Validation Loss: 0.3569
	--> Epoch [59/100], Loss: 0.0343, Validation Loss: 0.3562
	--> Epoch [60/100], Loss: 0.0310, Validation Loss: 0.3548
	--> Epoch [61/100], Loss: 0.0331, Validation Loss: 0.3530
	--> Epoch [62/100], Loss: 0.1732, Validation Loss: 0.3541
	--> Epoch [63/100], Loss: 0.0667, Validation Loss: 0.3537
	--> Epoch [64/100], Loss: 0.0941, Validation Loss: 0.3509
	--> Epoch [65/100], Loss: 0.0494, Validation Loss: 0.3503
	--> Epoch [66/100], Loss: 0.0562, Validation Loss: 0.3519
	--> Epoch [67/100], Loss: 0.0150, Validation Loss: 0.3513
	--> Epoch [68/100], Loss: 0.0894, Validation Loss: 0.3500
	--> Epoch [69/100], Loss: 0.0144, Validation Loss: 0.3478
	--> Epoch [70/100], Loss: 0.1458, Validation Loss: 0.3457
	--> Epoch [71/100], Loss: 0.0366, Validation Loss: 0.3455
	--> Epoch [72/100], Loss: 0.0171, Validation Loss: 0.3465
	--> Epoch [73/100], Loss: 0.0112, Validation Loss: 0.3469
	--> Epoch [74/100], Loss: 0.1226, Validation Loss: 0.3466
Early stopping
	--> Training for Fold 3 took 0.6264269351959229 sec, using 74 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8287, Validation Loss: 0.7142
	--> Epoch [2/100], Loss: 0.7217, Validation Loss: 0.6819
	--> Epoch [3/100], Loss: 0.6430, Validation Loss: 0.6598
	--> Epoch [4/100], Loss: 0.6504, Validation Loss: 0.6330
	--> Epoch [5/100], Loss: 0.5082, Validation Loss: 0.6171
	--> Epoch [6/100], Loss: 0.4733, Validation Loss: 0.5982
	--> Epoch [7/100], Loss: 0.4723, Validation Loss: 0.5824
	--> Epoch [8/100], Loss: 0.3862, Validation Loss: 0.5611
	--> Epoch [9/100], Loss: 0.3850, Validation Loss: 0.5456
	--> Epoch [10/100], Loss: 0.3825, Validation Loss: 0.5290
	--> Epoch [11/100], Loss: 0.3598, Validation Loss: 0.5145
	--> Epoch [12/100], Loss: 0.3782, Validation Loss: 0.5053
	--> Epoch [13/100], Loss: 0.2499, Validation Loss: 0.4931
	--> Epoch [14/100], Loss: 0.2272, Validation Loss: 0.4832
	--> Epoch [15/100], Loss: 0.3088, Validation Loss: 0.4774
	--> Epoch [16/100], Loss: 0.2631, Validation Loss: 0.4714
	--> Epoch [17/100], Loss: 0.1563, Validation Loss: 0.4646
	--> Epoch [18/100], Loss: 0.2156, Validation Loss: 0.4569
	--> Epoch [19/100], Loss: 0.2313, Validation Loss: 0.4479
	--> Epoch [20/100], Loss: 0.1748, Validation Loss: 0.4415
	--> Epoch [21/100], Loss: 0.1705, Validation Loss: 0.4343
	--> Epoch [22/100], Loss: 0.2895, Validation Loss: 0.4275
	--> Epoch [23/100], Loss: 0.3051, Validation Loss: 0.4288
	--> Epoch [24/100], Loss: 0.2084, Validation Loss: 0.4219
	--> Epoch [25/100], Loss: 0.0928, Validation Loss: 0.4144
	--> Epoch [26/100], Loss: 0.1640, Validation Loss: 0.4071
	--> Epoch [27/100], Loss: 0.1810, Validation Loss: 0.4036
	--> Epoch [28/100], Loss: 0.2209, Validation Loss: 0.4011
	--> Epoch [29/100], Loss: 0.1006, Validation Loss: 0.3956
	--> Epoch [30/100], Loss: 0.1657, Validation Loss: 0.3924
	--> Epoch [31/100], Loss: 0.0791, Validation Loss: 0.3892
	--> Epoch [32/100], Loss: 0.1222, Validation Loss: 0.3857
	--> Epoch [33/100], Loss: 0.0869, Validation Loss: 0.3817
	--> Epoch [34/100], Loss: 0.1124, Validation Loss: 0.3778
	--> Epoch [35/100], Loss: 0.0848, Validation Loss: 0.3776
	--> Epoch [36/100], Loss: 0.1063, Validation Loss: 0.3739
	--> Epoch [37/100], Loss: 0.1053, Validation Loss: 0.3705
	--> Epoch [38/100], Loss: 0.0946, Validation Loss: 0.3687
	--> Epoch [39/100], Loss: 0.1977, Validation Loss: 0.3680
	--> Epoch [40/100], Loss: 0.1248, Validation Loss: 0.3632
	--> Epoch [41/100], Loss: 0.1257, Validation Loss: 0.3617
	--> Epoch [42/100], Loss: 0.1431, Validation Loss: 0.3615
	--> Epoch [43/100], Loss: 0.0510, Validation Loss: 0.3561
	--> Epoch [44/100], Loss: 0.0377, Validation Loss: 0.3546
	--> Epoch [45/100], Loss: 0.0841, Validation Loss: 0.3550
	--> Epoch [46/100], Loss: 0.0402, Validation Loss: 0.3525
	--> Epoch [47/100], Loss: 0.0354, Validation Loss: 0.3521
	--> Epoch [48/100], Loss: 0.1459, Validation Loss: 0.3523
	--> Epoch [49/100], Loss: 0.1321, Validation Loss: 0.3510
	--> Epoch [50/100], Loss: 0.0919, Validation Loss: 0.3522
	--> Epoch [51/100], Loss: 0.0308, Validation Loss: 0.3527
	--> Epoch [52/100], Loss: 0.1767, Validation Loss: 0.3502
	--> Epoch [53/100], Loss: 0.1006, Validation Loss: 0.3494
	--> Epoch [54/100], Loss: 0.0791, Validation Loss: 0.3498
	--> Epoch [55/100], Loss: 0.1293, Validation Loss: 0.3478
	--> Epoch [56/100], Loss: 0.0890, Validation Loss: 0.3474
	--> Epoch [57/100], Loss: 0.0183, Validation Loss: 0.3462
	--> Epoch [58/100], Loss: 0.0349, Validation Loss: 0.3455
	--> Epoch [59/100], Loss: 0.0871, Validation Loss: 0.3447
	--> Epoch [60/100], Loss: 0.0266, Validation Loss: 0.3450
	--> Epoch [61/100], Loss: 0.0727, Validation Loss: 0.3432
	--> Epoch [62/100], Loss: 0.0744, Validation Loss: 0.3434
	--> Epoch [63/100], Loss: 0.0786, Validation Loss: 0.3426
	--> Epoch [64/100], Loss: 0.0499, Validation Loss: 0.3425
	--> Epoch [65/100], Loss: 0.0179, Validation Loss: 0.3426
	--> Epoch [66/100], Loss: 0.0890, Validation Loss: 0.3441
	--> Epoch [67/100], Loss: 0.0720, Validation Loss: 0.3465
Early stopping
	--> Training for Fold 4 took 0.5629158020019531 sec, using 67 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5305, Validation Loss: 0.7558
	--> Epoch [2/100], Loss: 0.4607, Validation Loss: 0.7386
	--> Epoch [3/100], Loss: 0.4476, Validation Loss: 0.7237
	--> Epoch [4/100], Loss: 0.4954, Validation Loss: 0.7132
	--> Epoch [5/100], Loss: 0.3935, Validation Loss: 0.7050
	--> Epoch [6/100], Loss: 0.3441, Validation Loss: 0.6992
	--> Epoch [7/100], Loss: 0.3375, Validation Loss: 0.6933
	--> Epoch [8/100], Loss: 0.3681, Validation Loss: 0.6830
	--> Epoch [9/100], Loss: 0.2835, Validation Loss: 0.6728
	--> Epoch [10/100], Loss: 0.2498, Validation Loss: 0.6693
	--> Epoch [11/100], Loss: 0.2645, Validation Loss: 0.6680
	--> Epoch [12/100], Loss: 0.3068, Validation Loss: 0.6629
	--> Epoch [13/100], Loss: 0.2622, Validation Loss: 0.6606
	--> Epoch [14/100], Loss: 0.2775, Validation Loss: 0.6571
	--> Epoch [15/100], Loss: 0.2747, Validation Loss: 0.6543
	--> Epoch [16/100], Loss: 0.2276, Validation Loss: 0.6466
	--> Epoch [17/100], Loss: 0.2440, Validation Loss: 0.6430
	--> Epoch [18/100], Loss: 0.2289, Validation Loss: 0.6408
	--> Epoch [19/100], Loss: 0.2026, Validation Loss: 0.6400
	--> Epoch [20/100], Loss: 0.1526, Validation Loss: 0.6385
	--> Epoch [21/100], Loss: 0.2411, Validation Loss: 0.6337
	--> Epoch [22/100], Loss: 0.2585, Validation Loss: 0.6337
	--> Epoch [23/100], Loss: 0.2120, Validation Loss: 0.6348
	--> Epoch [24/100], Loss: 0.1462, Validation Loss: 0.6304
	--> Epoch [25/100], Loss: 0.1894, Validation Loss: 0.6286
	--> Epoch [26/100], Loss: 0.1413, Validation Loss: 0.6288
	--> Epoch [27/100], Loss: 0.1905, Validation Loss: 0.6284
	--> Epoch [28/100], Loss: 0.1279, Validation Loss: 0.6262
	--> Epoch [29/100], Loss: 0.1531, Validation Loss: 0.6269
	--> Epoch [30/100], Loss: 0.1305, Validation Loss: 0.6260
	--> Epoch [31/100], Loss: 0.0746, Validation Loss: 0.6269
	--> Epoch [32/100], Loss: 0.1091, Validation Loss: 0.6264
	--> Epoch [33/100], Loss: 0.1064, Validation Loss: 0.6285
Early stopping
	--> Training for Fold 5 took 0.293196439743042 sec, using 33 epochs

Median number of epochs used: 67 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/67], Loss: 0.7194
	--> Final training Epoch [2/67], Loss: 0.6785
	--> Final training Epoch [3/67], Loss: 0.6590
	--> Final training Epoch [4/67], Loss: 0.6175
	--> Final training Epoch [5/67], Loss: 0.5966
	--> Final training Epoch [6/67], Loss: 0.5581
	--> Final training Epoch [7/67], Loss: 0.5231
	--> Final training Epoch [8/67], Loss: 0.5145
	--> Final training Epoch [9/67], Loss: 0.4966
	--> Final training Epoch [10/67], Loss: 0.4770
	--> Final training Epoch [11/67], Loss: 0.5246
	--> Final training Epoch [12/67], Loss: 0.4778
	--> Final training Epoch [13/67], Loss: 0.4391
	--> Final training Epoch [14/67], Loss: 0.3953
	--> Final training Epoch [15/67], Loss: 0.3989
	--> Final training Epoch [16/67], Loss: 0.3802
	--> Final training Epoch [17/67], Loss: 0.3875
	--> Final training Epoch [18/67], Loss: 0.3549
	--> Final training Epoch [19/67], Loss: 0.3545
	--> Final training Epoch [20/67], Loss: 0.3253
	--> Final training Epoch [21/67], Loss: 0.3705
	--> Final training Epoch [22/67], Loss: 0.3110
	--> Final training Epoch [23/67], Loss: 0.3126
	--> Final training Epoch [24/67], Loss: 0.3167
	--> Final training Epoch [25/67], Loss: 0.2439
	--> Final training Epoch [26/67], Loss: 0.2844
	--> Final training Epoch [27/67], Loss: 0.2443
	--> Final training Epoch [28/67], Loss: 0.3192
	--> Final training Epoch [29/67], Loss: 0.2226
	--> Final training Epoch [30/67], Loss: 0.2139
	--> Final training Epoch [31/67], Loss: 0.1989
	--> Final training Epoch [32/67], Loss: 0.2226
	--> Final training Epoch [33/67], Loss: 0.2020
	--> Final training Epoch [34/67], Loss: 0.2143
	--> Final training Epoch [35/67], Loss: 0.2148
	--> Final training Epoch [36/67], Loss: 0.1557
	--> Final training Epoch [37/67], Loss: 0.1663
	--> Final training Epoch [38/67], Loss: 0.1342
	--> Final training Epoch [39/67], Loss: 0.1848
	--> Final training Epoch [40/67], Loss: 0.1400
	--> Final training Epoch [41/67], Loss: 0.1337
	--> Final training Epoch [42/67], Loss: 0.1482
	--> Final training Epoch [43/67], Loss: 0.1396
	--> Final training Epoch [44/67], Loss: 0.0936
	--> Final training Epoch [45/67], Loss: 0.1338
	--> Final training Epoch [46/67], Loss: 0.1504
	--> Final training Epoch [47/67], Loss: 0.0943
	--> Final training Epoch [48/67], Loss: 0.1332
	--> Final training Epoch [49/67], Loss: 0.1144
	--> Final training Epoch [50/67], Loss: 0.1160
	--> Final training Epoch [51/67], Loss: 0.1111
	--> Final training Epoch [52/67], Loss: 0.1008
	--> Final training Epoch [53/67], Loss: 0.0817
	--> Final training Epoch [54/67], Loss: 0.1190
	--> Final training Epoch [55/67], Loss: 0.1041
	--> Final training Epoch [56/67], Loss: 0.0687
	--> Final training Epoch [57/67], Loss: 0.0799
	--> Final training Epoch [58/67], Loss: 0.0853
	--> Final training Epoch [59/67], Loss: 0.0673
	--> Final training Epoch [60/67], Loss: 0.0717
	--> Final training Epoch [61/67], Loss: 0.0762
	--> Final training Epoch [62/67], Loss: 0.1071
	--> Final training Epoch [63/67], Loss: 0.0945
	--> Final training Epoch [64/67], Loss: 0.0604
	--> Final training Epoch [65/67], Loss: 0.0484
	--> Final training Epoch [66/67], Loss: 0.1077
	--> Final training Epoch [67/67], Loss: 0.0821

Final training took 0.5712807178497314 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8791
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8819, Validation Loss: 0.3001,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3001
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3352,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3001
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3527,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3001
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.4031,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3001
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.3727,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3001
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8158, Validation Loss: 0.3998,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3001
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 0.4085,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3001
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8474, Validation Loss: 0.3833,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3001

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.9007, Validation Loss: 0.7513
	--> Epoch [2/100], Loss: 0.8049, Validation Loss: 0.7264
	--> Epoch [3/100], Loss: 0.7587, Validation Loss: 0.7074
	--> Epoch [4/100], Loss: 0.7969, Validation Loss: 0.6894
	--> Epoch [5/100], Loss: 0.6932, Validation Loss: 0.6720
	--> Epoch [6/100], Loss: 0.6568, Validation Loss: 0.6520
	--> Epoch [7/100], Loss: 0.6065, Validation Loss: 0.6384
	--> Epoch [8/100], Loss: 0.6123, Validation Loss: 0.6240
	--> Epoch [9/100], Loss: 0.5468, Validation Loss: 0.6126
	--> Epoch [10/100], Loss: 0.4720, Validation Loss: 0.5979
	--> Epoch [11/100], Loss: 0.4761, Validation Loss: 0.5862
	--> Epoch [12/100], Loss: 0.3719, Validation Loss: 0.5690
	--> Epoch [13/100], Loss: 0.3781, Validation Loss: 0.5582
	--> Epoch [14/100], Loss: 0.3813, Validation Loss: 0.5440
	--> Epoch [15/100], Loss: 0.4187, Validation Loss: 0.5338
	--> Epoch [16/100], Loss: 0.4071, Validation Loss: 0.5214
	--> Epoch [17/100], Loss: 0.4020, Validation Loss: 0.5089
	--> Epoch [18/100], Loss: 0.3100, Validation Loss: 0.4998
	--> Epoch [19/100], Loss: 0.3269, Validation Loss: 0.4881
	--> Epoch [20/100], Loss: 0.2583, Validation Loss: 0.4778
	--> Epoch [21/100], Loss: 0.3335, Validation Loss: 0.4714
	--> Epoch [22/100], Loss: 0.2436, Validation Loss: 0.4640
	--> Epoch [23/100], Loss: 0.2392, Validation Loss: 0.4565
	--> Epoch [24/100], Loss: 0.2837, Validation Loss: 0.4473
	--> Epoch [25/100], Loss: 0.1760, Validation Loss: 0.4380
	--> Epoch [26/100], Loss: 0.3254, Validation Loss: 0.4302
	--> Epoch [27/100], Loss: 0.2547, Validation Loss: 0.4237
	--> Epoch [28/100], Loss: 0.1762, Validation Loss: 0.4165
	--> Epoch [29/100], Loss: 0.1904, Validation Loss: 0.4128
	--> Epoch [30/100], Loss: 0.1972, Validation Loss: 0.4064
	--> Epoch [31/100], Loss: 0.1374, Validation Loss: 0.4012
	--> Epoch [32/100], Loss: 0.1719, Validation Loss: 0.3946
	--> Epoch [33/100], Loss: 0.2216, Validation Loss: 0.3888
	--> Epoch [34/100], Loss: 0.2510, Validation Loss: 0.3855
	--> Epoch [35/100], Loss: 0.2194, Validation Loss: 0.3811
	--> Epoch [36/100], Loss: 0.2124, Validation Loss: 0.3761
	--> Epoch [37/100], Loss: 0.1729, Validation Loss: 0.3716
	--> Epoch [38/100], Loss: 0.2255, Validation Loss: 0.3674
	--> Epoch [39/100], Loss: 0.0988, Validation Loss: 0.3629
	--> Epoch [40/100], Loss: 0.1463, Validation Loss: 0.3599
	--> Epoch [41/100], Loss: 0.1107, Validation Loss: 0.3577
	--> Epoch [42/100], Loss: 0.0991, Validation Loss: 0.3525
	--> Epoch [43/100], Loss: 0.1814, Validation Loss: 0.3516
	--> Epoch [44/100], Loss: 0.1221, Validation Loss: 0.3486
	--> Epoch [45/100], Loss: 0.1195, Validation Loss: 0.3432
	--> Epoch [46/100], Loss: 0.1362, Validation Loss: 0.3402
	--> Epoch [47/100], Loss: 0.0746, Validation Loss: 0.3358
	--> Epoch [48/100], Loss: 0.2108, Validation Loss: 0.3310
	--> Epoch [49/100], Loss: 0.2142, Validation Loss: 0.3286
	--> Epoch [50/100], Loss: 0.1272, Validation Loss: 0.3268
	--> Epoch [51/100], Loss: 0.1896, Validation Loss: 0.3240
	--> Epoch [52/100], Loss: 0.0486, Validation Loss: 0.3213
	--> Epoch [53/100], Loss: 0.3081, Validation Loss: 0.3182
	--> Epoch [54/100], Loss: 0.1293, Validation Loss: 0.3170
	--> Epoch [55/100], Loss: 0.0828, Validation Loss: 0.3156
	--> Epoch [56/100], Loss: 0.1937, Validation Loss: 0.3139
	--> Epoch [57/100], Loss: 0.0965, Validation Loss: 0.3123
	--> Epoch [58/100], Loss: 0.1827, Validation Loss: 0.3111
	--> Epoch [59/100], Loss: 0.0438, Validation Loss: 0.3108
	--> Epoch [60/100], Loss: 0.0587, Validation Loss: 0.3099
	--> Epoch [61/100], Loss: 0.0457, Validation Loss: 0.3097
	--> Epoch [62/100], Loss: 0.0454, Validation Loss: 0.3070
	--> Epoch [63/100], Loss: 0.0962, Validation Loss: 0.3065
	--> Epoch [64/100], Loss: 0.1046, Validation Loss: 0.3060
	--> Epoch [65/100], Loss: 0.1048, Validation Loss: 0.3056
	--> Epoch [66/100], Loss: 0.0900, Validation Loss: 0.3050
	--> Epoch [67/100], Loss: 0.1271, Validation Loss: 0.3038
	--> Epoch [68/100], Loss: 0.1598, Validation Loss: 0.3031
	--> Epoch [69/100], Loss: 0.1173, Validation Loss: 0.3032
	--> Epoch [70/100], Loss: 0.1017, Validation Loss: 0.3016
	--> Epoch [71/100], Loss: 0.0315, Validation Loss: 0.2993
	--> Epoch [72/100], Loss: 0.1774, Validation Loss: 0.3001
	--> Epoch [73/100], Loss: 0.0799, Validation Loss: 0.2974
	--> Epoch [74/100], Loss: 0.0944, Validation Loss: 0.2966
	--> Epoch [75/100], Loss: 0.1667, Validation Loss: 0.2933
	--> Epoch [76/100], Loss: 0.1043, Validation Loss: 0.2958
	--> Epoch [77/100], Loss: 0.0199, Validation Loss: 0.2951
	--> Epoch [78/100], Loss: 0.1568, Validation Loss: 0.2923
	--> Epoch [79/100], Loss: 0.0493, Validation Loss: 0.2909
	--> Epoch [80/100], Loss: 0.1126, Validation Loss: 0.2892
	--> Epoch [81/100], Loss: 0.1529, Validation Loss: 0.2874
	--> Epoch [82/100], Loss: 0.1741, Validation Loss: 0.2851
	--> Epoch [83/100], Loss: 0.1750, Validation Loss: 0.2842
	--> Epoch [84/100], Loss: 0.1619, Validation Loss: 0.2838
	--> Epoch [85/100], Loss: 0.0396, Validation Loss: 0.2828
	--> Epoch [86/100], Loss: 0.0851, Validation Loss: 0.2816
	--> Epoch [87/100], Loss: 0.2296, Validation Loss: 0.2815
	--> Epoch [88/100], Loss: 0.0247, Validation Loss: 0.2811
	--> Epoch [89/100], Loss: 0.0322, Validation Loss: 0.2817
	--> Epoch [90/100], Loss: 0.0823, Validation Loss: 0.2845
	--> Epoch [91/100], Loss: 0.2385, Validation Loss: 0.2842
Early stopping
	--> Training for Fold 1 took 1.1284465789794922 sec, using 91 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.9295, Validation Loss: 0.7050
	--> Epoch [2/100], Loss: 0.7569, Validation Loss: 0.6790
	--> Epoch [3/100], Loss: 0.6752, Validation Loss: 0.6575
	--> Epoch [4/100], Loss: 0.6551, Validation Loss: 0.6419
	--> Epoch [5/100], Loss: 0.6181, Validation Loss: 0.6276
	--> Epoch [6/100], Loss: 0.5815, Validation Loss: 0.6136
	--> Epoch [7/100], Loss: 0.5787, Validation Loss: 0.5994
	--> Epoch [8/100], Loss: 0.5089, Validation Loss: 0.5877
	--> Epoch [9/100], Loss: 0.5273, Validation Loss: 0.5749
	--> Epoch [10/100], Loss: 0.4340, Validation Loss: 0.5616
	--> Epoch [11/100], Loss: 0.3754, Validation Loss: 0.5433
	--> Epoch [12/100], Loss: 0.3806, Validation Loss: 0.5288
	--> Epoch [13/100], Loss: 0.3496, Validation Loss: 0.5149
	--> Epoch [14/100], Loss: 0.3468, Validation Loss: 0.5010
	--> Epoch [15/100], Loss: 0.2847, Validation Loss: 0.4887
	--> Epoch [16/100], Loss: 0.3047, Validation Loss: 0.4744
	--> Epoch [17/100], Loss: 0.2728, Validation Loss: 0.4604
	--> Epoch [18/100], Loss: 0.3237, Validation Loss: 0.4467
	--> Epoch [19/100], Loss: 0.3140, Validation Loss: 0.4351
	--> Epoch [20/100], Loss: 0.3121, Validation Loss: 0.4240
	--> Epoch [21/100], Loss: 0.2325, Validation Loss: 0.4130
	--> Epoch [22/100], Loss: 0.2287, Validation Loss: 0.4051
	--> Epoch [23/100], Loss: 0.2589, Validation Loss: 0.3967
	--> Epoch [24/100], Loss: 0.2692, Validation Loss: 0.3889
	--> Epoch [25/100], Loss: 0.2224, Validation Loss: 0.3818
	--> Epoch [26/100], Loss: 0.1658, Validation Loss: 0.3717
	--> Epoch [27/100], Loss: 0.2347, Validation Loss: 0.3634
	--> Epoch [28/100], Loss: 0.2432, Validation Loss: 0.3581
	--> Epoch [29/100], Loss: 0.1748, Validation Loss: 0.3506
	--> Epoch [30/100], Loss: 0.1176, Validation Loss: 0.3452
	--> Epoch [31/100], Loss: 0.1293, Validation Loss: 0.3374
	--> Epoch [32/100], Loss: 0.2110, Validation Loss: 0.3305
	--> Epoch [33/100], Loss: 0.1210, Validation Loss: 0.3240
	--> Epoch [34/100], Loss: 0.1635, Validation Loss: 0.3199
	--> Epoch [35/100], Loss: 0.1560, Validation Loss: 0.3140
	--> Epoch [36/100], Loss: 0.1637, Validation Loss: 0.3107
	--> Epoch [37/100], Loss: 0.1074, Validation Loss: 0.3059
	--> Epoch [38/100], Loss: 0.2034, Validation Loss: 0.3010
	--> Epoch [39/100], Loss: 0.1357, Validation Loss: 0.2932
	--> Epoch [40/100], Loss: 0.1051, Validation Loss: 0.2886
	--> Epoch [41/100], Loss: 0.1574, Validation Loss: 0.2887
	--> Epoch [42/100], Loss: 0.1251, Validation Loss: 0.2843
	--> Epoch [43/100], Loss: 0.1883, Validation Loss: 0.2812
	--> Epoch [44/100], Loss: 0.0663, Validation Loss: 0.2774
	--> Epoch [45/100], Loss: 0.1070, Validation Loss: 0.2727
	--> Epoch [46/100], Loss: 0.1004, Validation Loss: 0.2702
	--> Epoch [47/100], Loss: 0.1166, Validation Loss: 0.2684
	--> Epoch [48/100], Loss: 0.0419, Validation Loss: 0.2637
	--> Epoch [49/100], Loss: 0.1588, Validation Loss: 0.2596
	--> Epoch [50/100], Loss: 0.0770, Validation Loss: 0.2580
	--> Epoch [51/100], Loss: 0.1021, Validation Loss: 0.2585
	--> Epoch [52/100], Loss: 0.0348, Validation Loss: 0.2544
	--> Epoch [53/100], Loss: 0.0455, Validation Loss: 0.2543
	--> Epoch [54/100], Loss: 0.0403, Validation Loss: 0.2523
	--> Epoch [55/100], Loss: 0.0586, Validation Loss: 0.2503
	--> Epoch [56/100], Loss: 0.1437, Validation Loss: 0.2474
	--> Epoch [57/100], Loss: 0.0465, Validation Loss: 0.2459
	--> Epoch [58/100], Loss: 0.0499, Validation Loss: 0.2448
	--> Epoch [59/100], Loss: 0.0481, Validation Loss: 0.2413
	--> Epoch [60/100], Loss: 0.0253, Validation Loss: 0.2394
	--> Epoch [61/100], Loss: 0.1024, Validation Loss: 0.2363
	--> Epoch [62/100], Loss: 0.0329, Validation Loss: 0.2352
	--> Epoch [63/100], Loss: 0.1269, Validation Loss: 0.2298
	--> Epoch [64/100], Loss: 0.0178, Validation Loss: 0.2279
	--> Epoch [65/100], Loss: 0.0122, Validation Loss: 0.2264
	--> Epoch [66/100], Loss: 0.0250, Validation Loss: 0.2254
	--> Epoch [67/100], Loss: 0.0227, Validation Loss: 0.2229
	--> Epoch [68/100], Loss: 0.1148, Validation Loss: 0.2175
	--> Epoch [69/100], Loss: 0.1098, Validation Loss: 0.2188
	--> Epoch [70/100], Loss: 0.0865, Validation Loss: 0.2170
	--> Epoch [71/100], Loss: 0.1041, Validation Loss: 0.2167
	--> Epoch [72/100], Loss: 0.0486, Validation Loss: 0.2160
	--> Epoch [73/100], Loss: 0.0457, Validation Loss: 0.2156
	--> Epoch [74/100], Loss: 0.0313, Validation Loss: 0.2181
	--> Epoch [75/100], Loss: 0.0763, Validation Loss: 0.2160
	--> Epoch [76/100], Loss: 0.1485, Validation Loss: 0.2151
	--> Epoch [77/100], Loss: 0.0139, Validation Loss: 0.2134
	--> Epoch [78/100], Loss: 0.0218, Validation Loss: 0.2125
	--> Epoch [79/100], Loss: 0.1415, Validation Loss: 0.2122
	--> Epoch [80/100], Loss: 0.0383, Validation Loss: 0.2118
	--> Epoch [81/100], Loss: 0.0208, Validation Loss: 0.2111
	--> Epoch [82/100], Loss: 0.0319, Validation Loss: 0.2112
	--> Epoch [83/100], Loss: 0.0163, Validation Loss: 0.2120
	--> Epoch [84/100], Loss: 0.0814, Validation Loss: 0.2096
	--> Epoch [85/100], Loss: 0.0157, Validation Loss: 0.2074
	--> Epoch [86/100], Loss: 0.0491, Validation Loss: 0.2078
	--> Epoch [87/100], Loss: 0.0214, Validation Loss: 0.2068
	--> Epoch [88/100], Loss: 0.0927, Validation Loss: 0.2071
	--> Epoch [89/100], Loss: 0.0141, Validation Loss: 0.2048
	--> Epoch [90/100], Loss: 0.0226, Validation Loss: 0.2048
	--> Epoch [91/100], Loss: 0.0873, Validation Loss: 0.2066
	--> Epoch [92/100], Loss: 0.0928, Validation Loss: 0.2090
	--> Epoch [93/100], Loss: 0.0776, Validation Loss: 0.2073
Early stopping
	--> Training for Fold 2 took 1.2358782291412354 sec, using 93 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6997, Validation Loss: 0.6644
	--> Epoch [2/100], Loss: 0.6007, Validation Loss: 0.6483
	--> Epoch [3/100], Loss: 0.6061, Validation Loss: 0.6368
	--> Epoch [4/100], Loss: 0.5016, Validation Loss: 0.6248
	--> Epoch [5/100], Loss: 0.5300, Validation Loss: 0.6162
	--> Epoch [6/100], Loss: 0.4737, Validation Loss: 0.6060
	--> Epoch [7/100], Loss: 0.4562, Validation Loss: 0.5903
	--> Epoch [8/100], Loss: 0.4130, Validation Loss: 0.5807
	--> Epoch [9/100], Loss: 0.3897, Validation Loss: 0.5643
	--> Epoch [10/100], Loss: 0.4151, Validation Loss: 0.5507
	--> Epoch [11/100], Loss: 0.3263, Validation Loss: 0.5444
	--> Epoch [12/100], Loss: 0.3330, Validation Loss: 0.5336
	--> Epoch [13/100], Loss: 0.2928, Validation Loss: 0.5239
	--> Epoch [14/100], Loss: 0.2671, Validation Loss: 0.5154
	--> Epoch [15/100], Loss: 0.2683, Validation Loss: 0.5049
	--> Epoch [16/100], Loss: 0.2098, Validation Loss: 0.4965
	--> Epoch [17/100], Loss: 0.2208, Validation Loss: 0.4906
	--> Epoch [18/100], Loss: 0.2123, Validation Loss: 0.4824
	--> Epoch [19/100], Loss: 0.1861, Validation Loss: 0.4713
	--> Epoch [20/100], Loss: 0.2391, Validation Loss: 0.4654
	--> Epoch [21/100], Loss: 0.1709, Validation Loss: 0.4593
	--> Epoch [22/100], Loss: 0.2813, Validation Loss: 0.4534
	--> Epoch [23/100], Loss: 0.1551, Validation Loss: 0.4507
	--> Epoch [24/100], Loss: 0.0896, Validation Loss: 0.4463
	--> Epoch [25/100], Loss: 0.1191, Validation Loss: 0.4420
	--> Epoch [26/100], Loss: 0.1721, Validation Loss: 0.4372
	--> Epoch [27/100], Loss: 0.2168, Validation Loss: 0.4331
	--> Epoch [28/100], Loss: 0.1343, Validation Loss: 0.4264
	--> Epoch [29/100], Loss: 0.0742, Validation Loss: 0.4204
	--> Epoch [30/100], Loss: 0.1416, Validation Loss: 0.4171
	--> Epoch [31/100], Loss: 0.1109, Validation Loss: 0.4126
	--> Epoch [32/100], Loss: 0.0874, Validation Loss: 0.4081
	--> Epoch [33/100], Loss: 0.0571, Validation Loss: 0.4037
	--> Epoch [34/100], Loss: 0.1133, Validation Loss: 0.4011
	--> Epoch [35/100], Loss: 0.0670, Validation Loss: 0.3977
	--> Epoch [36/100], Loss: 0.0670, Validation Loss: 0.3978
	--> Epoch [37/100], Loss: 0.0709, Validation Loss: 0.3951
	--> Epoch [38/100], Loss: 0.1836, Validation Loss: 0.3903
	--> Epoch [39/100], Loss: 0.0699, Validation Loss: 0.3891
	--> Epoch [40/100], Loss: 0.0793, Validation Loss: 0.3889
	--> Epoch [41/100], Loss: 0.0432, Validation Loss: 0.3861
	--> Epoch [42/100], Loss: 0.1098, Validation Loss: 0.3824
	--> Epoch [43/100], Loss: 0.0908, Validation Loss: 0.3790
	--> Epoch [44/100], Loss: 0.0634, Validation Loss: 0.3754
	--> Epoch [45/100], Loss: 0.0311, Validation Loss: 0.3746
	--> Epoch [46/100], Loss: 0.0304, Validation Loss: 0.3721
	--> Epoch [47/100], Loss: 0.0843, Validation Loss: 0.3716
	--> Epoch [48/100], Loss: 0.0714, Validation Loss: 0.3710
	--> Epoch [49/100], Loss: 0.0187, Validation Loss: 0.3695
	--> Epoch [50/100], Loss: 0.0542, Validation Loss: 0.3688
	--> Epoch [51/100], Loss: 0.0561, Validation Loss: 0.3684
	--> Epoch [52/100], Loss: 0.0442, Validation Loss: 0.3685
	--> Epoch [53/100], Loss: 0.0515, Validation Loss: 0.3673
	--> Epoch [54/100], Loss: 0.0735, Validation Loss: 0.3667
	--> Epoch [55/100], Loss: 0.0271, Validation Loss: 0.3654
	--> Epoch [56/100], Loss: 0.0560, Validation Loss: 0.3672
	--> Epoch [57/100], Loss: 0.0427, Validation Loss: 0.3658
	--> Epoch [58/100], Loss: 0.0118, Validation Loss: 0.3652
	--> Epoch [59/100], Loss: 0.1334, Validation Loss: 0.3659
	--> Epoch [60/100], Loss: 0.0879, Validation Loss: 0.3657
	--> Epoch [61/100], Loss: 0.0087, Validation Loss: 0.3659
Early stopping
	--> Training for Fold 3 took 0.8214554786682129 sec, using 61 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7326, Validation Loss: 0.5922
	--> Epoch [2/100], Loss: 0.6835, Validation Loss: 0.5791
	--> Epoch [3/100], Loss: 0.6028, Validation Loss: 0.5712
	--> Epoch [4/100], Loss: 0.6220, Validation Loss: 0.5658
	--> Epoch [5/100], Loss: 0.5699, Validation Loss: 0.5570
	--> Epoch [6/100], Loss: 0.5702, Validation Loss: 0.5469
	--> Epoch [7/100], Loss: 0.5104, Validation Loss: 0.5347
	--> Epoch [8/100], Loss: 0.5133, Validation Loss: 0.5276
	--> Epoch [9/100], Loss: 0.5359, Validation Loss: 0.5166
	--> Epoch [10/100], Loss: 0.4137, Validation Loss: 0.5056
	--> Epoch [11/100], Loss: 0.4415, Validation Loss: 0.4967
	--> Epoch [12/100], Loss: 0.3667, Validation Loss: 0.4834
	--> Epoch [13/100], Loss: 0.2962, Validation Loss: 0.4725
	--> Epoch [14/100], Loss: 0.2918, Validation Loss: 0.4595
	--> Epoch [15/100], Loss: 0.2802, Validation Loss: 0.4459
	--> Epoch [16/100], Loss: 0.3223, Validation Loss: 0.4384
	--> Epoch [17/100], Loss: 0.1989, Validation Loss: 0.4281
	--> Epoch [18/100], Loss: 0.2868, Validation Loss: 0.4176
	--> Epoch [19/100], Loss: 0.3076, Validation Loss: 0.4071
	--> Epoch [20/100], Loss: 0.3250, Validation Loss: 0.3955
	--> Epoch [21/100], Loss: 0.2286, Validation Loss: 0.3876
	--> Epoch [22/100], Loss: 0.1811, Validation Loss: 0.3785
	--> Epoch [23/100], Loss: 0.2744, Validation Loss: 0.3717
	--> Epoch [24/100], Loss: 0.2628, Validation Loss: 0.3629
	--> Epoch [25/100], Loss: 0.1644, Validation Loss: 0.3580
	--> Epoch [26/100], Loss: 0.2190, Validation Loss: 0.3502
	--> Epoch [27/100], Loss: 0.2081, Validation Loss: 0.3416
	--> Epoch [28/100], Loss: 0.1456, Validation Loss: 0.3338
	--> Epoch [29/100], Loss: 0.1915, Validation Loss: 0.3334
	--> Epoch [30/100], Loss: 0.2093, Validation Loss: 0.3295
	--> Epoch [31/100], Loss: 0.1292, Validation Loss: 0.3240
	--> Epoch [32/100], Loss: 0.1927, Validation Loss: 0.3163
	--> Epoch [33/100], Loss: 0.1490, Validation Loss: 0.3107
	--> Epoch [34/100], Loss: 0.2473, Validation Loss: 0.3058
	--> Epoch [35/100], Loss: 0.2511, Validation Loss: 0.3012
	--> Epoch [36/100], Loss: 0.1441, Validation Loss: 0.2989
	--> Epoch [37/100], Loss: 0.1861, Validation Loss: 0.2980
	--> Epoch [38/100], Loss: 0.1671, Validation Loss: 0.2977
	--> Epoch [39/100], Loss: 0.2147, Validation Loss: 0.2946
	--> Epoch [40/100], Loss: 0.2335, Validation Loss: 0.2900
	--> Epoch [41/100], Loss: 0.1671, Validation Loss: 0.2867
	--> Epoch [42/100], Loss: 0.1741, Validation Loss: 0.2814
	--> Epoch [43/100], Loss: 0.1365, Validation Loss: 0.2781
	--> Epoch [44/100], Loss: 0.2059, Validation Loss: 0.2743
	--> Epoch [45/100], Loss: 0.1050, Validation Loss: 0.2719
	--> Epoch [46/100], Loss: 0.1535, Validation Loss: 0.2693
	--> Epoch [47/100], Loss: 0.1708, Validation Loss: 0.2741
	--> Epoch [48/100], Loss: 0.1212, Validation Loss: 0.2701
	--> Epoch [49/100], Loss: 0.1120, Validation Loss: 0.2670
	--> Epoch [50/100], Loss: 0.1137, Validation Loss: 0.2679
	--> Epoch [51/100], Loss: 0.1142, Validation Loss: 0.2645
	--> Epoch [52/100], Loss: 0.0963, Validation Loss: 0.2637
	--> Epoch [53/100], Loss: 0.0973, Validation Loss: 0.2639
	--> Epoch [54/100], Loss: 0.1160, Validation Loss: 0.2610
	--> Epoch [55/100], Loss: 0.0856, Validation Loss: 0.2589
	--> Epoch [56/100], Loss: 0.1669, Validation Loss: 0.2560
	--> Epoch [57/100], Loss: 0.1654, Validation Loss: 0.2545
	--> Epoch [58/100], Loss: 0.0795, Validation Loss: 0.2519
	--> Epoch [59/100], Loss: 0.0937, Validation Loss: 0.2492
	--> Epoch [60/100], Loss: 0.0932, Validation Loss: 0.2486
	--> Epoch [61/100], Loss: 0.1001, Validation Loss: 0.2461
	--> Epoch [62/100], Loss: 0.1443, Validation Loss: 0.2478
	--> Epoch [63/100], Loss: 0.2482, Validation Loss: 0.2466
	--> Epoch [64/100], Loss: 0.2093, Validation Loss: 0.2467
Early stopping
	--> Training for Fold 4 took 0.8719065189361572 sec, using 64 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6111, Validation Loss: 0.6701
	--> Epoch [2/100], Loss: 0.5888, Validation Loss: 0.6567
	--> Epoch [3/100], Loss: 0.5518, Validation Loss: 0.6435
	--> Epoch [4/100], Loss: 0.5056, Validation Loss: 0.6312
	--> Epoch [5/100], Loss: 0.4845, Validation Loss: 0.6173
	--> Epoch [6/100], Loss: 0.5018, Validation Loss: 0.6044
	--> Epoch [7/100], Loss: 0.4410, Validation Loss: 0.5889
	--> Epoch [8/100], Loss: 0.4532, Validation Loss: 0.5761
	--> Epoch [9/100], Loss: 0.3748, Validation Loss: 0.5658
	--> Epoch [10/100], Loss: 0.4051, Validation Loss: 0.5600
	--> Epoch [11/100], Loss: 0.3393, Validation Loss: 0.5510
	--> Epoch [12/100], Loss: 0.3635, Validation Loss: 0.5448
	--> Epoch [13/100], Loss: 0.2746, Validation Loss: 0.5396
	--> Epoch [14/100], Loss: 0.2745, Validation Loss: 0.5366
	--> Epoch [15/100], Loss: 0.2842, Validation Loss: 0.5311
	--> Epoch [16/100], Loss: 0.2505, Validation Loss: 0.5292
	--> Epoch [17/100], Loss: 0.2383, Validation Loss: 0.5248
	--> Epoch [18/100], Loss: 0.2621, Validation Loss: 0.5203
	--> Epoch [19/100], Loss: 0.2694, Validation Loss: 0.5151
	--> Epoch [20/100], Loss: 0.1707, Validation Loss: 0.5137
	--> Epoch [21/100], Loss: 0.2567, Validation Loss: 0.5104
	--> Epoch [22/100], Loss: 0.2411, Validation Loss: 0.5095
	--> Epoch [23/100], Loss: 0.1407, Validation Loss: 0.5071
	--> Epoch [24/100], Loss: 0.2717, Validation Loss: 0.5059
	--> Epoch [25/100], Loss: 0.2224, Validation Loss: 0.5024
	--> Epoch [26/100], Loss: 0.1637, Validation Loss: 0.4965
	--> Epoch [27/100], Loss: 0.2380, Validation Loss: 0.4965
	--> Epoch [28/100], Loss: 0.1712, Validation Loss: 0.4950
	--> Epoch [29/100], Loss: 0.1667, Validation Loss: 0.4930
	--> Epoch [30/100], Loss: 0.1846, Validation Loss: 0.4896
	--> Epoch [31/100], Loss: 0.1504, Validation Loss: 0.4888
	--> Epoch [32/100], Loss: 0.1369, Validation Loss: 0.4904
	--> Epoch [33/100], Loss: 0.1403, Validation Loss: 0.4893
	--> Epoch [34/100], Loss: 0.1768, Validation Loss: 0.4886
	--> Epoch [35/100], Loss: 0.0854, Validation Loss: 0.4847
	--> Epoch [36/100], Loss: 0.0751, Validation Loss: 0.4813
	--> Epoch [37/100], Loss: 0.1058, Validation Loss: 0.4766
	--> Epoch [38/100], Loss: 0.0994, Validation Loss: 0.4750
	--> Epoch [39/100], Loss: 0.1263, Validation Loss: 0.4752
	--> Epoch [40/100], Loss: 0.0980, Validation Loss: 0.4753
	--> Epoch [41/100], Loss: 0.0534, Validation Loss: 0.4731
	--> Epoch [42/100], Loss: 0.0876, Validation Loss: 0.4733
	--> Epoch [43/100], Loss: 0.1373, Validation Loss: 0.4729
	--> Epoch [44/100], Loss: 0.0734, Validation Loss: 0.4688
	--> Epoch [45/100], Loss: 0.0642, Validation Loss: 0.4687
	--> Epoch [46/100], Loss: 0.0431, Validation Loss: 0.4692
	--> Epoch [47/100], Loss: 0.1355, Validation Loss: 0.4688
	--> Epoch [48/100], Loss: 0.1045, Validation Loss: 0.4676
	--> Epoch [49/100], Loss: 0.1620, Validation Loss: 0.4689
	--> Epoch [50/100], Loss: 0.0693, Validation Loss: 0.4665
	--> Epoch [51/100], Loss: 0.1050, Validation Loss: 0.4651
	--> Epoch [52/100], Loss: 0.0514, Validation Loss: 0.4670
	--> Epoch [53/100], Loss: 0.1970, Validation Loss: 0.4665
	--> Epoch [54/100], Loss: 0.0434, Validation Loss: 0.4604
	--> Epoch [55/100], Loss: 0.0774, Validation Loss: 0.4639
	--> Epoch [56/100], Loss: 0.0341, Validation Loss: 0.4657
	--> Epoch [57/100], Loss: 0.1193, Validation Loss: 0.4648
Early stopping
	--> Training for Fold 5 took 0.8152971267700195 sec, using 57 epochs

Median number of epochs used: 64 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/64], Loss: 0.7167
	--> Final training Epoch [2/64], Loss: 0.6794
	--> Final training Epoch [3/64], Loss: 0.6405
	--> Final training Epoch [4/64], Loss: 0.5893
	--> Final training Epoch [5/64], Loss: 0.5424
	--> Final training Epoch [6/64], Loss: 0.4998
	--> Final training Epoch [7/64], Loss: 0.4948
	--> Final training Epoch [8/64], Loss: 0.5200
	--> Final training Epoch [9/64], Loss: 0.4657
	--> Final training Epoch [10/64], Loss: 0.4693
	--> Final training Epoch [11/64], Loss: 0.4029
	--> Final training Epoch [12/64], Loss: 0.4143
	--> Final training Epoch [13/64], Loss: 0.4360
	--> Final training Epoch [14/64], Loss: 0.3595
	--> Final training Epoch [15/64], Loss: 0.3697
	--> Final training Epoch [16/64], Loss: 0.3328
	--> Final training Epoch [17/64], Loss: 0.3769
	--> Final training Epoch [18/64], Loss: 0.3625
	--> Final training Epoch [19/64], Loss: 0.3341
	--> Final training Epoch [20/64], Loss: 0.3230
	--> Final training Epoch [21/64], Loss: 0.2681
	--> Final training Epoch [22/64], Loss: 0.3055
	--> Final training Epoch [23/64], Loss: 0.2970
	--> Final training Epoch [24/64], Loss: 0.3183
	--> Final training Epoch [25/64], Loss: 0.2206
	--> Final training Epoch [26/64], Loss: 0.2064
	--> Final training Epoch [27/64], Loss: 0.1997
	--> Final training Epoch [28/64], Loss: 0.2450
	--> Final training Epoch [29/64], Loss: 0.2056
	--> Final training Epoch [30/64], Loss: 0.1506
	--> Final training Epoch [31/64], Loss: 0.1833
	--> Final training Epoch [32/64], Loss: 0.1724
	--> Final training Epoch [33/64], Loss: 0.1435
	--> Final training Epoch [34/64], Loss: 0.2195
	--> Final training Epoch [35/64], Loss: 0.2062
	--> Final training Epoch [36/64], Loss: 0.2109
	--> Final training Epoch [37/64], Loss: 0.2059
	--> Final training Epoch [38/64], Loss: 0.1958
	--> Final training Epoch [39/64], Loss: 0.1133
	--> Final training Epoch [40/64], Loss: 0.1281
	--> Final training Epoch [41/64], Loss: 0.1772
	--> Final training Epoch [42/64], Loss: 0.1970
	--> Final training Epoch [43/64], Loss: 0.1411
	--> Final training Epoch [44/64], Loss: 0.2000
	--> Final training Epoch [45/64], Loss: 0.1433
	--> Final training Epoch [46/64], Loss: 0.1612
	--> Final training Epoch [47/64], Loss: 0.1013
	--> Final training Epoch [48/64], Loss: 0.1280
	--> Final training Epoch [49/64], Loss: 0.1011
	--> Final training Epoch [50/64], Loss: 0.1460
	--> Final training Epoch [51/64], Loss: 0.0840
	--> Final training Epoch [52/64], Loss: 0.1176
	--> Final training Epoch [53/64], Loss: 0.0971
	--> Final training Epoch [54/64], Loss: 0.0900
	--> Final training Epoch [55/64], Loss: 0.0724
	--> Final training Epoch [56/64], Loss: 0.1152
	--> Final training Epoch [57/64], Loss: 0.1474
	--> Final training Epoch [58/64], Loss: 0.1097
	--> Final training Epoch [59/64], Loss: 0.0989
	--> Final training Epoch [60/64], Loss: 0.0712
	--> Final training Epoch [61/64], Loss: 0.0841
	--> Final training Epoch [62/64], Loss: 0.1190
	--> Final training Epoch [63/64], Loss: 0.0700
	--> Final training Epoch [64/64], Loss: 0.0857

Final training took 0.8316330909729004 sec

TESTING
	--> Testing took 0.0158 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.9406
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.9029, Validation Loss: 0.3368,  Current Best Accuracy: 0.9029,  Current Best Validation Loss: 0.3368
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8819, Validation Loss: 0.3418,  Current Best Accuracy: 0.9029,  Current Best Validation Loss: 0.3368
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3447,  Current Best Accuracy: 0.9029,  Current Best Validation Loss: 0.3368
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3611,  Current Best Accuracy: 0.9029,  Current Best Validation Loss: 0.3368

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6601, Validation Loss: 0.6491
	--> Epoch [2/100], Loss: 0.7167, Validation Loss: 0.6196
	--> Epoch [3/100], Loss: 0.5798, Validation Loss: 0.5970
	--> Epoch [4/100], Loss: 0.5471, Validation Loss: 0.5746
	--> Epoch [5/100], Loss: 0.5075, Validation Loss: 0.5602
	--> Epoch [6/100], Loss: 0.4510, Validation Loss: 0.5433
	--> Epoch [7/100], Loss: 0.5512, Validation Loss: 0.5271
	--> Epoch [8/100], Loss: 0.5640, Validation Loss: 0.5180
	--> Epoch [9/100], Loss: 0.4275, Validation Loss: 0.5049
	--> Epoch [10/100], Loss: 0.4591, Validation Loss: 0.4910
	--> Epoch [11/100], Loss: 0.3930, Validation Loss: 0.4779
	--> Epoch [12/100], Loss: 0.4280, Validation Loss: 0.4709
	--> Epoch [13/100], Loss: 0.3503, Validation Loss: 0.4578
	--> Epoch [14/100], Loss: 0.3301, Validation Loss: 0.4442
	--> Epoch [15/100], Loss: 0.3887, Validation Loss: 0.4344
	--> Epoch [16/100], Loss: 0.3280, Validation Loss: 0.4249
	--> Epoch [17/100], Loss: 0.3571, Validation Loss: 0.4161
	--> Epoch [18/100], Loss: 0.1986, Validation Loss: 0.4073
	--> Epoch [19/100], Loss: 0.3606, Validation Loss: 0.3978
	--> Epoch [20/100], Loss: 0.3421, Validation Loss: 0.3913
	--> Epoch [21/100], Loss: 0.1919, Validation Loss: 0.3830
	--> Epoch [22/100], Loss: 0.3051, Validation Loss: 0.3771
	--> Epoch [23/100], Loss: 0.2815, Validation Loss: 0.3681
	--> Epoch [24/100], Loss: 0.2727, Validation Loss: 0.3621
	--> Epoch [25/100], Loss: 0.2723, Validation Loss: 0.3559
	--> Epoch [26/100], Loss: 0.2343, Validation Loss: 0.3510
	--> Epoch [27/100], Loss: 0.2348, Validation Loss: 0.3467
	--> Epoch [28/100], Loss: 0.2198, Validation Loss: 0.3409
	--> Epoch [29/100], Loss: 0.3683, Validation Loss: 0.3368
	--> Epoch [30/100], Loss: 0.2528, Validation Loss: 0.3326
	--> Epoch [31/100], Loss: 0.2403, Validation Loss: 0.3274
	--> Epoch [32/100], Loss: 0.1704, Validation Loss: 0.3231
	--> Epoch [33/100], Loss: 0.3116, Validation Loss: 0.3194
	--> Epoch [34/100], Loss: 0.1957, Validation Loss: 0.3171
	--> Epoch [35/100], Loss: 0.2074, Validation Loss: 0.3137
	--> Epoch [36/100], Loss: 0.2679, Validation Loss: 0.3129
	--> Epoch [37/100], Loss: 0.1974, Validation Loss: 0.3071
	--> Epoch [38/100], Loss: 0.1145, Validation Loss: 0.3038
	--> Epoch [39/100], Loss: 0.1865, Validation Loss: 0.2991
	--> Epoch [40/100], Loss: 0.1851, Validation Loss: 0.2974
	--> Epoch [41/100], Loss: 0.1983, Validation Loss: 0.2961
	--> Epoch [42/100], Loss: 0.1826, Validation Loss: 0.2933
	--> Epoch [43/100], Loss: 0.1623, Validation Loss: 0.2911
	--> Epoch [44/100], Loss: 0.1886, Validation Loss: 0.2875
	--> Epoch [45/100], Loss: 0.1706, Validation Loss: 0.2868
	--> Epoch [46/100], Loss: 0.3734, Validation Loss: 0.2857
	--> Epoch [47/100], Loss: 0.2209, Validation Loss: 0.2826
	--> Epoch [48/100], Loss: 0.2296, Validation Loss: 0.2805
	--> Epoch [49/100], Loss: 0.1204, Validation Loss: 0.2786
	--> Epoch [50/100], Loss: 0.1153, Validation Loss: 0.2776
	--> Epoch [51/100], Loss: 0.1059, Validation Loss: 0.2759
	--> Epoch [52/100], Loss: 0.1706, Validation Loss: 0.2755
	--> Epoch [53/100], Loss: 0.1525, Validation Loss: 0.2748
	--> Epoch [54/100], Loss: 0.1292, Validation Loss: 0.2739
	--> Epoch [55/100], Loss: 0.1821, Validation Loss: 0.2718
	--> Epoch [56/100], Loss: 0.2279, Validation Loss: 0.2722
	--> Epoch [57/100], Loss: 0.0982, Validation Loss: 0.2700
	--> Epoch [58/100], Loss: 0.1355, Validation Loss: 0.2716
	--> Epoch [59/100], Loss: 0.0886, Validation Loss: 0.2720
	--> Epoch [60/100], Loss: 0.2273, Validation Loss: 0.2713
Early stopping
	--> Training for Fold 1 took 0.7998878955841064 sec, using 60 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7814, Validation Loss: 0.6842
	--> Epoch [2/100], Loss: 0.7278, Validation Loss: 0.6660
	--> Epoch [3/100], Loss: 0.6745, Validation Loss: 0.6470
	--> Epoch [4/100], Loss: 0.6400, Validation Loss: 0.6289
	--> Epoch [5/100], Loss: 0.6001, Validation Loss: 0.6081
	--> Epoch [6/100], Loss: 0.5267, Validation Loss: 0.5892
	--> Epoch [7/100], Loss: 0.6143, Validation Loss: 0.5725
	--> Epoch [8/100], Loss: 0.5751, Validation Loss: 0.5584
	--> Epoch [9/100], Loss: 0.4980, Validation Loss: 0.5438
	--> Epoch [10/100], Loss: 0.5158, Validation Loss: 0.5271
	--> Epoch [11/100], Loss: 0.4860, Validation Loss: 0.5147
	--> Epoch [12/100], Loss: 0.4809, Validation Loss: 0.5020
	--> Epoch [13/100], Loss: 0.5112, Validation Loss: 0.4908
	--> Epoch [14/100], Loss: 0.4490, Validation Loss: 0.4779
	--> Epoch [15/100], Loss: 0.4815, Validation Loss: 0.4674
	--> Epoch [16/100], Loss: 0.3714, Validation Loss: 0.4548
	--> Epoch [17/100], Loss: 0.2956, Validation Loss: 0.4419
	--> Epoch [18/100], Loss: 0.2971, Validation Loss: 0.4297
	--> Epoch [19/100], Loss: 0.3244, Validation Loss: 0.4183
	--> Epoch [20/100], Loss: 0.3654, Validation Loss: 0.4072
	--> Epoch [21/100], Loss: 0.2791, Validation Loss: 0.3971
	--> Epoch [22/100], Loss: 0.2065, Validation Loss: 0.3856
	--> Epoch [23/100], Loss: 0.2160, Validation Loss: 0.3788
	--> Epoch [24/100], Loss: 0.3386, Validation Loss: 0.3688
	--> Epoch [25/100], Loss: 0.1881, Validation Loss: 0.3603
	--> Epoch [26/100], Loss: 0.2133, Validation Loss: 0.3527
	--> Epoch [27/100], Loss: 0.2329, Validation Loss: 0.3452
	--> Epoch [28/100], Loss: 0.2942, Validation Loss: 0.3387
	--> Epoch [29/100], Loss: 0.2288, Validation Loss: 0.3330
	--> Epoch [30/100], Loss: 0.2470, Validation Loss: 0.3269
	--> Epoch [31/100], Loss: 0.1191, Validation Loss: 0.3218
	--> Epoch [32/100], Loss: 0.1610, Validation Loss: 0.3177
	--> Epoch [33/100], Loss: 0.2558, Validation Loss: 0.3117
	--> Epoch [34/100], Loss: 0.3706, Validation Loss: 0.3087
	--> Epoch [35/100], Loss: 0.1615, Validation Loss: 0.3030
	--> Epoch [36/100], Loss: 0.3202, Validation Loss: 0.2981
	--> Epoch [37/100], Loss: 0.2237, Validation Loss: 0.2932
	--> Epoch [38/100], Loss: 0.3035, Validation Loss: 0.2906
	--> Epoch [39/100], Loss: 0.2178, Validation Loss: 0.2861
	--> Epoch [40/100], Loss: 0.1316, Validation Loss: 0.2825
	--> Epoch [41/100], Loss: 0.1936, Validation Loss: 0.2806
	--> Epoch [42/100], Loss: 0.1218, Validation Loss: 0.2782
	--> Epoch [43/100], Loss: 0.1850, Validation Loss: 0.2731
	--> Epoch [44/100], Loss: 0.2199, Validation Loss: 0.2713
	--> Epoch [45/100], Loss: 0.0429, Validation Loss: 0.2690
	--> Epoch [46/100], Loss: 0.2107, Validation Loss: 0.2670
	--> Epoch [47/100], Loss: 0.2805, Validation Loss: 0.2664
	--> Epoch [48/100], Loss: 0.1247, Validation Loss: 0.2642
	--> Epoch [49/100], Loss: 0.2184, Validation Loss: 0.2620
	--> Epoch [50/100], Loss: 0.2293, Validation Loss: 0.2570
	--> Epoch [51/100], Loss: 0.1717, Validation Loss: 0.2546
	--> Epoch [52/100], Loss: 0.1402, Validation Loss: 0.2538
	--> Epoch [53/100], Loss: 0.1036, Validation Loss: 0.2527
	--> Epoch [54/100], Loss: 0.3852, Validation Loss: 0.2520
	--> Epoch [55/100], Loss: 0.1615, Validation Loss: 0.2502
	--> Epoch [56/100], Loss: 0.1596, Validation Loss: 0.2466
	--> Epoch [57/100], Loss: 0.2699, Validation Loss: 0.2435
	--> Epoch [58/100], Loss: 0.1475, Validation Loss: 0.2392
	--> Epoch [59/100], Loss: 0.1127, Validation Loss: 0.2379
	--> Epoch [60/100], Loss: 0.2234, Validation Loss: 0.2348
	--> Epoch [61/100], Loss: 0.1474, Validation Loss: 0.2343
	--> Epoch [62/100], Loss: 0.2459, Validation Loss: 0.2317
	--> Epoch [63/100], Loss: 0.2241, Validation Loss: 0.2279
	--> Epoch [64/100], Loss: 0.2267, Validation Loss: 0.2267
	--> Epoch [65/100], Loss: 0.0896, Validation Loss: 0.2277
	--> Epoch [66/100], Loss: 0.1513, Validation Loss: 0.2272
	--> Epoch [67/100], Loss: 0.2731, Validation Loss: 0.2259
	--> Epoch [68/100], Loss: 0.1437, Validation Loss: 0.2247
	--> Epoch [69/100], Loss: 0.1351, Validation Loss: 0.2232
	--> Epoch [70/100], Loss: 0.0204, Validation Loss: 0.2212
	--> Epoch [71/100], Loss: 0.1948, Validation Loss: 0.2200
	--> Epoch [72/100], Loss: 0.1944, Validation Loss: 0.2194
	--> Epoch [73/100], Loss: 0.2016, Validation Loss: 0.2155
	--> Epoch [74/100], Loss: 0.0213, Validation Loss: 0.2153
	--> Epoch [75/100], Loss: 0.1407, Validation Loss: 0.2137
	--> Epoch [76/100], Loss: 0.1454, Validation Loss: 0.2132
	--> Epoch [77/100], Loss: 0.1507, Validation Loss: 0.2118
	--> Epoch [78/100], Loss: 0.0778, Validation Loss: 0.2111
	--> Epoch [79/100], Loss: 0.1436, Validation Loss: 0.2124
	--> Epoch [80/100], Loss: 0.0896, Validation Loss: 0.2118
	--> Epoch [81/100], Loss: 0.1356, Validation Loss: 0.2107
	--> Epoch [82/100], Loss: 0.1254, Validation Loss: 0.2100
	--> Epoch [83/100], Loss: 0.1927, Validation Loss: 0.2095
	--> Epoch [84/100], Loss: 0.1302, Validation Loss: 0.2079
	--> Epoch [85/100], Loss: 0.0750, Validation Loss: 0.2065
	--> Epoch [86/100], Loss: 0.1480, Validation Loss: 0.2052
	--> Epoch [87/100], Loss: 0.2094, Validation Loss: 0.2046
	--> Epoch [88/100], Loss: 0.1336, Validation Loss: 0.2042
	--> Epoch [89/100], Loss: 0.0760, Validation Loss: 0.2029
	--> Epoch [90/100], Loss: 0.0735, Validation Loss: 0.2024
	--> Epoch [91/100], Loss: 0.0717, Validation Loss: 0.2031
	--> Epoch [92/100], Loss: 0.1885, Validation Loss: 0.2020
	--> Epoch [93/100], Loss: 0.1249, Validation Loss: 0.2010
	--> Epoch [94/100], Loss: 0.0689, Validation Loss: 0.2007
	--> Epoch [95/100], Loss: 0.3247, Validation Loss: 0.1992
	--> Epoch [96/100], Loss: 0.0925, Validation Loss: 0.1982
	--> Epoch [97/100], Loss: 0.0872, Validation Loss: 0.1954
	--> Epoch [98/100], Loss: 0.0756, Validation Loss: 0.1942
	--> Epoch [99/100], Loss: 0.1885, Validation Loss: 0.1938
	--> Epoch [100/100], Loss: 0.2360, Validation Loss: 0.1935
	--> Training for Fold 2 took 1.3421192169189453 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6793, Validation Loss: 0.7108
	--> Epoch [2/100], Loss: 0.6390, Validation Loss: 0.6975
	--> Epoch [3/100], Loss: 0.5349, Validation Loss: 0.6848
	--> Epoch [4/100], Loss: 0.4593, Validation Loss: 0.6710
	--> Epoch [5/100], Loss: 0.5647, Validation Loss: 0.6604
	--> Epoch [6/100], Loss: 0.4199, Validation Loss: 0.6419
	--> Epoch [7/100], Loss: 0.3818, Validation Loss: 0.6275
	--> Epoch [8/100], Loss: 0.4139, Validation Loss: 0.6165
	--> Epoch [9/100], Loss: 0.4085, Validation Loss: 0.6053
	--> Epoch [10/100], Loss: 0.4257, Validation Loss: 0.5967
	--> Epoch [11/100], Loss: 0.2942, Validation Loss: 0.5847
	--> Epoch [12/100], Loss: 0.3784, Validation Loss: 0.5756
	--> Epoch [13/100], Loss: 0.3803, Validation Loss: 0.5651
	--> Epoch [14/100], Loss: 0.3884, Validation Loss: 0.5574
	--> Epoch [15/100], Loss: 0.2622, Validation Loss: 0.5433
	--> Epoch [16/100], Loss: 0.2628, Validation Loss: 0.5364
	--> Epoch [17/100], Loss: 0.3410, Validation Loss: 0.5259
	--> Epoch [18/100], Loss: 0.2026, Validation Loss: 0.5162
	--> Epoch [19/100], Loss: 0.2755, Validation Loss: 0.5099
	--> Epoch [20/100], Loss: 0.3362, Validation Loss: 0.4996
	--> Epoch [21/100], Loss: 0.2043, Validation Loss: 0.4922
	--> Epoch [22/100], Loss: 0.2458, Validation Loss: 0.4843
	--> Epoch [23/100], Loss: 0.2175, Validation Loss: 0.4775
	--> Epoch [24/100], Loss: 0.2511, Validation Loss: 0.4698
	--> Epoch [25/100], Loss: 0.2619, Validation Loss: 0.4609
	--> Epoch [26/100], Loss: 0.2585, Validation Loss: 0.4532
	--> Epoch [27/100], Loss: 0.2128, Validation Loss: 0.4491
	--> Epoch [28/100], Loss: 0.1561, Validation Loss: 0.4420
	--> Epoch [29/100], Loss: 0.2534, Validation Loss: 0.4358
	--> Epoch [30/100], Loss: 0.2110, Validation Loss: 0.4292
	--> Epoch [31/100], Loss: 0.2412, Validation Loss: 0.4248
	--> Epoch [32/100], Loss: 0.1770, Validation Loss: 0.4243
	--> Epoch [33/100], Loss: 0.2967, Validation Loss: 0.4208
	--> Epoch [34/100], Loss: 0.1639, Validation Loss: 0.4188
	--> Epoch [35/100], Loss: 0.1385, Validation Loss: 0.4147
	--> Epoch [36/100], Loss: 0.1851, Validation Loss: 0.4103
	--> Epoch [37/100], Loss: 0.1060, Validation Loss: 0.4041
	--> Epoch [38/100], Loss: 0.2345, Validation Loss: 0.4012
	--> Epoch [39/100], Loss: 0.1420, Validation Loss: 0.3989
	--> Epoch [40/100], Loss: 0.1869, Validation Loss: 0.3974
	--> Epoch [41/100], Loss: 0.1382, Validation Loss: 0.3925
	--> Epoch [42/100], Loss: 0.1373, Validation Loss: 0.3873
	--> Epoch [43/100], Loss: 0.1967, Validation Loss: 0.3843
	--> Epoch [44/100], Loss: 0.1791, Validation Loss: 0.3809
	--> Epoch [45/100], Loss: 0.1248, Validation Loss: 0.3797
	--> Epoch [46/100], Loss: 0.1864, Validation Loss: 0.3786
	--> Epoch [47/100], Loss: 0.2093, Validation Loss: 0.3762
	--> Epoch [48/100], Loss: 0.1707, Validation Loss: 0.3728
	--> Epoch [49/100], Loss: 0.1364, Validation Loss: 0.3721
	--> Epoch [50/100], Loss: 0.1527, Validation Loss: 0.3702
	--> Epoch [51/100], Loss: 0.1710, Validation Loss: 0.3680
	--> Epoch [52/100], Loss: 0.1455, Validation Loss: 0.3668
	--> Epoch [53/100], Loss: 0.0797, Validation Loss: 0.3649
	--> Epoch [54/100], Loss: 0.1442, Validation Loss: 0.3622
	--> Epoch [55/100], Loss: 0.1621, Validation Loss: 0.3599
	--> Epoch [56/100], Loss: 0.1231, Validation Loss: 0.3594
	--> Epoch [57/100], Loss: 0.1326, Validation Loss: 0.3573
	--> Epoch [58/100], Loss: 0.0690, Validation Loss: 0.3545
	--> Epoch [59/100], Loss: 0.1112, Validation Loss: 0.3504
	--> Epoch [60/100], Loss: 0.1644, Validation Loss: 0.3486
	--> Epoch [61/100], Loss: 0.2018, Validation Loss: 0.3442
	--> Epoch [62/100], Loss: 0.1532, Validation Loss: 0.3423
	--> Epoch [63/100], Loss: 0.2075, Validation Loss: 0.3403
	--> Epoch [64/100], Loss: 0.1060, Validation Loss: 0.3407
	--> Epoch [65/100], Loss: 0.2010, Validation Loss: 0.3382
	--> Epoch [66/100], Loss: 0.1041, Validation Loss: 0.3346
	--> Epoch [67/100], Loss: 0.1299, Validation Loss: 0.3348
	--> Epoch [68/100], Loss: 0.1030, Validation Loss: 0.3352
	--> Epoch [69/100], Loss: 0.1063, Validation Loss: 0.3324
	--> Epoch [70/100], Loss: 0.1932, Validation Loss: 0.3284
	--> Epoch [71/100], Loss: 0.1584, Validation Loss: 0.3253
	--> Epoch [72/100], Loss: 0.2811, Validation Loss: 0.3236
	--> Epoch [73/100], Loss: 0.1071, Validation Loss: 0.3224
	--> Epoch [74/100], Loss: 0.1458, Validation Loss: 0.3205
	--> Epoch [75/100], Loss: 0.0735, Validation Loss: 0.3186
	--> Epoch [76/100], Loss: 0.1478, Validation Loss: 0.3158
	--> Epoch [77/100], Loss: 0.1909, Validation Loss: 0.3108
	--> Epoch [78/100], Loss: 0.1949, Validation Loss: 0.3086
	--> Epoch [79/100], Loss: 0.1865, Validation Loss: 0.3076
	--> Epoch [80/100], Loss: 0.1048, Validation Loss: 0.3076
	--> Epoch [81/100], Loss: 0.1930, Validation Loss: 0.3063
	--> Epoch [82/100], Loss: 0.1213, Validation Loss: 0.3056
	--> Epoch [83/100], Loss: 0.1068, Validation Loss: 0.3042
	--> Epoch [84/100], Loss: 0.1467, Validation Loss: 0.3013
	--> Epoch [85/100], Loss: 0.0663, Validation Loss: 0.3022
	--> Epoch [86/100], Loss: 0.1429, Validation Loss: 0.3011
	--> Epoch [87/100], Loss: 0.1406, Validation Loss: 0.3021
	--> Epoch [88/100], Loss: 0.2832, Validation Loss: 0.3027
	--> Epoch [89/100], Loss: 0.1823, Validation Loss: 0.3006
	--> Epoch [90/100], Loss: 0.0652, Validation Loss: 0.2989
	--> Epoch [91/100], Loss: 0.1366, Validation Loss: 0.2950
	--> Epoch [92/100], Loss: 0.0962, Validation Loss: 0.2922
	--> Epoch [93/100], Loss: 0.1422, Validation Loss: 0.2903
	--> Epoch [94/100], Loss: 0.2440, Validation Loss: 0.2868
	--> Epoch [95/100], Loss: 0.1006, Validation Loss: 0.2851
	--> Epoch [96/100], Loss: 0.1359, Validation Loss: 0.2851
	--> Epoch [97/100], Loss: 0.1847, Validation Loss: 0.2843
	--> Epoch [98/100], Loss: 0.0488, Validation Loss: 0.2813
	--> Epoch [99/100], Loss: 0.0927, Validation Loss: 0.2823
	--> Epoch [100/100], Loss: 0.2231, Validation Loss: 0.2851
	--> Training for Fold 3 took 1.1975810527801514 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7375, Validation Loss: 0.6940
	--> Epoch [2/100], Loss: 0.7034, Validation Loss: 0.6767
	--> Epoch [3/100], Loss: 0.6392, Validation Loss: 0.6668
	--> Epoch [4/100], Loss: 0.5606, Validation Loss: 0.6492
	--> Epoch [5/100], Loss: 0.5774, Validation Loss: 0.6436
	--> Epoch [6/100], Loss: 0.5800, Validation Loss: 0.6333
	--> Epoch [7/100], Loss: 0.5505, Validation Loss: 0.6242
	--> Epoch [8/100], Loss: 0.5179, Validation Loss: 0.6223
	--> Epoch [9/100], Loss: 0.5219, Validation Loss: 0.6153
	--> Epoch [10/100], Loss: 0.4491, Validation Loss: 0.6039
	--> Epoch [11/100], Loss: 0.4334, Validation Loss: 0.5959
	--> Epoch [12/100], Loss: 0.4358, Validation Loss: 0.5921
	--> Epoch [13/100], Loss: 0.4304, Validation Loss: 0.5871
	--> Epoch [14/100], Loss: 0.4909, Validation Loss: 0.5738
	--> Epoch [15/100], Loss: 0.3604, Validation Loss: 0.5707
	--> Epoch [16/100], Loss: 0.3834, Validation Loss: 0.5598
	--> Epoch [17/100], Loss: 0.4010, Validation Loss: 0.5546
	--> Epoch [18/100], Loss: 0.3672, Validation Loss: 0.5553
	--> Epoch [19/100], Loss: 0.3726, Validation Loss: 0.5471
	--> Epoch [20/100], Loss: 0.2746, Validation Loss: 0.5371
	--> Epoch [21/100], Loss: 0.2616, Validation Loss: 0.5314
	--> Epoch [22/100], Loss: 0.1784, Validation Loss: 0.5222
	--> Epoch [23/100], Loss: 0.2998, Validation Loss: 0.5150
	--> Epoch [24/100], Loss: 0.1934, Validation Loss: 0.5099
	--> Epoch [25/100], Loss: 0.2932, Validation Loss: 0.4954
	--> Epoch [26/100], Loss: 0.3579, Validation Loss: 0.4917
	--> Epoch [27/100], Loss: 0.2461, Validation Loss: 0.4808
	--> Epoch [28/100], Loss: 0.3653, Validation Loss: 0.4814
	--> Epoch [29/100], Loss: 0.1941, Validation Loss: 0.4730
	--> Epoch [30/100], Loss: 0.2941, Validation Loss: 0.4714
	--> Epoch [31/100], Loss: 0.2753, Validation Loss: 0.4632
	--> Epoch [32/100], Loss: 0.1485, Validation Loss: 0.4573
	--> Epoch [33/100], Loss: 0.3498, Validation Loss: 0.4535
	--> Epoch [34/100], Loss: 0.3060, Validation Loss: 0.4547
	--> Epoch [35/100], Loss: 0.1920, Validation Loss: 0.4469
	--> Epoch [36/100], Loss: 0.1480, Validation Loss: 0.4423
	--> Epoch [37/100], Loss: 0.1913, Validation Loss: 0.4401
	--> Epoch [38/100], Loss: 0.2234, Validation Loss: 0.4379
	--> Epoch [39/100], Loss: 0.2100, Validation Loss: 0.4334
	--> Epoch [40/100], Loss: 0.2101, Validation Loss: 0.4360
	--> Epoch [41/100], Loss: 0.1691, Validation Loss: 0.4306
	--> Epoch [42/100], Loss: 0.2475, Validation Loss: 0.4317
	--> Epoch [43/100], Loss: 0.0963, Validation Loss: 0.4250
	--> Epoch [44/100], Loss: 0.0674, Validation Loss: 0.4184
	--> Epoch [45/100], Loss: 0.1636, Validation Loss: 0.4148
	--> Epoch [46/100], Loss: 0.1730, Validation Loss: 0.4113
	--> Epoch [47/100], Loss: 0.2162, Validation Loss: 0.4060
	--> Epoch [48/100], Loss: 0.2062, Validation Loss: 0.4009
	--> Epoch [49/100], Loss: 0.1988, Validation Loss: 0.4027
	--> Epoch [50/100], Loss: 0.1408, Validation Loss: 0.4004
	--> Epoch [51/100], Loss: 0.1496, Validation Loss: 0.3981
	--> Epoch [52/100], Loss: 0.0453, Validation Loss: 0.3986
	--> Epoch [53/100], Loss: 0.1929, Validation Loss: 0.3924
	--> Epoch [54/100], Loss: 0.2092, Validation Loss: 0.3906
	--> Epoch [55/100], Loss: 0.1043, Validation Loss: 0.3863
	--> Epoch [56/100], Loss: 0.0880, Validation Loss: 0.3920
	--> Epoch [57/100], Loss: 0.2199, Validation Loss: 0.3873
	--> Epoch [58/100], Loss: 0.0960, Validation Loss: 0.3845
	--> Epoch [59/100], Loss: 0.1628, Validation Loss: 0.3822
	--> Epoch [60/100], Loss: 0.1224, Validation Loss: 0.3809
	--> Epoch [61/100], Loss: 0.1693, Validation Loss: 0.3818
	--> Epoch [62/100], Loss: 0.1462, Validation Loss: 0.3806
	--> Epoch [63/100], Loss: 0.0239, Validation Loss: 0.3808
	--> Epoch [64/100], Loss: 0.2082, Validation Loss: 0.3869
	--> Epoch [65/100], Loss: 0.0511, Validation Loss: 0.3870
Early stopping
	--> Training for Fold 4 took 0.693640947341919 sec, using 65 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8618, Validation Loss: 0.6237
	--> Epoch [2/100], Loss: 0.8659, Validation Loss: 0.6171
	--> Epoch [3/100], Loss: 0.8001, Validation Loss: 0.6098
	--> Epoch [4/100], Loss: 0.7628, Validation Loss: 0.6025
	--> Epoch [5/100], Loss: 0.7682, Validation Loss: 0.5957
	--> Epoch [6/100], Loss: 0.7563, Validation Loss: 0.5861
	--> Epoch [7/100], Loss: 0.6956, Validation Loss: 0.5786
	--> Epoch [8/100], Loss: 0.7298, Validation Loss: 0.5739
	--> Epoch [9/100], Loss: 0.6675, Validation Loss: 0.5695
	--> Epoch [10/100], Loss: 0.5867, Validation Loss: 0.5644
	--> Epoch [11/100], Loss: 0.6005, Validation Loss: 0.5594
	--> Epoch [12/100], Loss: 0.5874, Validation Loss: 0.5535
	--> Epoch [13/100], Loss: 0.5776, Validation Loss: 0.5500
	--> Epoch [14/100], Loss: 0.6162, Validation Loss: 0.5469
	--> Epoch [15/100], Loss: 0.5245, Validation Loss: 0.5448
	--> Epoch [16/100], Loss: 0.4597, Validation Loss: 0.5396
	--> Epoch [17/100], Loss: 0.4419, Validation Loss: 0.5351
	--> Epoch [18/100], Loss: 0.5320, Validation Loss: 0.5318
	--> Epoch [19/100], Loss: 0.4435, Validation Loss: 0.5288
	--> Epoch [20/100], Loss: 0.4150, Validation Loss: 0.5232
	--> Epoch [21/100], Loss: 0.3412, Validation Loss: 0.5204
	--> Epoch [22/100], Loss: 0.5292, Validation Loss: 0.5189
	--> Epoch [23/100], Loss: 0.3499, Validation Loss: 0.5162
	--> Epoch [24/100], Loss: 0.3690, Validation Loss: 0.5147
	--> Epoch [25/100], Loss: 0.4080, Validation Loss: 0.5112
	--> Epoch [26/100], Loss: 0.3339, Validation Loss: 0.5102
	--> Epoch [27/100], Loss: 0.3937, Validation Loss: 0.5100
	--> Epoch [28/100], Loss: 0.3714, Validation Loss: 0.5067
	--> Epoch [29/100], Loss: 0.2279, Validation Loss: 0.5041
	--> Epoch [30/100], Loss: 0.3320, Validation Loss: 0.5004
	--> Epoch [31/100], Loss: 0.3303, Validation Loss: 0.4989
	--> Epoch [32/100], Loss: 0.2588, Validation Loss: 0.4951
	--> Epoch [33/100], Loss: 0.2361, Validation Loss: 0.4917
	--> Epoch [34/100], Loss: 0.3369, Validation Loss: 0.4887
	--> Epoch [35/100], Loss: 0.2486, Validation Loss: 0.4881
	--> Epoch [36/100], Loss: 0.3455, Validation Loss: 0.4859
	--> Epoch [37/100], Loss: 0.2911, Validation Loss: 0.4855
	--> Epoch [38/100], Loss: 0.3461, Validation Loss: 0.4845
	--> Epoch [39/100], Loss: 0.2655, Validation Loss: 0.4858
	--> Epoch [40/100], Loss: 0.2159, Validation Loss: 0.4858
	--> Epoch [41/100], Loss: 0.2428, Validation Loss: 0.4844
	--> Epoch [42/100], Loss: 0.2694, Validation Loss: 0.4833
	--> Epoch [43/100], Loss: 0.2922, Validation Loss: 0.4818
	--> Epoch [44/100], Loss: 0.3204, Validation Loss: 0.4790
	--> Epoch [45/100], Loss: 0.2498, Validation Loss: 0.4786
	--> Epoch [46/100], Loss: 0.2607, Validation Loss: 0.4791
	--> Epoch [47/100], Loss: 0.1950, Validation Loss: 0.4776
	--> Epoch [48/100], Loss: 0.2808, Validation Loss: 0.4774
	--> Epoch [49/100], Loss: 0.2676, Validation Loss: 0.4791
	--> Epoch [50/100], Loss: 0.2795, Validation Loss: 0.4788
	--> Epoch [51/100], Loss: 0.2571, Validation Loss: 0.4767
	--> Epoch [52/100], Loss: 0.3524, Validation Loss: 0.4752
	--> Epoch [53/100], Loss: 0.2998, Validation Loss: 0.4726
	--> Epoch [54/100], Loss: 0.2969, Validation Loss: 0.4736
	--> Epoch [55/100], Loss: 0.1630, Validation Loss: 0.4719
	--> Epoch [56/100], Loss: 0.1514, Validation Loss: 0.4706
	--> Epoch [57/100], Loss: 0.2462, Validation Loss: 0.4699
	--> Epoch [58/100], Loss: 0.3246, Validation Loss: 0.4654
	--> Epoch [59/100], Loss: 0.1400, Validation Loss: 0.4652
	--> Epoch [60/100], Loss: 0.3356, Validation Loss: 0.4649
	--> Epoch [61/100], Loss: 0.1757, Validation Loss: 0.4671
	--> Epoch [62/100], Loss: 0.1783, Validation Loss: 0.4677
	--> Epoch [63/100], Loss: 0.2812, Validation Loss: 0.4680
Early stopping
	--> Training for Fold 5 took 0.7233185768127441 sec, using 63 epochs

Median number of epochs used: 65 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/65], Loss: 0.8673
	--> Final training Epoch [2/65], Loss: 0.7546
	--> Final training Epoch [3/65], Loss: 0.7017
	--> Final training Epoch [4/65], Loss: 0.6662
	--> Final training Epoch [5/65], Loss: 0.6635
	--> Final training Epoch [6/65], Loss: 0.5773
	--> Final training Epoch [7/65], Loss: 0.6117
	--> Final training Epoch [8/65], Loss: 0.5944
	--> Final training Epoch [9/65], Loss: 0.5747
	--> Final training Epoch [10/65], Loss: 0.5577
	--> Final training Epoch [11/65], Loss: 0.5416
	--> Final training Epoch [12/65], Loss: 0.5655
	--> Final training Epoch [13/65], Loss: 0.4685
	--> Final training Epoch [14/65], Loss: 0.5264
	--> Final training Epoch [15/65], Loss: 0.4711
	--> Final training Epoch [16/65], Loss: 0.4772
	--> Final training Epoch [17/65], Loss: 0.4793
	--> Final training Epoch [18/65], Loss: 0.4273
	--> Final training Epoch [19/65], Loss: 0.3919
	--> Final training Epoch [20/65], Loss: 0.4048
	--> Final training Epoch [21/65], Loss: 0.4197
	--> Final training Epoch [22/65], Loss: 0.3631
	--> Final training Epoch [23/65], Loss: 0.3643
	--> Final training Epoch [24/65], Loss: 0.3172
	--> Final training Epoch [25/65], Loss: 0.4269
	--> Final training Epoch [26/65], Loss: 0.3964
	--> Final training Epoch [27/65], Loss: 0.2747
	--> Final training Epoch [28/65], Loss: 0.4334
	--> Final training Epoch [29/65], Loss: 0.3987
	--> Final training Epoch [30/65], Loss: 0.3343
	--> Final training Epoch [31/65], Loss: 0.3596
	--> Final training Epoch [32/65], Loss: 0.2899
	--> Final training Epoch [33/65], Loss: 0.2925
	--> Final training Epoch [34/65], Loss: 0.3283
	--> Final training Epoch [35/65], Loss: 0.3418
	--> Final training Epoch [36/65], Loss: 0.2575
	--> Final training Epoch [37/65], Loss: 0.2374
	--> Final training Epoch [38/65], Loss: 0.2886
	--> Final training Epoch [39/65], Loss: 0.2784
	--> Final training Epoch [40/65], Loss: 0.2601
	--> Final training Epoch [41/65], Loss: 0.3021
	--> Final training Epoch [42/65], Loss: 0.2681
	--> Final training Epoch [43/65], Loss: 0.2150
	--> Final training Epoch [44/65], Loss: 0.2488
	--> Final training Epoch [45/65], Loss: 0.2026
	--> Final training Epoch [46/65], Loss: 0.2397
	--> Final training Epoch [47/65], Loss: 0.2033
	--> Final training Epoch [48/65], Loss: 0.2165
	--> Final training Epoch [49/65], Loss: 0.1831
	--> Final training Epoch [50/65], Loss: 0.2223
	--> Final training Epoch [51/65], Loss: 0.1636
	--> Final training Epoch [52/65], Loss: 0.2527
	--> Final training Epoch [53/65], Loss: 0.2162
	--> Final training Epoch [54/65], Loss: 0.3004
	--> Final training Epoch [55/65], Loss: 0.2250
	--> Final training Epoch [56/65], Loss: 0.2030
	--> Final training Epoch [57/65], Loss: 0.1849
	--> Final training Epoch [58/65], Loss: 0.2260
	--> Final training Epoch [59/65], Loss: 0.1638
	--> Final training Epoch [60/65], Loss: 0.1642
	--> Final training Epoch [61/65], Loss: 0.2027
	--> Final training Epoch [62/65], Loss: 0.1819
	--> Final training Epoch [63/65], Loss: 0.1683
	--> Final training Epoch [64/65], Loss: 0.1749
	--> Final training Epoch [65/65], Loss: 0.2349

Final training took 0.6761133670806885 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.9159
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8801, Validation Loss: 0.3262,  Current Best Accuracy: 0.8801,  Current Best Validation Loss: 0.3262
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8713, Validation Loss: 0.3514,  Current Best Accuracy: 0.8801,  Current Best Validation Loss: 0.3262
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4058,  Current Best Accuracy: 0.8801,  Current Best Validation Loss: 0.3262
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8480, Validation Loss: 0.3952,  Current Best Accuracy: 0.8801,  Current Best Validation Loss: 0.3262
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8058, Validation Loss: 0.4081,  Current Best Accuracy: 0.8801,  Current Best Validation Loss: 0.3262

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6826, Validation Loss: 0.6526
	--> Epoch [2/100], Loss: 0.6341, Validation Loss: 0.6360
	--> Epoch [3/100], Loss: 0.5975, Validation Loss: 0.6224
	--> Epoch [4/100], Loss: 0.5670, Validation Loss: 0.6093
	--> Epoch [5/100], Loss: 0.5242, Validation Loss: 0.5973
	--> Epoch [6/100], Loss: 0.5465, Validation Loss: 0.5854
	--> Epoch [7/100], Loss: 0.5316, Validation Loss: 0.5746
	--> Epoch [8/100], Loss: 0.4543, Validation Loss: 0.5654
	--> Epoch [9/100], Loss: 0.4680, Validation Loss: 0.5545
	--> Epoch [10/100], Loss: 0.4462, Validation Loss: 0.5445
	--> Epoch [11/100], Loss: 0.4620, Validation Loss: 0.5339
	--> Epoch [12/100], Loss: 0.3871, Validation Loss: 0.5250
	--> Epoch [13/100], Loss: 0.4565, Validation Loss: 0.5169
	--> Epoch [14/100], Loss: 0.4184, Validation Loss: 0.5090
	--> Epoch [15/100], Loss: 0.2842, Validation Loss: 0.4985
	--> Epoch [16/100], Loss: 0.2873, Validation Loss: 0.4893
	--> Epoch [17/100], Loss: 0.3219, Validation Loss: 0.4811
	--> Epoch [18/100], Loss: 0.3403, Validation Loss: 0.4746
	--> Epoch [19/100], Loss: 0.3048, Validation Loss: 0.4667
	--> Epoch [20/100], Loss: 0.2665, Validation Loss: 0.4590
	--> Epoch [21/100], Loss: 0.2325, Validation Loss: 0.4535
	--> Epoch [22/100], Loss: 0.3095, Validation Loss: 0.4480
	--> Epoch [23/100], Loss: 0.2262, Validation Loss: 0.4412
	--> Epoch [24/100], Loss: 0.2249, Validation Loss: 0.4343
	--> Epoch [25/100], Loss: 0.2174, Validation Loss: 0.4282
	--> Epoch [26/100], Loss: 0.1483, Validation Loss: 0.4222
	--> Epoch [27/100], Loss: 0.1902, Validation Loss: 0.4169
	--> Epoch [28/100], Loss: 0.2066, Validation Loss: 0.4112
	--> Epoch [29/100], Loss: 0.1888, Validation Loss: 0.4059
	--> Epoch [30/100], Loss: 0.2110, Validation Loss: 0.4015
	--> Epoch [31/100], Loss: 0.1807, Validation Loss: 0.3958
	--> Epoch [32/100], Loss: 0.1596, Validation Loss: 0.3908
	--> Epoch [33/100], Loss: 0.1881, Validation Loss: 0.3867
	--> Epoch [34/100], Loss: 0.1651, Validation Loss: 0.3822
	--> Epoch [35/100], Loss: 0.1234, Validation Loss: 0.3787
	--> Epoch [36/100], Loss: 0.1711, Validation Loss: 0.3749
	--> Epoch [37/100], Loss: 0.1104, Validation Loss: 0.3712
	--> Epoch [38/100], Loss: 0.2039, Validation Loss: 0.3681
	--> Epoch [39/100], Loss: 0.1771, Validation Loss: 0.3639
	--> Epoch [40/100], Loss: 0.1871, Validation Loss: 0.3606
	--> Epoch [41/100], Loss: 0.2294, Validation Loss: 0.3585
	--> Epoch [42/100], Loss: 0.1282, Validation Loss: 0.3552
	--> Epoch [43/100], Loss: 0.1852, Validation Loss: 0.3519
	--> Epoch [44/100], Loss: 0.1431, Validation Loss: 0.3487
	--> Epoch [45/100], Loss: 0.1539, Validation Loss: 0.3450
	--> Epoch [46/100], Loss: 0.1357, Validation Loss: 0.3424
	--> Epoch [47/100], Loss: 0.0925, Validation Loss: 0.3392
	--> Epoch [48/100], Loss: 0.1084, Validation Loss: 0.3368
	--> Epoch [49/100], Loss: 0.1379, Validation Loss: 0.3338
	--> Epoch [50/100], Loss: 0.1547, Validation Loss: 0.3316
	--> Epoch [51/100], Loss: 0.1237, Validation Loss: 0.3293
	--> Epoch [52/100], Loss: 0.1153, Validation Loss: 0.3263
	--> Epoch [53/100], Loss: 0.0822, Validation Loss: 0.3240
	--> Epoch [54/100], Loss: 0.1121, Validation Loss: 0.3219
	--> Epoch [55/100], Loss: 0.1028, Validation Loss: 0.3197
	--> Epoch [56/100], Loss: 0.1773, Validation Loss: 0.3177
	--> Epoch [57/100], Loss: 0.1077, Validation Loss: 0.3162
	--> Epoch [58/100], Loss: 0.0997, Validation Loss: 0.3139
	--> Epoch [59/100], Loss: 0.0837, Validation Loss: 0.3118
	--> Epoch [60/100], Loss: 0.0914, Validation Loss: 0.3097
	--> Epoch [61/100], Loss: 0.1867, Validation Loss: 0.3090
	--> Epoch [62/100], Loss: 0.0893, Validation Loss: 0.3074
	--> Epoch [63/100], Loss: 0.0899, Validation Loss: 0.3058
	--> Epoch [64/100], Loss: 0.0746, Validation Loss: 0.3053
	--> Epoch [65/100], Loss: 0.0876, Validation Loss: 0.3037
	--> Epoch [66/100], Loss: 0.0741, Validation Loss: 0.3012
	--> Epoch [67/100], Loss: 0.0906, Validation Loss: 0.2994
	--> Epoch [68/100], Loss: 0.1008, Validation Loss: 0.2979
	--> Epoch [69/100], Loss: 0.1000, Validation Loss: 0.2963
	--> Epoch [70/100], Loss: 0.1577, Validation Loss: 0.2961
	--> Epoch [71/100], Loss: 0.0829, Validation Loss: 0.2954
	--> Epoch [72/100], Loss: 0.0920, Validation Loss: 0.2948
	--> Epoch [73/100], Loss: 0.0799, Validation Loss: 0.2937
	--> Epoch [74/100], Loss: 0.1440, Validation Loss: 0.2928
	--> Epoch [75/100], Loss: 0.0854, Validation Loss: 0.2914
	--> Epoch [76/100], Loss: 0.0965, Validation Loss: 0.2907
	--> Epoch [77/100], Loss: 0.0802, Validation Loss: 0.2896
	--> Epoch [78/100], Loss: 0.0844, Validation Loss: 0.2894
	--> Epoch [79/100], Loss: 0.1090, Validation Loss: 0.2883
	--> Epoch [80/100], Loss: 0.1437, Validation Loss: 0.2886
	--> Epoch [81/100], Loss: 0.0952, Validation Loss: 0.2872
	--> Epoch [82/100], Loss: 0.0823, Validation Loss: 0.2871
	--> Epoch [83/100], Loss: 0.0736, Validation Loss: 0.2865
	--> Epoch [84/100], Loss: 0.0890, Validation Loss: 0.2854
	--> Epoch [85/100], Loss: 0.0815, Validation Loss: 0.2858
	--> Epoch [86/100], Loss: 0.0772, Validation Loss: 0.2854
	--> Epoch [87/100], Loss: 0.0793, Validation Loss: 0.2848
	--> Epoch [88/100], Loss: 0.0706, Validation Loss: 0.2841
	--> Epoch [89/100], Loss: 0.0768, Validation Loss: 0.2837
	--> Epoch [90/100], Loss: 0.0738, Validation Loss: 0.2824
	--> Epoch [91/100], Loss: 0.0773, Validation Loss: 0.2822
	--> Epoch [92/100], Loss: 0.0917, Validation Loss: 0.2815
	--> Epoch [93/100], Loss: 0.0760, Validation Loss: 0.2809
	--> Epoch [94/100], Loss: 0.0759, Validation Loss: 0.2804
	--> Epoch [95/100], Loss: 0.0770, Validation Loss: 0.2800
	--> Epoch [96/100], Loss: 0.0750, Validation Loss: 0.2790
	--> Epoch [97/100], Loss: 0.0969, Validation Loss: 0.2786
	--> Epoch [98/100], Loss: 0.1430, Validation Loss: 0.2786
	--> Epoch [99/100], Loss: 0.1243, Validation Loss: 0.2782
	--> Epoch [100/100], Loss: 0.0782, Validation Loss: 0.2775
	--> Training for Fold 1 took 0.7209010124206543 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7516, Validation Loss: 0.7183
	--> Epoch [2/100], Loss: 0.5549, Validation Loss: 0.6840
	--> Epoch [3/100], Loss: 0.5434, Validation Loss: 0.6611
	--> Epoch [4/100], Loss: 0.5879, Validation Loss: 0.6367
	--> Epoch [5/100], Loss: 0.5073, Validation Loss: 0.6166
	--> Epoch [6/100], Loss: 0.5870, Validation Loss: 0.6056
	--> Epoch [7/100], Loss: 0.3808, Validation Loss: 0.5938
	--> Epoch [8/100], Loss: 0.4100, Validation Loss: 0.5813
	--> Epoch [9/100], Loss: 0.3125, Validation Loss: 0.5661
	--> Epoch [10/100], Loss: 0.2954, Validation Loss: 0.5550
	--> Epoch [11/100], Loss: 0.2874, Validation Loss: 0.5470
	--> Epoch [12/100], Loss: 0.2682, Validation Loss: 0.5332
	--> Epoch [13/100], Loss: 0.3692, Validation Loss: 0.5252
	--> Epoch [14/100], Loss: 0.2905, Validation Loss: 0.5161
	--> Epoch [15/100], Loss: 0.2506, Validation Loss: 0.5073
	--> Epoch [16/100], Loss: 0.3024, Validation Loss: 0.4979
	--> Epoch [17/100], Loss: 0.2294, Validation Loss: 0.4886
	--> Epoch [18/100], Loss: 0.1694, Validation Loss: 0.4792
	--> Epoch [19/100], Loss: 0.2334, Validation Loss: 0.4684
	--> Epoch [20/100], Loss: 0.1877, Validation Loss: 0.4603
	--> Epoch [21/100], Loss: 0.2633, Validation Loss: 0.4536
	--> Epoch [22/100], Loss: 0.1297, Validation Loss: 0.4480
	--> Epoch [23/100], Loss: 0.1492, Validation Loss: 0.4417
	--> Epoch [24/100], Loss: 0.1313, Validation Loss: 0.4354
	--> Epoch [25/100], Loss: 0.2459, Validation Loss: 0.4280
	--> Epoch [26/100], Loss: 0.1602, Validation Loss: 0.4198
	--> Epoch [27/100], Loss: 0.1976, Validation Loss: 0.4145
	--> Epoch [28/100], Loss: 0.2068, Validation Loss: 0.4088
	--> Epoch [29/100], Loss: 0.1606, Validation Loss: 0.4010
	--> Epoch [30/100], Loss: 0.2920, Validation Loss: 0.3946
	--> Epoch [31/100], Loss: 0.2229, Validation Loss: 0.3846
	--> Epoch [32/100], Loss: 0.1930, Validation Loss: 0.3771
	--> Epoch [33/100], Loss: 0.1532, Validation Loss: 0.3706
	--> Epoch [34/100], Loss: 0.0569, Validation Loss: 0.3644
	--> Epoch [35/100], Loss: 0.0690, Validation Loss: 0.3590
	--> Epoch [36/100], Loss: 0.1059, Validation Loss: 0.3561
	--> Epoch [37/100], Loss: 0.1628, Validation Loss: 0.3506
	--> Epoch [38/100], Loss: 0.1815, Validation Loss: 0.3439
	--> Epoch [39/100], Loss: 0.1180, Validation Loss: 0.3392
	--> Epoch [40/100], Loss: 0.0527, Validation Loss: 0.3359
	--> Epoch [41/100], Loss: 0.0834, Validation Loss: 0.3326
	--> Epoch [42/100], Loss: 0.1413, Validation Loss: 0.3285
	--> Epoch [43/100], Loss: 0.1021, Validation Loss: 0.3255
	--> Epoch [44/100], Loss: 0.2445, Validation Loss: 0.3204
	--> Epoch [45/100], Loss: 0.1639, Validation Loss: 0.3171
	--> Epoch [46/100], Loss: 0.1084, Validation Loss: 0.3129
	--> Epoch [47/100], Loss: 0.0706, Validation Loss: 0.3097
	--> Epoch [48/100], Loss: 0.0915, Validation Loss: 0.3052
	--> Epoch [49/100], Loss: 0.0548, Validation Loss: 0.3035
	--> Epoch [50/100], Loss: 0.1723, Validation Loss: 0.2998
	--> Epoch [51/100], Loss: 0.1213, Validation Loss: 0.2977
	--> Epoch [52/100], Loss: 0.1019, Validation Loss: 0.2963
	--> Epoch [53/100], Loss: 0.0943, Validation Loss: 0.2955
	--> Epoch [54/100], Loss: 0.0258, Validation Loss: 0.2937
	--> Epoch [55/100], Loss: 0.0237, Validation Loss: 0.2925
	--> Epoch [56/100], Loss: 0.1097, Validation Loss: 0.2917
	--> Epoch [57/100], Loss: 0.0274, Validation Loss: 0.2895
	--> Epoch [58/100], Loss: 0.0857, Validation Loss: 0.2862
	--> Epoch [59/100], Loss: 0.1607, Validation Loss: 0.2834
	--> Epoch [60/100], Loss: 0.0327, Validation Loss: 0.2828
	--> Epoch [61/100], Loss: 0.1908, Validation Loss: 0.2823
	--> Epoch [62/100], Loss: 0.1052, Validation Loss: 0.2813
	--> Epoch [63/100], Loss: 0.0421, Validation Loss: 0.2769
	--> Epoch [64/100], Loss: 0.0410, Validation Loss: 0.2756
	--> Epoch [65/100], Loss: 0.0655, Validation Loss: 0.2730
	--> Epoch [66/100], Loss: 0.1683, Validation Loss: 0.2685
	--> Epoch [67/100], Loss: 0.1018, Validation Loss: 0.2660
	--> Epoch [68/100], Loss: 0.1094, Validation Loss: 0.2653
	--> Epoch [69/100], Loss: 0.1101, Validation Loss: 0.2635
	--> Epoch [70/100], Loss: 0.1198, Validation Loss: 0.2607
	--> Epoch [71/100], Loss: 0.0956, Validation Loss: 0.2591
	--> Epoch [72/100], Loss: 0.1035, Validation Loss: 0.2579
	--> Epoch [73/100], Loss: 0.1235, Validation Loss: 0.2572
	--> Epoch [74/100], Loss: 0.0249, Validation Loss: 0.2551
	--> Epoch [75/100], Loss: 0.0208, Validation Loss: 0.2548
	--> Epoch [76/100], Loss: 0.0417, Validation Loss: 0.2538
	--> Epoch [77/100], Loss: 0.0839, Validation Loss: 0.2535
	--> Epoch [78/100], Loss: 0.0257, Validation Loss: 0.2528
	--> Epoch [79/100], Loss: 0.0909, Validation Loss: 0.2489
	--> Epoch [80/100], Loss: 0.0360, Validation Loss: 0.2477
	--> Epoch [81/100], Loss: 0.0185, Validation Loss: 0.2478
	--> Epoch [82/100], Loss: 0.0164, Validation Loss: 0.2457
	--> Epoch [83/100], Loss: 0.1126, Validation Loss: 0.2417
	--> Epoch [84/100], Loss: 0.0177, Validation Loss: 0.2413
	--> Epoch [85/100], Loss: 0.0241, Validation Loss: 0.2403
	--> Epoch [86/100], Loss: 0.0271, Validation Loss: 0.2392
	--> Epoch [87/100], Loss: 0.0209, Validation Loss: 0.2369
	--> Epoch [88/100], Loss: 0.1036, Validation Loss: 0.2347
	--> Epoch [89/100], Loss: 0.0169, Validation Loss: 0.2331
	--> Epoch [90/100], Loss: 0.0386, Validation Loss: 0.2328
	--> Epoch [91/100], Loss: 0.0296, Validation Loss: 0.2328
	--> Epoch [92/100], Loss: 0.0123, Validation Loss: 0.2315
	--> Epoch [93/100], Loss: 0.0102, Validation Loss: 0.2322
	--> Epoch [94/100], Loss: 0.0895, Validation Loss: 0.2314
	--> Epoch [95/100], Loss: 0.0931, Validation Loss: 0.2310
	--> Epoch [96/100], Loss: 0.0458, Validation Loss: 0.2302
	--> Epoch [97/100], Loss: 0.1609, Validation Loss: 0.2286
	--> Epoch [98/100], Loss: 0.0153, Validation Loss: 0.2273
	--> Epoch [99/100], Loss: 0.0785, Validation Loss: 0.2266
	--> Epoch [100/100], Loss: 0.0186, Validation Loss: 0.2263
	--> Training for Fold 2 took 0.6871623992919922 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6062, Validation Loss: 0.7291
	--> Epoch [2/100], Loss: 0.5469, Validation Loss: 0.7179
	--> Epoch [3/100], Loss: 0.5508, Validation Loss: 0.7065
	--> Epoch [4/100], Loss: 0.5258, Validation Loss: 0.6939
	--> Epoch [5/100], Loss: 0.4756, Validation Loss: 0.6837
	--> Epoch [6/100], Loss: 0.4340, Validation Loss: 0.6743
	--> Epoch [7/100], Loss: 0.4091, Validation Loss: 0.6639
	--> Epoch [8/100], Loss: 0.3926, Validation Loss: 0.6545
	--> Epoch [9/100], Loss: 0.3722, Validation Loss: 0.6451
	--> Epoch [10/100], Loss: 0.3924, Validation Loss: 0.6369
	--> Epoch [11/100], Loss: 0.3940, Validation Loss: 0.6272
	--> Epoch [12/100], Loss: 0.3642, Validation Loss: 0.6201
	--> Epoch [13/100], Loss: 0.3410, Validation Loss: 0.6121
	--> Epoch [14/100], Loss: 0.3301, Validation Loss: 0.6035
	--> Epoch [15/100], Loss: 0.2559, Validation Loss: 0.5954
	--> Epoch [16/100], Loss: 0.2682, Validation Loss: 0.5880
	--> Epoch [17/100], Loss: 0.2658, Validation Loss: 0.5808
	--> Epoch [18/100], Loss: 0.2721, Validation Loss: 0.5727
	--> Epoch [19/100], Loss: 0.2321, Validation Loss: 0.5669
	--> Epoch [20/100], Loss: 0.2201, Validation Loss: 0.5611
	--> Epoch [21/100], Loss: 0.2785, Validation Loss: 0.5534
	--> Epoch [22/100], Loss: 0.2142, Validation Loss: 0.5478
	--> Epoch [23/100], Loss: 0.1804, Validation Loss: 0.5426
	--> Epoch [24/100], Loss: 0.1998, Validation Loss: 0.5354
	--> Epoch [25/100], Loss: 0.1363, Validation Loss: 0.5292
	--> Epoch [26/100], Loss: 0.1343, Validation Loss: 0.5233
	--> Epoch [27/100], Loss: 0.1559, Validation Loss: 0.5187
	--> Epoch [28/100], Loss: 0.1942, Validation Loss: 0.5124
	--> Epoch [29/100], Loss: 0.1699, Validation Loss: 0.5047
	--> Epoch [30/100], Loss: 0.2235, Validation Loss: 0.5017
	--> Epoch [31/100], Loss: 0.2165, Validation Loss: 0.4970
	--> Epoch [32/100], Loss: 0.0995, Validation Loss: 0.4919
	--> Epoch [33/100], Loss: 0.1338, Validation Loss: 0.4868
	--> Epoch [34/100], Loss: 0.1344, Validation Loss: 0.4818
	--> Epoch [35/100], Loss: 0.1508, Validation Loss: 0.4761
	--> Epoch [36/100], Loss: 0.1243, Validation Loss: 0.4715
	--> Epoch [37/100], Loss: 0.0753, Validation Loss: 0.4668
	--> Epoch [38/100], Loss: 0.1401, Validation Loss: 0.4622
	--> Epoch [39/100], Loss: 0.0992, Validation Loss: 0.4588
	--> Epoch [40/100], Loss: 0.1266, Validation Loss: 0.4558
	--> Epoch [41/100], Loss: 0.2133, Validation Loss: 0.4531
	--> Epoch [42/100], Loss: 0.0679, Validation Loss: 0.4493
	--> Epoch [43/100], Loss: 0.0966, Validation Loss: 0.4461
	--> Epoch [44/100], Loss: 0.0941, Validation Loss: 0.4437
	--> Epoch [45/100], Loss: 0.0743, Validation Loss: 0.4411
	--> Epoch [46/100], Loss: 0.0497, Validation Loss: 0.4377
	--> Epoch [47/100], Loss: 0.0788, Validation Loss: 0.4347
	--> Epoch [48/100], Loss: 0.0938, Validation Loss: 0.4315
	--> Epoch [49/100], Loss: 0.1242, Validation Loss: 0.4288
	--> Epoch [50/100], Loss: 0.1345, Validation Loss: 0.4263
	--> Epoch [51/100], Loss: 0.0758, Validation Loss: 0.4244
	--> Epoch [52/100], Loss: 0.0603, Validation Loss: 0.4212
	--> Epoch [53/100], Loss: 0.0730, Validation Loss: 0.4186
	--> Epoch [54/100], Loss: 0.0716, Validation Loss: 0.4164
	--> Epoch [55/100], Loss: 0.0353, Validation Loss: 0.4133
	--> Epoch [56/100], Loss: 0.1375, Validation Loss: 0.4114
	--> Epoch [57/100], Loss: 0.0575, Validation Loss: 0.4093
	--> Epoch [58/100], Loss: 0.0599, Validation Loss: 0.4081
	--> Epoch [59/100], Loss: 0.0927, Validation Loss: 0.4064
	--> Epoch [60/100], Loss: 0.0530, Validation Loss: 0.4045
	--> Epoch [61/100], Loss: 0.0971, Validation Loss: 0.4039
	--> Epoch [62/100], Loss: 0.0445, Validation Loss: 0.4030
	--> Epoch [63/100], Loss: 0.0401, Validation Loss: 0.4006
	--> Epoch [64/100], Loss: 0.0749, Validation Loss: 0.3986
	--> Epoch [65/100], Loss: 0.1142, Validation Loss: 0.3985
	--> Epoch [66/100], Loss: 0.0569, Validation Loss: 0.3970
	--> Epoch [67/100], Loss: 0.0552, Validation Loss: 0.3968
	--> Epoch [68/100], Loss: 0.1059, Validation Loss: 0.3940
	--> Epoch [69/100], Loss: 0.0905, Validation Loss: 0.3920
	--> Epoch [70/100], Loss: 0.0223, Validation Loss: 0.3897
	--> Epoch [71/100], Loss: 0.0335, Validation Loss: 0.3895
	--> Epoch [72/100], Loss: 0.0191, Validation Loss: 0.3873
	--> Epoch [73/100], Loss: 0.0198, Validation Loss: 0.3869
	--> Epoch [74/100], Loss: 0.0640, Validation Loss: 0.3861
	--> Epoch [75/100], Loss: 0.0810, Validation Loss: 0.3863
	--> Epoch [76/100], Loss: 0.0246, Validation Loss: 0.3859
	--> Epoch [77/100], Loss: 0.0183, Validation Loss: 0.3851
	--> Epoch [78/100], Loss: 0.0278, Validation Loss: 0.3820
	--> Epoch [79/100], Loss: 0.0617, Validation Loss: 0.3807
	--> Epoch [80/100], Loss: 0.1187, Validation Loss: 0.3796
	--> Epoch [81/100], Loss: 0.0194, Validation Loss: 0.3784
	--> Epoch [82/100], Loss: 0.0617, Validation Loss: 0.3750
	--> Epoch [83/100], Loss: 0.0345, Validation Loss: 0.3746
	--> Epoch [84/100], Loss: 0.1145, Validation Loss: 0.3743
	--> Epoch [85/100], Loss: 0.0604, Validation Loss: 0.3742
	--> Epoch [86/100], Loss: 0.1099, Validation Loss: 0.3741
	--> Epoch [87/100], Loss: 0.0695, Validation Loss: 0.3745
	--> Epoch [88/100], Loss: 0.0702, Validation Loss: 0.3730
	--> Epoch [89/100], Loss: 0.0242, Validation Loss: 0.3704
	--> Epoch [90/100], Loss: 0.0321, Validation Loss: 0.3703
	--> Epoch [91/100], Loss: 0.0605, Validation Loss: 0.3689
	--> Epoch [92/100], Loss: 0.1049, Validation Loss: 0.3692
	--> Epoch [93/100], Loss: 0.0109, Validation Loss: 0.3680
	--> Epoch [94/100], Loss: 0.1567, Validation Loss: 0.3669
	--> Epoch [95/100], Loss: 0.0786, Validation Loss: 0.3663
	--> Epoch [96/100], Loss: 0.0132, Validation Loss: 0.3656
	--> Epoch [97/100], Loss: 0.0232, Validation Loss: 0.3654
	--> Epoch [98/100], Loss: 0.0157, Validation Loss: 0.3637
	--> Epoch [99/100], Loss: 0.0539, Validation Loss: 0.3627
	--> Epoch [100/100], Loss: 0.0607, Validation Loss: 0.3625
	--> Training for Fold 3 took 0.721935510635376 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8964, Validation Loss: 0.5370
	--> Epoch [2/100], Loss: 0.8164, Validation Loss: 0.5257
	--> Epoch [3/100], Loss: 0.8080, Validation Loss: 0.5175
	--> Epoch [4/100], Loss: 0.8332, Validation Loss: 0.5163
	--> Epoch [5/100], Loss: 0.7366, Validation Loss: 0.5086
	--> Epoch [6/100], Loss: 0.7205, Validation Loss: 0.5009
	--> Epoch [7/100], Loss: 0.7098, Validation Loss: 0.4960
	--> Epoch [8/100], Loss: 0.6804, Validation Loss: 0.4889
	--> Epoch [9/100], Loss: 0.6812, Validation Loss: 0.4825
	--> Epoch [10/100], Loss: 0.6407, Validation Loss: 0.4771
	--> Epoch [11/100], Loss: 0.6265, Validation Loss: 0.4698
	--> Epoch [12/100], Loss: 0.5848, Validation Loss: 0.4644
	--> Epoch [13/100], Loss: 0.6308, Validation Loss: 0.4584
	--> Epoch [14/100], Loss: 0.5419, Validation Loss: 0.4535
	--> Epoch [15/100], Loss: 0.5623, Validation Loss: 0.4448
	--> Epoch [16/100], Loss: 0.5275, Validation Loss: 0.4373
	--> Epoch [17/100], Loss: 0.4686, Validation Loss: 0.4310
	--> Epoch [18/100], Loss: 0.5620, Validation Loss: 0.4252
	--> Epoch [19/100], Loss: 0.4288, Validation Loss: 0.4172
	--> Epoch [20/100], Loss: 0.4528, Validation Loss: 0.4119
	--> Epoch [21/100], Loss: 0.4429, Validation Loss: 0.4035
	--> Epoch [22/100], Loss: 0.3991, Validation Loss: 0.4024
	--> Epoch [23/100], Loss: 0.4721, Validation Loss: 0.3970
	--> Epoch [24/100], Loss: 0.3793, Validation Loss: 0.3915
	--> Epoch [25/100], Loss: 0.3937, Validation Loss: 0.3854
	--> Epoch [26/100], Loss: 0.3447, Validation Loss: 0.3791
	--> Epoch [27/100], Loss: 0.2882, Validation Loss: 0.3736
	--> Epoch [28/100], Loss: 0.3131, Validation Loss: 0.3689
	--> Epoch [29/100], Loss: 0.3636, Validation Loss: 0.3641
	--> Epoch [30/100], Loss: 0.4632, Validation Loss: 0.3643
	--> Epoch [31/100], Loss: 0.2389, Validation Loss: 0.3594
	--> Epoch [32/100], Loss: 0.2115, Validation Loss: 0.3574
	--> Epoch [33/100], Loss: 0.4993, Validation Loss: 0.3516
	--> Epoch [34/100], Loss: 0.2109, Validation Loss: 0.3477
	--> Epoch [35/100], Loss: 0.1909, Validation Loss: 0.3430
	--> Epoch [36/100], Loss: 0.3195, Validation Loss: 0.3367
	--> Epoch [37/100], Loss: 0.1968, Validation Loss: 0.3329
	--> Epoch [38/100], Loss: 0.1268, Validation Loss: 0.3308
	--> Epoch [39/100], Loss: 0.4006, Validation Loss: 0.3313
	--> Epoch [40/100], Loss: 0.1880, Validation Loss: 0.3297
	--> Epoch [41/100], Loss: 0.1511, Validation Loss: 0.3273
	--> Epoch [42/100], Loss: 0.1856, Validation Loss: 0.3251
	--> Epoch [43/100], Loss: 0.1648, Validation Loss: 0.3217
	--> Epoch [44/100], Loss: 0.1427, Validation Loss: 0.3183
	--> Epoch [45/100], Loss: 0.2606, Validation Loss: 0.3155
	--> Epoch [46/100], Loss: 0.1289, Validation Loss: 0.3133
	--> Epoch [47/100], Loss: 0.2323, Validation Loss: 0.3116
	--> Epoch [48/100], Loss: 0.2224, Validation Loss: 0.3087
	--> Epoch [49/100], Loss: 0.2664, Validation Loss: 0.3067
	--> Epoch [50/100], Loss: 0.1491, Validation Loss: 0.3046
	--> Epoch [51/100], Loss: 0.2236, Validation Loss: 0.3027
	--> Epoch [52/100], Loss: 0.1573, Validation Loss: 0.3038
	--> Epoch [53/100], Loss: 0.1291, Validation Loss: 0.3010
	--> Epoch [54/100], Loss: 0.1572, Validation Loss: 0.2985
	--> Epoch [55/100], Loss: 0.2184, Validation Loss: 0.2970
	--> Epoch [56/100], Loss: 0.1876, Validation Loss: 0.2952
	--> Epoch [57/100], Loss: 0.2300, Validation Loss: 0.2937
	--> Epoch [58/100], Loss: 0.1676, Validation Loss: 0.2972
	--> Epoch [59/100], Loss: 0.1600, Validation Loss: 0.2959
	--> Epoch [60/100], Loss: 0.1665, Validation Loss: 0.2943
Early stopping
	--> Training for Fold 4 took 0.3872363567352295 sec, using 60 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6667, Validation Loss: 0.7005
	--> Epoch [2/100], Loss: 0.6011, Validation Loss: 0.6953
	--> Epoch [3/100], Loss: 0.5965, Validation Loss: 0.6876
	--> Epoch [4/100], Loss: 0.5858, Validation Loss: 0.6815
	--> Epoch [5/100], Loss: 0.5628, Validation Loss: 0.6743
	--> Epoch [6/100], Loss: 0.5739, Validation Loss: 0.6706
	--> Epoch [7/100], Loss: 0.5466, Validation Loss: 0.6664
	--> Epoch [8/100], Loss: 0.5070, Validation Loss: 0.6626
	--> Epoch [9/100], Loss: 0.4656, Validation Loss: 0.6592
	--> Epoch [10/100], Loss: 0.4259, Validation Loss: 0.6552
	--> Epoch [11/100], Loss: 0.4298, Validation Loss: 0.6492
	--> Epoch [12/100], Loss: 0.4389, Validation Loss: 0.6457
	--> Epoch [13/100], Loss: 0.3932, Validation Loss: 0.6421
	--> Epoch [14/100], Loss: 0.3759, Validation Loss: 0.6397
	--> Epoch [15/100], Loss: 0.3470, Validation Loss: 0.6366
	--> Epoch [16/100], Loss: 0.3932, Validation Loss: 0.6340
	--> Epoch [17/100], Loss: 0.3582, Validation Loss: 0.6317
	--> Epoch [18/100], Loss: 0.3308, Validation Loss: 0.6290
	--> Epoch [19/100], Loss: 0.3351, Validation Loss: 0.6256
	--> Epoch [20/100], Loss: 0.3281, Validation Loss: 0.6222
	--> Epoch [21/100], Loss: 0.2869, Validation Loss: 0.6199
	--> Epoch [22/100], Loss: 0.3014, Validation Loss: 0.6166
	--> Epoch [23/100], Loss: 0.2457, Validation Loss: 0.6140
	--> Epoch [24/100], Loss: 0.2680, Validation Loss: 0.6114
	--> Epoch [25/100], Loss: 0.2761, Validation Loss: 0.6098
	--> Epoch [26/100], Loss: 0.2742, Validation Loss: 0.6068
	--> Epoch [27/100], Loss: 0.2235, Validation Loss: 0.6041
	--> Epoch [28/100], Loss: 0.2162, Validation Loss: 0.6016
	--> Epoch [29/100], Loss: 0.2621, Validation Loss: 0.5983
	--> Epoch [30/100], Loss: 0.2214, Validation Loss: 0.5971
	--> Epoch [31/100], Loss: 0.1952, Validation Loss: 0.5947
	--> Epoch [32/100], Loss: 0.1904, Validation Loss: 0.5934
	--> Epoch [33/100], Loss: 0.1769, Validation Loss: 0.5911
	--> Epoch [34/100], Loss: 0.1762, Validation Loss: 0.5915
	--> Epoch [35/100], Loss: 0.1603, Validation Loss: 0.5901
	--> Epoch [36/100], Loss: 0.1122, Validation Loss: 0.5903
	--> Epoch [37/100], Loss: 0.1128, Validation Loss: 0.5891
	--> Epoch [38/100], Loss: 0.1753, Validation Loss: 0.5883
	--> Epoch [39/100], Loss: 0.1123, Validation Loss: 0.5864
	--> Epoch [40/100], Loss: 0.1316, Validation Loss: 0.5873
	--> Epoch [41/100], Loss: 0.0853, Validation Loss: 0.5859
	--> Epoch [42/100], Loss: 0.1582, Validation Loss: 0.5857
	--> Epoch [43/100], Loss: 0.1181, Validation Loss: 0.5867
	--> Epoch [44/100], Loss: 0.1186, Validation Loss: 0.5865
	--> Epoch [45/100], Loss: 0.0785, Validation Loss: 0.5863
Early stopping
	--> Training for Fold 5 took 0.29158711433410645 sec, using 45 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7401
	--> Final training Epoch [2/100], Loss: 0.7122
	--> Final training Epoch [3/100], Loss: 0.6537
	--> Final training Epoch [4/100], Loss: 0.6023
	--> Final training Epoch [5/100], Loss: 0.5748
	--> Final training Epoch [6/100], Loss: 0.5032
	--> Final training Epoch [7/100], Loss: 0.5092
	--> Final training Epoch [8/100], Loss: 0.4860
	--> Final training Epoch [9/100], Loss: 0.4803
	--> Final training Epoch [10/100], Loss: 0.4923
	--> Final training Epoch [11/100], Loss: 0.4660
	--> Final training Epoch [12/100], Loss: 0.4642
	--> Final training Epoch [13/100], Loss: 0.3850
	--> Final training Epoch [14/100], Loss: 0.4042
	--> Final training Epoch [15/100], Loss: 0.3807
	--> Final training Epoch [16/100], Loss: 0.4236
	--> Final training Epoch [17/100], Loss: 0.3502
	--> Final training Epoch [18/100], Loss: 0.4104
	--> Final training Epoch [19/100], Loss: 0.3170
	--> Final training Epoch [20/100], Loss: 0.2750
	--> Final training Epoch [21/100], Loss: 0.2959
	--> Final training Epoch [22/100], Loss: 0.3213
	--> Final training Epoch [23/100], Loss: 0.3041
	--> Final training Epoch [24/100], Loss: 0.2509
	--> Final training Epoch [25/100], Loss: 0.2395
	--> Final training Epoch [26/100], Loss: 0.2596
	--> Final training Epoch [27/100], Loss: 0.2341
	--> Final training Epoch [28/100], Loss: 0.2513
	--> Final training Epoch [29/100], Loss: 0.2259
	--> Final training Epoch [30/100], Loss: 0.2758
	--> Final training Epoch [31/100], Loss: 0.2380
	--> Final training Epoch [32/100], Loss: 0.2026
	--> Final training Epoch [33/100], Loss: 0.2099
	--> Final training Epoch [34/100], Loss: 0.1635
	--> Final training Epoch [35/100], Loss: 0.1978
	--> Final training Epoch [36/100], Loss: 0.1775
	--> Final training Epoch [37/100], Loss: 0.1705
	--> Final training Epoch [38/100], Loss: 0.1654
	--> Final training Epoch [39/100], Loss: 0.1534
	--> Final training Epoch [40/100], Loss: 0.1985
	--> Final training Epoch [41/100], Loss: 0.2020
	--> Final training Epoch [42/100], Loss: 0.1709
	--> Final training Epoch [43/100], Loss: 0.1800
	--> Final training Epoch [44/100], Loss: 0.1340
	--> Final training Epoch [45/100], Loss: 0.1646
	--> Final training Epoch [46/100], Loss: 0.1360
	--> Final training Epoch [47/100], Loss: 0.1802
	--> Final training Epoch [48/100], Loss: 0.1537
	--> Final training Epoch [49/100], Loss: 0.1038
	--> Final training Epoch [50/100], Loss: 0.1143
	--> Final training Epoch [51/100], Loss: 0.1116
	--> Final training Epoch [52/100], Loss: 0.1551
	--> Final training Epoch [53/100], Loss: 0.1716
	--> Final training Epoch [54/100], Loss: 0.1163
	--> Final training Epoch [55/100], Loss: 0.0911
	--> Final training Epoch [56/100], Loss: 0.1341
	--> Final training Epoch [57/100], Loss: 0.1530
	--> Final training Epoch [58/100], Loss: 0.1564
	--> Final training Epoch [59/100], Loss: 0.0898
	--> Final training Epoch [60/100], Loss: 0.1231
	--> Final training Epoch [61/100], Loss: 0.1019
	--> Final training Epoch [62/100], Loss: 0.0970
	--> Final training Epoch [63/100], Loss: 0.0969
	--> Final training Epoch [64/100], Loss: 0.1015
	--> Final training Epoch [65/100], Loss: 0.1419
	--> Final training Epoch [66/100], Loss: 0.0584
	--> Final training Epoch [67/100], Loss: 0.1193
	--> Final training Epoch [68/100], Loss: 0.1052
	--> Final training Epoch [69/100], Loss: 0.0910
	--> Final training Epoch [70/100], Loss: 0.1103
	--> Final training Epoch [71/100], Loss: 0.1355
	--> Final training Epoch [72/100], Loss: 0.0906
	--> Final training Epoch [73/100], Loss: 0.0993
	--> Final training Epoch [74/100], Loss: 0.0862
	--> Final training Epoch [75/100], Loss: 0.0671
	--> Final training Epoch [76/100], Loss: 0.0742
	--> Final training Epoch [77/100], Loss: 0.0580
	--> Final training Epoch [78/100], Loss: 0.0999
	--> Final training Epoch [79/100], Loss: 0.0866
	--> Final training Epoch [80/100], Loss: 0.0913
	--> Final training Epoch [81/100], Loss: 0.0353
	--> Final training Epoch [82/100], Loss: 0.1358
	--> Final training Epoch [83/100], Loss: 0.0893
	--> Final training Epoch [84/100], Loss: 0.1236
	--> Final training Epoch [85/100], Loss: 0.0986
	--> Final training Epoch [86/100], Loss: 0.1028
	--> Final training Epoch [87/100], Loss: 0.0378
	--> Final training Epoch [88/100], Loss: 0.0432
	--> Final training Epoch [89/100], Loss: 0.0925
	--> Final training Epoch [90/100], Loss: 0.0919
	--> Final training Epoch [91/100], Loss: 0.1120
	--> Final training Epoch [92/100], Loss: 0.0794
	--> Final training Epoch [93/100], Loss: 0.0980
	--> Final training Epoch [94/100], Loss: 0.0597
	--> Final training Epoch [95/100], Loss: 0.0584
	--> Final training Epoch [96/100], Loss: 0.0584
	--> Final training Epoch [97/100], Loss: 0.0603
	--> Final training Epoch [98/100], Loss: 0.0711
	--> Final training Epoch [99/100], Loss: 0.0913
	--> Final training Epoch [100/100], Loss: 0.0659

Final training took 0.6245884895324707 sec

TESTING
	--> Testing took 0.0095 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8480
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8819, Validation Loss: 0.3390,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3390
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.3717,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3390

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6275, Validation Loss: 0.6394
	--> Epoch [2/100], Loss: 0.6688, Validation Loss: 0.6263
	--> Epoch [3/100], Loss: 0.6189, Validation Loss: 0.6128
	--> Epoch [4/100], Loss: 0.5846, Validation Loss: 0.6000
	--> Epoch [5/100], Loss: 0.5215, Validation Loss: 0.5859
	--> Epoch [6/100], Loss: 0.4700, Validation Loss: 0.5725
	--> Epoch [7/100], Loss: 0.4718, Validation Loss: 0.5593
	--> Epoch [8/100], Loss: 0.4070, Validation Loss: 0.5485
	--> Epoch [9/100], Loss: 0.4699, Validation Loss: 0.5404
	--> Epoch [10/100], Loss: 0.3796, Validation Loss: 0.5297
	--> Epoch [11/100], Loss: 0.4093, Validation Loss: 0.5188
	--> Epoch [12/100], Loss: 0.4859, Validation Loss: 0.5116
	--> Epoch [13/100], Loss: 0.3873, Validation Loss: 0.5020
	--> Epoch [14/100], Loss: 0.4792, Validation Loss: 0.4922
	--> Epoch [15/100], Loss: 0.2991, Validation Loss: 0.4832
	--> Epoch [16/100], Loss: 0.3117, Validation Loss: 0.4762
	--> Epoch [17/100], Loss: 0.3162, Validation Loss: 0.4679
	--> Epoch [18/100], Loss: 0.4234, Validation Loss: 0.4610
	--> Epoch [19/100], Loss: 0.2884, Validation Loss: 0.4536
	--> Epoch [20/100], Loss: 0.3352, Validation Loss: 0.4456
	--> Epoch [21/100], Loss: 0.3480, Validation Loss: 0.4388
	--> Epoch [22/100], Loss: 0.3230, Validation Loss: 0.4331
	--> Epoch [23/100], Loss: 0.3471, Validation Loss: 0.4274
	--> Epoch [24/100], Loss: 0.2555, Validation Loss: 0.4213
	--> Epoch [25/100], Loss: 0.2714, Validation Loss: 0.4152
	--> Epoch [26/100], Loss: 0.2555, Validation Loss: 0.4079
	--> Epoch [27/100], Loss: 0.2470, Validation Loss: 0.4015
	--> Epoch [28/100], Loss: 0.2116, Validation Loss: 0.3957
	--> Epoch [29/100], Loss: 0.2172, Validation Loss: 0.3922
	--> Epoch [30/100], Loss: 0.2134, Validation Loss: 0.3860
	--> Epoch [31/100], Loss: 0.2484, Validation Loss: 0.3817
	--> Epoch [32/100], Loss: 0.2430, Validation Loss: 0.3769
	--> Epoch [33/100], Loss: 0.2231, Validation Loss: 0.3722
	--> Epoch [34/100], Loss: 0.2583, Validation Loss: 0.3666
	--> Epoch [35/100], Loss: 0.1525, Validation Loss: 0.3623
	--> Epoch [36/100], Loss: 0.1781, Validation Loss: 0.3580
	--> Epoch [37/100], Loss: 0.1254, Validation Loss: 0.3539
	--> Epoch [38/100], Loss: 0.1357, Validation Loss: 0.3514
	--> Epoch [39/100], Loss: 0.1569, Validation Loss: 0.3471
	--> Epoch [40/100], Loss: 0.2096, Validation Loss: 0.3434
	--> Epoch [41/100], Loss: 0.2310, Validation Loss: 0.3398
	--> Epoch [42/100], Loss: 0.2003, Validation Loss: 0.3378
	--> Epoch [43/100], Loss: 0.1494, Validation Loss: 0.3340
	--> Epoch [44/100], Loss: 0.1660, Validation Loss: 0.3310
	--> Epoch [45/100], Loss: 0.1776, Validation Loss: 0.3270
	--> Epoch [46/100], Loss: 0.1032, Validation Loss: 0.3249
	--> Epoch [47/100], Loss: 0.1572, Validation Loss: 0.3238
	--> Epoch [48/100], Loss: 0.2047, Validation Loss: 0.3201
	--> Epoch [49/100], Loss: 0.2211, Validation Loss: 0.3170
	--> Epoch [50/100], Loss: 0.1176, Validation Loss: 0.3140
	--> Epoch [51/100], Loss: 0.1764, Validation Loss: 0.3110
	--> Epoch [52/100], Loss: 0.1299, Validation Loss: 0.3091
	--> Epoch [53/100], Loss: 0.1571, Validation Loss: 0.3075
	--> Epoch [54/100], Loss: 0.0897, Validation Loss: 0.3059
	--> Epoch [55/100], Loss: 0.2291, Validation Loss: 0.3042
	--> Epoch [56/100], Loss: 0.1726, Validation Loss: 0.3029
	--> Epoch [57/100], Loss: 0.1219, Validation Loss: 0.3013
	--> Epoch [58/100], Loss: 0.1334, Validation Loss: 0.2980
	--> Epoch [59/100], Loss: 0.1726, Validation Loss: 0.2967
	--> Epoch [60/100], Loss: 0.1738, Validation Loss: 0.2965
	--> Epoch [61/100], Loss: 0.0990, Validation Loss: 0.2954
	--> Epoch [62/100], Loss: 0.0943, Validation Loss: 0.2946
	--> Epoch [63/100], Loss: 0.1132, Validation Loss: 0.2931
	--> Epoch [64/100], Loss: 0.0986, Validation Loss: 0.2918
	--> Epoch [65/100], Loss: 0.1592, Validation Loss: 0.2910
	--> Epoch [66/100], Loss: 0.1569, Validation Loss: 0.2905
	--> Epoch [67/100], Loss: 0.1291, Validation Loss: 0.2888
	--> Epoch [68/100], Loss: 0.1033, Validation Loss: 0.2887
	--> Epoch [69/100], Loss: 0.0967, Validation Loss: 0.2881
	--> Epoch [70/100], Loss: 0.1843, Validation Loss: 0.2869
	--> Epoch [71/100], Loss: 0.2147, Validation Loss: 0.2868
	--> Epoch [72/100], Loss: 0.0973, Validation Loss: 0.2861
	--> Epoch [73/100], Loss: 0.1198, Validation Loss: 0.2856
	--> Epoch [74/100], Loss: 0.1218, Validation Loss: 0.2855
	--> Epoch [75/100], Loss: 0.0822, Validation Loss: 0.2844
	--> Epoch [76/100], Loss: 0.1514, Validation Loss: 0.2829
	--> Epoch [77/100], Loss: 0.1130, Validation Loss: 0.2828
	--> Epoch [78/100], Loss: 0.2400, Validation Loss: 0.2803
	--> Epoch [79/100], Loss: 0.1704, Validation Loss: 0.2793
	--> Epoch [80/100], Loss: 0.1227, Validation Loss: 0.2794
	--> Epoch [81/100], Loss: 0.1060, Validation Loss: 0.2782
	--> Epoch [82/100], Loss: 0.1702, Validation Loss: 0.2769
	--> Epoch [83/100], Loss: 0.1459, Validation Loss: 0.2767
	--> Epoch [84/100], Loss: 0.0955, Validation Loss: 0.2757
	--> Epoch [85/100], Loss: 0.0925, Validation Loss: 0.2754
	--> Epoch [86/100], Loss: 0.1587, Validation Loss: 0.2761
	--> Epoch [87/100], Loss: 0.0848, Validation Loss: 0.2755
	--> Epoch [88/100], Loss: 0.1458, Validation Loss: 0.2756
Early stopping
	--> Training for Fold 1 took 0.5355532169342041 sec, using 88 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7364, Validation Loss: 0.7273
	--> Epoch [2/100], Loss: 0.6729, Validation Loss: 0.7147
	--> Epoch [3/100], Loss: 0.6366, Validation Loss: 0.6970
	--> Epoch [4/100], Loss: 0.6430, Validation Loss: 0.6823
	--> Epoch [5/100], Loss: 0.6131, Validation Loss: 0.6673
	--> Epoch [6/100], Loss: 0.5840, Validation Loss: 0.6545
	--> Epoch [7/100], Loss: 0.5142, Validation Loss: 0.6419
	--> Epoch [8/100], Loss: 0.5188, Validation Loss: 0.6291
	--> Epoch [9/100], Loss: 0.5361, Validation Loss: 0.6172
	--> Epoch [10/100], Loss: 0.4675, Validation Loss: 0.6025
	--> Epoch [11/100], Loss: 0.4539, Validation Loss: 0.5886
	--> Epoch [12/100], Loss: 0.4542, Validation Loss: 0.5769
	--> Epoch [13/100], Loss: 0.4125, Validation Loss: 0.5651
	--> Epoch [14/100], Loss: 0.3753, Validation Loss: 0.5519
	--> Epoch [15/100], Loss: 0.3783, Validation Loss: 0.5384
	--> Epoch [16/100], Loss: 0.3904, Validation Loss: 0.5281
	--> Epoch [17/100], Loss: 0.4504, Validation Loss: 0.5184
	--> Epoch [18/100], Loss: 0.4941, Validation Loss: 0.5093
	--> Epoch [19/100], Loss: 0.3262, Validation Loss: 0.4997
	--> Epoch [20/100], Loss: 0.3958, Validation Loss: 0.4901
	--> Epoch [21/100], Loss: 0.3202, Validation Loss: 0.4800
	--> Epoch [22/100], Loss: 0.3475, Validation Loss: 0.4716
	--> Epoch [23/100], Loss: 0.3137, Validation Loss: 0.4618
	--> Epoch [24/100], Loss: 0.3028, Validation Loss: 0.4523
	--> Epoch [25/100], Loss: 0.3740, Validation Loss: 0.4440
	--> Epoch [26/100], Loss: 0.2615, Validation Loss: 0.4349
	--> Epoch [27/100], Loss: 0.2668, Validation Loss: 0.4272
	--> Epoch [28/100], Loss: 0.2669, Validation Loss: 0.4177
	--> Epoch [29/100], Loss: 0.2812, Validation Loss: 0.4106
	--> Epoch [30/100], Loss: 0.2298, Validation Loss: 0.4023
	--> Epoch [31/100], Loss: 0.2627, Validation Loss: 0.3960
	--> Epoch [32/100], Loss: 0.2092, Validation Loss: 0.3876
	--> Epoch [33/100], Loss: 0.1738, Validation Loss: 0.3796
	--> Epoch [34/100], Loss: 0.2565, Validation Loss: 0.3747
	--> Epoch [35/100], Loss: 0.2322, Validation Loss: 0.3683
	--> Epoch [36/100], Loss: 0.2732, Validation Loss: 0.3629
	--> Epoch [37/100], Loss: 0.1395, Validation Loss: 0.3581
	--> Epoch [38/100], Loss: 0.1586, Validation Loss: 0.3548
	--> Epoch [39/100], Loss: 0.2323, Validation Loss: 0.3505
	--> Epoch [40/100], Loss: 0.1630, Validation Loss: 0.3453
	--> Epoch [41/100], Loss: 0.1436, Validation Loss: 0.3418
	--> Epoch [42/100], Loss: 0.2102, Validation Loss: 0.3371
	--> Epoch [43/100], Loss: 0.2245, Validation Loss: 0.3321
	--> Epoch [44/100], Loss: 0.1925, Validation Loss: 0.3290
	--> Epoch [45/100], Loss: 0.1112, Validation Loss: 0.3252
	--> Epoch [46/100], Loss: 0.1401, Validation Loss: 0.3211
	--> Epoch [47/100], Loss: 0.1881, Validation Loss: 0.3162
	--> Epoch [48/100], Loss: 0.1828, Validation Loss: 0.3137
	--> Epoch [49/100], Loss: 0.1148, Validation Loss: 0.3085
	--> Epoch [50/100], Loss: 0.1321, Validation Loss: 0.3052
	--> Epoch [51/100], Loss: 0.1462, Validation Loss: 0.3029
	--> Epoch [52/100], Loss: 0.1977, Validation Loss: 0.2990
	--> Epoch [53/100], Loss: 0.1214, Validation Loss: 0.2981
	--> Epoch [54/100], Loss: 0.1240, Validation Loss: 0.2961
	--> Epoch [55/100], Loss: 0.0996, Validation Loss: 0.2929
	--> Epoch [56/100], Loss: 0.1447, Validation Loss: 0.2913
	--> Epoch [57/100], Loss: 0.1400, Validation Loss: 0.2884
	--> Epoch [58/100], Loss: 0.1057, Validation Loss: 0.2865
	--> Epoch [59/100], Loss: 0.0955, Validation Loss: 0.2845
	--> Epoch [60/100], Loss: 0.1179, Validation Loss: 0.2819
	--> Epoch [61/100], Loss: 0.0821, Validation Loss: 0.2802
	--> Epoch [62/100], Loss: 0.1354, Validation Loss: 0.2779
	--> Epoch [63/100], Loss: 0.1169, Validation Loss: 0.2765
	--> Epoch [64/100], Loss: 0.0803, Validation Loss: 0.2737
	--> Epoch [65/100], Loss: 0.1374, Validation Loss: 0.2732
	--> Epoch [66/100], Loss: 0.0941, Validation Loss: 0.2717
	--> Epoch [67/100], Loss: 0.1763, Validation Loss: 0.2711
	--> Epoch [68/100], Loss: 0.1019, Validation Loss: 0.2693
	--> Epoch [69/100], Loss: 0.1935, Validation Loss: 0.2639
	--> Epoch [70/100], Loss: 0.0933, Validation Loss: 0.2595
	--> Epoch [71/100], Loss: 0.0951, Validation Loss: 0.2577
	--> Epoch [72/100], Loss: 0.1277, Validation Loss: 0.2568
	--> Epoch [73/100], Loss: 0.1122, Validation Loss: 0.2541
	--> Epoch [74/100], Loss: 0.1091, Validation Loss: 0.2522
	--> Epoch [75/100], Loss: 0.1507, Validation Loss: 0.2523
	--> Epoch [76/100], Loss: 0.1474, Validation Loss: 0.2511
	--> Epoch [77/100], Loss: 0.0942, Validation Loss: 0.2496
	--> Epoch [78/100], Loss: 0.1579, Validation Loss: 0.2489
	--> Epoch [79/100], Loss: 0.0683, Validation Loss: 0.2476
	--> Epoch [80/100], Loss: 0.1022, Validation Loss: 0.2459
	--> Epoch [81/100], Loss: 0.0730, Validation Loss: 0.2447
	--> Epoch [82/100], Loss: 0.0877, Validation Loss: 0.2446
	--> Epoch [83/100], Loss: 0.0871, Validation Loss: 0.2425
	--> Epoch [84/100], Loss: 0.0902, Validation Loss: 0.2409
	--> Epoch [85/100], Loss: 0.0892, Validation Loss: 0.2391
	--> Epoch [86/100], Loss: 0.1964, Validation Loss: 0.2379
	--> Epoch [87/100], Loss: 0.1265, Validation Loss: 0.2367
	--> Epoch [88/100], Loss: 0.1427, Validation Loss: 0.2354
	--> Epoch [89/100], Loss: 0.0792, Validation Loss: 0.2340
	--> Epoch [90/100], Loss: 0.0861, Validation Loss: 0.2336
	--> Epoch [91/100], Loss: 0.1395, Validation Loss: 0.2317
	--> Epoch [92/100], Loss: 0.0738, Validation Loss: 0.2296
	--> Epoch [93/100], Loss: 0.0806, Validation Loss: 0.2267
	--> Epoch [94/100], Loss: 0.0721, Validation Loss: 0.2250
	--> Epoch [95/100], Loss: 0.0652, Validation Loss: 0.2234
	--> Epoch [96/100], Loss: 0.1280, Validation Loss: 0.2243
	--> Epoch [97/100], Loss: 0.0751, Validation Loss: 0.2230
	--> Epoch [98/100], Loss: 0.0689, Validation Loss: 0.2214
	--> Epoch [99/100], Loss: 0.1958, Validation Loss: 0.2205
	--> Epoch [100/100], Loss: 0.0703, Validation Loss: 0.2164
	--> Training for Fold 2 took 0.5761783123016357 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7589, Validation Loss: 0.7145
	--> Epoch [2/100], Loss: 0.6888, Validation Loss: 0.6983
	--> Epoch [3/100], Loss: 0.8134, Validation Loss: 0.6806
	--> Epoch [4/100], Loss: 0.5994, Validation Loss: 0.6684
	--> Epoch [5/100], Loss: 0.5513, Validation Loss: 0.6554
	--> Epoch [6/100], Loss: 0.5196, Validation Loss: 0.6469
	--> Epoch [7/100], Loss: 0.5429, Validation Loss: 0.6394
	--> Epoch [8/100], Loss: 0.4723, Validation Loss: 0.6337
	--> Epoch [9/100], Loss: 0.3778, Validation Loss: 0.6263
	--> Epoch [10/100], Loss: 0.4222, Validation Loss: 0.6195
	--> Epoch [11/100], Loss: 0.4086, Validation Loss: 0.6091
	--> Epoch [12/100], Loss: 0.3710, Validation Loss: 0.5980
	--> Epoch [13/100], Loss: 0.3595, Validation Loss: 0.5892
	--> Epoch [14/100], Loss: 0.3107, Validation Loss: 0.5867
	--> Epoch [15/100], Loss: 0.2525, Validation Loss: 0.5785
	--> Epoch [16/100], Loss: 0.2922, Validation Loss: 0.5678
	--> Epoch [17/100], Loss: 0.2994, Validation Loss: 0.5594
	--> Epoch [18/100], Loss: 0.2802, Validation Loss: 0.5526
	--> Epoch [19/100], Loss: 0.2003, Validation Loss: 0.5502
	--> Epoch [20/100], Loss: 0.2769, Validation Loss: 0.5436
	--> Epoch [21/100], Loss: 0.3250, Validation Loss: 0.5392
	--> Epoch [22/100], Loss: 0.2027, Validation Loss: 0.5361
	--> Epoch [23/100], Loss: 0.2616, Validation Loss: 0.5302
	--> Epoch [24/100], Loss: 0.1925, Validation Loss: 0.5240
	--> Epoch [25/100], Loss: 0.2151, Validation Loss: 0.5183
	--> Epoch [26/100], Loss: 0.1889, Validation Loss: 0.5137
	--> Epoch [27/100], Loss: 0.1704, Validation Loss: 0.5083
	--> Epoch [28/100], Loss: 0.2248, Validation Loss: 0.5019
	--> Epoch [29/100], Loss: 0.1815, Validation Loss: 0.4987
	--> Epoch [30/100], Loss: 0.2124, Validation Loss: 0.4946
	--> Epoch [31/100], Loss: 0.1417, Validation Loss: 0.4904
	--> Epoch [32/100], Loss: 0.3273, Validation Loss: 0.4865
	--> Epoch [33/100], Loss: 0.1536, Validation Loss: 0.4820
	--> Epoch [34/100], Loss: 0.1760, Validation Loss: 0.4776
	--> Epoch [35/100], Loss: 0.2286, Validation Loss: 0.4721
	--> Epoch [36/100], Loss: 0.1316, Validation Loss: 0.4682
	--> Epoch [37/100], Loss: 0.2556, Validation Loss: 0.4596
	--> Epoch [38/100], Loss: 0.1909, Validation Loss: 0.4572
	--> Epoch [39/100], Loss: 0.1815, Validation Loss: 0.4530
	--> Epoch [40/100], Loss: 0.2187, Validation Loss: 0.4504
	--> Epoch [41/100], Loss: 0.1934, Validation Loss: 0.4448
	--> Epoch [42/100], Loss: 0.0946, Validation Loss: 0.4398
	--> Epoch [43/100], Loss: 0.1799, Validation Loss: 0.4386
	--> Epoch [44/100], Loss: 0.1068, Validation Loss: 0.4346
	--> Epoch [45/100], Loss: 0.2616, Validation Loss: 0.4307
	--> Epoch [46/100], Loss: 0.1904, Validation Loss: 0.4270
	--> Epoch [47/100], Loss: 0.1944, Validation Loss: 0.4230
	--> Epoch [48/100], Loss: 0.1507, Validation Loss: 0.4205
	--> Epoch [49/100], Loss: 0.0833, Validation Loss: 0.4169
	--> Epoch [50/100], Loss: 0.1894, Validation Loss: 0.4117
	--> Epoch [51/100], Loss: 0.1276, Validation Loss: 0.4084
	--> Epoch [52/100], Loss: 0.1619, Validation Loss: 0.4051
	--> Epoch [53/100], Loss: 0.0927, Validation Loss: 0.4029
	--> Epoch [54/100], Loss: 0.1787, Validation Loss: 0.3993
	--> Epoch [55/100], Loss: 0.1071, Validation Loss: 0.3976
	--> Epoch [56/100], Loss: 0.1156, Validation Loss: 0.3960
	--> Epoch [57/100], Loss: 0.0911, Validation Loss: 0.3933
	--> Epoch [58/100], Loss: 0.0955, Validation Loss: 0.3915
	--> Epoch [59/100], Loss: 0.0866, Validation Loss: 0.3893
	--> Epoch [60/100], Loss: 0.1307, Validation Loss: 0.3878
	--> Epoch [61/100], Loss: 0.0429, Validation Loss: 0.3856
	--> Epoch [62/100], Loss: 0.1577, Validation Loss: 0.3826
	--> Epoch [63/100], Loss: 0.1162, Validation Loss: 0.3805
	--> Epoch [64/100], Loss: 0.0383, Validation Loss: 0.3781
	--> Epoch [65/100], Loss: 0.0771, Validation Loss: 0.3766
	--> Epoch [66/100], Loss: 0.1323, Validation Loss: 0.3755
	--> Epoch [67/100], Loss: 0.1162, Validation Loss: 0.3729
	--> Epoch [68/100], Loss: 0.1811, Validation Loss: 0.3690
	--> Epoch [69/100], Loss: 0.0946, Validation Loss: 0.3661
	--> Epoch [70/100], Loss: 0.1576, Validation Loss: 0.3650
	--> Epoch [71/100], Loss: 0.1599, Validation Loss: 0.3635
	--> Epoch [72/100], Loss: 0.1152, Validation Loss: 0.3608
	--> Epoch [73/100], Loss: 0.0739, Validation Loss: 0.3587
	--> Epoch [74/100], Loss: 0.1272, Validation Loss: 0.3565
	--> Epoch [75/100], Loss: 0.1101, Validation Loss: 0.3556
	--> Epoch [76/100], Loss: 0.1119, Validation Loss: 0.3570
	--> Epoch [77/100], Loss: 0.1043, Validation Loss: 0.3548
	--> Epoch [78/100], Loss: 0.1128, Validation Loss: 0.3520
	--> Epoch [79/100], Loss: 0.0914, Validation Loss: 0.3495
	--> Epoch [80/100], Loss: 0.1108, Validation Loss: 0.3488
	--> Epoch [81/100], Loss: 0.0685, Validation Loss: 0.3466
	--> Epoch [82/100], Loss: 0.1086, Validation Loss: 0.3458
	--> Epoch [83/100], Loss: 0.1443, Validation Loss: 0.3438
	--> Epoch [84/100], Loss: 0.1195, Validation Loss: 0.3429
	--> Epoch [85/100], Loss: 0.0633, Validation Loss: 0.3421
	--> Epoch [86/100], Loss: 0.1020, Validation Loss: 0.3396
	--> Epoch [87/100], Loss: 0.0634, Validation Loss: 0.3377
	--> Epoch [88/100], Loss: 0.0609, Validation Loss: 0.3372
	--> Epoch [89/100], Loss: 0.0221, Validation Loss: 0.3353
	--> Epoch [90/100], Loss: 0.1018, Validation Loss: 0.3337
	--> Epoch [91/100], Loss: 0.0992, Validation Loss: 0.3332
	--> Epoch [92/100], Loss: 0.2181, Validation Loss: 0.3315
	--> Epoch [93/100], Loss: 0.1075, Validation Loss: 0.3305
	--> Epoch [94/100], Loss: 0.0201, Validation Loss: 0.3290
	--> Epoch [95/100], Loss: 0.1457, Validation Loss: 0.3290
	--> Epoch [96/100], Loss: 0.0207, Validation Loss: 0.3276
	--> Epoch [97/100], Loss: 0.0221, Validation Loss: 0.3264
	--> Epoch [98/100], Loss: 0.0115, Validation Loss: 0.3260
	--> Epoch [99/100], Loss: 0.0580, Validation Loss: 0.3252
	--> Epoch [100/100], Loss: 0.0133, Validation Loss: 0.3245
	--> Training for Fold 3 took 0.5855894088745117 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6910, Validation Loss: 0.6591
	--> Epoch [2/100], Loss: 0.6638, Validation Loss: 0.6481
	--> Epoch [3/100], Loss: 0.6638, Validation Loss: 0.6313
	--> Epoch [4/100], Loss: 0.6867, Validation Loss: 0.6243
	--> Epoch [5/100], Loss: 0.6124, Validation Loss: 0.6228
	--> Epoch [6/100], Loss: 0.6106, Validation Loss: 0.6177
	--> Epoch [7/100], Loss: 0.5615, Validation Loss: 0.6113
	--> Epoch [8/100], Loss: 0.5361, Validation Loss: 0.6024
	--> Epoch [9/100], Loss: 0.5019, Validation Loss: 0.5962
	--> Epoch [10/100], Loss: 0.5175, Validation Loss: 0.5852
	--> Epoch [11/100], Loss: 0.4929, Validation Loss: 0.5774
	--> Epoch [12/100], Loss: 0.4314, Validation Loss: 0.5680
	--> Epoch [13/100], Loss: 0.3844, Validation Loss: 0.5580
	--> Epoch [14/100], Loss: 0.3491, Validation Loss: 0.5485
	--> Epoch [15/100], Loss: 0.4435, Validation Loss: 0.5380
	--> Epoch [16/100], Loss: 0.3404, Validation Loss: 0.5335
	--> Epoch [17/100], Loss: 0.4019, Validation Loss: 0.5247
	--> Epoch [18/100], Loss: 0.3069, Validation Loss: 0.5166
	--> Epoch [19/100], Loss: 0.3209, Validation Loss: 0.5081
	--> Epoch [20/100], Loss: 0.2059, Validation Loss: 0.4992
	--> Epoch [21/100], Loss: 0.2276, Validation Loss: 0.4894
	--> Epoch [22/100], Loss: 0.1964, Validation Loss: 0.4801
	--> Epoch [23/100], Loss: 0.2273, Validation Loss: 0.4711
	--> Epoch [24/100], Loss: 0.2556, Validation Loss: 0.4622
	--> Epoch [25/100], Loss: 0.2017, Validation Loss: 0.4546
	--> Epoch [26/100], Loss: 0.2631, Validation Loss: 0.4511
	--> Epoch [27/100], Loss: 0.1115, Validation Loss: 0.4458
	--> Epoch [28/100], Loss: 0.1752, Validation Loss: 0.4371
	--> Epoch [29/100], Loss: 0.2350, Validation Loss: 0.4305
	--> Epoch [30/100], Loss: 0.1634, Validation Loss: 0.4239
	--> Epoch [31/100], Loss: 0.2136, Validation Loss: 0.4171
	--> Epoch [32/100], Loss: 0.1833, Validation Loss: 0.4105
	--> Epoch [33/100], Loss: 0.1698, Validation Loss: 0.4045
	--> Epoch [34/100], Loss: 0.1013, Validation Loss: 0.3991
	--> Epoch [35/100], Loss: 0.1875, Validation Loss: 0.3938
	--> Epoch [36/100], Loss: 0.1949, Validation Loss: 0.3921
	--> Epoch [37/100], Loss: 0.0681, Validation Loss: 0.3874
	--> Epoch [38/100], Loss: 0.1592, Validation Loss: 0.3844
	--> Epoch [39/100], Loss: 0.1349, Validation Loss: 0.3784
	--> Epoch [40/100], Loss: 0.1396, Validation Loss: 0.3724
	--> Epoch [41/100], Loss: 0.1390, Validation Loss: 0.3742
	--> Epoch [42/100], Loss: 0.0603, Validation Loss: 0.3696
	--> Epoch [43/100], Loss: 0.1129, Validation Loss: 0.3656
	--> Epoch [44/100], Loss: 0.1415, Validation Loss: 0.3616
	--> Epoch [45/100], Loss: 0.0733, Validation Loss: 0.3570
	--> Epoch [46/100], Loss: 0.1038, Validation Loss: 0.3534
	--> Epoch [47/100], Loss: 0.1180, Validation Loss: 0.3506
	--> Epoch [48/100], Loss: 0.0675, Validation Loss: 0.3467
	--> Epoch [49/100], Loss: 0.1052, Validation Loss: 0.3431
	--> Epoch [50/100], Loss: 0.0496, Validation Loss: 0.3391
	--> Epoch [51/100], Loss: 0.1528, Validation Loss: 0.3400
	--> Epoch [52/100], Loss: 0.0381, Validation Loss: 0.3367
	--> Epoch [53/100], Loss: 0.1082, Validation Loss: 0.3332
	--> Epoch [54/100], Loss: 0.1760, Validation Loss: 0.3309
	--> Epoch [55/100], Loss: 0.0948, Validation Loss: 0.3275
	--> Epoch [56/100], Loss: 0.1457, Validation Loss: 0.3237
	--> Epoch [57/100], Loss: 0.0602, Validation Loss: 0.3207
	--> Epoch [58/100], Loss: 0.0262, Validation Loss: 0.3191
	--> Epoch [59/100], Loss: 0.0401, Validation Loss: 0.3176
	--> Epoch [60/100], Loss: 0.0689, Validation Loss: 0.3142
	--> Epoch [61/100], Loss: 0.0341, Validation Loss: 0.3121
	--> Epoch [62/100], Loss: 0.0758, Validation Loss: 0.3122
	--> Epoch [63/100], Loss: 0.1519, Validation Loss: 0.3097
	--> Epoch [64/100], Loss: 0.0300, Validation Loss: 0.3073
	--> Epoch [65/100], Loss: 0.0258, Validation Loss: 0.3063
	--> Epoch [66/100], Loss: 0.0269, Validation Loss: 0.3046
	--> Epoch [67/100], Loss: 0.0271, Validation Loss: 0.3026
	--> Epoch [68/100], Loss: 0.0268, Validation Loss: 0.2992
	--> Epoch [69/100], Loss: 0.0915, Validation Loss: 0.2980
	--> Epoch [70/100], Loss: 0.2039, Validation Loss: 0.2970
	--> Epoch [71/100], Loss: 0.0338, Validation Loss: 0.2954
	--> Epoch [72/100], Loss: 0.1181, Validation Loss: 0.2933
	--> Epoch [73/100], Loss: 0.0353, Validation Loss: 0.2918
	--> Epoch [74/100], Loss: 0.0912, Validation Loss: 0.2908
	--> Epoch [75/100], Loss: 0.0287, Validation Loss: 0.2912
	--> Epoch [76/100], Loss: 0.0253, Validation Loss: 0.2919
	--> Epoch [77/100], Loss: 0.0353, Validation Loss: 0.2906
	--> Epoch [78/100], Loss: 0.0734, Validation Loss: 0.2898
	--> Epoch [79/100], Loss: 0.1035, Validation Loss: 0.2889
	--> Epoch [80/100], Loss: 0.0724, Validation Loss: 0.2877
	--> Epoch [81/100], Loss: 0.1453, Validation Loss: 0.2873
	--> Epoch [82/100], Loss: 0.0312, Validation Loss: 0.2860
	--> Epoch [83/100], Loss: 0.0417, Validation Loss: 0.2834
	--> Epoch [84/100], Loss: 0.0661, Validation Loss: 0.2824
	--> Epoch [85/100], Loss: 0.0423, Validation Loss: 0.2797
	--> Epoch [86/100], Loss: 0.0304, Validation Loss: 0.2773
	--> Epoch [87/100], Loss: 0.0382, Validation Loss: 0.2766
	--> Epoch [88/100], Loss: 0.0211, Validation Loss: 0.2763
	--> Epoch [89/100], Loss: 0.0423, Validation Loss: 0.2751
	--> Epoch [90/100], Loss: 0.0149, Validation Loss: 0.2748
	--> Epoch [91/100], Loss: 0.0207, Validation Loss: 0.2738
	--> Epoch [92/100], Loss: 0.1078, Validation Loss: 0.2773
	--> Epoch [93/100], Loss: 0.0282, Validation Loss: 0.2755
	--> Epoch [94/100], Loss: 0.1023, Validation Loss: 0.2743
Early stopping
	--> Training for Fold 4 took 0.5435848236083984 sec, using 94 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7692, Validation Loss: 0.6863
	--> Epoch [2/100], Loss: 0.7185, Validation Loss: 0.6765
	--> Epoch [3/100], Loss: 0.6971, Validation Loss: 0.6680
	--> Epoch [4/100], Loss: 0.6443, Validation Loss: 0.6608
	--> Epoch [5/100], Loss: 0.5960, Validation Loss: 0.6550
	--> Epoch [6/100], Loss: 0.6165, Validation Loss: 0.6482
	--> Epoch [7/100], Loss: 0.5916, Validation Loss: 0.6432
	--> Epoch [8/100], Loss: 0.5338, Validation Loss: 0.6362
	--> Epoch [9/100], Loss: 0.5028, Validation Loss: 0.6296
	--> Epoch [10/100], Loss: 0.5977, Validation Loss: 0.6235
	--> Epoch [11/100], Loss: 0.4892, Validation Loss: 0.6156
	--> Epoch [12/100], Loss: 0.5458, Validation Loss: 0.6094
	--> Epoch [13/100], Loss: 0.4214, Validation Loss: 0.6041
	--> Epoch [14/100], Loss: 0.3987, Validation Loss: 0.5961
	--> Epoch [15/100], Loss: 0.4062, Validation Loss: 0.5898
	--> Epoch [16/100], Loss: 0.3995, Validation Loss: 0.5843
	--> Epoch [17/100], Loss: 0.3797, Validation Loss: 0.5782
	--> Epoch [18/100], Loss: 0.3905, Validation Loss: 0.5743
	--> Epoch [19/100], Loss: 0.3932, Validation Loss: 0.5690
	--> Epoch [20/100], Loss: 0.3882, Validation Loss: 0.5628
	--> Epoch [21/100], Loss: 0.2947, Validation Loss: 0.5576
	--> Epoch [22/100], Loss: 0.3010, Validation Loss: 0.5517
	--> Epoch [23/100], Loss: 0.2820, Validation Loss: 0.5478
	--> Epoch [24/100], Loss: 0.2685, Validation Loss: 0.5438
	--> Epoch [25/100], Loss: 0.3468, Validation Loss: 0.5403
	--> Epoch [26/100], Loss: 0.2665, Validation Loss: 0.5367
	--> Epoch [27/100], Loss: 0.2705, Validation Loss: 0.5341
	--> Epoch [28/100], Loss: 0.2970, Validation Loss: 0.5300
	--> Epoch [29/100], Loss: 0.3457, Validation Loss: 0.5272
	--> Epoch [30/100], Loss: 0.3140, Validation Loss: 0.5247
	--> Epoch [31/100], Loss: 0.3586, Validation Loss: 0.5216
	--> Epoch [32/100], Loss: 0.2670, Validation Loss: 0.5193
	--> Epoch [33/100], Loss: 0.2193, Validation Loss: 0.5169
	--> Epoch [34/100], Loss: 0.2688, Validation Loss: 0.5159
	--> Epoch [35/100], Loss: 0.2850, Validation Loss: 0.5135
	--> Epoch [36/100], Loss: 0.2035, Validation Loss: 0.5117
	--> Epoch [37/100], Loss: 0.2523, Validation Loss: 0.5093
	--> Epoch [38/100], Loss: 0.1274, Validation Loss: 0.5090
	--> Epoch [39/100], Loss: 0.1536, Validation Loss: 0.5083
	--> Epoch [40/100], Loss: 0.1392, Validation Loss: 0.5060
	--> Epoch [41/100], Loss: 0.2350, Validation Loss: 0.5036
	--> Epoch [42/100], Loss: 0.1379, Validation Loss: 0.5024
	--> Epoch [43/100], Loss: 0.2788, Validation Loss: 0.5013
	--> Epoch [44/100], Loss: 0.1360, Validation Loss: 0.5009
	--> Epoch [45/100], Loss: 0.1395, Validation Loss: 0.5002
	--> Epoch [46/100], Loss: 0.1620, Validation Loss: 0.4984
	--> Epoch [47/100], Loss: 0.2062, Validation Loss: 0.4979
	--> Epoch [48/100], Loss: 0.1671, Validation Loss: 0.4959
	--> Epoch [49/100], Loss: 0.1146, Validation Loss: 0.4946
	--> Epoch [50/100], Loss: 0.0905, Validation Loss: 0.4940
	--> Epoch [51/100], Loss: 0.1896, Validation Loss: 0.4950
	--> Epoch [52/100], Loss: 0.1604, Validation Loss: 0.4962
	--> Epoch [53/100], Loss: 0.0639, Validation Loss: 0.4961
Early stopping
	--> Training for Fold 5 took 0.3147134780883789 sec, using 53 epochs

Median number of epochs used: 94 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/94], Loss: 0.7257
	--> Final training Epoch [2/94], Loss: 0.6864
	--> Final training Epoch [3/94], Loss: 0.6676
	--> Final training Epoch [4/94], Loss: 0.6530
	--> Final training Epoch [5/94], Loss: 0.5962
	--> Final training Epoch [6/94], Loss: 0.6259
	--> Final training Epoch [7/94], Loss: 0.5808
	--> Final training Epoch [8/94], Loss: 0.5790
	--> Final training Epoch [9/94], Loss: 0.5179
	--> Final training Epoch [10/94], Loss: 0.5496
	--> Final training Epoch [11/94], Loss: 0.5153
	--> Final training Epoch [12/94], Loss: 0.4968
	--> Final training Epoch [13/94], Loss: 0.4601
	--> Final training Epoch [14/94], Loss: 0.4573
	--> Final training Epoch [15/94], Loss: 0.4524
	--> Final training Epoch [16/94], Loss: 0.4568
	--> Final training Epoch [17/94], Loss: 0.4575
	--> Final training Epoch [18/94], Loss: 0.4030
	--> Final training Epoch [19/94], Loss: 0.4225
	--> Final training Epoch [20/94], Loss: 0.3680
	--> Final training Epoch [21/94], Loss: 0.3566
	--> Final training Epoch [22/94], Loss: 0.3642
	--> Final training Epoch [23/94], Loss: 0.3915
	--> Final training Epoch [24/94], Loss: 0.3118
	--> Final training Epoch [25/94], Loss: 0.3474
	--> Final training Epoch [26/94], Loss: 0.2935
	--> Final training Epoch [27/94], Loss: 0.2684
	--> Final training Epoch [28/94], Loss: 0.3098
	--> Final training Epoch [29/94], Loss: 0.2540
	--> Final training Epoch [30/94], Loss: 0.2818
	--> Final training Epoch [31/94], Loss: 0.3262
	--> Final training Epoch [32/94], Loss: 0.2563
	--> Final training Epoch [33/94], Loss: 0.2318
	--> Final training Epoch [34/94], Loss: 0.2768
	--> Final training Epoch [35/94], Loss: 0.2459
	--> Final training Epoch [36/94], Loss: 0.2004
	--> Final training Epoch [37/94], Loss: 0.2061
	--> Final training Epoch [38/94], Loss: 0.2005
	--> Final training Epoch [39/94], Loss: 0.1789
	--> Final training Epoch [40/94], Loss: 0.2279
	--> Final training Epoch [41/94], Loss: 0.1569
	--> Final training Epoch [42/94], Loss: 0.1979
	--> Final training Epoch [43/94], Loss: 0.1580
	--> Final training Epoch [44/94], Loss: 0.1940
	--> Final training Epoch [45/94], Loss: 0.1505
	--> Final training Epoch [46/94], Loss: 0.1958
	--> Final training Epoch [47/94], Loss: 0.1698
	--> Final training Epoch [48/94], Loss: 0.1659
	--> Final training Epoch [49/94], Loss: 0.2137
	--> Final training Epoch [50/94], Loss: 0.1374
	--> Final training Epoch [51/94], Loss: 0.1091
	--> Final training Epoch [52/94], Loss: 0.1440
	--> Final training Epoch [53/94], Loss: 0.1635
	--> Final training Epoch [54/94], Loss: 0.1274
	--> Final training Epoch [55/94], Loss: 0.1049
	--> Final training Epoch [56/94], Loss: 0.1006
	--> Final training Epoch [57/94], Loss: 0.1300
	--> Final training Epoch [58/94], Loss: 0.0857
	--> Final training Epoch [59/94], Loss: 0.1522
	--> Final training Epoch [60/94], Loss: 0.0933
	--> Final training Epoch [61/94], Loss: 0.0842
	--> Final training Epoch [62/94], Loss: 0.1327
	--> Final training Epoch [63/94], Loss: 0.1230
	--> Final training Epoch [64/94], Loss: 0.1215
	--> Final training Epoch [65/94], Loss: 0.0881
	--> Final training Epoch [66/94], Loss: 0.0634
	--> Final training Epoch [67/94], Loss: 0.0973
	--> Final training Epoch [68/94], Loss: 0.0885
	--> Final training Epoch [69/94], Loss: 0.1482
	--> Final training Epoch [70/94], Loss: 0.1019
	--> Final training Epoch [71/94], Loss: 0.1923
	--> Final training Epoch [72/94], Loss: 0.1015
	--> Final training Epoch [73/94], Loss: 0.0782
	--> Final training Epoch [74/94], Loss: 0.0806
	--> Final training Epoch [75/94], Loss: 0.0711
	--> Final training Epoch [76/94], Loss: 0.0791
	--> Final training Epoch [77/94], Loss: 0.0978
	--> Final training Epoch [78/94], Loss: 0.0656
	--> Final training Epoch [79/94], Loss: 0.1218
	--> Final training Epoch [80/94], Loss: 0.0899
	--> Final training Epoch [81/94], Loss: 0.0593
	--> Final training Epoch [82/94], Loss: 0.0872
	--> Final training Epoch [83/94], Loss: 0.0551
	--> Final training Epoch [84/94], Loss: 0.0785
	--> Final training Epoch [85/94], Loss: 0.1095
	--> Final training Epoch [86/94], Loss: 0.0905
	--> Final training Epoch [87/94], Loss: 0.0761
	--> Final training Epoch [88/94], Loss: 0.0750
	--> Final training Epoch [89/94], Loss: 0.0376
	--> Final training Epoch [90/94], Loss: 0.0735
	--> Final training Epoch [91/94], Loss: 0.0575
	--> Final training Epoch [92/94], Loss: 0.0420
	--> Final training Epoch [93/94], Loss: 0.0485
	--> Final training Epoch [94/94], Loss: 0.0508

Final training took 0.5760440826416016 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9451
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8585, Validation Loss: 0.3145,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3145
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8152, Validation Loss: 0.3672,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3145
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8386, Validation Loss: 0.3793,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3145
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.3762,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3145
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.4265,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3145
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7398, Validation Loss: 0.4512,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3145
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8175, Validation Loss: 0.4406,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3145
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8152, Validation Loss: 0.3853,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.3145

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5958, Validation Loss: 0.7121
	--> Epoch [2/100], Loss: 0.5859, Validation Loss: 0.6942
	--> Epoch [3/100], Loss: 0.5677, Validation Loss: 0.6781
	--> Epoch [4/100], Loss: 0.5438, Validation Loss: 0.6733
	--> Epoch [5/100], Loss: 0.4955, Validation Loss: 0.6593
	--> Epoch [6/100], Loss: 0.5565, Validation Loss: 0.6520
	--> Epoch [7/100], Loss: 0.4911, Validation Loss: 0.6422
	--> Epoch [8/100], Loss: 0.4755, Validation Loss: 0.6320
	--> Epoch [9/100], Loss: 0.4218, Validation Loss: 0.6218
	--> Epoch [10/100], Loss: 0.4092, Validation Loss: 0.6097
	--> Epoch [11/100], Loss: 0.4645, Validation Loss: 0.6011
	--> Epoch [12/100], Loss: 0.4488, Validation Loss: 0.5891
	--> Epoch [13/100], Loss: 0.4499, Validation Loss: 0.5787
	--> Epoch [14/100], Loss: 0.3679, Validation Loss: 0.5658
	--> Epoch [15/100], Loss: 0.3390, Validation Loss: 0.5530
	--> Epoch [16/100], Loss: 0.3025, Validation Loss: 0.5389
	--> Epoch [17/100], Loss: 0.4012, Validation Loss: 0.5288
	--> Epoch [18/100], Loss: 0.3190, Validation Loss: 0.5181
	--> Epoch [19/100], Loss: 0.2662, Validation Loss: 0.5065
	--> Epoch [20/100], Loss: 0.2761, Validation Loss: 0.4967
	--> Epoch [21/100], Loss: 0.2363, Validation Loss: 0.4853
	--> Epoch [22/100], Loss: 0.2701, Validation Loss: 0.4738
	--> Epoch [23/100], Loss: 0.2635, Validation Loss: 0.4663
	--> Epoch [24/100], Loss: 0.3085, Validation Loss: 0.4574
	--> Epoch [25/100], Loss: 0.2098, Validation Loss: 0.4480
	--> Epoch [26/100], Loss: 0.2037, Validation Loss: 0.4416
	--> Epoch [27/100], Loss: 0.2127, Validation Loss: 0.4332
	--> Epoch [28/100], Loss: 0.1792, Validation Loss: 0.4258
	--> Epoch [29/100], Loss: 0.2285, Validation Loss: 0.4199
	--> Epoch [30/100], Loss: 0.1952, Validation Loss: 0.4137
	--> Epoch [31/100], Loss: 0.1432, Validation Loss: 0.4064
	--> Epoch [32/100], Loss: 0.2199, Validation Loss: 0.4012
	--> Epoch [33/100], Loss: 0.1681, Validation Loss: 0.3953
	--> Epoch [34/100], Loss: 0.1346, Validation Loss: 0.3900
	--> Epoch [35/100], Loss: 0.1574, Validation Loss: 0.3862
	--> Epoch [36/100], Loss: 0.1773, Validation Loss: 0.3803
	--> Epoch [37/100], Loss: 0.1294, Validation Loss: 0.3758
	--> Epoch [38/100], Loss: 0.1391, Validation Loss: 0.3692
	--> Epoch [39/100], Loss: 0.1639, Validation Loss: 0.3632
	--> Epoch [40/100], Loss: 0.2601, Validation Loss: 0.3581
	--> Epoch [41/100], Loss: 0.1195, Validation Loss: 0.3527
	--> Epoch [42/100], Loss: 0.1845, Validation Loss: 0.3490
	--> Epoch [43/100], Loss: 0.2086, Validation Loss: 0.3468
	--> Epoch [44/100], Loss: 0.1009, Validation Loss: 0.3447
	--> Epoch [45/100], Loss: 0.1629, Validation Loss: 0.3408
	--> Epoch [46/100], Loss: 0.1462, Validation Loss: 0.3367
	--> Epoch [47/100], Loss: 0.1751, Validation Loss: 0.3320
	--> Epoch [48/100], Loss: 0.1168, Validation Loss: 0.3285
	--> Epoch [49/100], Loss: 0.1127, Validation Loss: 0.3248
	--> Epoch [50/100], Loss: 0.1420, Validation Loss: 0.3221
	--> Epoch [51/100], Loss: 0.1155, Validation Loss: 0.3193
	--> Epoch [52/100], Loss: 0.1080, Validation Loss: 0.3180
	--> Epoch [53/100], Loss: 0.0800, Validation Loss: 0.3156
	--> Epoch [54/100], Loss: 0.1276, Validation Loss: 0.3128
	--> Epoch [55/100], Loss: 0.0964, Validation Loss: 0.3097
	--> Epoch [56/100], Loss: 0.0664, Validation Loss: 0.3091
	--> Epoch [57/100], Loss: 0.0808, Validation Loss: 0.3082
	--> Epoch [58/100], Loss: 0.1336, Validation Loss: 0.3043
	--> Epoch [59/100], Loss: 0.1416, Validation Loss: 0.3029
	--> Epoch [60/100], Loss: 0.0887, Validation Loss: 0.3014
	--> Epoch [61/100], Loss: 0.1240, Validation Loss: 0.3003
	--> Epoch [62/100], Loss: 0.0908, Validation Loss: 0.2977
	--> Epoch [63/100], Loss: 0.1066, Validation Loss: 0.2964
	--> Epoch [64/100], Loss: 0.0796, Validation Loss: 0.2953
	--> Epoch [65/100], Loss: 0.1208, Validation Loss: 0.2935
	--> Epoch [66/100], Loss: 0.1830, Validation Loss: 0.2907
	--> Epoch [67/100], Loss: 0.0717, Validation Loss: 0.2898
	--> Epoch [68/100], Loss: 0.0812, Validation Loss: 0.2882
	--> Epoch [69/100], Loss: 0.0867, Validation Loss: 0.2903
	--> Epoch [70/100], Loss: 0.0876, Validation Loss: 0.2877
	--> Epoch [71/100], Loss: 0.0950, Validation Loss: 0.2854
	--> Epoch [72/100], Loss: 0.0777, Validation Loss: 0.2837
	--> Epoch [73/100], Loss: 0.0819, Validation Loss: 0.2820
	--> Epoch [74/100], Loss: 0.1135, Validation Loss: 0.2803
	--> Epoch [75/100], Loss: 0.1154, Validation Loss: 0.2794
	--> Epoch [76/100], Loss: 0.0837, Validation Loss: 0.2785
	--> Epoch [77/100], Loss: 0.0708, Validation Loss: 0.2774
	--> Epoch [78/100], Loss: 0.0973, Validation Loss: 0.2762
	--> Epoch [79/100], Loss: 0.0674, Validation Loss: 0.2747
	--> Epoch [80/100], Loss: 0.1319, Validation Loss: 0.2735
	--> Epoch [81/100], Loss: 0.0736, Validation Loss: 0.2721
	--> Epoch [82/100], Loss: 0.0730, Validation Loss: 0.2713
	--> Epoch [83/100], Loss: 0.0736, Validation Loss: 0.2701
	--> Epoch [84/100], Loss: 0.1269, Validation Loss: 0.2693
	--> Epoch [85/100], Loss: 0.0709, Validation Loss: 0.2689
	--> Epoch [86/100], Loss: 0.0773, Validation Loss: 0.2682
	--> Epoch [87/100], Loss: 0.0560, Validation Loss: 0.2676
	--> Epoch [88/100], Loss: 0.1014, Validation Loss: 0.2690
	--> Epoch [89/100], Loss: 0.0702, Validation Loss: 0.2686
	--> Epoch [90/100], Loss: 0.0775, Validation Loss: 0.2673
	--> Epoch [91/100], Loss: 0.1125, Validation Loss: 0.2663
	--> Epoch [92/100], Loss: 0.0906, Validation Loss: 0.2645
	--> Epoch [93/100], Loss: 0.1630, Validation Loss: 0.2641
	--> Epoch [94/100], Loss: 0.0624, Validation Loss: 0.2635
	--> Epoch [95/100], Loss: 0.1045, Validation Loss: 0.2625
	--> Epoch [96/100], Loss: 0.1150, Validation Loss: 0.2615
	--> Epoch [97/100], Loss: 0.0788, Validation Loss: 0.2617
	--> Epoch [98/100], Loss: 0.0602, Validation Loss: 0.2608
	--> Epoch [99/100], Loss: 0.0540, Validation Loss: 0.2597
	--> Epoch [100/100], Loss: 0.0549, Validation Loss: 0.2592
	--> Training for Fold 1 took 0.5855624675750732 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5700, Validation Loss: 0.7874
	--> Epoch [2/100], Loss: 0.5554, Validation Loss: 0.7669
	--> Epoch [3/100], Loss: 0.4365, Validation Loss: 0.7390
	--> Epoch [4/100], Loss: 0.3953, Validation Loss: 0.7138
	--> Epoch [5/100], Loss: 0.4671, Validation Loss: 0.6957
	--> Epoch [6/100], Loss: 0.4620, Validation Loss: 0.6698
	--> Epoch [7/100], Loss: 0.4652, Validation Loss: 0.6550
	--> Epoch [8/100], Loss: 0.3856, Validation Loss: 0.6372
	--> Epoch [9/100], Loss: 0.3968, Validation Loss: 0.6147
	--> Epoch [10/100], Loss: 0.2795, Validation Loss: 0.5913
	--> Epoch [11/100], Loss: 0.2754, Validation Loss: 0.5752
	--> Epoch [12/100], Loss: 0.2962, Validation Loss: 0.5567
	--> Epoch [13/100], Loss: 0.2874, Validation Loss: 0.5439
	--> Epoch [14/100], Loss: 0.2929, Validation Loss: 0.5269
	--> Epoch [15/100], Loss: 0.2547, Validation Loss: 0.5125
	--> Epoch [16/100], Loss: 0.2689, Validation Loss: 0.4989
	--> Epoch [17/100], Loss: 0.2504, Validation Loss: 0.4847
	--> Epoch [18/100], Loss: 0.2293, Validation Loss: 0.4718
	--> Epoch [19/100], Loss: 0.1928, Validation Loss: 0.4596
	--> Epoch [20/100], Loss: 0.2077, Validation Loss: 0.4490
	--> Epoch [21/100], Loss: 0.2360, Validation Loss: 0.4364
	--> Epoch [22/100], Loss: 0.2401, Validation Loss: 0.4267
	--> Epoch [23/100], Loss: 0.2098, Validation Loss: 0.4162
	--> Epoch [24/100], Loss: 0.1768, Validation Loss: 0.4036
	--> Epoch [25/100], Loss: 0.1968, Validation Loss: 0.3940
	--> Epoch [26/100], Loss: 0.2249, Validation Loss: 0.3858
	--> Epoch [27/100], Loss: 0.1735, Validation Loss: 0.3777
	--> Epoch [28/100], Loss: 0.1600, Validation Loss: 0.3696
	--> Epoch [29/100], Loss: 0.1302, Validation Loss: 0.3591
	--> Epoch [30/100], Loss: 0.1022, Validation Loss: 0.3515
	--> Epoch [31/100], Loss: 0.1036, Validation Loss: 0.3417
	--> Epoch [32/100], Loss: 0.1289, Validation Loss: 0.3338
	--> Epoch [33/100], Loss: 0.0933, Validation Loss: 0.3263
	--> Epoch [34/100], Loss: 0.1064, Validation Loss: 0.3192
	--> Epoch [35/100], Loss: 0.1015, Validation Loss: 0.3141
	--> Epoch [36/100], Loss: 0.1676, Validation Loss: 0.3087
	--> Epoch [37/100], Loss: 0.1734, Validation Loss: 0.3036
	--> Epoch [38/100], Loss: 0.1541, Validation Loss: 0.2997
	--> Epoch [39/100], Loss: 0.1319, Validation Loss: 0.2951
	--> Epoch [40/100], Loss: 0.0936, Validation Loss: 0.2904
	--> Epoch [41/100], Loss: 0.0952, Validation Loss: 0.2867
	--> Epoch [42/100], Loss: 0.0930, Validation Loss: 0.2815
	--> Epoch [43/100], Loss: 0.0842, Validation Loss: 0.2770
	--> Epoch [44/100], Loss: 0.1172, Validation Loss: 0.2740
	--> Epoch [45/100], Loss: 0.0711, Validation Loss: 0.2704
	--> Epoch [46/100], Loss: 0.0615, Validation Loss: 0.2668
	--> Epoch [47/100], Loss: 0.1160, Validation Loss: 0.2629
	--> Epoch [48/100], Loss: 0.1109, Validation Loss: 0.2595
	--> Epoch [49/100], Loss: 0.0538, Validation Loss: 0.2570
	--> Epoch [50/100], Loss: 0.0390, Validation Loss: 0.2538
	--> Epoch [51/100], Loss: 0.1048, Validation Loss: 0.2518
	--> Epoch [52/100], Loss: 0.0795, Validation Loss: 0.2482
	--> Epoch [53/100], Loss: 0.0620, Validation Loss: 0.2442
	--> Epoch [54/100], Loss: 0.1341, Validation Loss: 0.2409
	--> Epoch [55/100], Loss: 0.0377, Validation Loss: 0.2393
	--> Epoch [56/100], Loss: 0.0659, Validation Loss: 0.2363
	--> Epoch [57/100], Loss: 0.0951, Validation Loss: 0.2330
	--> Epoch [58/100], Loss: 0.0443, Validation Loss: 0.2315
	--> Epoch [59/100], Loss: 0.0529, Validation Loss: 0.2299
	--> Epoch [60/100], Loss: 0.1056, Validation Loss: 0.2265
	--> Epoch [61/100], Loss: 0.0747, Validation Loss: 0.2245
	--> Epoch [62/100], Loss: 0.1660, Validation Loss: 0.2205
	--> Epoch [63/100], Loss: 0.0923, Validation Loss: 0.2181
	--> Epoch [64/100], Loss: 0.0864, Validation Loss: 0.2141
	--> Epoch [65/100], Loss: 0.0218, Validation Loss: 0.2119
	--> Epoch [66/100], Loss: 0.0512, Validation Loss: 0.2108
	--> Epoch [67/100], Loss: 0.0473, Validation Loss: 0.2077
	--> Epoch [68/100], Loss: 0.0218, Validation Loss: 0.2069
	--> Epoch [69/100], Loss: 0.0315, Validation Loss: 0.2050
	--> Epoch [70/100], Loss: 0.0717, Validation Loss: 0.2031
	--> Epoch [71/100], Loss: 0.0976, Validation Loss: 0.2010
	--> Epoch [72/100], Loss: 0.0483, Validation Loss: 0.1992
	--> Epoch [73/100], Loss: 0.0787, Validation Loss: 0.1987
	--> Epoch [74/100], Loss: 0.0672, Validation Loss: 0.1961
	--> Epoch [75/100], Loss: 0.0586, Validation Loss: 0.1951
	--> Epoch [76/100], Loss: 0.0647, Validation Loss: 0.1947
	--> Epoch [77/100], Loss: 0.1043, Validation Loss: 0.1937
	--> Epoch [78/100], Loss: 0.0610, Validation Loss: 0.1913
	--> Epoch [79/100], Loss: 0.0388, Validation Loss: 0.1899
	--> Epoch [80/100], Loss: 0.0277, Validation Loss: 0.1889
	--> Epoch [81/100], Loss: 0.0273, Validation Loss: 0.1873
	--> Epoch [82/100], Loss: 0.0108, Validation Loss: 0.1855
	--> Epoch [83/100], Loss: 0.0666, Validation Loss: 0.1844
	--> Epoch [84/100], Loss: 0.0844, Validation Loss: 0.1834
	--> Epoch [85/100], Loss: 0.0529, Validation Loss: 0.1806
	--> Epoch [86/100], Loss: 0.1049, Validation Loss: 0.1785
	--> Epoch [87/100], Loss: 0.0521, Validation Loss: 0.1772
	--> Epoch [88/100], Loss: 0.0482, Validation Loss: 0.1765
	--> Epoch [89/100], Loss: 0.0520, Validation Loss: 0.1738
	--> Epoch [90/100], Loss: 0.0440, Validation Loss: 0.1728
	--> Epoch [91/100], Loss: 0.0622, Validation Loss: 0.1725
	--> Epoch [92/100], Loss: 0.0110, Validation Loss: 0.1722
	--> Epoch [93/100], Loss: 0.0537, Validation Loss: 0.1715
	--> Epoch [94/100], Loss: 0.0119, Validation Loss: 0.1700
	--> Epoch [95/100], Loss: 0.0066, Validation Loss: 0.1690
	--> Epoch [96/100], Loss: 0.0640, Validation Loss: 0.1680
	--> Epoch [97/100], Loss: 0.0592, Validation Loss: 0.1675
	--> Epoch [98/100], Loss: 0.0059, Validation Loss: 0.1671
	--> Epoch [99/100], Loss: 0.0527, Validation Loss: 0.1664
	--> Epoch [100/100], Loss: 0.0197, Validation Loss: 0.1658
	--> Training for Fold 2 took 0.6345734596252441 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6654, Validation Loss: 0.7205
	--> Epoch [2/100], Loss: 0.6414, Validation Loss: 0.7115
	--> Epoch [3/100], Loss: 0.6081, Validation Loss: 0.7021
	--> Epoch [4/100], Loss: 0.5847, Validation Loss: 0.6920
	--> Epoch [5/100], Loss: 0.5685, Validation Loss: 0.6848
	--> Epoch [6/100], Loss: 0.5559, Validation Loss: 0.6774
	--> Epoch [7/100], Loss: 0.5047, Validation Loss: 0.6684
	--> Epoch [8/100], Loss: 0.4839, Validation Loss: 0.6586
	--> Epoch [9/100], Loss: 0.4848, Validation Loss: 0.6506
	--> Epoch [10/100], Loss: 0.4720, Validation Loss: 0.6413
	--> Epoch [11/100], Loss: 0.4085, Validation Loss: 0.6328
	--> Epoch [12/100], Loss: 0.4385, Validation Loss: 0.6235
	--> Epoch [13/100], Loss: 0.4085, Validation Loss: 0.6139
	--> Epoch [14/100], Loss: 0.4238, Validation Loss: 0.6067
	--> Epoch [15/100], Loss: 0.3412, Validation Loss: 0.5986
	--> Epoch [16/100], Loss: 0.4018, Validation Loss: 0.5902
	--> Epoch [17/100], Loss: 0.2822, Validation Loss: 0.5827
	--> Epoch [18/100], Loss: 0.3432, Validation Loss: 0.5780
	--> Epoch [19/100], Loss: 0.2883, Validation Loss: 0.5697
	--> Epoch [20/100], Loss: 0.2384, Validation Loss: 0.5614
	--> Epoch [21/100], Loss: 0.2761, Validation Loss: 0.5536
	--> Epoch [22/100], Loss: 0.2529, Validation Loss: 0.5451
	--> Epoch [23/100], Loss: 0.2455, Validation Loss: 0.5390
	--> Epoch [24/100], Loss: 0.2556, Validation Loss: 0.5316
	--> Epoch [25/100], Loss: 0.2742, Validation Loss: 0.5245
	--> Epoch [26/100], Loss: 0.2824, Validation Loss: 0.5182
	--> Epoch [27/100], Loss: 0.2920, Validation Loss: 0.5110
	--> Epoch [28/100], Loss: 0.2145, Validation Loss: 0.5038
	--> Epoch [29/100], Loss: 0.3155, Validation Loss: 0.4978
	--> Epoch [30/100], Loss: 0.1938, Validation Loss: 0.4889
	--> Epoch [31/100], Loss: 0.1821, Validation Loss: 0.4822
	--> Epoch [32/100], Loss: 0.1887, Validation Loss: 0.4761
	--> Epoch [33/100], Loss: 0.1787, Validation Loss: 0.4709
	--> Epoch [34/100], Loss: 0.2114, Validation Loss: 0.4646
	--> Epoch [35/100], Loss: 0.1385, Validation Loss: 0.4581
	--> Epoch [36/100], Loss: 0.1701, Validation Loss: 0.4525
	--> Epoch [37/100], Loss: 0.1407, Validation Loss: 0.4462
	--> Epoch [38/100], Loss: 0.1483, Validation Loss: 0.4410
	--> Epoch [39/100], Loss: 0.2469, Validation Loss: 0.4362
	--> Epoch [40/100], Loss: 0.1264, Validation Loss: 0.4331
	--> Epoch [41/100], Loss: 0.1256, Validation Loss: 0.4283
	--> Epoch [42/100], Loss: 0.1279, Validation Loss: 0.4236
	--> Epoch [43/100], Loss: 0.1368, Validation Loss: 0.4197
	--> Epoch [44/100], Loss: 0.1658, Validation Loss: 0.4163
	--> Epoch [45/100], Loss: 0.1660, Validation Loss: 0.4124
	--> Epoch [46/100], Loss: 0.1662, Validation Loss: 0.4090
	--> Epoch [47/100], Loss: 0.0986, Validation Loss: 0.4050
	--> Epoch [48/100], Loss: 0.1152, Validation Loss: 0.4016
	--> Epoch [49/100], Loss: 0.1002, Validation Loss: 0.3980
	--> Epoch [50/100], Loss: 0.1230, Validation Loss: 0.3964
	--> Epoch [51/100], Loss: 0.1556, Validation Loss: 0.3928
	--> Epoch [52/100], Loss: 0.1963, Validation Loss: 0.3892
	--> Epoch [53/100], Loss: 0.1957, Validation Loss: 0.3864
	--> Epoch [54/100], Loss: 0.1493, Validation Loss: 0.3834
	--> Epoch [55/100], Loss: 0.1389, Validation Loss: 0.3801
	--> Epoch [56/100], Loss: 0.2053, Validation Loss: 0.3773
	--> Epoch [57/100], Loss: 0.1123, Validation Loss: 0.3748
	--> Epoch [58/100], Loss: 0.0960, Validation Loss: 0.3722
	--> Epoch [59/100], Loss: 0.0891, Validation Loss: 0.3701
	--> Epoch [60/100], Loss: 0.0819, Validation Loss: 0.3679
	--> Epoch [61/100], Loss: 0.0865, Validation Loss: 0.3651
	--> Epoch [62/100], Loss: 0.2066, Validation Loss: 0.3631
	--> Epoch [63/100], Loss: 0.0993, Validation Loss: 0.3615
	--> Epoch [64/100], Loss: 0.1905, Validation Loss: 0.3598
	--> Epoch [65/100], Loss: 0.1309, Validation Loss: 0.3568
	--> Epoch [66/100], Loss: 0.1468, Validation Loss: 0.3557
	--> Epoch [67/100], Loss: 0.0894, Validation Loss: 0.3541
	--> Epoch [68/100], Loss: 0.0881, Validation Loss: 0.3534
	--> Epoch [69/100], Loss: 0.0820, Validation Loss: 0.3529
	--> Epoch [70/100], Loss: 0.0778, Validation Loss: 0.3505
	--> Epoch [71/100], Loss: 0.0752, Validation Loss: 0.3471
	--> Epoch [72/100], Loss: 0.1253, Validation Loss: 0.3467
	--> Epoch [73/100], Loss: 0.1498, Validation Loss: 0.3448
	--> Epoch [74/100], Loss: 0.0731, Validation Loss: 0.3431
	--> Epoch [75/100], Loss: 0.1444, Validation Loss: 0.3410
	--> Epoch [76/100], Loss: 0.1006, Validation Loss: 0.3408
	--> Epoch [77/100], Loss: 0.0831, Validation Loss: 0.3398
	--> Epoch [78/100], Loss: 0.1338, Validation Loss: 0.3395
	--> Epoch [79/100], Loss: 0.1030, Validation Loss: 0.3386
	--> Epoch [80/100], Loss: 0.1291, Validation Loss: 0.3361
	--> Epoch [81/100], Loss: 0.0829, Validation Loss: 0.3354
	--> Epoch [82/100], Loss: 0.0630, Validation Loss: 0.3340
	--> Epoch [83/100], Loss: 0.0693, Validation Loss: 0.3329
	--> Epoch [84/100], Loss: 0.0861, Validation Loss: 0.3327
	--> Epoch [85/100], Loss: 0.1378, Validation Loss: 0.3330
	--> Epoch [86/100], Loss: 0.0697, Validation Loss: 0.3324
	--> Epoch [87/100], Loss: 0.0982, Validation Loss: 0.3326
	--> Epoch [88/100], Loss: 0.1303, Validation Loss: 0.3321
	--> Epoch [89/100], Loss: 0.1354, Validation Loss: 0.3306
	--> Epoch [90/100], Loss: 0.1767, Validation Loss: 0.3307
	--> Epoch [91/100], Loss: 0.0804, Validation Loss: 0.3299
	--> Epoch [92/100], Loss: 0.1490, Validation Loss: 0.3295
	--> Epoch [93/100], Loss: 0.0830, Validation Loss: 0.3299
	--> Epoch [94/100], Loss: 0.1597, Validation Loss: 0.3290
	--> Epoch [95/100], Loss: 0.1306, Validation Loss: 0.3287
	--> Epoch [96/100], Loss: 0.0714, Validation Loss: 0.3290
	--> Epoch [97/100], Loss: 0.0687, Validation Loss: 0.3282
	--> Epoch [98/100], Loss: 0.1331, Validation Loss: 0.3243
	--> Epoch [99/100], Loss: 0.0726, Validation Loss: 0.3240
	--> Epoch [100/100], Loss: 0.1309, Validation Loss: 0.3222
	--> Training for Fold 3 took 0.5886163711547852 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7452, Validation Loss: 0.6873
	--> Epoch [2/100], Loss: 0.6534, Validation Loss: 0.6752
	--> Epoch [3/100], Loss: 0.6436, Validation Loss: 0.6590
	--> Epoch [4/100], Loss: 0.6151, Validation Loss: 0.6423
	--> Epoch [5/100], Loss: 0.5545, Validation Loss: 0.6312
	--> Epoch [6/100], Loss: 0.5135, Validation Loss: 0.6201
	--> Epoch [7/100], Loss: 0.5206, Validation Loss: 0.6101
	--> Epoch [8/100], Loss: 0.5071, Validation Loss: 0.6003
	--> Epoch [9/100], Loss: 0.4715, Validation Loss: 0.5924
	--> Epoch [10/100], Loss: 0.4288, Validation Loss: 0.5829
	--> Epoch [11/100], Loss: 0.4222, Validation Loss: 0.5755
	--> Epoch [12/100], Loss: 0.3718, Validation Loss: 0.5678
	--> Epoch [13/100], Loss: 0.3721, Validation Loss: 0.5586
	--> Epoch [14/100], Loss: 0.4155, Validation Loss: 0.5489
	--> Epoch [15/100], Loss: 0.4129, Validation Loss: 0.5461
	--> Epoch [16/100], Loss: 0.3215, Validation Loss: 0.5389
	--> Epoch [17/100], Loss: 0.3168, Validation Loss: 0.5333
	--> Epoch [18/100], Loss: 0.2691, Validation Loss: 0.5303
	--> Epoch [19/100], Loss: 0.2663, Validation Loss: 0.5225
	--> Epoch [20/100], Loss: 0.3308, Validation Loss: 0.5154
	--> Epoch [21/100], Loss: 0.2396, Validation Loss: 0.5103
	--> Epoch [22/100], Loss: 0.2598, Validation Loss: 0.5065
	--> Epoch [23/100], Loss: 0.2652, Validation Loss: 0.5021
	--> Epoch [24/100], Loss: 0.2647, Validation Loss: 0.4970
	--> Epoch [25/100], Loss: 0.2543, Validation Loss: 0.4923
	--> Epoch [26/100], Loss: 0.2080, Validation Loss: 0.4894
	--> Epoch [27/100], Loss: 0.2549, Validation Loss: 0.4845
	--> Epoch [28/100], Loss: 0.2048, Validation Loss: 0.4812
	--> Epoch [29/100], Loss: 0.1696, Validation Loss: 0.4780
	--> Epoch [30/100], Loss: 0.1676, Validation Loss: 0.4740
	--> Epoch [31/100], Loss: 0.2094, Validation Loss: 0.4714
	--> Epoch [32/100], Loss: 0.1139, Validation Loss: 0.4682
	--> Epoch [33/100], Loss: 0.1207, Validation Loss: 0.4664
	--> Epoch [34/100], Loss: 0.1368, Validation Loss: 0.4656
	--> Epoch [35/100], Loss: 0.1034, Validation Loss: 0.4611
	--> Epoch [36/100], Loss: 0.0840, Validation Loss: 0.4580
	--> Epoch [37/100], Loss: 0.0931, Validation Loss: 0.4580
	--> Epoch [38/100], Loss: 0.2259, Validation Loss: 0.4547
	--> Epoch [39/100], Loss: 0.1625, Validation Loss: 0.4504
	--> Epoch [40/100], Loss: 0.1189, Validation Loss: 0.4494
	--> Epoch [41/100], Loss: 0.2136, Validation Loss: 0.4476
	--> Epoch [42/100], Loss: 0.1128, Validation Loss: 0.4462
	--> Epoch [43/100], Loss: 0.1036, Validation Loss: 0.4450
	--> Epoch [44/100], Loss: 0.1196, Validation Loss: 0.4440
	--> Epoch [45/100], Loss: 0.1107, Validation Loss: 0.4421
	--> Epoch [46/100], Loss: 0.0766, Validation Loss: 0.4403
	--> Epoch [47/100], Loss: 0.0770, Validation Loss: 0.4380
	--> Epoch [48/100], Loss: 0.1157, Validation Loss: 0.4355
	--> Epoch [49/100], Loss: 0.0749, Validation Loss: 0.4324
	--> Epoch [50/100], Loss: 0.0792, Validation Loss: 0.4318
	--> Epoch [51/100], Loss: 0.0992, Validation Loss: 0.4318
	--> Epoch [52/100], Loss: 0.0566, Validation Loss: 0.4294
	--> Epoch [53/100], Loss: 0.1161, Validation Loss: 0.4355
	--> Epoch [54/100], Loss: 0.0810, Validation Loss: 0.4338
	--> Epoch [55/100], Loss: 0.0460, Validation Loss: 0.4320
Early stopping
	--> Training for Fold 4 took 0.3315911293029785 sec, using 55 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7224, Validation Loss: 0.6152
	--> Epoch [2/100], Loss: 0.7535, Validation Loss: 0.6065
	--> Epoch [3/100], Loss: 0.7018, Validation Loss: 0.5991
	--> Epoch [4/100], Loss: 0.6076, Validation Loss: 0.5943
	--> Epoch [5/100], Loss: 0.5737, Validation Loss: 0.5883
	--> Epoch [6/100], Loss: 0.6032, Validation Loss: 0.5826
	--> Epoch [7/100], Loss: 0.5681, Validation Loss: 0.5781
	--> Epoch [8/100], Loss: 0.5147, Validation Loss: 0.5731
	--> Epoch [9/100], Loss: 0.5370, Validation Loss: 0.5671
	--> Epoch [10/100], Loss: 0.4888, Validation Loss: 0.5625
	--> Epoch [11/100], Loss: 0.4026, Validation Loss: 0.5605
	--> Epoch [12/100], Loss: 0.4110, Validation Loss: 0.5570
	--> Epoch [13/100], Loss: 0.3936, Validation Loss: 0.5536
	--> Epoch [14/100], Loss: 0.4164, Validation Loss: 0.5483
	--> Epoch [15/100], Loss: 0.3629, Validation Loss: 0.5434
	--> Epoch [16/100], Loss: 0.3299, Validation Loss: 0.5401
	--> Epoch [17/100], Loss: 0.3718, Validation Loss: 0.5350
	--> Epoch [18/100], Loss: 0.2902, Validation Loss: 0.5305
	--> Epoch [19/100], Loss: 0.2638, Validation Loss: 0.5279
	--> Epoch [20/100], Loss: 0.3400, Validation Loss: 0.5248
	--> Epoch [21/100], Loss: 0.3193, Validation Loss: 0.5212
	--> Epoch [22/100], Loss: 0.2753, Validation Loss: 0.5165
	--> Epoch [23/100], Loss: 0.2931, Validation Loss: 0.5137
	--> Epoch [24/100], Loss: 0.2358, Validation Loss: 0.5107
	--> Epoch [25/100], Loss: 0.2210, Validation Loss: 0.5083
	--> Epoch [26/100], Loss: 0.2818, Validation Loss: 0.5071
	--> Epoch [27/100], Loss: 0.1910, Validation Loss: 0.5050
	--> Epoch [28/100], Loss: 0.1834, Validation Loss: 0.5017
	--> Epoch [29/100], Loss: 0.2480, Validation Loss: 0.5007
	--> Epoch [30/100], Loss: 0.1763, Validation Loss: 0.4989
	--> Epoch [31/100], Loss: 0.1924, Validation Loss: 0.4993
	--> Epoch [32/100], Loss: 0.1359, Validation Loss: 0.4965
	--> Epoch [33/100], Loss: 0.1447, Validation Loss: 0.4968
	--> Epoch [34/100], Loss: 0.3120, Validation Loss: 0.4965
	--> Epoch [35/100], Loss: 0.1392, Validation Loss: 0.4950
	--> Epoch [36/100], Loss: 0.1291, Validation Loss: 0.4941
	--> Epoch [37/100], Loss: 0.1484, Validation Loss: 0.4959
	--> Epoch [38/100], Loss: 0.1542, Validation Loss: 0.4944
	--> Epoch [39/100], Loss: 0.2076, Validation Loss: 0.4937
	--> Epoch [40/100], Loss: 0.1613, Validation Loss: 0.4940
	--> Epoch [41/100], Loss: 0.0804, Validation Loss: 0.4940
	--> Epoch [42/100], Loss: 0.1155, Validation Loss: 0.4926
	--> Epoch [43/100], Loss: 0.1453, Validation Loss: 0.4941
	--> Epoch [44/100], Loss: 0.1042, Validation Loss: 0.4941
	--> Epoch [45/100], Loss: 0.1359, Validation Loss: 0.4915
	--> Epoch [46/100], Loss: 0.0738, Validation Loss: 0.4893
	--> Epoch [47/100], Loss: 0.0848, Validation Loss: 0.4881
	--> Epoch [48/100], Loss: 0.1384, Validation Loss: 0.4880
	--> Epoch [49/100], Loss: 0.1199, Validation Loss: 0.4893
	--> Epoch [50/100], Loss: 0.0628, Validation Loss: 0.4885
	--> Epoch [51/100], Loss: 0.0559, Validation Loss: 0.4873
	--> Epoch [52/100], Loss: 0.0618, Validation Loss: 0.4873
	--> Epoch [53/100], Loss: 0.1585, Validation Loss: 0.4889
	--> Epoch [54/100], Loss: 0.0422, Validation Loss: 0.4885
Early stopping
	--> Training for Fold 5 took 0.3218855857849121 sec, using 54 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6842
	--> Final training Epoch [2/100], Loss: 0.6802
	--> Final training Epoch [3/100], Loss: 0.6658
	--> Final training Epoch [4/100], Loss: 0.6415
	--> Final training Epoch [5/100], Loss: 0.6314
	--> Final training Epoch [6/100], Loss: 0.6056
	--> Final training Epoch [7/100], Loss: 0.5932
	--> Final training Epoch [8/100], Loss: 0.6100
	--> Final training Epoch [9/100], Loss: 0.5762
	--> Final training Epoch [10/100], Loss: 0.5437
	--> Final training Epoch [11/100], Loss: 0.5211
	--> Final training Epoch [12/100], Loss: 0.5229
	--> Final training Epoch [13/100], Loss: 0.4974
	--> Final training Epoch [14/100], Loss: 0.4728
	--> Final training Epoch [15/100], Loss: 0.4524
	--> Final training Epoch [16/100], Loss: 0.4566
	--> Final training Epoch [17/100], Loss: 0.4681
	--> Final training Epoch [18/100], Loss: 0.4241
	--> Final training Epoch [19/100], Loss: 0.4471
	--> Final training Epoch [20/100], Loss: 0.3965
	--> Final training Epoch [21/100], Loss: 0.4003
	--> Final training Epoch [22/100], Loss: 0.3998
	--> Final training Epoch [23/100], Loss: 0.3439
	--> Final training Epoch [24/100], Loss: 0.3232
	--> Final training Epoch [25/100], Loss: 0.3497
	--> Final training Epoch [26/100], Loss: 0.3145
	--> Final training Epoch [27/100], Loss: 0.3297
	--> Final training Epoch [28/100], Loss: 0.2849
	--> Final training Epoch [29/100], Loss: 0.2894
	--> Final training Epoch [30/100], Loss: 0.2878
	--> Final training Epoch [31/100], Loss: 0.2875
	--> Final training Epoch [32/100], Loss: 0.2832
	--> Final training Epoch [33/100], Loss: 0.3102
	--> Final training Epoch [34/100], Loss: 0.2263
	--> Final training Epoch [35/100], Loss: 0.1994
	--> Final training Epoch [36/100], Loss: 0.2361
	--> Final training Epoch [37/100], Loss: 0.2082
	--> Final training Epoch [38/100], Loss: 0.2254
	--> Final training Epoch [39/100], Loss: 0.1956
	--> Final training Epoch [40/100], Loss: 0.1875
	--> Final training Epoch [41/100], Loss: 0.1770
	--> Final training Epoch [42/100], Loss: 0.1453
	--> Final training Epoch [43/100], Loss: 0.1741
	--> Final training Epoch [44/100], Loss: 0.1507
	--> Final training Epoch [45/100], Loss: 0.1617
	--> Final training Epoch [46/100], Loss: 0.1678
	--> Final training Epoch [47/100], Loss: 0.1829
	--> Final training Epoch [48/100], Loss: 0.1711
	--> Final training Epoch [49/100], Loss: 0.1981
	--> Final training Epoch [50/100], Loss: 0.1097
	--> Final training Epoch [51/100], Loss: 0.1392
	--> Final training Epoch [52/100], Loss: 0.1416
	--> Final training Epoch [53/100], Loss: 0.1300
	--> Final training Epoch [54/100], Loss: 0.1135
	--> Final training Epoch [55/100], Loss: 0.1047
	--> Final training Epoch [56/100], Loss: 0.1633
	--> Final training Epoch [57/100], Loss: 0.1238
	--> Final training Epoch [58/100], Loss: 0.1270
	--> Final training Epoch [59/100], Loss: 0.1059
	--> Final training Epoch [60/100], Loss: 0.1101
	--> Final training Epoch [61/100], Loss: 0.1371
	--> Final training Epoch [62/100], Loss: 0.1012
	--> Final training Epoch [63/100], Loss: 0.1261
	--> Final training Epoch [64/100], Loss: 0.1286
	--> Final training Epoch [65/100], Loss: 0.0782
	--> Final training Epoch [66/100], Loss: 0.1478
	--> Final training Epoch [67/100], Loss: 0.0688
	--> Final training Epoch [68/100], Loss: 0.0860
	--> Final training Epoch [69/100], Loss: 0.0862
	--> Final training Epoch [70/100], Loss: 0.1237
	--> Final training Epoch [71/100], Loss: 0.1134
	--> Final training Epoch [72/100], Loss: 0.0710
	--> Final training Epoch [73/100], Loss: 0.1062
	--> Final training Epoch [74/100], Loss: 0.0530
	--> Final training Epoch [75/100], Loss: 0.0713
	--> Final training Epoch [76/100], Loss: 0.1536
	--> Final training Epoch [77/100], Loss: 0.0597
	--> Final training Epoch [78/100], Loss: 0.0972
	--> Final training Epoch [79/100], Loss: 0.1466
	--> Final training Epoch [80/100], Loss: 0.1434
	--> Final training Epoch [81/100], Loss: 0.0650
	--> Final training Epoch [82/100], Loss: 0.0693
	--> Final training Epoch [83/100], Loss: 0.0360
	--> Final training Epoch [84/100], Loss: 0.0520
	--> Final training Epoch [85/100], Loss: 0.0774
	--> Final training Epoch [86/100], Loss: 0.0539
	--> Final training Epoch [87/100], Loss: 0.0626
	--> Final training Epoch [88/100], Loss: 0.0629
	--> Final training Epoch [89/100], Loss: 0.0644
	--> Final training Epoch [90/100], Loss: 0.0868
	--> Final training Epoch [91/100], Loss: 0.1044
	--> Final training Epoch [92/100], Loss: 0.0796
	--> Final training Epoch [93/100], Loss: 0.0651
	--> Final training Epoch [94/100], Loss: 0.0645
	--> Final training Epoch [95/100], Loss: 0.0884
	--> Final training Epoch [96/100], Loss: 0.0966
	--> Final training Epoch [97/100], Loss: 0.0830
	--> Final training Epoch [98/100], Loss: 0.0584
	--> Final training Epoch [99/100], Loss: 0.0558
	--> Final training Epoch [100/100], Loss: 0.0546

Final training took 0.5748610496520996 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8745
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3354,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3354
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7708, Validation Loss: 0.3795,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3354
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8696, Validation Loss: 0.3796,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3354

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6711, Validation Loss: 0.6806
	--> Epoch [2/100], Loss: 0.6092, Validation Loss: 0.6717
	--> Epoch [3/100], Loss: 0.6326, Validation Loss: 0.6626
	--> Epoch [4/100], Loss: 0.5654, Validation Loss: 0.6575
	--> Epoch [5/100], Loss: 0.5674, Validation Loss: 0.6493
	--> Epoch [6/100], Loss: 0.6079, Validation Loss: 0.6429
	--> Epoch [7/100], Loss: 0.5428, Validation Loss: 0.6374
	--> Epoch [8/100], Loss: 0.5650, Validation Loss: 0.6308
	--> Epoch [9/100], Loss: 0.4603, Validation Loss: 0.6215
	--> Epoch [10/100], Loss: 0.5468, Validation Loss: 0.6167
	--> Epoch [11/100], Loss: 0.4832, Validation Loss: 0.6088
	--> Epoch [12/100], Loss: 0.5037, Validation Loss: 0.6018
	--> Epoch [13/100], Loss: 0.4727, Validation Loss: 0.5948
	--> Epoch [14/100], Loss: 0.4896, Validation Loss: 0.5904
	--> Epoch [15/100], Loss: 0.5071, Validation Loss: 0.5837
	--> Epoch [16/100], Loss: 0.4516, Validation Loss: 0.5775
	--> Epoch [17/100], Loss: 0.4123, Validation Loss: 0.5726
	--> Epoch [18/100], Loss: 0.4632, Validation Loss: 0.5671
	--> Epoch [19/100], Loss: 0.4339, Validation Loss: 0.5605
	--> Epoch [20/100], Loss: 0.3493, Validation Loss: 0.5529
	--> Epoch [21/100], Loss: 0.4090, Validation Loss: 0.5461
	--> Epoch [22/100], Loss: 0.3574, Validation Loss: 0.5388
	--> Epoch [23/100], Loss: 0.4346, Validation Loss: 0.5324
	--> Epoch [24/100], Loss: 0.4066, Validation Loss: 0.5268
	--> Epoch [25/100], Loss: 0.3135, Validation Loss: 0.5206
	--> Epoch [26/100], Loss: 0.4116, Validation Loss: 0.5147
	--> Epoch [27/100], Loss: 0.2818, Validation Loss: 0.5077
	--> Epoch [28/100], Loss: 0.3902, Validation Loss: 0.5014
	--> Epoch [29/100], Loss: 0.3475, Validation Loss: 0.4953
	--> Epoch [30/100], Loss: 0.3226, Validation Loss: 0.4884
	--> Epoch [31/100], Loss: 0.2770, Validation Loss: 0.4825
	--> Epoch [32/100], Loss: 0.2685, Validation Loss: 0.4765
	--> Epoch [33/100], Loss: 0.2894, Validation Loss: 0.4711
	--> Epoch [34/100], Loss: 0.3756, Validation Loss: 0.4646
	--> Epoch [35/100], Loss: 0.2097, Validation Loss: 0.4618
	--> Epoch [36/100], Loss: 0.2663, Validation Loss: 0.4570
	--> Epoch [37/100], Loss: 0.2326, Validation Loss: 0.4521
	--> Epoch [38/100], Loss: 0.1911, Validation Loss: 0.4470
	--> Epoch [39/100], Loss: 0.2771, Validation Loss: 0.4423
	--> Epoch [40/100], Loss: 0.2173, Validation Loss: 0.4380
	--> Epoch [41/100], Loss: 0.1801, Validation Loss: 0.4355
	--> Epoch [42/100], Loss: 0.2540, Validation Loss: 0.4314
	--> Epoch [43/100], Loss: 0.3597, Validation Loss: 0.4277
	--> Epoch [44/100], Loss: 0.1287, Validation Loss: 0.4237
	--> Epoch [45/100], Loss: 0.2479, Validation Loss: 0.4203
	--> Epoch [46/100], Loss: 0.2935, Validation Loss: 0.4166
	--> Epoch [47/100], Loss: 0.2050, Validation Loss: 0.4146
	--> Epoch [48/100], Loss: 0.1612, Validation Loss: 0.4115
	--> Epoch [49/100], Loss: 0.3445, Validation Loss: 0.4087
	--> Epoch [50/100], Loss: 0.3185, Validation Loss: 0.4034
	--> Epoch [51/100], Loss: 0.1913, Validation Loss: 0.3995
	--> Epoch [52/100], Loss: 0.1992, Validation Loss: 0.3950
	--> Epoch [53/100], Loss: 0.3432, Validation Loss: 0.3930
	--> Epoch [54/100], Loss: 0.2952, Validation Loss: 0.3889
	--> Epoch [55/100], Loss: 0.1986, Validation Loss: 0.3859
	--> Epoch [56/100], Loss: 0.1950, Validation Loss: 0.3823
	--> Epoch [57/100], Loss: 0.1866, Validation Loss: 0.3823
	--> Epoch [58/100], Loss: 0.2008, Validation Loss: 0.3816
	--> Epoch [59/100], Loss: 0.2830, Validation Loss: 0.3795
	--> Epoch [60/100], Loss: 0.1942, Validation Loss: 0.3768
	--> Epoch [61/100], Loss: 0.2449, Validation Loss: 0.3755
	--> Epoch [62/100], Loss: 0.1386, Validation Loss: 0.3743
	--> Epoch [63/100], Loss: 0.1383, Validation Loss: 0.3724
	--> Epoch [64/100], Loss: 0.1458, Validation Loss: 0.3702
	--> Epoch [65/100], Loss: 0.2083, Validation Loss: 0.3686
	--> Epoch [66/100], Loss: 0.3033, Validation Loss: 0.3657
	--> Epoch [67/100], Loss: 0.1443, Validation Loss: 0.3637
	--> Epoch [68/100], Loss: 0.1893, Validation Loss: 0.3624
	--> Epoch [69/100], Loss: 0.1380, Validation Loss: 0.3604
	--> Epoch [70/100], Loss: 0.1917, Validation Loss: 0.3587
	--> Epoch [71/100], Loss: 0.1193, Validation Loss: 0.3569
	--> Epoch [72/100], Loss: 0.1849, Validation Loss: 0.3572
	--> Epoch [73/100], Loss: 0.2175, Validation Loss: 0.3559
	--> Epoch [74/100], Loss: 0.1724, Validation Loss: 0.3549
	--> Epoch [75/100], Loss: 0.0741, Validation Loss: 0.3539
	--> Epoch [76/100], Loss: 0.1401, Validation Loss: 0.3528
	--> Epoch [77/100], Loss: 0.1660, Validation Loss: 0.3525
	--> Epoch [78/100], Loss: 0.2240, Validation Loss: 0.3514
	--> Epoch [79/100], Loss: 0.1237, Validation Loss: 0.3503
	--> Epoch [80/100], Loss: 0.1218, Validation Loss: 0.3479
	--> Epoch [81/100], Loss: 0.3000, Validation Loss: 0.3465
	--> Epoch [82/100], Loss: 0.2179, Validation Loss: 0.3448
	--> Epoch [83/100], Loss: 0.1210, Validation Loss: 0.3434
	--> Epoch [84/100], Loss: 0.0870, Validation Loss: 0.3414
	--> Epoch [85/100], Loss: 0.1239, Validation Loss: 0.3413
	--> Epoch [86/100], Loss: 0.0701, Validation Loss: 0.3405
	--> Epoch [87/100], Loss: 0.2088, Validation Loss: 0.3392
	--> Epoch [88/100], Loss: 0.1640, Validation Loss: 0.3380
	--> Epoch [89/100], Loss: 0.1682, Validation Loss: 0.3368
	--> Epoch [90/100], Loss: 0.1556, Validation Loss: 0.3371
	--> Epoch [91/100], Loss: 0.2108, Validation Loss: 0.3372
	--> Epoch [92/100], Loss: 0.2028, Validation Loss: 0.3373
Early stopping
	--> Training for Fold 1 took 0.5481712818145752 sec, using 92 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7893, Validation Loss: 0.6609
	--> Epoch [2/100], Loss: 0.6860, Validation Loss: 0.6421
	--> Epoch [3/100], Loss: 0.7291, Validation Loss: 0.6250
	--> Epoch [4/100], Loss: 0.6446, Validation Loss: 0.6136
	--> Epoch [5/100], Loss: 0.6596, Validation Loss: 0.6026
	--> Epoch [6/100], Loss: 0.6091, Validation Loss: 0.5935
	--> Epoch [7/100], Loss: 0.6101, Validation Loss: 0.5847
	--> Epoch [8/100], Loss: 0.6248, Validation Loss: 0.5759
	--> Epoch [9/100], Loss: 0.5656, Validation Loss: 0.5665
	--> Epoch [10/100], Loss: 0.5510, Validation Loss: 0.5586
	--> Epoch [11/100], Loss: 0.4560, Validation Loss: 0.5507
	--> Epoch [12/100], Loss: 0.4620, Validation Loss: 0.5407
	--> Epoch [13/100], Loss: 0.3723, Validation Loss: 0.5320
	--> Epoch [14/100], Loss: 0.4874, Validation Loss: 0.5232
	--> Epoch [15/100], Loss: 0.4442, Validation Loss: 0.5152
	--> Epoch [16/100], Loss: 0.3915, Validation Loss: 0.5079
	--> Epoch [17/100], Loss: 0.4444, Validation Loss: 0.4988
	--> Epoch [18/100], Loss: 0.3584, Validation Loss: 0.4913
	--> Epoch [19/100], Loss: 0.3669, Validation Loss: 0.4825
	--> Epoch [20/100], Loss: 0.2917, Validation Loss: 0.4754
	--> Epoch [21/100], Loss: 0.4142, Validation Loss: 0.4685
	--> Epoch [22/100], Loss: 0.2433, Validation Loss: 0.4628
	--> Epoch [23/100], Loss: 0.3883, Validation Loss: 0.4568
	--> Epoch [24/100], Loss: 0.2582, Validation Loss: 0.4492
	--> Epoch [25/100], Loss: 0.3869, Validation Loss: 0.4445
	--> Epoch [26/100], Loss: 0.3545, Validation Loss: 0.4368
	--> Epoch [27/100], Loss: 0.2528, Validation Loss: 0.4321
	--> Epoch [28/100], Loss: 0.2718, Validation Loss: 0.4248
	--> Epoch [29/100], Loss: 0.2873, Validation Loss: 0.4200
	--> Epoch [30/100], Loss: 0.1541, Validation Loss: 0.4150
	--> Epoch [31/100], Loss: 0.2264, Validation Loss: 0.4109
	--> Epoch [32/100], Loss: 0.2954, Validation Loss: 0.4054
	--> Epoch [33/100], Loss: 0.2368, Validation Loss: 0.3988
	--> Epoch [34/100], Loss: 0.1612, Validation Loss: 0.3960
	--> Epoch [35/100], Loss: 0.1217, Validation Loss: 0.3909
	--> Epoch [36/100], Loss: 0.2264, Validation Loss: 0.3849
	--> Epoch [37/100], Loss: 0.1785, Validation Loss: 0.3803
	--> Epoch [38/100], Loss: 0.2484, Validation Loss: 0.3767
	--> Epoch [39/100], Loss: 0.2145, Validation Loss: 0.3724
	--> Epoch [40/100], Loss: 0.1283, Validation Loss: 0.3691
	--> Epoch [41/100], Loss: 0.1607, Validation Loss: 0.3649
	--> Epoch [42/100], Loss: 0.1651, Validation Loss: 0.3614
	--> Epoch [43/100], Loss: 0.2276, Validation Loss: 0.3568
	--> Epoch [44/100], Loss: 0.1261, Validation Loss: 0.3539
	--> Epoch [45/100], Loss: 0.0433, Validation Loss: 0.3501
	--> Epoch [46/100], Loss: 0.1320, Validation Loss: 0.3485
	--> Epoch [47/100], Loss: 0.1065, Validation Loss: 0.3459
	--> Epoch [48/100], Loss: 0.2445, Validation Loss: 0.3427
	--> Epoch [49/100], Loss: 0.0929, Validation Loss: 0.3399
	--> Epoch [50/100], Loss: 0.3109, Validation Loss: 0.3379
	--> Epoch [51/100], Loss: 0.1223, Validation Loss: 0.3341
	--> Epoch [52/100], Loss: 0.1110, Validation Loss: 0.3329
	--> Epoch [53/100], Loss: 0.0437, Validation Loss: 0.3313
	--> Epoch [54/100], Loss: 0.1166, Validation Loss: 0.3285
	--> Epoch [55/100], Loss: 0.0413, Validation Loss: 0.3262
	--> Epoch [56/100], Loss: 0.0830, Validation Loss: 0.3242
	--> Epoch [57/100], Loss: 0.2633, Validation Loss: 0.3198
	--> Epoch [58/100], Loss: 0.0736, Validation Loss: 0.3179
	--> Epoch [59/100], Loss: 0.0802, Validation Loss: 0.3163
	--> Epoch [60/100], Loss: 0.1997, Validation Loss: 0.3164
	--> Epoch [61/100], Loss: 0.2002, Validation Loss: 0.3119
	--> Epoch [62/100], Loss: 0.3613, Validation Loss: 0.3081
	--> Epoch [63/100], Loss: 0.0712, Validation Loss: 0.3089
	--> Epoch [64/100], Loss: 0.2148, Validation Loss: 0.3078
	--> Epoch [65/100], Loss: 0.2370, Validation Loss: 0.3065
	--> Epoch [66/100], Loss: 0.1924, Validation Loss: 0.3049
	--> Epoch [67/100], Loss: 0.1293, Validation Loss: 0.3013
	--> Epoch [68/100], Loss: 0.0490, Validation Loss: 0.3000
	--> Epoch [69/100], Loss: 0.0546, Validation Loss: 0.2980
	--> Epoch [70/100], Loss: 0.1554, Validation Loss: 0.2966
	--> Epoch [71/100], Loss: 0.1002, Validation Loss: 0.2951
	--> Epoch [72/100], Loss: 0.0690, Validation Loss: 0.2942
	--> Epoch [73/100], Loss: 0.0384, Validation Loss: 0.2936
	--> Epoch [74/100], Loss: 0.0975, Validation Loss: 0.2935
	--> Epoch [75/100], Loss: 0.0299, Validation Loss: 0.2925
	--> Epoch [76/100], Loss: 0.2715, Validation Loss: 0.2906
	--> Epoch [77/100], Loss: 0.1237, Validation Loss: 0.2896
	--> Epoch [78/100], Loss: 0.0731, Validation Loss: 0.2901
	--> Epoch [79/100], Loss: 0.2061, Validation Loss: 0.2888
	--> Epoch [80/100], Loss: 0.0430, Validation Loss: 0.2867
	--> Epoch [81/100], Loss: 0.1993, Validation Loss: 0.2862
	--> Epoch [82/100], Loss: 0.0484, Validation Loss: 0.2843
	--> Epoch [83/100], Loss: 0.0651, Validation Loss: 0.2803
	--> Epoch [84/100], Loss: 0.0386, Validation Loss: 0.2785
	--> Epoch [85/100], Loss: 0.1695, Validation Loss: 0.2775
	--> Epoch [86/100], Loss: 0.1045, Validation Loss: 0.2766
	--> Epoch [87/100], Loss: 0.0226, Validation Loss: 0.2753
	--> Epoch [88/100], Loss: 0.1711, Validation Loss: 0.2724
	--> Epoch [89/100], Loss: 0.0308, Validation Loss: 0.2722
	--> Epoch [90/100], Loss: 0.1389, Validation Loss: 0.2715
	--> Epoch [91/100], Loss: 0.1718, Validation Loss: 0.2687
	--> Epoch [92/100], Loss: 0.1235, Validation Loss: 0.2685
	--> Epoch [93/100], Loss: 0.2668, Validation Loss: 0.2669
	--> Epoch [94/100], Loss: 0.1779, Validation Loss: 0.2673
	--> Epoch [95/100], Loss: 0.1245, Validation Loss: 0.2662
	--> Epoch [96/100], Loss: 0.0697, Validation Loss: 0.2667
	--> Epoch [97/100], Loss: 0.0869, Validation Loss: 0.2688
	--> Epoch [98/100], Loss: 0.0198, Validation Loss: 0.2669
Early stopping
	--> Training for Fold 2 took 0.5887596607208252 sec, using 98 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4605, Validation Loss: 0.8433
	--> Epoch [2/100], Loss: 0.4707, Validation Loss: 0.8284
	--> Epoch [3/100], Loss: 0.4588, Validation Loss: 0.8182
	--> Epoch [4/100], Loss: 0.4143, Validation Loss: 0.8050
	--> Epoch [5/100], Loss: 0.4341, Validation Loss: 0.7943
	--> Epoch [6/100], Loss: 0.3725, Validation Loss: 0.7858
	--> Epoch [7/100], Loss: 0.3353, Validation Loss: 0.7818
	--> Epoch [8/100], Loss: 0.2920, Validation Loss: 0.7747
	--> Epoch [9/100], Loss: 0.3485, Validation Loss: 0.7679
	--> Epoch [10/100], Loss: 0.3830, Validation Loss: 0.7619
	--> Epoch [11/100], Loss: 0.3656, Validation Loss: 0.7550
	--> Epoch [12/100], Loss: 0.2397, Validation Loss: 0.7510
	--> Epoch [13/100], Loss: 0.3453, Validation Loss: 0.7440
	--> Epoch [14/100], Loss: 0.2700, Validation Loss: 0.7411
	--> Epoch [15/100], Loss: 0.2767, Validation Loss: 0.7337
	--> Epoch [16/100], Loss: 0.3516, Validation Loss: 0.7279
	--> Epoch [17/100], Loss: 0.3065, Validation Loss: 0.7211
	--> Epoch [18/100], Loss: 0.1669, Validation Loss: 0.7168
	--> Epoch [19/100], Loss: 0.1709, Validation Loss: 0.7078
	--> Epoch [20/100], Loss: 0.2629, Validation Loss: 0.7028
	--> Epoch [21/100], Loss: 0.2241, Validation Loss: 0.6973
	--> Epoch [22/100], Loss: 0.2350, Validation Loss: 0.6892
	--> Epoch [23/100], Loss: 0.1643, Validation Loss: 0.6839
	--> Epoch [24/100], Loss: 0.1944, Validation Loss: 0.6780
	--> Epoch [25/100], Loss: 0.2590, Validation Loss: 0.6728
	--> Epoch [26/100], Loss: 0.2700, Validation Loss: 0.6670
	--> Epoch [27/100], Loss: 0.2142, Validation Loss: 0.6607
	--> Epoch [28/100], Loss: 0.1570, Validation Loss: 0.6518
	--> Epoch [29/100], Loss: 0.0618, Validation Loss: 0.6445
	--> Epoch [30/100], Loss: 0.1891, Validation Loss: 0.6401
	--> Epoch [31/100], Loss: 0.1523, Validation Loss: 0.6337
	--> Epoch [32/100], Loss: 0.1163, Validation Loss: 0.6264
	--> Epoch [33/100], Loss: 0.1456, Validation Loss: 0.6201
	--> Epoch [34/100], Loss: 0.0805, Validation Loss: 0.6167
	--> Epoch [35/100], Loss: 0.2184, Validation Loss: 0.6098
	--> Epoch [36/100], Loss: 0.1712, Validation Loss: 0.6070
	--> Epoch [37/100], Loss: 0.1086, Validation Loss: 0.6077
	--> Epoch [38/100], Loss: 0.1899, Validation Loss: 0.6049
	--> Epoch [39/100], Loss: 0.0886, Validation Loss: 0.6015
	--> Epoch [40/100], Loss: 0.1141, Validation Loss: 0.5966
	--> Epoch [41/100], Loss: 0.1505, Validation Loss: 0.5915
	--> Epoch [42/100], Loss: 0.0640, Validation Loss: 0.5853
	--> Epoch [43/100], Loss: 0.0861, Validation Loss: 0.5822
	--> Epoch [44/100], Loss: 0.1801, Validation Loss: 0.5766
	--> Epoch [45/100], Loss: 0.0743, Validation Loss: 0.5744
	--> Epoch [46/100], Loss: 0.1295, Validation Loss: 0.5705
	--> Epoch [47/100], Loss: 0.0811, Validation Loss: 0.5687
	--> Epoch [48/100], Loss: 0.0429, Validation Loss: 0.5643
	--> Epoch [49/100], Loss: 0.0976, Validation Loss: 0.5632
	--> Epoch [50/100], Loss: 0.0960, Validation Loss: 0.5571
	--> Epoch [51/100], Loss: 0.0521, Validation Loss: 0.5528
	--> Epoch [52/100], Loss: 0.0921, Validation Loss: 0.5500
	--> Epoch [53/100], Loss: 0.0828, Validation Loss: 0.5468
	--> Epoch [54/100], Loss: 0.1282, Validation Loss: 0.5422
	--> Epoch [55/100], Loss: 0.1413, Validation Loss: 0.5363
	--> Epoch [56/100], Loss: 0.0468, Validation Loss: 0.5344
	--> Epoch [57/100], Loss: 0.1754, Validation Loss: 0.5294
	--> Epoch [58/100], Loss: 0.0570, Validation Loss: 0.5265
	--> Epoch [59/100], Loss: 0.0148, Validation Loss: 0.5221
	--> Epoch [60/100], Loss: 0.0698, Validation Loss: 0.5224
	--> Epoch [61/100], Loss: 0.0445, Validation Loss: 0.5177
	--> Epoch [62/100], Loss: 0.0245, Validation Loss: 0.5162
	--> Epoch [63/100], Loss: 0.2119, Validation Loss: 0.5160
	--> Epoch [64/100], Loss: 0.0420, Validation Loss: 0.5132
	--> Epoch [65/100], Loss: 0.1040, Validation Loss: 0.5107
	--> Epoch [66/100], Loss: 0.0251, Validation Loss: 0.5078
	--> Epoch [67/100], Loss: 0.0204, Validation Loss: 0.5050
	--> Epoch [68/100], Loss: 0.1423, Validation Loss: 0.5033
	--> Epoch [69/100], Loss: 0.0190, Validation Loss: 0.5015
	--> Epoch [70/100], Loss: 0.0878, Validation Loss: 0.4995
	--> Epoch [71/100], Loss: 0.0623, Validation Loss: 0.4977
	--> Epoch [72/100], Loss: 0.1267, Validation Loss: 0.4951
	--> Epoch [73/100], Loss: 0.1000, Validation Loss: 0.4905
	--> Epoch [74/100], Loss: 0.1038, Validation Loss: 0.4898
	--> Epoch [75/100], Loss: 0.0183, Validation Loss: 0.4888
	--> Epoch [76/100], Loss: 0.0185, Validation Loss: 0.4873
	--> Epoch [77/100], Loss: 0.0197, Validation Loss: 0.4840
	--> Epoch [78/100], Loss: 0.0701, Validation Loss: 0.4808
	--> Epoch [79/100], Loss: 0.1008, Validation Loss: 0.4782
	--> Epoch [80/100], Loss: 0.1627, Validation Loss: 0.4811
	--> Epoch [81/100], Loss: 0.0294, Validation Loss: 0.4778
	--> Epoch [82/100], Loss: 0.0574, Validation Loss: 0.4748
	--> Epoch [83/100], Loss: 0.0098, Validation Loss: 0.4722
	--> Epoch [84/100], Loss: 0.0160, Validation Loss: 0.4724
	--> Epoch [85/100], Loss: 0.2014, Validation Loss: 0.4710
	--> Epoch [86/100], Loss: 0.1049, Validation Loss: 0.4701
	--> Epoch [87/100], Loss: 0.0092, Validation Loss: 0.4675
	--> Epoch [88/100], Loss: 0.1125, Validation Loss: 0.4650
	--> Epoch [89/100], Loss: 0.1008, Validation Loss: 0.4645
	--> Epoch [90/100], Loss: 0.0765, Validation Loss: 0.4640
	--> Epoch [91/100], Loss: 0.1238, Validation Loss: 0.4631
	--> Epoch [92/100], Loss: 0.0594, Validation Loss: 0.4620
	--> Epoch [93/100], Loss: 0.0059, Validation Loss: 0.4603
	--> Epoch [94/100], Loss: 0.0645, Validation Loss: 0.4607
	--> Epoch [95/100], Loss: 0.0624, Validation Loss: 0.4595
	--> Epoch [96/100], Loss: 0.0927, Validation Loss: 0.4572
	--> Epoch [97/100], Loss: 0.1042, Validation Loss: 0.4572
	--> Epoch [98/100], Loss: 0.1450, Validation Loss: 0.4566
	--> Epoch [99/100], Loss: 0.1880, Validation Loss: 0.4537
	--> Epoch [100/100], Loss: 0.0107, Validation Loss: 0.4526
	--> Training for Fold 3 took 0.6054625511169434 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5232, Validation Loss: 0.8874
	--> Epoch [2/100], Loss: 0.5159, Validation Loss: 0.8769
	--> Epoch [3/100], Loss: 0.4648, Validation Loss: 0.8612
	--> Epoch [4/100], Loss: 0.6044, Validation Loss: 0.8520
	--> Epoch [5/100], Loss: 0.5193, Validation Loss: 0.8410
	--> Epoch [6/100], Loss: 0.4777, Validation Loss: 0.8321
	--> Epoch [7/100], Loss: 0.4958, Validation Loss: 0.8213
	--> Epoch [8/100], Loss: 0.4906, Validation Loss: 0.8170
	--> Epoch [9/100], Loss: 0.3993, Validation Loss: 0.8050
	--> Epoch [10/100], Loss: 0.3869, Validation Loss: 0.7990
	--> Epoch [11/100], Loss: 0.3772, Validation Loss: 0.7928
	--> Epoch [12/100], Loss: 0.4443, Validation Loss: 0.7839
	--> Epoch [13/100], Loss: 0.3605, Validation Loss: 0.7717
	--> Epoch [14/100], Loss: 0.4022, Validation Loss: 0.7629
	--> Epoch [15/100], Loss: 0.3103, Validation Loss: 0.7533
	--> Epoch [16/100], Loss: 0.3392, Validation Loss: 0.7412
	--> Epoch [17/100], Loss: 0.2675, Validation Loss: 0.7318
	--> Epoch [18/100], Loss: 0.3201, Validation Loss: 0.7246
	--> Epoch [19/100], Loss: 0.3105, Validation Loss: 0.7165
	--> Epoch [20/100], Loss: 0.3288, Validation Loss: 0.7083
	--> Epoch [21/100], Loss: 0.3145, Validation Loss: 0.7003
	--> Epoch [22/100], Loss: 0.4174, Validation Loss: 0.6935
	--> Epoch [23/100], Loss: 0.3920, Validation Loss: 0.6869
	--> Epoch [24/100], Loss: 0.2234, Validation Loss: 0.6753
	--> Epoch [25/100], Loss: 0.2684, Validation Loss: 0.6681
	--> Epoch [26/100], Loss: 0.1784, Validation Loss: 0.6575
	--> Epoch [27/100], Loss: 0.2635, Validation Loss: 0.6452
	--> Epoch [28/100], Loss: 0.1595, Validation Loss: 0.6352
	--> Epoch [29/100], Loss: 0.2232, Validation Loss: 0.6282
	--> Epoch [30/100], Loss: 0.2650, Validation Loss: 0.6213
	--> Epoch [31/100], Loss: 0.2727, Validation Loss: 0.6210
	--> Epoch [32/100], Loss: 0.1991, Validation Loss: 0.6134
	--> Epoch [33/100], Loss: 0.2573, Validation Loss: 0.6081
	--> Epoch [34/100], Loss: 0.1509, Validation Loss: 0.5994
	--> Epoch [35/100], Loss: 0.2185, Validation Loss: 0.5844
	--> Epoch [36/100], Loss: 0.2990, Validation Loss: 0.5768
	--> Epoch [37/100], Loss: 0.2717, Validation Loss: 0.5753
	--> Epoch [38/100], Loss: 0.1045, Validation Loss: 0.5645
	--> Epoch [39/100], Loss: 0.2241, Validation Loss: 0.5565
	--> Epoch [40/100], Loss: 0.3025, Validation Loss: 0.5486
	--> Epoch [41/100], Loss: 0.1699, Validation Loss: 0.5416
	--> Epoch [42/100], Loss: 0.1923, Validation Loss: 0.5354
	--> Epoch [43/100], Loss: 0.1945, Validation Loss: 0.5334
	--> Epoch [44/100], Loss: 0.2576, Validation Loss: 0.5256
	--> Epoch [45/100], Loss: 0.1866, Validation Loss: 0.5197
	--> Epoch [46/100], Loss: 0.3008, Validation Loss: 0.5140
	--> Epoch [47/100], Loss: 0.1998, Validation Loss: 0.5080
	--> Epoch [48/100], Loss: 0.0702, Validation Loss: 0.5010
	--> Epoch [49/100], Loss: 0.2033, Validation Loss: 0.4950
	--> Epoch [50/100], Loss: 0.1836, Validation Loss: 0.4908
	--> Epoch [51/100], Loss: 0.2691, Validation Loss: 0.4892
	--> Epoch [52/100], Loss: 0.1679, Validation Loss: 0.4896
	--> Epoch [53/100], Loss: 0.1155, Validation Loss: 0.4885
	--> Epoch [54/100], Loss: 0.2062, Validation Loss: 0.4855
	--> Epoch [55/100], Loss: 0.0416, Validation Loss: 0.4790
	--> Epoch [56/100], Loss: 0.0717, Validation Loss: 0.4735
	--> Epoch [57/100], Loss: 0.1122, Validation Loss: 0.4695
	--> Epoch [58/100], Loss: 0.1117, Validation Loss: 0.4657
	--> Epoch [59/100], Loss: 0.1150, Validation Loss: 0.4613
	--> Epoch [60/100], Loss: 0.1886, Validation Loss: 0.4609
	--> Epoch [61/100], Loss: 0.1061, Validation Loss: 0.4558
	--> Epoch [62/100], Loss: 0.1880, Validation Loss: 0.4506
	--> Epoch [63/100], Loss: 0.1316, Validation Loss: 0.4443
	--> Epoch [64/100], Loss: 0.1105, Validation Loss: 0.4428
	--> Epoch [65/100], Loss: 0.0597, Validation Loss: 0.4514
	--> Epoch [66/100], Loss: 0.0958, Validation Loss: 0.4512
	--> Epoch [67/100], Loss: 0.1030, Validation Loss: 0.4499
Early stopping
	--> Training for Fold 4 took 0.4207768440246582 sec, using 67 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6907, Validation Loss: 0.7039
	--> Epoch [2/100], Loss: 0.6452, Validation Loss: 0.6992
	--> Epoch [3/100], Loss: 0.6716, Validation Loss: 0.6959
	--> Epoch [4/100], Loss: 0.6561, Validation Loss: 0.6936
	--> Epoch [5/100], Loss: 0.5694, Validation Loss: 0.6891
	--> Epoch [6/100], Loss: 0.5356, Validation Loss: 0.6883
	--> Epoch [7/100], Loss: 0.5926, Validation Loss: 0.6847
	--> Epoch [8/100], Loss: 0.4833, Validation Loss: 0.6826
	--> Epoch [9/100], Loss: 0.5409, Validation Loss: 0.6787
	--> Epoch [10/100], Loss: 0.4175, Validation Loss: 0.6776
	--> Epoch [11/100], Loss: 0.5726, Validation Loss: 0.6753
	--> Epoch [12/100], Loss: 0.3839, Validation Loss: 0.6738
	--> Epoch [13/100], Loss: 0.3854, Validation Loss: 0.6713
	--> Epoch [14/100], Loss: 0.3635, Validation Loss: 0.6709
	--> Epoch [15/100], Loss: 0.4166, Validation Loss: 0.6694
	--> Epoch [16/100], Loss: 0.3671, Validation Loss: 0.6696
	--> Epoch [17/100], Loss: 0.3709, Validation Loss: 0.6670
	--> Epoch [18/100], Loss: 0.3076, Validation Loss: 0.6657
	--> Epoch [19/100], Loss: 0.3146, Validation Loss: 0.6665
	--> Epoch [20/100], Loss: 0.3753, Validation Loss: 0.6652
	--> Epoch [21/100], Loss: 0.3206, Validation Loss: 0.6633
	--> Epoch [22/100], Loss: 0.2861, Validation Loss: 0.6635
	--> Epoch [23/100], Loss: 0.2702, Validation Loss: 0.6649
	--> Epoch [24/100], Loss: 0.3245, Validation Loss: 0.6624
	--> Epoch [25/100], Loss: 0.3366, Validation Loss: 0.6615
	--> Epoch [26/100], Loss: 0.2581, Validation Loss: 0.6612
	--> Epoch [27/100], Loss: 0.1977, Validation Loss: 0.6587
	--> Epoch [28/100], Loss: 0.2053, Validation Loss: 0.6579
	--> Epoch [29/100], Loss: 0.2156, Validation Loss: 0.6574
	--> Epoch [30/100], Loss: 0.2379, Validation Loss: 0.6563
	--> Epoch [31/100], Loss: 0.2012, Validation Loss: 0.6550
	--> Epoch [32/100], Loss: 0.1851, Validation Loss: 0.6553
	--> Epoch [33/100], Loss: 0.2363, Validation Loss: 0.6540
	--> Epoch [34/100], Loss: 0.2530, Validation Loss: 0.6540
	--> Epoch [35/100], Loss: 0.1574, Validation Loss: 0.6543
	--> Epoch [36/100], Loss: 0.1336, Validation Loss: 0.6531
	--> Epoch [37/100], Loss: 0.1193, Validation Loss: 0.6515
	--> Epoch [38/100], Loss: 0.1614, Validation Loss: 0.6513
	--> Epoch [39/100], Loss: 0.1174, Validation Loss: 0.6507
	--> Epoch [40/100], Loss: 0.1961, Validation Loss: 0.6495
	--> Epoch [41/100], Loss: 0.2054, Validation Loss: 0.6482
	--> Epoch [42/100], Loss: 0.2146, Validation Loss: 0.6482
	--> Epoch [43/100], Loss: 0.1101, Validation Loss: 0.6475
	--> Epoch [44/100], Loss: 0.1496, Validation Loss: 0.6473
	--> Epoch [45/100], Loss: 0.2642, Validation Loss: 0.6487
	--> Epoch [46/100], Loss: 0.1844, Validation Loss: 0.6504
	--> Epoch [47/100], Loss: 0.1210, Validation Loss: 0.6528
Early stopping
	--> Training for Fold 5 took 0.29152369499206543 sec, using 47 epochs

Median number of epochs used: 92 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/92], Loss: 0.7057
	--> Final training Epoch [2/92], Loss: 0.6743
	--> Final training Epoch [3/92], Loss: 0.6449
	--> Final training Epoch [4/92], Loss: 0.6751
	--> Final training Epoch [5/92], Loss: 0.6272
	--> Final training Epoch [6/92], Loss: 0.5745
	--> Final training Epoch [7/92], Loss: 0.6254
	--> Final training Epoch [8/92], Loss: 0.5788
	--> Final training Epoch [9/92], Loss: 0.5679
	--> Final training Epoch [10/92], Loss: 0.5775
	--> Final training Epoch [11/92], Loss: 0.5034
	--> Final training Epoch [12/92], Loss: 0.5307
	--> Final training Epoch [13/92], Loss: 0.4914
	--> Final training Epoch [14/92], Loss: 0.4916
	--> Final training Epoch [15/92], Loss: 0.4512
	--> Final training Epoch [16/92], Loss: 0.4397
	--> Final training Epoch [17/92], Loss: 0.4293
	--> Final training Epoch [18/92], Loss: 0.4551
	--> Final training Epoch [19/92], Loss: 0.5219
	--> Final training Epoch [20/92], Loss: 0.4244
	--> Final training Epoch [21/92], Loss: 0.4308
	--> Final training Epoch [22/92], Loss: 0.3912
	--> Final training Epoch [23/92], Loss: 0.4149
	--> Final training Epoch [24/92], Loss: 0.3474
	--> Final training Epoch [25/92], Loss: 0.3216
	--> Final training Epoch [26/92], Loss: 0.3328
	--> Final training Epoch [27/92], Loss: 0.3299
	--> Final training Epoch [28/92], Loss: 0.3200
	--> Final training Epoch [29/92], Loss: 0.3254
	--> Final training Epoch [30/92], Loss: 0.2877
	--> Final training Epoch [31/92], Loss: 0.2768
	--> Final training Epoch [32/92], Loss: 0.2989
	--> Final training Epoch [33/92], Loss: 0.2573
	--> Final training Epoch [34/92], Loss: 0.1950
	--> Final training Epoch [35/92], Loss: 0.2962
	--> Final training Epoch [36/92], Loss: 0.2918
	--> Final training Epoch [37/92], Loss: 0.2660
	--> Final training Epoch [38/92], Loss: 0.3203
	--> Final training Epoch [39/92], Loss: 0.2752
	--> Final training Epoch [40/92], Loss: 0.2065
	--> Final training Epoch [41/92], Loss: 0.2503
	--> Final training Epoch [42/92], Loss: 0.2838
	--> Final training Epoch [43/92], Loss: 0.1849
	--> Final training Epoch [44/92], Loss: 0.2102
	--> Final training Epoch [45/92], Loss: 0.2533
	--> Final training Epoch [46/92], Loss: 0.2128
	--> Final training Epoch [47/92], Loss: 0.2069
	--> Final training Epoch [48/92], Loss: 0.1782
	--> Final training Epoch [49/92], Loss: 0.2115
	--> Final training Epoch [50/92], Loss: 0.2241
	--> Final training Epoch [51/92], Loss: 0.1954
	--> Final training Epoch [52/92], Loss: 0.1516
	--> Final training Epoch [53/92], Loss: 0.2127
	--> Final training Epoch [54/92], Loss: 0.1566
	--> Final training Epoch [55/92], Loss: 0.1827
	--> Final training Epoch [56/92], Loss: 0.1621
	--> Final training Epoch [57/92], Loss: 0.2315
	--> Final training Epoch [58/92], Loss: 0.1498
	--> Final training Epoch [59/92], Loss: 0.1667
	--> Final training Epoch [60/92], Loss: 0.1828
	--> Final training Epoch [61/92], Loss: 0.1630
	--> Final training Epoch [62/92], Loss: 0.2064
	--> Final training Epoch [63/92], Loss: 0.1399
	--> Final training Epoch [64/92], Loss: 0.2342
	--> Final training Epoch [65/92], Loss: 0.1542
	--> Final training Epoch [66/92], Loss: 0.1887
	--> Final training Epoch [67/92], Loss: 0.1319
	--> Final training Epoch [68/92], Loss: 0.1965
	--> Final training Epoch [69/92], Loss: 0.1106
	--> Final training Epoch [70/92], Loss: 0.2184
	--> Final training Epoch [71/92], Loss: 0.1549
	--> Final training Epoch [72/92], Loss: 0.1163
	--> Final training Epoch [73/92], Loss: 0.0674
	--> Final training Epoch [74/92], Loss: 0.1617
	--> Final training Epoch [75/92], Loss: 0.0880
	--> Final training Epoch [76/92], Loss: 0.1509
	--> Final training Epoch [77/92], Loss: 0.2253
	--> Final training Epoch [78/92], Loss: 0.1349
	--> Final training Epoch [79/92], Loss: 0.1571
	--> Final training Epoch [80/92], Loss: 0.1572
	--> Final training Epoch [81/92], Loss: 0.1453
	--> Final training Epoch [82/92], Loss: 0.1472
	--> Final training Epoch [83/92], Loss: 0.1528
	--> Final training Epoch [84/92], Loss: 0.1072
	--> Final training Epoch [85/92], Loss: 0.0831
	--> Final training Epoch [86/92], Loss: 0.1321
	--> Final training Epoch [87/92], Loss: 0.1354
	--> Final training Epoch [88/92], Loss: 0.1084
	--> Final training Epoch [89/92], Loss: 0.0923
	--> Final training Epoch [90/92], Loss: 0.1262
	--> Final training Epoch [91/92], Loss: 0.1305
	--> Final training Epoch [92/92], Loss: 0.1953

Final training took 0.5292024612426758 sec

TESTING
	--> Testing took 0.0094 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8327
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3482,  Current Best Accuracy: 0.8807,  Current Best Validation Loss: 0.3482

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6349, Validation Loss: 0.6611
	--> Epoch [2/100], Loss: 0.6515, Validation Loss: 0.6516
	--> Epoch [3/100], Loss: 0.6385, Validation Loss: 0.6396
	--> Epoch [4/100], Loss: 0.6374, Validation Loss: 0.6313
	--> Epoch [5/100], Loss: 0.5755, Validation Loss: 0.6247
	--> Epoch [6/100], Loss: 0.5559, Validation Loss: 0.6149
	--> Epoch [7/100], Loss: 0.5674, Validation Loss: 0.6071
	--> Epoch [8/100], Loss: 0.5171, Validation Loss: 0.5996
	--> Epoch [9/100], Loss: 0.5355, Validation Loss: 0.5906
	--> Epoch [10/100], Loss: 0.4743, Validation Loss: 0.5817
	--> Epoch [11/100], Loss: 0.5663, Validation Loss: 0.5755
	--> Epoch [12/100], Loss: 0.4697, Validation Loss: 0.5675
	--> Epoch [13/100], Loss: 0.4550, Validation Loss: 0.5603
	--> Epoch [14/100], Loss: 0.4419, Validation Loss: 0.5504
	--> Epoch [15/100], Loss: 0.5051, Validation Loss: 0.5450
	--> Epoch [16/100], Loss: 0.4199, Validation Loss: 0.5348
	--> Epoch [17/100], Loss: 0.4193, Validation Loss: 0.5270
	--> Epoch [18/100], Loss: 0.3150, Validation Loss: 0.5178
	--> Epoch [19/100], Loss: 0.3790, Validation Loss: 0.5106
	--> Epoch [20/100], Loss: 0.4727, Validation Loss: 0.5023
	--> Epoch [21/100], Loss: 0.3043, Validation Loss: 0.4924
	--> Epoch [22/100], Loss: 0.3818, Validation Loss: 0.4860
	--> Epoch [23/100], Loss: 0.2670, Validation Loss: 0.4789
	--> Epoch [24/100], Loss: 0.3182, Validation Loss: 0.4727
	--> Epoch [25/100], Loss: 0.2706, Validation Loss: 0.4658
	--> Epoch [26/100], Loss: 0.2883, Validation Loss: 0.4594
	--> Epoch [27/100], Loss: 0.3479, Validation Loss: 0.4528
	--> Epoch [28/100], Loss: 0.3169, Validation Loss: 0.4446
	--> Epoch [29/100], Loss: 0.2689, Validation Loss: 0.4398
	--> Epoch [30/100], Loss: 0.2604, Validation Loss: 0.4329
	--> Epoch [31/100], Loss: 0.2677, Validation Loss: 0.4276
	--> Epoch [32/100], Loss: 0.2280, Validation Loss: 0.4229
	--> Epoch [33/100], Loss: 0.2097, Validation Loss: 0.4203
	--> Epoch [34/100], Loss: 0.1998, Validation Loss: 0.4151
	--> Epoch [35/100], Loss: 0.1895, Validation Loss: 0.4096
	--> Epoch [36/100], Loss: 0.2476, Validation Loss: 0.4024
	--> Epoch [37/100], Loss: 0.2718, Validation Loss: 0.3992
	--> Epoch [38/100], Loss: 0.2025, Validation Loss: 0.3956
	--> Epoch [39/100], Loss: 0.2155, Validation Loss: 0.3911
	--> Epoch [40/100], Loss: 0.1144, Validation Loss: 0.3861
	--> Epoch [41/100], Loss: 0.2355, Validation Loss: 0.3830
	--> Epoch [42/100], Loss: 0.2630, Validation Loss: 0.3786
	--> Epoch [43/100], Loss: 0.2840, Validation Loss: 0.3746
	--> Epoch [44/100], Loss: 0.1583, Validation Loss: 0.3714
	--> Epoch [45/100], Loss: 0.3061, Validation Loss: 0.3688
	--> Epoch [46/100], Loss: 0.1417, Validation Loss: 0.3661
	--> Epoch [47/100], Loss: 0.1916, Validation Loss: 0.3636
	--> Epoch [48/100], Loss: 0.0418, Validation Loss: 0.3608
	--> Epoch [49/100], Loss: 0.1680, Validation Loss: 0.3586
	--> Epoch [50/100], Loss: 0.1940, Validation Loss: 0.3557
	--> Epoch [51/100], Loss: 0.2168, Validation Loss: 0.3538
	--> Epoch [52/100], Loss: 0.2036, Validation Loss: 0.3514
	--> Epoch [53/100], Loss: 0.2650, Validation Loss: 0.3501
	--> Epoch [54/100], Loss: 0.0829, Validation Loss: 0.3486
	--> Epoch [55/100], Loss: 0.1179, Validation Loss: 0.3463
	--> Epoch [56/100], Loss: 0.1092, Validation Loss: 0.3450
	--> Epoch [57/100], Loss: 0.1186, Validation Loss: 0.3436
	--> Epoch [58/100], Loss: 0.1325, Validation Loss: 0.3412
	--> Epoch [59/100], Loss: 0.0704, Validation Loss: 0.3393
	--> Epoch [60/100], Loss: 0.1226, Validation Loss: 0.3374
	--> Epoch [61/100], Loss: 0.0402, Validation Loss: 0.3358
	--> Epoch [62/100], Loss: 0.1535, Validation Loss: 0.3342
	--> Epoch [63/100], Loss: 0.0572, Validation Loss: 0.3328
	--> Epoch [64/100], Loss: 0.1757, Validation Loss: 0.3314
	--> Epoch [65/100], Loss: 0.2953, Validation Loss: 0.3309
	--> Epoch [66/100], Loss: 0.0374, Validation Loss: 0.3286
	--> Epoch [67/100], Loss: 0.2017, Validation Loss: 0.3280
	--> Epoch [68/100], Loss: 0.1443, Validation Loss: 0.3268
	--> Epoch [69/100], Loss: 0.0967, Validation Loss: 0.3261
	--> Epoch [70/100], Loss: 0.1467, Validation Loss: 0.3252
	--> Epoch [71/100], Loss: 0.2389, Validation Loss: 0.3237
	--> Epoch [72/100], Loss: 0.2282, Validation Loss: 0.3238
	--> Epoch [73/100], Loss: 0.0425, Validation Loss: 0.3226
	--> Epoch [74/100], Loss: 0.1480, Validation Loss: 0.3214
	--> Epoch [75/100], Loss: 0.1793, Validation Loss: 0.3205
	--> Epoch [76/100], Loss: 0.1061, Validation Loss: 0.3189
	--> Epoch [77/100], Loss: 0.0964, Validation Loss: 0.3173
	--> Epoch [78/100], Loss: 0.2627, Validation Loss: 0.3169
	--> Epoch [79/100], Loss: 0.0120, Validation Loss: 0.3168
	--> Epoch [80/100], Loss: 0.1509, Validation Loss: 0.3158
	--> Epoch [81/100], Loss: 0.0511, Validation Loss: 0.3164
	--> Epoch [82/100], Loss: 0.0644, Validation Loss: 0.3145
	--> Epoch [83/100], Loss: 0.1272, Validation Loss: 0.3146
	--> Epoch [84/100], Loss: 0.0349, Validation Loss: 0.3141
	--> Epoch [85/100], Loss: 0.0569, Validation Loss: 0.3138
	--> Epoch [86/100], Loss: 0.2037, Validation Loss: 0.3129
	--> Epoch [87/100], Loss: 0.0948, Validation Loss: 0.3131
	--> Epoch [88/100], Loss: 0.0982, Validation Loss: 0.3120
	--> Epoch [89/100], Loss: 0.0912, Validation Loss: 0.3108
	--> Epoch [90/100], Loss: 0.1380, Validation Loss: 0.3107
	--> Epoch [91/100], Loss: 0.0851, Validation Loss: 0.3105
	--> Epoch [92/100], Loss: 0.1953, Validation Loss: 0.3102
	--> Epoch [93/100], Loss: 0.1429, Validation Loss: 0.3096
	--> Epoch [94/100], Loss: 0.1858, Validation Loss: 0.3095
	--> Epoch [95/100], Loss: 0.0270, Validation Loss: 0.3090
	--> Epoch [96/100], Loss: 0.2302, Validation Loss: 0.3082
	--> Epoch [97/100], Loss: 0.1453, Validation Loss: 0.3073
	--> Epoch [98/100], Loss: 0.0850, Validation Loss: 0.3080
	--> Epoch [99/100], Loss: 0.0309, Validation Loss: 0.3068
	--> Epoch [100/100], Loss: 0.0954, Validation Loss: 0.3067
	--> Training for Fold 1 took 0.6177010536193848 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7525, Validation Loss: 0.6021
	--> Epoch [2/100], Loss: 0.7045, Validation Loss: 0.5838
	--> Epoch [3/100], Loss: 0.5960, Validation Loss: 0.5682
	--> Epoch [4/100], Loss: 0.5581, Validation Loss: 0.5497
	--> Epoch [5/100], Loss: 0.5931, Validation Loss: 0.5363
	--> Epoch [6/100], Loss: 0.5478, Validation Loss: 0.5240
	--> Epoch [7/100], Loss: 0.4684, Validation Loss: 0.5170
	--> Epoch [8/100], Loss: 0.4841, Validation Loss: 0.5077
	--> Epoch [9/100], Loss: 0.3904, Validation Loss: 0.4955
	--> Epoch [10/100], Loss: 0.4176, Validation Loss: 0.4844
	--> Epoch [11/100], Loss: 0.5003, Validation Loss: 0.4740
	--> Epoch [12/100], Loss: 0.4315, Validation Loss: 0.4661
	--> Epoch [13/100], Loss: 0.3507, Validation Loss: 0.4549
	--> Epoch [14/100], Loss: 0.3521, Validation Loss: 0.4462
	--> Epoch [15/100], Loss: 0.3482, Validation Loss: 0.4383
	--> Epoch [16/100], Loss: 0.2420, Validation Loss: 0.4303
	--> Epoch [17/100], Loss: 0.2827, Validation Loss: 0.4213
	--> Epoch [18/100], Loss: 0.3596, Validation Loss: 0.4167
	--> Epoch [19/100], Loss: 0.3480, Validation Loss: 0.4100
	--> Epoch [20/100], Loss: 0.2592, Validation Loss: 0.4071
	--> Epoch [21/100], Loss: 0.2951, Validation Loss: 0.4009
	--> Epoch [22/100], Loss: 0.2722, Validation Loss: 0.3940
	--> Epoch [23/100], Loss: 0.2289, Validation Loss: 0.3867
	--> Epoch [24/100], Loss: 0.1647, Validation Loss: 0.3803
	--> Epoch [25/100], Loss: 0.4245, Validation Loss: 0.3733
	--> Epoch [26/100], Loss: 0.3070, Validation Loss: 0.3675
	--> Epoch [27/100], Loss: 0.2582, Validation Loss: 0.3648
	--> Epoch [28/100], Loss: 0.1626, Validation Loss: 0.3606
	--> Epoch [29/100], Loss: 0.2305, Validation Loss: 0.3572
	--> Epoch [30/100], Loss: 0.2096, Validation Loss: 0.3521
	--> Epoch [31/100], Loss: 0.2340, Validation Loss: 0.3464
	--> Epoch [32/100], Loss: 0.1826, Validation Loss: 0.3436
	--> Epoch [33/100], Loss: 0.2617, Validation Loss: 0.3383
	--> Epoch [34/100], Loss: 0.1616, Validation Loss: 0.3332
	--> Epoch [35/100], Loss: 0.1211, Validation Loss: 0.3301
	--> Epoch [36/100], Loss: 0.1393, Validation Loss: 0.3248
	--> Epoch [37/100], Loss: 0.0754, Validation Loss: 0.3196
	--> Epoch [38/100], Loss: 0.2601, Validation Loss: 0.3152
	--> Epoch [39/100], Loss: 0.1376, Validation Loss: 0.3113
	--> Epoch [40/100], Loss: 0.1700, Validation Loss: 0.3089
	--> Epoch [41/100], Loss: 0.1212, Validation Loss: 0.3070
	--> Epoch [42/100], Loss: 0.1817, Validation Loss: 0.3031
	--> Epoch [43/100], Loss: 0.1348, Validation Loss: 0.3000
	--> Epoch [44/100], Loss: 0.0428, Validation Loss: 0.2967
	--> Epoch [45/100], Loss: 0.1874, Validation Loss: 0.2933
	--> Epoch [46/100], Loss: 0.0875, Validation Loss: 0.2916
	--> Epoch [47/100], Loss: 0.1295, Validation Loss: 0.2871
	--> Epoch [48/100], Loss: 0.2143, Validation Loss: 0.2851
	--> Epoch [49/100], Loss: 0.1793, Validation Loss: 0.2854
	--> Epoch [50/100], Loss: 0.1237, Validation Loss: 0.2800
	--> Epoch [51/100], Loss: 0.1128, Validation Loss: 0.2769
	--> Epoch [52/100], Loss: 0.1130, Validation Loss: 0.2738
	--> Epoch [53/100], Loss: 0.1240, Validation Loss: 0.2722
	--> Epoch [54/100], Loss: 0.1275, Validation Loss: 0.2695
	--> Epoch [55/100], Loss: 0.2016, Validation Loss: 0.2688
	--> Epoch [56/100], Loss: 0.0433, Validation Loss: 0.2664
	--> Epoch [57/100], Loss: 0.1108, Validation Loss: 0.2643
	--> Epoch [58/100], Loss: 0.2422, Validation Loss: 0.2636
	--> Epoch [59/100], Loss: 0.0978, Validation Loss: 0.2610
	--> Epoch [60/100], Loss: 0.1483, Validation Loss: 0.2598
	--> Epoch [61/100], Loss: 0.0694, Validation Loss: 0.2579
	--> Epoch [62/100], Loss: 0.0611, Validation Loss: 0.2575
	--> Epoch [63/100], Loss: 0.1583, Validation Loss: 0.2555
	--> Epoch [64/100], Loss: 0.1100, Validation Loss: 0.2554
	--> Epoch [65/100], Loss: 0.1642, Validation Loss: 0.2544
	--> Epoch [66/100], Loss: 0.0462, Validation Loss: 0.2530
	--> Epoch [67/100], Loss: 0.1398, Validation Loss: 0.2504
	--> Epoch [68/100], Loss: 0.1457, Validation Loss: 0.2503
	--> Epoch [69/100], Loss: 0.0310, Validation Loss: 0.2483
	--> Epoch [70/100], Loss: 0.0426, Validation Loss: 0.2464
	--> Epoch [71/100], Loss: 0.0240, Validation Loss: 0.2455
	--> Epoch [72/100], Loss: 0.0314, Validation Loss: 0.2439
	--> Epoch [73/100], Loss: 0.1686, Validation Loss: 0.2443
	--> Epoch [74/100], Loss: 0.0602, Validation Loss: 0.2443
	--> Epoch [75/100], Loss: 0.2913, Validation Loss: 0.2436
	--> Epoch [76/100], Loss: 0.0901, Validation Loss: 0.2414
	--> Epoch [77/100], Loss: 0.0481, Validation Loss: 0.2405
	--> Epoch [78/100], Loss: 0.0234, Validation Loss: 0.2394
	--> Epoch [79/100], Loss: 0.1416, Validation Loss: 0.2381
	--> Epoch [80/100], Loss: 0.1076, Validation Loss: 0.2367
	--> Epoch [81/100], Loss: 0.2940, Validation Loss: 0.2354
	--> Epoch [82/100], Loss: 0.1089, Validation Loss: 0.2348
	--> Epoch [83/100], Loss: 0.1758, Validation Loss: 0.2336
	--> Epoch [84/100], Loss: 0.1003, Validation Loss: 0.2326
	--> Epoch [85/100], Loss: 0.1460, Validation Loss: 0.2306
	--> Epoch [86/100], Loss: 0.0223, Validation Loss: 0.2302
	--> Epoch [87/100], Loss: 0.0170, Validation Loss: 0.2302
	--> Epoch [88/100], Loss: 0.0938, Validation Loss: 0.2285
	--> Epoch [89/100], Loss: 0.1677, Validation Loss: 0.2266
	--> Epoch [90/100], Loss: 0.0827, Validation Loss: 0.2258
	--> Epoch [91/100], Loss: 0.0921, Validation Loss: 0.2253
	--> Epoch [92/100], Loss: 0.0860, Validation Loss: 0.2237
	--> Epoch [93/100], Loss: 0.0843, Validation Loss: 0.2224
	--> Epoch [94/100], Loss: 0.0241, Validation Loss: 0.2218
	--> Epoch [95/100], Loss: 0.0779, Validation Loss: 0.2208
	--> Epoch [96/100], Loss: 0.0382, Validation Loss: 0.2207
	--> Epoch [97/100], Loss: 0.0048, Validation Loss: 0.2203
	--> Epoch [98/100], Loss: 0.0252, Validation Loss: 0.2193
	--> Epoch [99/100], Loss: 0.0931, Validation Loss: 0.2187
	--> Epoch [100/100], Loss: 0.1591, Validation Loss: 0.2179
	--> Training for Fold 2 took 0.6179943084716797 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8730, Validation Loss: 0.6879
	--> Epoch [2/100], Loss: 0.7713, Validation Loss: 0.6753
	--> Epoch [3/100], Loss: 0.7462, Validation Loss: 0.6635
	--> Epoch [4/100], Loss: 0.7122, Validation Loss: 0.6555
	--> Epoch [5/100], Loss: 0.6715, Validation Loss: 0.6501
	--> Epoch [6/100], Loss: 0.7334, Validation Loss: 0.6423
	--> Epoch [7/100], Loss: 0.6385, Validation Loss: 0.6352
	--> Epoch [8/100], Loss: 0.6115, Validation Loss: 0.6282
	--> Epoch [9/100], Loss: 0.6464, Validation Loss: 0.6221
	--> Epoch [10/100], Loss: 0.5493, Validation Loss: 0.6139
	--> Epoch [11/100], Loss: 0.4654, Validation Loss: 0.6087
	--> Epoch [12/100], Loss: 0.5208, Validation Loss: 0.6037
	--> Epoch [13/100], Loss: 0.5479, Validation Loss: 0.5994
	--> Epoch [14/100], Loss: 0.5578, Validation Loss: 0.5951
	--> Epoch [15/100], Loss: 0.5172, Validation Loss: 0.5860
	--> Epoch [16/100], Loss: 0.4423, Validation Loss: 0.5797
	--> Epoch [17/100], Loss: 0.4325, Validation Loss: 0.5750
	--> Epoch [18/100], Loss: 0.4364, Validation Loss: 0.5688
	--> Epoch [19/100], Loss: 0.4954, Validation Loss: 0.5644
	--> Epoch [20/100], Loss: 0.5073, Validation Loss: 0.5615
	--> Epoch [21/100], Loss: 0.4476, Validation Loss: 0.5562
	--> Epoch [22/100], Loss: 0.3448, Validation Loss: 0.5498
	--> Epoch [23/100], Loss: 0.3737, Validation Loss: 0.5442
	--> Epoch [24/100], Loss: 0.4206, Validation Loss: 0.5388
	--> Epoch [25/100], Loss: 0.4696, Validation Loss: 0.5343
	--> Epoch [26/100], Loss: 0.3764, Validation Loss: 0.5311
	--> Epoch [27/100], Loss: 0.2958, Validation Loss: 0.5279
	--> Epoch [28/100], Loss: 0.1988, Validation Loss: 0.5227
	--> Epoch [29/100], Loss: 0.3068, Validation Loss: 0.5176
	--> Epoch [30/100], Loss: 0.2249, Validation Loss: 0.5136
	--> Epoch [31/100], Loss: 0.2887, Validation Loss: 0.5085
	--> Epoch [32/100], Loss: 0.3524, Validation Loss: 0.5041
	--> Epoch [33/100], Loss: 0.3172, Validation Loss: 0.5018
	--> Epoch [34/100], Loss: 0.2046, Validation Loss: 0.4962
	--> Epoch [35/100], Loss: 0.1772, Validation Loss: 0.4932
	--> Epoch [36/100], Loss: 0.2018, Validation Loss: 0.4896
	--> Epoch [37/100], Loss: 0.2399, Validation Loss: 0.4866
	--> Epoch [38/100], Loss: 0.1913, Validation Loss: 0.4816
	--> Epoch [39/100], Loss: 0.1462, Validation Loss: 0.4782
	--> Epoch [40/100], Loss: 0.3254, Validation Loss: 0.4748
	--> Epoch [41/100], Loss: 0.2774, Validation Loss: 0.4712
	--> Epoch [42/100], Loss: 0.1808, Validation Loss: 0.4684
	--> Epoch [43/100], Loss: 0.2209, Validation Loss: 0.4645
	--> Epoch [44/100], Loss: 0.1856, Validation Loss: 0.4612
	--> Epoch [45/100], Loss: 0.1370, Validation Loss: 0.4572
	--> Epoch [46/100], Loss: 0.2154, Validation Loss: 0.4544
	--> Epoch [47/100], Loss: 0.0823, Validation Loss: 0.4503
	--> Epoch [48/100], Loss: 0.0879, Validation Loss: 0.4478
	--> Epoch [49/100], Loss: 0.2484, Validation Loss: 0.4461
	--> Epoch [50/100], Loss: 0.2159, Validation Loss: 0.4435
	--> Epoch [51/100], Loss: 0.1406, Validation Loss: 0.4408
	--> Epoch [52/100], Loss: 0.2197, Validation Loss: 0.4369
	--> Epoch [53/100], Loss: 0.2760, Validation Loss: 0.4338
	--> Epoch [54/100], Loss: 0.1222, Validation Loss: 0.4317
	--> Epoch [55/100], Loss: 0.1848, Validation Loss: 0.4284
	--> Epoch [56/100], Loss: 0.1223, Validation Loss: 0.4257
	--> Epoch [57/100], Loss: 0.2704, Validation Loss: 0.4241
	--> Epoch [58/100], Loss: 0.2042, Validation Loss: 0.4232
	--> Epoch [59/100], Loss: 0.0603, Validation Loss: 0.4212
	--> Epoch [60/100], Loss: 0.1092, Validation Loss: 0.4181
	--> Epoch [61/100], Loss: 0.2395, Validation Loss: 0.4164
	--> Epoch [62/100], Loss: 0.1777, Validation Loss: 0.4140
	--> Epoch [63/100], Loss: 0.2045, Validation Loss: 0.4130
	--> Epoch [64/100], Loss: 0.1874, Validation Loss: 0.4111
	--> Epoch [65/100], Loss: 0.1207, Validation Loss: 0.4093
	--> Epoch [66/100], Loss: 0.2484, Validation Loss: 0.4067
	--> Epoch [67/100], Loss: 0.1595, Validation Loss: 0.4060
	--> Epoch [68/100], Loss: 0.1882, Validation Loss: 0.4054
	--> Epoch [69/100], Loss: 0.1820, Validation Loss: 0.4028
	--> Epoch [70/100], Loss: 0.2592, Validation Loss: 0.3994
	--> Epoch [71/100], Loss: 0.1327, Validation Loss: 0.3978
	--> Epoch [72/100], Loss: 0.0362, Validation Loss: 0.3949
	--> Epoch [73/100], Loss: 0.2367, Validation Loss: 0.3927
	--> Epoch [74/100], Loss: 0.1101, Validation Loss: 0.3908
	--> Epoch [75/100], Loss: 0.1931, Validation Loss: 0.3894
	--> Epoch [76/100], Loss: 0.2393, Validation Loss: 0.3829
	--> Epoch [77/100], Loss: 0.1148, Validation Loss: 0.3816
	--> Epoch [78/100], Loss: 0.2404, Validation Loss: 0.3791
	--> Epoch [79/100], Loss: 0.3883, Validation Loss: 0.3783
	--> Epoch [80/100], Loss: 0.1727, Validation Loss: 0.3769
	--> Epoch [81/100], Loss: 0.2315, Validation Loss: 0.3755
	--> Epoch [82/100], Loss: 0.1456, Validation Loss: 0.3738
	--> Epoch [83/100], Loss: 0.0510, Validation Loss: 0.3725
	--> Epoch [84/100], Loss: 0.3060, Validation Loss: 0.3697
	--> Epoch [85/100], Loss: 0.1074, Validation Loss: 0.3669
	--> Epoch [86/100], Loss: 0.2487, Validation Loss: 0.3667
	--> Epoch [87/100], Loss: 0.0948, Validation Loss: 0.3659
	--> Epoch [88/100], Loss: 0.0993, Validation Loss: 0.3642
	--> Epoch [89/100], Loss: 0.1565, Validation Loss: 0.3606
	--> Epoch [90/100], Loss: 0.1149, Validation Loss: 0.3610
	--> Epoch [91/100], Loss: 0.1631, Validation Loss: 0.3597
	--> Epoch [92/100], Loss: 0.1495, Validation Loss: 0.3585
	--> Epoch [93/100], Loss: 0.1106, Validation Loss: 0.3565
	--> Epoch [94/100], Loss: 0.1576, Validation Loss: 0.3554
	--> Epoch [95/100], Loss: 0.1606, Validation Loss: 0.3529
	--> Epoch [96/100], Loss: 0.1521, Validation Loss: 0.3512
	--> Epoch [97/100], Loss: 0.1647, Validation Loss: 0.3489
	--> Epoch [98/100], Loss: 0.1611, Validation Loss: 0.3473
	--> Epoch [99/100], Loss: 0.2350, Validation Loss: 0.3464
	--> Epoch [100/100], Loss: 0.0371, Validation Loss: 0.3471
	--> Training for Fold 3 took 0.6308751106262207 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8149, Validation Loss: 0.6601
	--> Epoch [2/100], Loss: 0.8005, Validation Loss: 0.6457
	--> Epoch [3/100], Loss: 0.7413, Validation Loss: 0.6327
	--> Epoch [4/100], Loss: 0.7333, Validation Loss: 0.6184
	--> Epoch [5/100], Loss: 0.7474, Validation Loss: 0.6118
	--> Epoch [6/100], Loss: 0.7100, Validation Loss: 0.6049
	--> Epoch [7/100], Loss: 0.6270, Validation Loss: 0.5948
	--> Epoch [8/100], Loss: 0.6132, Validation Loss: 0.5846
	--> Epoch [9/100], Loss: 0.5929, Validation Loss: 0.5775
	--> Epoch [10/100], Loss: 0.6165, Validation Loss: 0.5709
	--> Epoch [11/100], Loss: 0.5552, Validation Loss: 0.5630
	--> Epoch [12/100], Loss: 0.5522, Validation Loss: 0.5607
	--> Epoch [13/100], Loss: 0.4365, Validation Loss: 0.5522
	--> Epoch [14/100], Loss: 0.4362, Validation Loss: 0.5467
	--> Epoch [15/100], Loss: 0.3881, Validation Loss: 0.5432
	--> Epoch [16/100], Loss: 0.3792, Validation Loss: 0.5398
	--> Epoch [17/100], Loss: 0.3352, Validation Loss: 0.5324
	--> Epoch [18/100], Loss: 0.4200, Validation Loss: 0.5285
	--> Epoch [19/100], Loss: 0.3642, Validation Loss: 0.5213
	--> Epoch [20/100], Loss: 0.3082, Validation Loss: 0.5150
	--> Epoch [21/100], Loss: 0.3419, Validation Loss: 0.5133
	--> Epoch [22/100], Loss: 0.3643, Validation Loss: 0.5083
	--> Epoch [23/100], Loss: 0.2405, Validation Loss: 0.5011
	--> Epoch [24/100], Loss: 0.2454, Validation Loss: 0.4971
	--> Epoch [25/100], Loss: 0.4143, Validation Loss: 0.4921
	--> Epoch [26/100], Loss: 0.3437, Validation Loss: 0.4908
	--> Epoch [27/100], Loss: 0.4191, Validation Loss: 0.4868
	--> Epoch [28/100], Loss: 0.3592, Validation Loss: 0.4784
	--> Epoch [29/100], Loss: 0.3758, Validation Loss: 0.4722
	--> Epoch [30/100], Loss: 0.1992, Validation Loss: 0.4674
	--> Epoch [31/100], Loss: 0.1757, Validation Loss: 0.4615
	--> Epoch [32/100], Loss: 0.3007, Validation Loss: 0.4572
	--> Epoch [33/100], Loss: 0.2513, Validation Loss: 0.4523
	--> Epoch [34/100], Loss: 0.2444, Validation Loss: 0.4483
	--> Epoch [35/100], Loss: 0.2062, Validation Loss: 0.4469
	--> Epoch [36/100], Loss: 0.2533, Validation Loss: 0.4421
	--> Epoch [37/100], Loss: 0.2080, Validation Loss: 0.4415
	--> Epoch [38/100], Loss: 0.1994, Validation Loss: 0.4381
	--> Epoch [39/100], Loss: 0.1647, Validation Loss: 0.4353
	--> Epoch [40/100], Loss: 0.2401, Validation Loss: 0.4300
	--> Epoch [41/100], Loss: 0.1628, Validation Loss: 0.4265
	--> Epoch [42/100], Loss: 0.1376, Validation Loss: 0.4233
	--> Epoch [43/100], Loss: 0.2046, Validation Loss: 0.4175
	--> Epoch [44/100], Loss: 0.2014, Validation Loss: 0.4179
	--> Epoch [45/100], Loss: 0.2542, Validation Loss: 0.4134
	--> Epoch [46/100], Loss: 0.1934, Validation Loss: 0.4098
	--> Epoch [47/100], Loss: 0.1447, Validation Loss: 0.4069
	--> Epoch [48/100], Loss: 0.1355, Validation Loss: 0.4044
	--> Epoch [49/100], Loss: 0.1162, Validation Loss: 0.4011
	--> Epoch [50/100], Loss: 0.1161, Validation Loss: 0.3981
	--> Epoch [51/100], Loss: 0.1792, Validation Loss: 0.3988
	--> Epoch [52/100], Loss: 0.0519, Validation Loss: 0.3975
	--> Epoch [53/100], Loss: 0.1804, Validation Loss: 0.3926
	--> Epoch [54/100], Loss: 0.2515, Validation Loss: 0.3886
	--> Epoch [55/100], Loss: 0.1894, Validation Loss: 0.3853
	--> Epoch [56/100], Loss: 0.1519, Validation Loss: 0.3828
	--> Epoch [57/100], Loss: 0.1469, Validation Loss: 0.3818
	--> Epoch [58/100], Loss: 0.3084, Validation Loss: 0.3867
	--> Epoch [59/100], Loss: 0.1571, Validation Loss: 0.3843
	--> Epoch [60/100], Loss: 0.1185, Validation Loss: 0.3817
	--> Epoch [61/100], Loss: 0.1799, Validation Loss: 0.3782
	--> Epoch [62/100], Loss: 0.1112, Validation Loss: 0.3759
	--> Epoch [63/100], Loss: 0.0848, Validation Loss: 0.3729
	--> Epoch [64/100], Loss: 0.1429, Validation Loss: 0.3684
	--> Epoch [65/100], Loss: 0.1374, Validation Loss: 0.3704
	--> Epoch [66/100], Loss: 0.1621, Validation Loss: 0.3688
	--> Epoch [67/100], Loss: 0.1614, Validation Loss: 0.3679
	--> Epoch [68/100], Loss: 0.2227, Validation Loss: 0.3652
	--> Epoch [69/100], Loss: 0.0997, Validation Loss: 0.3638
	--> Epoch [70/100], Loss: 0.2173, Validation Loss: 0.3602
	--> Epoch [71/100], Loss: 0.0893, Validation Loss: 0.3581
	--> Epoch [72/100], Loss: 0.0992, Validation Loss: 0.3550
	--> Epoch [73/100], Loss: 0.0264, Validation Loss: 0.3544
	--> Epoch [74/100], Loss: 0.1461, Validation Loss: 0.3535
	--> Epoch [75/100], Loss: 0.0496, Validation Loss: 0.3507
	--> Epoch [76/100], Loss: 0.0664, Validation Loss: 0.3475
	--> Epoch [77/100], Loss: 0.2288, Validation Loss: 0.3450
	--> Epoch [78/100], Loss: 0.2197, Validation Loss: 0.3473
	--> Epoch [79/100], Loss: 0.1671, Validation Loss: 0.3458
	--> Epoch [80/100], Loss: 0.1623, Validation Loss: 0.3516
Early stopping
	--> Training for Fold 4 took 0.5062499046325684 sec, using 80 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8253, Validation Loss: 0.6562
	--> Epoch [2/100], Loss: 0.7046, Validation Loss: 0.6513
	--> Epoch [3/100], Loss: 0.7685, Validation Loss: 0.6492
	--> Epoch [4/100], Loss: 0.6812, Validation Loss: 0.6475
	--> Epoch [5/100], Loss: 0.6433, Validation Loss: 0.6462
	--> Epoch [6/100], Loss: 0.5981, Validation Loss: 0.6458
	--> Epoch [7/100], Loss: 0.5893, Validation Loss: 0.6453
	--> Epoch [8/100], Loss: 0.5307, Validation Loss: 0.6450
	--> Epoch [9/100], Loss: 0.5135, Validation Loss: 0.6426
	--> Epoch [10/100], Loss: 0.5608, Validation Loss: 0.6390
	--> Epoch [11/100], Loss: 0.6489, Validation Loss: 0.6365
	--> Epoch [12/100], Loss: 0.5524, Validation Loss: 0.6334
	--> Epoch [13/100], Loss: 0.6357, Validation Loss: 0.6314
	--> Epoch [14/100], Loss: 0.4262, Validation Loss: 0.6290
	--> Epoch [15/100], Loss: 0.4237, Validation Loss: 0.6247
	--> Epoch [16/100], Loss: 0.4385, Validation Loss: 0.6241
	--> Epoch [17/100], Loss: 0.3622, Validation Loss: 0.6176
	--> Epoch [18/100], Loss: 0.3911, Validation Loss: 0.6156
	--> Epoch [19/100], Loss: 0.4967, Validation Loss: 0.6125
	--> Epoch [20/100], Loss: 0.4617, Validation Loss: 0.6097
	--> Epoch [21/100], Loss: 0.4339, Validation Loss: 0.6072
	--> Epoch [22/100], Loss: 0.3343, Validation Loss: 0.6027
	--> Epoch [23/100], Loss: 0.4727, Validation Loss: 0.5991
	--> Epoch [24/100], Loss: 0.3763, Validation Loss: 0.5940
	--> Epoch [25/100], Loss: 0.4300, Validation Loss: 0.5892
	--> Epoch [26/100], Loss: 0.3639, Validation Loss: 0.5866
	--> Epoch [27/100], Loss: 0.4037, Validation Loss: 0.5825
	--> Epoch [28/100], Loss: 0.3284, Validation Loss: 0.5793
	--> Epoch [29/100], Loss: 0.4346, Validation Loss: 0.5776
	--> Epoch [30/100], Loss: 0.4484, Validation Loss: 0.5740
	--> Epoch [31/100], Loss: 0.4190, Validation Loss: 0.5704
	--> Epoch [32/100], Loss: 0.4054, Validation Loss: 0.5651
	--> Epoch [33/100], Loss: 0.2290, Validation Loss: 0.5624
	--> Epoch [34/100], Loss: 0.2944, Validation Loss: 0.5624
	--> Epoch [35/100], Loss: 0.4165, Validation Loss: 0.5592
	--> Epoch [36/100], Loss: 0.3425, Validation Loss: 0.5596
	--> Epoch [37/100], Loss: 0.3432, Validation Loss: 0.5546
	--> Epoch [38/100], Loss: 0.3694, Validation Loss: 0.5519
	--> Epoch [39/100], Loss: 0.3266, Validation Loss: 0.5521
	--> Epoch [40/100], Loss: 0.2796, Validation Loss: 0.5501
	--> Epoch [41/100], Loss: 0.3672, Validation Loss: 0.5477
	--> Epoch [42/100], Loss: 0.2550, Validation Loss: 0.5487
	--> Epoch [43/100], Loss: 0.2793, Validation Loss: 0.5465
	--> Epoch [44/100], Loss: 0.3137, Validation Loss: 0.5437
	--> Epoch [45/100], Loss: 0.1723, Validation Loss: 0.5439
	--> Epoch [46/100], Loss: 0.3247, Validation Loss: 0.5405
	--> Epoch [47/100], Loss: 0.2245, Validation Loss: 0.5377
	--> Epoch [48/100], Loss: 0.1755, Validation Loss: 0.5410
	--> Epoch [49/100], Loss: 0.3360, Validation Loss: 0.5384
	--> Epoch [50/100], Loss: 0.1389, Validation Loss: 0.5378
Early stopping
	--> Training for Fold 5 took 0.2987098693847656 sec, using 50 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6718
	--> Final training Epoch [2/100], Loss: 0.6579
	--> Final training Epoch [3/100], Loss: 0.6351
	--> Final training Epoch [4/100], Loss: 0.6269
	--> Final training Epoch [5/100], Loss: 0.6546
	--> Final training Epoch [6/100], Loss: 0.5873
	--> Final training Epoch [7/100], Loss: 0.5542
	--> Final training Epoch [8/100], Loss: 0.5872
	--> Final training Epoch [9/100], Loss: 0.5539
	--> Final training Epoch [10/100], Loss: 0.5156
	--> Final training Epoch [11/100], Loss: 0.5259
	--> Final training Epoch [12/100], Loss: 0.5169
	--> Final training Epoch [13/100], Loss: 0.4891
	--> Final training Epoch [14/100], Loss: 0.4666
	--> Final training Epoch [15/100], Loss: 0.4278
	--> Final training Epoch [16/100], Loss: 0.4663
	--> Final training Epoch [17/100], Loss: 0.4919
	--> Final training Epoch [18/100], Loss: 0.4094
	--> Final training Epoch [19/100], Loss: 0.4200
	--> Final training Epoch [20/100], Loss: 0.3689
	--> Final training Epoch [21/100], Loss: 0.3999
	--> Final training Epoch [22/100], Loss: 0.3682
	--> Final training Epoch [23/100], Loss: 0.4066
	--> Final training Epoch [24/100], Loss: 0.3095
	--> Final training Epoch [25/100], Loss: 0.4031
	--> Final training Epoch [26/100], Loss: 0.3195
	--> Final training Epoch [27/100], Loss: 0.3218
	--> Final training Epoch [28/100], Loss: 0.3182
	--> Final training Epoch [29/100], Loss: 0.3231
	--> Final training Epoch [30/100], Loss: 0.2903
	--> Final training Epoch [31/100], Loss: 0.3123
	--> Final training Epoch [32/100], Loss: 0.2660
	--> Final training Epoch [33/100], Loss: 0.3219
	--> Final training Epoch [34/100], Loss: 0.2745
	--> Final training Epoch [35/100], Loss: 0.2696
	--> Final training Epoch [36/100], Loss: 0.2483
	--> Final training Epoch [37/100], Loss: 0.2825
	--> Final training Epoch [38/100], Loss: 0.2371
	--> Final training Epoch [39/100], Loss: 0.2348
	--> Final training Epoch [40/100], Loss: 0.2102
	--> Final training Epoch [41/100], Loss: 0.2177
	--> Final training Epoch [42/100], Loss: 0.2305
	--> Final training Epoch [43/100], Loss: 0.2804
	--> Final training Epoch [44/100], Loss: 0.2648
	--> Final training Epoch [45/100], Loss: 0.1991
	--> Final training Epoch [46/100], Loss: 0.2368
	--> Final training Epoch [47/100], Loss: 0.2283
	--> Final training Epoch [48/100], Loss: 0.2668
	--> Final training Epoch [49/100], Loss: 0.2413
	--> Final training Epoch [50/100], Loss: 0.2397
	--> Final training Epoch [51/100], Loss: 0.2043
	--> Final training Epoch [52/100], Loss: 0.2696
	--> Final training Epoch [53/100], Loss: 0.2666
	--> Final training Epoch [54/100], Loss: 0.1502
	--> Final training Epoch [55/100], Loss: 0.1634
	--> Final training Epoch [56/100], Loss: 0.1502
	--> Final training Epoch [57/100], Loss: 0.2162
	--> Final training Epoch [58/100], Loss: 0.2030
	--> Final training Epoch [59/100], Loss: 0.1545
	--> Final training Epoch [60/100], Loss: 0.1503
	--> Final training Epoch [61/100], Loss: 0.1269
	--> Final training Epoch [62/100], Loss: 0.1382
	--> Final training Epoch [63/100], Loss: 0.1404
	--> Final training Epoch [64/100], Loss: 0.1658
	--> Final training Epoch [65/100], Loss: 0.1552
	--> Final training Epoch [66/100], Loss: 0.2278
	--> Final training Epoch [67/100], Loss: 0.1568
	--> Final training Epoch [68/100], Loss: 0.1458
	--> Final training Epoch [69/100], Loss: 0.2296
	--> Final training Epoch [70/100], Loss: 0.1933
	--> Final training Epoch [71/100], Loss: 0.1705
	--> Final training Epoch [72/100], Loss: 0.1486
	--> Final training Epoch [73/100], Loss: 0.1339
	--> Final training Epoch [74/100], Loss: 0.1688
	--> Final training Epoch [75/100], Loss: 0.1661
	--> Final training Epoch [76/100], Loss: 0.1632
	--> Final training Epoch [77/100], Loss: 0.1537
	--> Final training Epoch [78/100], Loss: 0.1616
	--> Final training Epoch [79/100], Loss: 0.1203
	--> Final training Epoch [80/100], Loss: 0.1890
	--> Final training Epoch [81/100], Loss: 0.1754
	--> Final training Epoch [82/100], Loss: 0.0906
	--> Final training Epoch [83/100], Loss: 0.2324
	--> Final training Epoch [84/100], Loss: 0.1728
	--> Final training Epoch [85/100], Loss: 0.2282
	--> Final training Epoch [86/100], Loss: 0.1367
	--> Final training Epoch [87/100], Loss: 0.1470
	--> Final training Epoch [88/100], Loss: 0.1293
	--> Final training Epoch [89/100], Loss: 0.1839
	--> Final training Epoch [90/100], Loss: 0.1477
	--> Final training Epoch [91/100], Loss: 0.0946
	--> Final training Epoch [92/100], Loss: 0.1440
	--> Final training Epoch [93/100], Loss: 0.1640
	--> Final training Epoch [94/100], Loss: 0.1185
	--> Final training Epoch [95/100], Loss: 0.1389
	--> Final training Epoch [96/100], Loss: 0.1141
	--> Final training Epoch [97/100], Loss: 0.0687
	--> Final training Epoch [98/100], Loss: 0.1754
	--> Final training Epoch [99/100], Loss: 0.2015
	--> Final training Epoch [100/100], Loss: 0.0880

Final training took 0.6226410865783691 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.9822
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8918, Validation Loss: 0.3276,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3276
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7596, Validation Loss: 0.4567,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3276
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 0.4492,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3276
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7731, Validation Loss: 0.4562,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3276

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6113, Validation Loss: 0.6340
	--> Epoch [2/100], Loss: 0.5456, Validation Loss: 0.6171
	--> Epoch [3/100], Loss: 0.4956, Validation Loss: 0.6091
	--> Epoch [4/100], Loss: 0.4866, Validation Loss: 0.5990
	--> Epoch [5/100], Loss: 0.5097, Validation Loss: 0.5922
	--> Epoch [6/100], Loss: 0.4644, Validation Loss: 0.5826
	--> Epoch [7/100], Loss: 0.4288, Validation Loss: 0.5747
	--> Epoch [8/100], Loss: 0.3569, Validation Loss: 0.5661
	--> Epoch [9/100], Loss: 0.3276, Validation Loss: 0.5617
	--> Epoch [10/100], Loss: 0.4379, Validation Loss: 0.5579
	--> Epoch [11/100], Loss: 0.3659, Validation Loss: 0.5528
	--> Epoch [12/100], Loss: 0.3375, Validation Loss: 0.5462
	--> Epoch [13/100], Loss: 0.3294, Validation Loss: 0.5396
	--> Epoch [14/100], Loss: 0.3510, Validation Loss: 0.5329
	--> Epoch [15/100], Loss: 0.4150, Validation Loss: 0.5258
	--> Epoch [16/100], Loss: 0.2708, Validation Loss: 0.5204
	--> Epoch [17/100], Loss: 0.2825, Validation Loss: 0.5149
	--> Epoch [18/100], Loss: 0.3053, Validation Loss: 0.5097
	--> Epoch [19/100], Loss: 0.2619, Validation Loss: 0.5042
	--> Epoch [20/100], Loss: 0.2795, Validation Loss: 0.4993
	--> Epoch [21/100], Loss: 0.2141, Validation Loss: 0.4925
	--> Epoch [22/100], Loss: 0.1940, Validation Loss: 0.4863
	--> Epoch [23/100], Loss: 0.2867, Validation Loss: 0.4813
	--> Epoch [24/100], Loss: 0.3091, Validation Loss: 0.4765
	--> Epoch [25/100], Loss: 0.1969, Validation Loss: 0.4702
	--> Epoch [26/100], Loss: 0.1535, Validation Loss: 0.4649
	--> Epoch [27/100], Loss: 0.1646, Validation Loss: 0.4609
	--> Epoch [28/100], Loss: 0.2715, Validation Loss: 0.4555
	--> Epoch [29/100], Loss: 0.2079, Validation Loss: 0.4499
	--> Epoch [30/100], Loss: 0.2200, Validation Loss: 0.4461
	--> Epoch [31/100], Loss: 0.2002, Validation Loss: 0.4419
	--> Epoch [32/100], Loss: 0.2714, Validation Loss: 0.4356
	--> Epoch [33/100], Loss: 0.1280, Validation Loss: 0.4306
	--> Epoch [34/100], Loss: 0.2382, Validation Loss: 0.4272
	--> Epoch [35/100], Loss: 0.2023, Validation Loss: 0.4232
	--> Epoch [36/100], Loss: 0.1102, Validation Loss: 0.4191
	--> Epoch [37/100], Loss: 0.1056, Validation Loss: 0.4163
	--> Epoch [38/100], Loss: 0.1455, Validation Loss: 0.4127
	--> Epoch [39/100], Loss: 0.1214, Validation Loss: 0.4096
	--> Epoch [40/100], Loss: 0.0792, Validation Loss: 0.4067
	--> Epoch [41/100], Loss: 0.0764, Validation Loss: 0.4010
	--> Epoch [42/100], Loss: 0.1261, Validation Loss: 0.3983
	--> Epoch [43/100], Loss: 0.1515, Validation Loss: 0.3950
	--> Epoch [44/100], Loss: 0.1500, Validation Loss: 0.3921
	--> Epoch [45/100], Loss: 0.1175, Validation Loss: 0.3903
	--> Epoch [46/100], Loss: 0.0803, Validation Loss: 0.3873
	--> Epoch [47/100], Loss: 0.0411, Validation Loss: 0.3846
	--> Epoch [48/100], Loss: 0.0846, Validation Loss: 0.3805
	--> Epoch [49/100], Loss: 0.0379, Validation Loss: 0.3787
	--> Epoch [50/100], Loss: 0.1299, Validation Loss: 0.3767
	--> Epoch [51/100], Loss: 0.2164, Validation Loss: 0.3732
	--> Epoch [52/100], Loss: 0.1135, Validation Loss: 0.3724
	--> Epoch [53/100], Loss: 0.0554, Validation Loss: 0.3704
	--> Epoch [54/100], Loss: 0.1744, Validation Loss: 0.3680
	--> Epoch [55/100], Loss: 0.0884, Validation Loss: 0.3664
	--> Epoch [56/100], Loss: 0.0674, Validation Loss: 0.3639
	--> Epoch [57/100], Loss: 0.0371, Validation Loss: 0.3627
	--> Epoch [58/100], Loss: 0.1498, Validation Loss: 0.3611
	--> Epoch [59/100], Loss: 0.2036, Validation Loss: 0.3595
	--> Epoch [60/100], Loss: 0.0216, Validation Loss: 0.3575
	--> Epoch [61/100], Loss: 0.0221, Validation Loss: 0.3554
	--> Epoch [62/100], Loss: 0.0892, Validation Loss: 0.3540
	--> Epoch [63/100], Loss: 0.0840, Validation Loss: 0.3534
	--> Epoch [64/100], Loss: 0.1020, Validation Loss: 0.3526
	--> Epoch [65/100], Loss: 0.0371, Validation Loss: 0.3514
	--> Epoch [66/100], Loss: 0.1491, Validation Loss: 0.3515
	--> Epoch [67/100], Loss: 0.0955, Validation Loss: 0.3519
	--> Epoch [68/100], Loss: 0.1994, Validation Loss: 0.3499
	--> Epoch [69/100], Loss: 0.1197, Validation Loss: 0.3495
	--> Epoch [70/100], Loss: 0.0982, Validation Loss: 0.3481
	--> Epoch [71/100], Loss: 0.0957, Validation Loss: 0.3443
	--> Epoch [72/100], Loss: 0.0445, Validation Loss: 0.3432
	--> Epoch [73/100], Loss: 0.0591, Validation Loss: 0.3430
	--> Epoch [74/100], Loss: 0.0850, Validation Loss: 0.3425
	--> Epoch [75/100], Loss: 0.1247, Validation Loss: 0.3414
	--> Epoch [76/100], Loss: 0.0801, Validation Loss: 0.3391
	--> Epoch [77/100], Loss: 0.0804, Validation Loss: 0.3371
	--> Epoch [78/100], Loss: 0.0237, Validation Loss: 0.3352
	--> Epoch [79/100], Loss: 0.0770, Validation Loss: 0.3339
	--> Epoch [80/100], Loss: 0.1004, Validation Loss: 0.3339
	--> Epoch [81/100], Loss: 0.0118, Validation Loss: 0.3324
	--> Epoch [82/100], Loss: 0.0351, Validation Loss: 0.3320
	--> Epoch [83/100], Loss: 0.0277, Validation Loss: 0.3322
	--> Epoch [84/100], Loss: 0.0092, Validation Loss: 0.3316
	--> Epoch [85/100], Loss: 0.0981, Validation Loss: 0.3306
	--> Epoch [86/100], Loss: 0.0413, Validation Loss: 0.3307
	--> Epoch [87/100], Loss: 0.0206, Validation Loss: 0.3292
	--> Epoch [88/100], Loss: 0.0782, Validation Loss: 0.3273
	--> Epoch [89/100], Loss: 0.0122, Validation Loss: 0.3259
	--> Epoch [90/100], Loss: 0.1005, Validation Loss: 0.3250
	--> Epoch [91/100], Loss: 0.0199, Validation Loss: 0.3248
	--> Epoch [92/100], Loss: 0.0085, Validation Loss: 0.3238
	--> Epoch [93/100], Loss: 0.0067, Validation Loss: 0.3237
	--> Epoch [94/100], Loss: 0.0712, Validation Loss: 0.3226
	--> Epoch [95/100], Loss: 0.0143, Validation Loss: 0.3205
	--> Epoch [96/100], Loss: 0.0264, Validation Loss: 0.3182
	--> Epoch [97/100], Loss: 0.0073, Validation Loss: 0.3174
	--> Epoch [98/100], Loss: 0.0086, Validation Loss: 0.3164
	--> Epoch [99/100], Loss: 0.1821, Validation Loss: 0.3175
	--> Epoch [100/100], Loss: 0.0123, Validation Loss: 0.3173
	--> Training for Fold 1 took 0.7613162994384766 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7401, Validation Loss: 0.6998
	--> Epoch [2/100], Loss: 0.6853, Validation Loss: 0.6794
	--> Epoch [3/100], Loss: 0.6539, Validation Loss: 0.6647
	--> Epoch [4/100], Loss: 0.5879, Validation Loss: 0.6540
	--> Epoch [5/100], Loss: 0.6116, Validation Loss: 0.6380
	--> Epoch [6/100], Loss: 0.5934, Validation Loss: 0.6259
	--> Epoch [7/100], Loss: 0.5070, Validation Loss: 0.6136
	--> Epoch [8/100], Loss: 0.5610, Validation Loss: 0.6057
	--> Epoch [9/100], Loss: 0.5407, Validation Loss: 0.5941
	--> Epoch [10/100], Loss: 0.5387, Validation Loss: 0.5833
	--> Epoch [11/100], Loss: 0.5041, Validation Loss: 0.5702
	--> Epoch [12/100], Loss: 0.4420, Validation Loss: 0.5622
	--> Epoch [13/100], Loss: 0.3843, Validation Loss: 0.5531
	--> Epoch [14/100], Loss: 0.4620, Validation Loss: 0.5439
	--> Epoch [15/100], Loss: 0.4295, Validation Loss: 0.5372
	--> Epoch [16/100], Loss: 0.3777, Validation Loss: 0.5320
	--> Epoch [17/100], Loss: 0.3793, Validation Loss: 0.5244
	--> Epoch [18/100], Loss: 0.3335, Validation Loss: 0.5169
	--> Epoch [19/100], Loss: 0.3374, Validation Loss: 0.5088
	--> Epoch [20/100], Loss: 0.2792, Validation Loss: 0.5043
	--> Epoch [21/100], Loss: 0.3243, Validation Loss: 0.4986
	--> Epoch [22/100], Loss: 0.2908, Validation Loss: 0.4913
	--> Epoch [23/100], Loss: 0.3123, Validation Loss: 0.4852
	--> Epoch [24/100], Loss: 0.3077, Validation Loss: 0.4806
	--> Epoch [25/100], Loss: 0.2970, Validation Loss: 0.4753
	--> Epoch [26/100], Loss: 0.3689, Validation Loss: 0.4689
	--> Epoch [27/100], Loss: 0.3672, Validation Loss: 0.4619
	--> Epoch [28/100], Loss: 0.2166, Validation Loss: 0.4565
	--> Epoch [29/100], Loss: 0.2494, Validation Loss: 0.4508
	--> Epoch [30/100], Loss: 0.2404, Validation Loss: 0.4474
	--> Epoch [31/100], Loss: 0.2565, Validation Loss: 0.4429
	--> Epoch [32/100], Loss: 0.2134, Validation Loss: 0.4360
	--> Epoch [33/100], Loss: 0.2872, Validation Loss: 0.4316
	--> Epoch [34/100], Loss: 0.2690, Validation Loss: 0.4272
	--> Epoch [35/100], Loss: 0.2451, Validation Loss: 0.4207
	--> Epoch [36/100], Loss: 0.2737, Validation Loss: 0.4171
	--> Epoch [37/100], Loss: 0.2459, Validation Loss: 0.4120
	--> Epoch [38/100], Loss: 0.2906, Validation Loss: 0.4096
	--> Epoch [39/100], Loss: 0.2110, Validation Loss: 0.4061
	--> Epoch [40/100], Loss: 0.1838, Validation Loss: 0.3996
	--> Epoch [41/100], Loss: 0.2526, Validation Loss: 0.3960
	--> Epoch [42/100], Loss: 0.2022, Validation Loss: 0.3905
	--> Epoch [43/100], Loss: 0.1918, Validation Loss: 0.3887
	--> Epoch [44/100], Loss: 0.2055, Validation Loss: 0.3848
	--> Epoch [45/100], Loss: 0.2242, Validation Loss: 0.3819
	--> Epoch [46/100], Loss: 0.2377, Validation Loss: 0.3789
	--> Epoch [47/100], Loss: 0.2043, Validation Loss: 0.3747
	--> Epoch [48/100], Loss: 0.1708, Validation Loss: 0.3728
	--> Epoch [49/100], Loss: 0.2821, Validation Loss: 0.3703
	--> Epoch [50/100], Loss: 0.2354, Validation Loss: 0.3687
	--> Epoch [51/100], Loss: 0.2235, Validation Loss: 0.3663
	--> Epoch [52/100], Loss: 0.2230, Validation Loss: 0.3638
	--> Epoch [53/100], Loss: 0.1629, Validation Loss: 0.3573
	--> Epoch [54/100], Loss: 0.2504, Validation Loss: 0.3566
	--> Epoch [55/100], Loss: 0.1725, Validation Loss: 0.3561
	--> Epoch [56/100], Loss: 0.1632, Validation Loss: 0.3545
	--> Epoch [57/100], Loss: 0.2381, Validation Loss: 0.3507
	--> Epoch [58/100], Loss: 0.1678, Validation Loss: 0.3493
	--> Epoch [59/100], Loss: 0.1723, Validation Loss: 0.3466
	--> Epoch [60/100], Loss: 0.2021, Validation Loss: 0.3460
	--> Epoch [61/100], Loss: 0.2356, Validation Loss: 0.3462
	--> Epoch [62/100], Loss: 0.1628, Validation Loss: 0.3446
	--> Epoch [63/100], Loss: 0.2185, Validation Loss: 0.3426
	--> Epoch [64/100], Loss: 0.3198, Validation Loss: 0.3403
	--> Epoch [65/100], Loss: 0.1785, Validation Loss: 0.3362
	--> Epoch [66/100], Loss: 0.1477, Validation Loss: 0.3342
	--> Epoch [67/100], Loss: 0.1494, Validation Loss: 0.3323
	--> Epoch [68/100], Loss: 0.1674, Validation Loss: 0.3280
	--> Epoch [69/100], Loss: 0.1536, Validation Loss: 0.3248
	--> Epoch [70/100], Loss: 0.2375, Validation Loss: 0.3246
	--> Epoch [71/100], Loss: 0.1651, Validation Loss: 0.3225
	--> Epoch [72/100], Loss: 0.1493, Validation Loss: 0.3204
	--> Epoch [73/100], Loss: 0.2075, Validation Loss: 0.3193
	--> Epoch [74/100], Loss: 0.1676, Validation Loss: 0.3172
	--> Epoch [75/100], Loss: 0.1577, Validation Loss: 0.3163
	--> Epoch [76/100], Loss: 0.1733, Validation Loss: 0.3151
	--> Epoch [77/100], Loss: 0.1462, Validation Loss: 0.3144
	--> Epoch [78/100], Loss: 0.1535, Validation Loss: 0.3091
	--> Epoch [79/100], Loss: 0.2291, Validation Loss: 0.3081
	--> Epoch [80/100], Loss: 0.1441, Validation Loss: 0.3072
	--> Epoch [81/100], Loss: 0.1394, Validation Loss: 0.3064
	--> Epoch [82/100], Loss: 0.2089, Validation Loss: 0.3064
	--> Epoch [83/100], Loss: 0.2054, Validation Loss: 0.3051
	--> Epoch [84/100], Loss: 0.1426, Validation Loss: 0.3044
	--> Epoch [85/100], Loss: 0.2266, Validation Loss: 0.3044
	--> Epoch [86/100], Loss: 0.1397, Validation Loss: 0.3024
	--> Epoch [87/100], Loss: 0.1450, Validation Loss: 0.3007
	--> Epoch [88/100], Loss: 0.1878, Validation Loss: 0.3000
	--> Epoch [89/100], Loss: 0.1505, Validation Loss: 0.2989
	--> Epoch [90/100], Loss: 0.1418, Validation Loss: 0.2984
	--> Epoch [91/100], Loss: 0.1539, Validation Loss: 0.2973
	--> Epoch [92/100], Loss: 0.2021, Validation Loss: 0.2941
	--> Epoch [93/100], Loss: 0.1386, Validation Loss: 0.2888
	--> Epoch [94/100], Loss: 0.2124, Validation Loss: 0.2841
	--> Epoch [95/100], Loss: 0.1623, Validation Loss: 0.2838
	--> Epoch [96/100], Loss: 0.2046, Validation Loss: 0.2827
	--> Epoch [97/100], Loss: 0.1381, Validation Loss: 0.2815
	--> Epoch [98/100], Loss: 0.1623, Validation Loss: 0.2797
	--> Epoch [99/100], Loss: 0.1548, Validation Loss: 0.2787
	--> Epoch [100/100], Loss: 0.1367, Validation Loss: 0.2772
	--> Training for Fold 2 took 0.6480224132537842 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5432, Validation Loss: 0.7911
	--> Epoch [2/100], Loss: 0.5078, Validation Loss: 0.7852
	--> Epoch [3/100], Loss: 0.5172, Validation Loss: 0.7761
	--> Epoch [4/100], Loss: 0.4990, Validation Loss: 0.7687
	--> Epoch [5/100], Loss: 0.4415, Validation Loss: 0.7620
	--> Epoch [6/100], Loss: 0.4288, Validation Loss: 0.7525
	--> Epoch [7/100], Loss: 0.4829, Validation Loss: 0.7438
	--> Epoch [8/100], Loss: 0.3977, Validation Loss: 0.7358
	--> Epoch [9/100], Loss: 0.4077, Validation Loss: 0.7269
	--> Epoch [10/100], Loss: 0.3932, Validation Loss: 0.7170
	--> Epoch [11/100], Loss: 0.3991, Validation Loss: 0.7099
	--> Epoch [12/100], Loss: 0.3465, Validation Loss: 0.7022
	--> Epoch [13/100], Loss: 0.3696, Validation Loss: 0.6941
	--> Epoch [14/100], Loss: 0.2974, Validation Loss: 0.6837
	--> Epoch [15/100], Loss: 0.2677, Validation Loss: 0.6722
	--> Epoch [16/100], Loss: 0.3434, Validation Loss: 0.6642
	--> Epoch [17/100], Loss: 0.2258, Validation Loss: 0.6542
	--> Epoch [18/100], Loss: 0.2431, Validation Loss: 0.6471
	--> Epoch [19/100], Loss: 0.2739, Validation Loss: 0.6383
	--> Epoch [20/100], Loss: 0.2295, Validation Loss: 0.6306
	--> Epoch [21/100], Loss: 0.1695, Validation Loss: 0.6229
	--> Epoch [22/100], Loss: 0.2264, Validation Loss: 0.6153
	--> Epoch [23/100], Loss: 0.1590, Validation Loss: 0.6067
	--> Epoch [24/100], Loss: 0.1979, Validation Loss: 0.5985
	--> Epoch [25/100], Loss: 0.1544, Validation Loss: 0.5920
	--> Epoch [26/100], Loss: 0.2125, Validation Loss: 0.5833
	--> Epoch [27/100], Loss: 0.1920, Validation Loss: 0.5763
	--> Epoch [28/100], Loss: 0.1581, Validation Loss: 0.5704
	--> Epoch [29/100], Loss: 0.2500, Validation Loss: 0.5648
	--> Epoch [30/100], Loss: 0.2021, Validation Loss: 0.5573
	--> Epoch [31/100], Loss: 0.1590, Validation Loss: 0.5468
	--> Epoch [32/100], Loss: 0.1150, Validation Loss: 0.5402
	--> Epoch [33/100], Loss: 0.1049, Validation Loss: 0.5345
	--> Epoch [34/100], Loss: 0.0767, Validation Loss: 0.5279
	--> Epoch [35/100], Loss: 0.1388, Validation Loss: 0.5261
	--> Epoch [36/100], Loss: 0.0986, Validation Loss: 0.5197
	--> Epoch [37/100], Loss: 0.1423, Validation Loss: 0.5154
	--> Epoch [38/100], Loss: 0.0985, Validation Loss: 0.5092
	--> Epoch [39/100], Loss: 0.2403, Validation Loss: 0.5044
	--> Epoch [40/100], Loss: 0.2061, Validation Loss: 0.5001
	--> Epoch [41/100], Loss: 0.0518, Validation Loss: 0.4942
	--> Epoch [42/100], Loss: 0.0978, Validation Loss: 0.4907
	--> Epoch [43/100], Loss: 0.1460, Validation Loss: 0.4850
	--> Epoch [44/100], Loss: 0.1248, Validation Loss: 0.4799
	--> Epoch [45/100], Loss: 0.0559, Validation Loss: 0.4752
	--> Epoch [46/100], Loss: 0.0407, Validation Loss: 0.4715
	--> Epoch [47/100], Loss: 0.1234, Validation Loss: 0.4672
	--> Epoch [48/100], Loss: 0.0621, Validation Loss: 0.4638
	--> Epoch [49/100], Loss: 0.0986, Validation Loss: 0.4605
	--> Epoch [50/100], Loss: 0.0820, Validation Loss: 0.4558
	--> Epoch [51/100], Loss: 0.2604, Validation Loss: 0.4543
	--> Epoch [52/100], Loss: 0.1318, Validation Loss: 0.4542
	--> Epoch [53/100], Loss: 0.1045, Validation Loss: 0.4509
	--> Epoch [54/100], Loss: 0.1296, Validation Loss: 0.4475
	--> Epoch [55/100], Loss: 0.0940, Validation Loss: 0.4440
	--> Epoch [56/100], Loss: 0.0995, Validation Loss: 0.4414
	--> Epoch [57/100], Loss: 0.1177, Validation Loss: 0.4391
	--> Epoch [58/100], Loss: 0.0763, Validation Loss: 0.4351
	--> Epoch [59/100], Loss: 0.0992, Validation Loss: 0.4313
	--> Epoch [60/100], Loss: 0.0381, Validation Loss: 0.4283
	--> Epoch [61/100], Loss: 0.0237, Validation Loss: 0.4249
	--> Epoch [62/100], Loss: 0.0367, Validation Loss: 0.4214
	--> Epoch [63/100], Loss: 0.0453, Validation Loss: 0.4193
	--> Epoch [64/100], Loss: 0.0756, Validation Loss: 0.4161
	--> Epoch [65/100], Loss: 0.0197, Validation Loss: 0.4128
	--> Epoch [66/100], Loss: 0.0236, Validation Loss: 0.4111
	--> Epoch [67/100], Loss: 0.0744, Validation Loss: 0.4091
	--> Epoch [68/100], Loss: 0.0510, Validation Loss: 0.4079
	--> Epoch [69/100], Loss: 0.0630, Validation Loss: 0.4051
	--> Epoch [70/100], Loss: 0.1748, Validation Loss: 0.4037
	--> Epoch [71/100], Loss: 0.0717, Validation Loss: 0.4010
	--> Epoch [72/100], Loss: 0.0176, Validation Loss: 0.3979
	--> Epoch [73/100], Loss: 0.1761, Validation Loss: 0.3985
	--> Epoch [74/100], Loss: 0.0276, Validation Loss: 0.3959
	--> Epoch [75/100], Loss: 0.1053, Validation Loss: 0.3939
	--> Epoch [76/100], Loss: 0.0298, Validation Loss: 0.3917
	--> Epoch [77/100], Loss: 0.0608, Validation Loss: 0.3904
	--> Epoch [78/100], Loss: 0.2025, Validation Loss: 0.3900
	--> Epoch [79/100], Loss: 0.0225, Validation Loss: 0.3898
	--> Epoch [80/100], Loss: 0.0128, Validation Loss: 0.3884
	--> Epoch [81/100], Loss: 0.0205, Validation Loss: 0.3875
	--> Epoch [82/100], Loss: 0.1254, Validation Loss: 0.3870
	--> Epoch [83/100], Loss: 0.0694, Validation Loss: 0.3865
	--> Epoch [84/100], Loss: 0.0186, Validation Loss: 0.3831
	--> Epoch [85/100], Loss: 0.0731, Validation Loss: 0.3853
	--> Epoch [86/100], Loss: 0.0176, Validation Loss: 0.3839
	--> Epoch [87/100], Loss: 0.1508, Validation Loss: 0.3815
	--> Epoch [88/100], Loss: 0.0170, Validation Loss: 0.3797
	--> Epoch [89/100], Loss: 0.1093, Validation Loss: 0.3795
	--> Epoch [90/100], Loss: 0.0228, Validation Loss: 0.3783
	--> Epoch [91/100], Loss: 0.0295, Validation Loss: 0.3771
	--> Epoch [92/100], Loss: 0.0162, Validation Loss: 0.3747
	--> Epoch [93/100], Loss: 0.0178, Validation Loss: 0.3743
	--> Epoch [94/100], Loss: 0.0141, Validation Loss: 0.3748
	--> Epoch [95/100], Loss: 0.0385, Validation Loss: 0.3731
	--> Epoch [96/100], Loss: 0.0640, Validation Loss: 0.3725
	--> Epoch [97/100], Loss: 0.0075, Validation Loss: 0.3703
	--> Epoch [98/100], Loss: 0.0707, Validation Loss: 0.3696
	--> Epoch [99/100], Loss: 0.0577, Validation Loss: 0.3693
	--> Epoch [100/100], Loss: 0.0179, Validation Loss: 0.3685
	--> Training for Fold 3 took 0.7324321269989014 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5676, Validation Loss: 0.9540
	--> Epoch [2/100], Loss: 0.5294, Validation Loss: 0.9214
	--> Epoch [3/100], Loss: 0.5102, Validation Loss: 0.8952
	--> Epoch [4/100], Loss: 0.5119, Validation Loss: 0.8745
	--> Epoch [5/100], Loss: 0.4717, Validation Loss: 0.8526
	--> Epoch [6/100], Loss: 0.4220, Validation Loss: 0.8285
	--> Epoch [7/100], Loss: 0.3944, Validation Loss: 0.8050
	--> Epoch [8/100], Loss: 0.3965, Validation Loss: 0.7926
	--> Epoch [9/100], Loss: 0.3475, Validation Loss: 0.7755
	--> Epoch [10/100], Loss: 0.3583, Validation Loss: 0.7614
	--> Epoch [11/100], Loss: 0.3984, Validation Loss: 0.7470
	--> Epoch [12/100], Loss: 0.3821, Validation Loss: 0.7346
	--> Epoch [13/100], Loss: 0.3604, Validation Loss: 0.7191
	--> Epoch [14/100], Loss: 0.3491, Validation Loss: 0.7063
	--> Epoch [15/100], Loss: 0.2612, Validation Loss: 0.6931
	--> Epoch [16/100], Loss: 0.3364, Validation Loss: 0.6800
	--> Epoch [17/100], Loss: 0.2863, Validation Loss: 0.6655
	--> Epoch [18/100], Loss: 0.3073, Validation Loss: 0.6520
	--> Epoch [19/100], Loss: 0.3019, Validation Loss: 0.6393
	--> Epoch [20/100], Loss: 0.2671, Validation Loss: 0.6221
	--> Epoch [21/100], Loss: 0.3222, Validation Loss: 0.6105
	--> Epoch [22/100], Loss: 0.2776, Validation Loss: 0.5982
	--> Epoch [23/100], Loss: 0.2696, Validation Loss: 0.5851
	--> Epoch [24/100], Loss: 0.2879, Validation Loss: 0.5749
	--> Epoch [25/100], Loss: 0.2058, Validation Loss: 0.5627
	--> Epoch [26/100], Loss: 0.1424, Validation Loss: 0.5516
	--> Epoch [27/100], Loss: 0.1646, Validation Loss: 0.5424
	--> Epoch [28/100], Loss: 0.2398, Validation Loss: 0.5335
	--> Epoch [29/100], Loss: 0.1453, Validation Loss: 0.5204
	--> Epoch [30/100], Loss: 0.2329, Validation Loss: 0.5100
	--> Epoch [31/100], Loss: 0.1614, Validation Loss: 0.5022
	--> Epoch [32/100], Loss: 0.1089, Validation Loss: 0.4916
	--> Epoch [33/100], Loss: 0.0929, Validation Loss: 0.4815
	--> Epoch [34/100], Loss: 0.1294, Validation Loss: 0.4722
	--> Epoch [35/100], Loss: 0.0861, Validation Loss: 0.4636
	--> Epoch [36/100], Loss: 0.1000, Validation Loss: 0.4567
	--> Epoch [37/100], Loss: 0.1645, Validation Loss: 0.4523
	--> Epoch [38/100], Loss: 0.2233, Validation Loss: 0.4520
	--> Epoch [39/100], Loss: 0.0895, Validation Loss: 0.4419
	--> Epoch [40/100], Loss: 0.1449, Validation Loss: 0.4386
	--> Epoch [41/100], Loss: 0.1586, Validation Loss: 0.4331
	--> Epoch [42/100], Loss: 0.1080, Validation Loss: 0.4293
	--> Epoch [43/100], Loss: 0.0816, Validation Loss: 0.4289
	--> Epoch [44/100], Loss: 0.2026, Validation Loss: 0.4228
	--> Epoch [45/100], Loss: 0.1317, Validation Loss: 0.4197
	--> Epoch [46/100], Loss: 0.0609, Validation Loss: 0.4156
	--> Epoch [47/100], Loss: 0.0413, Validation Loss: 0.4091
	--> Epoch [48/100], Loss: 0.0827, Validation Loss: 0.4043
	--> Epoch [49/100], Loss: 0.1014, Validation Loss: 0.4025
	--> Epoch [50/100], Loss: 0.1161, Validation Loss: 0.3990
	--> Epoch [51/100], Loss: 0.1377, Validation Loss: 0.3934
	--> Epoch [52/100], Loss: 0.2394, Validation Loss: 0.3940
	--> Epoch [53/100], Loss: 0.0528, Validation Loss: 0.3893
	--> Epoch [54/100], Loss: 0.1884, Validation Loss: 0.3807
	--> Epoch [55/100], Loss: 0.0950, Validation Loss: 0.3775
	--> Epoch [56/100], Loss: 0.1558, Validation Loss: 0.3745
	--> Epoch [57/100], Loss: 0.0471, Validation Loss: 0.3720
	--> Epoch [58/100], Loss: 0.1396, Validation Loss: 0.3680
	--> Epoch [59/100], Loss: 0.0729, Validation Loss: 0.3673
	--> Epoch [60/100], Loss: 0.1877, Validation Loss: 0.3646
	--> Epoch [61/100], Loss: 0.0917, Validation Loss: 0.3676
	--> Epoch [62/100], Loss: 0.1413, Validation Loss: 0.3647
	--> Epoch [63/100], Loss: 0.0440, Validation Loss: 0.3619
	--> Epoch [64/100], Loss: 0.1593, Validation Loss: 0.3596
	--> Epoch [65/100], Loss: 0.0704, Validation Loss: 0.3566
	--> Epoch [66/100], Loss: 0.0233, Validation Loss: 0.3556
	--> Epoch [67/100], Loss: 0.0279, Validation Loss: 0.3542
	--> Epoch [68/100], Loss: 0.0324, Validation Loss: 0.3520
	--> Epoch [69/100], Loss: 0.0067, Validation Loss: 0.3492
	--> Epoch [70/100], Loss: 0.1217, Validation Loss: 0.3456
	--> Epoch [71/100], Loss: 0.0308, Validation Loss: 0.3437
	--> Epoch [72/100], Loss: 0.0497, Validation Loss: 0.3422
	--> Epoch [73/100], Loss: 0.0308, Validation Loss: 0.3418
	--> Epoch [74/100], Loss: 0.0169, Validation Loss: 0.3410
	--> Epoch [75/100], Loss: 0.0522, Validation Loss: 0.3405
	--> Epoch [76/100], Loss: 0.0870, Validation Loss: 0.3426
	--> Epoch [77/100], Loss: 0.0193, Validation Loss: 0.3410
	--> Epoch [78/100], Loss: 0.0368, Validation Loss: 0.3376
	--> Epoch [79/100], Loss: 0.0101, Validation Loss: 0.3371
	--> Epoch [80/100], Loss: 0.0265, Validation Loss: 0.3345
	--> Epoch [81/100], Loss: 0.0611, Validation Loss: 0.3344
	--> Epoch [82/100], Loss: 0.0221, Validation Loss: 0.3345
	--> Epoch [83/100], Loss: 0.0650, Validation Loss: 0.3331
	--> Epoch [84/100], Loss: 0.1053, Validation Loss: 0.3362
	--> Epoch [85/100], Loss: 0.0217, Validation Loss: 0.3331
	--> Epoch [86/100], Loss: 0.0988, Validation Loss: 0.3322
	--> Epoch [87/100], Loss: 0.0132, Validation Loss: 0.3311
	--> Epoch [88/100], Loss: 0.0092, Validation Loss: 0.3302
	--> Epoch [89/100], Loss: 0.1063, Validation Loss: 0.3300
	--> Epoch [90/100], Loss: 0.0199, Validation Loss: 0.3270
	--> Epoch [91/100], Loss: 0.0165, Validation Loss: 0.3253
	--> Epoch [92/100], Loss: 0.1127, Validation Loss: 0.3242
	--> Epoch [93/100], Loss: 0.1039, Validation Loss: 0.3225
	--> Epoch [94/100], Loss: 0.0895, Validation Loss: 0.3232
	--> Epoch [95/100], Loss: 0.0382, Validation Loss: 0.3225
	--> Epoch [96/100], Loss: 0.0046, Validation Loss: 0.3218
	--> Epoch [97/100], Loss: 0.0731, Validation Loss: 0.3227
	--> Epoch [98/100], Loss: 0.0261, Validation Loss: 0.3223
	--> Epoch [99/100], Loss: 0.0138, Validation Loss: 0.3233
Early stopping
	--> Training for Fold 4 took 0.6257729530334473 sec, using 99 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5654, Validation Loss: 0.7494
	--> Epoch [2/100], Loss: 0.5803, Validation Loss: 0.7362
	--> Epoch [3/100], Loss: 0.5645, Validation Loss: 0.7269
	--> Epoch [4/100], Loss: 0.5039, Validation Loss: 0.7186
	--> Epoch [5/100], Loss: 0.4466, Validation Loss: 0.7094
	--> Epoch [6/100], Loss: 0.4838, Validation Loss: 0.7008
	--> Epoch [7/100], Loss: 0.4283, Validation Loss: 0.6916
	--> Epoch [8/100], Loss: 0.4566, Validation Loss: 0.6828
	--> Epoch [9/100], Loss: 0.3963, Validation Loss: 0.6729
	--> Epoch [10/100], Loss: 0.3650, Validation Loss: 0.6663
	--> Epoch [11/100], Loss: 0.3920, Validation Loss: 0.6580
	--> Epoch [12/100], Loss: 0.3198, Validation Loss: 0.6511
	--> Epoch [13/100], Loss: 0.3198, Validation Loss: 0.6452
	--> Epoch [14/100], Loss: 0.2832, Validation Loss: 0.6395
	--> Epoch [15/100], Loss: 0.2611, Validation Loss: 0.6365
	--> Epoch [16/100], Loss: 0.3052, Validation Loss: 0.6325
	--> Epoch [17/100], Loss: 0.1776, Validation Loss: 0.6284
	--> Epoch [18/100], Loss: 0.2810, Validation Loss: 0.6242
	--> Epoch [19/100], Loss: 0.2856, Validation Loss: 0.6182
	--> Epoch [20/100], Loss: 0.2061, Validation Loss: 0.6129
	--> Epoch [21/100], Loss: 0.2567, Validation Loss: 0.6084
	--> Epoch [22/100], Loss: 0.1460, Validation Loss: 0.6055
	--> Epoch [23/100], Loss: 0.1281, Validation Loss: 0.6027
	--> Epoch [24/100], Loss: 0.1556, Validation Loss: 0.5991
	--> Epoch [25/100], Loss: 0.1762, Validation Loss: 0.5996
	--> Epoch [26/100], Loss: 0.1527, Validation Loss: 0.5952
	--> Epoch [27/100], Loss: 0.0951, Validation Loss: 0.5939
	--> Epoch [28/100], Loss: 0.1590, Validation Loss: 0.5949
	--> Epoch [29/100], Loss: 0.1072, Validation Loss: 0.5911
	--> Epoch [30/100], Loss: 0.1842, Validation Loss: 0.5904
	--> Epoch [31/100], Loss: 0.1091, Validation Loss: 0.5880
	--> Epoch [32/100], Loss: 0.1413, Validation Loss: 0.5836
	--> Epoch [33/100], Loss: 0.0899, Validation Loss: 0.5819
	--> Epoch [34/100], Loss: 0.1411, Validation Loss: 0.5792
	--> Epoch [35/100], Loss: 0.1133, Validation Loss: 0.5816
	--> Epoch [36/100], Loss: 0.0988, Validation Loss: 0.5795
	--> Epoch [37/100], Loss: 0.0607, Validation Loss: 0.5794
Early stopping
	--> Training for Fold 5 took 0.21808719635009766 sec, using 37 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6959
	--> Final training Epoch [2/100], Loss: 0.6428
	--> Final training Epoch [3/100], Loss: 0.6137
	--> Final training Epoch [4/100], Loss: 0.5718
	--> Final training Epoch [5/100], Loss: 0.5804
	--> Final training Epoch [6/100], Loss: 0.5243
	--> Final training Epoch [7/100], Loss: 0.5308
	--> Final training Epoch [8/100], Loss: 0.4948
	--> Final training Epoch [9/100], Loss: 0.5123
	--> Final training Epoch [10/100], Loss: 0.4873
	--> Final training Epoch [11/100], Loss: 0.4840
	--> Final training Epoch [12/100], Loss: 0.4567
	--> Final training Epoch [13/100], Loss: 0.4348
	--> Final training Epoch [14/100], Loss: 0.4400
	--> Final training Epoch [15/100], Loss: 0.4084
	--> Final training Epoch [16/100], Loss: 0.3807
	--> Final training Epoch [17/100], Loss: 0.3485
	--> Final training Epoch [18/100], Loss: 0.3450
	--> Final training Epoch [19/100], Loss: 0.3745
	--> Final training Epoch [20/100], Loss: 0.3212
	--> Final training Epoch [21/100], Loss: 0.3711
	--> Final training Epoch [22/100], Loss: 0.3279
	--> Final training Epoch [23/100], Loss: 0.3441
	--> Final training Epoch [24/100], Loss: 0.3229
	--> Final training Epoch [25/100], Loss: 0.2691
	--> Final training Epoch [26/100], Loss: 0.3285
	--> Final training Epoch [27/100], Loss: 0.2540
	--> Final training Epoch [28/100], Loss: 0.2684
	--> Final training Epoch [29/100], Loss: 0.3029
	--> Final training Epoch [30/100], Loss: 0.2583
	--> Final training Epoch [31/100], Loss: 0.2553
	--> Final training Epoch [32/100], Loss: 0.2258
	--> Final training Epoch [33/100], Loss: 0.2174
	--> Final training Epoch [34/100], Loss: 0.2657
	--> Final training Epoch [35/100], Loss: 0.2089
	--> Final training Epoch [36/100], Loss: 0.3109
	--> Final training Epoch [37/100], Loss: 0.2083
	--> Final training Epoch [38/100], Loss: 0.2019
	--> Final training Epoch [39/100], Loss: 0.2071
	--> Final training Epoch [40/100], Loss: 0.1770
	--> Final training Epoch [41/100], Loss: 0.1775
	--> Final training Epoch [42/100], Loss: 0.1791
	--> Final training Epoch [43/100], Loss: 0.1630
	--> Final training Epoch [44/100], Loss: 0.2257
	--> Final training Epoch [45/100], Loss: 0.1803
	--> Final training Epoch [46/100], Loss: 0.1663
	--> Final training Epoch [47/100], Loss: 0.1711
	--> Final training Epoch [48/100], Loss: 0.1684
	--> Final training Epoch [49/100], Loss: 0.1582
	--> Final training Epoch [50/100], Loss: 0.1744
	--> Final training Epoch [51/100], Loss: 0.1029
	--> Final training Epoch [52/100], Loss: 0.1914
	--> Final training Epoch [53/100], Loss: 0.1777
	--> Final training Epoch [54/100], Loss: 0.2107
	--> Final training Epoch [55/100], Loss: 0.1128
	--> Final training Epoch [56/100], Loss: 0.1201
	--> Final training Epoch [57/100], Loss: 0.1497
	--> Final training Epoch [58/100], Loss: 0.1334
	--> Final training Epoch [59/100], Loss: 0.1346
	--> Final training Epoch [60/100], Loss: 0.1109
	--> Final training Epoch [61/100], Loss: 0.1042
	--> Final training Epoch [62/100], Loss: 0.0915
	--> Final training Epoch [63/100], Loss: 0.1034
	--> Final training Epoch [64/100], Loss: 0.1068
	--> Final training Epoch [65/100], Loss: 0.1127
	--> Final training Epoch [66/100], Loss: 0.0938
	--> Final training Epoch [67/100], Loss: 0.0959
	--> Final training Epoch [68/100], Loss: 0.0860
	--> Final training Epoch [69/100], Loss: 0.1132
	--> Final training Epoch [70/100], Loss: 0.0872
	--> Final training Epoch [71/100], Loss: 0.0750
	--> Final training Epoch [72/100], Loss: 0.0978
	--> Final training Epoch [73/100], Loss: 0.0991
	--> Final training Epoch [74/100], Loss: 0.0658
	--> Final training Epoch [75/100], Loss: 0.0963
	--> Final training Epoch [76/100], Loss: 0.0720
	--> Final training Epoch [77/100], Loss: 0.0976
	--> Final training Epoch [78/100], Loss: 0.0626
	--> Final training Epoch [79/100], Loss: 0.1180
	--> Final training Epoch [80/100], Loss: 0.0913
	--> Final training Epoch [81/100], Loss: 0.1264
	--> Final training Epoch [82/100], Loss: 0.0618
	--> Final training Epoch [83/100], Loss: 0.0425
	--> Final training Epoch [84/100], Loss: 0.0714
	--> Final training Epoch [85/100], Loss: 0.0667
	--> Final training Epoch [86/100], Loss: 0.0961
	--> Final training Epoch [87/100], Loss: 0.0662
	--> Final training Epoch [88/100], Loss: 0.0592
	--> Final training Epoch [89/100], Loss: 0.0570
	--> Final training Epoch [90/100], Loss: 0.1274
	--> Final training Epoch [91/100], Loss: 0.0413
	--> Final training Epoch [92/100], Loss: 0.0677
	--> Final training Epoch [93/100], Loss: 0.0296
	--> Final training Epoch [94/100], Loss: 0.0661
	--> Final training Epoch [95/100], Loss: 0.1094
	--> Final training Epoch [96/100], Loss: 0.1072
	--> Final training Epoch [97/100], Loss: 0.0742
	--> Final training Epoch [98/100], Loss: 0.0748
	--> Final training Epoch [99/100], Loss: 0.0395
	--> Final training Epoch [100/100], Loss: 0.0795

Final training took 0.6056351661682129 sec

TESTING
	--> Testing took 0.0074 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9950
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8819, Validation Loss: 0.3247,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8579, Validation Loss: 0.3887,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8579, Validation Loss: 0.3459,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3247
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8368, Validation Loss: 0.4073,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3247

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7524, Validation Loss: 0.7262
	--> Epoch [2/100], Loss: 0.8404, Validation Loss: 0.7181
	--> Epoch [3/100], Loss: 0.7183, Validation Loss: 0.7059
	--> Epoch [4/100], Loss: 0.7475, Validation Loss: 0.6963
	--> Epoch [5/100], Loss: 0.8385, Validation Loss: 0.6876
	--> Epoch [6/100], Loss: 0.6702, Validation Loss: 0.6777
	--> Epoch [7/100], Loss: 0.6359, Validation Loss: 0.6656
	--> Epoch [8/100], Loss: 0.6747, Validation Loss: 0.6591
	--> Epoch [9/100], Loss: 0.6266, Validation Loss: 0.6421
	--> Epoch [10/100], Loss: 0.6679, Validation Loss: 0.6310
	--> Epoch [11/100], Loss: 0.5003, Validation Loss: 0.6206
	--> Epoch [12/100], Loss: 0.5579, Validation Loss: 0.6101
	--> Epoch [13/100], Loss: 0.4711, Validation Loss: 0.5993
	--> Epoch [14/100], Loss: 0.6260, Validation Loss: 0.5873
	--> Epoch [15/100], Loss: 0.4218, Validation Loss: 0.5783
	--> Epoch [16/100], Loss: 0.4423, Validation Loss: 0.5693
	--> Epoch [17/100], Loss: 0.5253, Validation Loss: 0.5616
	--> Epoch [18/100], Loss: 0.4459, Validation Loss: 0.5493
	--> Epoch [19/100], Loss: 0.5451, Validation Loss: 0.5418
	--> Epoch [20/100], Loss: 0.3873, Validation Loss: 0.5337
	--> Epoch [21/100], Loss: 0.4449, Validation Loss: 0.5257
	--> Epoch [22/100], Loss: 0.3607, Validation Loss: 0.5199
	--> Epoch [23/100], Loss: 0.5239, Validation Loss: 0.5125
	--> Epoch [24/100], Loss: 0.4259, Validation Loss: 0.5054
	--> Epoch [25/100], Loss: 0.4359, Validation Loss: 0.5027
	--> Epoch [26/100], Loss: 0.4601, Validation Loss: 0.4941
	--> Epoch [27/100], Loss: 0.2031, Validation Loss: 0.4856
	--> Epoch [28/100], Loss: 0.3349, Validation Loss: 0.4750
	--> Epoch [29/100], Loss: 0.1952, Validation Loss: 0.4682
	--> Epoch [30/100], Loss: 0.2466, Validation Loss: 0.4638
	--> Epoch [31/100], Loss: 0.1685, Validation Loss: 0.4536
	--> Epoch [32/100], Loss: 0.2809, Validation Loss: 0.4501
	--> Epoch [33/100], Loss: 0.4562, Validation Loss: 0.4411
	--> Epoch [34/100], Loss: 0.0798, Validation Loss: 0.4362
	--> Epoch [35/100], Loss: 0.3053, Validation Loss: 0.4305
	--> Epoch [36/100], Loss: 0.1111, Validation Loss: 0.4270
	--> Epoch [37/100], Loss: 0.4464, Validation Loss: 0.4201
	--> Epoch [38/100], Loss: 0.2161, Validation Loss: 0.4129
	--> Epoch [39/100], Loss: 0.3057, Validation Loss: 0.4135
	--> Epoch [40/100], Loss: 0.1239, Validation Loss: 0.4060
	--> Epoch [41/100], Loss: 0.1321, Validation Loss: 0.3994
	--> Epoch [42/100], Loss: 0.2524, Validation Loss: 0.3925
	--> Epoch [43/100], Loss: 0.1204, Validation Loss: 0.3892
	--> Epoch [44/100], Loss: 0.1001, Validation Loss: 0.3823
	--> Epoch [45/100], Loss: 0.1068, Validation Loss: 0.3792
	--> Epoch [46/100], Loss: 0.1219, Validation Loss: 0.3750
	--> Epoch [47/100], Loss: 0.2023, Validation Loss: 0.3710
	--> Epoch [48/100], Loss: 0.1162, Validation Loss: 0.3660
	--> Epoch [49/100], Loss: 0.1866, Validation Loss: 0.3619
	--> Epoch [50/100], Loss: 0.1876, Validation Loss: 0.3604
	--> Epoch [51/100], Loss: 0.2445, Validation Loss: 0.3561
	--> Epoch [52/100], Loss: 0.3045, Validation Loss: 0.3523
	--> Epoch [53/100], Loss: 0.2432, Validation Loss: 0.3490
	--> Epoch [54/100], Loss: 0.1864, Validation Loss: 0.3477
	--> Epoch [55/100], Loss: 0.2221, Validation Loss: 0.3445
	--> Epoch [56/100], Loss: 0.2498, Validation Loss: 0.3451
	--> Epoch [57/100], Loss: 0.1508, Validation Loss: 0.3446
	--> Epoch [58/100], Loss: 0.2729, Validation Loss: 0.3417
	--> Epoch [59/100], Loss: 0.0944, Validation Loss: 0.3373
	--> Epoch [60/100], Loss: 0.1604, Validation Loss: 0.3354
	--> Epoch [61/100], Loss: 0.2269, Validation Loss: 0.3316
	--> Epoch [62/100], Loss: 0.1345, Validation Loss: 0.3295
	--> Epoch [63/100], Loss: 0.1130, Validation Loss: 0.3270
	--> Epoch [64/100], Loss: 0.3455, Validation Loss: 0.3234
	--> Epoch [65/100], Loss: 0.2170, Validation Loss: 0.3206
	--> Epoch [66/100], Loss: 0.1308, Validation Loss: 0.3188
	--> Epoch [67/100], Loss: 0.2220, Validation Loss: 0.3170
	--> Epoch [68/100], Loss: 0.3362, Validation Loss: 0.3166
	--> Epoch [69/100], Loss: 0.0547, Validation Loss: 0.3156
	--> Epoch [70/100], Loss: 0.0969, Validation Loss: 0.3131
	--> Epoch [71/100], Loss: 0.1424, Validation Loss: 0.3104
	--> Epoch [72/100], Loss: 0.0639, Validation Loss: 0.3095
	--> Epoch [73/100], Loss: 0.1210, Validation Loss: 0.3095
	--> Epoch [74/100], Loss: 0.2954, Validation Loss: 0.3087
	--> Epoch [75/100], Loss: 0.0524, Validation Loss: 0.3082
	--> Epoch [76/100], Loss: 0.2786, Validation Loss: 0.3057
	--> Epoch [77/100], Loss: 0.1184, Validation Loss: 0.3040
	--> Epoch [78/100], Loss: 0.1274, Validation Loss: 0.3035
	--> Epoch [79/100], Loss: 0.1243, Validation Loss: 0.3030
	--> Epoch [80/100], Loss: 0.2226, Validation Loss: 0.3014
	--> Epoch [81/100], Loss: 0.1298, Validation Loss: 0.3012
	--> Epoch [82/100], Loss: 0.1993, Validation Loss: 0.3011
	--> Epoch [83/100], Loss: 0.3690, Validation Loss: 0.2984
	--> Epoch [84/100], Loss: 0.1186, Validation Loss: 0.2987
	--> Epoch [85/100], Loss: 0.2250, Validation Loss: 0.2981
	--> Epoch [86/100], Loss: 0.1204, Validation Loss: 0.2967
	--> Epoch [87/100], Loss: 0.2414, Validation Loss: 0.2929
	--> Epoch [88/100], Loss: 0.1866, Validation Loss: 0.2918
	--> Epoch [89/100], Loss: 0.1968, Validation Loss: 0.2919
	--> Epoch [90/100], Loss: 0.2001, Validation Loss: 0.2913
	--> Epoch [91/100], Loss: 0.2815, Validation Loss: 0.2896
	--> Epoch [92/100], Loss: 0.0230, Validation Loss: 0.2890
	--> Epoch [93/100], Loss: 0.1020, Validation Loss: 0.2850
	--> Epoch [94/100], Loss: 0.1054, Validation Loss: 0.2847
	--> Epoch [95/100], Loss: 0.2559, Validation Loss: 0.2837
	--> Epoch [96/100], Loss: 0.2045, Validation Loss: 0.2837
	--> Epoch [97/100], Loss: 0.1919, Validation Loss: 0.2822
	--> Epoch [98/100], Loss: 0.2465, Validation Loss: 0.2810
	--> Epoch [99/100], Loss: 0.2364, Validation Loss: 0.2805
	--> Epoch [100/100], Loss: 0.1587, Validation Loss: 0.2803
	--> Training for Fold 1 took 0.6391739845275879 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5457, Validation Loss: 0.6632
	--> Epoch [2/100], Loss: 0.5302, Validation Loss: 0.6370
	--> Epoch [3/100], Loss: 0.5036, Validation Loss: 0.6206
	--> Epoch [4/100], Loss: 0.4484, Validation Loss: 0.5981
	--> Epoch [5/100], Loss: 0.4131, Validation Loss: 0.5858
	--> Epoch [6/100], Loss: 0.4028, Validation Loss: 0.5693
	--> Epoch [7/100], Loss: 0.3871, Validation Loss: 0.5519
	--> Epoch [8/100], Loss: 0.3498, Validation Loss: 0.5378
	--> Epoch [9/100], Loss: 0.4280, Validation Loss: 0.5229
	--> Epoch [10/100], Loss: 0.4102, Validation Loss: 0.5120
	--> Epoch [11/100], Loss: 0.4233, Validation Loss: 0.5030
	--> Epoch [12/100], Loss: 0.3829, Validation Loss: 0.4922
	--> Epoch [13/100], Loss: 0.3411, Validation Loss: 0.4803
	--> Epoch [14/100], Loss: 0.3020, Validation Loss: 0.4699
	--> Epoch [15/100], Loss: 0.3738, Validation Loss: 0.4601
	--> Epoch [16/100], Loss: 0.3519, Validation Loss: 0.4517
	--> Epoch [17/100], Loss: 0.2838, Validation Loss: 0.4433
	--> Epoch [18/100], Loss: 0.2869, Validation Loss: 0.4350
	--> Epoch [19/100], Loss: 0.2341, Validation Loss: 0.4245
	--> Epoch [20/100], Loss: 0.2547, Validation Loss: 0.4157
	--> Epoch [21/100], Loss: 0.2202, Validation Loss: 0.4062
	--> Epoch [22/100], Loss: 0.2373, Validation Loss: 0.3992
	--> Epoch [23/100], Loss: 0.3326, Validation Loss: 0.3919
	--> Epoch [24/100], Loss: 0.3178, Validation Loss: 0.3829
	--> Epoch [25/100], Loss: 0.2089, Validation Loss: 0.3746
	--> Epoch [26/100], Loss: 0.1083, Validation Loss: 0.3662
	--> Epoch [27/100], Loss: 0.1976, Validation Loss: 0.3572
	--> Epoch [28/100], Loss: 0.2250, Validation Loss: 0.3497
	--> Epoch [29/100], Loss: 0.0918, Validation Loss: 0.3443
	--> Epoch [30/100], Loss: 0.2413, Validation Loss: 0.3381
	--> Epoch [31/100], Loss: 0.2259, Validation Loss: 0.3315
	--> Epoch [32/100], Loss: 0.2593, Validation Loss: 0.3262
	--> Epoch [33/100], Loss: 0.2417, Validation Loss: 0.3207
	--> Epoch [34/100], Loss: 0.2489, Validation Loss: 0.3158
	--> Epoch [35/100], Loss: 0.2104, Validation Loss: 0.3089
	--> Epoch [36/100], Loss: 0.1838, Validation Loss: 0.3037
	--> Epoch [37/100], Loss: 0.1159, Validation Loss: 0.2988
	--> Epoch [38/100], Loss: 0.1363, Validation Loss: 0.2940
	--> Epoch [39/100], Loss: 0.1271, Validation Loss: 0.2902
	--> Epoch [40/100], Loss: 0.1668, Validation Loss: 0.2853
	--> Epoch [41/100], Loss: 0.0835, Validation Loss: 0.2814
	--> Epoch [42/100], Loss: 0.1747, Validation Loss: 0.2792
	--> Epoch [43/100], Loss: 0.0986, Validation Loss: 0.2745
	--> Epoch [44/100], Loss: 0.0369, Validation Loss: 0.2691
	--> Epoch [45/100], Loss: 0.1160, Validation Loss: 0.2661
	--> Epoch [46/100], Loss: 0.1473, Validation Loss: 0.2631
	--> Epoch [47/100], Loss: 0.1847, Validation Loss: 0.2628
	--> Epoch [48/100], Loss: 0.1342, Validation Loss: 0.2600
	--> Epoch [49/100], Loss: 0.0387, Validation Loss: 0.2585
	--> Epoch [50/100], Loss: 0.1492, Validation Loss: 0.2539
	--> Epoch [51/100], Loss: 0.0354, Validation Loss: 0.2521
	--> Epoch [52/100], Loss: 0.1754, Validation Loss: 0.2498
	--> Epoch [53/100], Loss: 0.1003, Validation Loss: 0.2492
	--> Epoch [54/100], Loss: 0.2780, Validation Loss: 0.2475
	--> Epoch [55/100], Loss: 0.1024, Validation Loss: 0.2452
	--> Epoch [56/100], Loss: 0.0350, Validation Loss: 0.2416
	--> Epoch [57/100], Loss: 0.1194, Validation Loss: 0.2390
	--> Epoch [58/100], Loss: 0.1455, Validation Loss: 0.2382
	--> Epoch [59/100], Loss: 0.0972, Validation Loss: 0.2349
	--> Epoch [60/100], Loss: 0.0394, Validation Loss: 0.2325
	--> Epoch [61/100], Loss: 0.0948, Validation Loss: 0.2313
	--> Epoch [62/100], Loss: 0.1775, Validation Loss: 0.2283
	--> Epoch [63/100], Loss: 0.0269, Validation Loss: 0.2271
	--> Epoch [64/100], Loss: 0.1767, Validation Loss: 0.2263
	--> Epoch [65/100], Loss: 0.1658, Validation Loss: 0.2247
	--> Epoch [66/100], Loss: 0.0915, Validation Loss: 0.2235
	--> Epoch [67/100], Loss: 0.2119, Validation Loss: 0.2232
	--> Epoch [68/100], Loss: 0.1004, Validation Loss: 0.2222
	--> Epoch [69/100], Loss: 0.1357, Validation Loss: 0.2209
	--> Epoch [70/100], Loss: 0.1337, Validation Loss: 0.2201
	--> Epoch [71/100], Loss: 0.0460, Validation Loss: 0.2184
	--> Epoch [72/100], Loss: 0.1106, Validation Loss: 0.2193
	--> Epoch [73/100], Loss: 0.0982, Validation Loss: 0.2144
	--> Epoch [74/100], Loss: 0.0508, Validation Loss: 0.2137
	--> Epoch [75/100], Loss: 0.0275, Validation Loss: 0.2129
	--> Epoch [76/100], Loss: 0.0406, Validation Loss: 0.2122
	--> Epoch [77/100], Loss: 0.1050, Validation Loss: 0.2114
	--> Epoch [78/100], Loss: 0.1581, Validation Loss: 0.2113
	--> Epoch [79/100], Loss: 0.1191, Validation Loss: 0.2098
	--> Epoch [80/100], Loss: 0.0231, Validation Loss: 0.2072
	--> Epoch [81/100], Loss: 0.1357, Validation Loss: 0.2055
	--> Epoch [82/100], Loss: 0.0710, Validation Loss: 0.2049
	--> Epoch [83/100], Loss: 0.2152, Validation Loss: 0.2040
	--> Epoch [84/100], Loss: 0.0191, Validation Loss: 0.2035
	--> Epoch [85/100], Loss: 0.1480, Validation Loss: 0.2020
	--> Epoch [86/100], Loss: 0.0149, Validation Loss: 0.2004
	--> Epoch [87/100], Loss: 0.1417, Validation Loss: 0.2009
	--> Epoch [88/100], Loss: 0.0793, Validation Loss: 0.1991
	--> Epoch [89/100], Loss: 0.0561, Validation Loss: 0.1988
	--> Epoch [90/100], Loss: 0.1412, Validation Loss: 0.1976
	--> Epoch [91/100], Loss: 0.0642, Validation Loss: 0.1983
	--> Epoch [92/100], Loss: 0.0388, Validation Loss: 0.1978
	--> Epoch [93/100], Loss: 0.0124, Validation Loss: 0.1960
	--> Epoch [94/100], Loss: 0.2319, Validation Loss: 0.1954
	--> Epoch [95/100], Loss: 0.0876, Validation Loss: 0.1939
	--> Epoch [96/100], Loss: 0.0363, Validation Loss: 0.1935
	--> Epoch [97/100], Loss: 0.0448, Validation Loss: 0.1907
	--> Epoch [98/100], Loss: 0.0170, Validation Loss: 0.1902
	--> Epoch [99/100], Loss: 0.0267, Validation Loss: 0.1889
	--> Epoch [100/100], Loss: 0.1548, Validation Loss: 0.1887
	--> Training for Fold 2 took 0.6646513938903809 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6237, Validation Loss: 0.7658
	--> Epoch [2/100], Loss: 0.5662, Validation Loss: 0.7583
	--> Epoch [3/100], Loss: 0.6085, Validation Loss: 0.7514
	--> Epoch [4/100], Loss: 0.5370, Validation Loss: 0.7455
	--> Epoch [5/100], Loss: 0.5483, Validation Loss: 0.7377
	--> Epoch [6/100], Loss: 0.5291, Validation Loss: 0.7331
	--> Epoch [7/100], Loss: 0.5195, Validation Loss: 0.7268
	--> Epoch [8/100], Loss: 0.4745, Validation Loss: 0.7203
	--> Epoch [9/100], Loss: 0.5046, Validation Loss: 0.7144
	--> Epoch [10/100], Loss: 0.4528, Validation Loss: 0.7090
	--> Epoch [11/100], Loss: 0.4287, Validation Loss: 0.7035
	--> Epoch [12/100], Loss: 0.4288, Validation Loss: 0.6969
	--> Epoch [13/100], Loss: 0.4903, Validation Loss: 0.6913
	--> Epoch [14/100], Loss: 0.4204, Validation Loss: 0.6855
	--> Epoch [15/100], Loss: 0.4253, Validation Loss: 0.6792
	--> Epoch [16/100], Loss: 0.4359, Validation Loss: 0.6735
	--> Epoch [17/100], Loss: 0.3471, Validation Loss: 0.6655
	--> Epoch [18/100], Loss: 0.3954, Validation Loss: 0.6595
	--> Epoch [19/100], Loss: 0.3915, Validation Loss: 0.6502
	--> Epoch [20/100], Loss: 0.4289, Validation Loss: 0.6407
	--> Epoch [21/100], Loss: 0.3983, Validation Loss: 0.6322
	--> Epoch [22/100], Loss: 0.4457, Validation Loss: 0.6260
	--> Epoch [23/100], Loss: 0.3242, Validation Loss: 0.6183
	--> Epoch [24/100], Loss: 0.2860, Validation Loss: 0.6088
	--> Epoch [25/100], Loss: 0.2820, Validation Loss: 0.6026
	--> Epoch [26/100], Loss: 0.2135, Validation Loss: 0.5943
	--> Epoch [27/100], Loss: 0.4117, Validation Loss: 0.5865
	--> Epoch [28/100], Loss: 0.2688, Validation Loss: 0.5754
	--> Epoch [29/100], Loss: 0.3783, Validation Loss: 0.5663
	--> Epoch [30/100], Loss: 0.4110, Validation Loss: 0.5581
	--> Epoch [31/100], Loss: 0.2582, Validation Loss: 0.5502
	--> Epoch [32/100], Loss: 0.3305, Validation Loss: 0.5449
	--> Epoch [33/100], Loss: 0.2602, Validation Loss: 0.5366
	--> Epoch [34/100], Loss: 0.1984, Validation Loss: 0.5317
	--> Epoch [35/100], Loss: 0.2487, Validation Loss: 0.5251
	--> Epoch [36/100], Loss: 0.2456, Validation Loss: 0.5194
	--> Epoch [37/100], Loss: 0.2457, Validation Loss: 0.5123
	--> Epoch [38/100], Loss: 0.2267, Validation Loss: 0.5067
	--> Epoch [39/100], Loss: 0.0996, Validation Loss: 0.5014
	--> Epoch [40/100], Loss: 0.1633, Validation Loss: 0.4968
	--> Epoch [41/100], Loss: 0.1004, Validation Loss: 0.4908
	--> Epoch [42/100], Loss: 0.2824, Validation Loss: 0.4855
	--> Epoch [43/100], Loss: 0.1408, Validation Loss: 0.4808
	--> Epoch [44/100], Loss: 0.2790, Validation Loss: 0.4811
	--> Epoch [45/100], Loss: 0.1404, Validation Loss: 0.4751
	--> Epoch [46/100], Loss: 0.1722, Validation Loss: 0.4689
	--> Epoch [47/100], Loss: 0.0895, Validation Loss: 0.4618
	--> Epoch [48/100], Loss: 0.1581, Validation Loss: 0.4558
	--> Epoch [49/100], Loss: 0.1452, Validation Loss: 0.4520
	--> Epoch [50/100], Loss: 0.0979, Validation Loss: 0.4483
	--> Epoch [51/100], Loss: 0.1411, Validation Loss: 0.4435
	--> Epoch [52/100], Loss: 0.1574, Validation Loss: 0.4402
	--> Epoch [53/100], Loss: 0.2277, Validation Loss: 0.4345
	--> Epoch [54/100], Loss: 0.1229, Validation Loss: 0.4296
	--> Epoch [55/100], Loss: 0.0755, Validation Loss: 0.4271
	--> Epoch [56/100], Loss: 0.1517, Validation Loss: 0.4219
	--> Epoch [57/100], Loss: 0.3236, Validation Loss: 0.4182
	--> Epoch [58/100], Loss: 0.0845, Validation Loss: 0.4150
	--> Epoch [59/100], Loss: 0.0974, Validation Loss: 0.4118
	--> Epoch [60/100], Loss: 0.0836, Validation Loss: 0.4087
	--> Epoch [61/100], Loss: 0.1280, Validation Loss: 0.4074
	--> Epoch [62/100], Loss: 0.1468, Validation Loss: 0.4052
	--> Epoch [63/100], Loss: 0.2454, Validation Loss: 0.4045
	--> Epoch [64/100], Loss: 0.1694, Validation Loss: 0.4079
	--> Epoch [65/100], Loss: 0.1047, Validation Loss: 0.4047
	--> Epoch [66/100], Loss: 0.0915, Validation Loss: 0.4010
	--> Epoch [67/100], Loss: 0.1774, Validation Loss: 0.3988
	--> Epoch [68/100], Loss: 0.1230, Validation Loss: 0.3978
	--> Epoch [69/100], Loss: 0.1168, Validation Loss: 0.3974
	--> Epoch [70/100], Loss: 0.0607, Validation Loss: 0.3950
	--> Epoch [71/100], Loss: 0.1320, Validation Loss: 0.3918
	--> Epoch [72/100], Loss: 0.1121, Validation Loss: 0.3902
	--> Epoch [73/100], Loss: 0.0943, Validation Loss: 0.3883
	--> Epoch [74/100], Loss: 0.1409, Validation Loss: 0.3874
	--> Epoch [75/100], Loss: 0.1388, Validation Loss: 0.3835
	--> Epoch [76/100], Loss: 0.0773, Validation Loss: 0.3829
	--> Epoch [77/100], Loss: 0.1214, Validation Loss: 0.3808
	--> Epoch [78/100], Loss: 0.1283, Validation Loss: 0.3795
	--> Epoch [79/100], Loss: 0.0379, Validation Loss: 0.3783
	--> Epoch [80/100], Loss: 0.2284, Validation Loss: 0.3783
	--> Epoch [81/100], Loss: 0.1732, Validation Loss: 0.3774
	--> Epoch [82/100], Loss: 0.0807, Validation Loss: 0.3774
	--> Epoch [83/100], Loss: 0.2534, Validation Loss: 0.3759
	--> Epoch [84/100], Loss: 0.1205, Validation Loss: 0.3749
	--> Epoch [85/100], Loss: 0.1194, Validation Loss: 0.3730
	--> Epoch [86/100], Loss: 0.1085, Validation Loss: 0.3723
	--> Epoch [87/100], Loss: 0.1450, Validation Loss: 0.3748
	--> Epoch [88/100], Loss: 0.2667, Validation Loss: 0.3755
	--> Epoch [89/100], Loss: 0.1619, Validation Loss: 0.3756
Early stopping
	--> Training for Fold 3 took 0.5246427059173584 sec, using 89 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6429, Validation Loss: 0.7029
	--> Epoch [2/100], Loss: 0.6448, Validation Loss: 0.6772
	--> Epoch [3/100], Loss: 0.6197, Validation Loss: 0.6667
	--> Epoch [4/100], Loss: 0.5832, Validation Loss: 0.6549
	--> Epoch [5/100], Loss: 0.5707, Validation Loss: 0.6458
	--> Epoch [6/100], Loss: 0.5611, Validation Loss: 0.6390
	--> Epoch [7/100], Loss: 0.4727, Validation Loss: 0.6287
	--> Epoch [8/100], Loss: 0.4448, Validation Loss: 0.6209
	--> Epoch [9/100], Loss: 0.5369, Validation Loss: 0.6167
	--> Epoch [10/100], Loss: 0.4075, Validation Loss: 0.6100
	--> Epoch [11/100], Loss: 0.4062, Validation Loss: 0.6055
	--> Epoch [12/100], Loss: 0.3374, Validation Loss: 0.6001
	--> Epoch [13/100], Loss: 0.3799, Validation Loss: 0.5928
	--> Epoch [14/100], Loss: 0.3419, Validation Loss: 0.5840
	--> Epoch [15/100], Loss: 0.3312, Validation Loss: 0.5792
	--> Epoch [16/100], Loss: 0.3643, Validation Loss: 0.5721
	--> Epoch [17/100], Loss: 0.3297, Validation Loss: 0.5648
	--> Epoch [18/100], Loss: 0.3567, Validation Loss: 0.5601
	--> Epoch [19/100], Loss: 0.4227, Validation Loss: 0.5551
	--> Epoch [20/100], Loss: 0.3995, Validation Loss: 0.5498
	--> Epoch [21/100], Loss: 0.3093, Validation Loss: 0.5434
	--> Epoch [22/100], Loss: 0.3374, Validation Loss: 0.5371
	--> Epoch [23/100], Loss: 0.3031, Validation Loss: 0.5343
	--> Epoch [24/100], Loss: 0.4282, Validation Loss: 0.5288
	--> Epoch [25/100], Loss: 0.2761, Validation Loss: 0.5218
	--> Epoch [26/100], Loss: 0.2475, Validation Loss: 0.5161
	--> Epoch [27/100], Loss: 0.3256, Validation Loss: 0.5090
	--> Epoch [28/100], Loss: 0.3862, Validation Loss: 0.5035
	--> Epoch [29/100], Loss: 0.3070, Validation Loss: 0.4958
	--> Epoch [30/100], Loss: 0.3317, Validation Loss: 0.4889
	--> Epoch [31/100], Loss: 0.2435, Validation Loss: 0.4849
	--> Epoch [32/100], Loss: 0.1735, Validation Loss: 0.4761
	--> Epoch [33/100], Loss: 0.4083, Validation Loss: 0.4728
	--> Epoch [34/100], Loss: 0.2773, Validation Loss: 0.4678
	--> Epoch [35/100], Loss: 0.3065, Validation Loss: 0.4584
	--> Epoch [36/100], Loss: 0.1683, Validation Loss: 0.4492
	--> Epoch [37/100], Loss: 0.2066, Validation Loss: 0.4426
	--> Epoch [38/100], Loss: 0.2578, Validation Loss: 0.4367
	--> Epoch [39/100], Loss: 0.4348, Validation Loss: 0.4341
	--> Epoch [40/100], Loss: 0.2540, Validation Loss: 0.4243
	--> Epoch [41/100], Loss: 0.1967, Validation Loss: 0.4198
	--> Epoch [42/100], Loss: 0.2719, Validation Loss: 0.4140
	--> Epoch [43/100], Loss: 0.1485, Validation Loss: 0.4087
	--> Epoch [44/100], Loss: 0.2374, Validation Loss: 0.4033
	--> Epoch [45/100], Loss: 0.1828, Validation Loss: 0.4037
	--> Epoch [46/100], Loss: 0.1682, Validation Loss: 0.3978
	--> Epoch [47/100], Loss: 0.1887, Validation Loss: 0.3946
	--> Epoch [48/100], Loss: 0.1556, Validation Loss: 0.3922
	--> Epoch [49/100], Loss: 0.1814, Validation Loss: 0.3891
	--> Epoch [50/100], Loss: 0.2077, Validation Loss: 0.3829
	--> Epoch [51/100], Loss: 0.1593, Validation Loss: 0.3785
	--> Epoch [52/100], Loss: 0.1724, Validation Loss: 0.3742
	--> Epoch [53/100], Loss: 0.1989, Validation Loss: 0.3692
	--> Epoch [54/100], Loss: 0.1095, Validation Loss: 0.3639
	--> Epoch [55/100], Loss: 0.1728, Validation Loss: 0.3598
	--> Epoch [56/100], Loss: 0.1669, Validation Loss: 0.3549
	--> Epoch [57/100], Loss: 0.2260, Validation Loss: 0.3571
	--> Epoch [58/100], Loss: 0.1942, Validation Loss: 0.3524
	--> Epoch [59/100], Loss: 0.1769, Validation Loss: 0.3479
	--> Epoch [60/100], Loss: 0.2066, Validation Loss: 0.3452
	--> Epoch [61/100], Loss: 0.1957, Validation Loss: 0.3426
	--> Epoch [62/100], Loss: 0.1509, Validation Loss: 0.3399
	--> Epoch [63/100], Loss: 0.2277, Validation Loss: 0.3367
	--> Epoch [64/100], Loss: 0.2262, Validation Loss: 0.3349
	--> Epoch [65/100], Loss: 0.1536, Validation Loss: 0.3320
	--> Epoch [66/100], Loss: 0.2118, Validation Loss: 0.3293
	--> Epoch [67/100], Loss: 0.1567, Validation Loss: 0.3254
	--> Epoch [68/100], Loss: 0.1669, Validation Loss: 0.3236
	--> Epoch [69/100], Loss: 0.1357, Validation Loss: 0.3199
	--> Epoch [70/100], Loss: 0.1598, Validation Loss: 0.3174
	--> Epoch [71/100], Loss: 0.1421, Validation Loss: 0.3210
	--> Epoch [72/100], Loss: 0.2549, Validation Loss: 0.3185
	--> Epoch [73/100], Loss: 0.1375, Validation Loss: 0.3154
	--> Epoch [74/100], Loss: 0.1175, Validation Loss: 0.3138
	--> Epoch [75/100], Loss: 0.2465, Validation Loss: 0.3111
	--> Epoch [76/100], Loss: 0.0997, Validation Loss: 0.3079
	--> Epoch [77/100], Loss: 0.0899, Validation Loss: 0.3048
	--> Epoch [78/100], Loss: 0.1732, Validation Loss: 0.3016
	--> Epoch [79/100], Loss: 0.1849, Validation Loss: 0.3009
	--> Epoch [80/100], Loss: 0.0889, Validation Loss: 0.2990
	--> Epoch [81/100], Loss: 0.1654, Validation Loss: 0.2968
	--> Epoch [82/100], Loss: 0.1331, Validation Loss: 0.2951
	--> Epoch [83/100], Loss: 0.1886, Validation Loss: 0.2921
	--> Epoch [84/100], Loss: 0.1819, Validation Loss: 0.2901
	--> Epoch [85/100], Loss: 0.2767, Validation Loss: 0.2879
	--> Epoch [86/100], Loss: 0.3162, Validation Loss: 0.2859
	--> Epoch [87/100], Loss: 0.2063, Validation Loss: 0.2837
	--> Epoch [88/100], Loss: 0.1605, Validation Loss: 0.2825
	--> Epoch [89/100], Loss: 0.2371, Validation Loss: 0.2799
	--> Epoch [90/100], Loss: 0.0871, Validation Loss: 0.2784
	--> Epoch [91/100], Loss: 0.2534, Validation Loss: 0.2767
	--> Epoch [92/100], Loss: 0.2882, Validation Loss: 0.2759
	--> Epoch [93/100], Loss: 0.1885, Validation Loss: 0.2748
	--> Epoch [94/100], Loss: 0.1163, Validation Loss: 0.2718
	--> Epoch [95/100], Loss: 0.1636, Validation Loss: 0.2698
	--> Epoch [96/100], Loss: 0.2377, Validation Loss: 0.2676
	--> Epoch [97/100], Loss: 0.2745, Validation Loss: 0.2658
	--> Epoch [98/100], Loss: 0.2860, Validation Loss: 0.2642
	--> Epoch [99/100], Loss: 0.1392, Validation Loss: 0.2730
	--> Epoch [100/100], Loss: 0.1997, Validation Loss: 0.2716
	--> Training for Fold 4 took 0.6128497123718262 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5703, Validation Loss: 0.8733
	--> Epoch [2/100], Loss: 0.5035, Validation Loss: 0.8605
	--> Epoch [3/100], Loss: 0.5002, Validation Loss: 0.8496
	--> Epoch [4/100], Loss: 0.5134, Validation Loss: 0.8380
	--> Epoch [5/100], Loss: 0.4813, Validation Loss: 0.8254
	--> Epoch [6/100], Loss: 0.3666, Validation Loss: 0.8128
	--> Epoch [7/100], Loss: 0.4904, Validation Loss: 0.8024
	--> Epoch [8/100], Loss: 0.4525, Validation Loss: 0.7952
	--> Epoch [9/100], Loss: 0.4045, Validation Loss: 0.7859
	--> Epoch [10/100], Loss: 0.3089, Validation Loss: 0.7767
	--> Epoch [11/100], Loss: 0.4046, Validation Loss: 0.7727
	--> Epoch [12/100], Loss: 0.3944, Validation Loss: 0.7640
	--> Epoch [13/100], Loss: 0.3256, Validation Loss: 0.7565
	--> Epoch [14/100], Loss: 0.2728, Validation Loss: 0.7533
	--> Epoch [15/100], Loss: 0.2920, Validation Loss: 0.7498
	--> Epoch [16/100], Loss: 0.2468, Validation Loss: 0.7477
	--> Epoch [17/100], Loss: 0.2781, Validation Loss: 0.7429
	--> Epoch [18/100], Loss: 0.3229, Validation Loss: 0.7389
	--> Epoch [19/100], Loss: 0.2450, Validation Loss: 0.7377
	--> Epoch [20/100], Loss: 0.3247, Validation Loss: 0.7339
	--> Epoch [21/100], Loss: 0.3778, Validation Loss: 0.7304
	--> Epoch [22/100], Loss: 0.1952, Validation Loss: 0.7311
	--> Epoch [23/100], Loss: 0.2998, Validation Loss: 0.7270
	--> Epoch [24/100], Loss: 0.2148, Validation Loss: 0.7271
	--> Epoch [25/100], Loss: 0.2183, Validation Loss: 0.7244
	--> Epoch [26/100], Loss: 0.1433, Validation Loss: 0.7187
	--> Epoch [27/100], Loss: 0.1857, Validation Loss: 0.7183
	--> Epoch [28/100], Loss: 0.1413, Validation Loss: 0.7121
	--> Epoch [29/100], Loss: 0.3640, Validation Loss: 0.7070
	--> Epoch [30/100], Loss: 0.1911, Validation Loss: 0.7031
	--> Epoch [31/100], Loss: 0.1959, Validation Loss: 0.7047
	--> Epoch [32/100], Loss: 0.2180, Validation Loss: 0.7029
	--> Epoch [33/100], Loss: 0.1717, Validation Loss: 0.7007
	--> Epoch [34/100], Loss: 0.1614, Validation Loss: 0.7031
	--> Epoch [35/100], Loss: 0.2004, Validation Loss: 0.7038
	--> Epoch [36/100], Loss: 0.1933, Validation Loss: 0.7034
Early stopping
	--> Training for Fold 5 took 0.22756123542785645 sec, using 36 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6313
	--> Final training Epoch [2/100], Loss: 0.6308
	--> Final training Epoch [3/100], Loss: 0.6694
	--> Final training Epoch [4/100], Loss: 0.6479
	--> Final training Epoch [5/100], Loss: 0.6152
	--> Final training Epoch [6/100], Loss: 0.5904
	--> Final training Epoch [7/100], Loss: 0.5480
	--> Final training Epoch [8/100], Loss: 0.5134
	--> Final training Epoch [9/100], Loss: 0.4781
	--> Final training Epoch [10/100], Loss: 0.4748
	--> Final training Epoch [11/100], Loss: 0.5040
	--> Final training Epoch [12/100], Loss: 0.5070
	--> Final training Epoch [13/100], Loss: 0.4805
	--> Final training Epoch [14/100], Loss: 0.4969
	--> Final training Epoch [15/100], Loss: 0.4278
	--> Final training Epoch [16/100], Loss: 0.4124
	--> Final training Epoch [17/100], Loss: 0.4373
	--> Final training Epoch [18/100], Loss: 0.4074
	--> Final training Epoch [19/100], Loss: 0.3910
	--> Final training Epoch [20/100], Loss: 0.3818
	--> Final training Epoch [21/100], Loss: 0.3774
	--> Final training Epoch [22/100], Loss: 0.4052
	--> Final training Epoch [23/100], Loss: 0.3252
	--> Final training Epoch [24/100], Loss: 0.3144
	--> Final training Epoch [25/100], Loss: 0.3301
	--> Final training Epoch [26/100], Loss: 0.3725
	--> Final training Epoch [27/100], Loss: 0.3288
	--> Final training Epoch [28/100], Loss: 0.3607
	--> Final training Epoch [29/100], Loss: 0.2877
	--> Final training Epoch [30/100], Loss: 0.4179
	--> Final training Epoch [31/100], Loss: 0.2959
	--> Final training Epoch [32/100], Loss: 0.3151
	--> Final training Epoch [33/100], Loss: 0.3230
	--> Final training Epoch [34/100], Loss: 0.2436
	--> Final training Epoch [35/100], Loss: 0.2794
	--> Final training Epoch [36/100], Loss: 0.2544
	--> Final training Epoch [37/100], Loss: 0.2602
	--> Final training Epoch [38/100], Loss: 0.2526
	--> Final training Epoch [39/100], Loss: 0.2611
	--> Final training Epoch [40/100], Loss: 0.2322
	--> Final training Epoch [41/100], Loss: 0.2639
	--> Final training Epoch [42/100], Loss: 0.2610
	--> Final training Epoch [43/100], Loss: 0.2801
	--> Final training Epoch [44/100], Loss: 0.2745
	--> Final training Epoch [45/100], Loss: 0.1872
	--> Final training Epoch [46/100], Loss: 0.2675
	--> Final training Epoch [47/100], Loss: 0.2239
	--> Final training Epoch [48/100], Loss: 0.1677
	--> Final training Epoch [49/100], Loss: 0.2177
	--> Final training Epoch [50/100], Loss: 0.1941
	--> Final training Epoch [51/100], Loss: 0.1755
	--> Final training Epoch [52/100], Loss: 0.1680
	--> Final training Epoch [53/100], Loss: 0.2044
	--> Final training Epoch [54/100], Loss: 0.1724
	--> Final training Epoch [55/100], Loss: 0.2155
	--> Final training Epoch [56/100], Loss: 0.2230
	--> Final training Epoch [57/100], Loss: 0.2562
	--> Final training Epoch [58/100], Loss: 0.2098
	--> Final training Epoch [59/100], Loss: 0.2312
	--> Final training Epoch [60/100], Loss: 0.1562
	--> Final training Epoch [61/100], Loss: 0.2557
	--> Final training Epoch [62/100], Loss: 0.1149
	--> Final training Epoch [63/100], Loss: 0.1986
	--> Final training Epoch [64/100], Loss: 0.1856
	--> Final training Epoch [65/100], Loss: 0.1424
	--> Final training Epoch [66/100], Loss: 0.1803
	--> Final training Epoch [67/100], Loss: 0.1731
	--> Final training Epoch [68/100], Loss: 0.1680
	--> Final training Epoch [69/100], Loss: 0.1870
	--> Final training Epoch [70/100], Loss: 0.1531
	--> Final training Epoch [71/100], Loss: 0.1710
	--> Final training Epoch [72/100], Loss: 0.1906
	--> Final training Epoch [73/100], Loss: 0.1632
	--> Final training Epoch [74/100], Loss: 0.2092
	--> Final training Epoch [75/100], Loss: 0.1562
	--> Final training Epoch [76/100], Loss: 0.1769
	--> Final training Epoch [77/100], Loss: 0.1360
	--> Final training Epoch [78/100], Loss: 0.1605
	--> Final training Epoch [79/100], Loss: 0.1309
	--> Final training Epoch [80/100], Loss: 0.0960
	--> Final training Epoch [81/100], Loss: 0.1484
	--> Final training Epoch [82/100], Loss: 0.1599
	--> Final training Epoch [83/100], Loss: 0.1021
	--> Final training Epoch [84/100], Loss: 0.1812
	--> Final training Epoch [85/100], Loss: 0.1745
	--> Final training Epoch [86/100], Loss: 0.1490
	--> Final training Epoch [87/100], Loss: 0.1408
	--> Final training Epoch [88/100], Loss: 0.1409
	--> Final training Epoch [89/100], Loss: 0.1858
	--> Final training Epoch [90/100], Loss: 0.1276
	--> Final training Epoch [91/100], Loss: 0.1625
	--> Final training Epoch [92/100], Loss: 0.0769
	--> Final training Epoch [93/100], Loss: 0.1104
	--> Final training Epoch [94/100], Loss: 0.1457
	--> Final training Epoch [95/100], Loss: 0.1224
	--> Final training Epoch [96/100], Loss: 0.1522
	--> Final training Epoch [97/100], Loss: 0.1178
	--> Final training Epoch [98/100], Loss: 0.0667
	--> Final training Epoch [99/100], Loss: 0.1770
	--> Final training Epoch [100/100], Loss: 0.1501

Final training took 0.5790302753448486 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.8493
	--> Final Precision: 0.7143
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7407
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8912, Validation Loss: 0.3541,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8158, Validation Loss: 0.4012,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7936, Validation Loss: 0.4778,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3941,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.4338,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7924, Validation Loss: 0.3776,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3724,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3910,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3593,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3785,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8374, Validation Loss: 0.4413,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8269, Validation Loss: 0.4511,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7626, Validation Loss: 0.4371,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8368, Validation Loss: 0.3866,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3715,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 0.3933,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3668,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3541

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7478, Validation Loss: 0.7973
	--> Epoch [2/100], Loss: 0.8293, Validation Loss: 0.7686
	--> Epoch [3/100], Loss: 0.8158, Validation Loss: 0.7380
	--> Epoch [4/100], Loss: 0.6840, Validation Loss: 0.7143
	--> Epoch [5/100], Loss: 0.5529, Validation Loss: 0.6985
	--> Epoch [6/100], Loss: 0.5708, Validation Loss: 0.6743
	--> Epoch [7/100], Loss: 0.5590, Validation Loss: 0.6551
	--> Epoch [8/100], Loss: 0.5722, Validation Loss: 0.6345
	--> Epoch [9/100], Loss: 0.7026, Validation Loss: 0.6205
	--> Epoch [10/100], Loss: 0.4283, Validation Loss: 0.6019
	--> Epoch [11/100], Loss: 0.4016, Validation Loss: 0.5912
	--> Epoch [12/100], Loss: 0.5545, Validation Loss: 0.5814
	--> Epoch [13/100], Loss: 0.4471, Validation Loss: 0.5703
	--> Epoch [14/100], Loss: 0.4619, Validation Loss: 0.5610
	--> Epoch [15/100], Loss: 0.3576, Validation Loss: 0.5469
	--> Epoch [16/100], Loss: 0.4648, Validation Loss: 0.5356
	--> Epoch [17/100], Loss: 0.5404, Validation Loss: 0.5322
	--> Epoch [18/100], Loss: 0.3573, Validation Loss: 0.5258
	--> Epoch [19/100], Loss: 0.3048, Validation Loss: 0.5165
	--> Epoch [20/100], Loss: 0.3064, Validation Loss: 0.5110
	--> Epoch [21/100], Loss: 0.3033, Validation Loss: 0.5029
	--> Epoch [22/100], Loss: 0.2636, Validation Loss: 0.4954
	--> Epoch [23/100], Loss: 0.2704, Validation Loss: 0.4909
	--> Epoch [24/100], Loss: 0.3062, Validation Loss: 0.4842
	--> Epoch [25/100], Loss: 0.3388, Validation Loss: 0.4822
	--> Epoch [26/100], Loss: 0.1249, Validation Loss: 0.4747
	--> Epoch [27/100], Loss: 0.3775, Validation Loss: 0.4673
	--> Epoch [28/100], Loss: 0.3571, Validation Loss: 0.4602
	--> Epoch [29/100], Loss: 0.2561, Validation Loss: 0.4540
	--> Epoch [30/100], Loss: 0.2196, Validation Loss: 0.4499
	--> Epoch [31/100], Loss: 0.2462, Validation Loss: 0.4454
	--> Epoch [32/100], Loss: 0.2127, Validation Loss: 0.4399
	--> Epoch [33/100], Loss: 0.2131, Validation Loss: 0.4367
	--> Epoch [34/100], Loss: 0.2053, Validation Loss: 0.4334
	--> Epoch [35/100], Loss: 0.2560, Validation Loss: 0.4306
	--> Epoch [36/100], Loss: 0.2057, Validation Loss: 0.4258
	--> Epoch [37/100], Loss: 0.2724, Validation Loss: 0.4227
	--> Epoch [38/100], Loss: 0.2241, Validation Loss: 0.4174
	--> Epoch [39/100], Loss: 0.2152, Validation Loss: 0.4139
	--> Epoch [40/100], Loss: 0.1965, Validation Loss: 0.4098
	--> Epoch [41/100], Loss: 0.3081, Validation Loss: 0.4041
	--> Epoch [42/100], Loss: 0.2466, Validation Loss: 0.4009
	--> Epoch [43/100], Loss: 0.3332, Validation Loss: 0.3963
	--> Epoch [44/100], Loss: 0.1601, Validation Loss: 0.3922
	--> Epoch [45/100], Loss: 0.1691, Validation Loss: 0.3866
	--> Epoch [46/100], Loss: 0.2520, Validation Loss: 0.3825
	--> Epoch [47/100], Loss: 0.1409, Validation Loss: 0.3786
	--> Epoch [48/100], Loss: 0.1802, Validation Loss: 0.3746
	--> Epoch [49/100], Loss: 0.1960, Validation Loss: 0.3710
	--> Epoch [50/100], Loss: 0.3565, Validation Loss: 0.3686
	--> Epoch [51/100], Loss: 0.0677, Validation Loss: 0.3650
	--> Epoch [52/100], Loss: 0.2969, Validation Loss: 0.3633
	--> Epoch [53/100], Loss: 0.1364, Validation Loss: 0.3603
	--> Epoch [54/100], Loss: 0.2010, Validation Loss: 0.3572
	--> Epoch [55/100], Loss: 0.1737, Validation Loss: 0.3549
	--> Epoch [56/100], Loss: 0.1878, Validation Loss: 0.3538
	--> Epoch [57/100], Loss: 0.2014, Validation Loss: 0.3523
	--> Epoch [58/100], Loss: 0.2126, Validation Loss: 0.3477
	--> Epoch [59/100], Loss: 0.2825, Validation Loss: 0.3452
	--> Epoch [60/100], Loss: 0.0817, Validation Loss: 0.3434
	--> Epoch [61/100], Loss: 0.0349, Validation Loss: 0.3410
	--> Epoch [62/100], Loss: 0.2091, Validation Loss: 0.3387
	--> Epoch [63/100], Loss: 0.0951, Validation Loss: 0.3363
	--> Epoch [64/100], Loss: 0.1196, Validation Loss: 0.3332
	--> Epoch [65/100], Loss: 0.0483, Validation Loss: 0.3310
	--> Epoch [66/100], Loss: 0.1823, Validation Loss: 0.3299
	--> Epoch [67/100], Loss: 0.1817, Validation Loss: 0.3260
	--> Epoch [68/100], Loss: 0.1797, Validation Loss: 0.3246
	--> Epoch [69/100], Loss: 0.1173, Validation Loss: 0.3232
	--> Epoch [70/100], Loss: 0.1240, Validation Loss: 0.3197
	--> Epoch [71/100], Loss: 0.1733, Validation Loss: 0.3186
	--> Epoch [72/100], Loss: 0.1181, Validation Loss: 0.3192
	--> Epoch [73/100], Loss: 0.2341, Validation Loss: 0.3164
	--> Epoch [74/100], Loss: 0.3008, Validation Loss: 0.3138
	--> Epoch [75/100], Loss: 0.1899, Validation Loss: 0.3110
	--> Epoch [76/100], Loss: 0.1141, Validation Loss: 0.3093
	--> Epoch [77/100], Loss: 0.2394, Validation Loss: 0.3070
	--> Epoch [78/100], Loss: 0.1561, Validation Loss: 0.3049
	--> Epoch [79/100], Loss: 0.2353, Validation Loss: 0.3038
	--> Epoch [80/100], Loss: 0.1039, Validation Loss: 0.3012
	--> Epoch [81/100], Loss: 0.1705, Validation Loss: 0.2993
	--> Epoch [82/100], Loss: 0.1713, Validation Loss: 0.2985
	--> Epoch [83/100], Loss: 0.1052, Validation Loss: 0.2971
	--> Epoch [84/100], Loss: 0.0884, Validation Loss: 0.2968
	--> Epoch [85/100], Loss: 0.2353, Validation Loss: 0.2960
	--> Epoch [86/100], Loss: 0.0944, Validation Loss: 0.2947
	--> Epoch [87/100], Loss: 0.0309, Validation Loss: 0.2934
	--> Epoch [88/100], Loss: 0.0864, Validation Loss: 0.2914
	--> Epoch [89/100], Loss: 0.2240, Validation Loss: 0.2887
	--> Epoch [90/100], Loss: 0.1662, Validation Loss: 0.2876
	--> Epoch [91/100], Loss: 0.1002, Validation Loss: 0.2862
	--> Epoch [92/100], Loss: 0.2245, Validation Loss: 0.2869
	--> Epoch [93/100], Loss: 0.2373, Validation Loss: 0.2866
	--> Epoch [94/100], Loss: 0.0838, Validation Loss: 0.2856
	--> Epoch [95/100], Loss: 0.1635, Validation Loss: 0.2848
	--> Epoch [96/100], Loss: 0.1673, Validation Loss: 0.2828
	--> Epoch [97/100], Loss: 0.1636, Validation Loss: 0.2808
	--> Epoch [98/100], Loss: 0.1627, Validation Loss: 0.2804
	--> Epoch [99/100], Loss: 0.0226, Validation Loss: 0.2790
	--> Epoch [100/100], Loss: 0.2219, Validation Loss: 0.2775
	--> Training for Fold 1 took 0.738487720489502 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6762, Validation Loss: 0.8704
	--> Epoch [2/100], Loss: 0.9056, Validation Loss: 0.8470
	--> Epoch [3/100], Loss: 0.6066, Validation Loss: 0.8196
	--> Epoch [4/100], Loss: 0.6852, Validation Loss: 0.7957
	--> Epoch [5/100], Loss: 0.6455, Validation Loss: 0.7653
	--> Epoch [6/100], Loss: 0.6251, Validation Loss: 0.7372
	--> Epoch [7/100], Loss: 0.6648, Validation Loss: 0.7191
	--> Epoch [8/100], Loss: 0.5425, Validation Loss: 0.6998
	--> Epoch [9/100], Loss: 0.4985, Validation Loss: 0.6816
	--> Epoch [10/100], Loss: 0.4308, Validation Loss: 0.6622
	--> Epoch [11/100], Loss: 0.4622, Validation Loss: 0.6365
	--> Epoch [12/100], Loss: 0.3661, Validation Loss: 0.6185
	--> Epoch [13/100], Loss: 0.4915, Validation Loss: 0.6049
	--> Epoch [14/100], Loss: 0.3075, Validation Loss: 0.5893
	--> Epoch [15/100], Loss: 0.3153, Validation Loss: 0.5761
	--> Epoch [16/100], Loss: 0.3890, Validation Loss: 0.5588
	--> Epoch [17/100], Loss: 0.2915, Validation Loss: 0.5487
	--> Epoch [18/100], Loss: 0.2639, Validation Loss: 0.5402
	--> Epoch [19/100], Loss: 0.2130, Validation Loss: 0.5317
	--> Epoch [20/100], Loss: 0.3978, Validation Loss: 0.5182
	--> Epoch [21/100], Loss: 0.2860, Validation Loss: 0.5055
	--> Epoch [22/100], Loss: 0.2596, Validation Loss: 0.4959
	--> Epoch [23/100], Loss: 0.2695, Validation Loss: 0.4870
	--> Epoch [24/100], Loss: 0.1804, Validation Loss: 0.4790
	--> Epoch [25/100], Loss: 0.2356, Validation Loss: 0.4693
	--> Epoch [26/100], Loss: 0.2437, Validation Loss: 0.4605
	--> Epoch [27/100], Loss: 0.2155, Validation Loss: 0.4541
	--> Epoch [28/100], Loss: 0.2558, Validation Loss: 0.4483
	--> Epoch [29/100], Loss: 0.3509, Validation Loss: 0.4414
	--> Epoch [30/100], Loss: 0.2119, Validation Loss: 0.4322
	--> Epoch [31/100], Loss: 0.3067, Validation Loss: 0.4284
	--> Epoch [32/100], Loss: 0.2819, Validation Loss: 0.4220
	--> Epoch [33/100], Loss: 0.1652, Validation Loss: 0.4174
	--> Epoch [34/100], Loss: 0.2486, Validation Loss: 0.4120
	--> Epoch [35/100], Loss: 0.2277, Validation Loss: 0.4067
	--> Epoch [36/100], Loss: 0.1801, Validation Loss: 0.4027
	--> Epoch [37/100], Loss: 0.1599, Validation Loss: 0.3963
	--> Epoch [38/100], Loss: 0.1772, Validation Loss: 0.3927
	--> Epoch [39/100], Loss: 0.1320, Validation Loss: 0.3875
	--> Epoch [40/100], Loss: 0.1980, Validation Loss: 0.3812
	--> Epoch [41/100], Loss: 0.2574, Validation Loss: 0.3782
	--> Epoch [42/100], Loss: 0.2549, Validation Loss: 0.3719
	--> Epoch [43/100], Loss: 0.1660, Validation Loss: 0.3647
	--> Epoch [44/100], Loss: 0.1616, Validation Loss: 0.3600
	--> Epoch [45/100], Loss: 0.1099, Validation Loss: 0.3583
	--> Epoch [46/100], Loss: 0.2369, Validation Loss: 0.3540
	--> Epoch [47/100], Loss: 0.2460, Validation Loss: 0.3505
	--> Epoch [48/100], Loss: 0.2087, Validation Loss: 0.3457
	--> Epoch [49/100], Loss: 0.2346, Validation Loss: 0.3442
	--> Epoch [50/100], Loss: 0.2407, Validation Loss: 0.3412
	--> Epoch [51/100], Loss: 0.0620, Validation Loss: 0.3390
	--> Epoch [52/100], Loss: 0.2451, Validation Loss: 0.3388
	--> Epoch [53/100], Loss: 0.2049, Validation Loss: 0.3349
	--> Epoch [54/100], Loss: 0.1121, Validation Loss: 0.3327
	--> Epoch [55/100], Loss: 0.1649, Validation Loss: 0.3291
	--> Epoch [56/100], Loss: 0.1066, Validation Loss: 0.3254
	--> Epoch [57/100], Loss: 0.0621, Validation Loss: 0.3226
	--> Epoch [58/100], Loss: 0.2385, Validation Loss: 0.3195
	--> Epoch [59/100], Loss: 0.1759, Validation Loss: 0.3187
	--> Epoch [60/100], Loss: 0.1920, Validation Loss: 0.3164
	--> Epoch [61/100], Loss: 0.0650, Validation Loss: 0.3142
	--> Epoch [62/100], Loss: 0.1551, Validation Loss: 0.3123
	--> Epoch [63/100], Loss: 0.1834, Validation Loss: 0.3104
	--> Epoch [64/100], Loss: 0.2362, Validation Loss: 0.3085
	--> Epoch [65/100], Loss: 0.1514, Validation Loss: 0.3057
	--> Epoch [66/100], Loss: 0.1088, Validation Loss: 0.3034
	--> Epoch [67/100], Loss: 0.0839, Validation Loss: 0.3004
	--> Epoch [68/100], Loss: 0.2320, Validation Loss: 0.2981
	--> Epoch [69/100], Loss: 0.0786, Validation Loss: 0.2962
	--> Epoch [70/100], Loss: 0.1135, Validation Loss: 0.2950
	--> Epoch [71/100], Loss: 0.1078, Validation Loss: 0.2924
	--> Epoch [72/100], Loss: 0.1146, Validation Loss: 0.2889
	--> Epoch [73/100], Loss: 0.1095, Validation Loss: 0.2883
	--> Epoch [74/100], Loss: 0.1470, Validation Loss: 0.2891
	--> Epoch [75/100], Loss: 0.2828, Validation Loss: 0.2898
	--> Epoch [76/100], Loss: 0.2763, Validation Loss: 0.2885
Early stopping
	--> Training for Fold 2 took 0.5815277099609375 sec, using 76 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6597, Validation Loss: 0.7233
	--> Epoch [2/100], Loss: 0.5451, Validation Loss: 0.7091
	--> Epoch [3/100], Loss: 0.6739, Validation Loss: 0.7004
	--> Epoch [4/100], Loss: 0.5567, Validation Loss: 0.6946
	--> Epoch [5/100], Loss: 0.5191, Validation Loss: 0.6886
	--> Epoch [6/100], Loss: 0.5323, Validation Loss: 0.6813
	--> Epoch [7/100], Loss: 0.3237, Validation Loss: 0.6769
	--> Epoch [8/100], Loss: 0.3187, Validation Loss: 0.6682
	--> Epoch [9/100], Loss: 0.4182, Validation Loss: 0.6572
	--> Epoch [10/100], Loss: 0.4898, Validation Loss: 0.6516
	--> Epoch [11/100], Loss: 0.4297, Validation Loss: 0.6494
	--> Epoch [12/100], Loss: 0.3346, Validation Loss: 0.6453
	--> Epoch [13/100], Loss: 0.2453, Validation Loss: 0.6399
	--> Epoch [14/100], Loss: 0.2277, Validation Loss: 0.6354
	--> Epoch [15/100], Loss: 0.2923, Validation Loss: 0.6300
	--> Epoch [16/100], Loss: 0.1536, Validation Loss: 0.6267
	--> Epoch [17/100], Loss: 0.3081, Validation Loss: 0.6200
	--> Epoch [18/100], Loss: 0.2700, Validation Loss: 0.6181
	--> Epoch [19/100], Loss: 0.2512, Validation Loss: 0.6144
	--> Epoch [20/100], Loss: 0.2359, Validation Loss: 0.6087
	--> Epoch [21/100], Loss: 0.2230, Validation Loss: 0.6029
	--> Epoch [22/100], Loss: 0.3008, Validation Loss: 0.5994
	--> Epoch [23/100], Loss: 0.1518, Validation Loss: 0.5974
	--> Epoch [24/100], Loss: 0.2409, Validation Loss: 0.5951
	--> Epoch [25/100], Loss: 0.1261, Validation Loss: 0.5901
	--> Epoch [26/100], Loss: 0.3607, Validation Loss: 0.5877
	--> Epoch [27/100], Loss: 0.2571, Validation Loss: 0.5876
	--> Epoch [28/100], Loss: 0.1981, Validation Loss: 0.5851
	--> Epoch [29/100], Loss: 0.3016, Validation Loss: 0.5846
	--> Epoch [30/100], Loss: 0.0976, Validation Loss: 0.5819
	--> Epoch [31/100], Loss: 0.0749, Validation Loss: 0.5795
	--> Epoch [32/100], Loss: 0.1364, Validation Loss: 0.5740
	--> Epoch [33/100], Loss: 0.1501, Validation Loss: 0.5721
	--> Epoch [34/100], Loss: 0.2120, Validation Loss: 0.5683
	--> Epoch [35/100], Loss: 0.2002, Validation Loss: 0.5671
	--> Epoch [36/100], Loss: 0.1083, Validation Loss: 0.5652
	--> Epoch [37/100], Loss: 0.1603, Validation Loss: 0.5634
	--> Epoch [38/100], Loss: 0.1854, Validation Loss: 0.5639
	--> Epoch [39/100], Loss: 0.1795, Validation Loss: 0.5626
	--> Epoch [40/100], Loss: 0.1623, Validation Loss: 0.5608
	--> Epoch [41/100], Loss: 0.1956, Validation Loss: 0.5592
	--> Epoch [42/100], Loss: 0.0524, Validation Loss: 0.5574
	--> Epoch [43/100], Loss: 0.2335, Validation Loss: 0.5574
	--> Epoch [44/100], Loss: 0.1081, Validation Loss: 0.5551
	--> Epoch [45/100], Loss: 0.0334, Validation Loss: 0.5516
	--> Epoch [46/100], Loss: 0.2286, Validation Loss: 0.5484
	--> Epoch [47/100], Loss: 0.2003, Validation Loss: 0.5482
	--> Epoch [48/100], Loss: 0.1710, Validation Loss: 0.5477
	--> Epoch [49/100], Loss: 0.1072, Validation Loss: 0.5460
	--> Epoch [50/100], Loss: 0.1448, Validation Loss: 0.5443
	--> Epoch [51/100], Loss: 0.1256, Validation Loss: 0.5418
	--> Epoch [52/100], Loss: 0.0974, Validation Loss: 0.5414
	--> Epoch [53/100], Loss: 0.1142, Validation Loss: 0.5412
	--> Epoch [54/100], Loss: 0.0788, Validation Loss: 0.5388
	--> Epoch [55/100], Loss: 0.1634, Validation Loss: 0.5401
	--> Epoch [56/100], Loss: 0.1922, Validation Loss: 0.5395
	--> Epoch [57/100], Loss: 0.1024, Validation Loss: 0.5375
	--> Epoch [58/100], Loss: 0.0782, Validation Loss: 0.5369
	--> Epoch [59/100], Loss: 0.1664, Validation Loss: 0.5368
	--> Epoch [60/100], Loss: 0.0960, Validation Loss: 0.5379
	--> Epoch [61/100], Loss: 0.1382, Validation Loss: 0.5376
	--> Epoch [62/100], Loss: 0.2107, Validation Loss: 0.5366
	--> Epoch [63/100], Loss: 0.2440, Validation Loss: 0.5364
	--> Epoch [64/100], Loss: 0.0898, Validation Loss: 0.5354
	--> Epoch [65/100], Loss: 0.0154, Validation Loss: 0.5354
	--> Epoch [66/100], Loss: 0.2390, Validation Loss: 0.5354
	--> Epoch [67/100], Loss: 0.0339, Validation Loss: 0.5359
Early stopping
	--> Training for Fold 3 took 0.5354492664337158 sec, using 67 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6695, Validation Loss: 0.8380
	--> Epoch [2/100], Loss: 0.6573, Validation Loss: 0.8262
	--> Epoch [3/100], Loss: 0.6284, Validation Loss: 0.8166
	--> Epoch [4/100], Loss: 0.6274, Validation Loss: 0.8029
	--> Epoch [5/100], Loss: 0.5709, Validation Loss: 0.7887
	--> Epoch [6/100], Loss: 0.6203, Validation Loss: 0.7737
	--> Epoch [7/100], Loss: 0.5581, Validation Loss: 0.7639
	--> Epoch [8/100], Loss: 0.5291, Validation Loss: 0.7516
	--> Epoch [9/100], Loss: 0.5013, Validation Loss: 0.7394
	--> Epoch [10/100], Loss: 0.4973, Validation Loss: 0.7259
	--> Epoch [11/100], Loss: 0.5428, Validation Loss: 0.7169
	--> Epoch [12/100], Loss: 0.3923, Validation Loss: 0.7067
	--> Epoch [13/100], Loss: 0.3898, Validation Loss: 0.6979
	--> Epoch [14/100], Loss: 0.4262, Validation Loss: 0.6871
	--> Epoch [15/100], Loss: 0.4012, Validation Loss: 0.6788
	--> Epoch [16/100], Loss: 0.3519, Validation Loss: 0.6695
	--> Epoch [17/100], Loss: 0.4092, Validation Loss: 0.6614
	--> Epoch [18/100], Loss: 0.4578, Validation Loss: 0.6562
	--> Epoch [19/100], Loss: 0.3974, Validation Loss: 0.6448
	--> Epoch [20/100], Loss: 0.3106, Validation Loss: 0.6379
	--> Epoch [21/100], Loss: 0.3256, Validation Loss: 0.6276
	--> Epoch [22/100], Loss: 0.3475, Validation Loss: 0.6179
	--> Epoch [23/100], Loss: 0.2845, Validation Loss: 0.6121
	--> Epoch [24/100], Loss: 0.2388, Validation Loss: 0.6077
	--> Epoch [25/100], Loss: 0.3084, Validation Loss: 0.6026
	--> Epoch [26/100], Loss: 0.2847, Validation Loss: 0.5963
	--> Epoch [27/100], Loss: 0.2286, Validation Loss: 0.5893
	--> Epoch [28/100], Loss: 0.3367, Validation Loss: 0.5817
	--> Epoch [29/100], Loss: 0.2159, Validation Loss: 0.5752
	--> Epoch [30/100], Loss: 0.2624, Validation Loss: 0.5727
	--> Epoch [31/100], Loss: 0.2175, Validation Loss: 0.5687
	--> Epoch [32/100], Loss: 0.1627, Validation Loss: 0.5628
	--> Epoch [33/100], Loss: 0.1076, Validation Loss: 0.5594
	--> Epoch [34/100], Loss: 0.2286, Validation Loss: 0.5550
	--> Epoch [35/100], Loss: 0.1141, Validation Loss: 0.5466
	--> Epoch [36/100], Loss: 0.2338, Validation Loss: 0.5404
	--> Epoch [37/100], Loss: 0.2253, Validation Loss: 0.5342
	--> Epoch [38/100], Loss: 0.1388, Validation Loss: 0.5313
	--> Epoch [39/100], Loss: 0.1973, Validation Loss: 0.5255
	--> Epoch [40/100], Loss: 0.1225, Validation Loss: 0.5197
	--> Epoch [41/100], Loss: 0.2462, Validation Loss: 0.5194
	--> Epoch [42/100], Loss: 0.1769, Validation Loss: 0.5149
	--> Epoch [43/100], Loss: 0.0865, Validation Loss: 0.5090
	--> Epoch [44/100], Loss: 0.1462, Validation Loss: 0.5057
	--> Epoch [45/100], Loss: 0.0772, Validation Loss: 0.5011
	--> Epoch [46/100], Loss: 0.2521, Validation Loss: 0.4984
	--> Epoch [47/100], Loss: 0.1810, Validation Loss: 0.4966
	--> Epoch [48/100], Loss: 0.1808, Validation Loss: 0.4891
	--> Epoch [49/100], Loss: 0.1351, Validation Loss: 0.4835
	--> Epoch [50/100], Loss: 0.1032, Validation Loss: 0.4827
	--> Epoch [51/100], Loss: 0.0634, Validation Loss: 0.4818
	--> Epoch [52/100], Loss: 0.0406, Validation Loss: 0.4800
	--> Epoch [53/100], Loss: 0.1306, Validation Loss: 0.4764
	--> Epoch [54/100], Loss: 0.1886, Validation Loss: 0.4725
	--> Epoch [55/100], Loss: 0.2165, Validation Loss: 0.4692
	--> Epoch [56/100], Loss: 0.1389, Validation Loss: 0.4674
	--> Epoch [57/100], Loss: 0.1401, Validation Loss: 0.4646
	--> Epoch [58/100], Loss: 0.1937, Validation Loss: 0.4668
	--> Epoch [59/100], Loss: 0.0711, Validation Loss: 0.4663
	--> Epoch [60/100], Loss: 0.1167, Validation Loss: 0.4628
	--> Epoch [61/100], Loss: 0.1661, Validation Loss: 0.4610
	--> Epoch [62/100], Loss: 0.1640, Validation Loss: 0.4596
	--> Epoch [63/100], Loss: 0.1701, Validation Loss: 0.4591
	--> Epoch [64/100], Loss: 0.1146, Validation Loss: 0.4557
	--> Epoch [65/100], Loss: 0.1085, Validation Loss: 0.4509
	--> Epoch [66/100], Loss: 0.1361, Validation Loss: 0.4496
	--> Epoch [67/100], Loss: 0.1833, Validation Loss: 0.4535
	--> Epoch [68/100], Loss: 0.0524, Validation Loss: 0.4530
	--> Epoch [69/100], Loss: 0.1591, Validation Loss: 0.4511
Early stopping
	--> Training for Fold 4 took 0.5762817859649658 sec, using 69 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7596, Validation Loss: 0.6782
	--> Epoch [2/100], Loss: 0.6851, Validation Loss: 0.6731
	--> Epoch [3/100], Loss: 0.6800, Validation Loss: 0.6664
	--> Epoch [4/100], Loss: 0.6310, Validation Loss: 0.6598
	--> Epoch [5/100], Loss: 0.5636, Validation Loss: 0.6547
	--> Epoch [6/100], Loss: 0.5408, Validation Loss: 0.6504
	--> Epoch [7/100], Loss: 0.5671, Validation Loss: 0.6476
	--> Epoch [8/100], Loss: 0.5148, Validation Loss: 0.6414
	--> Epoch [9/100], Loss: 0.5305, Validation Loss: 0.6378
	--> Epoch [10/100], Loss: 0.4905, Validation Loss: 0.6363
	--> Epoch [11/100], Loss: 0.4647, Validation Loss: 0.6340
	--> Epoch [12/100], Loss: 0.4271, Validation Loss: 0.6305
	--> Epoch [13/100], Loss: 0.4236, Validation Loss: 0.6302
	--> Epoch [14/100], Loss: 0.4350, Validation Loss: 0.6313
	--> Epoch [15/100], Loss: 0.4192, Validation Loss: 0.6292
	--> Epoch [16/100], Loss: 0.3324, Validation Loss: 0.6272
	--> Epoch [17/100], Loss: 0.2894, Validation Loss: 0.6261
	--> Epoch [18/100], Loss: 0.3001, Validation Loss: 0.6197
	--> Epoch [19/100], Loss: 0.3425, Validation Loss: 0.6200
	--> Epoch [20/100], Loss: 0.2888, Validation Loss: 0.6189
	--> Epoch [21/100], Loss: 0.3360, Validation Loss: 0.6207
	--> Epoch [22/100], Loss: 0.2448, Validation Loss: 0.6203
	--> Epoch [23/100], Loss: 0.2484, Validation Loss: 0.6226
Early stopping
	--> Training for Fold 5 took 0.1852104663848877 sec, using 23 epochs

Median number of epochs used: 69 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/69], Loss: 0.6838
	--> Final training Epoch [2/69], Loss: 0.7166
	--> Final training Epoch [3/69], Loss: 0.6888
	--> Final training Epoch [4/69], Loss: 0.6268
	--> Final training Epoch [5/69], Loss: 0.6223
	--> Final training Epoch [6/69], Loss: 0.6074
	--> Final training Epoch [7/69], Loss: 0.6026
	--> Final training Epoch [8/69], Loss: 0.5928
	--> Final training Epoch [9/69], Loss: 0.5562
	--> Final training Epoch [10/69], Loss: 0.5181
	--> Final training Epoch [11/69], Loss: 0.4921
	--> Final training Epoch [12/69], Loss: 0.5027
	--> Final training Epoch [13/69], Loss: 0.4864
	--> Final training Epoch [14/69], Loss: 0.4326
	--> Final training Epoch [15/69], Loss: 0.4910
	--> Final training Epoch [16/69], Loss: 0.4308
	--> Final training Epoch [17/69], Loss: 0.4639
	--> Final training Epoch [18/69], Loss: 0.4313
	--> Final training Epoch [19/69], Loss: 0.4356
	--> Final training Epoch [20/69], Loss: 0.4162
	--> Final training Epoch [21/69], Loss: 0.3874
	--> Final training Epoch [22/69], Loss: 0.3724
	--> Final training Epoch [23/69], Loss: 0.3327
	--> Final training Epoch [24/69], Loss: 0.3519
	--> Final training Epoch [25/69], Loss: 0.3264
	--> Final training Epoch [26/69], Loss: 0.4102
	--> Final training Epoch [27/69], Loss: 0.3914
	--> Final training Epoch [28/69], Loss: 0.3494
	--> Final training Epoch [29/69], Loss: 0.3337
	--> Final training Epoch [30/69], Loss: 0.3691
	--> Final training Epoch [31/69], Loss: 0.3494
	--> Final training Epoch [32/69], Loss: 0.3259
	--> Final training Epoch [33/69], Loss: 0.3126
	--> Final training Epoch [34/69], Loss: 0.3483
	--> Final training Epoch [35/69], Loss: 0.2835
	--> Final training Epoch [36/69], Loss: 0.2962
	--> Final training Epoch [37/69], Loss: 0.2908
	--> Final training Epoch [38/69], Loss: 0.3198
	--> Final training Epoch [39/69], Loss: 0.3234
	--> Final training Epoch [40/69], Loss: 0.3181
	--> Final training Epoch [41/69], Loss: 0.2603
	--> Final training Epoch [42/69], Loss: 0.2528
	--> Final training Epoch [43/69], Loss: 0.2893
	--> Final training Epoch [44/69], Loss: 0.2833
	--> Final training Epoch [45/69], Loss: 0.2656
	--> Final training Epoch [46/69], Loss: 0.3130
	--> Final training Epoch [47/69], Loss: 0.3199
	--> Final training Epoch [48/69], Loss: 0.2476
	--> Final training Epoch [49/69], Loss: 0.2451
	--> Final training Epoch [50/69], Loss: 0.2862
	--> Final training Epoch [51/69], Loss: 0.2429
	--> Final training Epoch [52/69], Loss: 0.2494
	--> Final training Epoch [53/69], Loss: 0.2569
	--> Final training Epoch [54/69], Loss: 0.2039
	--> Final training Epoch [55/69], Loss: 0.2182
	--> Final training Epoch [56/69], Loss: 0.2182
	--> Final training Epoch [57/69], Loss: 0.1958
	--> Final training Epoch [58/69], Loss: 0.2562
	--> Final training Epoch [59/69], Loss: 0.2268
	--> Final training Epoch [60/69], Loss: 0.2303
	--> Final training Epoch [61/69], Loss: 0.2448
	--> Final training Epoch [62/69], Loss: 0.2538
	--> Final training Epoch [63/69], Loss: 0.2105
	--> Final training Epoch [64/69], Loss: 0.2384
	--> Final training Epoch [65/69], Loss: 0.2060
	--> Final training Epoch [66/69], Loss: 0.2201
	--> Final training Epoch [67/69], Loss: 0.2211
	--> Final training Epoch [68/69], Loss: 0.2192
	--> Final training Epoch [69/69], Loss: 0.2216

Final training took 0.5827953815460205 sec

TESTING
	--> Testing took 0.0157 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 0.6848
	--> Final Precision: 0.7333
	--> Final Recall: 0.8462
	--> Final F1 Score: 0.7857
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3534,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3534
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3719,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3534

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7378, Validation Loss: 0.7269
	--> Epoch [2/100], Loss: 0.7115, Validation Loss: 0.7216
	--> Epoch [3/100], Loss: 0.7463, Validation Loss: 0.7106
	--> Epoch [4/100], Loss: 0.6550, Validation Loss: 0.7016
	--> Epoch [5/100], Loss: 0.6722, Validation Loss: 0.6925
	--> Epoch [6/100], Loss: 0.6349, Validation Loss: 0.6852
	--> Epoch [7/100], Loss: 0.6160, Validation Loss: 0.6738
	--> Epoch [8/100], Loss: 0.6146, Validation Loss: 0.6625
	--> Epoch [9/100], Loss: 0.5880, Validation Loss: 0.6518
	--> Epoch [10/100], Loss: 0.6481, Validation Loss: 0.6469
	--> Epoch [11/100], Loss: 0.6390, Validation Loss: 0.6419
	--> Epoch [12/100], Loss: 0.6432, Validation Loss: 0.6329
	--> Epoch [13/100], Loss: 0.6408, Validation Loss: 0.6254
	--> Epoch [14/100], Loss: 0.5818, Validation Loss: 0.6192
	--> Epoch [15/100], Loss: 0.5220, Validation Loss: 0.6122
	--> Epoch [16/100], Loss: 0.5547, Validation Loss: 0.6052
	--> Epoch [17/100], Loss: 0.5183, Validation Loss: 0.5968
	--> Epoch [18/100], Loss: 0.5233, Validation Loss: 0.5909
	--> Epoch [19/100], Loss: 0.5394, Validation Loss: 0.5823
	--> Epoch [20/100], Loss: 0.4883, Validation Loss: 0.5778
	--> Epoch [21/100], Loss: 0.5540, Validation Loss: 0.5685
	--> Epoch [22/100], Loss: 0.5506, Validation Loss: 0.5616
	--> Epoch [23/100], Loss: 0.5659, Validation Loss: 0.5574
	--> Epoch [24/100], Loss: 0.5119, Validation Loss: 0.5530
	--> Epoch [25/100], Loss: 0.4371, Validation Loss: 0.5462
	--> Epoch [26/100], Loss: 0.4807, Validation Loss: 0.5417
	--> Epoch [27/100], Loss: 0.4752, Validation Loss: 0.5371
	--> Epoch [28/100], Loss: 0.4918, Validation Loss: 0.5345
	--> Epoch [29/100], Loss: 0.4898, Validation Loss: 0.5278
	--> Epoch [30/100], Loss: 0.4444, Validation Loss: 0.5244
	--> Epoch [31/100], Loss: 0.4737, Validation Loss: 0.5202
	--> Epoch [32/100], Loss: 0.4164, Validation Loss: 0.5132
	--> Epoch [33/100], Loss: 0.4321, Validation Loss: 0.5087
	--> Epoch [34/100], Loss: 0.4910, Validation Loss: 0.5055
	--> Epoch [35/100], Loss: 0.4464, Validation Loss: 0.5015
	--> Epoch [36/100], Loss: 0.3623, Validation Loss: 0.4979
	--> Epoch [37/100], Loss: 0.3957, Validation Loss: 0.4944
	--> Epoch [38/100], Loss: 0.4620, Validation Loss: 0.4911
	--> Epoch [39/100], Loss: 0.4387, Validation Loss: 0.4870
	--> Epoch [40/100], Loss: 0.4269, Validation Loss: 0.4825
	--> Epoch [41/100], Loss: 0.3155, Validation Loss: 0.4780
	--> Epoch [42/100], Loss: 0.4146, Validation Loss: 0.4751
	--> Epoch [43/100], Loss: 0.3364, Validation Loss: 0.4707
	--> Epoch [44/100], Loss: 0.4065, Validation Loss: 0.4677
	--> Epoch [45/100], Loss: 0.3898, Validation Loss: 0.4673
	--> Epoch [46/100], Loss: 0.3865, Validation Loss: 0.4642
	--> Epoch [47/100], Loss: 0.3332, Validation Loss: 0.4619
	--> Epoch [48/100], Loss: 0.3278, Validation Loss: 0.4590
	--> Epoch [49/100], Loss: 0.3437, Validation Loss: 0.4559
	--> Epoch [50/100], Loss: 0.2769, Validation Loss: 0.4555
	--> Epoch [51/100], Loss: 0.3980, Validation Loss: 0.4522
	--> Epoch [52/100], Loss: 0.3835, Validation Loss: 0.4483
	--> Epoch [53/100], Loss: 0.4245, Validation Loss: 0.4484
	--> Epoch [54/100], Loss: 0.4708, Validation Loss: 0.4473
	--> Epoch [55/100], Loss: 0.3218, Validation Loss: 0.4455
	--> Epoch [56/100], Loss: 0.3804, Validation Loss: 0.4431
	--> Epoch [57/100], Loss: 0.4293, Validation Loss: 0.4404
	--> Epoch [58/100], Loss: 0.3277, Validation Loss: 0.4372
	--> Epoch [59/100], Loss: 0.3638, Validation Loss: 0.4398
	--> Epoch [60/100], Loss: 0.3668, Validation Loss: 0.4369
	--> Epoch [61/100], Loss: 0.3591, Validation Loss: 0.4381
	--> Epoch [62/100], Loss: 0.4184, Validation Loss: 0.4308
	--> Epoch [63/100], Loss: 0.3755, Validation Loss: 0.4290
	--> Epoch [64/100], Loss: 0.4727, Validation Loss: 0.4270
	--> Epoch [65/100], Loss: 0.2503, Validation Loss: 0.4234
	--> Epoch [66/100], Loss: 0.3495, Validation Loss: 0.4229
	--> Epoch [67/100], Loss: 0.3023, Validation Loss: 0.4220
	--> Epoch [68/100], Loss: 0.4526, Validation Loss: 0.4202
	--> Epoch [69/100], Loss: 0.3649, Validation Loss: 0.4192
	--> Epoch [70/100], Loss: 0.3565, Validation Loss: 0.4161
	--> Epoch [71/100], Loss: 0.3589, Validation Loss: 0.4143
	--> Epoch [72/100], Loss: 0.3044, Validation Loss: 0.4135
	--> Epoch [73/100], Loss: 0.3509, Validation Loss: 0.4138
	--> Epoch [74/100], Loss: 0.2956, Validation Loss: 0.4127
	--> Epoch [75/100], Loss: 0.4454, Validation Loss: 0.4103
	--> Epoch [76/100], Loss: 0.3906, Validation Loss: 0.4084
	--> Epoch [77/100], Loss: 0.2861, Validation Loss: 0.4053
	--> Epoch [78/100], Loss: 0.3425, Validation Loss: 0.4075
	--> Epoch [79/100], Loss: 0.3911, Validation Loss: 0.4054
	--> Epoch [80/100], Loss: 0.3689, Validation Loss: 0.4024
	--> Epoch [81/100], Loss: 0.3446, Validation Loss: 0.4010
	--> Epoch [82/100], Loss: 0.3316, Validation Loss: 0.3992
	--> Epoch [83/100], Loss: 0.2871, Validation Loss: 0.3986
	--> Epoch [84/100], Loss: 0.3717, Validation Loss: 0.3972
	--> Epoch [85/100], Loss: 0.4731, Validation Loss: 0.3971
	--> Epoch [86/100], Loss: 0.3456, Validation Loss: 0.3958
	--> Epoch [87/100], Loss: 0.3302, Validation Loss: 0.3935
	--> Epoch [88/100], Loss: 0.2761, Validation Loss: 0.3962
	--> Epoch [89/100], Loss: 0.3306, Validation Loss: 0.4001
	--> Epoch [90/100], Loss: 0.3291, Validation Loss: 0.4009
Early stopping
	--> Training for Fold 1 took 0.7002630233764648 sec, using 90 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6436, Validation Loss: 0.6609
	--> Epoch [2/100], Loss: 0.5847, Validation Loss: 0.6391
	--> Epoch [3/100], Loss: 0.5591, Validation Loss: 0.6250
	--> Epoch [4/100], Loss: 0.5764, Validation Loss: 0.6098
	--> Epoch [5/100], Loss: 0.6041, Validation Loss: 0.5977
	--> Epoch [6/100], Loss: 0.5032, Validation Loss: 0.5824
	--> Epoch [7/100], Loss: 0.5331, Validation Loss: 0.5735
	--> Epoch [8/100], Loss: 0.4763, Validation Loss: 0.5638
	--> Epoch [9/100], Loss: 0.4679, Validation Loss: 0.5549
	--> Epoch [10/100], Loss: 0.4449, Validation Loss: 0.5449
	--> Epoch [11/100], Loss: 0.5356, Validation Loss: 0.5379
	--> Epoch [12/100], Loss: 0.3853, Validation Loss: 0.5273
	--> Epoch [13/100], Loss: 0.4196, Validation Loss: 0.5213
	--> Epoch [14/100], Loss: 0.4171, Validation Loss: 0.5110
	--> Epoch [15/100], Loss: 0.3934, Validation Loss: 0.5033
	--> Epoch [16/100], Loss: 0.4160, Validation Loss: 0.4951
	--> Epoch [17/100], Loss: 0.3067, Validation Loss: 0.4876
	--> Epoch [18/100], Loss: 0.4075, Validation Loss: 0.4794
	--> Epoch [19/100], Loss: 0.2900, Validation Loss: 0.4696
	--> Epoch [20/100], Loss: 0.3051, Validation Loss: 0.4622
	--> Epoch [21/100], Loss: 0.4721, Validation Loss: 0.4541
	--> Epoch [22/100], Loss: 0.2830, Validation Loss: 0.4485
	--> Epoch [23/100], Loss: 0.3760, Validation Loss: 0.4392
	--> Epoch [24/100], Loss: 0.2656, Validation Loss: 0.4307
	--> Epoch [25/100], Loss: 0.2970, Validation Loss: 0.4225
	--> Epoch [26/100], Loss: 0.2639, Validation Loss: 0.4147
	--> Epoch [27/100], Loss: 0.3344, Validation Loss: 0.4071
	--> Epoch [28/100], Loss: 0.4314, Validation Loss: 0.4003
	--> Epoch [29/100], Loss: 0.1741, Validation Loss: 0.3931
	--> Epoch [30/100], Loss: 0.1871, Validation Loss: 0.3860
	--> Epoch [31/100], Loss: 0.2964, Validation Loss: 0.3798
	--> Epoch [32/100], Loss: 0.2723, Validation Loss: 0.3751
	--> Epoch [33/100], Loss: 0.3149, Validation Loss: 0.3715
	--> Epoch [34/100], Loss: 0.1054, Validation Loss: 0.3668
	--> Epoch [35/100], Loss: 0.2651, Validation Loss: 0.3641
	--> Epoch [36/100], Loss: 0.1987, Validation Loss: 0.3587
	--> Epoch [37/100], Loss: 0.0862, Validation Loss: 0.3547
	--> Epoch [38/100], Loss: 0.1483, Validation Loss: 0.3503
	--> Epoch [39/100], Loss: 0.1301, Validation Loss: 0.3464
	--> Epoch [40/100], Loss: 0.1553, Validation Loss: 0.3431
	--> Epoch [41/100], Loss: 0.2102, Validation Loss: 0.3402
	--> Epoch [42/100], Loss: 0.1108, Validation Loss: 0.3365
	--> Epoch [43/100], Loss: 0.1834, Validation Loss: 0.3321
	--> Epoch [44/100], Loss: 0.1045, Validation Loss: 0.3290
	--> Epoch [45/100], Loss: 0.1770, Validation Loss: 0.3261
	--> Epoch [46/100], Loss: 0.0353, Validation Loss: 0.3232
	--> Epoch [47/100], Loss: 0.1662, Validation Loss: 0.3197
	--> Epoch [48/100], Loss: 0.0865, Validation Loss: 0.3160
	--> Epoch [49/100], Loss: 0.2576, Validation Loss: 0.3118
	--> Epoch [50/100], Loss: 0.0814, Validation Loss: 0.3091
	--> Epoch [51/100], Loss: 0.1365, Validation Loss: 0.3058
	--> Epoch [52/100], Loss: 0.0529, Validation Loss: 0.3052
	--> Epoch [53/100], Loss: 0.2466, Validation Loss: 0.3031
	--> Epoch [54/100], Loss: 0.1120, Validation Loss: 0.3022
	--> Epoch [55/100], Loss: 0.0706, Validation Loss: 0.2993
	--> Epoch [56/100], Loss: 0.1308, Validation Loss: 0.2968
	--> Epoch [57/100], Loss: 0.0358, Validation Loss: 0.2939
	--> Epoch [58/100], Loss: 0.1823, Validation Loss: 0.2924
	--> Epoch [59/100], Loss: 0.1436, Validation Loss: 0.2916
	--> Epoch [60/100], Loss: 0.1341, Validation Loss: 0.2890
	--> Epoch [61/100], Loss: 0.0621, Validation Loss: 0.2863
	--> Epoch [62/100], Loss: 0.2509, Validation Loss: 0.2848
	--> Epoch [63/100], Loss: 0.1241, Validation Loss: 0.2816
	--> Epoch [64/100], Loss: 0.0420, Validation Loss: 0.2801
	--> Epoch [65/100], Loss: 0.2050, Validation Loss: 0.2777
	--> Epoch [66/100], Loss: 0.1835, Validation Loss: 0.2775
	--> Epoch [67/100], Loss: 0.1869, Validation Loss: 0.2736
	--> Epoch [68/100], Loss: 0.0772, Validation Loss: 0.2694
	--> Epoch [69/100], Loss: 0.1636, Validation Loss: 0.2681
	--> Epoch [70/100], Loss: 0.1012, Validation Loss: 0.2665
	--> Epoch [71/100], Loss: 0.0328, Validation Loss: 0.2652
	--> Epoch [72/100], Loss: 0.0364, Validation Loss: 0.2646
	--> Epoch [73/100], Loss: 0.1332, Validation Loss: 0.2631
	--> Epoch [74/100], Loss: 0.1139, Validation Loss: 0.2628
	--> Epoch [75/100], Loss: 0.0331, Validation Loss: 0.2620
	--> Epoch [76/100], Loss: 0.2586, Validation Loss: 0.2617
	--> Epoch [77/100], Loss: 0.2156, Validation Loss: 0.2575
	--> Epoch [78/100], Loss: 0.0807, Validation Loss: 0.2559
	--> Epoch [79/100], Loss: 0.1630, Validation Loss: 0.2553
	--> Epoch [80/100], Loss: 0.0836, Validation Loss: 0.2539
	--> Epoch [81/100], Loss: 0.2445, Validation Loss: 0.2503
	--> Epoch [82/100], Loss: 0.1624, Validation Loss: 0.2503
	--> Epoch [83/100], Loss: 0.1139, Validation Loss: 0.2485
	--> Epoch [84/100], Loss: 0.0927, Validation Loss: 0.2472
	--> Epoch [85/100], Loss: 0.2346, Validation Loss: 0.2456
	--> Epoch [86/100], Loss: 0.0107, Validation Loss: 0.2457
	--> Epoch [87/100], Loss: 0.1083, Validation Loss: 0.2444
	--> Epoch [88/100], Loss: 0.1141, Validation Loss: 0.2431
	--> Epoch [89/100], Loss: 0.0339, Validation Loss: 0.2430
	--> Epoch [90/100], Loss: 0.0198, Validation Loss: 0.2421
	--> Epoch [91/100], Loss: 0.1059, Validation Loss: 0.2413
	--> Epoch [92/100], Loss: 0.1763, Validation Loss: 0.2409
	--> Epoch [93/100], Loss: 0.1475, Validation Loss: 0.2405
	--> Epoch [94/100], Loss: 0.1582, Validation Loss: 0.2393
	--> Epoch [95/100], Loss: 0.1573, Validation Loss: 0.2386
	--> Epoch [96/100], Loss: 0.0857, Validation Loss: 0.2386
	--> Epoch [97/100], Loss: 0.1584, Validation Loss: 0.2371
	--> Epoch [98/100], Loss: 0.0156, Validation Loss: 0.2367
	--> Epoch [99/100], Loss: 0.0159, Validation Loss: 0.2355
	--> Epoch [100/100], Loss: 0.1463, Validation Loss: 0.2346
	--> Training for Fold 2 took 0.7862882614135742 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7004, Validation Loss: 0.6909
	--> Epoch [2/100], Loss: 0.6373, Validation Loss: 0.6746
	--> Epoch [3/100], Loss: 0.6020, Validation Loss: 0.6596
	--> Epoch [4/100], Loss: 0.4357, Validation Loss: 0.6395
	--> Epoch [5/100], Loss: 0.4520, Validation Loss: 0.6228
	--> Epoch [6/100], Loss: 0.3629, Validation Loss: 0.6111
	--> Epoch [7/100], Loss: 0.3953, Validation Loss: 0.6001
	--> Epoch [8/100], Loss: 0.4204, Validation Loss: 0.5875
	--> Epoch [9/100], Loss: 0.4605, Validation Loss: 0.5777
	--> Epoch [10/100], Loss: 0.3863, Validation Loss: 0.5677
	--> Epoch [11/100], Loss: 0.3922, Validation Loss: 0.5592
	--> Epoch [12/100], Loss: 0.3427, Validation Loss: 0.5503
	--> Epoch [13/100], Loss: 0.3651, Validation Loss: 0.5418
	--> Epoch [14/100], Loss: 0.2009, Validation Loss: 0.5336
	--> Epoch [15/100], Loss: 0.3029, Validation Loss: 0.5304
	--> Epoch [16/100], Loss: 0.3401, Validation Loss: 0.5218
	--> Epoch [17/100], Loss: 0.2428, Validation Loss: 0.5163
	--> Epoch [18/100], Loss: 0.1809, Validation Loss: 0.5067
	--> Epoch [19/100], Loss: 0.2860, Validation Loss: 0.5011
	--> Epoch [20/100], Loss: 0.3260, Validation Loss: 0.4932
	--> Epoch [21/100], Loss: 0.2262, Validation Loss: 0.4889
	--> Epoch [22/100], Loss: 0.2131, Validation Loss: 0.4831
	--> Epoch [23/100], Loss: 0.2565, Validation Loss: 0.4790
	--> Epoch [24/100], Loss: 0.3048, Validation Loss: 0.4722
	--> Epoch [25/100], Loss: 0.2849, Validation Loss: 0.4669
	--> Epoch [26/100], Loss: 0.2681, Validation Loss: 0.4623
	--> Epoch [27/100], Loss: 0.2109, Validation Loss: 0.4545
	--> Epoch [28/100], Loss: 0.2410, Validation Loss: 0.4504
	--> Epoch [29/100], Loss: 0.2352, Validation Loss: 0.4454
	--> Epoch [30/100], Loss: 0.2763, Validation Loss: 0.4424
	--> Epoch [31/100], Loss: 0.2514, Validation Loss: 0.4365
	--> Epoch [32/100], Loss: 0.0842, Validation Loss: 0.4329
	--> Epoch [33/100], Loss: 0.1097, Validation Loss: 0.4268
	--> Epoch [34/100], Loss: 0.1959, Validation Loss: 0.4222
	--> Epoch [35/100], Loss: 0.1887, Validation Loss: 0.4198
	--> Epoch [36/100], Loss: 0.1006, Validation Loss: 0.4166
	--> Epoch [37/100], Loss: 0.1496, Validation Loss: 0.4106
	--> Epoch [38/100], Loss: 0.0879, Validation Loss: 0.4070
	--> Epoch [39/100], Loss: 0.1546, Validation Loss: 0.4035
	--> Epoch [40/100], Loss: 0.2518, Validation Loss: 0.3975
	--> Epoch [41/100], Loss: 0.2297, Validation Loss: 0.3938
	--> Epoch [42/100], Loss: 0.1605, Validation Loss: 0.3893
	--> Epoch [43/100], Loss: 0.1824, Validation Loss: 0.3878
	--> Epoch [44/100], Loss: 0.0952, Validation Loss: 0.3819
	--> Epoch [45/100], Loss: 0.1513, Validation Loss: 0.3776
	--> Epoch [46/100], Loss: 0.3207, Validation Loss: 0.3739
	--> Epoch [47/100], Loss: 0.3243, Validation Loss: 0.3723
	--> Epoch [48/100], Loss: 0.3451, Validation Loss: 0.3691
	--> Epoch [49/100], Loss: 0.1791, Validation Loss: 0.3665
	--> Epoch [50/100], Loss: 0.1793, Validation Loss: 0.3647
	--> Epoch [51/100], Loss: 0.0595, Validation Loss: 0.3615
	--> Epoch [52/100], Loss: 0.1733, Validation Loss: 0.3602
	--> Epoch [53/100], Loss: 0.1497, Validation Loss: 0.3584
	--> Epoch [54/100], Loss: 0.0828, Validation Loss: 0.3569
	--> Epoch [55/100], Loss: 0.1058, Validation Loss: 0.3556
	--> Epoch [56/100], Loss: 0.2875, Validation Loss: 0.3535
	--> Epoch [57/100], Loss: 0.1833, Validation Loss: 0.3507
	--> Epoch [58/100], Loss: 0.1626, Validation Loss: 0.3472
	--> Epoch [59/100], Loss: 0.0923, Validation Loss: 0.3443
	--> Epoch [60/100], Loss: 0.1061, Validation Loss: 0.3434
	--> Epoch [61/100], Loss: 0.2310, Validation Loss: 0.3421
	--> Epoch [62/100], Loss: 0.2051, Validation Loss: 0.3394
	--> Epoch [63/100], Loss: 0.2210, Validation Loss: 0.3377
	--> Epoch [64/100], Loss: 0.1647, Validation Loss: 0.3365
	--> Epoch [65/100], Loss: 0.1777, Validation Loss: 0.3353
	--> Epoch [66/100], Loss: 0.2761, Validation Loss: 0.3325
	--> Epoch [67/100], Loss: 0.1425, Validation Loss: 0.3300
	--> Epoch [68/100], Loss: 0.1378, Validation Loss: 0.3279
	--> Epoch [69/100], Loss: 0.0804, Validation Loss: 0.3265
	--> Epoch [70/100], Loss: 0.2138, Validation Loss: 0.3256
	--> Epoch [71/100], Loss: 0.2654, Validation Loss: 0.3240
	--> Epoch [72/100], Loss: 0.1525, Validation Loss: 0.3240
	--> Epoch [73/100], Loss: 0.2101, Validation Loss: 0.3238
	--> Epoch [74/100], Loss: 0.1512, Validation Loss: 0.3218
	--> Epoch [75/100], Loss: 0.2048, Validation Loss: 0.3207
	--> Epoch [76/100], Loss: 0.0315, Validation Loss: 0.3209
	--> Epoch [77/100], Loss: 0.0342, Validation Loss: 0.3196
	--> Epoch [78/100], Loss: 0.0284, Validation Loss: 0.3191
	--> Epoch [79/100], Loss: 0.2073, Validation Loss: 0.3181
	--> Epoch [80/100], Loss: 0.1516, Validation Loss: 0.3162
	--> Epoch [81/100], Loss: 0.2207, Validation Loss: 0.3157
	--> Epoch [82/100], Loss: 0.1422, Validation Loss: 0.3146
	--> Epoch [83/100], Loss: 0.0900, Validation Loss: 0.3140
	--> Epoch [84/100], Loss: 0.1495, Validation Loss: 0.3161
	--> Epoch [85/100], Loss: 0.0927, Validation Loss: 0.3141
	--> Epoch [86/100], Loss: 0.0812, Validation Loss: 0.3125
	--> Epoch [87/100], Loss: 0.1991, Validation Loss: 0.3132
	--> Epoch [88/100], Loss: 0.0837, Validation Loss: 0.3122
	--> Epoch [89/100], Loss: 0.1557, Validation Loss: 0.3105
	--> Epoch [90/100], Loss: 0.0803, Validation Loss: 0.3106
	--> Epoch [91/100], Loss: 0.0781, Validation Loss: 0.3102
	--> Epoch [92/100], Loss: 0.0235, Validation Loss: 0.3099
	--> Epoch [93/100], Loss: 0.1355, Validation Loss: 0.3084
	--> Epoch [94/100], Loss: 0.2123, Validation Loss: 0.3068
	--> Epoch [95/100], Loss: 0.0308, Validation Loss: 0.3061
	--> Epoch [96/100], Loss: 0.0155, Validation Loss: 0.3053
	--> Epoch [97/100], Loss: 0.0848, Validation Loss: 0.3059
	--> Epoch [98/100], Loss: 0.1901, Validation Loss: 0.3050
	--> Epoch [99/100], Loss: 0.0130, Validation Loss: 0.3045
	--> Epoch [100/100], Loss: 0.0749, Validation Loss: 0.3039
	--> Training for Fold 3 took 0.7870581150054932 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7773, Validation Loss: 0.5762
	--> Epoch [2/100], Loss: 0.8977, Validation Loss: 0.5699
	--> Epoch [3/100], Loss: 0.7414, Validation Loss: 0.5647
	--> Epoch [4/100], Loss: 0.7411, Validation Loss: 0.5629
	--> Epoch [5/100], Loss: 0.7838, Validation Loss: 0.5544
	--> Epoch [6/100], Loss: 0.7072, Validation Loss: 0.5448
	--> Epoch [7/100], Loss: 0.6749, Validation Loss: 0.5377
	--> Epoch [8/100], Loss: 0.6700, Validation Loss: 0.5357
	--> Epoch [9/100], Loss: 0.6909, Validation Loss: 0.5332
	--> Epoch [10/100], Loss: 0.6043, Validation Loss: 0.5261
	--> Epoch [11/100], Loss: 0.5721, Validation Loss: 0.5201
	--> Epoch [12/100], Loss: 0.5465, Validation Loss: 0.5157
	--> Epoch [13/100], Loss: 0.5892, Validation Loss: 0.5137
	--> Epoch [14/100], Loss: 0.4588, Validation Loss: 0.5085
	--> Epoch [15/100], Loss: 0.5438, Validation Loss: 0.5050
	--> Epoch [16/100], Loss: 0.5111, Validation Loss: 0.5005
	--> Epoch [17/100], Loss: 0.5767, Validation Loss: 0.4951
	--> Epoch [18/100], Loss: 0.4423, Validation Loss: 0.4915
	--> Epoch [19/100], Loss: 0.4138, Validation Loss: 0.4840
	--> Epoch [20/100], Loss: 0.3563, Validation Loss: 0.4812
	--> Epoch [21/100], Loss: 0.3590, Validation Loss: 0.4768
	--> Epoch [22/100], Loss: 0.5481, Validation Loss: 0.4713
	--> Epoch [23/100], Loss: 0.2856, Validation Loss: 0.4652
	--> Epoch [24/100], Loss: 0.2410, Validation Loss: 0.4614
	--> Epoch [25/100], Loss: 0.2599, Validation Loss: 0.4592
	--> Epoch [26/100], Loss: 0.4688, Validation Loss: 0.4535
	--> Epoch [27/100], Loss: 0.4172, Validation Loss: 0.4470
	--> Epoch [28/100], Loss: 0.3125, Validation Loss: 0.4401
	--> Epoch [29/100], Loss: 0.3409, Validation Loss: 0.4335
	--> Epoch [30/100], Loss: 0.3689, Validation Loss: 0.4283
	--> Epoch [31/100], Loss: 0.2923, Validation Loss: 0.4201
	--> Epoch [32/100], Loss: 0.3375, Validation Loss: 0.4195
	--> Epoch [33/100], Loss: 0.2692, Validation Loss: 0.4125
	--> Epoch [34/100], Loss: 0.3314, Validation Loss: 0.4079
	--> Epoch [35/100], Loss: 0.2245, Validation Loss: 0.4017
	--> Epoch [36/100], Loss: 0.2263, Validation Loss: 0.3977
	--> Epoch [37/100], Loss: 0.3723, Validation Loss: 0.3962
	--> Epoch [38/100], Loss: 0.2770, Validation Loss: 0.3918
	--> Epoch [39/100], Loss: 0.3235, Validation Loss: 0.3832
	--> Epoch [40/100], Loss: 0.1787, Validation Loss: 0.3829
	--> Epoch [41/100], Loss: 0.1934, Validation Loss: 0.3771
	--> Epoch [42/100], Loss: 0.3849, Validation Loss: 0.3734
	--> Epoch [43/100], Loss: 0.1439, Validation Loss: 0.3693
	--> Epoch [44/100], Loss: 0.2109, Validation Loss: 0.3691
	--> Epoch [45/100], Loss: 0.2753, Validation Loss: 0.3674
	--> Epoch [46/100], Loss: 0.2331, Validation Loss: 0.3638
	--> Epoch [47/100], Loss: 0.4346, Validation Loss: 0.3612
	--> Epoch [48/100], Loss: 0.1721, Validation Loss: 0.3560
	--> Epoch [49/100], Loss: 0.1747, Validation Loss: 0.3562
	--> Epoch [50/100], Loss: 0.3642, Validation Loss: 0.3519
	--> Epoch [51/100], Loss: 0.3457, Validation Loss: 0.3486
	--> Epoch [52/100], Loss: 0.1793, Validation Loss: 0.3455
	--> Epoch [53/100], Loss: 0.2803, Validation Loss: 0.3408
	--> Epoch [54/100], Loss: 0.2133, Validation Loss: 0.3378
	--> Epoch [55/100], Loss: 0.2438, Validation Loss: 0.3351
	--> Epoch [56/100], Loss: 0.2930, Validation Loss: 0.3313
	--> Epoch [57/100], Loss: 0.3266, Validation Loss: 0.3331
	--> Epoch [58/100], Loss: 0.2001, Validation Loss: 0.3303
	--> Epoch [59/100], Loss: 0.5241, Validation Loss: 0.3260
	--> Epoch [60/100], Loss: 0.1076, Validation Loss: 0.3227
	--> Epoch [61/100], Loss: 0.3070, Validation Loss: 0.3187
	--> Epoch [62/100], Loss: 0.2435, Validation Loss: 0.3159
	--> Epoch [63/100], Loss: 0.1207, Validation Loss: 0.3122
	--> Epoch [64/100], Loss: 0.3100, Validation Loss: 0.3144
	--> Epoch [65/100], Loss: 0.2826, Validation Loss: 0.3169
	--> Epoch [66/100], Loss: 0.1501, Validation Loss: 0.3138
Early stopping
	--> Training for Fold 4 took 0.503429651260376 sec, using 66 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4660, Validation Loss: 0.8663
	--> Epoch [2/100], Loss: 0.4233, Validation Loss: 0.8592
	--> Epoch [3/100], Loss: 0.4457, Validation Loss: 0.8493
	--> Epoch [4/100], Loss: 0.4157, Validation Loss: 0.8414
	--> Epoch [5/100], Loss: 0.4042, Validation Loss: 0.8376
	--> Epoch [6/100], Loss: 0.4257, Validation Loss: 0.8300
	--> Epoch [7/100], Loss: 0.3818, Validation Loss: 0.8268
	--> Epoch [8/100], Loss: 0.3057, Validation Loss: 0.8222
	--> Epoch [9/100], Loss: 0.3883, Validation Loss: 0.8192
	--> Epoch [10/100], Loss: 0.3701, Validation Loss: 0.8133
	--> Epoch [11/100], Loss: 0.3184, Validation Loss: 0.8116
	--> Epoch [12/100], Loss: 0.2114, Validation Loss: 0.8097
	--> Epoch [13/100], Loss: 0.3480, Validation Loss: 0.8106
	--> Epoch [14/100], Loss: 0.3330, Validation Loss: 0.8064
	--> Epoch [15/100], Loss: 0.2358, Validation Loss: 0.8066
	--> Epoch [16/100], Loss: 0.2864, Validation Loss: 0.8005
	--> Epoch [17/100], Loss: 0.2162, Validation Loss: 0.7967
	--> Epoch [18/100], Loss: 0.2661, Validation Loss: 0.7927
	--> Epoch [19/100], Loss: 0.2911, Validation Loss: 0.7922
	--> Epoch [20/100], Loss: 0.3243, Validation Loss: 0.7917
	--> Epoch [21/100], Loss: 0.2877, Validation Loss: 0.7897
	--> Epoch [22/100], Loss: 0.2522, Validation Loss: 0.7888
	--> Epoch [23/100], Loss: 0.2162, Validation Loss: 0.7863
	--> Epoch [24/100], Loss: 0.2491, Validation Loss: 0.7855
	--> Epoch [25/100], Loss: 0.2718, Validation Loss: 0.7849
	--> Epoch [26/100], Loss: 0.2209, Validation Loss: 0.7824
	--> Epoch [27/100], Loss: 0.1822, Validation Loss: 0.7796
	--> Epoch [28/100], Loss: 0.2901, Validation Loss: 0.7760
	--> Epoch [29/100], Loss: 0.2331, Validation Loss: 0.7727
	--> Epoch [30/100], Loss: 0.1605, Validation Loss: 0.7712
	--> Epoch [31/100], Loss: 0.1550, Validation Loss: 0.7690
	--> Epoch [32/100], Loss: 0.2733, Validation Loss: 0.7693
	--> Epoch [33/100], Loss: 0.1975, Validation Loss: 0.7679
	--> Epoch [34/100], Loss: 0.1646, Validation Loss: 0.7701
	--> Epoch [35/100], Loss: 0.2286, Validation Loss: 0.7700
	--> Epoch [36/100], Loss: 0.2958, Validation Loss: 0.7672
	--> Epoch [37/100], Loss: 0.2316, Validation Loss: 0.7641
	--> Epoch [38/100], Loss: 0.2060, Validation Loss: 0.7643
	--> Epoch [39/100], Loss: 0.2360, Validation Loss: 0.7658
	--> Epoch [40/100], Loss: 0.1303, Validation Loss: 0.7601
	--> Epoch [41/100], Loss: 0.1268, Validation Loss: 0.7588
	--> Epoch [42/100], Loss: 0.1528, Validation Loss: 0.7586
	--> Epoch [43/100], Loss: 0.2047, Validation Loss: 0.7582
	--> Epoch [44/100], Loss: 0.2203, Validation Loss: 0.7586
	--> Epoch [45/100], Loss: 0.1688, Validation Loss: 0.7646
	--> Epoch [46/100], Loss: 0.1141, Validation Loss: 0.7631
Early stopping
	--> Training for Fold 5 took 0.33260178565979004 sec, using 46 epochs

Median number of epochs used: 90 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/90], Loss: 0.6719
	--> Final training Epoch [2/90], Loss: 0.7315
	--> Final training Epoch [3/90], Loss: 0.6677
	--> Final training Epoch [4/90], Loss: 0.6183
	--> Final training Epoch [5/90], Loss: 0.5913
	--> Final training Epoch [6/90], Loss: 0.5834
	--> Final training Epoch [7/90], Loss: 0.5667
	--> Final training Epoch [8/90], Loss: 0.5566
	--> Final training Epoch [9/90], Loss: 0.5306
	--> Final training Epoch [10/90], Loss: 0.5223
	--> Final training Epoch [11/90], Loss: 0.5168
	--> Final training Epoch [12/90], Loss: 0.5146
	--> Final training Epoch [13/90], Loss: 0.4947
	--> Final training Epoch [14/90], Loss: 0.4606
	--> Final training Epoch [15/90], Loss: 0.4488
	--> Final training Epoch [16/90], Loss: 0.4171
	--> Final training Epoch [17/90], Loss: 0.4633
	--> Final training Epoch [18/90], Loss: 0.4767
	--> Final training Epoch [19/90], Loss: 0.3919
	--> Final training Epoch [20/90], Loss: 0.4509
	--> Final training Epoch [21/90], Loss: 0.3993
	--> Final training Epoch [22/90], Loss: 0.4342
	--> Final training Epoch [23/90], Loss: 0.3956
	--> Final training Epoch [24/90], Loss: 0.3973
	--> Final training Epoch [25/90], Loss: 0.4051
	--> Final training Epoch [26/90], Loss: 0.3244
	--> Final training Epoch [27/90], Loss: 0.3320
	--> Final training Epoch [28/90], Loss: 0.3651
	--> Final training Epoch [29/90], Loss: 0.3153
	--> Final training Epoch [30/90], Loss: 0.3058
	--> Final training Epoch [31/90], Loss: 0.3207
	--> Final training Epoch [32/90], Loss: 0.3704
	--> Final training Epoch [33/90], Loss: 0.3196
	--> Final training Epoch [34/90], Loss: 0.2945
	--> Final training Epoch [35/90], Loss: 0.2897
	--> Final training Epoch [36/90], Loss: 0.1989
	--> Final training Epoch [37/90], Loss: 0.2754
	--> Final training Epoch [38/90], Loss: 0.2410
	--> Final training Epoch [39/90], Loss: 0.2689
	--> Final training Epoch [40/90], Loss: 0.2051
	--> Final training Epoch [41/90], Loss: 0.2248
	--> Final training Epoch [42/90], Loss: 0.3128
	--> Final training Epoch [43/90], Loss: 0.1904
	--> Final training Epoch [44/90], Loss: 0.2371
	--> Final training Epoch [45/90], Loss: 0.2379
	--> Final training Epoch [46/90], Loss: 0.2525
	--> Final training Epoch [47/90], Loss: 0.2203
	--> Final training Epoch [48/90], Loss: 0.2320
	--> Final training Epoch [49/90], Loss: 0.2289
	--> Final training Epoch [50/90], Loss: 0.2112
	--> Final training Epoch [51/90], Loss: 0.1809
	--> Final training Epoch [52/90], Loss: 0.1471
	--> Final training Epoch [53/90], Loss: 0.2279
	--> Final training Epoch [54/90], Loss: 0.2032
	--> Final training Epoch [55/90], Loss: 0.2955
	--> Final training Epoch [56/90], Loss: 0.1810
	--> Final training Epoch [57/90], Loss: 0.1411
	--> Final training Epoch [58/90], Loss: 0.2100
	--> Final training Epoch [59/90], Loss: 0.0919
	--> Final training Epoch [60/90], Loss: 0.1776
	--> Final training Epoch [61/90], Loss: 0.1329
	--> Final training Epoch [62/90], Loss: 0.1184
	--> Final training Epoch [63/90], Loss: 0.1836
	--> Final training Epoch [64/90], Loss: 0.1668
	--> Final training Epoch [65/90], Loss: 0.1211
	--> Final training Epoch [66/90], Loss: 0.2014
	--> Final training Epoch [67/90], Loss: 0.1625
	--> Final training Epoch [68/90], Loss: 0.1898
	--> Final training Epoch [69/90], Loss: 0.1349
	--> Final training Epoch [70/90], Loss: 0.1654
	--> Final training Epoch [71/90], Loss: 0.1196
	--> Final training Epoch [72/90], Loss: 0.1350
	--> Final training Epoch [73/90], Loss: 0.1571
	--> Final training Epoch [74/90], Loss: 0.2807
	--> Final training Epoch [75/90], Loss: 0.1661
	--> Final training Epoch [76/90], Loss: 0.2119
	--> Final training Epoch [77/90], Loss: 0.1110
	--> Final training Epoch [78/90], Loss: 0.2433
	--> Final training Epoch [79/90], Loss: 0.2657
	--> Final training Epoch [80/90], Loss: 0.1598
	--> Final training Epoch [81/90], Loss: 0.1139
	--> Final training Epoch [82/90], Loss: 0.1208
	--> Final training Epoch [83/90], Loss: 0.2005
	--> Final training Epoch [84/90], Loss: 0.1630
	--> Final training Epoch [85/90], Loss: 0.1247
	--> Final training Epoch [86/90], Loss: 0.1957
	--> Final training Epoch [87/90], Loss: 0.2000
	--> Final training Epoch [88/90], Loss: 0.1203
	--> Final training Epoch [89/90], Loss: 0.1058
	--> Final training Epoch [90/90], Loss: 0.1199

Final training took 0.6556346416473389 sec

TESTING
	--> Testing took 0.0000 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8881
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3475,  Current Best Accuracy: 0.8380,  Current Best Validation Loss: 0.3475
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7292, Validation Loss: 0.5002,  Current Best Accuracy: 0.8380,  Current Best Validation Loss: 0.3475

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5287, Validation Loss: 0.6344
	--> Epoch [2/100], Loss: 0.5974, Validation Loss: 0.6241
	--> Epoch [3/100], Loss: 0.5317, Validation Loss: 0.6143
	--> Epoch [4/100], Loss: 0.5948, Validation Loss: 0.6087
	--> Epoch [5/100], Loss: 0.4701, Validation Loss: 0.5974
	--> Epoch [6/100], Loss: 0.4891, Validation Loss: 0.5892
	--> Epoch [7/100], Loss: 0.4667, Validation Loss: 0.5853
	--> Epoch [8/100], Loss: 0.5423, Validation Loss: 0.5820
	--> Epoch [9/100], Loss: 0.4175, Validation Loss: 0.5750
	--> Epoch [10/100], Loss: 0.4830, Validation Loss: 0.5690
	--> Epoch [11/100], Loss: 0.4176, Validation Loss: 0.5618
	--> Epoch [12/100], Loss: 0.4345, Validation Loss: 0.5558
	--> Epoch [13/100], Loss: 0.3681, Validation Loss: 0.5495
	--> Epoch [14/100], Loss: 0.4151, Validation Loss: 0.5456
	--> Epoch [15/100], Loss: 0.5464, Validation Loss: 0.5422
	--> Epoch [16/100], Loss: 0.4177, Validation Loss: 0.5386
	--> Epoch [17/100], Loss: 0.4127, Validation Loss: 0.5353
	--> Epoch [18/100], Loss: 0.3624, Validation Loss: 0.5276
	--> Epoch [19/100], Loss: 0.4242, Validation Loss: 0.5219
	--> Epoch [20/100], Loss: 0.3943, Validation Loss: 0.5181
	--> Epoch [21/100], Loss: 0.3042, Validation Loss: 0.5136
	--> Epoch [22/100], Loss: 0.2805, Validation Loss: 0.5052
	--> Epoch [23/100], Loss: 0.2899, Validation Loss: 0.4981
	--> Epoch [24/100], Loss: 0.2890, Validation Loss: 0.4935
	--> Epoch [25/100], Loss: 0.3997, Validation Loss: 0.4895
	--> Epoch [26/100], Loss: 0.2850, Validation Loss: 0.4835
	--> Epoch [27/100], Loss: 0.2372, Validation Loss: 0.4767
	--> Epoch [28/100], Loss: 0.2233, Validation Loss: 0.4708
	--> Epoch [29/100], Loss: 0.2814, Validation Loss: 0.4636
	--> Epoch [30/100], Loss: 0.3861, Validation Loss: 0.4579
	--> Epoch [31/100], Loss: 0.4127, Validation Loss: 0.4545
	--> Epoch [32/100], Loss: 0.3069, Validation Loss: 0.4490
	--> Epoch [33/100], Loss: 0.2291, Validation Loss: 0.4428
	--> Epoch [34/100], Loss: 0.3694, Validation Loss: 0.4400
	--> Epoch [35/100], Loss: 0.2795, Validation Loss: 0.4370
	--> Epoch [36/100], Loss: 0.1823, Validation Loss: 0.4315
	--> Epoch [37/100], Loss: 0.4094, Validation Loss: 0.4270
	--> Epoch [38/100], Loss: 0.2344, Validation Loss: 0.4206
	--> Epoch [39/100], Loss: 0.3306, Validation Loss: 0.4145
	--> Epoch [40/100], Loss: 0.2588, Validation Loss: 0.4095
	--> Epoch [41/100], Loss: 0.1819, Validation Loss: 0.4049
	--> Epoch [42/100], Loss: 0.1519, Validation Loss: 0.4007
	--> Epoch [43/100], Loss: 0.3974, Validation Loss: 0.3974
	--> Epoch [44/100], Loss: 0.2540, Validation Loss: 0.3933
	--> Epoch [45/100], Loss: 0.4418, Validation Loss: 0.3897
	--> Epoch [46/100], Loss: 0.2778, Validation Loss: 0.3862
	--> Epoch [47/100], Loss: 0.0878, Validation Loss: 0.3837
	--> Epoch [48/100], Loss: 0.2705, Validation Loss: 0.3809
	--> Epoch [49/100], Loss: 0.3382, Validation Loss: 0.3779
	--> Epoch [50/100], Loss: 0.2539, Validation Loss: 0.3734
	--> Epoch [51/100], Loss: 0.3184, Validation Loss: 0.3726
	--> Epoch [52/100], Loss: 0.1311, Validation Loss: 0.3691
	--> Epoch [53/100], Loss: 0.2857, Validation Loss: 0.3655
	--> Epoch [54/100], Loss: 0.1075, Validation Loss: 0.3613
	--> Epoch [55/100], Loss: 0.1840, Validation Loss: 0.3583
	--> Epoch [56/100], Loss: 0.1139, Validation Loss: 0.3565
	--> Epoch [57/100], Loss: 0.3351, Validation Loss: 0.3537
	--> Epoch [58/100], Loss: 0.2056, Validation Loss: 0.3510
	--> Epoch [59/100], Loss: 0.3238, Validation Loss: 0.3486
	--> Epoch [60/100], Loss: 0.2438, Validation Loss: 0.3482
	--> Epoch [61/100], Loss: 0.2784, Validation Loss: 0.3454
	--> Epoch [62/100], Loss: 0.2347, Validation Loss: 0.3425
	--> Epoch [63/100], Loss: 0.2932, Validation Loss: 0.3399
	--> Epoch [64/100], Loss: 0.3270, Validation Loss: 0.3367
	--> Epoch [65/100], Loss: 0.1719, Validation Loss: 0.3325
	--> Epoch [66/100], Loss: 0.1241, Validation Loss: 0.3301
	--> Epoch [67/100], Loss: 0.1708, Validation Loss: 0.3270
	--> Epoch [68/100], Loss: 0.2660, Validation Loss: 0.3267
	--> Epoch [69/100], Loss: 0.1276, Validation Loss: 0.3260
	--> Epoch [70/100], Loss: 0.3565, Validation Loss: 0.3228
	--> Epoch [71/100], Loss: 0.1315, Validation Loss: 0.3218
	--> Epoch [72/100], Loss: 0.0745, Validation Loss: 0.3196
	--> Epoch [73/100], Loss: 0.1571, Validation Loss: 0.3178
	--> Epoch [74/100], Loss: 0.1759, Validation Loss: 0.3157
	--> Epoch [75/100], Loss: 0.2312, Validation Loss: 0.3153
	--> Epoch [76/100], Loss: 0.1613, Validation Loss: 0.3146
	--> Epoch [77/100], Loss: 0.2589, Validation Loss: 0.3126
	--> Epoch [78/100], Loss: 0.1722, Validation Loss: 0.3106
	--> Epoch [79/100], Loss: 0.1608, Validation Loss: 0.3083
	--> Epoch [80/100], Loss: 0.1687, Validation Loss: 0.3066
	--> Epoch [81/100], Loss: 0.1084, Validation Loss: 0.3045
	--> Epoch [82/100], Loss: 0.2211, Validation Loss: 0.3023
	--> Epoch [83/100], Loss: 0.0164, Validation Loss: 0.2993
	--> Epoch [84/100], Loss: 0.1603, Validation Loss: 0.2972
	--> Epoch [85/100], Loss: 0.1407, Validation Loss: 0.2952
	--> Epoch [86/100], Loss: 0.1369, Validation Loss: 0.2961
	--> Epoch [87/100], Loss: 0.2127, Validation Loss: 0.2955
	--> Epoch [88/100], Loss: 0.1703, Validation Loss: 0.2947
	--> Epoch [89/100], Loss: 0.1137, Validation Loss: 0.2938
	--> Epoch [90/100], Loss: 0.1181, Validation Loss: 0.2924
	--> Epoch [91/100], Loss: 0.1743, Validation Loss: 0.2910
	--> Epoch [92/100], Loss: 0.3080, Validation Loss: 0.2899
	--> Epoch [93/100], Loss: 0.2583, Validation Loss: 0.2890
	--> Epoch [94/100], Loss: 0.1697, Validation Loss: 0.2873
	--> Epoch [95/100], Loss: 0.1339, Validation Loss: 0.2858
	--> Epoch [96/100], Loss: 0.1228, Validation Loss: 0.2861
	--> Epoch [97/100], Loss: 0.1553, Validation Loss: 0.2844
	--> Epoch [98/100], Loss: 0.2017, Validation Loss: 0.2830
	--> Epoch [99/100], Loss: 0.2139, Validation Loss: 0.2821
	--> Epoch [100/100], Loss: 0.1158, Validation Loss: 0.2810
	--> Training for Fold 1 took 0.8006346225738525 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8030, Validation Loss: 0.6772
	--> Epoch [2/100], Loss: 0.9140, Validation Loss: 0.6613
	--> Epoch [3/100], Loss: 0.8149, Validation Loss: 0.6594
	--> Epoch [4/100], Loss: 0.7453, Validation Loss: 0.6420
	--> Epoch [5/100], Loss: 0.9214, Validation Loss: 0.6414
	--> Epoch [6/100], Loss: 0.8700, Validation Loss: 0.6300
	--> Epoch [7/100], Loss: 0.7665, Validation Loss: 0.6214
	--> Epoch [8/100], Loss: 0.7328, Validation Loss: 0.6105
	--> Epoch [9/100], Loss: 0.6883, Validation Loss: 0.5939
	--> Epoch [10/100], Loss: 0.6109, Validation Loss: 0.5775
	--> Epoch [11/100], Loss: 0.6170, Validation Loss: 0.5676
	--> Epoch [12/100], Loss: 0.6075, Validation Loss: 0.5598
	--> Epoch [13/100], Loss: 0.6682, Validation Loss: 0.5547
	--> Epoch [14/100], Loss: 0.5275, Validation Loss: 0.5460
	--> Epoch [15/100], Loss: 0.5239, Validation Loss: 0.5321
	--> Epoch [16/100], Loss: 0.5277, Validation Loss: 0.5247
	--> Epoch [17/100], Loss: 0.5444, Validation Loss: 0.5155
	--> Epoch [18/100], Loss: 0.5482, Validation Loss: 0.5081
	--> Epoch [19/100], Loss: 0.6459, Validation Loss: 0.4990
	--> Epoch [20/100], Loss: 0.3651, Validation Loss: 0.4909
	--> Epoch [21/100], Loss: 0.5459, Validation Loss: 0.4824
	--> Epoch [22/100], Loss: 0.2856, Validation Loss: 0.4730
	--> Epoch [23/100], Loss: 0.3746, Validation Loss: 0.4685
	--> Epoch [24/100], Loss: 0.6388, Validation Loss: 0.4618
	--> Epoch [25/100], Loss: 0.3733, Validation Loss: 0.4565
	--> Epoch [26/100], Loss: 0.6610, Validation Loss: 0.4508
	--> Epoch [27/100], Loss: 0.4612, Validation Loss: 0.4451
	--> Epoch [28/100], Loss: 0.4935, Validation Loss: 0.4429
	--> Epoch [29/100], Loss: 0.5765, Validation Loss: 0.4400
	--> Epoch [30/100], Loss: 0.6254, Validation Loss: 0.4348
	--> Epoch [31/100], Loss: 0.4336, Validation Loss: 0.4298
	--> Epoch [32/100], Loss: 0.4219, Validation Loss: 0.4254
	--> Epoch [33/100], Loss: 0.5047, Validation Loss: 0.4237
	--> Epoch [34/100], Loss: 0.3214, Validation Loss: 0.4171
	--> Epoch [35/100], Loss: 0.3092, Validation Loss: 0.4148
	--> Epoch [36/100], Loss: 0.5450, Validation Loss: 0.4115
	--> Epoch [37/100], Loss: 0.4617, Validation Loss: 0.4086
	--> Epoch [38/100], Loss: 0.2566, Validation Loss: 0.4044
	--> Epoch [39/100], Loss: 0.4750, Validation Loss: 0.3991
	--> Epoch [40/100], Loss: 0.4056, Validation Loss: 0.3969
	--> Epoch [41/100], Loss: 0.3453, Validation Loss: 0.3920
	--> Epoch [42/100], Loss: 0.4328, Validation Loss: 0.3885
	--> Epoch [43/100], Loss: 0.3549, Validation Loss: 0.3843
	--> Epoch [44/100], Loss: 0.5459, Validation Loss: 0.3822
	--> Epoch [45/100], Loss: 0.5514, Validation Loss: 0.3766
	--> Epoch [46/100], Loss: 0.3867, Validation Loss: 0.3724
	--> Epoch [47/100], Loss: 0.4373, Validation Loss: 0.3711
	--> Epoch [48/100], Loss: 0.3905, Validation Loss: 0.3661
	--> Epoch [49/100], Loss: 0.7238, Validation Loss: 0.3619
	--> Epoch [50/100], Loss: 0.4783, Validation Loss: 0.3583
	--> Epoch [51/100], Loss: 0.3455, Validation Loss: 0.3549
	--> Epoch [52/100], Loss: 0.4478, Validation Loss: 0.3542
	--> Epoch [53/100], Loss: 0.3024, Validation Loss: 0.3507
	--> Epoch [54/100], Loss: 0.3726, Validation Loss: 0.3471
	--> Epoch [55/100], Loss: 0.2785, Validation Loss: 0.3440
	--> Epoch [56/100], Loss: 0.3666, Validation Loss: 0.3401
	--> Epoch [57/100], Loss: 0.2594, Validation Loss: 0.3377
	--> Epoch [58/100], Loss: 0.3314, Validation Loss: 0.3356
	--> Epoch [59/100], Loss: 0.4133, Validation Loss: 0.3342
	--> Epoch [60/100], Loss: 0.2951, Validation Loss: 0.3323
	--> Epoch [61/100], Loss: 0.1926, Validation Loss: 0.3296
	--> Epoch [62/100], Loss: 0.5204, Validation Loss: 0.3262
	--> Epoch [63/100], Loss: 0.5723, Validation Loss: 0.3252
	--> Epoch [64/100], Loss: 0.4756, Validation Loss: 0.3199
	--> Epoch [65/100], Loss: 0.4903, Validation Loss: 0.3158
	--> Epoch [66/100], Loss: 0.3600, Validation Loss: 0.3140
	--> Epoch [67/100], Loss: 0.5087, Validation Loss: 0.3104
	--> Epoch [68/100], Loss: 0.4311, Validation Loss: 0.3074
	--> Epoch [69/100], Loss: 0.5286, Validation Loss: 0.3056
	--> Epoch [70/100], Loss: 0.3574, Validation Loss: 0.3046
	--> Epoch [71/100], Loss: 0.3604, Validation Loss: 0.2999
	--> Epoch [72/100], Loss: 0.4167, Validation Loss: 0.2991
	--> Epoch [73/100], Loss: 0.4920, Validation Loss: 0.2957
	--> Epoch [74/100], Loss: 0.4998, Validation Loss: 0.2926
	--> Epoch [75/100], Loss: 0.2127, Validation Loss: 0.2921
	--> Epoch [76/100], Loss: 0.4144, Validation Loss: 0.2872
	--> Epoch [77/100], Loss: 0.2652, Validation Loss: 0.2844
	--> Epoch [78/100], Loss: 0.2714, Validation Loss: 0.2815
	--> Epoch [79/100], Loss: 0.3314, Validation Loss: 0.2766
	--> Epoch [80/100], Loss: 0.3301, Validation Loss: 0.2749
	--> Epoch [81/100], Loss: 0.4939, Validation Loss: 0.2732
	--> Epoch [82/100], Loss: 0.4685, Validation Loss: 0.2717
	--> Epoch [83/100], Loss: 0.4165, Validation Loss: 0.2679
	--> Epoch [84/100], Loss: 0.1060, Validation Loss: 0.2659
	--> Epoch [85/100], Loss: 0.4323, Validation Loss: 0.2635
	--> Epoch [86/100], Loss: 0.4808, Validation Loss: 0.2626
	--> Epoch [87/100], Loss: 0.4866, Validation Loss: 0.2614
	--> Epoch [88/100], Loss: 0.3582, Validation Loss: 0.2594
	--> Epoch [89/100], Loss: 0.3215, Validation Loss: 0.2569
	--> Epoch [90/100], Loss: 0.4882, Validation Loss: 0.2543
	--> Epoch [91/100], Loss: 0.2462, Validation Loss: 0.2504
	--> Epoch [92/100], Loss: 0.3632, Validation Loss: 0.2485
	--> Epoch [93/100], Loss: 0.2490, Validation Loss: 0.2466
	--> Epoch [94/100], Loss: 0.3826, Validation Loss: 0.2446
	--> Epoch [95/100], Loss: 0.4074, Validation Loss: 0.2429
	--> Epoch [96/100], Loss: 0.1710, Validation Loss: 0.2414
	--> Epoch [97/100], Loss: 0.2309, Validation Loss: 0.2376
	--> Epoch [98/100], Loss: 0.4768, Validation Loss: 0.2355
	--> Epoch [99/100], Loss: 0.3758, Validation Loss: 0.2340
	--> Epoch [100/100], Loss: 0.1731, Validation Loss: 0.2320
	--> Training for Fold 2 took 0.8301796913146973 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5631, Validation Loss: 0.6603
	--> Epoch [2/100], Loss: 0.8239, Validation Loss: 0.6446
	--> Epoch [3/100], Loss: 0.6599, Validation Loss: 0.6373
	--> Epoch [4/100], Loss: 0.6278, Validation Loss: 0.6277
	--> Epoch [5/100], Loss: 0.5018, Validation Loss: 0.6159
	--> Epoch [6/100], Loss: 0.6160, Validation Loss: 0.6123
	--> Epoch [7/100], Loss: 0.5240, Validation Loss: 0.6072
	--> Epoch [8/100], Loss: 0.4795, Validation Loss: 0.6018
	--> Epoch [9/100], Loss: 0.5841, Validation Loss: 0.5972
	--> Epoch [10/100], Loss: 0.3516, Validation Loss: 0.5891
	--> Epoch [11/100], Loss: 0.4468, Validation Loss: 0.5865
	--> Epoch [12/100], Loss: 0.5454, Validation Loss: 0.5813
	--> Epoch [13/100], Loss: 0.4847, Validation Loss: 0.5721
	--> Epoch [14/100], Loss: 0.2877, Validation Loss: 0.5667
	--> Epoch [15/100], Loss: 0.4630, Validation Loss: 0.5608
	--> Epoch [16/100], Loss: 0.4506, Validation Loss: 0.5528
	--> Epoch [17/100], Loss: 0.3085, Validation Loss: 0.5487
	--> Epoch [18/100], Loss: 0.3272, Validation Loss: 0.5412
	--> Epoch [19/100], Loss: 0.4756, Validation Loss: 0.5414
	--> Epoch [20/100], Loss: 0.4441, Validation Loss: 0.5370
	--> Epoch [21/100], Loss: 0.3012, Validation Loss: 0.5342
	--> Epoch [22/100], Loss: 0.3936, Validation Loss: 0.5288
	--> Epoch [23/100], Loss: 0.4600, Validation Loss: 0.5262
	--> Epoch [24/100], Loss: 0.2350, Validation Loss: 0.5222
	--> Epoch [25/100], Loss: 0.2477, Validation Loss: 0.5187
	--> Epoch [26/100], Loss: 0.5857, Validation Loss: 0.5128
	--> Epoch [27/100], Loss: 0.3306, Validation Loss: 0.5093
	--> Epoch [28/100], Loss: 0.6168, Validation Loss: 0.5037
	--> Epoch [29/100], Loss: 0.2161, Validation Loss: 0.5008
	--> Epoch [30/100], Loss: 0.5040, Validation Loss: 0.4952
	--> Epoch [31/100], Loss: 0.2464, Validation Loss: 0.4907
	--> Epoch [32/100], Loss: 0.2781, Validation Loss: 0.4830
	--> Epoch [33/100], Loss: 0.2207, Validation Loss: 0.4789
	--> Epoch [34/100], Loss: 0.3101, Validation Loss: 0.4740
	--> Epoch [35/100], Loss: 0.2089, Validation Loss: 0.4711
	--> Epoch [36/100], Loss: 0.3413, Validation Loss: 0.4692
	--> Epoch [37/100], Loss: 0.2226, Validation Loss: 0.4668
	--> Epoch [38/100], Loss: 0.3710, Validation Loss: 0.4620
	--> Epoch [39/100], Loss: 0.3765, Validation Loss: 0.4604
	--> Epoch [40/100], Loss: 0.4664, Validation Loss: 0.4590
	--> Epoch [41/100], Loss: 0.2522, Validation Loss: 0.4542
	--> Epoch [42/100], Loss: 0.2845, Validation Loss: 0.4496
	--> Epoch [43/100], Loss: 0.3382, Validation Loss: 0.4473
	--> Epoch [44/100], Loss: 0.1930, Validation Loss: 0.4438
	--> Epoch [45/100], Loss: 0.1037, Validation Loss: 0.4408
	--> Epoch [46/100], Loss: 0.1426, Validation Loss: 0.4380
	--> Epoch [47/100], Loss: 0.2282, Validation Loss: 0.4356
	--> Epoch [48/100], Loss: 0.3074, Validation Loss: 0.4365
	--> Epoch [49/100], Loss: 0.3250, Validation Loss: 0.4357
	--> Epoch [50/100], Loss: 0.3310, Validation Loss: 0.4344
	--> Epoch [51/100], Loss: 0.2247, Validation Loss: 0.4324
	--> Epoch [52/100], Loss: 0.3071, Validation Loss: 0.4304
	--> Epoch [53/100], Loss: 0.1610, Validation Loss: 0.4283
	--> Epoch [54/100], Loss: 0.3707, Validation Loss: 0.4273
	--> Epoch [55/100], Loss: 0.3546, Validation Loss: 0.4241
	--> Epoch [56/100], Loss: 0.1490, Validation Loss: 0.4205
	--> Epoch [57/100], Loss: 0.2319, Validation Loss: 0.4203
	--> Epoch [58/100], Loss: 0.3626, Validation Loss: 0.4146
	--> Epoch [59/100], Loss: 0.1739, Validation Loss: 0.4118
	--> Epoch [60/100], Loss: 0.1650, Validation Loss: 0.4092
	--> Epoch [61/100], Loss: 0.4898, Validation Loss: 0.4069
	--> Epoch [62/100], Loss: 0.2836, Validation Loss: 0.4047
	--> Epoch [63/100], Loss: 0.2308, Validation Loss: 0.4019
	--> Epoch [64/100], Loss: 0.2757, Validation Loss: 0.4007
	--> Epoch [65/100], Loss: 0.2925, Validation Loss: 0.3987
	--> Epoch [66/100], Loss: 0.2263, Validation Loss: 0.3956
	--> Epoch [67/100], Loss: 0.2158, Validation Loss: 0.3953
	--> Epoch [68/100], Loss: 0.3468, Validation Loss: 0.3928
	--> Epoch [69/100], Loss: 0.1576, Validation Loss: 0.3924
	--> Epoch [70/100], Loss: 0.2055, Validation Loss: 0.3911
	--> Epoch [71/100], Loss: 0.2244, Validation Loss: 0.3883
	--> Epoch [72/100], Loss: 0.2148, Validation Loss: 0.3862
	--> Epoch [73/100], Loss: 0.1568, Validation Loss: 0.3853
	--> Epoch [74/100], Loss: 0.0976, Validation Loss: 0.3834
	--> Epoch [75/100], Loss: 0.2159, Validation Loss: 0.3815
	--> Epoch [76/100], Loss: 0.2115, Validation Loss: 0.3807
	--> Epoch [77/100], Loss: 0.2256, Validation Loss: 0.3796
	--> Epoch [78/100], Loss: 0.1481, Validation Loss: 0.3780
	--> Epoch [79/100], Loss: 0.3381, Validation Loss: 0.3782
	--> Epoch [80/100], Loss: 0.1499, Validation Loss: 0.3763
	--> Epoch [81/100], Loss: 0.2073, Validation Loss: 0.3764
	--> Epoch [82/100], Loss: 0.1506, Validation Loss: 0.3746
	--> Epoch [83/100], Loss: 0.1567, Validation Loss: 0.3768
	--> Epoch [84/100], Loss: 0.3380, Validation Loss: 0.3746
	--> Epoch [85/100], Loss: 0.1448, Validation Loss: 0.3733
	--> Epoch [86/100], Loss: 0.2786, Validation Loss: 0.3720
	--> Epoch [87/100], Loss: 0.3390, Validation Loss: 0.3713
	--> Epoch [88/100], Loss: 0.2216, Validation Loss: 0.3690
	--> Epoch [89/100], Loss: 0.2795, Validation Loss: 0.3676
	--> Epoch [90/100], Loss: 0.3397, Validation Loss: 0.3674
	--> Epoch [91/100], Loss: 0.2637, Validation Loss: 0.3661
	--> Epoch [92/100], Loss: 0.4645, Validation Loss: 0.3644
	--> Epoch [93/100], Loss: 0.2705, Validation Loss: 0.3631
	--> Epoch [94/100], Loss: 0.0815, Validation Loss: 0.3622
	--> Epoch [95/100], Loss: 0.1985, Validation Loss: 0.3618
	--> Epoch [96/100], Loss: 0.2801, Validation Loss: 0.3609
	--> Epoch [97/100], Loss: 0.1515, Validation Loss: 0.3606
	--> Epoch [98/100], Loss: 0.2058, Validation Loss: 0.3606
	--> Epoch [99/100], Loss: 0.1363, Validation Loss: 0.3591
	--> Epoch [100/100], Loss: 0.1334, Validation Loss: 0.3578
	--> Training for Fold 3 took 0.7423677444458008 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6009, Validation Loss: 0.8883
	--> Epoch [2/100], Loss: 0.5758, Validation Loss: 0.8648
	--> Epoch [3/100], Loss: 0.5106, Validation Loss: 0.8405
	--> Epoch [4/100], Loss: 0.5266, Validation Loss: 0.8193
	--> Epoch [5/100], Loss: 0.4943, Validation Loss: 0.8079
	--> Epoch [6/100], Loss: 0.6320, Validation Loss: 0.7946
	--> Epoch [7/100], Loss: 0.5380, Validation Loss: 0.7801
	--> Epoch [8/100], Loss: 0.5197, Validation Loss: 0.7647
	--> Epoch [9/100], Loss: 0.5348, Validation Loss: 0.7508
	--> Epoch [10/100], Loss: 0.4345, Validation Loss: 0.7416
	--> Epoch [11/100], Loss: 0.5809, Validation Loss: 0.7314
	--> Epoch [12/100], Loss: 0.4399, Validation Loss: 0.7193
	--> Epoch [13/100], Loss: 0.5573, Validation Loss: 0.7124
	--> Epoch [14/100], Loss: 0.5321, Validation Loss: 0.7053
	--> Epoch [15/100], Loss: 0.4677, Validation Loss: 0.7005
	--> Epoch [16/100], Loss: 0.3415, Validation Loss: 0.6902
	--> Epoch [17/100], Loss: 0.3770, Validation Loss: 0.6823
	--> Epoch [18/100], Loss: 0.3902, Validation Loss: 0.6725
	--> Epoch [19/100], Loss: 0.3328, Validation Loss: 0.6681
	--> Epoch [20/100], Loss: 0.4271, Validation Loss: 0.6590
	--> Epoch [21/100], Loss: 0.3593, Validation Loss: 0.6511
	--> Epoch [22/100], Loss: 0.3724, Validation Loss: 0.6427
	--> Epoch [23/100], Loss: 0.3856, Validation Loss: 0.6356
	--> Epoch [24/100], Loss: 0.3113, Validation Loss: 0.6311
	--> Epoch [25/100], Loss: 0.3627, Validation Loss: 0.6193
	--> Epoch [26/100], Loss: 0.2908, Validation Loss: 0.6133
	--> Epoch [27/100], Loss: 0.2262, Validation Loss: 0.6059
	--> Epoch [28/100], Loss: 0.3909, Validation Loss: 0.5988
	--> Epoch [29/100], Loss: 0.4147, Validation Loss: 0.5946
	--> Epoch [30/100], Loss: 0.4049, Validation Loss: 0.5857
	--> Epoch [31/100], Loss: 0.3946, Validation Loss: 0.5816
	--> Epoch [32/100], Loss: 0.3078, Validation Loss: 0.5800
	--> Epoch [33/100], Loss: 0.3552, Validation Loss: 0.5790
	--> Epoch [34/100], Loss: 0.1909, Validation Loss: 0.5674
	--> Epoch [35/100], Loss: 0.3094, Validation Loss: 0.5598
	--> Epoch [36/100], Loss: 0.3619, Validation Loss: 0.5534
	--> Epoch [37/100], Loss: 0.3828, Validation Loss: 0.5515
	--> Epoch [38/100], Loss: 0.3790, Validation Loss: 0.5482
	--> Epoch [39/100], Loss: 0.4733, Validation Loss: 0.5423
	--> Epoch [40/100], Loss: 0.3385, Validation Loss: 0.5352
	--> Epoch [41/100], Loss: 0.2880, Validation Loss: 0.5328
	--> Epoch [42/100], Loss: 0.2466, Validation Loss: 0.5239
	--> Epoch [43/100], Loss: 0.2319, Validation Loss: 0.5187
	--> Epoch [44/100], Loss: 0.3340, Validation Loss: 0.5127
	--> Epoch [45/100], Loss: 0.2311, Validation Loss: 0.5064
	--> Epoch [46/100], Loss: 0.2863, Validation Loss: 0.5009
	--> Epoch [47/100], Loss: 0.3163, Validation Loss: 0.4943
	--> Epoch [48/100], Loss: 0.2545, Validation Loss: 0.4889
	--> Epoch [49/100], Loss: 0.4088, Validation Loss: 0.4833
	--> Epoch [50/100], Loss: 0.2664, Validation Loss: 0.4778
	--> Epoch [51/100], Loss: 0.1371, Validation Loss: 0.4711
	--> Epoch [52/100], Loss: 0.2787, Validation Loss: 0.4742
	--> Epoch [53/100], Loss: 0.2058, Validation Loss: 0.4712
	--> Epoch [54/100], Loss: 0.3799, Validation Loss: 0.4638
	--> Epoch [55/100], Loss: 0.2032, Validation Loss: 0.4506
	--> Epoch [56/100], Loss: 0.2580, Validation Loss: 0.4480
	--> Epoch [57/100], Loss: 0.2659, Validation Loss: 0.4437
	--> Epoch [58/100], Loss: 0.2503, Validation Loss: 0.4376
	--> Epoch [59/100], Loss: 0.2731, Validation Loss: 0.4323
	--> Epoch [60/100], Loss: 0.1792, Validation Loss: 0.4251
	--> Epoch [61/100], Loss: 0.3214, Validation Loss: 0.4249
	--> Epoch [62/100], Loss: 0.4876, Validation Loss: 0.4215
	--> Epoch [63/100], Loss: 0.2919, Validation Loss: 0.4188
	--> Epoch [64/100], Loss: 0.3685, Validation Loss: 0.4160
	--> Epoch [65/100], Loss: 0.1474, Validation Loss: 0.4130
	--> Epoch [66/100], Loss: 0.2415, Validation Loss: 0.4142
	--> Epoch [67/100], Loss: 0.2500, Validation Loss: 0.4099
	--> Epoch [68/100], Loss: 0.3906, Validation Loss: 0.4040
	--> Epoch [69/100], Loss: 0.4539, Validation Loss: 0.4008
	--> Epoch [70/100], Loss: 0.1904, Validation Loss: 0.3962
	--> Epoch [71/100], Loss: 0.3565, Validation Loss: 0.3892
	--> Epoch [72/100], Loss: 0.3791, Validation Loss: 0.3821
	--> Epoch [73/100], Loss: 0.3341, Validation Loss: 0.3777
	--> Epoch [74/100], Loss: 0.3222, Validation Loss: 0.3756
	--> Epoch [75/100], Loss: 0.3097, Validation Loss: 0.3849
	--> Epoch [76/100], Loss: 0.2778, Validation Loss: 0.3827
	--> Epoch [77/100], Loss: 0.2902, Validation Loss: 0.3776
Early stopping
	--> Training for Fold 4 took 0.5126714706420898 sec, using 77 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6298, Validation Loss: 0.7179
	--> Epoch [2/100], Loss: 0.5700, Validation Loss: 0.7122
	--> Epoch [3/100], Loss: 0.5718, Validation Loss: 0.7080
	--> Epoch [4/100], Loss: 0.5770, Validation Loss: 0.7034
	--> Epoch [5/100], Loss: 0.5655, Validation Loss: 0.6980
	--> Epoch [6/100], Loss: 0.6103, Validation Loss: 0.6930
	--> Epoch [7/100], Loss: 0.5241, Validation Loss: 0.6900
	--> Epoch [8/100], Loss: 0.5516, Validation Loss: 0.6865
	--> Epoch [9/100], Loss: 0.5580, Validation Loss: 0.6812
	--> Epoch [10/100], Loss: 0.5483, Validation Loss: 0.6779
	--> Epoch [11/100], Loss: 0.5686, Validation Loss: 0.6754
	--> Epoch [12/100], Loss: 0.4779, Validation Loss: 0.6726
	--> Epoch [13/100], Loss: 0.4952, Validation Loss: 0.6731
	--> Epoch [14/100], Loss: 0.3718, Validation Loss: 0.6711
	--> Epoch [15/100], Loss: 0.3824, Validation Loss: 0.6701
	--> Epoch [16/100], Loss: 0.3850, Validation Loss: 0.6678
	--> Epoch [17/100], Loss: 0.3590, Validation Loss: 0.6648
	--> Epoch [18/100], Loss: 0.3577, Validation Loss: 0.6616
	--> Epoch [19/100], Loss: 0.4132, Validation Loss: 0.6598
	--> Epoch [20/100], Loss: 0.3513, Validation Loss: 0.6573
	--> Epoch [21/100], Loss: 0.3665, Validation Loss: 0.6533
	--> Epoch [22/100], Loss: 0.4679, Validation Loss: 0.6517
	--> Epoch [23/100], Loss: 0.4385, Validation Loss: 0.6519
	--> Epoch [24/100], Loss: 0.4832, Validation Loss: 0.6512
	--> Epoch [25/100], Loss: 0.4522, Validation Loss: 0.6496
	--> Epoch [26/100], Loss: 0.4213, Validation Loss: 0.6504
	--> Epoch [27/100], Loss: 0.2333, Validation Loss: 0.6513
	--> Epoch [28/100], Loss: 0.3116, Validation Loss: 0.6515
Early stopping
	--> Training for Fold 5 took 0.17206478118896484 sec, using 28 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7976
	--> Final training Epoch [2/100], Loss: 0.7579
	--> Final training Epoch [3/100], Loss: 0.7709
	--> Final training Epoch [4/100], Loss: 0.7268
	--> Final training Epoch [5/100], Loss: 0.6994
	--> Final training Epoch [6/100], Loss: 0.6792
	--> Final training Epoch [7/100], Loss: 0.6914
	--> Final training Epoch [8/100], Loss: 0.6725
	--> Final training Epoch [9/100], Loss: 0.6194
	--> Final training Epoch [10/100], Loss: 0.6061
	--> Final training Epoch [11/100], Loss: 0.5840
	--> Final training Epoch [12/100], Loss: 0.5564
	--> Final training Epoch [13/100], Loss: 0.6731
	--> Final training Epoch [14/100], Loss: 0.5993
	--> Final training Epoch [15/100], Loss: 0.5765
	--> Final training Epoch [16/100], Loss: 0.5543
	--> Final training Epoch [17/100], Loss: 0.6408
	--> Final training Epoch [18/100], Loss: 0.5778
	--> Final training Epoch [19/100], Loss: 0.5687
	--> Final training Epoch [20/100], Loss: 0.5395
	--> Final training Epoch [21/100], Loss: 0.5018
	--> Final training Epoch [22/100], Loss: 0.5574
	--> Final training Epoch [23/100], Loss: 0.5371
	--> Final training Epoch [24/100], Loss: 0.5425
	--> Final training Epoch [25/100], Loss: 0.4384
	--> Final training Epoch [26/100], Loss: 0.3941
	--> Final training Epoch [27/100], Loss: 0.4672
	--> Final training Epoch [28/100], Loss: 0.3959
	--> Final training Epoch [29/100], Loss: 0.4028
	--> Final training Epoch [30/100], Loss: 0.3618
	--> Final training Epoch [31/100], Loss: 0.3699
	--> Final training Epoch [32/100], Loss: 0.4482
	--> Final training Epoch [33/100], Loss: 0.3924
	--> Final training Epoch [34/100], Loss: 0.4043
	--> Final training Epoch [35/100], Loss: 0.4479
	--> Final training Epoch [36/100], Loss: 0.4040
	--> Final training Epoch [37/100], Loss: 0.3058
	--> Final training Epoch [38/100], Loss: 0.3486
	--> Final training Epoch [39/100], Loss: 0.4053
	--> Final training Epoch [40/100], Loss: 0.3419
	--> Final training Epoch [41/100], Loss: 0.3819
	--> Final training Epoch [42/100], Loss: 0.2895
	--> Final training Epoch [43/100], Loss: 0.3424
	--> Final training Epoch [44/100], Loss: 0.2245
	--> Final training Epoch [45/100], Loss: 0.3489
	--> Final training Epoch [46/100], Loss: 0.3137
	--> Final training Epoch [47/100], Loss: 0.3589
	--> Final training Epoch [48/100], Loss: 0.3459
	--> Final training Epoch [49/100], Loss: 0.2709
	--> Final training Epoch [50/100], Loss: 0.4278
	--> Final training Epoch [51/100], Loss: 0.2852
	--> Final training Epoch [52/100], Loss: 0.3631
	--> Final training Epoch [53/100], Loss: 0.2949
	--> Final training Epoch [54/100], Loss: 0.4128
	--> Final training Epoch [55/100], Loss: 0.3479
	--> Final training Epoch [56/100], Loss: 0.3628
	--> Final training Epoch [57/100], Loss: 0.2648
	--> Final training Epoch [58/100], Loss: 0.2583
	--> Final training Epoch [59/100], Loss: 0.3619
	--> Final training Epoch [60/100], Loss: 0.3175
	--> Final training Epoch [61/100], Loss: 0.2415
	--> Final training Epoch [62/100], Loss: 0.2760
	--> Final training Epoch [63/100], Loss: 0.2856
	--> Final training Epoch [64/100], Loss: 0.2903
	--> Final training Epoch [65/100], Loss: 0.2532
	--> Final training Epoch [66/100], Loss: 0.2549
	--> Final training Epoch [67/100], Loss: 0.3518
	--> Final training Epoch [68/100], Loss: 0.3942
	--> Final training Epoch [69/100], Loss: 0.2218
	--> Final training Epoch [70/100], Loss: 0.2309
	--> Final training Epoch [71/100], Loss: 0.3611
	--> Final training Epoch [72/100], Loss: 0.2768
	--> Final training Epoch [73/100], Loss: 0.2291
	--> Final training Epoch [74/100], Loss: 0.2396
	--> Final training Epoch [75/100], Loss: 0.2860
	--> Final training Epoch [76/100], Loss: 0.3140
	--> Final training Epoch [77/100], Loss: 0.2704
	--> Final training Epoch [78/100], Loss: 0.3490
	--> Final training Epoch [79/100], Loss: 0.3358
	--> Final training Epoch [80/100], Loss: 0.1778
	--> Final training Epoch [81/100], Loss: 0.2375
	--> Final training Epoch [82/100], Loss: 0.2268
	--> Final training Epoch [83/100], Loss: 0.2669
	--> Final training Epoch [84/100], Loss: 0.2933
	--> Final training Epoch [85/100], Loss: 0.3093
	--> Final training Epoch [86/100], Loss: 0.1962
	--> Final training Epoch [87/100], Loss: 0.1831
	--> Final training Epoch [88/100], Loss: 0.1410
	--> Final training Epoch [89/100], Loss: 0.2293
	--> Final training Epoch [90/100], Loss: 0.2988
	--> Final training Epoch [91/100], Loss: 0.3195
	--> Final training Epoch [92/100], Loss: 0.2002
	--> Final training Epoch [93/100], Loss: 0.3400
	--> Final training Epoch [94/100], Loss: 0.1539
	--> Final training Epoch [95/100], Loss: 0.2125
	--> Final training Epoch [96/100], Loss: 0.1445
	--> Final training Epoch [97/100], Loss: 0.2911
	--> Final training Epoch [98/100], Loss: 0.2496
	--> Final training Epoch [99/100], Loss: 0.1602
	--> Final training Epoch [100/100], Loss: 0.2129

Final training took 0.5989172458648682 sec

TESTING
	--> Testing took 0.0104 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9027
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8386, Validation Loss: 0.4032,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.4032
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8047, Validation Loss: 0.4430,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.4032

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6927, Validation Loss: 0.6572
	--> Epoch [2/100], Loss: 0.6860, Validation Loss: 0.6422
	--> Epoch [3/100], Loss: 0.6683, Validation Loss: 0.6283
	--> Epoch [4/100], Loss: 0.6532, Validation Loss: 0.6187
	--> Epoch [5/100], Loss: 0.6276, Validation Loss: 0.6106
	--> Epoch [6/100], Loss: 0.6261, Validation Loss: 0.6014
	--> Epoch [7/100], Loss: 0.6165, Validation Loss: 0.5922
	--> Epoch [8/100], Loss: 0.6053, Validation Loss: 0.5824
	--> Epoch [9/100], Loss: 0.5779, Validation Loss: 0.5738
	--> Epoch [10/100], Loss: 0.5724, Validation Loss: 0.5662
	--> Epoch [11/100], Loss: 0.5647, Validation Loss: 0.5594
	--> Epoch [12/100], Loss: 0.5579, Validation Loss: 0.5509
	--> Epoch [13/100], Loss: 0.5403, Validation Loss: 0.5443
	--> Epoch [14/100], Loss: 0.5295, Validation Loss: 0.5377
	--> Epoch [15/100], Loss: 0.5095, Validation Loss: 0.5305
	--> Epoch [16/100], Loss: 0.5126, Validation Loss: 0.5251
	--> Epoch [17/100], Loss: 0.5149, Validation Loss: 0.5195
	--> Epoch [18/100], Loss: 0.5083, Validation Loss: 0.5149
	--> Epoch [19/100], Loss: 0.4706, Validation Loss: 0.5076
	--> Epoch [20/100], Loss: 0.4827, Validation Loss: 0.5023
	--> Epoch [21/100], Loss: 0.4648, Validation Loss: 0.4980
	--> Epoch [22/100], Loss: 0.4512, Validation Loss: 0.4925
	--> Epoch [23/100], Loss: 0.4386, Validation Loss: 0.4879
	--> Epoch [24/100], Loss: 0.4278, Validation Loss: 0.4812
	--> Epoch [25/100], Loss: 0.4328, Validation Loss: 0.4769
	--> Epoch [26/100], Loss: 0.4030, Validation Loss: 0.4726
	--> Epoch [27/100], Loss: 0.4216, Validation Loss: 0.4691
	--> Epoch [28/100], Loss: 0.3863, Validation Loss: 0.4642
	--> Epoch [29/100], Loss: 0.4002, Validation Loss: 0.4590
	--> Epoch [30/100], Loss: 0.3985, Validation Loss: 0.4540
	--> Epoch [31/100], Loss: 0.3769, Validation Loss: 0.4484
	--> Epoch [32/100], Loss: 0.3743, Validation Loss: 0.4434
	--> Epoch [33/100], Loss: 0.3366, Validation Loss: 0.4390
	--> Epoch [34/100], Loss: 0.3721, Validation Loss: 0.4344
	--> Epoch [35/100], Loss: 0.3744, Validation Loss: 0.4310
	--> Epoch [36/100], Loss: 0.3273, Validation Loss: 0.4269
	--> Epoch [37/100], Loss: 0.3226, Validation Loss: 0.4244
	--> Epoch [38/100], Loss: 0.3027, Validation Loss: 0.4215
	--> Epoch [39/100], Loss: 0.3247, Validation Loss: 0.4171
	--> Epoch [40/100], Loss: 0.3407, Validation Loss: 0.4126
	--> Epoch [41/100], Loss: 0.3131, Validation Loss: 0.4073
	--> Epoch [42/100], Loss: 0.2821, Validation Loss: 0.4040
	--> Epoch [43/100], Loss: 0.2664, Validation Loss: 0.3992
	--> Epoch [44/100], Loss: 0.2912, Validation Loss: 0.3964
	--> Epoch [45/100], Loss: 0.2767, Validation Loss: 0.3917
	--> Epoch [46/100], Loss: 0.3161, Validation Loss: 0.3879
	--> Epoch [47/100], Loss: 0.2505, Validation Loss: 0.3841
	--> Epoch [48/100], Loss: 0.2703, Validation Loss: 0.3805
	--> Epoch [49/100], Loss: 0.2548, Validation Loss: 0.3770
	--> Epoch [50/100], Loss: 0.2565, Validation Loss: 0.3737
	--> Epoch [51/100], Loss: 0.2663, Validation Loss: 0.3705
	--> Epoch [52/100], Loss: 0.2573, Validation Loss: 0.3674
	--> Epoch [53/100], Loss: 0.2738, Validation Loss: 0.3666
	--> Epoch [54/100], Loss: 0.2556, Validation Loss: 0.3634
	--> Epoch [55/100], Loss: 0.2122, Validation Loss: 0.3598
	--> Epoch [56/100], Loss: 0.2300, Validation Loss: 0.3580
	--> Epoch [57/100], Loss: 0.2556, Validation Loss: 0.3561
	--> Epoch [58/100], Loss: 0.2141, Validation Loss: 0.3527
	--> Epoch [59/100], Loss: 0.2238, Validation Loss: 0.3505
	--> Epoch [60/100], Loss: 0.2236, Validation Loss: 0.3491
	--> Epoch [61/100], Loss: 0.2348, Validation Loss: 0.3466
	--> Epoch [62/100], Loss: 0.2081, Validation Loss: 0.3438
	--> Epoch [63/100], Loss: 0.1963, Validation Loss: 0.3403
	--> Epoch [64/100], Loss: 0.1964, Validation Loss: 0.3380
	--> Epoch [65/100], Loss: 0.2268, Validation Loss: 0.3356
	--> Epoch [66/100], Loss: 0.2081, Validation Loss: 0.3327
	--> Epoch [67/100], Loss: 0.2234, Validation Loss: 0.3310
	--> Epoch [68/100], Loss: 0.2240, Validation Loss: 0.3291
	--> Epoch [69/100], Loss: 0.2069, Validation Loss: 0.3271
	--> Epoch [70/100], Loss: 0.1645, Validation Loss: 0.3249
	--> Epoch [71/100], Loss: 0.1700, Validation Loss: 0.3232
	--> Epoch [72/100], Loss: 0.1886, Validation Loss: 0.3220
	--> Epoch [73/100], Loss: 0.2170, Validation Loss: 0.3188
	--> Epoch [74/100], Loss: 0.1564, Validation Loss: 0.3163
	--> Epoch [75/100], Loss: 0.1678, Validation Loss: 0.3150
	--> Epoch [76/100], Loss: 0.1800, Validation Loss: 0.3145
	--> Epoch [77/100], Loss: 0.1501, Validation Loss: 0.3123
	--> Epoch [78/100], Loss: 0.1559, Validation Loss: 0.3112
	--> Epoch [79/100], Loss: 0.1418, Validation Loss: 0.3101
	--> Epoch [80/100], Loss: 0.1498, Validation Loss: 0.3080
	--> Epoch [81/100], Loss: 0.1622, Validation Loss: 0.3070
	--> Epoch [82/100], Loss: 0.1563, Validation Loss: 0.3052
	--> Epoch [83/100], Loss: 0.1470, Validation Loss: 0.3040
	--> Epoch [84/100], Loss: 0.1512, Validation Loss: 0.3028
	--> Epoch [85/100], Loss: 0.1605, Validation Loss: 0.3013
	--> Epoch [86/100], Loss: 0.1539, Validation Loss: 0.2992
	--> Epoch [87/100], Loss: 0.1515, Validation Loss: 0.2974
	--> Epoch [88/100], Loss: 0.1342, Validation Loss: 0.2954
	--> Epoch [89/100], Loss: 0.1347, Validation Loss: 0.2941
	--> Epoch [90/100], Loss: 0.1390, Validation Loss: 0.2928
	--> Epoch [91/100], Loss: 0.1309, Validation Loss: 0.2917
	--> Epoch [92/100], Loss: 0.1544, Validation Loss: 0.2904
	--> Epoch [93/100], Loss: 0.1404, Validation Loss: 0.2875
	--> Epoch [94/100], Loss: 0.1464, Validation Loss: 0.2865
	--> Epoch [95/100], Loss: 0.1484, Validation Loss: 0.2855
	--> Epoch [96/100], Loss: 0.1109, Validation Loss: 0.2840
	--> Epoch [97/100], Loss: 0.1290, Validation Loss: 0.2828
	--> Epoch [98/100], Loss: 0.1214, Validation Loss: 0.2824
	--> Epoch [99/100], Loss: 0.1424, Validation Loss: 0.2805
	--> Epoch [100/100], Loss: 0.1653, Validation Loss: 0.2795
	--> Training for Fold 1 took 0.45965003967285156 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7317, Validation Loss: 0.6811
	--> Epoch [2/100], Loss: 0.7330, Validation Loss: 0.6613
	--> Epoch [3/100], Loss: 0.7202, Validation Loss: 0.6470
	--> Epoch [4/100], Loss: 0.6898, Validation Loss: 0.6355
	--> Epoch [5/100], Loss: 0.6712, Validation Loss: 0.6244
	--> Epoch [6/100], Loss: 0.6452, Validation Loss: 0.6108
	--> Epoch [7/100], Loss: 0.6208, Validation Loss: 0.5988
	--> Epoch [8/100], Loss: 0.6188, Validation Loss: 0.5887
	--> Epoch [9/100], Loss: 0.6266, Validation Loss: 0.5819
	--> Epoch [10/100], Loss: 0.6309, Validation Loss: 0.5740
	--> Epoch [11/100], Loss: 0.5917, Validation Loss: 0.5637
	--> Epoch [12/100], Loss: 0.5785, Validation Loss: 0.5542
	--> Epoch [13/100], Loss: 0.5907, Validation Loss: 0.5456
	--> Epoch [14/100], Loss: 0.5589, Validation Loss: 0.5376
	--> Epoch [15/100], Loss: 0.5682, Validation Loss: 0.5288
	--> Epoch [16/100], Loss: 0.5449, Validation Loss: 0.5211
	--> Epoch [17/100], Loss: 0.5269, Validation Loss: 0.5146
	--> Epoch [18/100], Loss: 0.5159, Validation Loss: 0.5082
	--> Epoch [19/100], Loss: 0.5231, Validation Loss: 0.5021
	--> Epoch [20/100], Loss: 0.5127, Validation Loss: 0.4956
	--> Epoch [21/100], Loss: 0.5022, Validation Loss: 0.4896
	--> Epoch [22/100], Loss: 0.4947, Validation Loss: 0.4834
	--> Epoch [23/100], Loss: 0.5056, Validation Loss: 0.4789
	--> Epoch [24/100], Loss: 0.4841, Validation Loss: 0.4749
	--> Epoch [25/100], Loss: 0.4699, Validation Loss: 0.4712
	--> Epoch [26/100], Loss: 0.4512, Validation Loss: 0.4665
	--> Epoch [27/100], Loss: 0.4611, Validation Loss: 0.4645
	--> Epoch [28/100], Loss: 0.4469, Validation Loss: 0.4612
	--> Epoch [29/100], Loss: 0.4343, Validation Loss: 0.4584
	--> Epoch [30/100], Loss: 0.3984, Validation Loss: 0.4551
	--> Epoch [31/100], Loss: 0.4480, Validation Loss: 0.4541
	--> Epoch [32/100], Loss: 0.4341, Validation Loss: 0.4522
	--> Epoch [33/100], Loss: 0.4172, Validation Loss: 0.4506
	--> Epoch [34/100], Loss: 0.3840, Validation Loss: 0.4451
	--> Epoch [35/100], Loss: 0.3761, Validation Loss: 0.4426
	--> Epoch [36/100], Loss: 0.3695, Validation Loss: 0.4386
	--> Epoch [37/100], Loss: 0.3798, Validation Loss: 0.4370
	--> Epoch [38/100], Loss: 0.4086, Validation Loss: 0.4351
	--> Epoch [39/100], Loss: 0.3726, Validation Loss: 0.4346
	--> Epoch [40/100], Loss: 0.3780, Validation Loss: 0.4330
	--> Epoch [41/100], Loss: 0.3788, Validation Loss: 0.4282
	--> Epoch [42/100], Loss: 0.3615, Validation Loss: 0.4268
	--> Epoch [43/100], Loss: 0.3565, Validation Loss: 0.4242
	--> Epoch [44/100], Loss: 0.3409, Validation Loss: 0.4216
	--> Epoch [45/100], Loss: 0.3117, Validation Loss: 0.4179
	--> Epoch [46/100], Loss: 0.3365, Validation Loss: 0.4152
	--> Epoch [47/100], Loss: 0.3383, Validation Loss: 0.4127
	--> Epoch [48/100], Loss: 0.2966, Validation Loss: 0.4096
	--> Epoch [49/100], Loss: 0.3001, Validation Loss: 0.4083
	--> Epoch [50/100], Loss: 0.3148, Validation Loss: 0.4056
	--> Epoch [51/100], Loss: 0.3314, Validation Loss: 0.4036
	--> Epoch [52/100], Loss: 0.2845, Validation Loss: 0.4005
	--> Epoch [53/100], Loss: 0.3110, Validation Loss: 0.3978
	--> Epoch [54/100], Loss: 0.2885, Validation Loss: 0.3947
	--> Epoch [55/100], Loss: 0.3106, Validation Loss: 0.3921
	--> Epoch [56/100], Loss: 0.3228, Validation Loss: 0.3905
	--> Epoch [57/100], Loss: 0.2980, Validation Loss: 0.3882
	--> Epoch [58/100], Loss: 0.3099, Validation Loss: 0.3865
	--> Epoch [59/100], Loss: 0.2918, Validation Loss: 0.3837
	--> Epoch [60/100], Loss: 0.2517, Validation Loss: 0.3817
	--> Epoch [61/100], Loss: 0.2755, Validation Loss: 0.3794
	--> Epoch [62/100], Loss: 0.2851, Validation Loss: 0.3772
	--> Epoch [63/100], Loss: 0.2746, Validation Loss: 0.3755
	--> Epoch [64/100], Loss: 0.2819, Validation Loss: 0.3765
	--> Epoch [65/100], Loss: 0.2743, Validation Loss: 0.3741
	--> Epoch [66/100], Loss: 0.2394, Validation Loss: 0.3728
	--> Epoch [67/100], Loss: 0.2819, Validation Loss: 0.3719
	--> Epoch [68/100], Loss: 0.2778, Validation Loss: 0.3705
	--> Epoch [69/100], Loss: 0.2688, Validation Loss: 0.3690
	--> Epoch [70/100], Loss: 0.2614, Validation Loss: 0.3668
	--> Epoch [71/100], Loss: 0.2624, Validation Loss: 0.3649
	--> Epoch [72/100], Loss: 0.2216, Validation Loss: 0.3632
	--> Epoch [73/100], Loss: 0.2462, Validation Loss: 0.3618
	--> Epoch [74/100], Loss: 0.2452, Validation Loss: 0.3615
	--> Epoch [75/100], Loss: 0.2460, Validation Loss: 0.3603
	--> Epoch [76/100], Loss: 0.2838, Validation Loss: 0.3576
	--> Epoch [77/100], Loss: 0.2838, Validation Loss: 0.3561
	--> Epoch [78/100], Loss: 0.2303, Validation Loss: 0.3540
	--> Epoch [79/100], Loss: 0.2595, Validation Loss: 0.3526
	--> Epoch [80/100], Loss: 0.2505, Validation Loss: 0.3509
	--> Epoch [81/100], Loss: 0.2112, Validation Loss: 0.3499
	--> Epoch [82/100], Loss: 0.2055, Validation Loss: 0.3487
	--> Epoch [83/100], Loss: 0.2074, Validation Loss: 0.3464
	--> Epoch [84/100], Loss: 0.2189, Validation Loss: 0.3468
	--> Epoch [85/100], Loss: 0.2464, Validation Loss: 0.3459
	--> Epoch [86/100], Loss: 0.2544, Validation Loss: 0.3423
	--> Epoch [87/100], Loss: 0.1986, Validation Loss: 0.3411
	--> Epoch [88/100], Loss: 0.2574, Validation Loss: 0.3415
	--> Epoch [89/100], Loss: 0.2282, Validation Loss: 0.3411
	--> Epoch [90/100], Loss: 0.2621, Validation Loss: 0.3398
	--> Epoch [91/100], Loss: 0.2433, Validation Loss: 0.3392
	--> Epoch [92/100], Loss: 0.1948, Validation Loss: 0.3402
	--> Epoch [93/100], Loss: 0.1806, Validation Loss: 0.3396
	--> Epoch [94/100], Loss: 0.2201, Validation Loss: 0.3385
	--> Epoch [95/100], Loss: 0.2350, Validation Loss: 0.3373
	--> Epoch [96/100], Loss: 0.2171, Validation Loss: 0.3367
	--> Epoch [97/100], Loss: 0.2044, Validation Loss: 0.3360
	--> Epoch [98/100], Loss: 0.1980, Validation Loss: 0.3342
	--> Epoch [99/100], Loss: 0.2272, Validation Loss: 0.3322
	--> Epoch [100/100], Loss: 0.2198, Validation Loss: 0.3315
	--> Training for Fold 2 took 0.4089803695678711 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6725, Validation Loss: 0.6597
	--> Epoch [2/100], Loss: 0.6543, Validation Loss: 0.6450
	--> Epoch [3/100], Loss: 0.6517, Validation Loss: 0.6330
	--> Epoch [4/100], Loss: 0.6195, Validation Loss: 0.6205
	--> Epoch [5/100], Loss: 0.6258, Validation Loss: 0.6103
	--> Epoch [6/100], Loss: 0.5893, Validation Loss: 0.5997
	--> Epoch [7/100], Loss: 0.5904, Validation Loss: 0.5917
	--> Epoch [8/100], Loss: 0.5564, Validation Loss: 0.5837
	--> Epoch [9/100], Loss: 0.5495, Validation Loss: 0.5756
	--> Epoch [10/100], Loss: 0.5641, Validation Loss: 0.5677
	--> Epoch [11/100], Loss: 0.5257, Validation Loss: 0.5596
	--> Epoch [12/100], Loss: 0.4890, Validation Loss: 0.5517
	--> Epoch [13/100], Loss: 0.4942, Validation Loss: 0.5439
	--> Epoch [14/100], Loss: 0.4651, Validation Loss: 0.5368
	--> Epoch [15/100], Loss: 0.4603, Validation Loss: 0.5294
	--> Epoch [16/100], Loss: 0.4707, Validation Loss: 0.5225
	--> Epoch [17/100], Loss: 0.4411, Validation Loss: 0.5159
	--> Epoch [18/100], Loss: 0.4418, Validation Loss: 0.5090
	--> Epoch [19/100], Loss: 0.4334, Validation Loss: 0.5022
	--> Epoch [20/100], Loss: 0.4271, Validation Loss: 0.4964
	--> Epoch [21/100], Loss: 0.3939, Validation Loss: 0.4905
	--> Epoch [22/100], Loss: 0.3917, Validation Loss: 0.4856
	--> Epoch [23/100], Loss: 0.3941, Validation Loss: 0.4812
	--> Epoch [24/100], Loss: 0.3857, Validation Loss: 0.4759
	--> Epoch [25/100], Loss: 0.3412, Validation Loss: 0.4713
	--> Epoch [26/100], Loss: 0.3842, Validation Loss: 0.4657
	--> Epoch [27/100], Loss: 0.3313, Validation Loss: 0.4615
	--> Epoch [28/100], Loss: 0.3486, Validation Loss: 0.4567
	--> Epoch [29/100], Loss: 0.3439, Validation Loss: 0.4520
	--> Epoch [30/100], Loss: 0.3131, Validation Loss: 0.4477
	--> Epoch [31/100], Loss: 0.3195, Validation Loss: 0.4444
	--> Epoch [32/100], Loss: 0.3278, Validation Loss: 0.4412
	--> Epoch [33/100], Loss: 0.3173, Validation Loss: 0.4370
	--> Epoch [34/100], Loss: 0.3087, Validation Loss: 0.4323
	--> Epoch [35/100], Loss: 0.2907, Validation Loss: 0.4279
	--> Epoch [36/100], Loss: 0.3126, Validation Loss: 0.4242
	--> Epoch [37/100], Loss: 0.2822, Validation Loss: 0.4209
	--> Epoch [38/100], Loss: 0.2785, Validation Loss: 0.4179
	--> Epoch [39/100], Loss: 0.2776, Validation Loss: 0.4154
	--> Epoch [40/100], Loss: 0.2625, Validation Loss: 0.4120
	--> Epoch [41/100], Loss: 0.2683, Validation Loss: 0.4083
	--> Epoch [42/100], Loss: 0.2595, Validation Loss: 0.4048
	--> Epoch [43/100], Loss: 0.2503, Validation Loss: 0.4025
	--> Epoch [44/100], Loss: 0.2577, Validation Loss: 0.4000
	--> Epoch [45/100], Loss: 0.2592, Validation Loss: 0.3974
	--> Epoch [46/100], Loss: 0.2478, Validation Loss: 0.3949
	--> Epoch [47/100], Loss: 0.2382, Validation Loss: 0.3925
	--> Epoch [48/100], Loss: 0.2265, Validation Loss: 0.3902
	--> Epoch [49/100], Loss: 0.2321, Validation Loss: 0.3879
	--> Epoch [50/100], Loss: 0.2244, Validation Loss: 0.3851
	--> Epoch [51/100], Loss: 0.2291, Validation Loss: 0.3828
	--> Epoch [52/100], Loss: 0.2316, Validation Loss: 0.3805
	--> Epoch [53/100], Loss: 0.1888, Validation Loss: 0.3784
	--> Epoch [54/100], Loss: 0.2179, Validation Loss: 0.3767
	--> Epoch [55/100], Loss: 0.1986, Validation Loss: 0.3747
	--> Epoch [56/100], Loss: 0.2032, Validation Loss: 0.3724
	--> Epoch [57/100], Loss: 0.1870, Validation Loss: 0.3694
	--> Epoch [58/100], Loss: 0.1902, Validation Loss: 0.3679
	--> Epoch [59/100], Loss: 0.1910, Validation Loss: 0.3661
	--> Epoch [60/100], Loss: 0.2006, Validation Loss: 0.3643
	--> Epoch [61/100], Loss: 0.1522, Validation Loss: 0.3626
	--> Epoch [62/100], Loss: 0.2057, Validation Loss: 0.3604
	--> Epoch [63/100], Loss: 0.1522, Validation Loss: 0.3581
	--> Epoch [64/100], Loss: 0.1546, Validation Loss: 0.3566
	--> Epoch [65/100], Loss: 0.1426, Validation Loss: 0.3546
	--> Epoch [66/100], Loss: 0.1567, Validation Loss: 0.3534
	--> Epoch [67/100], Loss: 0.1652, Validation Loss: 0.3519
	--> Epoch [68/100], Loss: 0.1426, Validation Loss: 0.3511
	--> Epoch [69/100], Loss: 0.1547, Validation Loss: 0.3499
	--> Epoch [70/100], Loss: 0.1622, Validation Loss: 0.3478
	--> Epoch [71/100], Loss: 0.1635, Validation Loss: 0.3466
	--> Epoch [72/100], Loss: 0.1416, Validation Loss: 0.3461
	--> Epoch [73/100], Loss: 0.1443, Validation Loss: 0.3448
	--> Epoch [74/100], Loss: 0.1380, Validation Loss: 0.3428
	--> Epoch [75/100], Loss: 0.1521, Validation Loss: 0.3417
	--> Epoch [76/100], Loss: 0.1262, Validation Loss: 0.3404
	--> Epoch [77/100], Loss: 0.1147, Validation Loss: 0.3390
	--> Epoch [78/100], Loss: 0.1165, Validation Loss: 0.3383
	--> Epoch [79/100], Loss: 0.1369, Validation Loss: 0.3372
	--> Epoch [80/100], Loss: 0.1711, Validation Loss: 0.3368
	--> Epoch [81/100], Loss: 0.1240, Validation Loss: 0.3345
	--> Epoch [82/100], Loss: 0.1427, Validation Loss: 0.3339
	--> Epoch [83/100], Loss: 0.1490, Validation Loss: 0.3332
	--> Epoch [84/100], Loss: 0.1159, Validation Loss: 0.3315
	--> Epoch [85/100], Loss: 0.1030, Validation Loss: 0.3307
	--> Epoch [86/100], Loss: 0.1035, Validation Loss: 0.3300
	--> Epoch [87/100], Loss: 0.1287, Validation Loss: 0.3287
	--> Epoch [88/100], Loss: 0.1062, Validation Loss: 0.3271
	--> Epoch [89/100], Loss: 0.1207, Validation Loss: 0.3256
	--> Epoch [90/100], Loss: 0.1049, Validation Loss: 0.3256
	--> Epoch [91/100], Loss: 0.1342, Validation Loss: 0.3243
	--> Epoch [92/100], Loss: 0.1256, Validation Loss: 0.3226
	--> Epoch [93/100], Loss: 0.1199, Validation Loss: 0.3223
	--> Epoch [94/100], Loss: 0.1120, Validation Loss: 0.3217
	--> Epoch [95/100], Loss: 0.1360, Validation Loss: 0.3208
	--> Epoch [96/100], Loss: 0.1041, Validation Loss: 0.3204
	--> Epoch [97/100], Loss: 0.1227, Validation Loss: 0.3203
	--> Epoch [98/100], Loss: 0.1178, Validation Loss: 0.3193
	--> Epoch [99/100], Loss: 0.1196, Validation Loss: 0.3194
	--> Epoch [100/100], Loss: 0.0924, Validation Loss: 0.3195
	--> Training for Fold 3 took 0.43296098709106445 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7556, Validation Loss: 1.0297
	--> Epoch [2/100], Loss: 0.7327, Validation Loss: 0.9887
	--> Epoch [3/100], Loss: 0.7094, Validation Loss: 0.9485
	--> Epoch [4/100], Loss: 0.6762, Validation Loss: 0.9116
	--> Epoch [5/100], Loss: 0.6601, Validation Loss: 0.8861
	--> Epoch [6/100], Loss: 0.6404, Validation Loss: 0.8596
	--> Epoch [7/100], Loss: 0.6109, Validation Loss: 0.8373
	--> Epoch [8/100], Loss: 0.5934, Validation Loss: 0.8191
	--> Epoch [9/100], Loss: 0.5874, Validation Loss: 0.7994
	--> Epoch [10/100], Loss: 0.5789, Validation Loss: 0.7831
	--> Epoch [11/100], Loss: 0.5788, Validation Loss: 0.7684
	--> Epoch [12/100], Loss: 0.5475, Validation Loss: 0.7516
	--> Epoch [13/100], Loss: 0.5134, Validation Loss: 0.7347
	--> Epoch [14/100], Loss: 0.4957, Validation Loss: 0.7152
	--> Epoch [15/100], Loss: 0.5197, Validation Loss: 0.7024
	--> Epoch [16/100], Loss: 0.4936, Validation Loss: 0.6861
	--> Epoch [17/100], Loss: 0.4684, Validation Loss: 0.6742
	--> Epoch [18/100], Loss: 0.4571, Validation Loss: 0.6602
	--> Epoch [19/100], Loss: 0.4390, Validation Loss: 0.6496
	--> Epoch [20/100], Loss: 0.4106, Validation Loss: 0.6366
	--> Epoch [21/100], Loss: 0.4225, Validation Loss: 0.6226
	--> Epoch [22/100], Loss: 0.4195, Validation Loss: 0.6128
	--> Epoch [23/100], Loss: 0.4169, Validation Loss: 0.6008
	--> Epoch [24/100], Loss: 0.3868, Validation Loss: 0.5893
	--> Epoch [25/100], Loss: 0.3860, Validation Loss: 0.5797
	--> Epoch [26/100], Loss: 0.4081, Validation Loss: 0.5718
	--> Epoch [27/100], Loss: 0.3862, Validation Loss: 0.5628
	--> Epoch [28/100], Loss: 0.3572, Validation Loss: 0.5553
	--> Epoch [29/100], Loss: 0.3736, Validation Loss: 0.5481
	--> Epoch [30/100], Loss: 0.3509, Validation Loss: 0.5398
	--> Epoch [31/100], Loss: 0.3373, Validation Loss: 0.5328
	--> Epoch [32/100], Loss: 0.3318, Validation Loss: 0.5257
	--> Epoch [33/100], Loss: 0.3315, Validation Loss: 0.5207
	--> Epoch [34/100], Loss: 0.3324, Validation Loss: 0.5168
	--> Epoch [35/100], Loss: 0.3090, Validation Loss: 0.5113
	--> Epoch [36/100], Loss: 0.3212, Validation Loss: 0.5062
	--> Epoch [37/100], Loss: 0.2782, Validation Loss: 0.5033
	--> Epoch [38/100], Loss: 0.2816, Validation Loss: 0.4994
	--> Epoch [39/100], Loss: 0.2759, Validation Loss: 0.4934
	--> Epoch [40/100], Loss: 0.2677, Validation Loss: 0.4882
	--> Epoch [41/100], Loss: 0.2738, Validation Loss: 0.4847
	--> Epoch [42/100], Loss: 0.2576, Validation Loss: 0.4822
	--> Epoch [43/100], Loss: 0.2696, Validation Loss: 0.4771
	--> Epoch [44/100], Loss: 0.2379, Validation Loss: 0.4744
	--> Epoch [45/100], Loss: 0.2402, Validation Loss: 0.4698
	--> Epoch [46/100], Loss: 0.2333, Validation Loss: 0.4675
	--> Epoch [47/100], Loss: 0.2282, Validation Loss: 0.4661
	--> Epoch [48/100], Loss: 0.2475, Validation Loss: 0.4621
	--> Epoch [49/100], Loss: 0.2255, Validation Loss: 0.4588
	--> Epoch [50/100], Loss: 0.2048, Validation Loss: 0.4549
	--> Epoch [51/100], Loss: 0.2153, Validation Loss: 0.4532
	--> Epoch [52/100], Loss: 0.2306, Validation Loss: 0.4516
	--> Epoch [53/100], Loss: 0.2414, Validation Loss: 0.4478
	--> Epoch [54/100], Loss: 0.2165, Validation Loss: 0.4455
	--> Epoch [55/100], Loss: 0.1886, Validation Loss: 0.4416
	--> Epoch [56/100], Loss: 0.1767, Validation Loss: 0.4407
	--> Epoch [57/100], Loss: 0.1921, Validation Loss: 0.4382
	--> Epoch [58/100], Loss: 0.2067, Validation Loss: 0.4367
	--> Epoch [59/100], Loss: 0.2145, Validation Loss: 0.4326
	--> Epoch [60/100], Loss: 0.1622, Validation Loss: 0.4306
	--> Epoch [61/100], Loss: 0.1868, Validation Loss: 0.4288
	--> Epoch [62/100], Loss: 0.1930, Validation Loss: 0.4283
	--> Epoch [63/100], Loss: 0.1748, Validation Loss: 0.4261
	--> Epoch [64/100], Loss: 0.1698, Validation Loss: 0.4253
	--> Epoch [65/100], Loss: 0.1510, Validation Loss: 0.4247
	--> Epoch [66/100], Loss: 0.1706, Validation Loss: 0.4227
	--> Epoch [67/100], Loss: 0.1579, Validation Loss: 0.4202
	--> Epoch [68/100], Loss: 0.1545, Validation Loss: 0.4186
	--> Epoch [69/100], Loss: 0.1562, Validation Loss: 0.4173
	--> Epoch [70/100], Loss: 0.1973, Validation Loss: 0.4173
	--> Epoch [71/100], Loss: 0.1570, Validation Loss: 0.4152
	--> Epoch [72/100], Loss: 0.1475, Validation Loss: 0.4130
	--> Epoch [73/100], Loss: 0.1448, Validation Loss: 0.4120
	--> Epoch [74/100], Loss: 0.1432, Validation Loss: 0.4118
	--> Epoch [75/100], Loss: 0.1274, Validation Loss: 0.4100
	--> Epoch [76/100], Loss: 0.1562, Validation Loss: 0.4093
	--> Epoch [77/100], Loss: 0.1525, Validation Loss: 0.4095
	--> Epoch [78/100], Loss: 0.1191, Validation Loss: 0.4089
	--> Epoch [79/100], Loss: 0.1249, Validation Loss: 0.4083
	--> Epoch [80/100], Loss: 0.1446, Validation Loss: 0.4068
	--> Epoch [81/100], Loss: 0.1380, Validation Loss: 0.4044
	--> Epoch [82/100], Loss: 0.1100, Validation Loss: 0.4035
	--> Epoch [83/100], Loss: 0.1264, Validation Loss: 0.4022
	--> Epoch [84/100], Loss: 0.1124, Validation Loss: 0.4030
	--> Epoch [85/100], Loss: 0.1139, Validation Loss: 0.4032
	--> Epoch [86/100], Loss: 0.1194, Validation Loss: 0.4044
Early stopping
	--> Training for Fold 4 took 0.46460533142089844 sec, using 86 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7386, Validation Loss: 0.7222
	--> Epoch [2/100], Loss: 0.7007, Validation Loss: 0.7160
	--> Epoch [3/100], Loss: 0.6935, Validation Loss: 0.7091
	--> Epoch [4/100], Loss: 0.6730, Validation Loss: 0.7025
	--> Epoch [5/100], Loss: 0.6489, Validation Loss: 0.6977
	--> Epoch [6/100], Loss: 0.6329, Validation Loss: 0.6933
	--> Epoch [7/100], Loss: 0.6215, Validation Loss: 0.6885
	--> Epoch [8/100], Loss: 0.5972, Validation Loss: 0.6841
	--> Epoch [9/100], Loss: 0.5707, Validation Loss: 0.6797
	--> Epoch [10/100], Loss: 0.5612, Validation Loss: 0.6758
	--> Epoch [11/100], Loss: 0.5526, Validation Loss: 0.6724
	--> Epoch [12/100], Loss: 0.5521, Validation Loss: 0.6677
	--> Epoch [13/100], Loss: 0.5261, Validation Loss: 0.6627
	--> Epoch [14/100], Loss: 0.5273, Validation Loss: 0.6599
	--> Epoch [15/100], Loss: 0.4872, Validation Loss: 0.6561
	--> Epoch [16/100], Loss: 0.4829, Validation Loss: 0.6533
	--> Epoch [17/100], Loss: 0.4795, Validation Loss: 0.6501
	--> Epoch [18/100], Loss: 0.4706, Validation Loss: 0.6465
	--> Epoch [19/100], Loss: 0.4551, Validation Loss: 0.6436
	--> Epoch [20/100], Loss: 0.4279, Validation Loss: 0.6413
	--> Epoch [21/100], Loss: 0.4465, Validation Loss: 0.6372
	--> Epoch [22/100], Loss: 0.4161, Validation Loss: 0.6332
	--> Epoch [23/100], Loss: 0.4187, Validation Loss: 0.6292
	--> Epoch [24/100], Loss: 0.4156, Validation Loss: 0.6272
	--> Epoch [25/100], Loss: 0.3988, Validation Loss: 0.6257
	--> Epoch [26/100], Loss: 0.3899, Validation Loss: 0.6237
	--> Epoch [27/100], Loss: 0.3921, Validation Loss: 0.6198
	--> Epoch [28/100], Loss: 0.3835, Validation Loss: 0.6183
	--> Epoch [29/100], Loss: 0.3461, Validation Loss: 0.6153
	--> Epoch [30/100], Loss: 0.3400, Validation Loss: 0.6117
	--> Epoch [31/100], Loss: 0.3379, Validation Loss: 0.6074
	--> Epoch [32/100], Loss: 0.3456, Validation Loss: 0.6051
	--> Epoch [33/100], Loss: 0.3255, Validation Loss: 0.6022
	--> Epoch [34/100], Loss: 0.3473, Validation Loss: 0.6010
	--> Epoch [35/100], Loss: 0.3129, Validation Loss: 0.5993
	--> Epoch [36/100], Loss: 0.3311, Validation Loss: 0.5977
	--> Epoch [37/100], Loss: 0.2960, Validation Loss: 0.5952
	--> Epoch [38/100], Loss: 0.2973, Validation Loss: 0.5933
	--> Epoch [39/100], Loss: 0.2892, Validation Loss: 0.5908
	--> Epoch [40/100], Loss: 0.3202, Validation Loss: 0.5888
	--> Epoch [41/100], Loss: 0.3024, Validation Loss: 0.5878
	--> Epoch [42/100], Loss: 0.2780, Validation Loss: 0.5865
	--> Epoch [43/100], Loss: 0.2834, Validation Loss: 0.5853
	--> Epoch [44/100], Loss: 0.2887, Validation Loss: 0.5841
	--> Epoch [45/100], Loss: 0.2631, Validation Loss: 0.5813
	--> Epoch [46/100], Loss: 0.2832, Validation Loss: 0.5803
	--> Epoch [47/100], Loss: 0.2858, Validation Loss: 0.5785
	--> Epoch [48/100], Loss: 0.2458, Validation Loss: 0.5768
	--> Epoch [49/100], Loss: 0.2297, Validation Loss: 0.5744
	--> Epoch [50/100], Loss: 0.2510, Validation Loss: 0.5728
	--> Epoch [51/100], Loss: 0.2714, Validation Loss: 0.5717
	--> Epoch [52/100], Loss: 0.2317, Validation Loss: 0.5717
	--> Epoch [53/100], Loss: 0.2686, Validation Loss: 0.5699
	--> Epoch [54/100], Loss: 0.2586, Validation Loss: 0.5675
	--> Epoch [55/100], Loss: 0.2528, Validation Loss: 0.5684
	--> Epoch [56/100], Loss: 0.2466, Validation Loss: 0.5690
	--> Epoch [57/100], Loss: 0.2389, Validation Loss: 0.5682
Early stopping
	--> Training for Fold 5 took 0.24130702018737793 sec, using 57 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6646
	--> Final training Epoch [2/100], Loss: 0.6478
	--> Final training Epoch [3/100], Loss: 0.6195
	--> Final training Epoch [4/100], Loss: 0.6083
	--> Final training Epoch [5/100], Loss: 0.5935
	--> Final training Epoch [6/100], Loss: 0.5576
	--> Final training Epoch [7/100], Loss: 0.5703
	--> Final training Epoch [8/100], Loss: 0.5417
	--> Final training Epoch [9/100], Loss: 0.5288
	--> Final training Epoch [10/100], Loss: 0.5169
	--> Final training Epoch [11/100], Loss: 0.4773
	--> Final training Epoch [12/100], Loss: 0.4938
	--> Final training Epoch [13/100], Loss: 0.4870
	--> Final training Epoch [14/100], Loss: 0.4834
	--> Final training Epoch [15/100], Loss: 0.4757
	--> Final training Epoch [16/100], Loss: 0.4393
	--> Final training Epoch [17/100], Loss: 0.4646
	--> Final training Epoch [18/100], Loss: 0.4387
	--> Final training Epoch [19/100], Loss: 0.4485
	--> Final training Epoch [20/100], Loss: 0.3987
	--> Final training Epoch [21/100], Loss: 0.4150
	--> Final training Epoch [22/100], Loss: 0.4156
	--> Final training Epoch [23/100], Loss: 0.3744
	--> Final training Epoch [24/100], Loss: 0.3739
	--> Final training Epoch [25/100], Loss: 0.3561
	--> Final training Epoch [26/100], Loss: 0.3794
	--> Final training Epoch [27/100], Loss: 0.3760
	--> Final training Epoch [28/100], Loss: 0.3376
	--> Final training Epoch [29/100], Loss: 0.3617
	--> Final training Epoch [30/100], Loss: 0.3440
	--> Final training Epoch [31/100], Loss: 0.3329
	--> Final training Epoch [32/100], Loss: 0.3125
	--> Final training Epoch [33/100], Loss: 0.3070
	--> Final training Epoch [34/100], Loss: 0.3300
	--> Final training Epoch [35/100], Loss: 0.3110
	--> Final training Epoch [36/100], Loss: 0.3047
	--> Final training Epoch [37/100], Loss: 0.3076
	--> Final training Epoch [38/100], Loss: 0.2849
	--> Final training Epoch [39/100], Loss: 0.2776
	--> Final training Epoch [40/100], Loss: 0.2741
	--> Final training Epoch [41/100], Loss: 0.2736
	--> Final training Epoch [42/100], Loss: 0.2607
	--> Final training Epoch [43/100], Loss: 0.2676
	--> Final training Epoch [44/100], Loss: 0.2779
	--> Final training Epoch [45/100], Loss: 0.2383
	--> Final training Epoch [46/100], Loss: 0.2643
	--> Final training Epoch [47/100], Loss: 0.2321
	--> Final training Epoch [48/100], Loss: 0.2371
	--> Final training Epoch [49/100], Loss: 0.2528
	--> Final training Epoch [50/100], Loss: 0.2343
	--> Final training Epoch [51/100], Loss: 0.2526
	--> Final training Epoch [52/100], Loss: 0.2380
	--> Final training Epoch [53/100], Loss: 0.2052
	--> Final training Epoch [54/100], Loss: 0.2324
	--> Final training Epoch [55/100], Loss: 0.2150
	--> Final training Epoch [56/100], Loss: 0.2067
	--> Final training Epoch [57/100], Loss: 0.1817
	--> Final training Epoch [58/100], Loss: 0.2344
	--> Final training Epoch [59/100], Loss: 0.2004
	--> Final training Epoch [60/100], Loss: 0.2023
	--> Final training Epoch [61/100], Loss: 0.2137
	--> Final training Epoch [62/100], Loss: 0.1994
	--> Final training Epoch [63/100], Loss: 0.1949
	--> Final training Epoch [64/100], Loss: 0.2002
	--> Final training Epoch [65/100], Loss: 0.2121
	--> Final training Epoch [66/100], Loss: 0.1950
	--> Final training Epoch [67/100], Loss: 0.1896
	--> Final training Epoch [68/100], Loss: 0.1915
	--> Final training Epoch [69/100], Loss: 0.1557
	--> Final training Epoch [70/100], Loss: 0.1740
	--> Final training Epoch [71/100], Loss: 0.1567
	--> Final training Epoch [72/100], Loss: 0.1578
	--> Final training Epoch [73/100], Loss: 0.1736
	--> Final training Epoch [74/100], Loss: 0.1393
	--> Final training Epoch [75/100], Loss: 0.1621
	--> Final training Epoch [76/100], Loss: 0.1728
	--> Final training Epoch [77/100], Loss: 0.1342
	--> Final training Epoch [78/100], Loss: 0.1520
	--> Final training Epoch [79/100], Loss: 0.1489
	--> Final training Epoch [80/100], Loss: 0.1573
	--> Final training Epoch [81/100], Loss: 0.1428
	--> Final training Epoch [82/100], Loss: 0.1475
	--> Final training Epoch [83/100], Loss: 0.1326
	--> Final training Epoch [84/100], Loss: 0.1213
	--> Final training Epoch [85/100], Loss: 0.1722
	--> Final training Epoch [86/100], Loss: 0.1708
	--> Final training Epoch [87/100], Loss: 0.1289
	--> Final training Epoch [88/100], Loss: 0.1371
	--> Final training Epoch [89/100], Loss: 0.1416
	--> Final training Epoch [90/100], Loss: 0.1361
	--> Final training Epoch [91/100], Loss: 0.1333
	--> Final training Epoch [92/100], Loss: 0.1198
	--> Final training Epoch [93/100], Loss: 0.1287
	--> Final training Epoch [94/100], Loss: 0.1140
	--> Final training Epoch [95/100], Loss: 0.1482
	--> Final training Epoch [96/100], Loss: 0.1245
	--> Final training Epoch [97/100], Loss: 0.1346
	--> Final training Epoch [98/100], Loss: 0.1167
	--> Final training Epoch [99/100], Loss: 0.1272
	--> Final training Epoch [100/100], Loss: 0.1256

Final training took 0.3870837688446045 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8812
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8497, Validation Loss: 0.3479,  Current Best Accuracy: 0.8497,  Current Best Validation Loss: 0.3479
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.3925,  Current Best Accuracy: 0.8497,  Current Best Validation Loss: 0.3479

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6600, Validation Loss: 0.6615
	--> Epoch [2/100], Loss: 0.6514, Validation Loss: 0.6437
	--> Epoch [3/100], Loss: 0.6263, Validation Loss: 0.6271
	--> Epoch [4/100], Loss: 0.6281, Validation Loss: 0.6144
	--> Epoch [5/100], Loss: 0.5887, Validation Loss: 0.6019
	--> Epoch [6/100], Loss: 0.6051, Validation Loss: 0.5870
	--> Epoch [7/100], Loss: 0.5673, Validation Loss: 0.5748
	--> Epoch [8/100], Loss: 0.5367, Validation Loss: 0.5624
	--> Epoch [9/100], Loss: 0.5259, Validation Loss: 0.5503
	--> Epoch [10/100], Loss: 0.5331, Validation Loss: 0.5410
	--> Epoch [11/100], Loss: 0.4947, Validation Loss: 0.5326
	--> Epoch [12/100], Loss: 0.5082, Validation Loss: 0.5255
	--> Epoch [13/100], Loss: 0.4641, Validation Loss: 0.5164
	--> Epoch [14/100], Loss: 0.4873, Validation Loss: 0.5081
	--> Epoch [15/100], Loss: 0.4707, Validation Loss: 0.4993
	--> Epoch [16/100], Loss: 0.4672, Validation Loss: 0.4911
	--> Epoch [17/100], Loss: 0.4595, Validation Loss: 0.4834
	--> Epoch [18/100], Loss: 0.4642, Validation Loss: 0.4763
	--> Epoch [19/100], Loss: 0.4365, Validation Loss: 0.4702
	--> Epoch [20/100], Loss: 0.4509, Validation Loss: 0.4634
	--> Epoch [21/100], Loss: 0.4499, Validation Loss: 0.4577
	--> Epoch [22/100], Loss: 0.4207, Validation Loss: 0.4511
	--> Epoch [23/100], Loss: 0.3811, Validation Loss: 0.4446
	--> Epoch [24/100], Loss: 0.4098, Validation Loss: 0.4400
	--> Epoch [25/100], Loss: 0.3780, Validation Loss: 0.4350
	--> Epoch [26/100], Loss: 0.3502, Validation Loss: 0.4305
	--> Epoch [27/100], Loss: 0.3631, Validation Loss: 0.4252
	--> Epoch [28/100], Loss: 0.3719, Validation Loss: 0.4199
	--> Epoch [29/100], Loss: 0.3397, Validation Loss: 0.4164
	--> Epoch [30/100], Loss: 0.3327, Validation Loss: 0.4123
	--> Epoch [31/100], Loss: 0.3438, Validation Loss: 0.4081
	--> Epoch [32/100], Loss: 0.3199, Validation Loss: 0.4031
	--> Epoch [33/100], Loss: 0.3153, Validation Loss: 0.3989
	--> Epoch [34/100], Loss: 0.2996, Validation Loss: 0.3953
	--> Epoch [35/100], Loss: 0.3176, Validation Loss: 0.3914
	--> Epoch [36/100], Loss: 0.3185, Validation Loss: 0.3862
	--> Epoch [37/100], Loss: 0.2882, Validation Loss: 0.3823
	--> Epoch [38/100], Loss: 0.2801, Validation Loss: 0.3792
	--> Epoch [39/100], Loss: 0.2985, Validation Loss: 0.3767
	--> Epoch [40/100], Loss: 0.2873, Validation Loss: 0.3725
	--> Epoch [41/100], Loss: 0.2616, Validation Loss: 0.3699
	--> Epoch [42/100], Loss: 0.2563, Validation Loss: 0.3675
	--> Epoch [43/100], Loss: 0.2794, Validation Loss: 0.3621
	--> Epoch [44/100], Loss: 0.2680, Validation Loss: 0.3586
	--> Epoch [45/100], Loss: 0.2433, Validation Loss: 0.3562
	--> Epoch [46/100], Loss: 0.2658, Validation Loss: 0.3539
	--> Epoch [47/100], Loss: 0.2519, Validation Loss: 0.3512
	--> Epoch [48/100], Loss: 0.2611, Validation Loss: 0.3475
	--> Epoch [49/100], Loss: 0.2603, Validation Loss: 0.3449
	--> Epoch [50/100], Loss: 0.2055, Validation Loss: 0.3420
	--> Epoch [51/100], Loss: 0.2106, Validation Loss: 0.3395
	--> Epoch [52/100], Loss: 0.2037, Validation Loss: 0.3357
	--> Epoch [53/100], Loss: 0.2358, Validation Loss: 0.3342
	--> Epoch [54/100], Loss: 0.2154, Validation Loss: 0.3314
	--> Epoch [55/100], Loss: 0.2316, Validation Loss: 0.3291
	--> Epoch [56/100], Loss: 0.2180, Validation Loss: 0.3265
	--> Epoch [57/100], Loss: 0.1843, Validation Loss: 0.3247
	--> Epoch [58/100], Loss: 0.1808, Validation Loss: 0.3222
	--> Epoch [59/100], Loss: 0.2321, Validation Loss: 0.3195
	--> Epoch [60/100], Loss: 0.1884, Validation Loss: 0.3171
	--> Epoch [61/100], Loss: 0.1871, Validation Loss: 0.3143
	--> Epoch [62/100], Loss: 0.1876, Validation Loss: 0.3122
	--> Epoch [63/100], Loss: 0.1796, Validation Loss: 0.3099
	--> Epoch [64/100], Loss: 0.1633, Validation Loss: 0.3070
	--> Epoch [65/100], Loss: 0.1682, Validation Loss: 0.3057
	--> Epoch [66/100], Loss: 0.1971, Validation Loss: 0.3043
	--> Epoch [67/100], Loss: 0.1950, Validation Loss: 0.3023
	--> Epoch [68/100], Loss: 0.1567, Validation Loss: 0.3004
	--> Epoch [69/100], Loss: 0.1434, Validation Loss: 0.2994
	--> Epoch [70/100], Loss: 0.1762, Validation Loss: 0.2989
	--> Epoch [71/100], Loss: 0.1543, Validation Loss: 0.2982
	--> Epoch [72/100], Loss: 0.1465, Validation Loss: 0.2968
	--> Epoch [73/100], Loss: 0.1693, Validation Loss: 0.2945
	--> Epoch [74/100], Loss: 0.1574, Validation Loss: 0.2936
	--> Epoch [75/100], Loss: 0.1606, Validation Loss: 0.2942
	--> Epoch [76/100], Loss: 0.1577, Validation Loss: 0.2925
	--> Epoch [77/100], Loss: 0.1828, Validation Loss: 0.2922
	--> Epoch [78/100], Loss: 0.1307, Validation Loss: 0.2915
	--> Epoch [79/100], Loss: 0.1499, Validation Loss: 0.2914
	--> Epoch [80/100], Loss: 0.1649, Validation Loss: 0.2892
	--> Epoch [81/100], Loss: 0.1440, Validation Loss: 0.2868
	--> Epoch [82/100], Loss: 0.1578, Validation Loss: 0.2860
	--> Epoch [83/100], Loss: 0.1430, Validation Loss: 0.2846
	--> Epoch [84/100], Loss: 0.1326, Validation Loss: 0.2828
	--> Epoch [85/100], Loss: 0.1248, Validation Loss: 0.2820
	--> Epoch [86/100], Loss: 0.1759, Validation Loss: 0.2805
	--> Epoch [87/100], Loss: 0.1492, Validation Loss: 0.2796
	--> Epoch [88/100], Loss: 0.1505, Validation Loss: 0.2776
	--> Epoch [89/100], Loss: 0.1156, Validation Loss: 0.2770
	--> Epoch [90/100], Loss: 0.1249, Validation Loss: 0.2765
	--> Epoch [91/100], Loss: 0.1420, Validation Loss: 0.2762
	--> Epoch [92/100], Loss: 0.1193, Validation Loss: 0.2749
	--> Epoch [93/100], Loss: 0.1212, Validation Loss: 0.2745
	--> Epoch [94/100], Loss: 0.1084, Validation Loss: 0.2735
	--> Epoch [95/100], Loss: 0.1134, Validation Loss: 0.2717
	--> Epoch [96/100], Loss: 0.1099, Validation Loss: 0.2721
	--> Epoch [97/100], Loss: 0.1042, Validation Loss: 0.2717
	--> Epoch [98/100], Loss: 0.1087, Validation Loss: 0.2723
Early stopping
	--> Training for Fold 1 took 0.3699030876159668 sec, using 98 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7640, Validation Loss: 0.5987
	--> Epoch [2/100], Loss: 0.6927, Validation Loss: 0.5790
	--> Epoch [3/100], Loss: 0.7024, Validation Loss: 0.5611
	--> Epoch [4/100], Loss: 0.6624, Validation Loss: 0.5501
	--> Epoch [5/100], Loss: 0.6665, Validation Loss: 0.5380
	--> Epoch [6/100], Loss: 0.6137, Validation Loss: 0.5229
	--> Epoch [7/100], Loss: 0.5962, Validation Loss: 0.5111
	--> Epoch [8/100], Loss: 0.5802, Validation Loss: 0.4995
	--> Epoch [9/100], Loss: 0.5450, Validation Loss: 0.4893
	--> Epoch [10/100], Loss: 0.5561, Validation Loss: 0.4803
	--> Epoch [11/100], Loss: 0.5287, Validation Loss: 0.4739
	--> Epoch [12/100], Loss: 0.5128, Validation Loss: 0.4668
	--> Epoch [13/100], Loss: 0.5201, Validation Loss: 0.4595
	--> Epoch [14/100], Loss: 0.5170, Validation Loss: 0.4524
	--> Epoch [15/100], Loss: 0.5009, Validation Loss: 0.4465
	--> Epoch [16/100], Loss: 0.4631, Validation Loss: 0.4402
	--> Epoch [17/100], Loss: 0.4373, Validation Loss: 0.4362
	--> Epoch [18/100], Loss: 0.4487, Validation Loss: 0.4317
	--> Epoch [19/100], Loss: 0.4284, Validation Loss: 0.4271
	--> Epoch [20/100], Loss: 0.4408, Validation Loss: 0.4216
	--> Epoch [21/100], Loss: 0.4023, Validation Loss: 0.4170
	--> Epoch [22/100], Loss: 0.4070, Validation Loss: 0.4132
	--> Epoch [23/100], Loss: 0.4172, Validation Loss: 0.4105
	--> Epoch [24/100], Loss: 0.3795, Validation Loss: 0.4056
	--> Epoch [25/100], Loss: 0.4162, Validation Loss: 0.4012
	--> Epoch [26/100], Loss: 0.3749, Validation Loss: 0.3984
	--> Epoch [27/100], Loss: 0.3688, Validation Loss: 0.3944
	--> Epoch [28/100], Loss: 0.3734, Validation Loss: 0.3901
	--> Epoch [29/100], Loss: 0.3719, Validation Loss: 0.3855
	--> Epoch [30/100], Loss: 0.3436, Validation Loss: 0.3825
	--> Epoch [31/100], Loss: 0.3272, Validation Loss: 0.3773
	--> Epoch [32/100], Loss: 0.3293, Validation Loss: 0.3752
	--> Epoch [33/100], Loss: 0.2897, Validation Loss: 0.3716
	--> Epoch [34/100], Loss: 0.3198, Validation Loss: 0.3683
	--> Epoch [35/100], Loss: 0.2923, Validation Loss: 0.3635
	--> Epoch [36/100], Loss: 0.3052, Validation Loss: 0.3611
	--> Epoch [37/100], Loss: 0.3154, Validation Loss: 0.3590
	--> Epoch [38/100], Loss: 0.2842, Validation Loss: 0.3561
	--> Epoch [39/100], Loss: 0.2877, Validation Loss: 0.3535
	--> Epoch [40/100], Loss: 0.2544, Validation Loss: 0.3513
	--> Epoch [41/100], Loss: 0.3023, Validation Loss: 0.3471
	--> Epoch [42/100], Loss: 0.2499, Validation Loss: 0.3444
	--> Epoch [43/100], Loss: 0.2817, Validation Loss: 0.3414
	--> Epoch [44/100], Loss: 0.2637, Validation Loss: 0.3367
	--> Epoch [45/100], Loss: 0.2676, Validation Loss: 0.3339
	--> Epoch [46/100], Loss: 0.2543, Validation Loss: 0.3320
	--> Epoch [47/100], Loss: 0.2358, Validation Loss: 0.3298
	--> Epoch [48/100], Loss: 0.2448, Validation Loss: 0.3266
	--> Epoch [49/100], Loss: 0.2398, Validation Loss: 0.3245
	--> Epoch [50/100], Loss: 0.2092, Validation Loss: 0.3230
	--> Epoch [51/100], Loss: 0.2027, Validation Loss: 0.3211
	--> Epoch [52/100], Loss: 0.2143, Validation Loss: 0.3196
	--> Epoch [53/100], Loss: 0.1989, Validation Loss: 0.3173
	--> Epoch [54/100], Loss: 0.2161, Validation Loss: 0.3146
	--> Epoch [55/100], Loss: 0.1919, Validation Loss: 0.3134
	--> Epoch [56/100], Loss: 0.1854, Validation Loss: 0.3105
	--> Epoch [57/100], Loss: 0.1906, Validation Loss: 0.3077
	--> Epoch [58/100], Loss: 0.2198, Validation Loss: 0.3056
	--> Epoch [59/100], Loss: 0.1881, Validation Loss: 0.3039
	--> Epoch [60/100], Loss: 0.1857, Validation Loss: 0.3019
	--> Epoch [61/100], Loss: 0.1815, Validation Loss: 0.3012
	--> Epoch [62/100], Loss: 0.1793, Validation Loss: 0.3007
	--> Epoch [63/100], Loss: 0.1929, Validation Loss: 0.2998
	--> Epoch [64/100], Loss: 0.1646, Validation Loss: 0.2984
	--> Epoch [65/100], Loss: 0.2152, Validation Loss: 0.2950
	--> Epoch [66/100], Loss: 0.1638, Validation Loss: 0.2931
	--> Epoch [67/100], Loss: 0.1706, Validation Loss: 0.2919
	--> Epoch [68/100], Loss: 0.1736, Validation Loss: 0.2911
	--> Epoch [69/100], Loss: 0.1695, Validation Loss: 0.2897
	--> Epoch [70/100], Loss: 0.1578, Validation Loss: 0.2880
	--> Epoch [71/100], Loss: 0.1556, Validation Loss: 0.2875
	--> Epoch [72/100], Loss: 0.1420, Validation Loss: 0.2871
	--> Epoch [73/100], Loss: 0.1206, Validation Loss: 0.2858
	--> Epoch [74/100], Loss: 0.1269, Validation Loss: 0.2850
	--> Epoch [75/100], Loss: 0.1391, Validation Loss: 0.2840
	--> Epoch [76/100], Loss: 0.1350, Validation Loss: 0.2826
	--> Epoch [77/100], Loss: 0.1527, Validation Loss: 0.2806
	--> Epoch [78/100], Loss: 0.1105, Validation Loss: 0.2800
	--> Epoch [79/100], Loss: 0.1177, Validation Loss: 0.2793
	--> Epoch [80/100], Loss: 0.1410, Validation Loss: 0.2776
	--> Epoch [81/100], Loss: 0.1077, Validation Loss: 0.2772
	--> Epoch [82/100], Loss: 0.1242, Validation Loss: 0.2758
	--> Epoch [83/100], Loss: 0.1403, Validation Loss: 0.2751
	--> Epoch [84/100], Loss: 0.1274, Validation Loss: 0.2738
	--> Epoch [85/100], Loss: 0.1628, Validation Loss: 0.2725
	--> Epoch [86/100], Loss: 0.1203, Validation Loss: 0.2712
	--> Epoch [87/100], Loss: 0.1187, Validation Loss: 0.2719
	--> Epoch [88/100], Loss: 0.1315, Validation Loss: 0.2722
	--> Epoch [89/100], Loss: 0.1557, Validation Loss: 0.2703
	--> Epoch [90/100], Loss: 0.1195, Validation Loss: 0.2694
	--> Epoch [91/100], Loss: 0.1062, Validation Loss: 0.2687
	--> Epoch [92/100], Loss: 0.1285, Validation Loss: 0.2673
	--> Epoch [93/100], Loss: 0.1175, Validation Loss: 0.2669
	--> Epoch [94/100], Loss: 0.1091, Validation Loss: 0.2655
	--> Epoch [95/100], Loss: 0.0956, Validation Loss: 0.2647
	--> Epoch [96/100], Loss: 0.1112, Validation Loss: 0.2646
	--> Epoch [97/100], Loss: 0.1015, Validation Loss: 0.2635
	--> Epoch [98/100], Loss: 0.1297, Validation Loss: 0.2629
	--> Epoch [99/100], Loss: 0.1124, Validation Loss: 0.2623
	--> Epoch [100/100], Loss: 0.1067, Validation Loss: 0.2617
	--> Training for Fold 2 took 0.4829976558685303 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6923, Validation Loss: 0.7110
	--> Epoch [2/100], Loss: 0.6606, Validation Loss: 0.6959
	--> Epoch [3/100], Loss: 0.6300, Validation Loss: 0.6836
	--> Epoch [4/100], Loss: 0.6078, Validation Loss: 0.6749
	--> Epoch [5/100], Loss: 0.6043, Validation Loss: 0.6667
	--> Epoch [6/100], Loss: 0.5546, Validation Loss: 0.6599
	--> Epoch [7/100], Loss: 0.5584, Validation Loss: 0.6530
	--> Epoch [8/100], Loss: 0.5147, Validation Loss: 0.6464
	--> Epoch [9/100], Loss: 0.5456, Validation Loss: 0.6394
	--> Epoch [10/100], Loss: 0.4997, Validation Loss: 0.6325
	--> Epoch [11/100], Loss: 0.4972, Validation Loss: 0.6252
	--> Epoch [12/100], Loss: 0.4844, Validation Loss: 0.6201
	--> Epoch [13/100], Loss: 0.4648, Validation Loss: 0.6145
	--> Epoch [14/100], Loss: 0.4743, Validation Loss: 0.6084
	--> Epoch [15/100], Loss: 0.4734, Validation Loss: 0.6031
	--> Epoch [16/100], Loss: 0.4494, Validation Loss: 0.5969
	--> Epoch [17/100], Loss: 0.4335, Validation Loss: 0.5910
	--> Epoch [18/100], Loss: 0.4244, Validation Loss: 0.5847
	--> Epoch [19/100], Loss: 0.4127, Validation Loss: 0.5778
	--> Epoch [20/100], Loss: 0.4220, Validation Loss: 0.5725
	--> Epoch [21/100], Loss: 0.3987, Validation Loss: 0.5670
	--> Epoch [22/100], Loss: 0.3756, Validation Loss: 0.5608
	--> Epoch [23/100], Loss: 0.3921, Validation Loss: 0.5565
	--> Epoch [24/100], Loss: 0.3566, Validation Loss: 0.5523
	--> Epoch [25/100], Loss: 0.3379, Validation Loss: 0.5466
	--> Epoch [26/100], Loss: 0.3773, Validation Loss: 0.5425
	--> Epoch [27/100], Loss: 0.3467, Validation Loss: 0.5386
	--> Epoch [28/100], Loss: 0.3193, Validation Loss: 0.5354
	--> Epoch [29/100], Loss: 0.3173, Validation Loss: 0.5322
	--> Epoch [30/100], Loss: 0.3098, Validation Loss: 0.5286
	--> Epoch [31/100], Loss: 0.2993, Validation Loss: 0.5246
	--> Epoch [32/100], Loss: 0.3158, Validation Loss: 0.5222
	--> Epoch [33/100], Loss: 0.3074, Validation Loss: 0.5187
	--> Epoch [34/100], Loss: 0.2794, Validation Loss: 0.5168
	--> Epoch [35/100], Loss: 0.2772, Validation Loss: 0.5133
	--> Epoch [36/100], Loss: 0.2814, Validation Loss: 0.5102
	--> Epoch [37/100], Loss: 0.2773, Validation Loss: 0.5081
	--> Epoch [38/100], Loss: 0.2829, Validation Loss: 0.5051
	--> Epoch [39/100], Loss: 0.2443, Validation Loss: 0.5015
	--> Epoch [40/100], Loss: 0.2743, Validation Loss: 0.4990
	--> Epoch [41/100], Loss: 0.2464, Validation Loss: 0.4970
	--> Epoch [42/100], Loss: 0.2422, Validation Loss: 0.4938
	--> Epoch [43/100], Loss: 0.2552, Validation Loss: 0.4913
	--> Epoch [44/100], Loss: 0.2536, Validation Loss: 0.4889
	--> Epoch [45/100], Loss: 0.2374, Validation Loss: 0.4869
	--> Epoch [46/100], Loss: 0.2294, Validation Loss: 0.4827
	--> Epoch [47/100], Loss: 0.2047, Validation Loss: 0.4801
	--> Epoch [48/100], Loss: 0.2133, Validation Loss: 0.4775
	--> Epoch [49/100], Loss: 0.2150, Validation Loss: 0.4772
	--> Epoch [50/100], Loss: 0.2248, Validation Loss: 0.4746
	--> Epoch [51/100], Loss: 0.2062, Validation Loss: 0.4719
	--> Epoch [52/100], Loss: 0.2239, Validation Loss: 0.4708
	--> Epoch [53/100], Loss: 0.2045, Validation Loss: 0.4690
	--> Epoch [54/100], Loss: 0.2034, Validation Loss: 0.4671
	--> Epoch [55/100], Loss: 0.2017, Validation Loss: 0.4652
	--> Epoch [56/100], Loss: 0.2093, Validation Loss: 0.4642
	--> Epoch [57/100], Loss: 0.1855, Validation Loss: 0.4612
	--> Epoch [58/100], Loss: 0.2034, Validation Loss: 0.4595
	--> Epoch [59/100], Loss: 0.1830, Validation Loss: 0.4576
	--> Epoch [60/100], Loss: 0.1632, Validation Loss: 0.4562
	--> Epoch [61/100], Loss: 0.1803, Validation Loss: 0.4552
	--> Epoch [62/100], Loss: 0.1639, Validation Loss: 0.4541
	--> Epoch [63/100], Loss: 0.1861, Validation Loss: 0.4527
	--> Epoch [64/100], Loss: 0.1670, Validation Loss: 0.4507
	--> Epoch [65/100], Loss: 0.1499, Validation Loss: 0.4493
	--> Epoch [66/100], Loss: 0.1916, Validation Loss: 0.4477
	--> Epoch [67/100], Loss: 0.1659, Validation Loss: 0.4459
	--> Epoch [68/100], Loss: 0.1639, Validation Loss: 0.4446
	--> Epoch [69/100], Loss: 0.1401, Validation Loss: 0.4435
	--> Epoch [70/100], Loss: 0.1506, Validation Loss: 0.4422
	--> Epoch [71/100], Loss: 0.1474, Validation Loss: 0.4413
	--> Epoch [72/100], Loss: 0.1643, Validation Loss: 0.4408
	--> Epoch [73/100], Loss: 0.1325, Validation Loss: 0.4399
	--> Epoch [74/100], Loss: 0.1276, Validation Loss: 0.4382
	--> Epoch [75/100], Loss: 0.1534, Validation Loss: 0.4353
	--> Epoch [76/100], Loss: 0.1420, Validation Loss: 0.4336
	--> Epoch [77/100], Loss: 0.1113, Validation Loss: 0.4323
	--> Epoch [78/100], Loss: 0.1196, Validation Loss: 0.4311
	--> Epoch [79/100], Loss: 0.1514, Validation Loss: 0.4303
	--> Epoch [80/100], Loss: 0.1473, Validation Loss: 0.4300
	--> Epoch [81/100], Loss: 0.1228, Validation Loss: 0.4291
	--> Epoch [82/100], Loss: 0.1463, Validation Loss: 0.4285
	--> Epoch [83/100], Loss: 0.1222, Validation Loss: 0.4277
	--> Epoch [84/100], Loss: 0.1634, Validation Loss: 0.4265
	--> Epoch [85/100], Loss: 0.1423, Validation Loss: 0.4256
	--> Epoch [86/100], Loss: 0.1022, Validation Loss: 0.4251
	--> Epoch [87/100], Loss: 0.1048, Validation Loss: 0.4249
	--> Epoch [88/100], Loss: 0.1364, Validation Loss: 0.4245
	--> Epoch [89/100], Loss: 0.1438, Validation Loss: 0.4237
	--> Epoch [90/100], Loss: 0.1349, Validation Loss: 0.4236
	--> Epoch [91/100], Loss: 0.0860, Validation Loss: 0.4236
	--> Epoch [92/100], Loss: 0.1428, Validation Loss: 0.4221
	--> Epoch [93/100], Loss: 0.1014, Validation Loss: 0.4206
	--> Epoch [94/100], Loss: 0.0908, Validation Loss: 0.4202
	--> Epoch [95/100], Loss: 0.1180, Validation Loss: 0.4206
	--> Epoch [96/100], Loss: 0.1080, Validation Loss: 0.4197
	--> Epoch [97/100], Loss: 0.1581, Validation Loss: 0.4208
	--> Epoch [98/100], Loss: 0.0917, Validation Loss: 0.4203
	--> Epoch [99/100], Loss: 0.1019, Validation Loss: 0.4201
Early stopping
	--> Training for Fold 3 took 0.4657289981842041 sec, using 99 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7347, Validation Loss: 0.5470
	--> Epoch [2/100], Loss: 0.7152, Validation Loss: 0.5322
	--> Epoch [3/100], Loss: 0.7140, Validation Loss: 0.5195
	--> Epoch [4/100], Loss: 0.6601, Validation Loss: 0.5108
	--> Epoch [5/100], Loss: 0.6520, Validation Loss: 0.5053
	--> Epoch [6/100], Loss: 0.6417, Validation Loss: 0.5000
	--> Epoch [7/100], Loss: 0.6057, Validation Loss: 0.4897
	--> Epoch [8/100], Loss: 0.5913, Validation Loss: 0.4818
	--> Epoch [9/100], Loss: 0.5819, Validation Loss: 0.4764
	--> Epoch [10/100], Loss: 0.5626, Validation Loss: 0.4708
	--> Epoch [11/100], Loss: 0.5684, Validation Loss: 0.4642
	--> Epoch [12/100], Loss: 0.5458, Validation Loss: 0.4591
	--> Epoch [13/100], Loss: 0.5302, Validation Loss: 0.4540
	--> Epoch [14/100], Loss: 0.5210, Validation Loss: 0.4491
	--> Epoch [15/100], Loss: 0.4873, Validation Loss: 0.4437
	--> Epoch [16/100], Loss: 0.4968, Validation Loss: 0.4396
	--> Epoch [17/100], Loss: 0.4613, Validation Loss: 0.4352
	--> Epoch [18/100], Loss: 0.4683, Validation Loss: 0.4308
	--> Epoch [19/100], Loss: 0.4768, Validation Loss: 0.4272
	--> Epoch [20/100], Loss: 0.4510, Validation Loss: 0.4250
	--> Epoch [21/100], Loss: 0.4403, Validation Loss: 0.4197
	--> Epoch [22/100], Loss: 0.4314, Validation Loss: 0.4155
	--> Epoch [23/100], Loss: 0.4280, Validation Loss: 0.4117
	--> Epoch [24/100], Loss: 0.4038, Validation Loss: 0.4096
	--> Epoch [25/100], Loss: 0.3642, Validation Loss: 0.4059
	--> Epoch [26/100], Loss: 0.3756, Validation Loss: 0.4016
	--> Epoch [27/100], Loss: 0.3660, Validation Loss: 0.3966
	--> Epoch [28/100], Loss: 0.3697, Validation Loss: 0.3910
	--> Epoch [29/100], Loss: 0.3748, Validation Loss: 0.3876
	--> Epoch [30/100], Loss: 0.3916, Validation Loss: 0.3834
	--> Epoch [31/100], Loss: 0.3419, Validation Loss: 0.3795
	--> Epoch [32/100], Loss: 0.3269, Validation Loss: 0.3766
	--> Epoch [33/100], Loss: 0.3550, Validation Loss: 0.3725
	--> Epoch [34/100], Loss: 0.3111, Validation Loss: 0.3692
	--> Epoch [35/100], Loss: 0.3250, Validation Loss: 0.3640
	--> Epoch [36/100], Loss: 0.3229, Validation Loss: 0.3607
	--> Epoch [37/100], Loss: 0.3090, Validation Loss: 0.3572
	--> Epoch [38/100], Loss: 0.3022, Validation Loss: 0.3543
	--> Epoch [39/100], Loss: 0.2688, Validation Loss: 0.3530
	--> Epoch [40/100], Loss: 0.2876, Validation Loss: 0.3494
	--> Epoch [41/100], Loss: 0.2699, Validation Loss: 0.3460
	--> Epoch [42/100], Loss: 0.2714, Validation Loss: 0.3427
	--> Epoch [43/100], Loss: 0.2809, Validation Loss: 0.3409
	--> Epoch [44/100], Loss: 0.2892, Validation Loss: 0.3376
	--> Epoch [45/100], Loss: 0.2872, Validation Loss: 0.3344
	--> Epoch [46/100], Loss: 0.2567, Validation Loss: 0.3332
	--> Epoch [47/100], Loss: 0.2360, Validation Loss: 0.3308
	--> Epoch [48/100], Loss: 0.2848, Validation Loss: 0.3294
	--> Epoch [49/100], Loss: 0.2325, Validation Loss: 0.3274
	--> Epoch [50/100], Loss: 0.2827, Validation Loss: 0.3251
	--> Epoch [51/100], Loss: 0.2480, Validation Loss: 0.3239
	--> Epoch [52/100], Loss: 0.2082, Validation Loss: 0.3214
	--> Epoch [53/100], Loss: 0.1982, Validation Loss: 0.3199
	--> Epoch [54/100], Loss: 0.2339, Validation Loss: 0.3174
	--> Epoch [55/100], Loss: 0.2321, Validation Loss: 0.3172
	--> Epoch [56/100], Loss: 0.2253, Validation Loss: 0.3162
	--> Epoch [57/100], Loss: 0.2408, Validation Loss: 0.3157
	--> Epoch [58/100], Loss: 0.1908, Validation Loss: 0.3132
	--> Epoch [59/100], Loss: 0.2095, Validation Loss: 0.3123
	--> Epoch [60/100], Loss: 0.1904, Validation Loss: 0.3115
	--> Epoch [61/100], Loss: 0.1867, Validation Loss: 0.3101
	--> Epoch [62/100], Loss: 0.1789, Validation Loss: 0.3097
	--> Epoch [63/100], Loss: 0.1830, Validation Loss: 0.3089
	--> Epoch [64/100], Loss: 0.1617, Validation Loss: 0.3059
	--> Epoch [65/100], Loss: 0.1737, Validation Loss: 0.3052
	--> Epoch [66/100], Loss: 0.1678, Validation Loss: 0.3045
	--> Epoch [67/100], Loss: 0.1784, Validation Loss: 0.3029
	--> Epoch [68/100], Loss: 0.1464, Validation Loss: 0.3033
	--> Epoch [69/100], Loss: 0.1486, Validation Loss: 0.3023
	--> Epoch [70/100], Loss: 0.1492, Validation Loss: 0.3014
	--> Epoch [71/100], Loss: 0.1804, Validation Loss: 0.3003
	--> Epoch [72/100], Loss: 0.1712, Validation Loss: 0.2995
	--> Epoch [73/100], Loss: 0.1413, Validation Loss: 0.2986
	--> Epoch [74/100], Loss: 0.1534, Validation Loss: 0.2971
	--> Epoch [75/100], Loss: 0.1644, Validation Loss: 0.2969
	--> Epoch [76/100], Loss: 0.1452, Validation Loss: 0.2957
	--> Epoch [77/100], Loss: 0.1515, Validation Loss: 0.2947
	--> Epoch [78/100], Loss: 0.1465, Validation Loss: 0.2940
	--> Epoch [79/100], Loss: 0.1502, Validation Loss: 0.2930
	--> Epoch [80/100], Loss: 0.1317, Validation Loss: 0.2919
	--> Epoch [81/100], Loss: 0.1342, Validation Loss: 0.2925
	--> Epoch [82/100], Loss: 0.1285, Validation Loss: 0.2929
	--> Epoch [83/100], Loss: 0.1443, Validation Loss: 0.2928
Early stopping
	--> Training for Fold 4 took 0.3260347843170166 sec, using 83 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7213, Validation Loss: 0.7679
	--> Epoch [2/100], Loss: 0.6866, Validation Loss: 0.7612
	--> Epoch [3/100], Loss: 0.6693, Validation Loss: 0.7551
	--> Epoch [4/100], Loss: 0.6805, Validation Loss: 0.7502
	--> Epoch [5/100], Loss: 0.6490, Validation Loss: 0.7444
	--> Epoch [6/100], Loss: 0.6232, Validation Loss: 0.7391
	--> Epoch [7/100], Loss: 0.6196, Validation Loss: 0.7334
	--> Epoch [8/100], Loss: 0.5817, Validation Loss: 0.7288
	--> Epoch [9/100], Loss: 0.5842, Validation Loss: 0.7241
	--> Epoch [10/100], Loss: 0.5466, Validation Loss: 0.7191
	--> Epoch [11/100], Loss: 0.5628, Validation Loss: 0.7153
	--> Epoch [12/100], Loss: 0.5413, Validation Loss: 0.7112
	--> Epoch [13/100], Loss: 0.5337, Validation Loss: 0.7086
	--> Epoch [14/100], Loss: 0.5132, Validation Loss: 0.7055
	--> Epoch [15/100], Loss: 0.5198, Validation Loss: 0.7025
	--> Epoch [16/100], Loss: 0.4870, Validation Loss: 0.7006
	--> Epoch [17/100], Loss: 0.4613, Validation Loss: 0.6983
	--> Epoch [18/100], Loss: 0.4800, Validation Loss: 0.6956
	--> Epoch [19/100], Loss: 0.4575, Validation Loss: 0.6944
	--> Epoch [20/100], Loss: 0.4265, Validation Loss: 0.6937
	--> Epoch [21/100], Loss: 0.4223, Validation Loss: 0.6929
	--> Epoch [22/100], Loss: 0.4375, Validation Loss: 0.6928
	--> Epoch [23/100], Loss: 0.4298, Validation Loss: 0.6906
	--> Epoch [24/100], Loss: 0.4115, Validation Loss: 0.6884
	--> Epoch [25/100], Loss: 0.3810, Validation Loss: 0.6866
	--> Epoch [26/100], Loss: 0.3682, Validation Loss: 0.6837
	--> Epoch [27/100], Loss: 0.3886, Validation Loss: 0.6821
	--> Epoch [28/100], Loss: 0.3800, Validation Loss: 0.6777
	--> Epoch [29/100], Loss: 0.3679, Validation Loss: 0.6748
	--> Epoch [30/100], Loss: 0.3523, Validation Loss: 0.6716
	--> Epoch [31/100], Loss: 0.3635, Validation Loss: 0.6690
	--> Epoch [32/100], Loss: 0.3563, Validation Loss: 0.6660
	--> Epoch [33/100], Loss: 0.3207, Validation Loss: 0.6641
	--> Epoch [34/100], Loss: 0.3323, Validation Loss: 0.6600
	--> Epoch [35/100], Loss: 0.3145, Validation Loss: 0.6582
	--> Epoch [36/100], Loss: 0.3081, Validation Loss: 0.6560
	--> Epoch [37/100], Loss: 0.3030, Validation Loss: 0.6521
	--> Epoch [38/100], Loss: 0.2991, Validation Loss: 0.6516
	--> Epoch [39/100], Loss: 0.2806, Validation Loss: 0.6501
	--> Epoch [40/100], Loss: 0.3392, Validation Loss: 0.6487
	--> Epoch [41/100], Loss: 0.2895, Validation Loss: 0.6467
	--> Epoch [42/100], Loss: 0.2879, Validation Loss: 0.6438
	--> Epoch [43/100], Loss: 0.3017, Validation Loss: 0.6397
	--> Epoch [44/100], Loss: 0.2930, Validation Loss: 0.6390
	--> Epoch [45/100], Loss: 0.2656, Validation Loss: 0.6379
	--> Epoch [46/100], Loss: 0.2644, Validation Loss: 0.6368
	--> Epoch [47/100], Loss: 0.2444, Validation Loss: 0.6351
	--> Epoch [48/100], Loss: 0.2516, Validation Loss: 0.6348
	--> Epoch [49/100], Loss: 0.2559, Validation Loss: 0.6328
	--> Epoch [50/100], Loss: 0.2236, Validation Loss: 0.6330
	--> Epoch [51/100], Loss: 0.2402, Validation Loss: 0.6299
	--> Epoch [52/100], Loss: 0.1982, Validation Loss: 0.6281
	--> Epoch [53/100], Loss: 0.2042, Validation Loss: 0.6258
	--> Epoch [54/100], Loss: 0.1923, Validation Loss: 0.6248
	--> Epoch [55/100], Loss: 0.2105, Validation Loss: 0.6214
	--> Epoch [56/100], Loss: 0.2257, Validation Loss: 0.6186
	--> Epoch [57/100], Loss: 0.2130, Validation Loss: 0.6174
	--> Epoch [58/100], Loss: 0.1906, Validation Loss: 0.6179
	--> Epoch [59/100], Loss: 0.2000, Validation Loss: 0.6158
	--> Epoch [60/100], Loss: 0.1929, Validation Loss: 0.6138
	--> Epoch [61/100], Loss: 0.1946, Validation Loss: 0.6118
	--> Epoch [62/100], Loss: 0.2022, Validation Loss: 0.6094
	--> Epoch [63/100], Loss: 0.1627, Validation Loss: 0.6080
	--> Epoch [64/100], Loss: 0.1758, Validation Loss: 0.6072
	--> Epoch [65/100], Loss: 0.1691, Validation Loss: 0.6075
	--> Epoch [66/100], Loss: 0.1739, Validation Loss: 0.6058
	--> Epoch [67/100], Loss: 0.1791, Validation Loss: 0.6041
	--> Epoch [68/100], Loss: 0.1511, Validation Loss: 0.6054
	--> Epoch [69/100], Loss: 0.1939, Validation Loss: 0.6016
	--> Epoch [70/100], Loss: 0.1669, Validation Loss: 0.6013
	--> Epoch [71/100], Loss: 0.1442, Validation Loss: 0.6019
	--> Epoch [72/100], Loss: 0.1961, Validation Loss: 0.5996
	--> Epoch [73/100], Loss: 0.1474, Validation Loss: 0.6000
	--> Epoch [74/100], Loss: 0.1413, Validation Loss: 0.5988
	--> Epoch [75/100], Loss: 0.1552, Validation Loss: 0.5973
	--> Epoch [76/100], Loss: 0.1634, Validation Loss: 0.5978
	--> Epoch [77/100], Loss: 0.1356, Validation Loss: 0.5982
	--> Epoch [78/100], Loss: 0.1593, Validation Loss: 0.5977
Early stopping
	--> Training for Fold 5 took 0.3507683277130127 sec, using 78 epochs

Median number of epochs used: 98 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/98], Loss: 0.7180
	--> Final training Epoch [2/98], Loss: 0.7022
	--> Final training Epoch [3/98], Loss: 0.6635
	--> Final training Epoch [4/98], Loss: 0.6743
	--> Final training Epoch [5/98], Loss: 0.6485
	--> Final training Epoch [6/98], Loss: 0.6312
	--> Final training Epoch [7/98], Loss: 0.6101
	--> Final training Epoch [8/98], Loss: 0.6177
	--> Final training Epoch [9/98], Loss: 0.5855
	--> Final training Epoch [10/98], Loss: 0.5923
	--> Final training Epoch [11/98], Loss: 0.5911
	--> Final training Epoch [12/98], Loss: 0.5582
	--> Final training Epoch [13/98], Loss: 0.5579
	--> Final training Epoch [14/98], Loss: 0.5144
	--> Final training Epoch [15/98], Loss: 0.5554
	--> Final training Epoch [16/98], Loss: 0.5174
	--> Final training Epoch [17/98], Loss: 0.5187
	--> Final training Epoch [18/98], Loss: 0.4769
	--> Final training Epoch [19/98], Loss: 0.4755
	--> Final training Epoch [20/98], Loss: 0.4839
	--> Final training Epoch [21/98], Loss: 0.4641
	--> Final training Epoch [22/98], Loss: 0.4510
	--> Final training Epoch [23/98], Loss: 0.4491
	--> Final training Epoch [24/98], Loss: 0.4285
	--> Final training Epoch [25/98], Loss: 0.4509
	--> Final training Epoch [26/98], Loss: 0.4228
	--> Final training Epoch [27/98], Loss: 0.4111
	--> Final training Epoch [28/98], Loss: 0.4076
	--> Final training Epoch [29/98], Loss: 0.4075
	--> Final training Epoch [30/98], Loss: 0.3949
	--> Final training Epoch [31/98], Loss: 0.3890
	--> Final training Epoch [32/98], Loss: 0.3745
	--> Final training Epoch [33/98], Loss: 0.3831
	--> Final training Epoch [34/98], Loss: 0.3678
	--> Final training Epoch [35/98], Loss: 0.3618
	--> Final training Epoch [36/98], Loss: 0.3652
	--> Final training Epoch [37/98], Loss: 0.3721
	--> Final training Epoch [38/98], Loss: 0.3607
	--> Final training Epoch [39/98], Loss: 0.3837
	--> Final training Epoch [40/98], Loss: 0.3436
	--> Final training Epoch [41/98], Loss: 0.3356
	--> Final training Epoch [42/98], Loss: 0.3374
	--> Final training Epoch [43/98], Loss: 0.3217
	--> Final training Epoch [44/98], Loss: 0.3186
	--> Final training Epoch [45/98], Loss: 0.3236
	--> Final training Epoch [46/98], Loss: 0.3135
	--> Final training Epoch [47/98], Loss: 0.3200
	--> Final training Epoch [48/98], Loss: 0.2881
	--> Final training Epoch [49/98], Loss: 0.2932
	--> Final training Epoch [50/98], Loss: 0.2962
	--> Final training Epoch [51/98], Loss: 0.2885
	--> Final training Epoch [52/98], Loss: 0.2963
	--> Final training Epoch [53/98], Loss: 0.2826
	--> Final training Epoch [54/98], Loss: 0.3034
	--> Final training Epoch [55/98], Loss: 0.3123
	--> Final training Epoch [56/98], Loss: 0.2799
	--> Final training Epoch [57/98], Loss: 0.2630
	--> Final training Epoch [58/98], Loss: 0.2837
	--> Final training Epoch [59/98], Loss: 0.2695
	--> Final training Epoch [60/98], Loss: 0.2556
	--> Final training Epoch [61/98], Loss: 0.2465
	--> Final training Epoch [62/98], Loss: 0.2485
	--> Final training Epoch [63/98], Loss: 0.2294
	--> Final training Epoch [64/98], Loss: 0.2457
	--> Final training Epoch [65/98], Loss: 0.2375
	--> Final training Epoch [66/98], Loss: 0.2178
	--> Final training Epoch [67/98], Loss: 0.2446
	--> Final training Epoch [68/98], Loss: 0.2398
	--> Final training Epoch [69/98], Loss: 0.2156
	--> Final training Epoch [70/98], Loss: 0.2513
	--> Final training Epoch [71/98], Loss: 0.2439
	--> Final training Epoch [72/98], Loss: 0.2448
	--> Final training Epoch [73/98], Loss: 0.2199
	--> Final training Epoch [74/98], Loss: 0.2261
	--> Final training Epoch [75/98], Loss: 0.2147
	--> Final training Epoch [76/98], Loss: 0.2365
	--> Final training Epoch [77/98], Loss: 0.2204
	--> Final training Epoch [78/98], Loss: 0.2654
	--> Final training Epoch [79/98], Loss: 0.1998
	--> Final training Epoch [80/98], Loss: 0.1926
	--> Final training Epoch [81/98], Loss: 0.2188
	--> Final training Epoch [82/98], Loss: 0.1994
	--> Final training Epoch [83/98], Loss: 0.1807
	--> Final training Epoch [84/98], Loss: 0.1995
	--> Final training Epoch [85/98], Loss: 0.2036
	--> Final training Epoch [86/98], Loss: 0.1845
	--> Final training Epoch [87/98], Loss: 0.2158
	--> Final training Epoch [88/98], Loss: 0.1887
	--> Final training Epoch [89/98], Loss: 0.1971
	--> Final training Epoch [90/98], Loss: 0.2001
	--> Final training Epoch [91/98], Loss: 0.2184
	--> Final training Epoch [92/98], Loss: 0.1707
	--> Final training Epoch [93/98], Loss: 0.1792
	--> Final training Epoch [94/98], Loss: 0.1723
	--> Final training Epoch [95/98], Loss: 0.1828
	--> Final training Epoch [96/98], Loss: 0.1763
	--> Final training Epoch [97/98], Loss: 0.1786
	--> Final training Epoch [98/98], Loss: 0.1522

Final training took 0.3719522953033447 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.7659
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3244,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3244
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7947, Validation Loss: 0.4082,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3244
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3690,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3244
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3649,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3244

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7409, Validation Loss: 0.8026
	--> Epoch [2/100], Loss: 0.8375, Validation Loss: 0.7882
	--> Epoch [3/100], Loss: 0.7728, Validation Loss: 0.7752
	--> Epoch [4/100], Loss: 0.7271, Validation Loss: 0.7584
	--> Epoch [5/100], Loss: 0.7159, Validation Loss: 0.7420
	--> Epoch [6/100], Loss: 0.6871, Validation Loss: 0.7294
	--> Epoch [7/100], Loss: 0.7064, Validation Loss: 0.7171
	--> Epoch [8/100], Loss: 0.7202, Validation Loss: 0.7077
	--> Epoch [9/100], Loss: 0.6731, Validation Loss: 0.6973
	--> Epoch [10/100], Loss: 0.6380, Validation Loss: 0.6889
	--> Epoch [11/100], Loss: 0.6695, Validation Loss: 0.6790
	--> Epoch [12/100], Loss: 0.6777, Validation Loss: 0.6719
	--> Epoch [13/100], Loss: 0.6256, Validation Loss: 0.6602
	--> Epoch [14/100], Loss: 0.5904, Validation Loss: 0.6526
	--> Epoch [15/100], Loss: 0.6154, Validation Loss: 0.6429
	--> Epoch [16/100], Loss: 0.5593, Validation Loss: 0.6340
	--> Epoch [17/100], Loss: 0.5868, Validation Loss: 0.6269
	--> Epoch [18/100], Loss: 0.5717, Validation Loss: 0.6168
	--> Epoch [19/100], Loss: 0.5375, Validation Loss: 0.6095
	--> Epoch [20/100], Loss: 0.5495, Validation Loss: 0.6036
	--> Epoch [21/100], Loss: 0.5442, Validation Loss: 0.5947
	--> Epoch [22/100], Loss: 0.5797, Validation Loss: 0.5908
	--> Epoch [23/100], Loss: 0.4990, Validation Loss: 0.5834
	--> Epoch [24/100], Loss: 0.5799, Validation Loss: 0.5778
	--> Epoch [25/100], Loss: 0.4940, Validation Loss: 0.5709
	--> Epoch [26/100], Loss: 0.4968, Validation Loss: 0.5639
	--> Epoch [27/100], Loss: 0.5343, Validation Loss: 0.5580
	--> Epoch [28/100], Loss: 0.5526, Validation Loss: 0.5553
	--> Epoch [29/100], Loss: 0.5003, Validation Loss: 0.5500
	--> Epoch [30/100], Loss: 0.4841, Validation Loss: 0.5444
	--> Epoch [31/100], Loss: 0.4631, Validation Loss: 0.5382
	--> Epoch [32/100], Loss: 0.4867, Validation Loss: 0.5321
	--> Epoch [33/100], Loss: 0.4889, Validation Loss: 0.5271
	--> Epoch [34/100], Loss: 0.4504, Validation Loss: 0.5241
	--> Epoch [35/100], Loss: 0.4499, Validation Loss: 0.5219
	--> Epoch [36/100], Loss: 0.4618, Validation Loss: 0.5192
	--> Epoch [37/100], Loss: 0.4498, Validation Loss: 0.5150
	--> Epoch [38/100], Loss: 0.4642, Validation Loss: 0.5112
	--> Epoch [39/100], Loss: 0.4055, Validation Loss: 0.5073
	--> Epoch [40/100], Loss: 0.4218, Validation Loss: 0.5031
	--> Epoch [41/100], Loss: 0.4523, Validation Loss: 0.5013
	--> Epoch [42/100], Loss: 0.4740, Validation Loss: 0.5000
	--> Epoch [43/100], Loss: 0.4323, Validation Loss: 0.4996
	--> Epoch [44/100], Loss: 0.4119, Validation Loss: 0.4930
	--> Epoch [45/100], Loss: 0.4152, Validation Loss: 0.4883
	--> Epoch [46/100], Loss: 0.4385, Validation Loss: 0.4869
	--> Epoch [47/100], Loss: 0.4045, Validation Loss: 0.4847
	--> Epoch [48/100], Loss: 0.3967, Validation Loss: 0.4813
	--> Epoch [49/100], Loss: 0.3906, Validation Loss: 0.4771
	--> Epoch [50/100], Loss: 0.3751, Validation Loss: 0.4722
	--> Epoch [51/100], Loss: 0.3735, Validation Loss: 0.4680
	--> Epoch [52/100], Loss: 0.4117, Validation Loss: 0.4628
	--> Epoch [53/100], Loss: 0.4228, Validation Loss: 0.4589
	--> Epoch [54/100], Loss: 0.4026, Validation Loss: 0.4604
	--> Epoch [55/100], Loss: 0.3876, Validation Loss: 0.4605
	--> Epoch [56/100], Loss: 0.3631, Validation Loss: 0.4583
	--> Epoch [57/100], Loss: 0.3848, Validation Loss: 0.4551
	--> Epoch [58/100], Loss: 0.3596, Validation Loss: 0.4496
	--> Epoch [59/100], Loss: 0.3551, Validation Loss: 0.4466
	--> Epoch [60/100], Loss: 0.3329, Validation Loss: 0.4436
	--> Epoch [61/100], Loss: 0.3482, Validation Loss: 0.4441
	--> Epoch [62/100], Loss: 0.3608, Validation Loss: 0.4433
	--> Epoch [63/100], Loss: 0.3216, Validation Loss: 0.4428
	--> Epoch [64/100], Loss: 0.3304, Validation Loss: 0.4385
	--> Epoch [65/100], Loss: 0.3687, Validation Loss: 0.4351
	--> Epoch [66/100], Loss: 0.3126, Validation Loss: 0.4300
	--> Epoch [67/100], Loss: 0.3272, Validation Loss: 0.4248
	--> Epoch [68/100], Loss: 0.2792, Validation Loss: 0.4230
	--> Epoch [69/100], Loss: 0.3303, Validation Loss: 0.4215
	--> Epoch [70/100], Loss: 0.3387, Validation Loss: 0.4197
	--> Epoch [71/100], Loss: 0.3718, Validation Loss: 0.4169
	--> Epoch [72/100], Loss: 0.2893, Validation Loss: 0.4122
	--> Epoch [73/100], Loss: 0.3645, Validation Loss: 0.4112
	--> Epoch [74/100], Loss: 0.3450, Validation Loss: 0.4096
	--> Epoch [75/100], Loss: 0.3383, Validation Loss: 0.4102
	--> Epoch [76/100], Loss: 0.2792, Validation Loss: 0.4114
	--> Epoch [77/100], Loss: 0.2625, Validation Loss: 0.4099
Early stopping
	--> Training for Fold 1 took 0.30208897590637207 sec, using 77 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8092, Validation Loss: 0.7544
	--> Epoch [2/100], Loss: 0.7896, Validation Loss: 0.7383
	--> Epoch [3/100], Loss: 0.7413, Validation Loss: 0.7265
	--> Epoch [4/100], Loss: 0.7706, Validation Loss: 0.7162
	--> Epoch [5/100], Loss: 0.6947, Validation Loss: 0.7075
	--> Epoch [6/100], Loss: 0.6936, Validation Loss: 0.7004
	--> Epoch [7/100], Loss: 0.6411, Validation Loss: 0.6924
	--> Epoch [8/100], Loss: 0.6561, Validation Loss: 0.6838
	--> Epoch [9/100], Loss: 0.6716, Validation Loss: 0.6751
	--> Epoch [10/100], Loss: 0.6932, Validation Loss: 0.6675
	--> Epoch [11/100], Loss: 0.6598, Validation Loss: 0.6582
	--> Epoch [12/100], Loss: 0.6257, Validation Loss: 0.6511
	--> Epoch [13/100], Loss: 0.6567, Validation Loss: 0.6412
	--> Epoch [14/100], Loss: 0.6741, Validation Loss: 0.6311
	--> Epoch [15/100], Loss: 0.6274, Validation Loss: 0.6249
	--> Epoch [16/100], Loss: 0.5946, Validation Loss: 0.6161
	--> Epoch [17/100], Loss: 0.6039, Validation Loss: 0.6079
	--> Epoch [18/100], Loss: 0.5547, Validation Loss: 0.5999
	--> Epoch [19/100], Loss: 0.5927, Validation Loss: 0.5936
	--> Epoch [20/100], Loss: 0.6056, Validation Loss: 0.5875
	--> Epoch [21/100], Loss: 0.5702, Validation Loss: 0.5800
	--> Epoch [22/100], Loss: 0.5249, Validation Loss: 0.5710
	--> Epoch [23/100], Loss: 0.5819, Validation Loss: 0.5653
	--> Epoch [24/100], Loss: 0.4985, Validation Loss: 0.5573
	--> Epoch [25/100], Loss: 0.5228, Validation Loss: 0.5497
	--> Epoch [26/100], Loss: 0.5124, Validation Loss: 0.5446
	--> Epoch [27/100], Loss: 0.5584, Validation Loss: 0.5389
	--> Epoch [28/100], Loss: 0.5515, Validation Loss: 0.5327
	--> Epoch [29/100], Loss: 0.5568, Validation Loss: 0.5282
	--> Epoch [30/100], Loss: 0.5295, Validation Loss: 0.5215
	--> Epoch [31/100], Loss: 0.4885, Validation Loss: 0.5160
	--> Epoch [32/100], Loss: 0.5170, Validation Loss: 0.5107
	--> Epoch [33/100], Loss: 0.4905, Validation Loss: 0.5065
	--> Epoch [34/100], Loss: 0.4876, Validation Loss: 0.5010
	--> Epoch [35/100], Loss: 0.5156, Validation Loss: 0.4963
	--> Epoch [36/100], Loss: 0.4838, Validation Loss: 0.4930
	--> Epoch [37/100], Loss: 0.5250, Validation Loss: 0.4922
	--> Epoch [38/100], Loss: 0.5387, Validation Loss: 0.4874
	--> Epoch [39/100], Loss: 0.4591, Validation Loss: 0.4793
	--> Epoch [40/100], Loss: 0.4724, Validation Loss: 0.4754
	--> Epoch [41/100], Loss: 0.5053, Validation Loss: 0.4711
	--> Epoch [42/100], Loss: 0.4809, Validation Loss: 0.4663
	--> Epoch [43/100], Loss: 0.4609, Validation Loss: 0.4621
	--> Epoch [44/100], Loss: 0.4575, Validation Loss: 0.4592
	--> Epoch [45/100], Loss: 0.4645, Validation Loss: 0.4558
	--> Epoch [46/100], Loss: 0.4774, Validation Loss: 0.4517
	--> Epoch [47/100], Loss: 0.4553, Validation Loss: 0.4467
	--> Epoch [48/100], Loss: 0.4276, Validation Loss: 0.4420
	--> Epoch [49/100], Loss: 0.4233, Validation Loss: 0.4387
	--> Epoch [50/100], Loss: 0.4080, Validation Loss: 0.4371
	--> Epoch [51/100], Loss: 0.5095, Validation Loss: 0.4343
	--> Epoch [52/100], Loss: 0.4491, Validation Loss: 0.4296
	--> Epoch [53/100], Loss: 0.4310, Validation Loss: 0.4258
	--> Epoch [54/100], Loss: 0.3897, Validation Loss: 0.4228
	--> Epoch [55/100], Loss: 0.4068, Validation Loss: 0.4206
	--> Epoch [56/100], Loss: 0.4123, Validation Loss: 0.4181
	--> Epoch [57/100], Loss: 0.3840, Validation Loss: 0.4140
	--> Epoch [58/100], Loss: 0.3970, Validation Loss: 0.4089
	--> Epoch [59/100], Loss: 0.4152, Validation Loss: 0.4068
	--> Epoch [60/100], Loss: 0.3952, Validation Loss: 0.4048
	--> Epoch [61/100], Loss: 0.4669, Validation Loss: 0.4025
	--> Epoch [62/100], Loss: 0.3771, Validation Loss: 0.4003
	--> Epoch [63/100], Loss: 0.3717, Validation Loss: 0.3970
	--> Epoch [64/100], Loss: 0.4227, Validation Loss: 0.3939
	--> Epoch [65/100], Loss: 0.4105, Validation Loss: 0.3901
	--> Epoch [66/100], Loss: 0.3912, Validation Loss: 0.3875
	--> Epoch [67/100], Loss: 0.3700, Validation Loss: 0.3853
	--> Epoch [68/100], Loss: 0.3559, Validation Loss: 0.3815
	--> Epoch [69/100], Loss: 0.3802, Validation Loss: 0.3799
	--> Epoch [70/100], Loss: 0.4455, Validation Loss: 0.3776
	--> Epoch [71/100], Loss: 0.4047, Validation Loss: 0.3757
	--> Epoch [72/100], Loss: 0.3972, Validation Loss: 0.3738
	--> Epoch [73/100], Loss: 0.3606, Validation Loss: 0.3696
	--> Epoch [74/100], Loss: 0.3405, Validation Loss: 0.3671
	--> Epoch [75/100], Loss: 0.3654, Validation Loss: 0.3650
	--> Epoch [76/100], Loss: 0.3538, Validation Loss: 0.3633
	--> Epoch [77/100], Loss: 0.3998, Validation Loss: 0.3617
	--> Epoch [78/100], Loss: 0.4066, Validation Loss: 0.3604
	--> Epoch [79/100], Loss: 0.3296, Validation Loss: 0.3584
	--> Epoch [80/100], Loss: 0.3172, Validation Loss: 0.3566
	--> Epoch [81/100], Loss: 0.3172, Validation Loss: 0.3540
	--> Epoch [82/100], Loss: 0.3478, Validation Loss: 0.3501
	--> Epoch [83/100], Loss: 0.4263, Validation Loss: 0.3481
	--> Epoch [84/100], Loss: 0.3130, Validation Loss: 0.3474
	--> Epoch [85/100], Loss: 0.3290, Validation Loss: 0.3462
	--> Epoch [86/100], Loss: 0.2928, Validation Loss: 0.3438
	--> Epoch [87/100], Loss: 0.3115, Validation Loss: 0.3413
	--> Epoch [88/100], Loss: 0.3136, Validation Loss: 0.3384
	--> Epoch [89/100], Loss: 0.2883, Validation Loss: 0.3366
	--> Epoch [90/100], Loss: 0.3137, Validation Loss: 0.3342
	--> Epoch [91/100], Loss: 0.2683, Validation Loss: 0.3322
	--> Epoch [92/100], Loss: 0.2863, Validation Loss: 0.3313
	--> Epoch [93/100], Loss: 0.2820, Validation Loss: 0.3303
	--> Epoch [94/100], Loss: 0.3159, Validation Loss: 0.3289
	--> Epoch [95/100], Loss: 0.3712, Validation Loss: 0.3279
	--> Epoch [96/100], Loss: 0.3584, Validation Loss: 0.3269
	--> Epoch [97/100], Loss: 0.3729, Validation Loss: 0.3271
	--> Epoch [98/100], Loss: 0.2819, Validation Loss: 0.3259
	--> Epoch [99/100], Loss: 0.3417, Validation Loss: 0.3250
	--> Epoch [100/100], Loss: 0.3099, Validation Loss: 0.3241
	--> Training for Fold 2 took 0.3831050395965576 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7555, Validation Loss: 0.6864
	--> Epoch [2/100], Loss: 0.7741, Validation Loss: 0.6782
	--> Epoch [3/100], Loss: 0.7061, Validation Loss: 0.6738
	--> Epoch [4/100], Loss: 0.7288, Validation Loss: 0.6676
	--> Epoch [5/100], Loss: 0.6752, Validation Loss: 0.6610
	--> Epoch [6/100], Loss: 0.7371, Validation Loss: 0.6546
	--> Epoch [7/100], Loss: 0.6435, Validation Loss: 0.6507
	--> Epoch [8/100], Loss: 0.7474, Validation Loss: 0.6411
	--> Epoch [9/100], Loss: 0.7070, Validation Loss: 0.6328
	--> Epoch [10/100], Loss: 0.6765, Validation Loss: 0.6260
	--> Epoch [11/100], Loss: 0.6501, Validation Loss: 0.6192
	--> Epoch [12/100], Loss: 0.5971, Validation Loss: 0.6140
	--> Epoch [13/100], Loss: 0.6786, Validation Loss: 0.6080
	--> Epoch [14/100], Loss: 0.6316, Validation Loss: 0.6027
	--> Epoch [15/100], Loss: 0.6245, Validation Loss: 0.5959
	--> Epoch [16/100], Loss: 0.6046, Validation Loss: 0.5909
	--> Epoch [17/100], Loss: 0.6068, Validation Loss: 0.5843
	--> Epoch [18/100], Loss: 0.5899, Validation Loss: 0.5786
	--> Epoch [19/100], Loss: 0.5839, Validation Loss: 0.5736
	--> Epoch [20/100], Loss: 0.5715, Validation Loss: 0.5685
	--> Epoch [21/100], Loss: 0.5464, Validation Loss: 0.5626
	--> Epoch [22/100], Loss: 0.5346, Validation Loss: 0.5590
	--> Epoch [23/100], Loss: 0.5505, Validation Loss: 0.5557
	--> Epoch [24/100], Loss: 0.5378, Validation Loss: 0.5502
	--> Epoch [25/100], Loss: 0.5801, Validation Loss: 0.5457
	--> Epoch [26/100], Loss: 0.5771, Validation Loss: 0.5428
	--> Epoch [27/100], Loss: 0.5371, Validation Loss: 0.5400
	--> Epoch [28/100], Loss: 0.4663, Validation Loss: 0.5351
	--> Epoch [29/100], Loss: 0.4964, Validation Loss: 0.5299
	--> Epoch [30/100], Loss: 0.5480, Validation Loss: 0.5266
	--> Epoch [31/100], Loss: 0.5224, Validation Loss: 0.5250
	--> Epoch [32/100], Loss: 0.5457, Validation Loss: 0.5213
	--> Epoch [33/100], Loss: 0.4688, Validation Loss: 0.5178
	--> Epoch [34/100], Loss: 0.4725, Validation Loss: 0.5137
	--> Epoch [35/100], Loss: 0.4950, Validation Loss: 0.5094
	--> Epoch [36/100], Loss: 0.4428, Validation Loss: 0.5048
	--> Epoch [37/100], Loss: 0.4879, Validation Loss: 0.5009
	--> Epoch [38/100], Loss: 0.4952, Validation Loss: 0.4963
	--> Epoch [39/100], Loss: 0.4746, Validation Loss: 0.4924
	--> Epoch [40/100], Loss: 0.4802, Validation Loss: 0.4893
	--> Epoch [41/100], Loss: 0.4656, Validation Loss: 0.4866
	--> Epoch [42/100], Loss: 0.4834, Validation Loss: 0.4842
	--> Epoch [43/100], Loss: 0.4865, Validation Loss: 0.4808
	--> Epoch [44/100], Loss: 0.4872, Validation Loss: 0.4784
	--> Epoch [45/100], Loss: 0.4476, Validation Loss: 0.4740
	--> Epoch [46/100], Loss: 0.4752, Validation Loss: 0.4713
	--> Epoch [47/100], Loss: 0.4374, Validation Loss: 0.4673
	--> Epoch [48/100], Loss: 0.3903, Validation Loss: 0.4654
	--> Epoch [49/100], Loss: 0.4839, Validation Loss: 0.4621
	--> Epoch [50/100], Loss: 0.4256, Validation Loss: 0.4601
	--> Epoch [51/100], Loss: 0.4725, Validation Loss: 0.4569
	--> Epoch [52/100], Loss: 0.3937, Validation Loss: 0.4542
	--> Epoch [53/100], Loss: 0.3692, Validation Loss: 0.4511
	--> Epoch [54/100], Loss: 0.3883, Validation Loss: 0.4482
	--> Epoch [55/100], Loss: 0.4090, Validation Loss: 0.4450
	--> Epoch [56/100], Loss: 0.3986, Validation Loss: 0.4427
	--> Epoch [57/100], Loss: 0.4367, Validation Loss: 0.4401
	--> Epoch [58/100], Loss: 0.4079, Validation Loss: 0.4375
	--> Epoch [59/100], Loss: 0.4054, Validation Loss: 0.4368
	--> Epoch [60/100], Loss: 0.4049, Validation Loss: 0.4344
	--> Epoch [61/100], Loss: 0.3440, Validation Loss: 0.4318
	--> Epoch [62/100], Loss: 0.3964, Validation Loss: 0.4302
	--> Epoch [63/100], Loss: 0.3845, Validation Loss: 0.4275
	--> Epoch [64/100], Loss: 0.3826, Validation Loss: 0.4258
	--> Epoch [65/100], Loss: 0.3868, Validation Loss: 0.4240
	--> Epoch [66/100], Loss: 0.3820, Validation Loss: 0.4225
	--> Epoch [67/100], Loss: 0.3693, Validation Loss: 0.4207
	--> Epoch [68/100], Loss: 0.3593, Validation Loss: 0.4182
	--> Epoch [69/100], Loss: 0.3562, Validation Loss: 0.4164
	--> Epoch [70/100], Loss: 0.3272, Validation Loss: 0.4136
	--> Epoch [71/100], Loss: 0.3471, Validation Loss: 0.4116
	--> Epoch [72/100], Loss: 0.3391, Validation Loss: 0.4090
	--> Epoch [73/100], Loss: 0.3260, Validation Loss: 0.4069
	--> Epoch [74/100], Loss: 0.3479, Validation Loss: 0.4048
	--> Epoch [75/100], Loss: 0.3915, Validation Loss: 0.4033
	--> Epoch [76/100], Loss: 0.3991, Validation Loss: 0.4006
	--> Epoch [77/100], Loss: 0.3841, Validation Loss: 0.3996
	--> Epoch [78/100], Loss: 0.3075, Validation Loss: 0.3981
	--> Epoch [79/100], Loss: 0.3576, Validation Loss: 0.3957
	--> Epoch [80/100], Loss: 0.3112, Validation Loss: 0.3937
	--> Epoch [81/100], Loss: 0.3422, Validation Loss: 0.3920
	--> Epoch [82/100], Loss: 0.3067, Validation Loss: 0.3910
	--> Epoch [83/100], Loss: 0.2990, Validation Loss: 0.3889
	--> Epoch [84/100], Loss: 0.3528, Validation Loss: 0.3877
	--> Epoch [85/100], Loss: 0.3269, Validation Loss: 0.3866
	--> Epoch [86/100], Loss: 0.3178, Validation Loss: 0.3846
	--> Epoch [87/100], Loss: 0.3428, Validation Loss: 0.3833
	--> Epoch [88/100], Loss: 0.3371, Validation Loss: 0.3821
	--> Epoch [89/100], Loss: 0.3464, Validation Loss: 0.3799
	--> Epoch [90/100], Loss: 0.3016, Validation Loss: 0.3791
	--> Epoch [91/100], Loss: 0.3341, Validation Loss: 0.3767
	--> Epoch [92/100], Loss: 0.3109, Validation Loss: 0.3747
	--> Epoch [93/100], Loss: 0.3667, Validation Loss: 0.3743
	--> Epoch [94/100], Loss: 0.3287, Validation Loss: 0.3723
	--> Epoch [95/100], Loss: 0.3118, Validation Loss: 0.3709
	--> Epoch [96/100], Loss: 0.3474, Validation Loss: 0.3710
	--> Epoch [97/100], Loss: 0.3083, Validation Loss: 0.3694
	--> Epoch [98/100], Loss: 0.3030, Validation Loss: 0.3680
	--> Epoch [99/100], Loss: 0.3028, Validation Loss: 0.3666
	--> Epoch [100/100], Loss: 0.2768, Validation Loss: 0.3658
	--> Training for Fold 3 took 0.402271032333374 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7233, Validation Loss: 0.7026
	--> Epoch [2/100], Loss: 0.6987, Validation Loss: 0.6980
	--> Epoch [3/100], Loss: 0.6519, Validation Loss: 0.6908
	--> Epoch [4/100], Loss: 0.6556, Validation Loss: 0.6839
	--> Epoch [5/100], Loss: 0.6909, Validation Loss: 0.6781
	--> Epoch [6/100], Loss: 0.6521, Validation Loss: 0.6724
	--> Epoch [7/100], Loss: 0.6549, Validation Loss: 0.6644
	--> Epoch [8/100], Loss: 0.6418, Validation Loss: 0.6571
	--> Epoch [9/100], Loss: 0.6542, Validation Loss: 0.6504
	--> Epoch [10/100], Loss: 0.6042, Validation Loss: 0.6390
	--> Epoch [11/100], Loss: 0.5951, Validation Loss: 0.6313
	--> Epoch [12/100], Loss: 0.6169, Validation Loss: 0.6243
	--> Epoch [13/100], Loss: 0.5710, Validation Loss: 0.6171
	--> Epoch [14/100], Loss: 0.5940, Validation Loss: 0.6111
	--> Epoch [15/100], Loss: 0.5704, Validation Loss: 0.6029
	--> Epoch [16/100], Loss: 0.5644, Validation Loss: 0.5949
	--> Epoch [17/100], Loss: 0.5622, Validation Loss: 0.5906
	--> Epoch [18/100], Loss: 0.5432, Validation Loss: 0.5836
	--> Epoch [19/100], Loss: 0.5256, Validation Loss: 0.5762
	--> Epoch [20/100], Loss: 0.5470, Validation Loss: 0.5743
	--> Epoch [21/100], Loss: 0.5607, Validation Loss: 0.5673
	--> Epoch [22/100], Loss: 0.4910, Validation Loss: 0.5588
	--> Epoch [23/100], Loss: 0.5436, Validation Loss: 0.5531
	--> Epoch [24/100], Loss: 0.5323, Validation Loss: 0.5510
	--> Epoch [25/100], Loss: 0.5143, Validation Loss: 0.5443
	--> Epoch [26/100], Loss: 0.4921, Validation Loss: 0.5392
	--> Epoch [27/100], Loss: 0.4839, Validation Loss: 0.5326
	--> Epoch [28/100], Loss: 0.4626, Validation Loss: 0.5262
	--> Epoch [29/100], Loss: 0.4961, Validation Loss: 0.5235
	--> Epoch [30/100], Loss: 0.4562, Validation Loss: 0.5167
	--> Epoch [31/100], Loss: 0.4669, Validation Loss: 0.5141
	--> Epoch [32/100], Loss: 0.4437, Validation Loss: 0.5095
	--> Epoch [33/100], Loss: 0.4388, Validation Loss: 0.5060
	--> Epoch [34/100], Loss: 0.4328, Validation Loss: 0.5003
	--> Epoch [35/100], Loss: 0.4133, Validation Loss: 0.4941
	--> Epoch [36/100], Loss: 0.4652, Validation Loss: 0.4891
	--> Epoch [37/100], Loss: 0.4469, Validation Loss: 0.4846
	--> Epoch [38/100], Loss: 0.4672, Validation Loss: 0.4813
	--> Epoch [39/100], Loss: 0.4296, Validation Loss: 0.4783
	--> Epoch [40/100], Loss: 0.4245, Validation Loss: 0.4723
	--> Epoch [41/100], Loss: 0.4123, Validation Loss: 0.4684
	--> Epoch [42/100], Loss: 0.4747, Validation Loss: 0.4669
	--> Epoch [43/100], Loss: 0.3878, Validation Loss: 0.4648
	--> Epoch [44/100], Loss: 0.4206, Validation Loss: 0.4609
	--> Epoch [45/100], Loss: 0.4007, Validation Loss: 0.4605
	--> Epoch [46/100], Loss: 0.3948, Validation Loss: 0.4569
	--> Epoch [47/100], Loss: 0.4430, Validation Loss: 0.4525
	--> Epoch [48/100], Loss: 0.3997, Validation Loss: 0.4500
	--> Epoch [49/100], Loss: 0.4109, Validation Loss: 0.4467
	--> Epoch [50/100], Loss: 0.4034, Validation Loss: 0.4425
	--> Epoch [51/100], Loss: 0.4005, Validation Loss: 0.4393
	--> Epoch [52/100], Loss: 0.3694, Validation Loss: 0.4373
	--> Epoch [53/100], Loss: 0.3684, Validation Loss: 0.4338
	--> Epoch [54/100], Loss: 0.3622, Validation Loss: 0.4293
	--> Epoch [55/100], Loss: 0.3952, Validation Loss: 0.4260
	--> Epoch [56/100], Loss: 0.3872, Validation Loss: 0.4238
	--> Epoch [57/100], Loss: 0.3660, Validation Loss: 0.4204
	--> Epoch [58/100], Loss: 0.3319, Validation Loss: 0.4189
	--> Epoch [59/100], Loss: 0.3532, Validation Loss: 0.4159
	--> Epoch [60/100], Loss: 0.3136, Validation Loss: 0.4144
	--> Epoch [61/100], Loss: 0.3686, Validation Loss: 0.4133
	--> Epoch [62/100], Loss: 0.3386, Validation Loss: 0.4112
	--> Epoch [63/100], Loss: 0.3164, Validation Loss: 0.4060
	--> Epoch [64/100], Loss: 0.3039, Validation Loss: 0.4050
	--> Epoch [65/100], Loss: 0.3756, Validation Loss: 0.4032
	--> Epoch [66/100], Loss: 0.3112, Validation Loss: 0.4022
	--> Epoch [67/100], Loss: 0.3960, Validation Loss: 0.4031
	--> Epoch [68/100], Loss: 0.4214, Validation Loss: 0.4007
	--> Epoch [69/100], Loss: 0.3511, Validation Loss: 0.3986
	--> Epoch [70/100], Loss: 0.3164, Validation Loss: 0.3949
	--> Epoch [71/100], Loss: 0.3774, Validation Loss: 0.3921
	--> Epoch [72/100], Loss: 0.2995, Validation Loss: 0.3892
	--> Epoch [73/100], Loss: 0.3430, Validation Loss: 0.3886
	--> Epoch [74/100], Loss: 0.3199, Validation Loss: 0.3884
	--> Epoch [75/100], Loss: 0.3360, Validation Loss: 0.3867
	--> Epoch [76/100], Loss: 0.3043, Validation Loss: 0.3844
	--> Epoch [77/100], Loss: 0.2848, Validation Loss: 0.3831
	--> Epoch [78/100], Loss: 0.3503, Validation Loss: 0.3816
	--> Epoch [79/100], Loss: 0.2809, Validation Loss: 0.3810
	--> Epoch [80/100], Loss: 0.3084, Validation Loss: 0.3800
	--> Epoch [81/100], Loss: 0.3044, Validation Loss: 0.3782
	--> Epoch [82/100], Loss: 0.2868, Validation Loss: 0.3764
	--> Epoch [83/100], Loss: 0.3122, Validation Loss: 0.3750
	--> Epoch [84/100], Loss: 0.3399, Validation Loss: 0.3725
	--> Epoch [85/100], Loss: 0.3301, Validation Loss: 0.3708
	--> Epoch [86/100], Loss: 0.2699, Validation Loss: 0.3699
	--> Epoch [87/100], Loss: 0.3315, Validation Loss: 0.3685
	--> Epoch [88/100], Loss: 0.2530, Validation Loss: 0.3670
	--> Epoch [89/100], Loss: 0.3033, Validation Loss: 0.3651
	--> Epoch [90/100], Loss: 0.2541, Validation Loss: 0.3626
	--> Epoch [91/100], Loss: 0.3393, Validation Loss: 0.3626
	--> Epoch [92/100], Loss: 0.3180, Validation Loss: 0.3620
	--> Epoch [93/100], Loss: 0.2595, Validation Loss: 0.3596
	--> Epoch [94/100], Loss: 0.2842, Validation Loss: 0.3583
	--> Epoch [95/100], Loss: 0.3011, Validation Loss: 0.3577
	--> Epoch [96/100], Loss: 0.2886, Validation Loss: 0.3561
	--> Epoch [97/100], Loss: 0.3525, Validation Loss: 0.3558
	--> Epoch [98/100], Loss: 0.3389, Validation Loss: 0.3549
	--> Epoch [99/100], Loss: 0.2465, Validation Loss: 0.3539
	--> Epoch [100/100], Loss: 0.2494, Validation Loss: 0.3529
	--> Training for Fold 4 took 0.3868846893310547 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8110, Validation Loss: 0.6884
	--> Epoch [2/100], Loss: 0.8342, Validation Loss: 0.6748
	--> Epoch [3/100], Loss: 0.7019, Validation Loss: 0.6665
	--> Epoch [4/100], Loss: 0.7165, Validation Loss: 0.6574
	--> Epoch [5/100], Loss: 0.7564, Validation Loss: 0.6529
	--> Epoch [6/100], Loss: 0.7297, Validation Loss: 0.6459
	--> Epoch [7/100], Loss: 0.6649, Validation Loss: 0.6413
	--> Epoch [8/100], Loss: 0.6606, Validation Loss: 0.6385
	--> Epoch [9/100], Loss: 0.6918, Validation Loss: 0.6374
	--> Epoch [10/100], Loss: 0.6019, Validation Loss: 0.6329
	--> Epoch [11/100], Loss: 0.5865, Validation Loss: 0.6271
	--> Epoch [12/100], Loss: 0.6154, Validation Loss: 0.6247
	--> Epoch [13/100], Loss: 0.6163, Validation Loss: 0.6201
	--> Epoch [14/100], Loss: 0.5727, Validation Loss: 0.6184
	--> Epoch [15/100], Loss: 0.5826, Validation Loss: 0.6154
	--> Epoch [16/100], Loss: 0.5563, Validation Loss: 0.6120
	--> Epoch [17/100], Loss: 0.5467, Validation Loss: 0.6113
	--> Epoch [18/100], Loss: 0.5059, Validation Loss: 0.6070
	--> Epoch [19/100], Loss: 0.5389, Validation Loss: 0.6033
	--> Epoch [20/100], Loss: 0.5226, Validation Loss: 0.5990
	--> Epoch [21/100], Loss: 0.4881, Validation Loss: 0.5953
	--> Epoch [22/100], Loss: 0.5063, Validation Loss: 0.5936
	--> Epoch [23/100], Loss: 0.5377, Validation Loss: 0.5923
	--> Epoch [24/100], Loss: 0.5270, Validation Loss: 0.5921
	--> Epoch [25/100], Loss: 0.4792, Validation Loss: 0.5904
	--> Epoch [26/100], Loss: 0.4413, Validation Loss: 0.5886
	--> Epoch [27/100], Loss: 0.4723, Validation Loss: 0.5862
	--> Epoch [28/100], Loss: 0.5063, Validation Loss: 0.5855
	--> Epoch [29/100], Loss: 0.5134, Validation Loss: 0.5835
	--> Epoch [30/100], Loss: 0.4540, Validation Loss: 0.5822
	--> Epoch [31/100], Loss: 0.4539, Validation Loss: 0.5835
	--> Epoch [32/100], Loss: 0.4668, Validation Loss: 0.5828
	--> Epoch [33/100], Loss: 0.4498, Validation Loss: 0.5808
	--> Epoch [34/100], Loss: 0.4252, Validation Loss: 0.5792
	--> Epoch [35/100], Loss: 0.4769, Validation Loss: 0.5754
	--> Epoch [36/100], Loss: 0.4243, Validation Loss: 0.5759
	--> Epoch [37/100], Loss: 0.4202, Validation Loss: 0.5748
	--> Epoch [38/100], Loss: 0.4635, Validation Loss: 0.5727
	--> Epoch [39/100], Loss: 0.4490, Validation Loss: 0.5729
	--> Epoch [40/100], Loss: 0.4484, Validation Loss: 0.5736
	--> Epoch [41/100], Loss: 0.3571, Validation Loss: 0.5734
Early stopping
	--> Training for Fold 5 took 0.15040326118469238 sec, using 41 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7521
	--> Final training Epoch [2/100], Loss: 0.7038
	--> Final training Epoch [3/100], Loss: 0.6923
	--> Final training Epoch [4/100], Loss: 0.6982
	--> Final training Epoch [5/100], Loss: 0.6787
	--> Final training Epoch [6/100], Loss: 0.6546
	--> Final training Epoch [7/100], Loss: 0.6355
	--> Final training Epoch [8/100], Loss: 0.6323
	--> Final training Epoch [9/100], Loss: 0.6354
	--> Final training Epoch [10/100], Loss: 0.6289
	--> Final training Epoch [11/100], Loss: 0.5921
	--> Final training Epoch [12/100], Loss: 0.6187
	--> Final training Epoch [13/100], Loss: 0.5841
	--> Final training Epoch [14/100], Loss: 0.5955
	--> Final training Epoch [15/100], Loss: 0.5859
	--> Final training Epoch [16/100], Loss: 0.5525
	--> Final training Epoch [17/100], Loss: 0.5750
	--> Final training Epoch [18/100], Loss: 0.5574
	--> Final training Epoch [19/100], Loss: 0.5183
	--> Final training Epoch [20/100], Loss: 0.5248
	--> Final training Epoch [21/100], Loss: 0.5430
	--> Final training Epoch [22/100], Loss: 0.5260
	--> Final training Epoch [23/100], Loss: 0.5093
	--> Final training Epoch [24/100], Loss: 0.4973
	--> Final training Epoch [25/100], Loss: 0.4960
	--> Final training Epoch [26/100], Loss: 0.4901
	--> Final training Epoch [27/100], Loss: 0.5070
	--> Final training Epoch [28/100], Loss: 0.4905
	--> Final training Epoch [29/100], Loss: 0.5147
	--> Final training Epoch [30/100], Loss: 0.5192
	--> Final training Epoch [31/100], Loss: 0.4945
	--> Final training Epoch [32/100], Loss: 0.5114
	--> Final training Epoch [33/100], Loss: 0.5000
	--> Final training Epoch [34/100], Loss: 0.4597
	--> Final training Epoch [35/100], Loss: 0.4075
	--> Final training Epoch [36/100], Loss: 0.4534
	--> Final training Epoch [37/100], Loss: 0.4909
	--> Final training Epoch [38/100], Loss: 0.4603
	--> Final training Epoch [39/100], Loss: 0.4432
	--> Final training Epoch [40/100], Loss: 0.4124
	--> Final training Epoch [41/100], Loss: 0.4130
	--> Final training Epoch [42/100], Loss: 0.4563
	--> Final training Epoch [43/100], Loss: 0.4250
	--> Final training Epoch [44/100], Loss: 0.4070
	--> Final training Epoch [45/100], Loss: 0.4530
	--> Final training Epoch [46/100], Loss: 0.3817
	--> Final training Epoch [47/100], Loss: 0.4556
	--> Final training Epoch [48/100], Loss: 0.4237
	--> Final training Epoch [49/100], Loss: 0.3740
	--> Final training Epoch [50/100], Loss: 0.4053
	--> Final training Epoch [51/100], Loss: 0.3788
	--> Final training Epoch [52/100], Loss: 0.3962
	--> Final training Epoch [53/100], Loss: 0.4220
	--> Final training Epoch [54/100], Loss: 0.4473
	--> Final training Epoch [55/100], Loss: 0.3628
	--> Final training Epoch [56/100], Loss: 0.3477
	--> Final training Epoch [57/100], Loss: 0.3833
	--> Final training Epoch [58/100], Loss: 0.4114
	--> Final training Epoch [59/100], Loss: 0.3845
	--> Final training Epoch [60/100], Loss: 0.3545
	--> Final training Epoch [61/100], Loss: 0.3944
	--> Final training Epoch [62/100], Loss: 0.3481
	--> Final training Epoch [63/100], Loss: 0.3725
	--> Final training Epoch [64/100], Loss: 0.3624
	--> Final training Epoch [65/100], Loss: 0.4414
	--> Final training Epoch [66/100], Loss: 0.3874
	--> Final training Epoch [67/100], Loss: 0.3701
	--> Final training Epoch [68/100], Loss: 0.3138
	--> Final training Epoch [69/100], Loss: 0.3900
	--> Final training Epoch [70/100], Loss: 0.3279
	--> Final training Epoch [71/100], Loss: 0.3424
	--> Final training Epoch [72/100], Loss: 0.3130
	--> Final training Epoch [73/100], Loss: 0.3799
	--> Final training Epoch [74/100], Loss: 0.4018
	--> Final training Epoch [75/100], Loss: 0.3825
	--> Final training Epoch [76/100], Loss: 0.2961
	--> Final training Epoch [77/100], Loss: 0.3338
	--> Final training Epoch [78/100], Loss: 0.3423
	--> Final training Epoch [79/100], Loss: 0.3329
	--> Final training Epoch [80/100], Loss: 0.3119
	--> Final training Epoch [81/100], Loss: 0.2746
	--> Final training Epoch [82/100], Loss: 0.3816
	--> Final training Epoch [83/100], Loss: 0.3294
	--> Final training Epoch [84/100], Loss: 0.3246
	--> Final training Epoch [85/100], Loss: 0.3411
	--> Final training Epoch [86/100], Loss: 0.3253
	--> Final training Epoch [87/100], Loss: 0.2943
	--> Final training Epoch [88/100], Loss: 0.3296
	--> Final training Epoch [89/100], Loss: 0.3261
	--> Final training Epoch [90/100], Loss: 0.3261
	--> Final training Epoch [91/100], Loss: 0.2630
	--> Final training Epoch [92/100], Loss: 0.2875
	--> Final training Epoch [93/100], Loss: 0.2858
	--> Final training Epoch [94/100], Loss: 0.3347
	--> Final training Epoch [95/100], Loss: 0.2925
	--> Final training Epoch [96/100], Loss: 0.2757
	--> Final training Epoch [97/100], Loss: 0.3114
	--> Final training Epoch [98/100], Loss: 0.2708
	--> Final training Epoch [99/100], Loss: 0.2852
	--> Final training Epoch [100/100], Loss: 0.3145

Final training took 0.35511159896850586 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.7249
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8819, Validation Loss: 0.3588,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3588
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8070, Validation Loss: 0.3957,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3588
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3954,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3588
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8175, Validation Loss: 0.3650,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3588
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3649,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3588
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.3722,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3588

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6585, Validation Loss: 0.7216
	--> Epoch [2/100], Loss: 0.6613, Validation Loss: 0.7108
	--> Epoch [3/100], Loss: 0.6412, Validation Loss: 0.7025
	--> Epoch [4/100], Loss: 0.6347, Validation Loss: 0.6923
	--> Epoch [5/100], Loss: 0.6274, Validation Loss: 0.6813
	--> Epoch [6/100], Loss: 0.6199, Validation Loss: 0.6719
	--> Epoch [7/100], Loss: 0.5955, Validation Loss: 0.6615
	--> Epoch [8/100], Loss: 0.6196, Validation Loss: 0.6548
	--> Epoch [9/100], Loss: 0.6210, Validation Loss: 0.6514
	--> Epoch [10/100], Loss: 0.5724, Validation Loss: 0.6443
	--> Epoch [11/100], Loss: 0.5731, Validation Loss: 0.6350
	--> Epoch [12/100], Loss: 0.5829, Validation Loss: 0.6276
	--> Epoch [13/100], Loss: 0.5238, Validation Loss: 0.6185
	--> Epoch [14/100], Loss: 0.5390, Validation Loss: 0.6109
	--> Epoch [15/100], Loss: 0.5464, Validation Loss: 0.6024
	--> Epoch [16/100], Loss: 0.5135, Validation Loss: 0.5933
	--> Epoch [17/100], Loss: 0.4749, Validation Loss: 0.5829
	--> Epoch [18/100], Loss: 0.4853, Validation Loss: 0.5729
	--> Epoch [19/100], Loss: 0.4799, Validation Loss: 0.5645
	--> Epoch [20/100], Loss: 0.4944, Validation Loss: 0.5577
	--> Epoch [21/100], Loss: 0.4882, Validation Loss: 0.5535
	--> Epoch [22/100], Loss: 0.4947, Validation Loss: 0.5475
	--> Epoch [23/100], Loss: 0.4497, Validation Loss: 0.5408
	--> Epoch [24/100], Loss: 0.4719, Validation Loss: 0.5357
	--> Epoch [25/100], Loss: 0.4466, Validation Loss: 0.5272
	--> Epoch [26/100], Loss: 0.4422, Validation Loss: 0.5190
	--> Epoch [27/100], Loss: 0.4655, Validation Loss: 0.5118
	--> Epoch [28/100], Loss: 0.4274, Validation Loss: 0.5053
	--> Epoch [29/100], Loss: 0.4435, Validation Loss: 0.4987
	--> Epoch [30/100], Loss: 0.4072, Validation Loss: 0.4930
	--> Epoch [31/100], Loss: 0.3899, Validation Loss: 0.4871
	--> Epoch [32/100], Loss: 0.3809, Validation Loss: 0.4813
	--> Epoch [33/100], Loss: 0.4049, Validation Loss: 0.4757
	--> Epoch [34/100], Loss: 0.3831, Validation Loss: 0.4696
	--> Epoch [35/100], Loss: 0.3935, Validation Loss: 0.4635
	--> Epoch [36/100], Loss: 0.4016, Validation Loss: 0.4570
	--> Epoch [37/100], Loss: 0.3799, Validation Loss: 0.4505
	--> Epoch [38/100], Loss: 0.3571, Validation Loss: 0.4449
	--> Epoch [39/100], Loss: 0.3675, Validation Loss: 0.4386
	--> Epoch [40/100], Loss: 0.3456, Validation Loss: 0.4320
	--> Epoch [41/100], Loss: 0.3336, Validation Loss: 0.4261
	--> Epoch [42/100], Loss: 0.3267, Validation Loss: 0.4202
	--> Epoch [43/100], Loss: 0.3679, Validation Loss: 0.4151
	--> Epoch [44/100], Loss: 0.3561, Validation Loss: 0.4128
	--> Epoch [45/100], Loss: 0.3468, Validation Loss: 0.4084
	--> Epoch [46/100], Loss: 0.3261, Validation Loss: 0.4052
	--> Epoch [47/100], Loss: 0.3125, Validation Loss: 0.4024
	--> Epoch [48/100], Loss: 0.3198, Validation Loss: 0.3976
	--> Epoch [49/100], Loss: 0.3185, Validation Loss: 0.3926
	--> Epoch [50/100], Loss: 0.3006, Validation Loss: 0.3881
	--> Epoch [51/100], Loss: 0.3013, Validation Loss: 0.3853
	--> Epoch [52/100], Loss: 0.3060, Validation Loss: 0.3799
	--> Epoch [53/100], Loss: 0.3023, Validation Loss: 0.3789
	--> Epoch [54/100], Loss: 0.2760, Validation Loss: 0.3742
	--> Epoch [55/100], Loss: 0.2720, Validation Loss: 0.3702
	--> Epoch [56/100], Loss: 0.2553, Validation Loss: 0.3681
	--> Epoch [57/100], Loss: 0.2886, Validation Loss: 0.3641
	--> Epoch [58/100], Loss: 0.2828, Validation Loss: 0.3592
	--> Epoch [59/100], Loss: 0.2528, Validation Loss: 0.3565
	--> Epoch [60/100], Loss: 0.3011, Validation Loss: 0.3533
	--> Epoch [61/100], Loss: 0.2842, Validation Loss: 0.3498
	--> Epoch [62/100], Loss: 0.2559, Validation Loss: 0.3467
	--> Epoch [63/100], Loss: 0.2565, Validation Loss: 0.3433
	--> Epoch [64/100], Loss: 0.2471, Validation Loss: 0.3418
	--> Epoch [65/100], Loss: 0.2766, Validation Loss: 0.3375
	--> Epoch [66/100], Loss: 0.2456, Validation Loss: 0.3344
	--> Epoch [67/100], Loss: 0.2820, Validation Loss: 0.3317
	--> Epoch [68/100], Loss: 0.2313, Validation Loss: 0.3281
	--> Epoch [69/100], Loss: 0.2307, Validation Loss: 0.3260
	--> Epoch [70/100], Loss: 0.2430, Validation Loss: 0.3219
	--> Epoch [71/100], Loss: 0.2065, Validation Loss: 0.3201
	--> Epoch [72/100], Loss: 0.2560, Validation Loss: 0.3172
	--> Epoch [73/100], Loss: 0.2163, Validation Loss: 0.3163
	--> Epoch [74/100], Loss: 0.2663, Validation Loss: 0.3141
	--> Epoch [75/100], Loss: 0.2110, Validation Loss: 0.3118
	--> Epoch [76/100], Loss: 0.1945, Validation Loss: 0.3099
	--> Epoch [77/100], Loss: 0.2533, Validation Loss: 0.3082
	--> Epoch [78/100], Loss: 0.1816, Validation Loss: 0.3058
	--> Epoch [79/100], Loss: 0.2425, Validation Loss: 0.3038
	--> Epoch [80/100], Loss: 0.1873, Validation Loss: 0.3011
	--> Epoch [81/100], Loss: 0.2090, Validation Loss: 0.2992
	--> Epoch [82/100], Loss: 0.2114, Validation Loss: 0.2966
	--> Epoch [83/100], Loss: 0.1827, Validation Loss: 0.2960
	--> Epoch [84/100], Loss: 0.1944, Validation Loss: 0.2946
	--> Epoch [85/100], Loss: 0.1999, Validation Loss: 0.2933
	--> Epoch [86/100], Loss: 0.2179, Validation Loss: 0.2914
	--> Epoch [87/100], Loss: 0.1891, Validation Loss: 0.2899
	--> Epoch [88/100], Loss: 0.2219, Validation Loss: 0.2865
	--> Epoch [89/100], Loss: 0.1775, Validation Loss: 0.2864
	--> Epoch [90/100], Loss: 0.1753, Validation Loss: 0.2857
	--> Epoch [91/100], Loss: 0.2236, Validation Loss: 0.2834
	--> Epoch [92/100], Loss: 0.1849, Validation Loss: 0.2808
	--> Epoch [93/100], Loss: 0.1548, Validation Loss: 0.2786
	--> Epoch [94/100], Loss: 0.1623, Validation Loss: 0.2760
	--> Epoch [95/100], Loss: 0.1627, Validation Loss: 0.2757
	--> Epoch [96/100], Loss: 0.1646, Validation Loss: 0.2754
	--> Epoch [97/100], Loss: 0.2019, Validation Loss: 0.2736
	--> Epoch [98/100], Loss: 0.1698, Validation Loss: 0.2725
	--> Epoch [99/100], Loss: 0.1678, Validation Loss: 0.2712
	--> Epoch [100/100], Loss: 0.1712, Validation Loss: 0.2701
	--> Training for Fold 1 took 0.470644474029541 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7692, Validation Loss: 0.6987
	--> Epoch [2/100], Loss: 0.7540, Validation Loss: 0.6858
	--> Epoch [3/100], Loss: 0.7356, Validation Loss: 0.6743
	--> Epoch [4/100], Loss: 0.7296, Validation Loss: 0.6656
	--> Epoch [5/100], Loss: 0.7228, Validation Loss: 0.6505
	--> Epoch [6/100], Loss: 0.6826, Validation Loss: 0.6395
	--> Epoch [7/100], Loss: 0.6529, Validation Loss: 0.6295
	--> Epoch [8/100], Loss: 0.6620, Validation Loss: 0.6212
	--> Epoch [9/100], Loss: 0.6632, Validation Loss: 0.6113
	--> Epoch [10/100], Loss: 0.6279, Validation Loss: 0.5990
	--> Epoch [11/100], Loss: 0.6256, Validation Loss: 0.5897
	--> Epoch [12/100], Loss: 0.6260, Validation Loss: 0.5830
	--> Epoch [13/100], Loss: 0.5993, Validation Loss: 0.5742
	--> Epoch [14/100], Loss: 0.5953, Validation Loss: 0.5656
	--> Epoch [15/100], Loss: 0.5754, Validation Loss: 0.5566
	--> Epoch [16/100], Loss: 0.5615, Validation Loss: 0.5487
	--> Epoch [17/100], Loss: 0.5779, Validation Loss: 0.5411
	--> Epoch [18/100], Loss: 0.5529, Validation Loss: 0.5348
	--> Epoch [19/100], Loss: 0.5820, Validation Loss: 0.5275
	--> Epoch [20/100], Loss: 0.5175, Validation Loss: 0.5220
	--> Epoch [21/100], Loss: 0.5676, Validation Loss: 0.5177
	--> Epoch [22/100], Loss: 0.5377, Validation Loss: 0.5121
	--> Epoch [23/100], Loss: 0.5233, Validation Loss: 0.5056
	--> Epoch [24/100], Loss: 0.4982, Validation Loss: 0.4998
	--> Epoch [25/100], Loss: 0.5019, Validation Loss: 0.4936
	--> Epoch [26/100], Loss: 0.4991, Validation Loss: 0.4869
	--> Epoch [27/100], Loss: 0.4976, Validation Loss: 0.4811
	--> Epoch [28/100], Loss: 0.4807, Validation Loss: 0.4763
	--> Epoch [29/100], Loss: 0.4891, Validation Loss: 0.4716
	--> Epoch [30/100], Loss: 0.4683, Validation Loss: 0.4677
	--> Epoch [31/100], Loss: 0.4425, Validation Loss: 0.4627
	--> Epoch [32/100], Loss: 0.4213, Validation Loss: 0.4578
	--> Epoch [33/100], Loss: 0.4732, Validation Loss: 0.4542
	--> Epoch [34/100], Loss: 0.4054, Validation Loss: 0.4500
	--> Epoch [35/100], Loss: 0.4567, Validation Loss: 0.4451
	--> Epoch [36/100], Loss: 0.4478, Validation Loss: 0.4405
	--> Epoch [37/100], Loss: 0.4208, Validation Loss: 0.4346
	--> Epoch [38/100], Loss: 0.4046, Validation Loss: 0.4307
	--> Epoch [39/100], Loss: 0.4115, Validation Loss: 0.4268
	--> Epoch [40/100], Loss: 0.3818, Validation Loss: 0.4234
	--> Epoch [41/100], Loss: 0.3943, Validation Loss: 0.4192
	--> Epoch [42/100], Loss: 0.4123, Validation Loss: 0.4157
	--> Epoch [43/100], Loss: 0.4025, Validation Loss: 0.4128
	--> Epoch [44/100], Loss: 0.4129, Validation Loss: 0.4095
	--> Epoch [45/100], Loss: 0.3928, Validation Loss: 0.4053
	--> Epoch [46/100], Loss: 0.4047, Validation Loss: 0.4025
	--> Epoch [47/100], Loss: 0.3571, Validation Loss: 0.3999
	--> Epoch [48/100], Loss: 0.3856, Validation Loss: 0.3971
	--> Epoch [49/100], Loss: 0.3583, Validation Loss: 0.3939
	--> Epoch [50/100], Loss: 0.3168, Validation Loss: 0.3896
	--> Epoch [51/100], Loss: 0.3378, Validation Loss: 0.3869
	--> Epoch [52/100], Loss: 0.3315, Validation Loss: 0.3839
	--> Epoch [53/100], Loss: 0.3294, Validation Loss: 0.3813
	--> Epoch [54/100], Loss: 0.3387, Validation Loss: 0.3771
	--> Epoch [55/100], Loss: 0.3644, Validation Loss: 0.3754
	--> Epoch [56/100], Loss: 0.3147, Validation Loss: 0.3723
	--> Epoch [57/100], Loss: 0.3508, Validation Loss: 0.3708
	--> Epoch [58/100], Loss: 0.3020, Validation Loss: 0.3690
	--> Epoch [59/100], Loss: 0.3009, Validation Loss: 0.3661
	--> Epoch [60/100], Loss: 0.2797, Validation Loss: 0.3630
	--> Epoch [61/100], Loss: 0.2638, Validation Loss: 0.3600
	--> Epoch [62/100], Loss: 0.2952, Validation Loss: 0.3574
	--> Epoch [63/100], Loss: 0.2953, Validation Loss: 0.3556
	--> Epoch [64/100], Loss: 0.2716, Validation Loss: 0.3534
	--> Epoch [65/100], Loss: 0.2601, Validation Loss: 0.3516
	--> Epoch [66/100], Loss: 0.3088, Validation Loss: 0.3503
	--> Epoch [67/100], Loss: 0.3189, Validation Loss: 0.3499
	--> Epoch [68/100], Loss: 0.2510, Validation Loss: 0.3471
	--> Epoch [69/100], Loss: 0.2844, Validation Loss: 0.3468
	--> Epoch [70/100], Loss: 0.2867, Validation Loss: 0.3457
	--> Epoch [71/100], Loss: 0.2598, Validation Loss: 0.3445
	--> Epoch [72/100], Loss: 0.2229, Validation Loss: 0.3429
	--> Epoch [73/100], Loss: 0.2580, Validation Loss: 0.3431
	--> Epoch [74/100], Loss: 0.2482, Validation Loss: 0.3429
	--> Epoch [75/100], Loss: 0.2535, Validation Loss: 0.3412
	--> Epoch [76/100], Loss: 0.2509, Validation Loss: 0.3386
	--> Epoch [77/100], Loss: 0.2436, Validation Loss: 0.3369
	--> Epoch [78/100], Loss: 0.2335, Validation Loss: 0.3354
	--> Epoch [79/100], Loss: 0.2676, Validation Loss: 0.3329
	--> Epoch [80/100], Loss: 0.2401, Validation Loss: 0.3322
	--> Epoch [81/100], Loss: 0.2428, Validation Loss: 0.3320
	--> Epoch [82/100], Loss: 0.2489, Validation Loss: 0.3305
	--> Epoch [83/100], Loss: 0.2286, Validation Loss: 0.3295
	--> Epoch [84/100], Loss: 0.2230, Validation Loss: 0.3277
	--> Epoch [85/100], Loss: 0.2579, Validation Loss: 0.3263
	--> Epoch [86/100], Loss: 0.2613, Validation Loss: 0.3242
	--> Epoch [87/100], Loss: 0.2557, Validation Loss: 0.3215
	--> Epoch [88/100], Loss: 0.2407, Validation Loss: 0.3194
	--> Epoch [89/100], Loss: 0.2252, Validation Loss: 0.3191
	--> Epoch [90/100], Loss: 0.2196, Validation Loss: 0.3186
	--> Epoch [91/100], Loss: 0.2061, Validation Loss: 0.3169
	--> Epoch [92/100], Loss: 0.2112, Validation Loss: 0.3148
	--> Epoch [93/100], Loss: 0.2321, Validation Loss: 0.3134
	--> Epoch [94/100], Loss: 0.2134, Validation Loss: 0.3118
	--> Epoch [95/100], Loss: 0.1794, Validation Loss: 0.3118
	--> Epoch [96/100], Loss: 0.2073, Validation Loss: 0.3115
	--> Epoch [97/100], Loss: 0.1931, Validation Loss: 0.3118
	--> Epoch [98/100], Loss: 0.1778, Validation Loss: 0.3106
	--> Epoch [99/100], Loss: 0.2158, Validation Loss: 0.3099
	--> Epoch [100/100], Loss: 0.1686, Validation Loss: 0.3090
	--> Training for Fold 2 took 0.47245097160339355 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7531, Validation Loss: 0.8004
	--> Epoch [2/100], Loss: 0.7319, Validation Loss: 0.7869
	--> Epoch [3/100], Loss: 0.7004, Validation Loss: 0.7752
	--> Epoch [4/100], Loss: 0.7188, Validation Loss: 0.7640
	--> Epoch [5/100], Loss: 0.6737, Validation Loss: 0.7545
	--> Epoch [6/100], Loss: 0.6293, Validation Loss: 0.7405
	--> Epoch [7/100], Loss: 0.6607, Validation Loss: 0.7326
	--> Epoch [8/100], Loss: 0.6680, Validation Loss: 0.7211
	--> Epoch [9/100], Loss: 0.6157, Validation Loss: 0.7137
	--> Epoch [10/100], Loss: 0.5819, Validation Loss: 0.7030
	--> Epoch [11/100], Loss: 0.5551, Validation Loss: 0.6948
	--> Epoch [12/100], Loss: 0.5727, Validation Loss: 0.6852
	--> Epoch [13/100], Loss: 0.5550, Validation Loss: 0.6763
	--> Epoch [14/100], Loss: 0.5827, Validation Loss: 0.6679
	--> Epoch [15/100], Loss: 0.5668, Validation Loss: 0.6591
	--> Epoch [16/100], Loss: 0.5301, Validation Loss: 0.6535
	--> Epoch [17/100], Loss: 0.5659, Validation Loss: 0.6446
	--> Epoch [18/100], Loss: 0.5087, Validation Loss: 0.6387
	--> Epoch [19/100], Loss: 0.5203, Validation Loss: 0.6321
	--> Epoch [20/100], Loss: 0.4685, Validation Loss: 0.6249
	--> Epoch [21/100], Loss: 0.5199, Validation Loss: 0.6177
	--> Epoch [22/100], Loss: 0.4841, Validation Loss: 0.6095
	--> Epoch [23/100], Loss: 0.4757, Validation Loss: 0.6020
	--> Epoch [24/100], Loss: 0.4360, Validation Loss: 0.5952
	--> Epoch [25/100], Loss: 0.5049, Validation Loss: 0.5893
	--> Epoch [26/100], Loss: 0.4668, Validation Loss: 0.5826
	--> Epoch [27/100], Loss: 0.4682, Validation Loss: 0.5774
	--> Epoch [28/100], Loss: 0.4615, Validation Loss: 0.5747
	--> Epoch [29/100], Loss: 0.4500, Validation Loss: 0.5688
	--> Epoch [30/100], Loss: 0.4099, Validation Loss: 0.5615
	--> Epoch [31/100], Loss: 0.4214, Validation Loss: 0.5542
	--> Epoch [32/100], Loss: 0.4161, Validation Loss: 0.5500
	--> Epoch [33/100], Loss: 0.4262, Validation Loss: 0.5448
	--> Epoch [34/100], Loss: 0.4209, Validation Loss: 0.5404
	--> Epoch [35/100], Loss: 0.3956, Validation Loss: 0.5363
	--> Epoch [36/100], Loss: 0.4340, Validation Loss: 0.5325
	--> Epoch [37/100], Loss: 0.3995, Validation Loss: 0.5270
	--> Epoch [38/100], Loss: 0.3969, Validation Loss: 0.5232
	--> Epoch [39/100], Loss: 0.3699, Validation Loss: 0.5185
	--> Epoch [40/100], Loss: 0.3982, Validation Loss: 0.5150
	--> Epoch [41/100], Loss: 0.3597, Validation Loss: 0.5122
	--> Epoch [42/100], Loss: 0.3387, Validation Loss: 0.5085
	--> Epoch [43/100], Loss: 0.3348, Validation Loss: 0.5043
	--> Epoch [44/100], Loss: 0.3035, Validation Loss: 0.5019
	--> Epoch [45/100], Loss: 0.3567, Validation Loss: 0.4973
	--> Epoch [46/100], Loss: 0.3755, Validation Loss: 0.4928
	--> Epoch [47/100], Loss: 0.3561, Validation Loss: 0.4902
	--> Epoch [48/100], Loss: 0.3768, Validation Loss: 0.4864
	--> Epoch [49/100], Loss: 0.3414, Validation Loss: 0.4835
	--> Epoch [50/100], Loss: 0.3139, Validation Loss: 0.4801
	--> Epoch [51/100], Loss: 0.3238, Validation Loss: 0.4769
	--> Epoch [52/100], Loss: 0.3342, Validation Loss: 0.4721
	--> Epoch [53/100], Loss: 0.3035, Validation Loss: 0.4694
	--> Epoch [54/100], Loss: 0.3290, Validation Loss: 0.4663
	--> Epoch [55/100], Loss: 0.3647, Validation Loss: 0.4642
	--> Epoch [56/100], Loss: 0.3319, Validation Loss: 0.4641
	--> Epoch [57/100], Loss: 0.2658, Validation Loss: 0.4604
	--> Epoch [58/100], Loss: 0.2849, Validation Loss: 0.4577
	--> Epoch [59/100], Loss: 0.3405, Validation Loss: 0.4562
	--> Epoch [60/100], Loss: 0.2871, Validation Loss: 0.4542
	--> Epoch [61/100], Loss: 0.3035, Validation Loss: 0.4509
	--> Epoch [62/100], Loss: 0.2860, Validation Loss: 0.4498
	--> Epoch [63/100], Loss: 0.3051, Validation Loss: 0.4476
	--> Epoch [64/100], Loss: 0.2324, Validation Loss: 0.4461
	--> Epoch [65/100], Loss: 0.2553, Validation Loss: 0.4435
	--> Epoch [66/100], Loss: 0.3133, Validation Loss: 0.4401
	--> Epoch [67/100], Loss: 0.2294, Validation Loss: 0.4377
	--> Epoch [68/100], Loss: 0.2572, Validation Loss: 0.4350
	--> Epoch [69/100], Loss: 0.2404, Validation Loss: 0.4339
	--> Epoch [70/100], Loss: 0.2543, Validation Loss: 0.4335
	--> Epoch [71/100], Loss: 0.2647, Validation Loss: 0.4313
	--> Epoch [72/100], Loss: 0.2147, Validation Loss: 0.4281
	--> Epoch [73/100], Loss: 0.2504, Validation Loss: 0.4279
	--> Epoch [74/100], Loss: 0.2654, Validation Loss: 0.4272
	--> Epoch [75/100], Loss: 0.1906, Validation Loss: 0.4253
	--> Epoch [76/100], Loss: 0.2322, Validation Loss: 0.4228
	--> Epoch [77/100], Loss: 0.2607, Validation Loss: 0.4207
	--> Epoch [78/100], Loss: 0.2512, Validation Loss: 0.4187
	--> Epoch [79/100], Loss: 0.2314, Validation Loss: 0.4178
	--> Epoch [80/100], Loss: 0.2280, Validation Loss: 0.4158
	--> Epoch [81/100], Loss: 0.2304, Validation Loss: 0.4141
	--> Epoch [82/100], Loss: 0.2973, Validation Loss: 0.4130
	--> Epoch [83/100], Loss: 0.2259, Validation Loss: 0.4113
	--> Epoch [84/100], Loss: 0.2205, Validation Loss: 0.4091
	--> Epoch [85/100], Loss: 0.2091, Validation Loss: 0.4086
	--> Epoch [86/100], Loss: 0.2249, Validation Loss: 0.4063
	--> Epoch [87/100], Loss: 0.2389, Validation Loss: 0.4049
	--> Epoch [88/100], Loss: 0.1998, Validation Loss: 0.4050
	--> Epoch [89/100], Loss: 0.2102, Validation Loss: 0.4024
	--> Epoch [90/100], Loss: 0.1903, Validation Loss: 0.4006
	--> Epoch [91/100], Loss: 0.1810, Validation Loss: 0.3999
	--> Epoch [92/100], Loss: 0.1955, Validation Loss: 0.3966
	--> Epoch [93/100], Loss: 0.2176, Validation Loss: 0.3946
	--> Epoch [94/100], Loss: 0.1958, Validation Loss: 0.3931
	--> Epoch [95/100], Loss: 0.1987, Validation Loss: 0.3926
	--> Epoch [96/100], Loss: 0.1827, Validation Loss: 0.3910
	--> Epoch [97/100], Loss: 0.2033, Validation Loss: 0.3912
	--> Epoch [98/100], Loss: 0.2196, Validation Loss: 0.3887
	--> Epoch [99/100], Loss: 0.1994, Validation Loss: 0.3888
	--> Epoch [100/100], Loss: 0.1922, Validation Loss: 0.3877
	--> Training for Fold 3 took 0.4779233932495117 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7423, Validation Loss: 0.6506
	--> Epoch [2/100], Loss: 0.6869, Validation Loss: 0.6391
	--> Epoch [3/100], Loss: 0.6637, Validation Loss: 0.6242
	--> Epoch [4/100], Loss: 0.6639, Validation Loss: 0.6130
	--> Epoch [5/100], Loss: 0.6788, Validation Loss: 0.6070
	--> Epoch [6/100], Loss: 0.6388, Validation Loss: 0.5971
	--> Epoch [7/100], Loss: 0.6320, Validation Loss: 0.5860
	--> Epoch [8/100], Loss: 0.6266, Validation Loss: 0.5785
	--> Epoch [9/100], Loss: 0.5849, Validation Loss: 0.5715
	--> Epoch [10/100], Loss: 0.5976, Validation Loss: 0.5646
	--> Epoch [11/100], Loss: 0.5753, Validation Loss: 0.5599
	--> Epoch [12/100], Loss: 0.5874, Validation Loss: 0.5566
	--> Epoch [13/100], Loss: 0.5484, Validation Loss: 0.5516
	--> Epoch [14/100], Loss: 0.5494, Validation Loss: 0.5450
	--> Epoch [15/100], Loss: 0.5587, Validation Loss: 0.5385
	--> Epoch [16/100], Loss: 0.5283, Validation Loss: 0.5324
	--> Epoch [17/100], Loss: 0.5208, Validation Loss: 0.5260
	--> Epoch [18/100], Loss: 0.4824, Validation Loss: 0.5206
	--> Epoch [19/100], Loss: 0.4814, Validation Loss: 0.5132
	--> Epoch [20/100], Loss: 0.4790, Validation Loss: 0.5076
	--> Epoch [21/100], Loss: 0.4425, Validation Loss: 0.5038
	--> Epoch [22/100], Loss: 0.4638, Validation Loss: 0.4984
	--> Epoch [23/100], Loss: 0.4529, Validation Loss: 0.4920
	--> Epoch [24/100], Loss: 0.4582, Validation Loss: 0.4859
	--> Epoch [25/100], Loss: 0.4427, Validation Loss: 0.4795
	--> Epoch [26/100], Loss: 0.4342, Validation Loss: 0.4741
	--> Epoch [27/100], Loss: 0.4383, Validation Loss: 0.4687
	--> Epoch [28/100], Loss: 0.4402, Validation Loss: 0.4652
	--> Epoch [29/100], Loss: 0.4408, Validation Loss: 0.4612
	--> Epoch [30/100], Loss: 0.4219, Validation Loss: 0.4566
	--> Epoch [31/100], Loss: 0.3795, Validation Loss: 0.4509
	--> Epoch [32/100], Loss: 0.4123, Validation Loss: 0.4469
	--> Epoch [33/100], Loss: 0.3885, Validation Loss: 0.4427
	--> Epoch [34/100], Loss: 0.3861, Validation Loss: 0.4397
	--> Epoch [35/100], Loss: 0.3808, Validation Loss: 0.4366
	--> Epoch [36/100], Loss: 0.3621, Validation Loss: 0.4344
	--> Epoch [37/100], Loss: 0.3696, Validation Loss: 0.4309
	--> Epoch [38/100], Loss: 0.3578, Validation Loss: 0.4263
	--> Epoch [39/100], Loss: 0.3498, Validation Loss: 0.4219
	--> Epoch [40/100], Loss: 0.3670, Validation Loss: 0.4186
	--> Epoch [41/100], Loss: 0.3299, Validation Loss: 0.4143
	--> Epoch [42/100], Loss: 0.2983, Validation Loss: 0.4110
	--> Epoch [43/100], Loss: 0.3251, Validation Loss: 0.4089
	--> Epoch [44/100], Loss: 0.3122, Validation Loss: 0.4061
	--> Epoch [45/100], Loss: 0.3325, Validation Loss: 0.4049
	--> Epoch [46/100], Loss: 0.3170, Validation Loss: 0.4008
	--> Epoch [47/100], Loss: 0.3331, Validation Loss: 0.3985
	--> Epoch [48/100], Loss: 0.3215, Validation Loss: 0.3951
	--> Epoch [49/100], Loss: 0.2994, Validation Loss: 0.3913
	--> Epoch [50/100], Loss: 0.2762, Validation Loss: 0.3873
	--> Epoch [51/100], Loss: 0.3456, Validation Loss: 0.3844
	--> Epoch [52/100], Loss: 0.2940, Validation Loss: 0.3829
	--> Epoch [53/100], Loss: 0.2873, Validation Loss: 0.3825
	--> Epoch [54/100], Loss: 0.2662, Validation Loss: 0.3806
	--> Epoch [55/100], Loss: 0.2745, Validation Loss: 0.3785
	--> Epoch [56/100], Loss: 0.3081, Validation Loss: 0.3775
	--> Epoch [57/100], Loss: 0.2506, Validation Loss: 0.3736
	--> Epoch [58/100], Loss: 0.2561, Validation Loss: 0.3732
	--> Epoch [59/100], Loss: 0.2563, Validation Loss: 0.3717
	--> Epoch [60/100], Loss: 0.2664, Validation Loss: 0.3705
	--> Epoch [61/100], Loss: 0.2287, Validation Loss: 0.3674
	--> Epoch [62/100], Loss: 0.2638, Validation Loss: 0.3658
	--> Epoch [63/100], Loss: 0.2440, Validation Loss: 0.3640
	--> Epoch [64/100], Loss: 0.2263, Validation Loss: 0.3621
	--> Epoch [65/100], Loss: 0.2752, Validation Loss: 0.3602
	--> Epoch [66/100], Loss: 0.2900, Validation Loss: 0.3601
	--> Epoch [67/100], Loss: 0.2478, Validation Loss: 0.3582
	--> Epoch [68/100], Loss: 0.2860, Validation Loss: 0.3566
	--> Epoch [69/100], Loss: 0.2006, Validation Loss: 0.3577
	--> Epoch [70/100], Loss: 0.2056, Validation Loss: 0.3549
	--> Epoch [71/100], Loss: 0.2724, Validation Loss: 0.3526
	--> Epoch [72/100], Loss: 0.2231, Validation Loss: 0.3517
	--> Epoch [73/100], Loss: 0.2237, Validation Loss: 0.3502
	--> Epoch [74/100], Loss: 0.2158, Validation Loss: 0.3489
	--> Epoch [75/100], Loss: 0.1915, Validation Loss: 0.3476
	--> Epoch [76/100], Loss: 0.2210, Validation Loss: 0.3476
	--> Epoch [77/100], Loss: 0.2422, Validation Loss: 0.3471
	--> Epoch [78/100], Loss: 0.1852, Validation Loss: 0.3458
	--> Epoch [79/100], Loss: 0.1997, Validation Loss: 0.3434
	--> Epoch [80/100], Loss: 0.2291, Validation Loss: 0.3423
	--> Epoch [81/100], Loss: 0.1974, Validation Loss: 0.3419
	--> Epoch [82/100], Loss: 0.2097, Validation Loss: 0.3403
	--> Epoch [83/100], Loss: 0.2364, Validation Loss: 0.3392
	--> Epoch [84/100], Loss: 0.1808, Validation Loss: 0.3396
	--> Epoch [85/100], Loss: 0.2660, Validation Loss: 0.3397
	--> Epoch [86/100], Loss: 0.1900, Validation Loss: 0.3387
	--> Epoch [87/100], Loss: 0.1563, Validation Loss: 0.3375
	--> Epoch [88/100], Loss: 0.1754, Validation Loss: 0.3370
	--> Epoch [89/100], Loss: 0.1907, Validation Loss: 0.3374
	--> Epoch [90/100], Loss: 0.1960, Validation Loss: 0.3364
	--> Epoch [91/100], Loss: 0.1626, Validation Loss: 0.3359
	--> Epoch [92/100], Loss: 0.1647, Validation Loss: 0.3345
	--> Epoch [93/100], Loss: 0.1761, Validation Loss: 0.3325
	--> Epoch [94/100], Loss: 0.2682, Validation Loss: 0.3326
	--> Epoch [95/100], Loss: 0.2098, Validation Loss: 0.3325
	--> Epoch [96/100], Loss: 0.2124, Validation Loss: 0.3312
	--> Epoch [97/100], Loss: 0.1670, Validation Loss: 0.3300
	--> Epoch [98/100], Loss: 0.2034, Validation Loss: 0.3307
	--> Epoch [99/100], Loss: 0.1675, Validation Loss: 0.3295
	--> Epoch [100/100], Loss: 0.1864, Validation Loss: 0.3295
	--> Training for Fold 4 took 0.4874749183654785 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6586, Validation Loss: 0.7156
	--> Epoch [2/100], Loss: 0.7043, Validation Loss: 0.7136
	--> Epoch [3/100], Loss: 0.6568, Validation Loss: 0.7087
	--> Epoch [4/100], Loss: 0.6580, Validation Loss: 0.7024
	--> Epoch [5/100], Loss: 0.6551, Validation Loss: 0.6988
	--> Epoch [6/100], Loss: 0.6036, Validation Loss: 0.6925
	--> Epoch [7/100], Loss: 0.6004, Validation Loss: 0.6886
	--> Epoch [8/100], Loss: 0.5883, Validation Loss: 0.6839
	--> Epoch [9/100], Loss: 0.5976, Validation Loss: 0.6802
	--> Epoch [10/100], Loss: 0.5697, Validation Loss: 0.6761
	--> Epoch [11/100], Loss: 0.5484, Validation Loss: 0.6729
	--> Epoch [12/100], Loss: 0.5297, Validation Loss: 0.6697
	--> Epoch [13/100], Loss: 0.5689, Validation Loss: 0.6663
	--> Epoch [14/100], Loss: 0.5263, Validation Loss: 0.6648
	--> Epoch [15/100], Loss: 0.5143, Validation Loss: 0.6637
	--> Epoch [16/100], Loss: 0.5251, Validation Loss: 0.6628
	--> Epoch [17/100], Loss: 0.4829, Validation Loss: 0.6608
	--> Epoch [18/100], Loss: 0.4816, Validation Loss: 0.6597
	--> Epoch [19/100], Loss: 0.4932, Validation Loss: 0.6577
	--> Epoch [20/100], Loss: 0.4430, Validation Loss: 0.6535
	--> Epoch [21/100], Loss: 0.4530, Validation Loss: 0.6524
	--> Epoch [22/100], Loss: 0.4850, Validation Loss: 0.6496
	--> Epoch [23/100], Loss: 0.4589, Validation Loss: 0.6479
	--> Epoch [24/100], Loss: 0.4861, Validation Loss: 0.6476
	--> Epoch [25/100], Loss: 0.4401, Validation Loss: 0.6439
	--> Epoch [26/100], Loss: 0.4299, Validation Loss: 0.6401
	--> Epoch [27/100], Loss: 0.4293, Validation Loss: 0.6383
	--> Epoch [28/100], Loss: 0.4192, Validation Loss: 0.6368
	--> Epoch [29/100], Loss: 0.4359, Validation Loss: 0.6344
	--> Epoch [30/100], Loss: 0.3935, Validation Loss: 0.6319
	--> Epoch [31/100], Loss: 0.4180, Validation Loss: 0.6275
	--> Epoch [32/100], Loss: 0.3775, Validation Loss: 0.6252
	--> Epoch [33/100], Loss: 0.3643, Validation Loss: 0.6242
	--> Epoch [34/100], Loss: 0.3880, Validation Loss: 0.6204
	--> Epoch [35/100], Loss: 0.3812, Validation Loss: 0.6161
	--> Epoch [36/100], Loss: 0.3503, Validation Loss: 0.6153
	--> Epoch [37/100], Loss: 0.3432, Validation Loss: 0.6141
	--> Epoch [38/100], Loss: 0.3328, Validation Loss: 0.6130
	--> Epoch [39/100], Loss: 0.3264, Validation Loss: 0.6111
	--> Epoch [40/100], Loss: 0.3378, Validation Loss: 0.6096
	--> Epoch [41/100], Loss: 0.3458, Validation Loss: 0.6075
	--> Epoch [42/100], Loss: 0.3175, Validation Loss: 0.6068
	--> Epoch [43/100], Loss: 0.3513, Validation Loss: 0.6051
	--> Epoch [44/100], Loss: 0.3006, Validation Loss: 0.6024
	--> Epoch [45/100], Loss: 0.3274, Validation Loss: 0.6010
	--> Epoch [46/100], Loss: 0.3198, Validation Loss: 0.5993
	--> Epoch [47/100], Loss: 0.3279, Validation Loss: 0.6006
	--> Epoch [48/100], Loss: 0.2896, Validation Loss: 0.5979
	--> Epoch [49/100], Loss: 0.2911, Validation Loss: 0.5966
	--> Epoch [50/100], Loss: 0.2889, Validation Loss: 0.5954
	--> Epoch [51/100], Loss: 0.2801, Validation Loss: 0.5947
	--> Epoch [52/100], Loss: 0.2810, Validation Loss: 0.5938
	--> Epoch [53/100], Loss: 0.2555, Validation Loss: 0.5917
	--> Epoch [54/100], Loss: 0.2532, Validation Loss: 0.5897
	--> Epoch [55/100], Loss: 0.2907, Validation Loss: 0.5906
	--> Epoch [56/100], Loss: 0.2809, Validation Loss: 0.5904
	--> Epoch [57/100], Loss: 0.2795, Validation Loss: 0.5884
	--> Epoch [58/100], Loss: 0.2838, Validation Loss: 0.5875
	--> Epoch [59/100], Loss: 0.2570, Validation Loss: 0.5868
	--> Epoch [60/100], Loss: 0.2583, Validation Loss: 0.5859
	--> Epoch [61/100], Loss: 0.2510, Validation Loss: 0.5863
	--> Epoch [62/100], Loss: 0.2809, Validation Loss: 0.5852
	--> Epoch [63/100], Loss: 0.2302, Validation Loss: 0.5830
	--> Epoch [64/100], Loss: 0.2786, Validation Loss: 0.5841
	--> Epoch [65/100], Loss: 0.2638, Validation Loss: 0.5812
	--> Epoch [66/100], Loss: 0.1993, Validation Loss: 0.5820
	--> Epoch [67/100], Loss: 0.2560, Validation Loss: 0.5809
	--> Epoch [68/100], Loss: 0.2176, Validation Loss: 0.5820
	--> Epoch [69/100], Loss: 0.2199, Validation Loss: 0.5799
	--> Epoch [70/100], Loss: 0.2142, Validation Loss: 0.5803
	--> Epoch [71/100], Loss: 0.2323, Validation Loss: 0.5821
	--> Epoch [72/100], Loss: 0.2682, Validation Loss: 0.5833
Early stopping
	--> Training for Fold 5 took 0.34565234184265137 sec, using 72 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7023
	--> Final training Epoch [2/100], Loss: 0.6683
	--> Final training Epoch [3/100], Loss: 0.6804
	--> Final training Epoch [4/100], Loss: 0.6540
	--> Final training Epoch [5/100], Loss: 0.6394
	--> Final training Epoch [6/100], Loss: 0.5838
	--> Final training Epoch [7/100], Loss: 0.5806
	--> Final training Epoch [8/100], Loss: 0.5783
	--> Final training Epoch [9/100], Loss: 0.5531
	--> Final training Epoch [10/100], Loss: 0.5605
	--> Final training Epoch [11/100], Loss: 0.5286
	--> Final training Epoch [12/100], Loss: 0.5078
	--> Final training Epoch [13/100], Loss: 0.5002
	--> Final training Epoch [14/100], Loss: 0.5219
	--> Final training Epoch [15/100], Loss: 0.5068
	--> Final training Epoch [16/100], Loss: 0.5127
	--> Final training Epoch [17/100], Loss: 0.4954
	--> Final training Epoch [18/100], Loss: 0.4801
	--> Final training Epoch [19/100], Loss: 0.5179
	--> Final training Epoch [20/100], Loss: 0.4418
	--> Final training Epoch [21/100], Loss: 0.4289
	--> Final training Epoch [22/100], Loss: 0.4535
	--> Final training Epoch [23/100], Loss: 0.4600
	--> Final training Epoch [24/100], Loss: 0.4418
	--> Final training Epoch [25/100], Loss: 0.4312
	--> Final training Epoch [26/100], Loss: 0.4174
	--> Final training Epoch [27/100], Loss: 0.4490
	--> Final training Epoch [28/100], Loss: 0.4414
	--> Final training Epoch [29/100], Loss: 0.4070
	--> Final training Epoch [30/100], Loss: 0.3741
	--> Final training Epoch [31/100], Loss: 0.3905
	--> Final training Epoch [32/100], Loss: 0.3752
	--> Final training Epoch [33/100], Loss: 0.3620
	--> Final training Epoch [34/100], Loss: 0.3443
	--> Final training Epoch [35/100], Loss: 0.3836
	--> Final training Epoch [36/100], Loss: 0.3496
	--> Final training Epoch [37/100], Loss: 0.3666
	--> Final training Epoch [38/100], Loss: 0.3255
	--> Final training Epoch [39/100], Loss: 0.3532
	--> Final training Epoch [40/100], Loss: 0.3019
	--> Final training Epoch [41/100], Loss: 0.3344
	--> Final training Epoch [42/100], Loss: 0.3514
	--> Final training Epoch [43/100], Loss: 0.3098
	--> Final training Epoch [44/100], Loss: 0.3346
	--> Final training Epoch [45/100], Loss: 0.3068
	--> Final training Epoch [46/100], Loss: 0.3172
	--> Final training Epoch [47/100], Loss: 0.2869
	--> Final training Epoch [48/100], Loss: 0.2913
	--> Final training Epoch [49/100], Loss: 0.3042
	--> Final training Epoch [50/100], Loss: 0.3045
	--> Final training Epoch [51/100], Loss: 0.2591
	--> Final training Epoch [52/100], Loss: 0.3521
	--> Final training Epoch [53/100], Loss: 0.3049
	--> Final training Epoch [54/100], Loss: 0.2969
	--> Final training Epoch [55/100], Loss: 0.2712
	--> Final training Epoch [56/100], Loss: 0.2920
	--> Final training Epoch [57/100], Loss: 0.2814
	--> Final training Epoch [58/100], Loss: 0.2721
	--> Final training Epoch [59/100], Loss: 0.2436
	--> Final training Epoch [60/100], Loss: 0.2469
	--> Final training Epoch [61/100], Loss: 0.3013
	--> Final training Epoch [62/100], Loss: 0.2763
	--> Final training Epoch [63/100], Loss: 0.2497
	--> Final training Epoch [64/100], Loss: 0.2658
	--> Final training Epoch [65/100], Loss: 0.2380
	--> Final training Epoch [66/100], Loss: 0.2466
	--> Final training Epoch [67/100], Loss: 0.2611
	--> Final training Epoch [68/100], Loss: 0.2458
	--> Final training Epoch [69/100], Loss: 0.2289
	--> Final training Epoch [70/100], Loss: 0.2244
	--> Final training Epoch [71/100], Loss: 0.2059
	--> Final training Epoch [72/100], Loss: 0.2332
	--> Final training Epoch [73/100], Loss: 0.2287
	--> Final training Epoch [74/100], Loss: 0.2081
	--> Final training Epoch [75/100], Loss: 0.2364
	--> Final training Epoch [76/100], Loss: 0.2042
	--> Final training Epoch [77/100], Loss: 0.2075
	--> Final training Epoch [78/100], Loss: 0.1923
	--> Final training Epoch [79/100], Loss: 0.2228
	--> Final training Epoch [80/100], Loss: 0.1926
	--> Final training Epoch [81/100], Loss: 0.2324
	--> Final training Epoch [82/100], Loss: 0.2042
	--> Final training Epoch [83/100], Loss: 0.2295
	--> Final training Epoch [84/100], Loss: 0.1964
	--> Final training Epoch [85/100], Loss: 0.2124
	--> Final training Epoch [86/100], Loss: 0.1860
	--> Final training Epoch [87/100], Loss: 0.1736
	--> Final training Epoch [88/100], Loss: 0.1801
	--> Final training Epoch [89/100], Loss: 0.1997
	--> Final training Epoch [90/100], Loss: 0.2007
	--> Final training Epoch [91/100], Loss: 0.1879
	--> Final training Epoch [92/100], Loss: 0.1979
	--> Final training Epoch [93/100], Loss: 0.1720
	--> Final training Epoch [94/100], Loss: 0.2084
	--> Final training Epoch [95/100], Loss: 0.1636
	--> Final training Epoch [96/100], Loss: 0.2181
	--> Final training Epoch [97/100], Loss: 0.2015
	--> Final training Epoch [98/100], Loss: 0.1946
	--> Final training Epoch [99/100], Loss: 0.1792
	--> Final training Epoch [100/100], Loss: 0.1582

Final training took 0.4398689270019531 sec

TESTING
	--> Testing took 0.0156 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.7083
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8497, Validation Loss: 0.3348,  Current Best Accuracy: 0.8497,  Current Best Validation Loss: 0.3348

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7069, Validation Loss: 0.6612
	--> Epoch [2/100], Loss: 0.6522, Validation Loss: 0.6461
	--> Epoch [3/100], Loss: 0.6471, Validation Loss: 0.6330
	--> Epoch [4/100], Loss: 0.5960, Validation Loss: 0.6190
	--> Epoch [5/100], Loss: 0.6241, Validation Loss: 0.6070
	--> Epoch [6/100], Loss: 0.6127, Validation Loss: 0.5980
	--> Epoch [7/100], Loss: 0.5923, Validation Loss: 0.5880
	--> Epoch [8/100], Loss: 0.5851, Validation Loss: 0.5805
	--> Epoch [9/100], Loss: 0.5685, Validation Loss: 0.5726
	--> Epoch [10/100], Loss: 0.5721, Validation Loss: 0.5659
	--> Epoch [11/100], Loss: 0.5483, Validation Loss: 0.5604
	--> Epoch [12/100], Loss: 0.5562, Validation Loss: 0.5562
	--> Epoch [13/100], Loss: 0.5338, Validation Loss: 0.5471
	--> Epoch [14/100], Loss: 0.5388, Validation Loss: 0.5426
	--> Epoch [15/100], Loss: 0.5149, Validation Loss: 0.5353
	--> Epoch [16/100], Loss: 0.5029, Validation Loss: 0.5265
	--> Epoch [17/100], Loss: 0.5246, Validation Loss: 0.5192
	--> Epoch [18/100], Loss: 0.5263, Validation Loss: 0.5123
	--> Epoch [19/100], Loss: 0.4945, Validation Loss: 0.5059
	--> Epoch [20/100], Loss: 0.4625, Validation Loss: 0.4990
	--> Epoch [21/100], Loss: 0.4748, Validation Loss: 0.4942
	--> Epoch [22/100], Loss: 0.4943, Validation Loss: 0.4906
	--> Epoch [23/100], Loss: 0.4634, Validation Loss: 0.4828
	--> Epoch [24/100], Loss: 0.4044, Validation Loss: 0.4774
	--> Epoch [25/100], Loss: 0.4592, Validation Loss: 0.4705
	--> Epoch [26/100], Loss: 0.4488, Validation Loss: 0.4645
	--> Epoch [27/100], Loss: 0.4356, Validation Loss: 0.4599
	--> Epoch [28/100], Loss: 0.4375, Validation Loss: 0.4540
	--> Epoch [29/100], Loss: 0.4177, Validation Loss: 0.4508
	--> Epoch [30/100], Loss: 0.4143, Validation Loss: 0.4467
	--> Epoch [31/100], Loss: 0.3750, Validation Loss: 0.4417
	--> Epoch [32/100], Loss: 0.3922, Validation Loss: 0.4360
	--> Epoch [33/100], Loss: 0.3724, Validation Loss: 0.4307
	--> Epoch [34/100], Loss: 0.3730, Validation Loss: 0.4250
	--> Epoch [35/100], Loss: 0.4375, Validation Loss: 0.4218
	--> Epoch [36/100], Loss: 0.3496, Validation Loss: 0.4188
	--> Epoch [37/100], Loss: 0.3969, Validation Loss: 0.4149
	--> Epoch [38/100], Loss: 0.4060, Validation Loss: 0.4088
	--> Epoch [39/100], Loss: 0.3674, Validation Loss: 0.4061
	--> Epoch [40/100], Loss: 0.3868, Validation Loss: 0.4023
	--> Epoch [41/100], Loss: 0.3495, Validation Loss: 0.3968
	--> Epoch [42/100], Loss: 0.3669, Validation Loss: 0.3925
	--> Epoch [43/100], Loss: 0.3701, Validation Loss: 0.3884
	--> Epoch [44/100], Loss: 0.3122, Validation Loss: 0.3867
	--> Epoch [45/100], Loss: 0.3575, Validation Loss: 0.3841
	--> Epoch [46/100], Loss: 0.3269, Validation Loss: 0.3780
	--> Epoch [47/100], Loss: 0.3333, Validation Loss: 0.3734
	--> Epoch [48/100], Loss: 0.3441, Validation Loss: 0.3712
	--> Epoch [49/100], Loss: 0.2920, Validation Loss: 0.3660
	--> Epoch [50/100], Loss: 0.2861, Validation Loss: 0.3645
	--> Epoch [51/100], Loss: 0.3365, Validation Loss: 0.3605
	--> Epoch [52/100], Loss: 0.3310, Validation Loss: 0.3577
	--> Epoch [53/100], Loss: 0.2672, Validation Loss: 0.3548
	--> Epoch [54/100], Loss: 0.3022, Validation Loss: 0.3496
	--> Epoch [55/100], Loss: 0.3035, Validation Loss: 0.3489
	--> Epoch [56/100], Loss: 0.2623, Validation Loss: 0.3438
	--> Epoch [57/100], Loss: 0.2863, Validation Loss: 0.3403
	--> Epoch [58/100], Loss: 0.2799, Validation Loss: 0.3368
	--> Epoch [59/100], Loss: 0.3089, Validation Loss: 0.3345
	--> Epoch [60/100], Loss: 0.2741, Validation Loss: 0.3330
	--> Epoch [61/100], Loss: 0.2413, Validation Loss: 0.3300
	--> Epoch [62/100], Loss: 0.2585, Validation Loss: 0.3273
	--> Epoch [63/100], Loss: 0.2492, Validation Loss: 0.3243
	--> Epoch [64/100], Loss: 0.2971, Validation Loss: 0.3229
	--> Epoch [65/100], Loss: 0.2600, Validation Loss: 0.3199
	--> Epoch [66/100], Loss: 0.2488, Validation Loss: 0.3183
	--> Epoch [67/100], Loss: 0.2562, Validation Loss: 0.3174
	--> Epoch [68/100], Loss: 0.2540, Validation Loss: 0.3147
	--> Epoch [69/100], Loss: 0.2473, Validation Loss: 0.3141
	--> Epoch [70/100], Loss: 0.2542, Validation Loss: 0.3111
	--> Epoch [71/100], Loss: 0.2442, Validation Loss: 0.3092
	--> Epoch [72/100], Loss: 0.2220, Validation Loss: 0.3064
	--> Epoch [73/100], Loss: 0.2466, Validation Loss: 0.3039
	--> Epoch [74/100], Loss: 0.2736, Validation Loss: 0.3016
	--> Epoch [75/100], Loss: 0.2320, Validation Loss: 0.2999
	--> Epoch [76/100], Loss: 0.2591, Validation Loss: 0.3003
	--> Epoch [77/100], Loss: 0.2119, Validation Loss: 0.2979
	--> Epoch [78/100], Loss: 0.2723, Validation Loss: 0.2975
	--> Epoch [79/100], Loss: 0.2169, Validation Loss: 0.2976
	--> Epoch [80/100], Loss: 0.2075, Validation Loss: 0.2953
	--> Epoch [81/100], Loss: 0.2213, Validation Loss: 0.2922
	--> Epoch [82/100], Loss: 0.2165, Validation Loss: 0.2912
	--> Epoch [83/100], Loss: 0.2166, Validation Loss: 0.2902
	--> Epoch [84/100], Loss: 0.2044, Validation Loss: 0.2883
	--> Epoch [85/100], Loss: 0.2112, Validation Loss: 0.2867
	--> Epoch [86/100], Loss: 0.1936, Validation Loss: 0.2853
	--> Epoch [87/100], Loss: 0.1713, Validation Loss: 0.2838
	--> Epoch [88/100], Loss: 0.2082, Validation Loss: 0.2833
	--> Epoch [89/100], Loss: 0.2439, Validation Loss: 0.2821
	--> Epoch [90/100], Loss: 0.1971, Validation Loss: 0.2796
	--> Epoch [91/100], Loss: 0.1988, Validation Loss: 0.2794
	--> Epoch [92/100], Loss: 0.2082, Validation Loss: 0.2795
	--> Epoch [93/100], Loss: 0.1915, Validation Loss: 0.2769
	--> Epoch [94/100], Loss: 0.1580, Validation Loss: 0.2740
	--> Epoch [95/100], Loss: 0.2342, Validation Loss: 0.2736
	--> Epoch [96/100], Loss: 0.2147, Validation Loss: 0.2736
	--> Epoch [97/100], Loss: 0.1668, Validation Loss: 0.2718
	--> Epoch [98/100], Loss: 0.2036, Validation Loss: 0.2711
	--> Epoch [99/100], Loss: 0.1793, Validation Loss: 0.2718
	--> Epoch [100/100], Loss: 0.1767, Validation Loss: 0.2705
	--> Training for Fold 1 took 0.5035345554351807 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7168, Validation Loss: 0.7183
	--> Epoch [2/100], Loss: 0.6898, Validation Loss: 0.7023
	--> Epoch [3/100], Loss: 0.6805, Validation Loss: 0.6876
	--> Epoch [4/100], Loss: 0.6811, Validation Loss: 0.6731
	--> Epoch [5/100], Loss: 0.6613, Validation Loss: 0.6607
	--> Epoch [6/100], Loss: 0.6630, Validation Loss: 0.6466
	--> Epoch [7/100], Loss: 0.6516, Validation Loss: 0.6361
	--> Epoch [8/100], Loss: 0.6080, Validation Loss: 0.6251
	--> Epoch [9/100], Loss: 0.6349, Validation Loss: 0.6161
	--> Epoch [10/100], Loss: 0.6125, Validation Loss: 0.6064
	--> Epoch [11/100], Loss: 0.5998, Validation Loss: 0.5943
	--> Epoch [12/100], Loss: 0.6039, Validation Loss: 0.5851
	--> Epoch [13/100], Loss: 0.5745, Validation Loss: 0.5772
	--> Epoch [14/100], Loss: 0.5786, Validation Loss: 0.5694
	--> Epoch [15/100], Loss: 0.5415, Validation Loss: 0.5579
	--> Epoch [16/100], Loss: 0.5484, Validation Loss: 0.5496
	--> Epoch [17/100], Loss: 0.5209, Validation Loss: 0.5384
	--> Epoch [18/100], Loss: 0.5543, Validation Loss: 0.5318
	--> Epoch [19/100], Loss: 0.5715, Validation Loss: 0.5228
	--> Epoch [20/100], Loss: 0.5016, Validation Loss: 0.5137
	--> Epoch [21/100], Loss: 0.4855, Validation Loss: 0.5048
	--> Epoch [22/100], Loss: 0.5295, Validation Loss: 0.4974
	--> Epoch [23/100], Loss: 0.4715, Validation Loss: 0.4875
	--> Epoch [24/100], Loss: 0.4772, Validation Loss: 0.4787
	--> Epoch [25/100], Loss: 0.4716, Validation Loss: 0.4703
	--> Epoch [26/100], Loss: 0.4121, Validation Loss: 0.4637
	--> Epoch [27/100], Loss: 0.4481, Validation Loss: 0.4566
	--> Epoch [28/100], Loss: 0.4274, Validation Loss: 0.4513
	--> Epoch [29/100], Loss: 0.4455, Validation Loss: 0.4433
	--> Epoch [30/100], Loss: 0.4301, Validation Loss: 0.4378
	--> Epoch [31/100], Loss: 0.3744, Validation Loss: 0.4320
	--> Epoch [32/100], Loss: 0.3718, Validation Loss: 0.4260
	--> Epoch [33/100], Loss: 0.4378, Validation Loss: 0.4191
	--> Epoch [34/100], Loss: 0.3635, Validation Loss: 0.4146
	--> Epoch [35/100], Loss: 0.4106, Validation Loss: 0.4097
	--> Epoch [36/100], Loss: 0.3474, Validation Loss: 0.4042
	--> Epoch [37/100], Loss: 0.3989, Validation Loss: 0.4001
	--> Epoch [38/100], Loss: 0.3497, Validation Loss: 0.3950
	--> Epoch [39/100], Loss: 0.3754, Validation Loss: 0.3880
	--> Epoch [40/100], Loss: 0.3475, Validation Loss: 0.3810
	--> Epoch [41/100], Loss: 0.3915, Validation Loss: 0.3782
	--> Epoch [42/100], Loss: 0.3092, Validation Loss: 0.3742
	--> Epoch [43/100], Loss: 0.3044, Validation Loss: 0.3700
	--> Epoch [44/100], Loss: 0.3411, Validation Loss: 0.3649
	--> Epoch [45/100], Loss: 0.3152, Validation Loss: 0.3619
	--> Epoch [46/100], Loss: 0.3275, Validation Loss: 0.3581
	--> Epoch [47/100], Loss: 0.3516, Validation Loss: 0.3542
	--> Epoch [48/100], Loss: 0.3350, Validation Loss: 0.3504
	--> Epoch [49/100], Loss: 0.3234, Validation Loss: 0.3475
	--> Epoch [50/100], Loss: 0.3142, Validation Loss: 0.3422
	--> Epoch [51/100], Loss: 0.3150, Validation Loss: 0.3391
	--> Epoch [52/100], Loss: 0.3034, Validation Loss: 0.3365
	--> Epoch [53/100], Loss: 0.2910, Validation Loss: 0.3328
	--> Epoch [54/100], Loss: 0.2789, Validation Loss: 0.3291
	--> Epoch [55/100], Loss: 0.3462, Validation Loss: 0.3267
	--> Epoch [56/100], Loss: 0.2921, Validation Loss: 0.3231
	--> Epoch [57/100], Loss: 0.2696, Validation Loss: 0.3177
	--> Epoch [58/100], Loss: 0.2926, Validation Loss: 0.3135
	--> Epoch [59/100], Loss: 0.2420, Validation Loss: 0.3099
	--> Epoch [60/100], Loss: 0.2629, Validation Loss: 0.3089
	--> Epoch [61/100], Loss: 0.2471, Validation Loss: 0.3077
	--> Epoch [62/100], Loss: 0.2565, Validation Loss: 0.3058
	--> Epoch [63/100], Loss: 0.2482, Validation Loss: 0.3045
	--> Epoch [64/100], Loss: 0.2528, Validation Loss: 0.3019
	--> Epoch [65/100], Loss: 0.2822, Validation Loss: 0.2995
	--> Epoch [66/100], Loss: 0.2322, Validation Loss: 0.2965
	--> Epoch [67/100], Loss: 0.2376, Validation Loss: 0.2945
	--> Epoch [68/100], Loss: 0.2362, Validation Loss: 0.2935
	--> Epoch [69/100], Loss: 0.1933, Validation Loss: 0.2921
	--> Epoch [70/100], Loss: 0.2426, Validation Loss: 0.2901
	--> Epoch [71/100], Loss: 0.1862, Validation Loss: 0.2877
	--> Epoch [72/100], Loss: 0.2190, Validation Loss: 0.2845
	--> Epoch [73/100], Loss: 0.2321, Validation Loss: 0.2819
	--> Epoch [74/100], Loss: 0.2027, Validation Loss: 0.2793
	--> Epoch [75/100], Loss: 0.2376, Validation Loss: 0.2786
	--> Epoch [76/100], Loss: 0.2276, Validation Loss: 0.2773
	--> Epoch [77/100], Loss: 0.2102, Validation Loss: 0.2749
	--> Epoch [78/100], Loss: 0.1953, Validation Loss: 0.2727
	--> Epoch [79/100], Loss: 0.2215, Validation Loss: 0.2704
	--> Epoch [80/100], Loss: 0.2255, Validation Loss: 0.2688
	--> Epoch [81/100], Loss: 0.1617, Validation Loss: 0.2683
	--> Epoch [82/100], Loss: 0.1483, Validation Loss: 0.2663
	--> Epoch [83/100], Loss: 0.2137, Validation Loss: 0.2638
	--> Epoch [84/100], Loss: 0.1605, Validation Loss: 0.2606
	--> Epoch [85/100], Loss: 0.1971, Validation Loss: 0.2588
	--> Epoch [86/100], Loss: 0.2277, Validation Loss: 0.2567
	--> Epoch [87/100], Loss: 0.2081, Validation Loss: 0.2551
	--> Epoch [88/100], Loss: 0.2047, Validation Loss: 0.2534
	--> Epoch [89/100], Loss: 0.1538, Validation Loss: 0.2513
	--> Epoch [90/100], Loss: 0.1730, Validation Loss: 0.2502
	--> Epoch [91/100], Loss: 0.2047, Validation Loss: 0.2485
	--> Epoch [92/100], Loss: 0.1776, Validation Loss: 0.2474
	--> Epoch [93/100], Loss: 0.1668, Validation Loss: 0.2457
	--> Epoch [94/100], Loss: 0.2720, Validation Loss: 0.2447
	--> Epoch [95/100], Loss: 0.1517, Validation Loss: 0.2429
	--> Epoch [96/100], Loss: 0.1945, Validation Loss: 0.2421
	--> Epoch [97/100], Loss: 0.1599, Validation Loss: 0.2398
	--> Epoch [98/100], Loss: 0.2314, Validation Loss: 0.2388
	--> Epoch [99/100], Loss: 0.1617, Validation Loss: 0.2378
	--> Epoch [100/100], Loss: 0.1496, Validation Loss: 0.2355
	--> Training for Fold 2 took 0.4875979423522949 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7300, Validation Loss: 0.6980
	--> Epoch [2/100], Loss: 0.6999, Validation Loss: 0.6902
	--> Epoch [3/100], Loss: 0.6761, Validation Loss: 0.6794
	--> Epoch [4/100], Loss: 0.6878, Validation Loss: 0.6681
	--> Epoch [5/100], Loss: 0.6719, Validation Loss: 0.6589
	--> Epoch [6/100], Loss: 0.6432, Validation Loss: 0.6520
	--> Epoch [7/100], Loss: 0.6587, Validation Loss: 0.6447
	--> Epoch [8/100], Loss: 0.6014, Validation Loss: 0.6377
	--> Epoch [9/100], Loss: 0.5982, Validation Loss: 0.6313
	--> Epoch [10/100], Loss: 0.6117, Validation Loss: 0.6274
	--> Epoch [11/100], Loss: 0.5717, Validation Loss: 0.6227
	--> Epoch [12/100], Loss: 0.5955, Validation Loss: 0.6177
	--> Epoch [13/100], Loss: 0.5466, Validation Loss: 0.6126
	--> Epoch [14/100], Loss: 0.5506, Validation Loss: 0.6075
	--> Epoch [15/100], Loss: 0.5311, Validation Loss: 0.6016
	--> Epoch [16/100], Loss: 0.5261, Validation Loss: 0.5963
	--> Epoch [17/100], Loss: 0.5183, Validation Loss: 0.5907
	--> Epoch [18/100], Loss: 0.5269, Validation Loss: 0.5854
	--> Epoch [19/100], Loss: 0.4896, Validation Loss: 0.5813
	--> Epoch [20/100], Loss: 0.5016, Validation Loss: 0.5751
	--> Epoch [21/100], Loss: 0.4829, Validation Loss: 0.5709
	--> Epoch [22/100], Loss: 0.4377, Validation Loss: 0.5674
	--> Epoch [23/100], Loss: 0.4463, Validation Loss: 0.5623
	--> Epoch [24/100], Loss: 0.4626, Validation Loss: 0.5578
	--> Epoch [25/100], Loss: 0.4444, Validation Loss: 0.5527
	--> Epoch [26/100], Loss: 0.4326, Validation Loss: 0.5477
	--> Epoch [27/100], Loss: 0.4320, Validation Loss: 0.5433
	--> Epoch [28/100], Loss: 0.4207, Validation Loss: 0.5398
	--> Epoch [29/100], Loss: 0.4289, Validation Loss: 0.5366
	--> Epoch [30/100], Loss: 0.4160, Validation Loss: 0.5341
	--> Epoch [31/100], Loss: 0.3763, Validation Loss: 0.5314
	--> Epoch [32/100], Loss: 0.4257, Validation Loss: 0.5271
	--> Epoch [33/100], Loss: 0.4072, Validation Loss: 0.5250
	--> Epoch [34/100], Loss: 0.3845, Validation Loss: 0.5210
	--> Epoch [35/100], Loss: 0.3923, Validation Loss: 0.5193
	--> Epoch [36/100], Loss: 0.3773, Validation Loss: 0.5151
	--> Epoch [37/100], Loss: 0.3612, Validation Loss: 0.5117
	--> Epoch [38/100], Loss: 0.3575, Validation Loss: 0.5074
	--> Epoch [39/100], Loss: 0.3819, Validation Loss: 0.5048
	--> Epoch [40/100], Loss: 0.3545, Validation Loss: 0.5034
	--> Epoch [41/100], Loss: 0.3321, Validation Loss: 0.4985
	--> Epoch [42/100], Loss: 0.3395, Validation Loss: 0.4952
	--> Epoch [43/100], Loss: 0.3378, Validation Loss: 0.4921
	--> Epoch [44/100], Loss: 0.3269, Validation Loss: 0.4886
	--> Epoch [45/100], Loss: 0.3223, Validation Loss: 0.4863
	--> Epoch [46/100], Loss: 0.3294, Validation Loss: 0.4840
	--> Epoch [47/100], Loss: 0.3556, Validation Loss: 0.4821
	--> Epoch [48/100], Loss: 0.3148, Validation Loss: 0.4814
	--> Epoch [49/100], Loss: 0.3175, Validation Loss: 0.4757
	--> Epoch [50/100], Loss: 0.3172, Validation Loss: 0.4731
	--> Epoch [51/100], Loss: 0.3001, Validation Loss: 0.4706
	--> Epoch [52/100], Loss: 0.3194, Validation Loss: 0.4714
	--> Epoch [53/100], Loss: 0.2942, Validation Loss: 0.4689
	--> Epoch [54/100], Loss: 0.2426, Validation Loss: 0.4649
	--> Epoch [55/100], Loss: 0.2810, Validation Loss: 0.4614
	--> Epoch [56/100], Loss: 0.2613, Validation Loss: 0.4583
	--> Epoch [57/100], Loss: 0.2388, Validation Loss: 0.4564
	--> Epoch [58/100], Loss: 0.2868, Validation Loss: 0.4547
	--> Epoch [59/100], Loss: 0.2344, Validation Loss: 0.4516
	--> Epoch [60/100], Loss: 0.2453, Validation Loss: 0.4478
	--> Epoch [61/100], Loss: 0.2473, Validation Loss: 0.4464
	--> Epoch [62/100], Loss: 0.2996, Validation Loss: 0.4472
	--> Epoch [63/100], Loss: 0.2939, Validation Loss: 0.4460
	--> Epoch [64/100], Loss: 0.2500, Validation Loss: 0.4428
	--> Epoch [65/100], Loss: 0.2536, Validation Loss: 0.4423
	--> Epoch [66/100], Loss: 0.2204, Validation Loss: 0.4400
	--> Epoch [67/100], Loss: 0.2194, Validation Loss: 0.4378
	--> Epoch [68/100], Loss: 0.2926, Validation Loss: 0.4354
	--> Epoch [69/100], Loss: 0.2379, Validation Loss: 0.4335
	--> Epoch [70/100], Loss: 0.2434, Validation Loss: 0.4314
	--> Epoch [71/100], Loss: 0.2512, Validation Loss: 0.4297
	--> Epoch [72/100], Loss: 0.2162, Validation Loss: 0.4272
	--> Epoch [73/100], Loss: 0.2079, Validation Loss: 0.4256
	--> Epoch [74/100], Loss: 0.2824, Validation Loss: 0.4255
	--> Epoch [75/100], Loss: 0.2981, Validation Loss: 0.4245
	--> Epoch [76/100], Loss: 0.2407, Validation Loss: 0.4222
	--> Epoch [77/100], Loss: 0.2269, Validation Loss: 0.4214
	--> Epoch [78/100], Loss: 0.2082, Validation Loss: 0.4202
	--> Epoch [79/100], Loss: 0.2153, Validation Loss: 0.4189
	--> Epoch [80/100], Loss: 0.2341, Validation Loss: 0.4179
	--> Epoch [81/100], Loss: 0.2404, Validation Loss: 0.4170
	--> Epoch [82/100], Loss: 0.1718, Validation Loss: 0.4158
	--> Epoch [83/100], Loss: 0.2209, Validation Loss: 0.4146
	--> Epoch [84/100], Loss: 0.1931, Validation Loss: 0.4136
	--> Epoch [85/100], Loss: 0.2003, Validation Loss: 0.4137
	--> Epoch [86/100], Loss: 0.2305, Validation Loss: 0.4129
	--> Epoch [87/100], Loss: 0.1803, Validation Loss: 0.4111
	--> Epoch [88/100], Loss: 0.1937, Validation Loss: 0.4104
	--> Epoch [89/100], Loss: 0.1661, Validation Loss: 0.4097
	--> Epoch [90/100], Loss: 0.1447, Validation Loss: 0.4076
	--> Epoch [91/100], Loss: 0.2138, Validation Loss: 0.4055
	--> Epoch [92/100], Loss: 0.2368, Validation Loss: 0.4046
	--> Epoch [93/100], Loss: 0.2111, Validation Loss: 0.4048
	--> Epoch [94/100], Loss: 0.1968, Validation Loss: 0.4032
	--> Epoch [95/100], Loss: 0.1760, Validation Loss: 0.4020
	--> Epoch [96/100], Loss: 0.1730, Validation Loss: 0.4005
	--> Epoch [97/100], Loss: 0.1746, Validation Loss: 0.3994
	--> Epoch [98/100], Loss: 0.2125, Validation Loss: 0.4007
	--> Epoch [99/100], Loss: 0.1731, Validation Loss: 0.3980
	--> Epoch [100/100], Loss: 0.2171, Validation Loss: 0.3972
	--> Training for Fold 3 took 0.4908316135406494 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8332, Validation Loss: 0.6105
	--> Epoch [2/100], Loss: 0.8288, Validation Loss: 0.5957
	--> Epoch [3/100], Loss: 0.7247, Validation Loss: 0.5801
	--> Epoch [4/100], Loss: 0.6779, Validation Loss: 0.5698
	--> Epoch [5/100], Loss: 0.6634, Validation Loss: 0.5566
	--> Epoch [6/100], Loss: 0.6474, Validation Loss: 0.5445
	--> Epoch [7/100], Loss: 0.6139, Validation Loss: 0.5349
	--> Epoch [8/100], Loss: 0.6515, Validation Loss: 0.5279
	--> Epoch [9/100], Loss: 0.6039, Validation Loss: 0.5182
	--> Epoch [10/100], Loss: 0.6270, Validation Loss: 0.5112
	--> Epoch [11/100], Loss: 0.5915, Validation Loss: 0.5043
	--> Epoch [12/100], Loss: 0.5813, Validation Loss: 0.4972
	--> Epoch [13/100], Loss: 0.5694, Validation Loss: 0.4912
	--> Epoch [14/100], Loss: 0.5343, Validation Loss: 0.4866
	--> Epoch [15/100], Loss: 0.5350, Validation Loss: 0.4818
	--> Epoch [16/100], Loss: 0.4933, Validation Loss: 0.4734
	--> Epoch [17/100], Loss: 0.5379, Validation Loss: 0.4662
	--> Epoch [18/100], Loss: 0.4615, Validation Loss: 0.4612
	--> Epoch [19/100], Loss: 0.4381, Validation Loss: 0.4575
	--> Epoch [20/100], Loss: 0.4486, Validation Loss: 0.4511
	--> Epoch [21/100], Loss: 0.4904, Validation Loss: 0.4464
	--> Epoch [22/100], Loss: 0.4627, Validation Loss: 0.4431
	--> Epoch [23/100], Loss: 0.4534, Validation Loss: 0.4396
	--> Epoch [24/100], Loss: 0.4396, Validation Loss: 0.4341
	--> Epoch [25/100], Loss: 0.4621, Validation Loss: 0.4283
	--> Epoch [26/100], Loss: 0.4239, Validation Loss: 0.4226
	--> Epoch [27/100], Loss: 0.4103, Validation Loss: 0.4193
	--> Epoch [28/100], Loss: 0.4369, Validation Loss: 0.4144
	--> Epoch [29/100], Loss: 0.4117, Validation Loss: 0.4129
	--> Epoch [30/100], Loss: 0.3797, Validation Loss: 0.4089
	--> Epoch [31/100], Loss: 0.3877, Validation Loss: 0.4076
	--> Epoch [32/100], Loss: 0.3778, Validation Loss: 0.4066
	--> Epoch [33/100], Loss: 0.3719, Validation Loss: 0.4031
	--> Epoch [34/100], Loss: 0.3872, Validation Loss: 0.4004
	--> Epoch [35/100], Loss: 0.3262, Validation Loss: 0.3981
	--> Epoch [36/100], Loss: 0.4370, Validation Loss: 0.3931
	--> Epoch [37/100], Loss: 0.3991, Validation Loss: 0.3903
	--> Epoch [38/100], Loss: 0.3918, Validation Loss: 0.3894
	--> Epoch [39/100], Loss: 0.3264, Validation Loss: 0.3854
	--> Epoch [40/100], Loss: 0.3360, Validation Loss: 0.3821
	--> Epoch [41/100], Loss: 0.3699, Validation Loss: 0.3824
	--> Epoch [42/100], Loss: 0.3227, Validation Loss: 0.3808
	--> Epoch [43/100], Loss: 0.3646, Validation Loss: 0.3773
	--> Epoch [44/100], Loss: 0.3386, Validation Loss: 0.3727
	--> Epoch [45/100], Loss: 0.3037, Validation Loss: 0.3716
	--> Epoch [46/100], Loss: 0.3323, Validation Loss: 0.3680
	--> Epoch [47/100], Loss: 0.3114, Validation Loss: 0.3652
	--> Epoch [48/100], Loss: 0.3219, Validation Loss: 0.3649
	--> Epoch [49/100], Loss: 0.2990, Validation Loss: 0.3633
	--> Epoch [50/100], Loss: 0.3193, Validation Loss: 0.3622
	--> Epoch [51/100], Loss: 0.3278, Validation Loss: 0.3591
	--> Epoch [52/100], Loss: 0.3229, Validation Loss: 0.3589
	--> Epoch [53/100], Loss: 0.3450, Validation Loss: 0.3558
	--> Epoch [54/100], Loss: 0.3241, Validation Loss: 0.3545
	--> Epoch [55/100], Loss: 0.2826, Validation Loss: 0.3522
	--> Epoch [56/100], Loss: 0.2830, Validation Loss: 0.3507
	--> Epoch [57/100], Loss: 0.3119, Validation Loss: 0.3501
	--> Epoch [58/100], Loss: 0.2837, Validation Loss: 0.3477
	--> Epoch [59/100], Loss: 0.2869, Validation Loss: 0.3458
	--> Epoch [60/100], Loss: 0.2703, Validation Loss: 0.3415
	--> Epoch [61/100], Loss: 0.2548, Validation Loss: 0.3398
	--> Epoch [62/100], Loss: 0.2824, Validation Loss: 0.3399
	--> Epoch [63/100], Loss: 0.2016, Validation Loss: 0.3403
	--> Epoch [64/100], Loss: 0.2651, Validation Loss: 0.3407
Early stopping
	--> Training for Fold 4 took 0.3235206604003906 sec, using 64 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7050, Validation Loss: 0.6779
	--> Epoch [2/100], Loss: 0.6841, Validation Loss: 0.6708
	--> Epoch [3/100], Loss: 0.6635, Validation Loss: 0.6638
	--> Epoch [4/100], Loss: 0.6644, Validation Loss: 0.6593
	--> Epoch [5/100], Loss: 0.6297, Validation Loss: 0.6551
	--> Epoch [6/100], Loss: 0.6436, Validation Loss: 0.6504
	--> Epoch [7/100], Loss: 0.5932, Validation Loss: 0.6468
	--> Epoch [8/100], Loss: 0.5559, Validation Loss: 0.6429
	--> Epoch [9/100], Loss: 0.5951, Validation Loss: 0.6387
	--> Epoch [10/100], Loss: 0.5526, Validation Loss: 0.6357
	--> Epoch [11/100], Loss: 0.5214, Validation Loss: 0.6323
	--> Epoch [12/100], Loss: 0.5571, Validation Loss: 0.6304
	--> Epoch [13/100], Loss: 0.5414, Validation Loss: 0.6291
	--> Epoch [14/100], Loss: 0.5323, Validation Loss: 0.6274
	--> Epoch [15/100], Loss: 0.5160, Validation Loss: 0.6232
	--> Epoch [16/100], Loss: 0.4386, Validation Loss: 0.6210
	--> Epoch [17/100], Loss: 0.4577, Validation Loss: 0.6197
	--> Epoch [18/100], Loss: 0.4840, Validation Loss: 0.6167
	--> Epoch [19/100], Loss: 0.4636, Validation Loss: 0.6147
	--> Epoch [20/100], Loss: 0.4577, Validation Loss: 0.6147
	--> Epoch [21/100], Loss: 0.4725, Validation Loss: 0.6128
	--> Epoch [22/100], Loss: 0.4192, Validation Loss: 0.6100
	--> Epoch [23/100], Loss: 0.4105, Validation Loss: 0.6087
	--> Epoch [24/100], Loss: 0.4174, Validation Loss: 0.6053
	--> Epoch [25/100], Loss: 0.4040, Validation Loss: 0.6039
	--> Epoch [26/100], Loss: 0.4124, Validation Loss: 0.6022
	--> Epoch [27/100], Loss: 0.3816, Validation Loss: 0.6006
	--> Epoch [28/100], Loss: 0.3683, Validation Loss: 0.5988
	--> Epoch [29/100], Loss: 0.3680, Validation Loss: 0.5960
	--> Epoch [30/100], Loss: 0.3874, Validation Loss: 0.5923
	--> Epoch [31/100], Loss: 0.3602, Validation Loss: 0.5906
	--> Epoch [32/100], Loss: 0.4031, Validation Loss: 0.5893
	--> Epoch [33/100], Loss: 0.3779, Validation Loss: 0.5870
	--> Epoch [34/100], Loss: 0.3361, Validation Loss: 0.5850
	--> Epoch [35/100], Loss: 0.3441, Validation Loss: 0.5842
	--> Epoch [36/100], Loss: 0.3329, Validation Loss: 0.5827
	--> Epoch [37/100], Loss: 0.3184, Validation Loss: 0.5811
	--> Epoch [38/100], Loss: 0.3219, Validation Loss: 0.5769
	--> Epoch [39/100], Loss: 0.2941, Validation Loss: 0.5755
	--> Epoch [40/100], Loss: 0.3344, Validation Loss: 0.5731
	--> Epoch [41/100], Loss: 0.3013, Validation Loss: 0.5735
	--> Epoch [42/100], Loss: 0.3420, Validation Loss: 0.5719
	--> Epoch [43/100], Loss: 0.3061, Validation Loss: 0.5707
	--> Epoch [44/100], Loss: 0.2981, Validation Loss: 0.5694
	--> Epoch [45/100], Loss: 0.2952, Validation Loss: 0.5669
	--> Epoch [46/100], Loss: 0.2757, Validation Loss: 0.5660
	--> Epoch [47/100], Loss: 0.2513, Validation Loss: 0.5645
	--> Epoch [48/100], Loss: 0.2618, Validation Loss: 0.5628
	--> Epoch [49/100], Loss: 0.2868, Validation Loss: 0.5613
	--> Epoch [50/100], Loss: 0.2594, Validation Loss: 0.5605
	--> Epoch [51/100], Loss: 0.2681, Validation Loss: 0.5584
	--> Epoch [52/100], Loss: 0.2585, Validation Loss: 0.5560
	--> Epoch [53/100], Loss: 0.2873, Validation Loss: 0.5561
	--> Epoch [54/100], Loss: 0.2513, Validation Loss: 0.5553
	--> Epoch [55/100], Loss: 0.2042, Validation Loss: 0.5547
	--> Epoch [56/100], Loss: 0.2666, Validation Loss: 0.5531
	--> Epoch [57/100], Loss: 0.2572, Validation Loss: 0.5499
	--> Epoch [58/100], Loss: 0.2328, Validation Loss: 0.5492
	--> Epoch [59/100], Loss: 0.2452, Validation Loss: 0.5477
	--> Epoch [60/100], Loss: 0.2319, Validation Loss: 0.5463
	--> Epoch [61/100], Loss: 0.2284, Validation Loss: 0.5426
	--> Epoch [62/100], Loss: 0.2331, Validation Loss: 0.5409
	--> Epoch [63/100], Loss: 0.2220, Validation Loss: 0.5408
	--> Epoch [64/100], Loss: 0.1888, Validation Loss: 0.5402
	--> Epoch [65/100], Loss: 0.2009, Validation Loss: 0.5390
	--> Epoch [66/100], Loss: 0.2378, Validation Loss: 0.5388
	--> Epoch [67/100], Loss: 0.1652, Validation Loss: 0.5368
	--> Epoch [68/100], Loss: 0.1879, Validation Loss: 0.5359
	--> Epoch [69/100], Loss: 0.1821, Validation Loss: 0.5357
	--> Epoch [70/100], Loss: 0.2147, Validation Loss: 0.5344
	--> Epoch [71/100], Loss: 0.2063, Validation Loss: 0.5356
	--> Epoch [72/100], Loss: 0.1963, Validation Loss: 0.5339
	--> Epoch [73/100], Loss: 0.2249, Validation Loss: 0.5338
	--> Epoch [74/100], Loss: 0.2033, Validation Loss: 0.5315
	--> Epoch [75/100], Loss: 0.1970, Validation Loss: 0.5331
	--> Epoch [76/100], Loss: 0.1730, Validation Loss: 0.5344
	--> Epoch [77/100], Loss: 0.1918, Validation Loss: 0.5332
Early stopping
	--> Training for Fold 5 took 0.385894775390625 sec, using 77 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7191
	--> Final training Epoch [2/100], Loss: 0.6779
	--> Final training Epoch [3/100], Loss: 0.6401
	--> Final training Epoch [4/100], Loss: 0.6613
	--> Final training Epoch [5/100], Loss: 0.6405
	--> Final training Epoch [6/100], Loss: 0.6215
	--> Final training Epoch [7/100], Loss: 0.5971
	--> Final training Epoch [8/100], Loss: 0.5835
	--> Final training Epoch [9/100], Loss: 0.5610
	--> Final training Epoch [10/100], Loss: 0.5557
	--> Final training Epoch [11/100], Loss: 0.5736
	--> Final training Epoch [12/100], Loss: 0.5691
	--> Final training Epoch [13/100], Loss: 0.5828
	--> Final training Epoch [14/100], Loss: 0.5242
	--> Final training Epoch [15/100], Loss: 0.4932
	--> Final training Epoch [16/100], Loss: 0.5140
	--> Final training Epoch [17/100], Loss: 0.5271
	--> Final training Epoch [18/100], Loss: 0.5170
	--> Final training Epoch [19/100], Loss: 0.4989
	--> Final training Epoch [20/100], Loss: 0.4627
	--> Final training Epoch [21/100], Loss: 0.4532
	--> Final training Epoch [22/100], Loss: 0.4869
	--> Final training Epoch [23/100], Loss: 0.4330
	--> Final training Epoch [24/100], Loss: 0.4432
	--> Final training Epoch [25/100], Loss: 0.4202
	--> Final training Epoch [26/100], Loss: 0.4152
	--> Final training Epoch [27/100], Loss: 0.4142
	--> Final training Epoch [28/100], Loss: 0.4226
	--> Final training Epoch [29/100], Loss: 0.4098
	--> Final training Epoch [30/100], Loss: 0.4371
	--> Final training Epoch [31/100], Loss: 0.3944
	--> Final training Epoch [32/100], Loss: 0.3599
	--> Final training Epoch [33/100], Loss: 0.3828
	--> Final training Epoch [34/100], Loss: 0.3768
	--> Final training Epoch [35/100], Loss: 0.3697
	--> Final training Epoch [36/100], Loss: 0.3632
	--> Final training Epoch [37/100], Loss: 0.3491
	--> Final training Epoch [38/100], Loss: 0.3492
	--> Final training Epoch [39/100], Loss: 0.3454
	--> Final training Epoch [40/100], Loss: 0.3330
	--> Final training Epoch [41/100], Loss: 0.3600
	--> Final training Epoch [42/100], Loss: 0.3479
	--> Final training Epoch [43/100], Loss: 0.3304
	--> Final training Epoch [44/100], Loss: 0.3354
	--> Final training Epoch [45/100], Loss: 0.3155
	--> Final training Epoch [46/100], Loss: 0.3294
	--> Final training Epoch [47/100], Loss: 0.2950
	--> Final training Epoch [48/100], Loss: 0.2916
	--> Final training Epoch [49/100], Loss: 0.3221
	--> Final training Epoch [50/100], Loss: 0.2876
	--> Final training Epoch [51/100], Loss: 0.2898
	--> Final training Epoch [52/100], Loss: 0.2997
	--> Final training Epoch [53/100], Loss: 0.2935
	--> Final training Epoch [54/100], Loss: 0.2868
	--> Final training Epoch [55/100], Loss: 0.2635
	--> Final training Epoch [56/100], Loss: 0.2765
	--> Final training Epoch [57/100], Loss: 0.2728
	--> Final training Epoch [58/100], Loss: 0.2679
	--> Final training Epoch [59/100], Loss: 0.3043
	--> Final training Epoch [60/100], Loss: 0.2678
	--> Final training Epoch [61/100], Loss: 0.2418
	--> Final training Epoch [62/100], Loss: 0.2495
	--> Final training Epoch [63/100], Loss: 0.2594
	--> Final training Epoch [64/100], Loss: 0.2598
	--> Final training Epoch [65/100], Loss: 0.2788
	--> Final training Epoch [66/100], Loss: 0.2430
	--> Final training Epoch [67/100], Loss: 0.2271
	--> Final training Epoch [68/100], Loss: 0.2443
	--> Final training Epoch [69/100], Loss: 0.2129
	--> Final training Epoch [70/100], Loss: 0.2798
	--> Final training Epoch [71/100], Loss: 0.2374
	--> Final training Epoch [72/100], Loss: 0.2381
	--> Final training Epoch [73/100], Loss: 0.2350
	--> Final training Epoch [74/100], Loss: 0.2943
	--> Final training Epoch [75/100], Loss: 0.2405
	--> Final training Epoch [76/100], Loss: 0.2520
	--> Final training Epoch [77/100], Loss: 0.2203
	--> Final training Epoch [78/100], Loss: 0.2113
	--> Final training Epoch [79/100], Loss: 0.2366
	--> Final training Epoch [80/100], Loss: 0.2017
	--> Final training Epoch [81/100], Loss: 0.2231
	--> Final training Epoch [82/100], Loss: 0.2114
	--> Final training Epoch [83/100], Loss: 0.1971
	--> Final training Epoch [84/100], Loss: 0.1975
	--> Final training Epoch [85/100], Loss: 0.2022
	--> Final training Epoch [86/100], Loss: 0.2162
	--> Final training Epoch [87/100], Loss: 0.2030
	--> Final training Epoch [88/100], Loss: 0.2038
	--> Final training Epoch [89/100], Loss: 0.2314
	--> Final training Epoch [90/100], Loss: 0.2079
	--> Final training Epoch [91/100], Loss: 0.1879
	--> Final training Epoch [92/100], Loss: 0.1794
	--> Final training Epoch [93/100], Loss: 0.1958
	--> Final training Epoch [94/100], Loss: 0.1625
	--> Final training Epoch [95/100], Loss: 0.1613
	--> Final training Epoch [96/100], Loss: 0.1865
	--> Final training Epoch [97/100], Loss: 0.1957
	--> Final training Epoch [98/100], Loss: 0.1888
	--> Final training Epoch [99/100], Loss: 0.1690
	--> Final training Epoch [100/100], Loss: 0.1949

Final training took 0.4628174304962158 sec

TESTING
	--> Testing took 0.0139 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8424
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3487,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3487
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3664,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3487
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7947, Validation Loss: 0.4214,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3487
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.4328,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3487
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.4072,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3487
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.3636,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3487

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6509, Validation Loss: 0.7164
	--> Epoch [2/100], Loss: 0.6598, Validation Loss: 0.7046
	--> Epoch [3/100], Loss: 0.6450, Validation Loss: 0.6969
	--> Epoch [4/100], Loss: 0.6017, Validation Loss: 0.6907
	--> Epoch [5/100], Loss: 0.6017, Validation Loss: 0.6827
	--> Epoch [6/100], Loss: 0.5998, Validation Loss: 0.6726
	--> Epoch [7/100], Loss: 0.5866, Validation Loss: 0.6650
	--> Epoch [8/100], Loss: 0.5719, Validation Loss: 0.6536
	--> Epoch [9/100], Loss: 0.5308, Validation Loss: 0.6464
	--> Epoch [10/100], Loss: 0.5381, Validation Loss: 0.6379
	--> Epoch [11/100], Loss: 0.5569, Validation Loss: 0.6295
	--> Epoch [12/100], Loss: 0.5400, Validation Loss: 0.6189
	--> Epoch [13/100], Loss: 0.5038, Validation Loss: 0.6102
	--> Epoch [14/100], Loss: 0.5027, Validation Loss: 0.6021
	--> Epoch [15/100], Loss: 0.5080, Validation Loss: 0.5933
	--> Epoch [16/100], Loss: 0.4853, Validation Loss: 0.5845
	--> Epoch [17/100], Loss: 0.4905, Validation Loss: 0.5742
	--> Epoch [18/100], Loss: 0.4587, Validation Loss: 0.5644
	--> Epoch [19/100], Loss: 0.4689, Validation Loss: 0.5542
	--> Epoch [20/100], Loss: 0.4211, Validation Loss: 0.5472
	--> Epoch [21/100], Loss: 0.4306, Validation Loss: 0.5389
	--> Epoch [22/100], Loss: 0.4318, Validation Loss: 0.5301
	--> Epoch [23/100], Loss: 0.3950, Validation Loss: 0.5241
	--> Epoch [24/100], Loss: 0.4065, Validation Loss: 0.5157
	--> Epoch [25/100], Loss: 0.3944, Validation Loss: 0.5091
	--> Epoch [26/100], Loss: 0.4095, Validation Loss: 0.5018
	--> Epoch [27/100], Loss: 0.3851, Validation Loss: 0.4962
	--> Epoch [28/100], Loss: 0.3879, Validation Loss: 0.4918
	--> Epoch [29/100], Loss: 0.3420, Validation Loss: 0.4858
	--> Epoch [30/100], Loss: 0.3798, Validation Loss: 0.4774
	--> Epoch [31/100], Loss: 0.3596, Validation Loss: 0.4718
	--> Epoch [32/100], Loss: 0.3460, Validation Loss: 0.4679
	--> Epoch [33/100], Loss: 0.3034, Validation Loss: 0.4623
	--> Epoch [34/100], Loss: 0.3421, Validation Loss: 0.4561
	--> Epoch [35/100], Loss: 0.3325, Validation Loss: 0.4500
	--> Epoch [36/100], Loss: 0.3079, Validation Loss: 0.4448
	--> Epoch [37/100], Loss: 0.2933, Validation Loss: 0.4400
	--> Epoch [38/100], Loss: 0.3092, Validation Loss: 0.4354
	--> Epoch [39/100], Loss: 0.3036, Validation Loss: 0.4295
	--> Epoch [40/100], Loss: 0.2875, Validation Loss: 0.4251
	--> Epoch [41/100], Loss: 0.2940, Validation Loss: 0.4208
	--> Epoch [42/100], Loss: 0.3034, Validation Loss: 0.4173
	--> Epoch [43/100], Loss: 0.2940, Validation Loss: 0.4105
	--> Epoch [44/100], Loss: 0.2917, Validation Loss: 0.4071
	--> Epoch [45/100], Loss: 0.2535, Validation Loss: 0.4032
	--> Epoch [46/100], Loss: 0.2883, Validation Loss: 0.3987
	--> Epoch [47/100], Loss: 0.2614, Validation Loss: 0.3949
	--> Epoch [48/100], Loss: 0.2591, Validation Loss: 0.3914
	--> Epoch [49/100], Loss: 0.2651, Validation Loss: 0.3868
	--> Epoch [50/100], Loss: 0.2497, Validation Loss: 0.3829
	--> Epoch [51/100], Loss: 0.2848, Validation Loss: 0.3780
	--> Epoch [52/100], Loss: 0.2633, Validation Loss: 0.3726
	--> Epoch [53/100], Loss: 0.2240, Validation Loss: 0.3692
	--> Epoch [54/100], Loss: 0.2398, Validation Loss: 0.3642
	--> Epoch [55/100], Loss: 0.2425, Validation Loss: 0.3608
	--> Epoch [56/100], Loss: 0.2340, Validation Loss: 0.3567
	--> Epoch [57/100], Loss: 0.2303, Validation Loss: 0.3540
	--> Epoch [58/100], Loss: 0.2029, Validation Loss: 0.3510
	--> Epoch [59/100], Loss: 0.2066, Validation Loss: 0.3491
	--> Epoch [60/100], Loss: 0.2154, Validation Loss: 0.3463
	--> Epoch [61/100], Loss: 0.1857, Validation Loss: 0.3425
	--> Epoch [62/100], Loss: 0.2033, Validation Loss: 0.3382
	--> Epoch [63/100], Loss: 0.1725, Validation Loss: 0.3350
	--> Epoch [64/100], Loss: 0.1763, Validation Loss: 0.3322
	--> Epoch [65/100], Loss: 0.1783, Validation Loss: 0.3291
	--> Epoch [66/100], Loss: 0.2054, Validation Loss: 0.3270
	--> Epoch [67/100], Loss: 0.1865, Validation Loss: 0.3254
	--> Epoch [68/100], Loss: 0.1762, Validation Loss: 0.3226
	--> Epoch [69/100], Loss: 0.1741, Validation Loss: 0.3193
	--> Epoch [70/100], Loss: 0.1974, Validation Loss: 0.3184
	--> Epoch [71/100], Loss: 0.1882, Validation Loss: 0.3162
	--> Epoch [72/100], Loss: 0.1929, Validation Loss: 0.3135
	--> Epoch [73/100], Loss: 0.1669, Validation Loss: 0.3109
	--> Epoch [74/100], Loss: 0.1885, Validation Loss: 0.3085
	--> Epoch [75/100], Loss: 0.1287, Validation Loss: 0.3066
	--> Epoch [76/100], Loss: 0.1515, Validation Loss: 0.3048
	--> Epoch [77/100], Loss: 0.1597, Validation Loss: 0.3036
	--> Epoch [78/100], Loss: 0.1558, Validation Loss: 0.3012
	--> Epoch [79/100], Loss: 0.1597, Validation Loss: 0.2992
	--> Epoch [80/100], Loss: 0.1393, Validation Loss: 0.2972
	--> Epoch [81/100], Loss: 0.1727, Validation Loss: 0.2948
	--> Epoch [82/100], Loss: 0.1562, Validation Loss: 0.2937
	--> Epoch [83/100], Loss: 0.1353, Validation Loss: 0.2919
	--> Epoch [84/100], Loss: 0.1506, Validation Loss: 0.2908
	--> Epoch [85/100], Loss: 0.1529, Validation Loss: 0.2877
	--> Epoch [86/100], Loss: 0.1815, Validation Loss: 0.2868
	--> Epoch [87/100], Loss: 0.1509, Validation Loss: 0.2851
	--> Epoch [88/100], Loss: 0.1581, Validation Loss: 0.2836
	--> Epoch [89/100], Loss: 0.1465, Validation Loss: 0.2809
	--> Epoch [90/100], Loss: 0.1421, Validation Loss: 0.2808
	--> Epoch [91/100], Loss: 0.1195, Validation Loss: 0.2795
	--> Epoch [92/100], Loss: 0.0947, Validation Loss: 0.2769
	--> Epoch [93/100], Loss: 0.1094, Validation Loss: 0.2764
	--> Epoch [94/100], Loss: 0.1140, Validation Loss: 0.2743
	--> Epoch [95/100], Loss: 0.1369, Validation Loss: 0.2734
	--> Epoch [96/100], Loss: 0.1325, Validation Loss: 0.2715
	--> Epoch [97/100], Loss: 0.0993, Validation Loss: 0.2695
	--> Epoch [98/100], Loss: 0.1162, Validation Loss: 0.2687
	--> Epoch [99/100], Loss: 0.1466, Validation Loss: 0.2681
	--> Epoch [100/100], Loss: 0.1348, Validation Loss: 0.2660
	--> Training for Fold 1 took 0.42293381690979004 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7286, Validation Loss: 0.6743
	--> Epoch [2/100], Loss: 0.7024, Validation Loss: 0.6506
	--> Epoch [3/100], Loss: 0.6799, Validation Loss: 0.6309
	--> Epoch [4/100], Loss: 0.6775, Validation Loss: 0.6147
	--> Epoch [5/100], Loss: 0.6631, Validation Loss: 0.5973
	--> Epoch [6/100], Loss: 0.6408, Validation Loss: 0.5821
	--> Epoch [7/100], Loss: 0.6316, Validation Loss: 0.5681
	--> Epoch [8/100], Loss: 0.6118, Validation Loss: 0.5568
	--> Epoch [9/100], Loss: 0.6138, Validation Loss: 0.5433
	--> Epoch [10/100], Loss: 0.6000, Validation Loss: 0.5328
	--> Epoch [11/100], Loss: 0.5897, Validation Loss: 0.5228
	--> Epoch [12/100], Loss: 0.5749, Validation Loss: 0.5126
	--> Epoch [13/100], Loss: 0.5546, Validation Loss: 0.5014
	--> Epoch [14/100], Loss: 0.5566, Validation Loss: 0.4916
	--> Epoch [15/100], Loss: 0.5298, Validation Loss: 0.4826
	--> Epoch [16/100], Loss: 0.5349, Validation Loss: 0.4730
	--> Epoch [17/100], Loss: 0.5282, Validation Loss: 0.4640
	--> Epoch [18/100], Loss: 0.5036, Validation Loss: 0.4555
	--> Epoch [19/100], Loss: 0.5021, Validation Loss: 0.4457
	--> Epoch [20/100], Loss: 0.4858, Validation Loss: 0.4365
	--> Epoch [21/100], Loss: 0.4632, Validation Loss: 0.4276
	--> Epoch [22/100], Loss: 0.4597, Validation Loss: 0.4190
	--> Epoch [23/100], Loss: 0.4521, Validation Loss: 0.4103
	--> Epoch [24/100], Loss: 0.4539, Validation Loss: 0.4015
	--> Epoch [25/100], Loss: 0.4315, Validation Loss: 0.3930
	--> Epoch [26/100], Loss: 0.4248, Validation Loss: 0.3841
	--> Epoch [27/100], Loss: 0.3917, Validation Loss: 0.3766
	--> Epoch [28/100], Loss: 0.3940, Validation Loss: 0.3699
	--> Epoch [29/100], Loss: 0.4200, Validation Loss: 0.3646
	--> Epoch [30/100], Loss: 0.3885, Validation Loss: 0.3587
	--> Epoch [31/100], Loss: 0.3928, Validation Loss: 0.3528
	--> Epoch [32/100], Loss: 0.3652, Validation Loss: 0.3469
	--> Epoch [33/100], Loss: 0.3850, Validation Loss: 0.3415
	--> Epoch [34/100], Loss: 0.3638, Validation Loss: 0.3357
	--> Epoch [35/100], Loss: 0.3656, Validation Loss: 0.3301
	--> Epoch [36/100], Loss: 0.3689, Validation Loss: 0.3256
	--> Epoch [37/100], Loss: 0.3511, Validation Loss: 0.3213
	--> Epoch [38/100], Loss: 0.3355, Validation Loss: 0.3173
	--> Epoch [39/100], Loss: 0.3221, Validation Loss: 0.3123
	--> Epoch [40/100], Loss: 0.3127, Validation Loss: 0.3075
	--> Epoch [41/100], Loss: 0.3298, Validation Loss: 0.3046
	--> Epoch [42/100], Loss: 0.3095, Validation Loss: 0.3009
	--> Epoch [43/100], Loss: 0.2702, Validation Loss: 0.2975
	--> Epoch [44/100], Loss: 0.3150, Validation Loss: 0.2941
	--> Epoch [45/100], Loss: 0.3023, Validation Loss: 0.2908
	--> Epoch [46/100], Loss: 0.2885, Validation Loss: 0.2874
	--> Epoch [47/100], Loss: 0.2824, Validation Loss: 0.2848
	--> Epoch [48/100], Loss: 0.2733, Validation Loss: 0.2820
	--> Epoch [49/100], Loss: 0.2850, Validation Loss: 0.2790
	--> Epoch [50/100], Loss: 0.2804, Validation Loss: 0.2761
	--> Epoch [51/100], Loss: 0.2575, Validation Loss: 0.2737
	--> Epoch [52/100], Loss: 0.2781, Validation Loss: 0.2708
	--> Epoch [53/100], Loss: 0.2917, Validation Loss: 0.2689
	--> Epoch [54/100], Loss: 0.2627, Validation Loss: 0.2662
	--> Epoch [55/100], Loss: 0.2397, Validation Loss: 0.2646
	--> Epoch [56/100], Loss: 0.2219, Validation Loss: 0.2623
	--> Epoch [57/100], Loss: 0.2495, Validation Loss: 0.2594
	--> Epoch [58/100], Loss: 0.2306, Validation Loss: 0.2570
	--> Epoch [59/100], Loss: 0.2424, Validation Loss: 0.2555
	--> Epoch [60/100], Loss: 0.2385, Validation Loss: 0.2539
	--> Epoch [61/100], Loss: 0.2387, Validation Loss: 0.2522
	--> Epoch [62/100], Loss: 0.2284, Validation Loss: 0.2508
	--> Epoch [63/100], Loss: 0.2383, Validation Loss: 0.2491
	--> Epoch [64/100], Loss: 0.2026, Validation Loss: 0.2469
	--> Epoch [65/100], Loss: 0.1955, Validation Loss: 0.2456
	--> Epoch [66/100], Loss: 0.2143, Validation Loss: 0.2443
	--> Epoch [67/100], Loss: 0.1864, Validation Loss: 0.2424
	--> Epoch [68/100], Loss: 0.1862, Validation Loss: 0.2413
	--> Epoch [69/100], Loss: 0.1977, Validation Loss: 0.2406
	--> Epoch [70/100], Loss: 0.2076, Validation Loss: 0.2386
	--> Epoch [71/100], Loss: 0.1723, Validation Loss: 0.2371
	--> Epoch [72/100], Loss: 0.1637, Validation Loss: 0.2359
	--> Epoch [73/100], Loss: 0.1558, Validation Loss: 0.2349
	--> Epoch [74/100], Loss: 0.1623, Validation Loss: 0.2333
	--> Epoch [75/100], Loss: 0.1792, Validation Loss: 0.2320
	--> Epoch [76/100], Loss: 0.1776, Validation Loss: 0.2303
	--> Epoch [77/100], Loss: 0.1651, Validation Loss: 0.2291
	--> Epoch [78/100], Loss: 0.1509, Validation Loss: 0.2291
	--> Epoch [79/100], Loss: 0.1697, Validation Loss: 0.2279
	--> Epoch [80/100], Loss: 0.1588, Validation Loss: 0.2275
	--> Epoch [81/100], Loss: 0.1548, Validation Loss: 0.2259
	--> Epoch [82/100], Loss: 0.1430, Validation Loss: 0.2247
	--> Epoch [83/100], Loss: 0.1572, Validation Loss: 0.2232
	--> Epoch [84/100], Loss: 0.1463, Validation Loss: 0.2223
	--> Epoch [85/100], Loss: 0.1545, Validation Loss: 0.2207
	--> Epoch [86/100], Loss: 0.1571, Validation Loss: 0.2196
	--> Epoch [87/100], Loss: 0.1429, Validation Loss: 0.2186
	--> Epoch [88/100], Loss: 0.1615, Validation Loss: 0.2181
	--> Epoch [89/100], Loss: 0.1296, Validation Loss: 0.2180
	--> Epoch [90/100], Loss: 0.1433, Validation Loss: 0.2164
	--> Epoch [91/100], Loss: 0.1220, Validation Loss: 0.2154
	--> Epoch [92/100], Loss: 0.1189, Validation Loss: 0.2149
	--> Epoch [93/100], Loss: 0.1177, Validation Loss: 0.2136
	--> Epoch [94/100], Loss: 0.1266, Validation Loss: 0.2124
	--> Epoch [95/100], Loss: 0.1207, Validation Loss: 0.2107
	--> Epoch [96/100], Loss: 0.1175, Validation Loss: 0.2097
	--> Epoch [97/100], Loss: 0.1112, Validation Loss: 0.2091
	--> Epoch [98/100], Loss: 0.1161, Validation Loss: 0.2078
	--> Epoch [99/100], Loss: 0.1248, Validation Loss: 0.2068
	--> Epoch [100/100], Loss: 0.1053, Validation Loss: 0.2064
	--> Training for Fold 2 took 0.40644359588623047 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7092, Validation Loss: 0.7399
	--> Epoch [2/100], Loss: 0.6697, Validation Loss: 0.7279
	--> Epoch [3/100], Loss: 0.6738, Validation Loss: 0.7193
	--> Epoch [4/100], Loss: 0.6573, Validation Loss: 0.7094
	--> Epoch [5/100], Loss: 0.6249, Validation Loss: 0.7024
	--> Epoch [6/100], Loss: 0.6036, Validation Loss: 0.6947
	--> Epoch [7/100], Loss: 0.5752, Validation Loss: 0.6857
	--> Epoch [8/100], Loss: 0.5790, Validation Loss: 0.6755
	--> Epoch [9/100], Loss: 0.5751, Validation Loss: 0.6663
	--> Epoch [10/100], Loss: 0.5407, Validation Loss: 0.6571
	--> Epoch [11/100], Loss: 0.5257, Validation Loss: 0.6504
	--> Epoch [12/100], Loss: 0.5113, Validation Loss: 0.6403
	--> Epoch [13/100], Loss: 0.5445, Validation Loss: 0.6325
	--> Epoch [14/100], Loss: 0.4991, Validation Loss: 0.6238
	--> Epoch [15/100], Loss: 0.4845, Validation Loss: 0.6160
	--> Epoch [16/100], Loss: 0.4751, Validation Loss: 0.6105
	--> Epoch [17/100], Loss: 0.4640, Validation Loss: 0.6032
	--> Epoch [18/100], Loss: 0.4654, Validation Loss: 0.5988
	--> Epoch [19/100], Loss: 0.4544, Validation Loss: 0.5930
	--> Epoch [20/100], Loss: 0.4453, Validation Loss: 0.5842
	--> Epoch [21/100], Loss: 0.4176, Validation Loss: 0.5792
	--> Epoch [22/100], Loss: 0.4192, Validation Loss: 0.5716
	--> Epoch [23/100], Loss: 0.4070, Validation Loss: 0.5648
	--> Epoch [24/100], Loss: 0.3845, Validation Loss: 0.5604
	--> Epoch [25/100], Loss: 0.3966, Validation Loss: 0.5543
	--> Epoch [26/100], Loss: 0.3895, Validation Loss: 0.5482
	--> Epoch [27/100], Loss: 0.3613, Validation Loss: 0.5423
	--> Epoch [28/100], Loss: 0.3358, Validation Loss: 0.5360
	--> Epoch [29/100], Loss: 0.3280, Validation Loss: 0.5295
	--> Epoch [30/100], Loss: 0.3291, Validation Loss: 0.5223
	--> Epoch [31/100], Loss: 0.3291, Validation Loss: 0.5177
	--> Epoch [32/100], Loss: 0.3441, Validation Loss: 0.5135
	--> Epoch [33/100], Loss: 0.3328, Validation Loss: 0.5092
	--> Epoch [34/100], Loss: 0.2889, Validation Loss: 0.5053
	--> Epoch [35/100], Loss: 0.3196, Validation Loss: 0.5014
	--> Epoch [36/100], Loss: 0.3176, Validation Loss: 0.4963
	--> Epoch [37/100], Loss: 0.3097, Validation Loss: 0.4898
	--> Epoch [38/100], Loss: 0.2916, Validation Loss: 0.4857
	--> Epoch [39/100], Loss: 0.2831, Validation Loss: 0.4801
	--> Epoch [40/100], Loss: 0.2972, Validation Loss: 0.4775
	--> Epoch [41/100], Loss: 0.2835, Validation Loss: 0.4732
	--> Epoch [42/100], Loss: 0.2601, Validation Loss: 0.4701
	--> Epoch [43/100], Loss: 0.2894, Validation Loss: 0.4660
	--> Epoch [44/100], Loss: 0.2516, Validation Loss: 0.4624
	--> Epoch [45/100], Loss: 0.2348, Validation Loss: 0.4584
	--> Epoch [46/100], Loss: 0.2420, Validation Loss: 0.4548
	--> Epoch [47/100], Loss: 0.2388, Validation Loss: 0.4512
	--> Epoch [48/100], Loss: 0.2407, Validation Loss: 0.4483
	--> Epoch [49/100], Loss: 0.2196, Validation Loss: 0.4440
	--> Epoch [50/100], Loss: 0.2292, Validation Loss: 0.4413
	--> Epoch [51/100], Loss: 0.2017, Validation Loss: 0.4388
	--> Epoch [52/100], Loss: 0.2072, Validation Loss: 0.4363
	--> Epoch [53/100], Loss: 0.2159, Validation Loss: 0.4341
	--> Epoch [54/100], Loss: 0.2146, Validation Loss: 0.4308
	--> Epoch [55/100], Loss: 0.1697, Validation Loss: 0.4268
	--> Epoch [56/100], Loss: 0.1838, Validation Loss: 0.4234
	--> Epoch [57/100], Loss: 0.1752, Validation Loss: 0.4196
	--> Epoch [58/100], Loss: 0.2153, Validation Loss: 0.4182
	--> Epoch [59/100], Loss: 0.2012, Validation Loss: 0.4161
	--> Epoch [60/100], Loss: 0.1900, Validation Loss: 0.4132
	--> Epoch [61/100], Loss: 0.1506, Validation Loss: 0.4102
	--> Epoch [62/100], Loss: 0.1852, Validation Loss: 0.4083
	--> Epoch [63/100], Loss: 0.1703, Validation Loss: 0.4052
	--> Epoch [64/100], Loss: 0.1693, Validation Loss: 0.4027
	--> Epoch [65/100], Loss: 0.1407, Validation Loss: 0.4002
	--> Epoch [66/100], Loss: 0.1631, Validation Loss: 0.3975
	--> Epoch [67/100], Loss: 0.1748, Validation Loss: 0.3955
	--> Epoch [68/100], Loss: 0.1613, Validation Loss: 0.3934
	--> Epoch [69/100], Loss: 0.1564, Validation Loss: 0.3911
	--> Epoch [70/100], Loss: 0.1473, Validation Loss: 0.3884
	--> Epoch [71/100], Loss: 0.1346, Validation Loss: 0.3865
	--> Epoch [72/100], Loss: 0.1553, Validation Loss: 0.3838
	--> Epoch [73/100], Loss: 0.1314, Validation Loss: 0.3829
	--> Epoch [74/100], Loss: 0.1327, Validation Loss: 0.3806
	--> Epoch [75/100], Loss: 0.1657, Validation Loss: 0.3764
	--> Epoch [76/100], Loss: 0.1295, Validation Loss: 0.3751
	--> Epoch [77/100], Loss: 0.1387, Validation Loss: 0.3736
	--> Epoch [78/100], Loss: 0.1314, Validation Loss: 0.3718
	--> Epoch [79/100], Loss: 0.1440, Validation Loss: 0.3694
	--> Epoch [80/100], Loss: 0.1454, Validation Loss: 0.3673
	--> Epoch [81/100], Loss: 0.0974, Validation Loss: 0.3644
	--> Epoch [82/100], Loss: 0.1343, Validation Loss: 0.3633
	--> Epoch [83/100], Loss: 0.1204, Validation Loss: 0.3617
	--> Epoch [84/100], Loss: 0.1365, Validation Loss: 0.3591
	--> Epoch [85/100], Loss: 0.0960, Validation Loss: 0.3576
	--> Epoch [86/100], Loss: 0.1031, Validation Loss: 0.3570
	--> Epoch [87/100], Loss: 0.1068, Validation Loss: 0.3561
	--> Epoch [88/100], Loss: 0.1305, Validation Loss: 0.3553
	--> Epoch [89/100], Loss: 0.1108, Validation Loss: 0.3551
	--> Epoch [90/100], Loss: 0.1388, Validation Loss: 0.3535
	--> Epoch [91/100], Loss: 0.1309, Validation Loss: 0.3525
	--> Epoch [92/100], Loss: 0.1054, Validation Loss: 0.3510
	--> Epoch [93/100], Loss: 0.1002, Validation Loss: 0.3503
	--> Epoch [94/100], Loss: 0.0952, Validation Loss: 0.3485
	--> Epoch [95/100], Loss: 0.1292, Validation Loss: 0.3475
	--> Epoch [96/100], Loss: 0.1252, Validation Loss: 0.3460
	--> Epoch [97/100], Loss: 0.1200, Validation Loss: 0.3445
	--> Epoch [98/100], Loss: 0.1099, Validation Loss: 0.3425
	--> Epoch [99/100], Loss: 0.1156, Validation Loss: 0.3407
	--> Epoch [100/100], Loss: 0.1048, Validation Loss: 0.3399
	--> Training for Fold 3 took 0.3957998752593994 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7382, Validation Loss: 0.8943
	--> Epoch [2/100], Loss: 0.7202, Validation Loss: 0.8798
	--> Epoch [3/100], Loss: 0.6997, Validation Loss: 0.8640
	--> Epoch [4/100], Loss: 0.6911, Validation Loss: 0.8506
	--> Epoch [5/100], Loss: 0.6680, Validation Loss: 0.8377
	--> Epoch [6/100], Loss: 0.6644, Validation Loss: 0.8263
	--> Epoch [7/100], Loss: 0.6538, Validation Loss: 0.8141
	--> Epoch [8/100], Loss: 0.6457, Validation Loss: 0.8008
	--> Epoch [9/100], Loss: 0.6386, Validation Loss: 0.7881
	--> Epoch [10/100], Loss: 0.6255, Validation Loss: 0.7763
	--> Epoch [11/100], Loss: 0.5999, Validation Loss: 0.7604
	--> Epoch [12/100], Loss: 0.6031, Validation Loss: 0.7460
	--> Epoch [13/100], Loss: 0.5674, Validation Loss: 0.7261
	--> Epoch [14/100], Loss: 0.5729, Validation Loss: 0.7112
	--> Epoch [15/100], Loss: 0.5543, Validation Loss: 0.6968
	--> Epoch [16/100], Loss: 0.5435, Validation Loss: 0.6823
	--> Epoch [17/100], Loss: 0.5168, Validation Loss: 0.6620
	--> Epoch [18/100], Loss: 0.5134, Validation Loss: 0.6500
	--> Epoch [19/100], Loss: 0.5110, Validation Loss: 0.6364
	--> Epoch [20/100], Loss: 0.4843, Validation Loss: 0.6221
	--> Epoch [21/100], Loss: 0.4811, Validation Loss: 0.6092
	--> Epoch [22/100], Loss: 0.4663, Validation Loss: 0.6007
	--> Epoch [23/100], Loss: 0.4390, Validation Loss: 0.5877
	--> Epoch [24/100], Loss: 0.4587, Validation Loss: 0.5797
	--> Epoch [25/100], Loss: 0.4243, Validation Loss: 0.5715
	--> Epoch [26/100], Loss: 0.4492, Validation Loss: 0.5625
	--> Epoch [27/100], Loss: 0.4255, Validation Loss: 0.5556
	--> Epoch [28/100], Loss: 0.3956, Validation Loss: 0.5477
	--> Epoch [29/100], Loss: 0.4000, Validation Loss: 0.5385
	--> Epoch [30/100], Loss: 0.3843, Validation Loss: 0.5303
	--> Epoch [31/100], Loss: 0.4039, Validation Loss: 0.5246
	--> Epoch [32/100], Loss: 0.3903, Validation Loss: 0.5213
	--> Epoch [33/100], Loss: 0.3745, Validation Loss: 0.5155
	--> Epoch [34/100], Loss: 0.3551, Validation Loss: 0.5071
	--> Epoch [35/100], Loss: 0.3456, Validation Loss: 0.5003
	--> Epoch [36/100], Loss: 0.3396, Validation Loss: 0.4958
	--> Epoch [37/100], Loss: 0.3144, Validation Loss: 0.4875
	--> Epoch [38/100], Loss: 0.3098, Validation Loss: 0.4807
	--> Epoch [39/100], Loss: 0.3348, Validation Loss: 0.4759
	--> Epoch [40/100], Loss: 0.3079, Validation Loss: 0.4700
	--> Epoch [41/100], Loss: 0.3038, Validation Loss: 0.4670
	--> Epoch [42/100], Loss: 0.3057, Validation Loss: 0.4627
	--> Epoch [43/100], Loss: 0.2921, Validation Loss: 0.4580
	--> Epoch [44/100], Loss: 0.2966, Validation Loss: 0.4551
	--> Epoch [45/100], Loss: 0.2798, Validation Loss: 0.4514
	--> Epoch [46/100], Loss: 0.2815, Validation Loss: 0.4493
	--> Epoch [47/100], Loss: 0.2922, Validation Loss: 0.4461
	--> Epoch [48/100], Loss: 0.2755, Validation Loss: 0.4444
	--> Epoch [49/100], Loss: 0.2465, Validation Loss: 0.4428
	--> Epoch [50/100], Loss: 0.2475, Validation Loss: 0.4416
	--> Epoch [51/100], Loss: 0.2670, Validation Loss: 0.4385
	--> Epoch [52/100], Loss: 0.2229, Validation Loss: 0.4354
	--> Epoch [53/100], Loss: 0.2421, Validation Loss: 0.4331
	--> Epoch [54/100], Loss: 0.2293, Validation Loss: 0.4310
	--> Epoch [55/100], Loss: 0.2295, Validation Loss: 0.4294
	--> Epoch [56/100], Loss: 0.2340, Validation Loss: 0.4269
	--> Epoch [57/100], Loss: 0.2065, Validation Loss: 0.4257
	--> Epoch [58/100], Loss: 0.1947, Validation Loss: 0.4237
	--> Epoch [59/100], Loss: 0.2302, Validation Loss: 0.4193
	--> Epoch [60/100], Loss: 0.1889, Validation Loss: 0.4189
	--> Epoch [61/100], Loss: 0.2224, Validation Loss: 0.4156
	--> Epoch [62/100], Loss: 0.1722, Validation Loss: 0.4146
	--> Epoch [63/100], Loss: 0.1961, Validation Loss: 0.4128
	--> Epoch [64/100], Loss: 0.2024, Validation Loss: 0.4113
	--> Epoch [65/100], Loss: 0.1507, Validation Loss: 0.4086
	--> Epoch [66/100], Loss: 0.1874, Validation Loss: 0.4071
	--> Epoch [67/100], Loss: 0.1716, Validation Loss: 0.4053
	--> Epoch [68/100], Loss: 0.1738, Validation Loss: 0.4041
	--> Epoch [69/100], Loss: 0.1805, Validation Loss: 0.4026
	--> Epoch [70/100], Loss: 0.1444, Validation Loss: 0.4024
	--> Epoch [71/100], Loss: 0.1611, Validation Loss: 0.4017
	--> Epoch [72/100], Loss: 0.1509, Validation Loss: 0.4019
	--> Epoch [73/100], Loss: 0.1777, Validation Loss: 0.3995
	--> Epoch [74/100], Loss: 0.1530, Validation Loss: 0.3984
	--> Epoch [75/100], Loss: 0.1615, Validation Loss: 0.3978
	--> Epoch [76/100], Loss: 0.1448, Validation Loss: 0.3970
	--> Epoch [77/100], Loss: 0.1521, Validation Loss: 0.3965
	--> Epoch [78/100], Loss: 0.1265, Validation Loss: 0.3956
	--> Epoch [79/100], Loss: 0.1725, Validation Loss: 0.3940
	--> Epoch [80/100], Loss: 0.1359, Validation Loss: 0.3936
	--> Epoch [81/100], Loss: 0.1733, Validation Loss: 0.3938
	--> Epoch [82/100], Loss: 0.1458, Validation Loss: 0.3916
	--> Epoch [83/100], Loss: 0.1292, Validation Loss: 0.3910
	--> Epoch [84/100], Loss: 0.1485, Validation Loss: 0.3914
	--> Epoch [85/100], Loss: 0.1350, Validation Loss: 0.3883
	--> Epoch [86/100], Loss: 0.1311, Validation Loss: 0.3874
	--> Epoch [87/100], Loss: 0.1459, Validation Loss: 0.3866
	--> Epoch [88/100], Loss: 0.1293, Validation Loss: 0.3864
	--> Epoch [89/100], Loss: 0.1148, Validation Loss: 0.3857
	--> Epoch [90/100], Loss: 0.1293, Validation Loss: 0.3861
	--> Epoch [91/100], Loss: 0.1173, Validation Loss: 0.3873
	--> Epoch [92/100], Loss: 0.1354, Validation Loss: 0.3860
Early stopping
	--> Training for Fold 4 took 0.36127710342407227 sec, using 92 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8194, Validation Loss: 0.6343
	--> Epoch [2/100], Loss: 0.7750, Validation Loss: 0.6265
	--> Epoch [3/100], Loss: 0.7795, Validation Loss: 0.6208
	--> Epoch [4/100], Loss: 0.7597, Validation Loss: 0.6134
	--> Epoch [5/100], Loss: 0.7327, Validation Loss: 0.6068
	--> Epoch [6/100], Loss: 0.6847, Validation Loss: 0.6009
	--> Epoch [7/100], Loss: 0.6803, Validation Loss: 0.5950
	--> Epoch [8/100], Loss: 0.6608, Validation Loss: 0.5880
	--> Epoch [9/100], Loss: 0.6560, Validation Loss: 0.5835
	--> Epoch [10/100], Loss: 0.6633, Validation Loss: 0.5770
	--> Epoch [11/100], Loss: 0.6239, Validation Loss: 0.5714
	--> Epoch [12/100], Loss: 0.6028, Validation Loss: 0.5659
	--> Epoch [13/100], Loss: 0.6199, Validation Loss: 0.5625
	--> Epoch [14/100], Loss: 0.5930, Validation Loss: 0.5591
	--> Epoch [15/100], Loss: 0.5709, Validation Loss: 0.5563
	--> Epoch [16/100], Loss: 0.5541, Validation Loss: 0.5510
	--> Epoch [17/100], Loss: 0.5694, Validation Loss: 0.5472
	--> Epoch [18/100], Loss: 0.5417, Validation Loss: 0.5425
	--> Epoch [19/100], Loss: 0.5355, Validation Loss: 0.5393
	--> Epoch [20/100], Loss: 0.5390, Validation Loss: 0.5343
	--> Epoch [21/100], Loss: 0.4981, Validation Loss: 0.5296
	--> Epoch [22/100], Loss: 0.5058, Validation Loss: 0.5265
	--> Epoch [23/100], Loss: 0.4944, Validation Loss: 0.5231
	--> Epoch [24/100], Loss: 0.4511, Validation Loss: 0.5212
	--> Epoch [25/100], Loss: 0.4777, Validation Loss: 0.5186
	--> Epoch [26/100], Loss: 0.4362, Validation Loss: 0.5146
	--> Epoch [27/100], Loss: 0.4656, Validation Loss: 0.5118
	--> Epoch [28/100], Loss: 0.4493, Validation Loss: 0.5098
	--> Epoch [29/100], Loss: 0.4259, Validation Loss: 0.5072
	--> Epoch [30/100], Loss: 0.4381, Validation Loss: 0.5043
	--> Epoch [31/100], Loss: 0.4030, Validation Loss: 0.5013
	--> Epoch [32/100], Loss: 0.4004, Validation Loss: 0.4993
	--> Epoch [33/100], Loss: 0.3868, Validation Loss: 0.4973
	--> Epoch [34/100], Loss: 0.3696, Validation Loss: 0.4943
	--> Epoch [35/100], Loss: 0.3978, Validation Loss: 0.4918
	--> Epoch [36/100], Loss: 0.3626, Validation Loss: 0.4891
	--> Epoch [37/100], Loss: 0.3839, Validation Loss: 0.4866
	--> Epoch [38/100], Loss: 0.3550, Validation Loss: 0.4837
	--> Epoch [39/100], Loss: 0.3735, Validation Loss: 0.4814
	--> Epoch [40/100], Loss: 0.3612, Validation Loss: 0.4802
	--> Epoch [41/100], Loss: 0.3564, Validation Loss: 0.4781
	--> Epoch [42/100], Loss: 0.3351, Validation Loss: 0.4754
	--> Epoch [43/100], Loss: 0.3015, Validation Loss: 0.4740
	--> Epoch [44/100], Loss: 0.3028, Validation Loss: 0.4722
	--> Epoch [45/100], Loss: 0.3478, Validation Loss: 0.4709
	--> Epoch [46/100], Loss: 0.3299, Validation Loss: 0.4701
	--> Epoch [47/100], Loss: 0.3341, Validation Loss: 0.4686
	--> Epoch [48/100], Loss: 0.3261, Validation Loss: 0.4664
	--> Epoch [49/100], Loss: 0.3580, Validation Loss: 0.4653
	--> Epoch [50/100], Loss: 0.3059, Validation Loss: 0.4643
	--> Epoch [51/100], Loss: 0.3021, Validation Loss: 0.4624
	--> Epoch [52/100], Loss: 0.3134, Validation Loss: 0.4609
	--> Epoch [53/100], Loss: 0.2978, Validation Loss: 0.4589
	--> Epoch [54/100], Loss: 0.2656, Validation Loss: 0.4572
	--> Epoch [55/100], Loss: 0.2673, Validation Loss: 0.4565
	--> Epoch [56/100], Loss: 0.2853, Validation Loss: 0.4559
	--> Epoch [57/100], Loss: 0.2700, Validation Loss: 0.4549
	--> Epoch [58/100], Loss: 0.2519, Validation Loss: 0.4545
	--> Epoch [59/100], Loss: 0.2438, Validation Loss: 0.4533
	--> Epoch [60/100], Loss: 0.2681, Validation Loss: 0.4512
	--> Epoch [61/100], Loss: 0.2618, Validation Loss: 0.4496
	--> Epoch [62/100], Loss: 0.2517, Validation Loss: 0.4484
	--> Epoch [63/100], Loss: 0.2909, Validation Loss: 0.4476
	--> Epoch [64/100], Loss: 0.2624, Validation Loss: 0.4468
	--> Epoch [65/100], Loss: 0.2384, Validation Loss: 0.4450
	--> Epoch [66/100], Loss: 0.2475, Validation Loss: 0.4450
	--> Epoch [67/100], Loss: 0.2308, Validation Loss: 0.4445
	--> Epoch [68/100], Loss: 0.2536, Validation Loss: 0.4443
	--> Epoch [69/100], Loss: 0.2588, Validation Loss: 0.4423
	--> Epoch [70/100], Loss: 0.2567, Validation Loss: 0.4410
	--> Epoch [71/100], Loss: 0.2175, Validation Loss: 0.4390
	--> Epoch [72/100], Loss: 0.2187, Validation Loss: 0.4386
	--> Epoch [73/100], Loss: 0.1881, Validation Loss: 0.4372
	--> Epoch [74/100], Loss: 0.2151, Validation Loss: 0.4369
	--> Epoch [75/100], Loss: 0.2484, Validation Loss: 0.4360
	--> Epoch [76/100], Loss: 0.1768, Validation Loss: 0.4358
	--> Epoch [77/100], Loss: 0.2015, Validation Loss: 0.4355
	--> Epoch [78/100], Loss: 0.1873, Validation Loss: 0.4348
	--> Epoch [79/100], Loss: 0.2436, Validation Loss: 0.4349
	--> Epoch [80/100], Loss: 0.2062, Validation Loss: 0.4349
	--> Epoch [81/100], Loss: 0.2318, Validation Loss: 0.4354
Early stopping
	--> Training for Fold 5 took 0.33442187309265137 sec, using 81 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7488
	--> Final training Epoch [2/100], Loss: 0.7120
	--> Final training Epoch [3/100], Loss: 0.7009
	--> Final training Epoch [4/100], Loss: 0.6723
	--> Final training Epoch [5/100], Loss: 0.6692
	--> Final training Epoch [6/100], Loss: 0.6398
	--> Final training Epoch [7/100], Loss: 0.6374
	--> Final training Epoch [8/100], Loss: 0.6256
	--> Final training Epoch [9/100], Loss: 0.6028
	--> Final training Epoch [10/100], Loss: 0.5940
	--> Final training Epoch [11/100], Loss: 0.5782
	--> Final training Epoch [12/100], Loss: 0.5830
	--> Final training Epoch [13/100], Loss: 0.5541
	--> Final training Epoch [14/100], Loss: 0.5342
	--> Final training Epoch [15/100], Loss: 0.5310
	--> Final training Epoch [16/100], Loss: 0.5313
	--> Final training Epoch [17/100], Loss: 0.5212
	--> Final training Epoch [18/100], Loss: 0.4925
	--> Final training Epoch [19/100], Loss: 0.5125
	--> Final training Epoch [20/100], Loss: 0.4727
	--> Final training Epoch [21/100], Loss: 0.4823
	--> Final training Epoch [22/100], Loss: 0.4651
	--> Final training Epoch [23/100], Loss: 0.4509
	--> Final training Epoch [24/100], Loss: 0.4600
	--> Final training Epoch [25/100], Loss: 0.4424
	--> Final training Epoch [26/100], Loss: 0.4342
	--> Final training Epoch [27/100], Loss: 0.4112
	--> Final training Epoch [28/100], Loss: 0.4171
	--> Final training Epoch [29/100], Loss: 0.4139
	--> Final training Epoch [30/100], Loss: 0.3769
	--> Final training Epoch [31/100], Loss: 0.3877
	--> Final training Epoch [32/100], Loss: 0.3709
	--> Final training Epoch [33/100], Loss: 0.3787
	--> Final training Epoch [34/100], Loss: 0.3795
	--> Final training Epoch [35/100], Loss: 0.3808
	--> Final training Epoch [36/100], Loss: 0.3551
	--> Final training Epoch [37/100], Loss: 0.3465
	--> Final training Epoch [38/100], Loss: 0.3169
	--> Final training Epoch [39/100], Loss: 0.3384
	--> Final training Epoch [40/100], Loss: 0.3270
	--> Final training Epoch [41/100], Loss: 0.3376
	--> Final training Epoch [42/100], Loss: 0.2995
	--> Final training Epoch [43/100], Loss: 0.3266
	--> Final training Epoch [44/100], Loss: 0.3048
	--> Final training Epoch [45/100], Loss: 0.2785
	--> Final training Epoch [46/100], Loss: 0.3030
	--> Final training Epoch [47/100], Loss: 0.2704
	--> Final training Epoch [48/100], Loss: 0.2898
	--> Final training Epoch [49/100], Loss: 0.2781
	--> Final training Epoch [50/100], Loss: 0.2728
	--> Final training Epoch [51/100], Loss: 0.2897
	--> Final training Epoch [52/100], Loss: 0.2391
	--> Final training Epoch [53/100], Loss: 0.2440
	--> Final training Epoch [54/100], Loss: 0.2556
	--> Final training Epoch [55/100], Loss: 0.2427
	--> Final training Epoch [56/100], Loss: 0.2588
	--> Final training Epoch [57/100], Loss: 0.2314
	--> Final training Epoch [58/100], Loss: 0.2302
	--> Final training Epoch [59/100], Loss: 0.2232
	--> Final training Epoch [60/100], Loss: 0.2343
	--> Final training Epoch [61/100], Loss: 0.2313
	--> Final training Epoch [62/100], Loss: 0.2172
	--> Final training Epoch [63/100], Loss: 0.2153
	--> Final training Epoch [64/100], Loss: 0.2223
	--> Final training Epoch [65/100], Loss: 0.2013
	--> Final training Epoch [66/100], Loss: 0.2094
	--> Final training Epoch [67/100], Loss: 0.2033
	--> Final training Epoch [68/100], Loss: 0.1871
	--> Final training Epoch [69/100], Loss: 0.1919
	--> Final training Epoch [70/100], Loss: 0.1967
	--> Final training Epoch [71/100], Loss: 0.1905
	--> Final training Epoch [72/100], Loss: 0.1865
	--> Final training Epoch [73/100], Loss: 0.1710
	--> Final training Epoch [74/100], Loss: 0.1627
	--> Final training Epoch [75/100], Loss: 0.1774
	--> Final training Epoch [76/100], Loss: 0.1806
	--> Final training Epoch [77/100], Loss: 0.1552
	--> Final training Epoch [78/100], Loss: 0.1739
	--> Final training Epoch [79/100], Loss: 0.1977
	--> Final training Epoch [80/100], Loss: 0.1710
	--> Final training Epoch [81/100], Loss: 0.1616
	--> Final training Epoch [82/100], Loss: 0.1689
	--> Final training Epoch [83/100], Loss: 0.1544
	--> Final training Epoch [84/100], Loss: 0.1688
	--> Final training Epoch [85/100], Loss: 0.1626
	--> Final training Epoch [86/100], Loss: 0.1455
	--> Final training Epoch [87/100], Loss: 0.1429
	--> Final training Epoch [88/100], Loss: 0.1361
	--> Final training Epoch [89/100], Loss: 0.1480
	--> Final training Epoch [90/100], Loss: 0.1460
	--> Final training Epoch [91/100], Loss: 0.1415
	--> Final training Epoch [92/100], Loss: 0.1580
	--> Final training Epoch [93/100], Loss: 0.1149
	--> Final training Epoch [94/100], Loss: 0.1221
	--> Final training Epoch [95/100], Loss: 0.1386
	--> Final training Epoch [96/100], Loss: 0.1388
	--> Final training Epoch [97/100], Loss: 0.1554
	--> Final training Epoch [98/100], Loss: 0.1248
	--> Final training Epoch [99/100], Loss: 0.1188
	--> Final training Epoch [100/100], Loss: 0.1405

Final training took 0.36170434951782227 sec

TESTING
	--> Testing took 0.0092 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8360
	--> Final Precision: 0.6923
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6923
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3812,  Current Best Accuracy: 0.8807,  Current Best Validation Loss: 0.3812

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7860, Validation Loss: 0.5563
	--> Epoch [2/100], Loss: 0.7775, Validation Loss: 0.5363
	--> Epoch [3/100], Loss: 0.7264, Validation Loss: 0.5187
	--> Epoch [4/100], Loss: 0.6682, Validation Loss: 0.5023
	--> Epoch [5/100], Loss: 0.6934, Validation Loss: 0.4824
	--> Epoch [6/100], Loss: 0.6701, Validation Loss: 0.4696
	--> Epoch [7/100], Loss: 0.6057, Validation Loss: 0.4584
	--> Epoch [8/100], Loss: 0.5935, Validation Loss: 0.4485
	--> Epoch [9/100], Loss: 0.5805, Validation Loss: 0.4346
	--> Epoch [10/100], Loss: 0.5685, Validation Loss: 0.4253
	--> Epoch [11/100], Loss: 0.5133, Validation Loss: 0.4175
	--> Epoch [12/100], Loss: 0.5161, Validation Loss: 0.4102
	--> Epoch [13/100], Loss: 0.5139, Validation Loss: 0.4035
	--> Epoch [14/100], Loss: 0.4897, Validation Loss: 0.3975
	--> Epoch [15/100], Loss: 0.4828, Validation Loss: 0.3907
	--> Epoch [16/100], Loss: 0.4622, Validation Loss: 0.3863
	--> Epoch [17/100], Loss: 0.4632, Validation Loss: 0.3810
	--> Epoch [18/100], Loss: 0.4332, Validation Loss: 0.3741
	--> Epoch [19/100], Loss: 0.4544, Validation Loss: 0.3693
	--> Epoch [20/100], Loss: 0.4070, Validation Loss: 0.3634
	--> Epoch [21/100], Loss: 0.4151, Validation Loss: 0.3579
	--> Epoch [22/100], Loss: 0.4167, Validation Loss: 0.3536
	--> Epoch [23/100], Loss: 0.3940, Validation Loss: 0.3488
	--> Epoch [24/100], Loss: 0.3859, Validation Loss: 0.3437
	--> Epoch [25/100], Loss: 0.3660, Validation Loss: 0.3392
	--> Epoch [26/100], Loss: 0.3964, Validation Loss: 0.3355
	--> Epoch [27/100], Loss: 0.3443, Validation Loss: 0.3319
	--> Epoch [28/100], Loss: 0.3878, Validation Loss: 0.3285
	--> Epoch [29/100], Loss: 0.3554, Validation Loss: 0.3256
	--> Epoch [30/100], Loss: 0.3397, Validation Loss: 0.3220
	--> Epoch [31/100], Loss: 0.3222, Validation Loss: 0.3190
	--> Epoch [32/100], Loss: 0.3249, Validation Loss: 0.3158
	--> Epoch [33/100], Loss: 0.3343, Validation Loss: 0.3126
	--> Epoch [34/100], Loss: 0.3264, Validation Loss: 0.3097
	--> Epoch [35/100], Loss: 0.3141, Validation Loss: 0.3070
	--> Epoch [36/100], Loss: 0.2972, Validation Loss: 0.3039
	--> Epoch [37/100], Loss: 0.3250, Validation Loss: 0.3009
	--> Epoch [38/100], Loss: 0.3051, Validation Loss: 0.2988
	--> Epoch [39/100], Loss: 0.2975, Validation Loss: 0.2967
	--> Epoch [40/100], Loss: 0.2819, Validation Loss: 0.2948
	--> Epoch [41/100], Loss: 0.2838, Validation Loss: 0.2931
	--> Epoch [42/100], Loss: 0.3011, Validation Loss: 0.2908
	--> Epoch [43/100], Loss: 0.2745, Validation Loss: 0.2885
	--> Epoch [44/100], Loss: 0.2854, Validation Loss: 0.2863
	--> Epoch [45/100], Loss: 0.2468, Validation Loss: 0.2855
	--> Epoch [46/100], Loss: 0.2465, Validation Loss: 0.2833
	--> Epoch [47/100], Loss: 0.2610, Validation Loss: 0.2811
	--> Epoch [48/100], Loss: 0.2324, Validation Loss: 0.2799
	--> Epoch [49/100], Loss: 0.2437, Validation Loss: 0.2779
	--> Epoch [50/100], Loss: 0.2607, Validation Loss: 0.2757
	--> Epoch [51/100], Loss: 0.2310, Validation Loss: 0.2740
	--> Epoch [52/100], Loss: 0.2271, Validation Loss: 0.2739
	--> Epoch [53/100], Loss: 0.2325, Validation Loss: 0.2720
	--> Epoch [54/100], Loss: 0.2300, Validation Loss: 0.2694
	--> Epoch [55/100], Loss: 0.2011, Validation Loss: 0.2688
	--> Epoch [56/100], Loss: 0.2133, Validation Loss: 0.2673
	--> Epoch [57/100], Loss: 0.2020, Validation Loss: 0.2660
	--> Epoch [58/100], Loss: 0.1950, Validation Loss: 0.2636
	--> Epoch [59/100], Loss: 0.2063, Validation Loss: 0.2628
	--> Epoch [60/100], Loss: 0.2204, Validation Loss: 0.2611
	--> Epoch [61/100], Loss: 0.2310, Validation Loss: 0.2602
	--> Epoch [62/100], Loss: 0.2209, Validation Loss: 0.2591
	--> Epoch [63/100], Loss: 0.2047, Validation Loss: 0.2578
	--> Epoch [64/100], Loss: 0.2111, Validation Loss: 0.2561
	--> Epoch [65/100], Loss: 0.2087, Validation Loss: 0.2548
	--> Epoch [66/100], Loss: 0.1910, Validation Loss: 0.2531
	--> Epoch [67/100], Loss: 0.1916, Validation Loss: 0.2519
	--> Epoch [68/100], Loss: 0.2019, Validation Loss: 0.2521
	--> Epoch [69/100], Loss: 0.1962, Validation Loss: 0.2511
	--> Epoch [70/100], Loss: 0.1791, Validation Loss: 0.2508
	--> Epoch [71/100], Loss: 0.1649, Validation Loss: 0.2496
	--> Epoch [72/100], Loss: 0.1602, Validation Loss: 0.2491
	--> Epoch [73/100], Loss: 0.1943, Validation Loss: 0.2470
	--> Epoch [74/100], Loss: 0.1656, Validation Loss: 0.2460
	--> Epoch [75/100], Loss: 0.1868, Validation Loss: 0.2446
	--> Epoch [76/100], Loss: 0.1674, Validation Loss: 0.2432
	--> Epoch [77/100], Loss: 0.1540, Validation Loss: 0.2432
	--> Epoch [78/100], Loss: 0.1784, Validation Loss: 0.2432
	--> Epoch [79/100], Loss: 0.1551, Validation Loss: 0.2431
	--> Epoch [80/100], Loss: 0.1562, Validation Loss: 0.2423
	--> Epoch [81/100], Loss: 0.1736, Validation Loss: 0.2414
	--> Epoch [82/100], Loss: 0.1765, Validation Loss: 0.2407
	--> Epoch [83/100], Loss: 0.1609, Validation Loss: 0.2412
	--> Epoch [84/100], Loss: 0.1585, Validation Loss: 0.2406
	--> Epoch [85/100], Loss: 0.1441, Validation Loss: 0.2407
	--> Epoch [86/100], Loss: 0.1324, Validation Loss: 0.2406
	--> Epoch [87/100], Loss: 0.2005, Validation Loss: 0.2397
	--> Epoch [88/100], Loss: 0.1260, Validation Loss: 0.2378
	--> Epoch [89/100], Loss: 0.1361, Validation Loss: 0.2376
	--> Epoch [90/100], Loss: 0.1421, Validation Loss: 0.2374
	--> Epoch [91/100], Loss: 0.1631, Validation Loss: 0.2365
	--> Epoch [92/100], Loss: 0.1299, Validation Loss: 0.2361
	--> Epoch [93/100], Loss: 0.1687, Validation Loss: 0.2356
	--> Epoch [94/100], Loss: 0.1690, Validation Loss: 0.2350
	--> Epoch [95/100], Loss: 0.1255, Validation Loss: 0.2349
	--> Epoch [96/100], Loss: 0.1455, Validation Loss: 0.2349
	--> Epoch [97/100], Loss: 0.1451, Validation Loss: 0.2340
	--> Epoch [98/100], Loss: 0.1401, Validation Loss: 0.2334
	--> Epoch [99/100], Loss: 0.1628, Validation Loss: 0.2333
	--> Epoch [100/100], Loss: 0.1135, Validation Loss: 0.2329
	--> Training for Fold 1 took 0.38200879096984863 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7265, Validation Loss: 0.6560
	--> Epoch [2/100], Loss: 0.6884, Validation Loss: 0.6244
	--> Epoch [3/100], Loss: 0.6614, Validation Loss: 0.5926
	--> Epoch [4/100], Loss: 0.6669, Validation Loss: 0.5581
	--> Epoch [5/100], Loss: 0.6189, Validation Loss: 0.5334
	--> Epoch [6/100], Loss: 0.6047, Validation Loss: 0.5117
	--> Epoch [7/100], Loss: 0.5739, Validation Loss: 0.4912
	--> Epoch [8/100], Loss: 0.5702, Validation Loss: 0.4745
	--> Epoch [9/100], Loss: 0.5417, Validation Loss: 0.4597
	--> Epoch [10/100], Loss: 0.5460, Validation Loss: 0.4464
	--> Epoch [11/100], Loss: 0.5063, Validation Loss: 0.4336
	--> Epoch [12/100], Loss: 0.5008, Validation Loss: 0.4225
	--> Epoch [13/100], Loss: 0.4973, Validation Loss: 0.4122
	--> Epoch [14/100], Loss: 0.4908, Validation Loss: 0.4044
	--> Epoch [15/100], Loss: 0.4600, Validation Loss: 0.3955
	--> Epoch [16/100], Loss: 0.4618, Validation Loss: 0.3880
	--> Epoch [17/100], Loss: 0.4554, Validation Loss: 0.3806
	--> Epoch [18/100], Loss: 0.4725, Validation Loss: 0.3726
	--> Epoch [19/100], Loss: 0.4319, Validation Loss: 0.3669
	--> Epoch [20/100], Loss: 0.4249, Validation Loss: 0.3601
	--> Epoch [21/100], Loss: 0.4246, Validation Loss: 0.3548
	--> Epoch [22/100], Loss: 0.4056, Validation Loss: 0.3476
	--> Epoch [23/100], Loss: 0.4024, Validation Loss: 0.3416
	--> Epoch [24/100], Loss: 0.3880, Validation Loss: 0.3360
	--> Epoch [25/100], Loss: 0.3866, Validation Loss: 0.3298
	--> Epoch [26/100], Loss: 0.3822, Validation Loss: 0.3251
	--> Epoch [27/100], Loss: 0.3553, Validation Loss: 0.3204
	--> Epoch [28/100], Loss: 0.3508, Validation Loss: 0.3144
	--> Epoch [29/100], Loss: 0.3495, Validation Loss: 0.3087
	--> Epoch [30/100], Loss: 0.3391, Validation Loss: 0.3051
	--> Epoch [31/100], Loss: 0.3324, Validation Loss: 0.3015
	--> Epoch [32/100], Loss: 0.3153, Validation Loss: 0.2978
	--> Epoch [33/100], Loss: 0.3344, Validation Loss: 0.2943
	--> Epoch [34/100], Loss: 0.3259, Validation Loss: 0.2900
	--> Epoch [35/100], Loss: 0.3109, Validation Loss: 0.2877
	--> Epoch [36/100], Loss: 0.2955, Validation Loss: 0.2841
	--> Epoch [37/100], Loss: 0.3005, Validation Loss: 0.2806
	--> Epoch [38/100], Loss: 0.2711, Validation Loss: 0.2792
	--> Epoch [39/100], Loss: 0.2835, Validation Loss: 0.2756
	--> Epoch [40/100], Loss: 0.2811, Validation Loss: 0.2732
	--> Epoch [41/100], Loss: 0.2657, Validation Loss: 0.2710
	--> Epoch [42/100], Loss: 0.2715, Validation Loss: 0.2677
	--> Epoch [43/100], Loss: 0.2285, Validation Loss: 0.2647
	--> Epoch [44/100], Loss: 0.2562, Validation Loss: 0.2618
	--> Epoch [45/100], Loss: 0.2645, Validation Loss: 0.2593
	--> Epoch [46/100], Loss: 0.2324, Validation Loss: 0.2581
	--> Epoch [47/100], Loss: 0.2460, Validation Loss: 0.2561
	--> Epoch [48/100], Loss: 0.1972, Validation Loss: 0.2541
	--> Epoch [49/100], Loss: 0.2264, Validation Loss: 0.2526
	--> Epoch [50/100], Loss: 0.2174, Validation Loss: 0.2513
	--> Epoch [51/100], Loss: 0.2436, Validation Loss: 0.2489
	--> Epoch [52/100], Loss: 0.2145, Validation Loss: 0.2480
	--> Epoch [53/100], Loss: 0.2067, Validation Loss: 0.2469
	--> Epoch [54/100], Loss: 0.1871, Validation Loss: 0.2453
	--> Epoch [55/100], Loss: 0.1845, Validation Loss: 0.2435
	--> Epoch [56/100], Loss: 0.2025, Validation Loss: 0.2413
	--> Epoch [57/100], Loss: 0.2037, Validation Loss: 0.2393
	--> Epoch [58/100], Loss: 0.2005, Validation Loss: 0.2377
	--> Epoch [59/100], Loss: 0.1875, Validation Loss: 0.2367
	--> Epoch [60/100], Loss: 0.2173, Validation Loss: 0.2356
	--> Epoch [61/100], Loss: 0.2065, Validation Loss: 0.2337
	--> Epoch [62/100], Loss: 0.1809, Validation Loss: 0.2320
	--> Epoch [63/100], Loss: 0.1663, Validation Loss: 0.2303
	--> Epoch [64/100], Loss: 0.1925, Validation Loss: 0.2283
	--> Epoch [65/100], Loss: 0.1817, Validation Loss: 0.2272
	--> Epoch [66/100], Loss: 0.1544, Validation Loss: 0.2252
	--> Epoch [67/100], Loss: 0.1644, Validation Loss: 0.2239
	--> Epoch [68/100], Loss: 0.1492, Validation Loss: 0.2232
	--> Epoch [69/100], Loss: 0.1776, Validation Loss: 0.2216
	--> Epoch [70/100], Loss: 0.1411, Validation Loss: 0.2206
	--> Epoch [71/100], Loss: 0.1525, Validation Loss: 0.2191
	--> Epoch [72/100], Loss: 0.1327, Validation Loss: 0.2178
	--> Epoch [73/100], Loss: 0.1530, Validation Loss: 0.2169
	--> Epoch [74/100], Loss: 0.1499, Validation Loss: 0.2162
	--> Epoch [75/100], Loss: 0.1339, Validation Loss: 0.2158
	--> Epoch [76/100], Loss: 0.1347, Validation Loss: 0.2143
	--> Epoch [77/100], Loss: 0.1558, Validation Loss: 0.2133
	--> Epoch [78/100], Loss: 0.1325, Validation Loss: 0.2116
	--> Epoch [79/100], Loss: 0.1326, Validation Loss: 0.2109
	--> Epoch [80/100], Loss: 0.1248, Validation Loss: 0.2096
	--> Epoch [81/100], Loss: 0.1359, Validation Loss: 0.2091
	--> Epoch [82/100], Loss: 0.1237, Validation Loss: 0.2083
	--> Epoch [83/100], Loss: 0.1300, Validation Loss: 0.2065
	--> Epoch [84/100], Loss: 0.1331, Validation Loss: 0.2055
	--> Epoch [85/100], Loss: 0.1467, Validation Loss: 0.2051
	--> Epoch [86/100], Loss: 0.1560, Validation Loss: 0.2038
	--> Epoch [87/100], Loss: 0.1014, Validation Loss: 0.2035
	--> Epoch [88/100], Loss: 0.0880, Validation Loss: 0.2029
	--> Epoch [89/100], Loss: 0.1148, Validation Loss: 0.2017
	--> Epoch [90/100], Loss: 0.1334, Validation Loss: 0.2014
	--> Epoch [91/100], Loss: 0.1091, Validation Loss: 0.2011
	--> Epoch [92/100], Loss: 0.0897, Validation Loss: 0.1998
	--> Epoch [93/100], Loss: 0.1190, Validation Loss: 0.1984
	--> Epoch [94/100], Loss: 0.1046, Validation Loss: 0.1988
	--> Epoch [95/100], Loss: 0.1093, Validation Loss: 0.1974
	--> Epoch [96/100], Loss: 0.1164, Validation Loss: 0.1961
	--> Epoch [97/100], Loss: 0.1150, Validation Loss: 0.1948
	--> Epoch [98/100], Loss: 0.1057, Validation Loss: 0.1946
	--> Epoch [99/100], Loss: 0.1001, Validation Loss: 0.1938
	--> Epoch [100/100], Loss: 0.0885, Validation Loss: 0.1937
	--> Training for Fold 2 took 0.3833796977996826 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7117, Validation Loss: 0.6516
	--> Epoch [2/100], Loss: 0.6616, Validation Loss: 0.6445
	--> Epoch [3/100], Loss: 0.6434, Validation Loss: 0.6377
	--> Epoch [4/100], Loss: 0.6182, Validation Loss: 0.6335
	--> Epoch [5/100], Loss: 0.6157, Validation Loss: 0.6287
	--> Epoch [6/100], Loss: 0.5942, Validation Loss: 0.6215
	--> Epoch [7/100], Loss: 0.5940, Validation Loss: 0.6138
	--> Epoch [8/100], Loss: 0.6046, Validation Loss: 0.6072
	--> Epoch [9/100], Loss: 0.5578, Validation Loss: 0.5993
	--> Epoch [10/100], Loss: 0.5535, Validation Loss: 0.5928
	--> Epoch [11/100], Loss: 0.5458, Validation Loss: 0.5860
	--> Epoch [12/100], Loss: 0.5279, Validation Loss: 0.5768
	--> Epoch [13/100], Loss: 0.5263, Validation Loss: 0.5708
	--> Epoch [14/100], Loss: 0.5200, Validation Loss: 0.5647
	--> Epoch [15/100], Loss: 0.4974, Validation Loss: 0.5568
	--> Epoch [16/100], Loss: 0.4810, Validation Loss: 0.5510
	--> Epoch [17/100], Loss: 0.4502, Validation Loss: 0.5439
	--> Epoch [18/100], Loss: 0.4673, Validation Loss: 0.5392
	--> Epoch [19/100], Loss: 0.4702, Validation Loss: 0.5328
	--> Epoch [20/100], Loss: 0.4168, Validation Loss: 0.5257
	--> Epoch [21/100], Loss: 0.4239, Validation Loss: 0.5197
	--> Epoch [22/100], Loss: 0.4110, Validation Loss: 0.5146
	--> Epoch [23/100], Loss: 0.3864, Validation Loss: 0.5108
	--> Epoch [24/100], Loss: 0.4251, Validation Loss: 0.5059
	--> Epoch [25/100], Loss: 0.3943, Validation Loss: 0.5047
	--> Epoch [26/100], Loss: 0.3773, Validation Loss: 0.4995
	--> Epoch [27/100], Loss: 0.3476, Validation Loss: 0.4950
	--> Epoch [28/100], Loss: 0.3568, Validation Loss: 0.4896
	--> Epoch [29/100], Loss: 0.3821, Validation Loss: 0.4859
	--> Epoch [30/100], Loss: 0.3261, Validation Loss: 0.4820
	--> Epoch [31/100], Loss: 0.3522, Validation Loss: 0.4786
	--> Epoch [32/100], Loss: 0.3172, Validation Loss: 0.4742
	--> Epoch [33/100], Loss: 0.3144, Validation Loss: 0.4698
	--> Epoch [34/100], Loss: 0.2921, Validation Loss: 0.4661
	--> Epoch [35/100], Loss: 0.3135, Validation Loss: 0.4628
	--> Epoch [36/100], Loss: 0.2972, Validation Loss: 0.4574
	--> Epoch [37/100], Loss: 0.2835, Validation Loss: 0.4539
	--> Epoch [38/100], Loss: 0.2876, Validation Loss: 0.4492
	--> Epoch [39/100], Loss: 0.2849, Validation Loss: 0.4460
	--> Epoch [40/100], Loss: 0.2807, Validation Loss: 0.4426
	--> Epoch [41/100], Loss: 0.2801, Validation Loss: 0.4389
	--> Epoch [42/100], Loss: 0.2731, Validation Loss: 0.4366
	--> Epoch [43/100], Loss: 0.2316, Validation Loss: 0.4345
	--> Epoch [44/100], Loss: 0.2776, Validation Loss: 0.4319
	--> Epoch [45/100], Loss: 0.2477, Validation Loss: 0.4285
	--> Epoch [46/100], Loss: 0.2558, Validation Loss: 0.4252
	--> Epoch [47/100], Loss: 0.2070, Validation Loss: 0.4226
	--> Epoch [48/100], Loss: 0.2422, Validation Loss: 0.4204
	--> Epoch [49/100], Loss: 0.2592, Validation Loss: 0.4172
	--> Epoch [50/100], Loss: 0.2122, Validation Loss: 0.4146
	--> Epoch [51/100], Loss: 0.2260, Validation Loss: 0.4120
	--> Epoch [52/100], Loss: 0.2326, Validation Loss: 0.4089
	--> Epoch [53/100], Loss: 0.2083, Validation Loss: 0.4048
	--> Epoch [54/100], Loss: 0.2302, Validation Loss: 0.4029
	--> Epoch [55/100], Loss: 0.2453, Validation Loss: 0.4010
	--> Epoch [56/100], Loss: 0.2264, Validation Loss: 0.3978
	--> Epoch [57/100], Loss: 0.1663, Validation Loss: 0.3949
	--> Epoch [58/100], Loss: 0.1710, Validation Loss: 0.3932
	--> Epoch [59/100], Loss: 0.1888, Validation Loss: 0.3920
	--> Epoch [60/100], Loss: 0.1863, Validation Loss: 0.3899
	--> Epoch [61/100], Loss: 0.2075, Validation Loss: 0.3890
	--> Epoch [62/100], Loss: 0.1681, Validation Loss: 0.3859
	--> Epoch [63/100], Loss: 0.1643, Validation Loss: 0.3846
	--> Epoch [64/100], Loss: 0.1786, Validation Loss: 0.3835
	--> Epoch [65/100], Loss: 0.1630, Validation Loss: 0.3803
	--> Epoch [66/100], Loss: 0.1670, Validation Loss: 0.3777
	--> Epoch [67/100], Loss: 0.1716, Validation Loss: 0.3756
	--> Epoch [68/100], Loss: 0.1448, Validation Loss: 0.3743
	--> Epoch [69/100], Loss: 0.1587, Validation Loss: 0.3718
	--> Epoch [70/100], Loss: 0.1659, Validation Loss: 0.3712
	--> Epoch [71/100], Loss: 0.1633, Validation Loss: 0.3699
	--> Epoch [72/100], Loss: 0.1395, Validation Loss: 0.3680
	--> Epoch [73/100], Loss: 0.1391, Validation Loss: 0.3666
	--> Epoch [74/100], Loss: 0.1464, Validation Loss: 0.3647
	--> Epoch [75/100], Loss: 0.1574, Validation Loss: 0.3632
	--> Epoch [76/100], Loss: 0.1738, Validation Loss: 0.3614
	--> Epoch [77/100], Loss: 0.1360, Validation Loss: 0.3604
	--> Epoch [78/100], Loss: 0.1132, Validation Loss: 0.3589
	--> Epoch [79/100], Loss: 0.1310, Validation Loss: 0.3578
	--> Epoch [80/100], Loss: 0.1408, Validation Loss: 0.3568
	--> Epoch [81/100], Loss: 0.1344, Validation Loss: 0.3557
	--> Epoch [82/100], Loss: 0.1531, Validation Loss: 0.3543
	--> Epoch [83/100], Loss: 0.1208, Validation Loss: 0.3541
	--> Epoch [84/100], Loss: 0.1401, Validation Loss: 0.3537
	--> Epoch [85/100], Loss: 0.1015, Validation Loss: 0.3533
	--> Epoch [86/100], Loss: 0.1332, Validation Loss: 0.3525
	--> Epoch [87/100], Loss: 0.1069, Validation Loss: 0.3508
	--> Epoch [88/100], Loss: 0.1261, Validation Loss: 0.3501
	--> Epoch [89/100], Loss: 0.1296, Validation Loss: 0.3491
	--> Epoch [90/100], Loss: 0.1136, Validation Loss: 0.3478
	--> Epoch [91/100], Loss: 0.1242, Validation Loss: 0.3468
	--> Epoch [92/100], Loss: 0.1014, Validation Loss: 0.3465
	--> Epoch [93/100], Loss: 0.1133, Validation Loss: 0.3464
	--> Epoch [94/100], Loss: 0.1319, Validation Loss: 0.3460
	--> Epoch [95/100], Loss: 0.1138, Validation Loss: 0.3448
	--> Epoch [96/100], Loss: 0.1244, Validation Loss: 0.3447
	--> Epoch [97/100], Loss: 0.1115, Validation Loss: 0.3438
	--> Epoch [98/100], Loss: 0.0961, Validation Loss: 0.3443
	--> Epoch [99/100], Loss: 0.0911, Validation Loss: 0.3430
	--> Epoch [100/100], Loss: 0.1015, Validation Loss: 0.3419
	--> Training for Fold 3 took 0.4637722969055176 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7067, Validation Loss: 0.6193
	--> Epoch [2/100], Loss: 0.7126, Validation Loss: 0.6090
	--> Epoch [3/100], Loss: 0.6807, Validation Loss: 0.5979
	--> Epoch [4/100], Loss: 0.6553, Validation Loss: 0.5891
	--> Epoch [5/100], Loss: 0.6322, Validation Loss: 0.5792
	--> Epoch [6/100], Loss: 0.6453, Validation Loss: 0.5718
	--> Epoch [7/100], Loss: 0.6127, Validation Loss: 0.5642
	--> Epoch [8/100], Loss: 0.5960, Validation Loss: 0.5554
	--> Epoch [9/100], Loss: 0.5829, Validation Loss: 0.5486
	--> Epoch [10/100], Loss: 0.5647, Validation Loss: 0.5418
	--> Epoch [11/100], Loss: 0.5476, Validation Loss: 0.5336
	--> Epoch [12/100], Loss: 0.5314, Validation Loss: 0.5263
	--> Epoch [13/100], Loss: 0.5353, Validation Loss: 0.5193
	--> Epoch [14/100], Loss: 0.5202, Validation Loss: 0.5135
	--> Epoch [15/100], Loss: 0.4997, Validation Loss: 0.5080
	--> Epoch [16/100], Loss: 0.4855, Validation Loss: 0.5024
	--> Epoch [17/100], Loss: 0.4829, Validation Loss: 0.4986
	--> Epoch [18/100], Loss: 0.4772, Validation Loss: 0.4928
	--> Epoch [19/100], Loss: 0.4705, Validation Loss: 0.4888
	--> Epoch [20/100], Loss: 0.4538, Validation Loss: 0.4832
	--> Epoch [21/100], Loss: 0.4576, Validation Loss: 0.4785
	--> Epoch [22/100], Loss: 0.4082, Validation Loss: 0.4722
	--> Epoch [23/100], Loss: 0.4075, Validation Loss: 0.4668
	--> Epoch [24/100], Loss: 0.4045, Validation Loss: 0.4620
	--> Epoch [25/100], Loss: 0.4184, Validation Loss: 0.4581
	--> Epoch [26/100], Loss: 0.3850, Validation Loss: 0.4525
	--> Epoch [27/100], Loss: 0.3962, Validation Loss: 0.4475
	--> Epoch [28/100], Loss: 0.3842, Validation Loss: 0.4430
	--> Epoch [29/100], Loss: 0.3776, Validation Loss: 0.4378
	--> Epoch [30/100], Loss: 0.3778, Validation Loss: 0.4331
	--> Epoch [31/100], Loss: 0.3320, Validation Loss: 0.4298
	--> Epoch [32/100], Loss: 0.3648, Validation Loss: 0.4257
	--> Epoch [33/100], Loss: 0.3401, Validation Loss: 0.4220
	--> Epoch [34/100], Loss: 0.3196, Validation Loss: 0.4175
	--> Epoch [35/100], Loss: 0.3204, Validation Loss: 0.4133
	--> Epoch [36/100], Loss: 0.3409, Validation Loss: 0.4103
	--> Epoch [37/100], Loss: 0.3081, Validation Loss: 0.4065
	--> Epoch [38/100], Loss: 0.2943, Validation Loss: 0.4017
	--> Epoch [39/100], Loss: 0.2769, Validation Loss: 0.3986
	--> Epoch [40/100], Loss: 0.2680, Validation Loss: 0.3961
	--> Epoch [41/100], Loss: 0.2750, Validation Loss: 0.3934
	--> Epoch [42/100], Loss: 0.2661, Validation Loss: 0.3903
	--> Epoch [43/100], Loss: 0.2801, Validation Loss: 0.3870
	--> Epoch [44/100], Loss: 0.2657, Validation Loss: 0.3846
	--> Epoch [45/100], Loss: 0.2518, Validation Loss: 0.3820
	--> Epoch [46/100], Loss: 0.2374, Validation Loss: 0.3793
	--> Epoch [47/100], Loss: 0.2346, Validation Loss: 0.3761
	--> Epoch [48/100], Loss: 0.2776, Validation Loss: 0.3725
	--> Epoch [49/100], Loss: 0.2188, Validation Loss: 0.3720
	--> Epoch [50/100], Loss: 0.2387, Validation Loss: 0.3679
	--> Epoch [51/100], Loss: 0.2449, Validation Loss: 0.3669
	--> Epoch [52/100], Loss: 0.2495, Validation Loss: 0.3637
	--> Epoch [53/100], Loss: 0.2410, Validation Loss: 0.3608
	--> Epoch [54/100], Loss: 0.2187, Validation Loss: 0.3589
	--> Epoch [55/100], Loss: 0.2077, Validation Loss: 0.3570
	--> Epoch [56/100], Loss: 0.2186, Validation Loss: 0.3547
	--> Epoch [57/100], Loss: 0.2239, Validation Loss: 0.3541
	--> Epoch [58/100], Loss: 0.1965, Validation Loss: 0.3523
	--> Epoch [59/100], Loss: 0.2147, Validation Loss: 0.3500
	--> Epoch [60/100], Loss: 0.1910, Validation Loss: 0.3487
	--> Epoch [61/100], Loss: 0.1705, Validation Loss: 0.3478
	--> Epoch [62/100], Loss: 0.1910, Validation Loss: 0.3471
	--> Epoch [63/100], Loss: 0.1915, Validation Loss: 0.3448
	--> Epoch [64/100], Loss: 0.2007, Validation Loss: 0.3426
	--> Epoch [65/100], Loss: 0.1604, Validation Loss: 0.3414
	--> Epoch [66/100], Loss: 0.1692, Validation Loss: 0.3400
	--> Epoch [67/100], Loss: 0.1576, Validation Loss: 0.3394
	--> Epoch [68/100], Loss: 0.1514, Validation Loss: 0.3388
	--> Epoch [69/100], Loss: 0.1666, Validation Loss: 0.3369
	--> Epoch [70/100], Loss: 0.1309, Validation Loss: 0.3363
	--> Epoch [71/100], Loss: 0.1725, Validation Loss: 0.3356
	--> Epoch [72/100], Loss: 0.1827, Validation Loss: 0.3342
	--> Epoch [73/100], Loss: 0.1612, Validation Loss: 0.3329
	--> Epoch [74/100], Loss: 0.1652, Validation Loss: 0.3317
	--> Epoch [75/100], Loss: 0.1501, Validation Loss: 0.3300
	--> Epoch [76/100], Loss: 0.1357, Validation Loss: 0.3286
	--> Epoch [77/100], Loss: 0.1683, Validation Loss: 0.3271
	--> Epoch [78/100], Loss: 0.1315, Validation Loss: 0.3255
	--> Epoch [79/100], Loss: 0.1585, Validation Loss: 0.3258
	--> Epoch [80/100], Loss: 0.1458, Validation Loss: 0.3257
	--> Epoch [81/100], Loss: 0.1640, Validation Loss: 0.3259
Early stopping
	--> Training for Fold 4 took 0.30855393409729004 sec, using 81 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7504, Validation Loss: 0.6337
	--> Epoch [2/100], Loss: 0.6963, Validation Loss: 0.6228
	--> Epoch [3/100], Loss: 0.7116, Validation Loss: 0.6135
	--> Epoch [4/100], Loss: 0.6559, Validation Loss: 0.6043
	--> Epoch [5/100], Loss: 0.6507, Validation Loss: 0.5956
	--> Epoch [6/100], Loss: 0.6587, Validation Loss: 0.5881
	--> Epoch [7/100], Loss: 0.6064, Validation Loss: 0.5806
	--> Epoch [8/100], Loss: 0.6092, Validation Loss: 0.5719
	--> Epoch [9/100], Loss: 0.5997, Validation Loss: 0.5658
	--> Epoch [10/100], Loss: 0.5935, Validation Loss: 0.5603
	--> Epoch [11/100], Loss: 0.5811, Validation Loss: 0.5530
	--> Epoch [12/100], Loss: 0.5677, Validation Loss: 0.5489
	--> Epoch [13/100], Loss: 0.5639, Validation Loss: 0.5454
	--> Epoch [14/100], Loss: 0.5534, Validation Loss: 0.5387
	--> Epoch [15/100], Loss: 0.5148, Validation Loss: 0.5344
	--> Epoch [16/100], Loss: 0.5143, Validation Loss: 0.5303
	--> Epoch [17/100], Loss: 0.4970, Validation Loss: 0.5265
	--> Epoch [18/100], Loss: 0.4996, Validation Loss: 0.5230
	--> Epoch [19/100], Loss: 0.4916, Validation Loss: 0.5179
	--> Epoch [20/100], Loss: 0.4891, Validation Loss: 0.5134
	--> Epoch [21/100], Loss: 0.4835, Validation Loss: 0.5091
	--> Epoch [22/100], Loss: 0.4440, Validation Loss: 0.5057
	--> Epoch [23/100], Loss: 0.4372, Validation Loss: 0.5009
	--> Epoch [24/100], Loss: 0.4185, Validation Loss: 0.4963
	--> Epoch [25/100], Loss: 0.4378, Validation Loss: 0.4920
	--> Epoch [26/100], Loss: 0.4334, Validation Loss: 0.4880
	--> Epoch [27/100], Loss: 0.4329, Validation Loss: 0.4847
	--> Epoch [28/100], Loss: 0.3998, Validation Loss: 0.4812
	--> Epoch [29/100], Loss: 0.3896, Validation Loss: 0.4789
	--> Epoch [30/100], Loss: 0.3820, Validation Loss: 0.4757
	--> Epoch [31/100], Loss: 0.3818, Validation Loss: 0.4730
	--> Epoch [32/100], Loss: 0.3924, Validation Loss: 0.4707
	--> Epoch [33/100], Loss: 0.3971, Validation Loss: 0.4687
	--> Epoch [34/100], Loss: 0.3563, Validation Loss: 0.4660
	--> Epoch [35/100], Loss: 0.3574, Validation Loss: 0.4635
	--> Epoch [36/100], Loss: 0.3646, Validation Loss: 0.4616
	--> Epoch [37/100], Loss: 0.3451, Validation Loss: 0.4590
	--> Epoch [38/100], Loss: 0.3107, Validation Loss: 0.4566
	--> Epoch [39/100], Loss: 0.3580, Validation Loss: 0.4558
	--> Epoch [40/100], Loss: 0.3376, Validation Loss: 0.4529
	--> Epoch [41/100], Loss: 0.3005, Validation Loss: 0.4513
	--> Epoch [42/100], Loss: 0.3196, Validation Loss: 0.4499
	--> Epoch [43/100], Loss: 0.3208, Validation Loss: 0.4483
	--> Epoch [44/100], Loss: 0.3279, Validation Loss: 0.4463
	--> Epoch [45/100], Loss: 0.3088, Validation Loss: 0.4448
	--> Epoch [46/100], Loss: 0.2968, Validation Loss: 0.4431
	--> Epoch [47/100], Loss: 0.3053, Validation Loss: 0.4416
	--> Epoch [48/100], Loss: 0.2693, Validation Loss: 0.4408
	--> Epoch [49/100], Loss: 0.2902, Validation Loss: 0.4396
	--> Epoch [50/100], Loss: 0.2572, Validation Loss: 0.4388
	--> Epoch [51/100], Loss: 0.2584, Validation Loss: 0.4370
	--> Epoch [52/100], Loss: 0.2517, Validation Loss: 0.4353
	--> Epoch [53/100], Loss: 0.2780, Validation Loss: 0.4354
	--> Epoch [54/100], Loss: 0.2627, Validation Loss: 0.4339
	--> Epoch [55/100], Loss: 0.2613, Validation Loss: 0.4324
	--> Epoch [56/100], Loss: 0.2637, Validation Loss: 0.4330
	--> Epoch [57/100], Loss: 0.2291, Validation Loss: 0.4313
	--> Epoch [58/100], Loss: 0.2581, Validation Loss: 0.4309
	--> Epoch [59/100], Loss: 0.2531, Validation Loss: 0.4296
	--> Epoch [60/100], Loss: 0.2360, Validation Loss: 0.4292
	--> Epoch [61/100], Loss: 0.2216, Validation Loss: 0.4287
	--> Epoch [62/100], Loss: 0.2552, Validation Loss: 0.4285
	--> Epoch [63/100], Loss: 0.2027, Validation Loss: 0.4285
	--> Epoch [64/100], Loss: 0.2329, Validation Loss: 0.4280
	--> Epoch [65/100], Loss: 0.2274, Validation Loss: 0.4272
	--> Epoch [66/100], Loss: 0.2226, Validation Loss: 0.4274
	--> Epoch [67/100], Loss: 0.2542, Validation Loss: 0.4257
	--> Epoch [68/100], Loss: 0.2173, Validation Loss: 0.4259
	--> Epoch [69/100], Loss: 0.1847, Validation Loss: 0.4261
	--> Epoch [70/100], Loss: 0.2241, Validation Loss: 0.4251
	--> Epoch [71/100], Loss: 0.2150, Validation Loss: 0.4264
	--> Epoch [72/100], Loss: 0.1896, Validation Loss: 0.4263
	--> Epoch [73/100], Loss: 0.2021, Validation Loss: 0.4252
Early stopping
	--> Training for Fold 5 took 0.2672443389892578 sec, using 73 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6932
	--> Final training Epoch [2/100], Loss: 0.6712
	--> Final training Epoch [3/100], Loss: 0.6584
	--> Final training Epoch [4/100], Loss: 0.6485
	--> Final training Epoch [5/100], Loss: 0.6108
	--> Final training Epoch [6/100], Loss: 0.5772
	--> Final training Epoch [7/100], Loss: 0.5649
	--> Final training Epoch [8/100], Loss: 0.5427
	--> Final training Epoch [9/100], Loss: 0.5146
	--> Final training Epoch [10/100], Loss: 0.5184
	--> Final training Epoch [11/100], Loss: 0.5031
	--> Final training Epoch [12/100], Loss: 0.5069
	--> Final training Epoch [13/100], Loss: 0.4876
	--> Final training Epoch [14/100], Loss: 0.4587
	--> Final training Epoch [15/100], Loss: 0.4393
	--> Final training Epoch [16/100], Loss: 0.4518
	--> Final training Epoch [17/100], Loss: 0.4433
	--> Final training Epoch [18/100], Loss: 0.4243
	--> Final training Epoch [19/100], Loss: 0.4341
	--> Final training Epoch [20/100], Loss: 0.4119
	--> Final training Epoch [21/100], Loss: 0.3737
	--> Final training Epoch [22/100], Loss: 0.3939
	--> Final training Epoch [23/100], Loss: 0.3880
	--> Final training Epoch [24/100], Loss: 0.3813
	--> Final training Epoch [25/100], Loss: 0.3694
	--> Final training Epoch [26/100], Loss: 0.3818
	--> Final training Epoch [27/100], Loss: 0.3281
	--> Final training Epoch [28/100], Loss: 0.3579
	--> Final training Epoch [29/100], Loss: 0.3228
	--> Final training Epoch [30/100], Loss: 0.3242
	--> Final training Epoch [31/100], Loss: 0.2946
	--> Final training Epoch [32/100], Loss: 0.3245
	--> Final training Epoch [33/100], Loss: 0.2745
	--> Final training Epoch [34/100], Loss: 0.3141
	--> Final training Epoch [35/100], Loss: 0.3060
	--> Final training Epoch [36/100], Loss: 0.2854
	--> Final training Epoch [37/100], Loss: 0.2675
	--> Final training Epoch [38/100], Loss: 0.2848
	--> Final training Epoch [39/100], Loss: 0.2681
	--> Final training Epoch [40/100], Loss: 0.2424
	--> Final training Epoch [41/100], Loss: 0.2665
	--> Final training Epoch [42/100], Loss: 0.2405
	--> Final training Epoch [43/100], Loss: 0.2475
	--> Final training Epoch [44/100], Loss: 0.2605
	--> Final training Epoch [45/100], Loss: 0.2186
	--> Final training Epoch [46/100], Loss: 0.2396
	--> Final training Epoch [47/100], Loss: 0.2219
	--> Final training Epoch [48/100], Loss: 0.2300
	--> Final training Epoch [49/100], Loss: 0.2243
	--> Final training Epoch [50/100], Loss: 0.2221
	--> Final training Epoch [51/100], Loss: 0.2219
	--> Final training Epoch [52/100], Loss: 0.1939
	--> Final training Epoch [53/100], Loss: 0.1994
	--> Final training Epoch [54/100], Loss: 0.2005
	--> Final training Epoch [55/100], Loss: 0.2031
	--> Final training Epoch [56/100], Loss: 0.2023
	--> Final training Epoch [57/100], Loss: 0.1968
	--> Final training Epoch [58/100], Loss: 0.1712
	--> Final training Epoch [59/100], Loss: 0.2218
	--> Final training Epoch [60/100], Loss: 0.1758
	--> Final training Epoch [61/100], Loss: 0.1799
	--> Final training Epoch [62/100], Loss: 0.1639
	--> Final training Epoch [63/100], Loss: 0.1815
	--> Final training Epoch [64/100], Loss: 0.1886
	--> Final training Epoch [65/100], Loss: 0.1902
	--> Final training Epoch [66/100], Loss: 0.1465
	--> Final training Epoch [67/100], Loss: 0.1567
	--> Final training Epoch [68/100], Loss: 0.1703
	--> Final training Epoch [69/100], Loss: 0.1325
	--> Final training Epoch [70/100], Loss: 0.1553
	--> Final training Epoch [71/100], Loss: 0.1487
	--> Final training Epoch [72/100], Loss: 0.1514
	--> Final training Epoch [73/100], Loss: 0.1584
	--> Final training Epoch [74/100], Loss: 0.1586
	--> Final training Epoch [75/100], Loss: 0.1392
	--> Final training Epoch [76/100], Loss: 0.1253
	--> Final training Epoch [77/100], Loss: 0.1564
	--> Final training Epoch [78/100], Loss: 0.1273
	--> Final training Epoch [79/100], Loss: 0.1319
	--> Final training Epoch [80/100], Loss: 0.1114
	--> Final training Epoch [81/100], Loss: 0.1491
	--> Final training Epoch [82/100], Loss: 0.1135
	--> Final training Epoch [83/100], Loss: 0.1319
	--> Final training Epoch [84/100], Loss: 0.1104
	--> Final training Epoch [85/100], Loss: 0.1381
	--> Final training Epoch [86/100], Loss: 0.1207
	--> Final training Epoch [87/100], Loss: 0.1234
	--> Final training Epoch [88/100], Loss: 0.1510
	--> Final training Epoch [89/100], Loss: 0.1200
	--> Final training Epoch [90/100], Loss: 0.1364
	--> Final training Epoch [91/100], Loss: 0.1113
	--> Final training Epoch [92/100], Loss: 0.1165
	--> Final training Epoch [93/100], Loss: 0.1284
	--> Final training Epoch [94/100], Loss: 0.1264
	--> Final training Epoch [95/100], Loss: 0.1091
	--> Final training Epoch [96/100], Loss: 0.0853
	--> Final training Epoch [97/100], Loss: 0.1098
	--> Final training Epoch [98/100], Loss: 0.1094
	--> Final training Epoch [99/100], Loss: 0.1000
	--> Final training Epoch [100/100], Loss: 0.0981

Final training took 0.3553159236907959 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.7868
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3132,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3132
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.4047,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3132
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7953, Validation Loss: 0.4268,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3132
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.3336,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3132
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8263, Validation Loss: 0.4108,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3132
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.4036,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3132

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8253, Validation Loss: 0.6670
	--> Epoch [2/100], Loss: 0.8019, Validation Loss: 0.6573
	--> Epoch [3/100], Loss: 0.7396, Validation Loss: 0.6438
	--> Epoch [4/100], Loss: 0.6902, Validation Loss: 0.6293
	--> Epoch [5/100], Loss: 0.7234, Validation Loss: 0.6156
	--> Epoch [6/100], Loss: 0.6983, Validation Loss: 0.6068
	--> Epoch [7/100], Loss: 0.6337, Validation Loss: 0.5965
	--> Epoch [8/100], Loss: 0.6669, Validation Loss: 0.5907
	--> Epoch [9/100], Loss: 0.6053, Validation Loss: 0.5774
	--> Epoch [10/100], Loss: 0.6746, Validation Loss: 0.5695
	--> Epoch [11/100], Loss: 0.6397, Validation Loss: 0.5627
	--> Epoch [12/100], Loss: 0.6000, Validation Loss: 0.5514
	--> Epoch [13/100], Loss: 0.5594, Validation Loss: 0.5440
	--> Epoch [14/100], Loss: 0.5763, Validation Loss: 0.5378
	--> Epoch [15/100], Loss: 0.6192, Validation Loss: 0.5305
	--> Epoch [16/100], Loss: 0.5629, Validation Loss: 0.5270
	--> Epoch [17/100], Loss: 0.5132, Validation Loss: 0.5234
	--> Epoch [18/100], Loss: 0.5189, Validation Loss: 0.5186
	--> Epoch [19/100], Loss: 0.5619, Validation Loss: 0.5114
	--> Epoch [20/100], Loss: 0.5437, Validation Loss: 0.5079
	--> Epoch [21/100], Loss: 0.5038, Validation Loss: 0.5041
	--> Epoch [22/100], Loss: 0.5058, Validation Loss: 0.4980
	--> Epoch [23/100], Loss: 0.4631, Validation Loss: 0.4927
	--> Epoch [24/100], Loss: 0.5061, Validation Loss: 0.4890
	--> Epoch [25/100], Loss: 0.5230, Validation Loss: 0.4842
	--> Epoch [26/100], Loss: 0.4571, Validation Loss: 0.4800
	--> Epoch [27/100], Loss: 0.5041, Validation Loss: 0.4778
	--> Epoch [28/100], Loss: 0.4880, Validation Loss: 0.4745
	--> Epoch [29/100], Loss: 0.4815, Validation Loss: 0.4736
	--> Epoch [30/100], Loss: 0.5101, Validation Loss: 0.4721
	--> Epoch [31/100], Loss: 0.4504, Validation Loss: 0.4687
	--> Epoch [32/100], Loss: 0.5049, Validation Loss: 0.4663
	--> Epoch [33/100], Loss: 0.4568, Validation Loss: 0.4626
	--> Epoch [34/100], Loss: 0.4819, Validation Loss: 0.4593
	--> Epoch [35/100], Loss: 0.4452, Validation Loss: 0.4564
	--> Epoch [36/100], Loss: 0.4115, Validation Loss: 0.4553
	--> Epoch [37/100], Loss: 0.4210, Validation Loss: 0.4537
	--> Epoch [38/100], Loss: 0.4235, Validation Loss: 0.4491
	--> Epoch [39/100], Loss: 0.4570, Validation Loss: 0.4465
	--> Epoch [40/100], Loss: 0.4975, Validation Loss: 0.4443
	--> Epoch [41/100], Loss: 0.4154, Validation Loss: 0.4427
	--> Epoch [42/100], Loss: 0.3970, Validation Loss: 0.4403
	--> Epoch [43/100], Loss: 0.4754, Validation Loss: 0.4397
	--> Epoch [44/100], Loss: 0.4071, Validation Loss: 0.4366
	--> Epoch [45/100], Loss: 0.4227, Validation Loss: 0.4338
	--> Epoch [46/100], Loss: 0.4144, Validation Loss: 0.4316
	--> Epoch [47/100], Loss: 0.4190, Validation Loss: 0.4294
	--> Epoch [48/100], Loss: 0.4499, Validation Loss: 0.4263
	--> Epoch [49/100], Loss: 0.4715, Validation Loss: 0.4241
	--> Epoch [50/100], Loss: 0.4040, Validation Loss: 0.4213
	--> Epoch [51/100], Loss: 0.3947, Validation Loss: 0.4197
	--> Epoch [52/100], Loss: 0.3827, Validation Loss: 0.4203
	--> Epoch [53/100], Loss: 0.3598, Validation Loss: 0.4185
	--> Epoch [54/100], Loss: 0.3861, Validation Loss: 0.4171
	--> Epoch [55/100], Loss: 0.4071, Validation Loss: 0.4139
	--> Epoch [56/100], Loss: 0.4498, Validation Loss: 0.4124
	--> Epoch [57/100], Loss: 0.4085, Validation Loss: 0.4107
	--> Epoch [58/100], Loss: 0.3551, Validation Loss: 0.4107
	--> Epoch [59/100], Loss: 0.4129, Validation Loss: 0.4062
	--> Epoch [60/100], Loss: 0.4505, Validation Loss: 0.4051
	--> Epoch [61/100], Loss: 0.3391, Validation Loss: 0.4040
	--> Epoch [62/100], Loss: 0.3395, Validation Loss: 0.4009
	--> Epoch [63/100], Loss: 0.3422, Validation Loss: 0.3986
	--> Epoch [64/100], Loss: 0.3966, Validation Loss: 0.3984
	--> Epoch [65/100], Loss: 0.3025, Validation Loss: 0.3960
	--> Epoch [66/100], Loss: 0.3383, Validation Loss: 0.3934
	--> Epoch [67/100], Loss: 0.3502, Validation Loss: 0.3926
	--> Epoch [68/100], Loss: 0.3532, Validation Loss: 0.3890
	--> Epoch [69/100], Loss: 0.3869, Validation Loss: 0.3879
	--> Epoch [70/100], Loss: 0.4027, Validation Loss: 0.3852
	--> Epoch [71/100], Loss: 0.3601, Validation Loss: 0.3834
	--> Epoch [72/100], Loss: 0.3421, Validation Loss: 0.3832
	--> Epoch [73/100], Loss: 0.3239, Validation Loss: 0.3798
	--> Epoch [74/100], Loss: 0.3300, Validation Loss: 0.3791
	--> Epoch [75/100], Loss: 0.3295, Validation Loss: 0.3766
	--> Epoch [76/100], Loss: 0.3260, Validation Loss: 0.3750
	--> Epoch [77/100], Loss: 0.3552, Validation Loss: 0.3735
	--> Epoch [78/100], Loss: 0.3528, Validation Loss: 0.3716
	--> Epoch [79/100], Loss: 0.3826, Validation Loss: 0.3704
	--> Epoch [80/100], Loss: 0.3692, Validation Loss: 0.3706
	--> Epoch [81/100], Loss: 0.3228, Validation Loss: 0.3685
	--> Epoch [82/100], Loss: 0.3392, Validation Loss: 0.3666
	--> Epoch [83/100], Loss: 0.3438, Validation Loss: 0.3648
	--> Epoch [84/100], Loss: 0.3306, Validation Loss: 0.3635
	--> Epoch [85/100], Loss: 0.3264, Validation Loss: 0.3616
	--> Epoch [86/100], Loss: 0.2913, Validation Loss: 0.3603
	--> Epoch [87/100], Loss: 0.3332, Validation Loss: 0.3604
	--> Epoch [88/100], Loss: 0.3483, Validation Loss: 0.3603
	--> Epoch [89/100], Loss: 0.3000, Validation Loss: 0.3594
	--> Epoch [90/100], Loss: 0.3045, Validation Loss: 0.3586
	--> Epoch [91/100], Loss: 0.2801, Validation Loss: 0.3591
	--> Epoch [92/100], Loss: 0.2828, Validation Loss: 0.3584
	--> Epoch [93/100], Loss: 0.2948, Validation Loss: 0.3580
	--> Epoch [94/100], Loss: 0.3657, Validation Loss: 0.3572
	--> Epoch [95/100], Loss: 0.3484, Validation Loss: 0.3545
	--> Epoch [96/100], Loss: 0.2608, Validation Loss: 0.3534
	--> Epoch [97/100], Loss: 0.3101, Validation Loss: 0.3534
	--> Epoch [98/100], Loss: 0.3180, Validation Loss: 0.3511
	--> Epoch [99/100], Loss: 0.3149, Validation Loss: 0.3509
	--> Epoch [100/100], Loss: 0.3591, Validation Loss: 0.3506
	--> Training for Fold 1 took 0.37312960624694824 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7998, Validation Loss: 0.7867
	--> Epoch [2/100], Loss: 0.7925, Validation Loss: 0.7674
	--> Epoch [3/100], Loss: 0.7367, Validation Loss: 0.7453
	--> Epoch [4/100], Loss: 0.7051, Validation Loss: 0.7339
	--> Epoch [5/100], Loss: 0.7273, Validation Loss: 0.7163
	--> Epoch [6/100], Loss: 0.7278, Validation Loss: 0.7058
	--> Epoch [7/100], Loss: 0.6902, Validation Loss: 0.6967
	--> Epoch [8/100], Loss: 0.6601, Validation Loss: 0.6842
	--> Epoch [9/100], Loss: 0.6617, Validation Loss: 0.6792
	--> Epoch [10/100], Loss: 0.6656, Validation Loss: 0.6688
	--> Epoch [11/100], Loss: 0.6526, Validation Loss: 0.6622
	--> Epoch [12/100], Loss: 0.6496, Validation Loss: 0.6494
	--> Epoch [13/100], Loss: 0.5949, Validation Loss: 0.6425
	--> Epoch [14/100], Loss: 0.5871, Validation Loss: 0.6362
	--> Epoch [15/100], Loss: 0.5899, Validation Loss: 0.6299
	--> Epoch [16/100], Loss: 0.5836, Validation Loss: 0.6246
	--> Epoch [17/100], Loss: 0.5434, Validation Loss: 0.6152
	--> Epoch [18/100], Loss: 0.5969, Validation Loss: 0.6087
	--> Epoch [19/100], Loss: 0.5926, Validation Loss: 0.5952
	--> Epoch [20/100], Loss: 0.6111, Validation Loss: 0.5933
	--> Epoch [21/100], Loss: 0.5759, Validation Loss: 0.5856
	--> Epoch [22/100], Loss: 0.5837, Validation Loss: 0.5819
	--> Epoch [23/100], Loss: 0.5688, Validation Loss: 0.5734
	--> Epoch [24/100], Loss: 0.5547, Validation Loss: 0.5673
	--> Epoch [25/100], Loss: 0.5172, Validation Loss: 0.5597
	--> Epoch [26/100], Loss: 0.5396, Validation Loss: 0.5512
	--> Epoch [27/100], Loss: 0.5242, Validation Loss: 0.5455
	--> Epoch [28/100], Loss: 0.5150, Validation Loss: 0.5409
	--> Epoch [29/100], Loss: 0.5128, Validation Loss: 0.5353
	--> Epoch [30/100], Loss: 0.5048, Validation Loss: 0.5342
	--> Epoch [31/100], Loss: 0.5479, Validation Loss: 0.5348
	--> Epoch [32/100], Loss: 0.4898, Validation Loss: 0.5305
	--> Epoch [33/100], Loss: 0.5121, Validation Loss: 0.5258
	--> Epoch [34/100], Loss: 0.5216, Validation Loss: 0.5241
	--> Epoch [35/100], Loss: 0.4672, Validation Loss: 0.5204
	--> Epoch [36/100], Loss: 0.4836, Validation Loss: 0.5134
	--> Epoch [37/100], Loss: 0.4518, Validation Loss: 0.5099
	--> Epoch [38/100], Loss: 0.4907, Validation Loss: 0.5042
	--> Epoch [39/100], Loss: 0.4644, Validation Loss: 0.5002
	--> Epoch [40/100], Loss: 0.4782, Validation Loss: 0.4923
	--> Epoch [41/100], Loss: 0.4802, Validation Loss: 0.4899
	--> Epoch [42/100], Loss: 0.4487, Validation Loss: 0.4856
	--> Epoch [43/100], Loss: 0.4725, Validation Loss: 0.4865
	--> Epoch [44/100], Loss: 0.4551, Validation Loss: 0.4821
	--> Epoch [45/100], Loss: 0.4519, Validation Loss: 0.4772
	--> Epoch [46/100], Loss: 0.3618, Validation Loss: 0.4709
	--> Epoch [47/100], Loss: 0.4569, Validation Loss: 0.4649
	--> Epoch [48/100], Loss: 0.4614, Validation Loss: 0.4624
	--> Epoch [49/100], Loss: 0.4705, Validation Loss: 0.4570
	--> Epoch [50/100], Loss: 0.3969, Validation Loss: 0.4526
	--> Epoch [51/100], Loss: 0.4217, Validation Loss: 0.4500
	--> Epoch [52/100], Loss: 0.4719, Validation Loss: 0.4468
	--> Epoch [53/100], Loss: 0.4183, Validation Loss: 0.4417
	--> Epoch [54/100], Loss: 0.4266, Validation Loss: 0.4416
	--> Epoch [55/100], Loss: 0.4211, Validation Loss: 0.4396
	--> Epoch [56/100], Loss: 0.3951, Validation Loss: 0.4383
	--> Epoch [57/100], Loss: 0.3662, Validation Loss: 0.4337
	--> Epoch [58/100], Loss: 0.4379, Validation Loss: 0.4320
	--> Epoch [59/100], Loss: 0.3586, Validation Loss: 0.4278
	--> Epoch [60/100], Loss: 0.3534, Validation Loss: 0.4241
	--> Epoch [61/100], Loss: 0.4150, Validation Loss: 0.4209
	--> Epoch [62/100], Loss: 0.4065, Validation Loss: 0.4195
	--> Epoch [63/100], Loss: 0.4181, Validation Loss: 0.4176
	--> Epoch [64/100], Loss: 0.3717, Validation Loss: 0.4159
	--> Epoch [65/100], Loss: 0.4195, Validation Loss: 0.4155
	--> Epoch [66/100], Loss: 0.3836, Validation Loss: 0.4100
	--> Epoch [67/100], Loss: 0.4049, Validation Loss: 0.4083
	--> Epoch [68/100], Loss: 0.3345, Validation Loss: 0.4050
	--> Epoch [69/100], Loss: 0.3119, Validation Loss: 0.4001
	--> Epoch [70/100], Loss: 0.4527, Validation Loss: 0.3982
	--> Epoch [71/100], Loss: 0.4302, Validation Loss: 0.3951
	--> Epoch [72/100], Loss: 0.3871, Validation Loss: 0.3920
	--> Epoch [73/100], Loss: 0.3823, Validation Loss: 0.3910
	--> Epoch [74/100], Loss: 0.3600, Validation Loss: 0.3882
	--> Epoch [75/100], Loss: 0.4189, Validation Loss: 0.3857
	--> Epoch [76/100], Loss: 0.3171, Validation Loss: 0.3821
	--> Epoch [77/100], Loss: 0.3715, Validation Loss: 0.3797
	--> Epoch [78/100], Loss: 0.4261, Validation Loss: 0.3768
	--> Epoch [79/100], Loss: 0.3775, Validation Loss: 0.3722
	--> Epoch [80/100], Loss: 0.3854, Validation Loss: 0.3673
	--> Epoch [81/100], Loss: 0.4053, Validation Loss: 0.3652
	--> Epoch [82/100], Loss: 0.3333, Validation Loss: 0.3638
	--> Epoch [83/100], Loss: 0.3043, Validation Loss: 0.3614
	--> Epoch [84/100], Loss: 0.3990, Validation Loss: 0.3621
	--> Epoch [85/100], Loss: 0.3421, Validation Loss: 0.3586
	--> Epoch [86/100], Loss: 0.3634, Validation Loss: 0.3571
	--> Epoch [87/100], Loss: 0.3219, Validation Loss: 0.3541
	--> Epoch [88/100], Loss: 0.3501, Validation Loss: 0.3545
	--> Epoch [89/100], Loss: 0.3570, Validation Loss: 0.3532
	--> Epoch [90/100], Loss: 0.3472, Validation Loss: 0.3501
	--> Epoch [91/100], Loss: 0.3703, Validation Loss: 0.3452
	--> Epoch [92/100], Loss: 0.3813, Validation Loss: 0.3460
	--> Epoch [93/100], Loss: 0.4117, Validation Loss: 0.3436
	--> Epoch [94/100], Loss: 0.3315, Validation Loss: 0.3437
	--> Epoch [95/100], Loss: 0.3077, Validation Loss: 0.3433
	--> Epoch [96/100], Loss: 0.3484, Validation Loss: 0.3434
	--> Epoch [97/100], Loss: 0.3129, Validation Loss: 0.3426
	--> Epoch [98/100], Loss: 0.2775, Validation Loss: 0.3402
	--> Epoch [99/100], Loss: 0.4079, Validation Loss: 0.3382
	--> Epoch [100/100], Loss: 0.3165, Validation Loss: 0.3369
	--> Training for Fold 2 took 0.38949108123779297 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7661, Validation Loss: 0.7159
	--> Epoch [2/100], Loss: 0.8097, Validation Loss: 0.7056
	--> Epoch [3/100], Loss: 0.7679, Validation Loss: 0.6967
	--> Epoch [4/100], Loss: 0.7370, Validation Loss: 0.6911
	--> Epoch [5/100], Loss: 0.7106, Validation Loss: 0.6853
	--> Epoch [6/100], Loss: 0.6888, Validation Loss: 0.6785
	--> Epoch [7/100], Loss: 0.6547, Validation Loss: 0.6732
	--> Epoch [8/100], Loss: 0.6664, Validation Loss: 0.6677
	--> Epoch [9/100], Loss: 0.6567, Validation Loss: 0.6628
	--> Epoch [10/100], Loss: 0.6622, Validation Loss: 0.6596
	--> Epoch [11/100], Loss: 0.6461, Validation Loss: 0.6530
	--> Epoch [12/100], Loss: 0.6649, Validation Loss: 0.6456
	--> Epoch [13/100], Loss: 0.6329, Validation Loss: 0.6423
	--> Epoch [14/100], Loss: 0.6358, Validation Loss: 0.6338
	--> Epoch [15/100], Loss: 0.6263, Validation Loss: 0.6266
	--> Epoch [16/100], Loss: 0.5973, Validation Loss: 0.6210
	--> Epoch [17/100], Loss: 0.5860, Validation Loss: 0.6143
	--> Epoch [18/100], Loss: 0.5707, Validation Loss: 0.6092
	--> Epoch [19/100], Loss: 0.6009, Validation Loss: 0.6063
	--> Epoch [20/100], Loss: 0.5774, Validation Loss: 0.6008
	--> Epoch [21/100], Loss: 0.5683, Validation Loss: 0.5977
	--> Epoch [22/100], Loss: 0.5651, Validation Loss: 0.5926
	--> Epoch [23/100], Loss: 0.5542, Validation Loss: 0.5887
	--> Epoch [24/100], Loss: 0.5494, Validation Loss: 0.5848
	--> Epoch [25/100], Loss: 0.5388, Validation Loss: 0.5805
	--> Epoch [26/100], Loss: 0.5088, Validation Loss: 0.5760
	--> Epoch [27/100], Loss: 0.5296, Validation Loss: 0.5727
	--> Epoch [28/100], Loss: 0.5209, Validation Loss: 0.5689
	--> Epoch [29/100], Loss: 0.5328, Validation Loss: 0.5648
	--> Epoch [30/100], Loss: 0.5264, Validation Loss: 0.5614
	--> Epoch [31/100], Loss: 0.5386, Validation Loss: 0.5563
	--> Epoch [32/100], Loss: 0.5162, Validation Loss: 0.5530
	--> Epoch [33/100], Loss: 0.5643, Validation Loss: 0.5503
	--> Epoch [34/100], Loss: 0.5307, Validation Loss: 0.5485
	--> Epoch [35/100], Loss: 0.5190, Validation Loss: 0.5461
	--> Epoch [36/100], Loss: 0.5034, Validation Loss: 0.5415
	--> Epoch [37/100], Loss: 0.4846, Validation Loss: 0.5376
	--> Epoch [38/100], Loss: 0.4602, Validation Loss: 0.5343
	--> Epoch [39/100], Loss: 0.4837, Validation Loss: 0.5306
	--> Epoch [40/100], Loss: 0.4691, Validation Loss: 0.5278
	--> Epoch [41/100], Loss: 0.5043, Validation Loss: 0.5256
	--> Epoch [42/100], Loss: 0.4558, Validation Loss: 0.5227
	--> Epoch [43/100], Loss: 0.4749, Validation Loss: 0.5203
	--> Epoch [44/100], Loss: 0.4049, Validation Loss: 0.5164
	--> Epoch [45/100], Loss: 0.4400, Validation Loss: 0.5131
	--> Epoch [46/100], Loss: 0.4851, Validation Loss: 0.5106
	--> Epoch [47/100], Loss: 0.4359, Validation Loss: 0.5074
	--> Epoch [48/100], Loss: 0.4656, Validation Loss: 0.5045
	--> Epoch [49/100], Loss: 0.4814, Validation Loss: 0.5015
	--> Epoch [50/100], Loss: 0.4558, Validation Loss: 0.5003
	--> Epoch [51/100], Loss: 0.4215, Validation Loss: 0.4985
	--> Epoch [52/100], Loss: 0.4230, Validation Loss: 0.4957
	--> Epoch [53/100], Loss: 0.4134, Validation Loss: 0.4912
	--> Epoch [54/100], Loss: 0.4127, Validation Loss: 0.4886
	--> Epoch [55/100], Loss: 0.4115, Validation Loss: 0.4863
	--> Epoch [56/100], Loss: 0.3784, Validation Loss: 0.4842
	--> Epoch [57/100], Loss: 0.4350, Validation Loss: 0.4827
	--> Epoch [58/100], Loss: 0.4043, Validation Loss: 0.4785
	--> Epoch [59/100], Loss: 0.4004, Validation Loss: 0.4764
	--> Epoch [60/100], Loss: 0.4261, Validation Loss: 0.4735
	--> Epoch [61/100], Loss: 0.3792, Validation Loss: 0.4719
	--> Epoch [62/100], Loss: 0.4010, Validation Loss: 0.4698
	--> Epoch [63/100], Loss: 0.3903, Validation Loss: 0.4675
	--> Epoch [64/100], Loss: 0.3769, Validation Loss: 0.4648
	--> Epoch [65/100], Loss: 0.3947, Validation Loss: 0.4626
	--> Epoch [66/100], Loss: 0.3815, Validation Loss: 0.4597
	--> Epoch [67/100], Loss: 0.3936, Validation Loss: 0.4582
	--> Epoch [68/100], Loss: 0.3733, Validation Loss: 0.4551
	--> Epoch [69/100], Loss: 0.3724, Validation Loss: 0.4525
	--> Epoch [70/100], Loss: 0.3285, Validation Loss: 0.4493
	--> Epoch [71/100], Loss: 0.3698, Validation Loss: 0.4476
	--> Epoch [72/100], Loss: 0.3889, Validation Loss: 0.4467
	--> Epoch [73/100], Loss: 0.3764, Validation Loss: 0.4448
	--> Epoch [74/100], Loss: 0.3944, Validation Loss: 0.4423
	--> Epoch [75/100], Loss: 0.3537, Validation Loss: 0.4408
	--> Epoch [76/100], Loss: 0.3470, Validation Loss: 0.4386
	--> Epoch [77/100], Loss: 0.3525, Validation Loss: 0.4370
	--> Epoch [78/100], Loss: 0.3859, Validation Loss: 0.4355
	--> Epoch [79/100], Loss: 0.3578, Validation Loss: 0.4332
	--> Epoch [80/100], Loss: 0.3733, Validation Loss: 0.4321
	--> Epoch [81/100], Loss: 0.3801, Validation Loss: 0.4303
	--> Epoch [82/100], Loss: 0.3527, Validation Loss: 0.4279
	--> Epoch [83/100], Loss: 0.3345, Validation Loss: 0.4263
	--> Epoch [84/100], Loss: 0.3616, Validation Loss: 0.4242
	--> Epoch [85/100], Loss: 0.3309, Validation Loss: 0.4221
	--> Epoch [86/100], Loss: 0.3296, Validation Loss: 0.4195
	--> Epoch [87/100], Loss: 0.2894, Validation Loss: 0.4180
	--> Epoch [88/100], Loss: 0.3200, Validation Loss: 0.4166
	--> Epoch [89/100], Loss: 0.3660, Validation Loss: 0.4154
	--> Epoch [90/100], Loss: 0.3413, Validation Loss: 0.4138
	--> Epoch [91/100], Loss: 0.3407, Validation Loss: 0.4122
	--> Epoch [92/100], Loss: 0.3632, Validation Loss: 0.4117
	--> Epoch [93/100], Loss: 0.3668, Validation Loss: 0.4097
	--> Epoch [94/100], Loss: 0.3705, Validation Loss: 0.4081
	--> Epoch [95/100], Loss: 0.3507, Validation Loss: 0.4063
	--> Epoch [96/100], Loss: 0.3171, Validation Loss: 0.4050
	--> Epoch [97/100], Loss: 0.3118, Validation Loss: 0.4036
	--> Epoch [98/100], Loss: 0.3474, Validation Loss: 0.4013
	--> Epoch [99/100], Loss: 0.2915, Validation Loss: 0.4007
	--> Epoch [100/100], Loss: 0.3414, Validation Loss: 0.3987
	--> Training for Fold 3 took 0.37947702407836914 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7712, Validation Loss: 0.6783
	--> Epoch [2/100], Loss: 0.7491, Validation Loss: 0.6677
	--> Epoch [3/100], Loss: 0.7313, Validation Loss: 0.6562
	--> Epoch [4/100], Loss: 0.7306, Validation Loss: 0.6472
	--> Epoch [5/100], Loss: 0.7029, Validation Loss: 0.6325
	--> Epoch [6/100], Loss: 0.7005, Validation Loss: 0.6287
	--> Epoch [7/100], Loss: 0.6701, Validation Loss: 0.6201
	--> Epoch [8/100], Loss: 0.6292, Validation Loss: 0.6108
	--> Epoch [9/100], Loss: 0.6115, Validation Loss: 0.6047
	--> Epoch [10/100], Loss: 0.6009, Validation Loss: 0.5973
	--> Epoch [11/100], Loss: 0.6500, Validation Loss: 0.5921
	--> Epoch [12/100], Loss: 0.5955, Validation Loss: 0.5867
	--> Epoch [13/100], Loss: 0.5897, Validation Loss: 0.5817
	--> Epoch [14/100], Loss: 0.5821, Validation Loss: 0.5768
	--> Epoch [15/100], Loss: 0.5743, Validation Loss: 0.5694
	--> Epoch [16/100], Loss: 0.4843, Validation Loss: 0.5608
	--> Epoch [17/100], Loss: 0.5375, Validation Loss: 0.5548
	--> Epoch [18/100], Loss: 0.5423, Validation Loss: 0.5539
	--> Epoch [19/100], Loss: 0.5083, Validation Loss: 0.5509
	--> Epoch [20/100], Loss: 0.5440, Validation Loss: 0.5496
	--> Epoch [21/100], Loss: 0.4961, Validation Loss: 0.5472
	--> Epoch [22/100], Loss: 0.5068, Validation Loss: 0.5450
	--> Epoch [23/100], Loss: 0.5170, Validation Loss: 0.5421
	--> Epoch [24/100], Loss: 0.5657, Validation Loss: 0.5417
	--> Epoch [25/100], Loss: 0.5248, Validation Loss: 0.5356
	--> Epoch [26/100], Loss: 0.4482, Validation Loss: 0.5349
	--> Epoch [27/100], Loss: 0.4941, Validation Loss: 0.5288
	--> Epoch [28/100], Loss: 0.4887, Validation Loss: 0.5250
	--> Epoch [29/100], Loss: 0.4426, Validation Loss: 0.5237
	--> Epoch [30/100], Loss: 0.4554, Validation Loss: 0.5217
	--> Epoch [31/100], Loss: 0.5154, Validation Loss: 0.5160
	--> Epoch [32/100], Loss: 0.4768, Validation Loss: 0.5135
	--> Epoch [33/100], Loss: 0.4300, Validation Loss: 0.5100
	--> Epoch [34/100], Loss: 0.4352, Validation Loss: 0.5077
	--> Epoch [35/100], Loss: 0.4376, Validation Loss: 0.5053
	--> Epoch [36/100], Loss: 0.4036, Validation Loss: 0.5028
	--> Epoch [37/100], Loss: 0.4082, Validation Loss: 0.4987
	--> Epoch [38/100], Loss: 0.4736, Validation Loss: 0.4956
	--> Epoch [39/100], Loss: 0.4320, Validation Loss: 0.4915
	--> Epoch [40/100], Loss: 0.4514, Validation Loss: 0.4895
	--> Epoch [41/100], Loss: 0.4246, Validation Loss: 0.4864
	--> Epoch [42/100], Loss: 0.4295, Validation Loss: 0.4819
	--> Epoch [43/100], Loss: 0.4795, Validation Loss: 0.4817
	--> Epoch [44/100], Loss: 0.4182, Validation Loss: 0.4781
	--> Epoch [45/100], Loss: 0.4769, Validation Loss: 0.4763
	--> Epoch [46/100], Loss: 0.3929, Validation Loss: 0.4721
	--> Epoch [47/100], Loss: 0.4073, Validation Loss: 0.4691
	--> Epoch [48/100], Loss: 0.4064, Validation Loss: 0.4638
	--> Epoch [49/100], Loss: 0.3638, Validation Loss: 0.4599
	--> Epoch [50/100], Loss: 0.4015, Validation Loss: 0.4567
	--> Epoch [51/100], Loss: 0.3834, Validation Loss: 0.4543
	--> Epoch [52/100], Loss: 0.4063, Validation Loss: 0.4521
	--> Epoch [53/100], Loss: 0.3423, Validation Loss: 0.4492
	--> Epoch [54/100], Loss: 0.4063, Validation Loss: 0.4437
	--> Epoch [55/100], Loss: 0.3795, Validation Loss: 0.4404
	--> Epoch [56/100], Loss: 0.3852, Validation Loss: 0.4391
	--> Epoch [57/100], Loss: 0.3498, Validation Loss: 0.4365
	--> Epoch [58/100], Loss: 0.3348, Validation Loss: 0.4335
	--> Epoch [59/100], Loss: 0.3721, Validation Loss: 0.4282
	--> Epoch [60/100], Loss: 0.3156, Validation Loss: 0.4257
	--> Epoch [61/100], Loss: 0.3023, Validation Loss: 0.4226
	--> Epoch [62/100], Loss: 0.3861, Validation Loss: 0.4215
	--> Epoch [63/100], Loss: 0.3411, Validation Loss: 0.4190
	--> Epoch [64/100], Loss: 0.3209, Validation Loss: 0.4175
	--> Epoch [65/100], Loss: 0.3534, Validation Loss: 0.4167
	--> Epoch [66/100], Loss: 0.3237, Validation Loss: 0.4136
	--> Epoch [67/100], Loss: 0.3606, Validation Loss: 0.4109
	--> Epoch [68/100], Loss: 0.3416, Validation Loss: 0.4091
	--> Epoch [69/100], Loss: 0.3318, Validation Loss: 0.4069
	--> Epoch [70/100], Loss: 0.3140, Validation Loss: 0.4057
	--> Epoch [71/100], Loss: 0.3485, Validation Loss: 0.4041
	--> Epoch [72/100], Loss: 0.3431, Validation Loss: 0.4009
	--> Epoch [73/100], Loss: 0.3578, Validation Loss: 0.3976
	--> Epoch [74/100], Loss: 0.3323, Validation Loss: 0.3966
	--> Epoch [75/100], Loss: 0.2742, Validation Loss: 0.3958
	--> Epoch [76/100], Loss: 0.3256, Validation Loss: 0.3938
	--> Epoch [77/100], Loss: 0.3401, Validation Loss: 0.3919
	--> Epoch [78/100], Loss: 0.3027, Validation Loss: 0.3885
	--> Epoch [79/100], Loss: 0.3349, Validation Loss: 0.3857
	--> Epoch [80/100], Loss: 0.3252, Validation Loss: 0.3856
	--> Epoch [81/100], Loss: 0.2760, Validation Loss: 0.3842
	--> Epoch [82/100], Loss: 0.3323, Validation Loss: 0.3838
	--> Epoch [83/100], Loss: 0.3589, Validation Loss: 0.3823
	--> Epoch [84/100], Loss: 0.3156, Validation Loss: 0.3810
	--> Epoch [85/100], Loss: 0.2940, Validation Loss: 0.3802
	--> Epoch [86/100], Loss: 0.3086, Validation Loss: 0.3774
	--> Epoch [87/100], Loss: 0.3256, Validation Loss: 0.3769
	--> Epoch [88/100], Loss: 0.2505, Validation Loss: 0.3765
	--> Epoch [89/100], Loss: 0.3021, Validation Loss: 0.3740
	--> Epoch [90/100], Loss: 0.2364, Validation Loss: 0.3723
	--> Epoch [91/100], Loss: 0.2722, Validation Loss: 0.3690
	--> Epoch [92/100], Loss: 0.3407, Validation Loss: 0.3661
	--> Epoch [93/100], Loss: 0.2990, Validation Loss: 0.3653
	--> Epoch [94/100], Loss: 0.3441, Validation Loss: 0.3641
	--> Epoch [95/100], Loss: 0.2791, Validation Loss: 0.3637
	--> Epoch [96/100], Loss: 0.3178, Validation Loss: 0.3637
	--> Epoch [97/100], Loss: 0.2659, Validation Loss: 0.3635
	--> Epoch [98/100], Loss: 0.3243, Validation Loss: 0.3622
	--> Epoch [99/100], Loss: 0.2864, Validation Loss: 0.3604
	--> Epoch [100/100], Loss: 0.2520, Validation Loss: 0.3596
	--> Training for Fold 4 took 0.4063427448272705 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7807, Validation Loss: 0.6797
	--> Epoch [2/100], Loss: 0.7390, Validation Loss: 0.6757
	--> Epoch [3/100], Loss: 0.7266, Validation Loss: 0.6715
	--> Epoch [4/100], Loss: 0.6926, Validation Loss: 0.6687
	--> Epoch [5/100], Loss: 0.7215, Validation Loss: 0.6665
	--> Epoch [6/100], Loss: 0.6233, Validation Loss: 0.6650
	--> Epoch [7/100], Loss: 0.6338, Validation Loss: 0.6608
	--> Epoch [8/100], Loss: 0.6446, Validation Loss: 0.6605
	--> Epoch [9/100], Loss: 0.6356, Validation Loss: 0.6578
	--> Epoch [10/100], Loss: 0.5971, Validation Loss: 0.6561
	--> Epoch [11/100], Loss: 0.6011, Validation Loss: 0.6534
	--> Epoch [12/100], Loss: 0.5880, Validation Loss: 0.6538
	--> Epoch [13/100], Loss: 0.5877, Validation Loss: 0.6511
	--> Epoch [14/100], Loss: 0.5678, Validation Loss: 0.6505
	--> Epoch [15/100], Loss: 0.5536, Validation Loss: 0.6499
	--> Epoch [16/100], Loss: 0.5109, Validation Loss: 0.6491
	--> Epoch [17/100], Loss: 0.5633, Validation Loss: 0.6483
	--> Epoch [18/100], Loss: 0.5106, Validation Loss: 0.6459
	--> Epoch [19/100], Loss: 0.5365, Validation Loss: 0.6442
	--> Epoch [20/100], Loss: 0.5300, Validation Loss: 0.6432
	--> Epoch [21/100], Loss: 0.5018, Validation Loss: 0.6439
	--> Epoch [22/100], Loss: 0.5406, Validation Loss: 0.6452
	--> Epoch [23/100], Loss: 0.4957, Validation Loss: 0.6416
	--> Epoch [24/100], Loss: 0.4838, Validation Loss: 0.6422
	--> Epoch [25/100], Loss: 0.4422, Validation Loss: 0.6427
	--> Epoch [26/100], Loss: 0.4582, Validation Loss: 0.6404
	--> Epoch [27/100], Loss: 0.4498, Validation Loss: 0.6405
	--> Epoch [28/100], Loss: 0.4996, Validation Loss: 0.6401
	--> Epoch [29/100], Loss: 0.4973, Validation Loss: 0.6389
	--> Epoch [30/100], Loss: 0.4490, Validation Loss: 0.6417
	--> Epoch [31/100], Loss: 0.4575, Validation Loss: 0.6423
	--> Epoch [32/100], Loss: 0.4506, Validation Loss: 0.6419
Early stopping
	--> Training for Fold 5 took 0.1325066089630127 sec, using 32 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7177
	--> Final training Epoch [2/100], Loss: 0.6776
	--> Final training Epoch [3/100], Loss: 0.6521
	--> Final training Epoch [4/100], Loss: 0.6650
	--> Final training Epoch [5/100], Loss: 0.6781
	--> Final training Epoch [6/100], Loss: 0.6514
	--> Final training Epoch [7/100], Loss: 0.6111
	--> Final training Epoch [8/100], Loss: 0.6248
	--> Final training Epoch [9/100], Loss: 0.6698
	--> Final training Epoch [10/100], Loss: 0.6118
	--> Final training Epoch [11/100], Loss: 0.5994
	--> Final training Epoch [12/100], Loss: 0.6305
	--> Final training Epoch [13/100], Loss: 0.5610
	--> Final training Epoch [14/100], Loss: 0.6059
	--> Final training Epoch [15/100], Loss: 0.5832
	--> Final training Epoch [16/100], Loss: 0.5889
	--> Final training Epoch [17/100], Loss: 0.6055
	--> Final training Epoch [18/100], Loss: 0.5608
	--> Final training Epoch [19/100], Loss: 0.5802
	--> Final training Epoch [20/100], Loss: 0.5868
	--> Final training Epoch [21/100], Loss: 0.5435
	--> Final training Epoch [22/100], Loss: 0.5370
	--> Final training Epoch [23/100], Loss: 0.5519
	--> Final training Epoch [24/100], Loss: 0.5472
	--> Final training Epoch [25/100], Loss: 0.5103
	--> Final training Epoch [26/100], Loss: 0.5132
	--> Final training Epoch [27/100], Loss: 0.5351
	--> Final training Epoch [28/100], Loss: 0.5187
	--> Final training Epoch [29/100], Loss: 0.5056
	--> Final training Epoch [30/100], Loss: 0.5086
	--> Final training Epoch [31/100], Loss: 0.5060
	--> Final training Epoch [32/100], Loss: 0.5255
	--> Final training Epoch [33/100], Loss: 0.5066
	--> Final training Epoch [34/100], Loss: 0.4580
	--> Final training Epoch [35/100], Loss: 0.4943
	--> Final training Epoch [36/100], Loss: 0.4812
	--> Final training Epoch [37/100], Loss: 0.4990
	--> Final training Epoch [38/100], Loss: 0.4723
	--> Final training Epoch [39/100], Loss: 0.4499
	--> Final training Epoch [40/100], Loss: 0.4975
	--> Final training Epoch [41/100], Loss: 0.4749
	--> Final training Epoch [42/100], Loss: 0.4532
	--> Final training Epoch [43/100], Loss: 0.4204
	--> Final training Epoch [44/100], Loss: 0.4178
	--> Final training Epoch [45/100], Loss: 0.4133
	--> Final training Epoch [46/100], Loss: 0.4083
	--> Final training Epoch [47/100], Loss: 0.4285
	--> Final training Epoch [48/100], Loss: 0.4429
	--> Final training Epoch [49/100], Loss: 0.4232
	--> Final training Epoch [50/100], Loss: 0.4447
	--> Final training Epoch [51/100], Loss: 0.4172
	--> Final training Epoch [52/100], Loss: 0.3898
	--> Final training Epoch [53/100], Loss: 0.3712
	--> Final training Epoch [54/100], Loss: 0.4105
	--> Final training Epoch [55/100], Loss: 0.4177
	--> Final training Epoch [56/100], Loss: 0.3879
	--> Final training Epoch [57/100], Loss: 0.3976
	--> Final training Epoch [58/100], Loss: 0.3985
	--> Final training Epoch [59/100], Loss: 0.3419
	--> Final training Epoch [60/100], Loss: 0.3861
	--> Final training Epoch [61/100], Loss: 0.3833
	--> Final training Epoch [62/100], Loss: 0.3562
	--> Final training Epoch [63/100], Loss: 0.3975
	--> Final training Epoch [64/100], Loss: 0.4054
	--> Final training Epoch [65/100], Loss: 0.3302
	--> Final training Epoch [66/100], Loss: 0.4092
	--> Final training Epoch [67/100], Loss: 0.3546
	--> Final training Epoch [68/100], Loss: 0.3317
	--> Final training Epoch [69/100], Loss: 0.3079
	--> Final training Epoch [70/100], Loss: 0.3317
	--> Final training Epoch [71/100], Loss: 0.3771
	--> Final training Epoch [72/100], Loss: 0.4085
	--> Final training Epoch [73/100], Loss: 0.4259
	--> Final training Epoch [74/100], Loss: 0.2687
	--> Final training Epoch [75/100], Loss: 0.3051
	--> Final training Epoch [76/100], Loss: 0.3775
	--> Final training Epoch [77/100], Loss: 0.3194
	--> Final training Epoch [78/100], Loss: 0.3276
	--> Final training Epoch [79/100], Loss: 0.3254
	--> Final training Epoch [80/100], Loss: 0.3216
	--> Final training Epoch [81/100], Loss: 0.3176
	--> Final training Epoch [82/100], Loss: 0.3378
	--> Final training Epoch [83/100], Loss: 0.2962
	--> Final training Epoch [84/100], Loss: 0.3458
	--> Final training Epoch [85/100], Loss: 0.3116
	--> Final training Epoch [86/100], Loss: 0.3610
	--> Final training Epoch [87/100], Loss: 0.3659
	--> Final training Epoch [88/100], Loss: 0.2930
	--> Final training Epoch [89/100], Loss: 0.3074
	--> Final training Epoch [90/100], Loss: 0.2650
	--> Final training Epoch [91/100], Loss: 0.3005
	--> Final training Epoch [92/100], Loss: 0.3079
	--> Final training Epoch [93/100], Loss: 0.2983
	--> Final training Epoch [94/100], Loss: 0.2688
	--> Final training Epoch [95/100], Loss: 0.3439
	--> Final training Epoch [96/100], Loss: 0.2976
	--> Final training Epoch [97/100], Loss: 0.2910
	--> Final training Epoch [98/100], Loss: 0.2815
	--> Final training Epoch [99/100], Loss: 0.2935
	--> Final training Epoch [100/100], Loss: 0.2608

Final training took 0.3528251647949219 sec

TESTING
	--> Testing took 0.0085 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.7601
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3758,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3758
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3854,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3758

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6817, Validation Loss: 0.6801
	--> Epoch [2/100], Loss: 0.6746, Validation Loss: 0.6648
	--> Epoch [3/100], Loss: 0.6524, Validation Loss: 0.6508
	--> Epoch [4/100], Loss: 0.6199, Validation Loss: 0.6336
	--> Epoch [5/100], Loss: 0.6092, Validation Loss: 0.6206
	--> Epoch [6/100], Loss: 0.6105, Validation Loss: 0.6111
	--> Epoch [7/100], Loss: 0.5925, Validation Loss: 0.6008
	--> Epoch [8/100], Loss: 0.5608, Validation Loss: 0.5885
	--> Epoch [9/100], Loss: 0.5530, Validation Loss: 0.5784
	--> Epoch [10/100], Loss: 0.5431, Validation Loss: 0.5691
	--> Epoch [11/100], Loss: 0.5280, Validation Loss: 0.5630
	--> Epoch [12/100], Loss: 0.5092, Validation Loss: 0.5537
	--> Epoch [13/100], Loss: 0.5303, Validation Loss: 0.5452
	--> Epoch [14/100], Loss: 0.4909, Validation Loss: 0.5368
	--> Epoch [15/100], Loss: 0.4906, Validation Loss: 0.5289
	--> Epoch [16/100], Loss: 0.4796, Validation Loss: 0.5212
	--> Epoch [17/100], Loss: 0.4979, Validation Loss: 0.5141
	--> Epoch [18/100], Loss: 0.4240, Validation Loss: 0.5076
	--> Epoch [19/100], Loss: 0.4383, Validation Loss: 0.5004
	--> Epoch [20/100], Loss: 0.4441, Validation Loss: 0.4933
	--> Epoch [21/100], Loss: 0.4123, Validation Loss: 0.4881
	--> Epoch [22/100], Loss: 0.4287, Validation Loss: 0.4812
	--> Epoch [23/100], Loss: 0.4220, Validation Loss: 0.4754
	--> Epoch [24/100], Loss: 0.4141, Validation Loss: 0.4700
	--> Epoch [25/100], Loss: 0.4002, Validation Loss: 0.4654
	--> Epoch [26/100], Loss: 0.3915, Validation Loss: 0.4585
	--> Epoch [27/100], Loss: 0.3823, Validation Loss: 0.4537
	--> Epoch [28/100], Loss: 0.3925, Validation Loss: 0.4485
	--> Epoch [29/100], Loss: 0.3413, Validation Loss: 0.4439
	--> Epoch [30/100], Loss: 0.3608, Validation Loss: 0.4393
	--> Epoch [31/100], Loss: 0.3603, Validation Loss: 0.4355
	--> Epoch [32/100], Loss: 0.3360, Validation Loss: 0.4307
	--> Epoch [33/100], Loss: 0.3596, Validation Loss: 0.4282
	--> Epoch [34/100], Loss: 0.3246, Validation Loss: 0.4226
	--> Epoch [35/100], Loss: 0.3118, Validation Loss: 0.4192
	--> Epoch [36/100], Loss: 0.3221, Validation Loss: 0.4150
	--> Epoch [37/100], Loss: 0.3414, Validation Loss: 0.4107
	--> Epoch [38/100], Loss: 0.3065, Validation Loss: 0.4064
	--> Epoch [39/100], Loss: 0.3017, Validation Loss: 0.4025
	--> Epoch [40/100], Loss: 0.2797, Validation Loss: 0.3983
	--> Epoch [41/100], Loss: 0.3055, Validation Loss: 0.3936
	--> Epoch [42/100], Loss: 0.2907, Validation Loss: 0.3898
	--> Epoch [43/100], Loss: 0.3098, Validation Loss: 0.3862
	--> Epoch [44/100], Loss: 0.2777, Validation Loss: 0.3849
	--> Epoch [45/100], Loss: 0.2735, Validation Loss: 0.3814
	--> Epoch [46/100], Loss: 0.2547, Validation Loss: 0.3791
	--> Epoch [47/100], Loss: 0.2634, Validation Loss: 0.3757
	--> Epoch [48/100], Loss: 0.2624, Validation Loss: 0.3727
	--> Epoch [49/100], Loss: 0.2377, Validation Loss: 0.3700
	--> Epoch [50/100], Loss: 0.2664, Validation Loss: 0.3669
	--> Epoch [51/100], Loss: 0.2551, Validation Loss: 0.3650
	--> Epoch [52/100], Loss: 0.2367, Validation Loss: 0.3616
	--> Epoch [53/100], Loss: 0.2355, Validation Loss: 0.3577
	--> Epoch [54/100], Loss: 0.2516, Validation Loss: 0.3543
	--> Epoch [55/100], Loss: 0.2450, Validation Loss: 0.3517
	--> Epoch [56/100], Loss: 0.2080, Validation Loss: 0.3490
	--> Epoch [57/100], Loss: 0.2158, Validation Loss: 0.3475
	--> Epoch [58/100], Loss: 0.2051, Validation Loss: 0.3465
	--> Epoch [59/100], Loss: 0.2074, Validation Loss: 0.3439
	--> Epoch [60/100], Loss: 0.1955, Validation Loss: 0.3409
	--> Epoch [61/100], Loss: 0.2011, Validation Loss: 0.3382
	--> Epoch [62/100], Loss: 0.1823, Validation Loss: 0.3366
	--> Epoch [63/100], Loss: 0.2121, Validation Loss: 0.3350
	--> Epoch [64/100], Loss: 0.1996, Validation Loss: 0.3343
	--> Epoch [65/100], Loss: 0.1744, Validation Loss: 0.3302
	--> Epoch [66/100], Loss: 0.1953, Validation Loss: 0.3276
	--> Epoch [67/100], Loss: 0.1937, Validation Loss: 0.3267
	--> Epoch [68/100], Loss: 0.1877, Validation Loss: 0.3247
	--> Epoch [69/100], Loss: 0.2036, Validation Loss: 0.3213
	--> Epoch [70/100], Loss: 0.1804, Validation Loss: 0.3193
	--> Epoch [71/100], Loss: 0.1869, Validation Loss: 0.3177
	--> Epoch [72/100], Loss: 0.1461, Validation Loss: 0.3159
	--> Epoch [73/100], Loss: 0.1541, Validation Loss: 0.3138
	--> Epoch [74/100], Loss: 0.1659, Validation Loss: 0.3129
	--> Epoch [75/100], Loss: 0.2026, Validation Loss: 0.3111
	--> Epoch [76/100], Loss: 0.1623, Validation Loss: 0.3100
	--> Epoch [77/100], Loss: 0.1475, Validation Loss: 0.3090
	--> Epoch [78/100], Loss: 0.1500, Validation Loss: 0.3079
	--> Epoch [79/100], Loss: 0.1721, Validation Loss: 0.3055
	--> Epoch [80/100], Loss: 0.1560, Validation Loss: 0.3047
	--> Epoch [81/100], Loss: 0.1635, Validation Loss: 0.3032
	--> Epoch [82/100], Loss: 0.1384, Validation Loss: 0.3020
	--> Epoch [83/100], Loss: 0.1633, Validation Loss: 0.3006
	--> Epoch [84/100], Loss: 0.1346, Validation Loss: 0.3005
	--> Epoch [85/100], Loss: 0.1467, Validation Loss: 0.3001
	--> Epoch [86/100], Loss: 0.1532, Validation Loss: 0.2998
	--> Epoch [87/100], Loss: 0.1541, Validation Loss: 0.2983
	--> Epoch [88/100], Loss: 0.1628, Validation Loss: 0.2964
	--> Epoch [89/100], Loss: 0.1420, Validation Loss: 0.2950
	--> Epoch [90/100], Loss: 0.1333, Validation Loss: 0.2937
	--> Epoch [91/100], Loss: 0.1223, Validation Loss: 0.2926
	--> Epoch [92/100], Loss: 0.1296, Validation Loss: 0.2921
	--> Epoch [93/100], Loss: 0.1305, Validation Loss: 0.2911
	--> Epoch [94/100], Loss: 0.1250, Validation Loss: 0.2912
	--> Epoch [95/100], Loss: 0.0996, Validation Loss: 0.2907
	--> Epoch [96/100], Loss: 0.1407, Validation Loss: 0.2903
	--> Epoch [97/100], Loss: 0.1389, Validation Loss: 0.2894
	--> Epoch [98/100], Loss: 0.1433, Validation Loss: 0.2884
	--> Epoch [99/100], Loss: 0.0948, Validation Loss: 0.2883
	--> Epoch [100/100], Loss: 0.1403, Validation Loss: 0.2887
	--> Training for Fold 1 took 0.41082143783569336 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6770, Validation Loss: 0.7020
	--> Epoch [2/100], Loss: 0.6459, Validation Loss: 0.6780
	--> Epoch [3/100], Loss: 0.6660, Validation Loss: 0.6506
	--> Epoch [4/100], Loss: 0.6072, Validation Loss: 0.6315
	--> Epoch [5/100], Loss: 0.6188, Validation Loss: 0.6173
	--> Epoch [6/100], Loss: 0.5821, Validation Loss: 0.6007
	--> Epoch [7/100], Loss: 0.5474, Validation Loss: 0.5846
	--> Epoch [8/100], Loss: 0.5817, Validation Loss: 0.5683
	--> Epoch [9/100], Loss: 0.5275, Validation Loss: 0.5574
	--> Epoch [10/100], Loss: 0.5256, Validation Loss: 0.5422
	--> Epoch [11/100], Loss: 0.5003, Validation Loss: 0.5305
	--> Epoch [12/100], Loss: 0.5016, Validation Loss: 0.5186
	--> Epoch [13/100], Loss: 0.4570, Validation Loss: 0.5083
	--> Epoch [14/100], Loss: 0.4663, Validation Loss: 0.4994
	--> Epoch [15/100], Loss: 0.4885, Validation Loss: 0.4896
	--> Epoch [16/100], Loss: 0.4315, Validation Loss: 0.4806
	--> Epoch [17/100], Loss: 0.4169, Validation Loss: 0.4727
	--> Epoch [18/100], Loss: 0.4192, Validation Loss: 0.4659
	--> Epoch [19/100], Loss: 0.4137, Validation Loss: 0.4621
	--> Epoch [20/100], Loss: 0.4187, Validation Loss: 0.4563
	--> Epoch [21/100], Loss: 0.4020, Validation Loss: 0.4526
	--> Epoch [22/100], Loss: 0.3834, Validation Loss: 0.4478
	--> Epoch [23/100], Loss: 0.3877, Validation Loss: 0.4434
	--> Epoch [24/100], Loss: 0.3710, Validation Loss: 0.4399
	--> Epoch [25/100], Loss: 0.3372, Validation Loss: 0.4322
	--> Epoch [26/100], Loss: 0.3829, Validation Loss: 0.4280
	--> Epoch [27/100], Loss: 0.3402, Validation Loss: 0.4239
	--> Epoch [28/100], Loss: 0.3210, Validation Loss: 0.4190
	--> Epoch [29/100], Loss: 0.3493, Validation Loss: 0.4134
	--> Epoch [30/100], Loss: 0.3054, Validation Loss: 0.4084
	--> Epoch [31/100], Loss: 0.3201, Validation Loss: 0.4052
	--> Epoch [32/100], Loss: 0.3296, Validation Loss: 0.4016
	--> Epoch [33/100], Loss: 0.3234, Validation Loss: 0.3967
	--> Epoch [34/100], Loss: 0.3188, Validation Loss: 0.3933
	--> Epoch [35/100], Loss: 0.3068, Validation Loss: 0.3892
	--> Epoch [36/100], Loss: 0.3090, Validation Loss: 0.3867
	--> Epoch [37/100], Loss: 0.2831, Validation Loss: 0.3831
	--> Epoch [38/100], Loss: 0.2681, Validation Loss: 0.3809
	--> Epoch [39/100], Loss: 0.2662, Validation Loss: 0.3769
	--> Epoch [40/100], Loss: 0.2527, Validation Loss: 0.3729
	--> Epoch [41/100], Loss: 0.2815, Validation Loss: 0.3692
	--> Epoch [42/100], Loss: 0.2246, Validation Loss: 0.3673
	--> Epoch [43/100], Loss: 0.2581, Validation Loss: 0.3647
	--> Epoch [44/100], Loss: 0.2523, Validation Loss: 0.3617
	--> Epoch [45/100], Loss: 0.2483, Validation Loss: 0.3588
	--> Epoch [46/100], Loss: 0.2393, Validation Loss: 0.3565
	--> Epoch [47/100], Loss: 0.2465, Validation Loss: 0.3537
	--> Epoch [48/100], Loss: 0.2377, Validation Loss: 0.3516
	--> Epoch [49/100], Loss: 0.2323, Validation Loss: 0.3496
	--> Epoch [50/100], Loss: 0.2116, Validation Loss: 0.3481
	--> Epoch [51/100], Loss: 0.1945, Validation Loss: 0.3459
	--> Epoch [52/100], Loss: 0.2264, Validation Loss: 0.3427
	--> Epoch [53/100], Loss: 0.2172, Validation Loss: 0.3406
	--> Epoch [54/100], Loss: 0.2007, Validation Loss: 0.3381
	--> Epoch [55/100], Loss: 0.1861, Validation Loss: 0.3364
	--> Epoch [56/100], Loss: 0.2072, Validation Loss: 0.3341
	--> Epoch [57/100], Loss: 0.1802, Validation Loss: 0.3335
	--> Epoch [58/100], Loss: 0.2034, Validation Loss: 0.3305
	--> Epoch [59/100], Loss: 0.2175, Validation Loss: 0.3293
	--> Epoch [60/100], Loss: 0.2078, Validation Loss: 0.3275
	--> Epoch [61/100], Loss: 0.1747, Validation Loss: 0.3262
	--> Epoch [62/100], Loss: 0.1804, Validation Loss: 0.3252
	--> Epoch [63/100], Loss: 0.1934, Validation Loss: 0.3234
	--> Epoch [64/100], Loss: 0.1633, Validation Loss: 0.3211
	--> Epoch [65/100], Loss: 0.1634, Validation Loss: 0.3206
	--> Epoch [66/100], Loss: 0.1645, Validation Loss: 0.3197
	--> Epoch [67/100], Loss: 0.1750, Validation Loss: 0.3185
	--> Epoch [68/100], Loss: 0.1718, Validation Loss: 0.3168
	--> Epoch [69/100], Loss: 0.1629, Validation Loss: 0.3146
	--> Epoch [70/100], Loss: 0.1588, Validation Loss: 0.3143
	--> Epoch [71/100], Loss: 0.1354, Validation Loss: 0.3139
	--> Epoch [72/100], Loss: 0.1768, Validation Loss: 0.3123
	--> Epoch [73/100], Loss: 0.1790, Validation Loss: 0.3122
	--> Epoch [74/100], Loss: 0.1828, Validation Loss: 0.3115
	--> Epoch [75/100], Loss: 0.1569, Validation Loss: 0.3104
	--> Epoch [76/100], Loss: 0.1382, Validation Loss: 0.3083
	--> Epoch [77/100], Loss: 0.1278, Validation Loss: 0.3091
	--> Epoch [78/100], Loss: 0.1444, Validation Loss: 0.3090
	--> Epoch [79/100], Loss: 0.1814, Validation Loss: 0.3098
Early stopping
	--> Training for Fold 2 took 0.30313992500305176 sec, using 79 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6890, Validation Loss: 0.6771
	--> Epoch [2/100], Loss: 0.6735, Validation Loss: 0.6683
	--> Epoch [3/100], Loss: 0.6514, Validation Loss: 0.6595
	--> Epoch [4/100], Loss: 0.6440, Validation Loss: 0.6489
	--> Epoch [5/100], Loss: 0.5918, Validation Loss: 0.6365
	--> Epoch [6/100], Loss: 0.5918, Validation Loss: 0.6256
	--> Epoch [7/100], Loss: 0.5817, Validation Loss: 0.6171
	--> Epoch [8/100], Loss: 0.5384, Validation Loss: 0.6083
	--> Epoch [9/100], Loss: 0.5438, Validation Loss: 0.5995
	--> Epoch [10/100], Loss: 0.5236, Validation Loss: 0.5904
	--> Epoch [11/100], Loss: 0.4862, Validation Loss: 0.5809
	--> Epoch [12/100], Loss: 0.5135, Validation Loss: 0.5729
	--> Epoch [13/100], Loss: 0.4864, Validation Loss: 0.5648
	--> Epoch [14/100], Loss: 0.4640, Validation Loss: 0.5577
	--> Epoch [15/100], Loss: 0.4510, Validation Loss: 0.5486
	--> Epoch [16/100], Loss: 0.4468, Validation Loss: 0.5419
	--> Epoch [17/100], Loss: 0.4331, Validation Loss: 0.5352
	--> Epoch [18/100], Loss: 0.4191, Validation Loss: 0.5286
	--> Epoch [19/100], Loss: 0.3920, Validation Loss: 0.5206
	--> Epoch [20/100], Loss: 0.3851, Validation Loss: 0.5143
	--> Epoch [21/100], Loss: 0.3834, Validation Loss: 0.5078
	--> Epoch [22/100], Loss: 0.3775, Validation Loss: 0.5019
	--> Epoch [23/100], Loss: 0.3523, Validation Loss: 0.4952
	--> Epoch [24/100], Loss: 0.3573, Validation Loss: 0.4899
	--> Epoch [25/100], Loss: 0.3528, Validation Loss: 0.4849
	--> Epoch [26/100], Loss: 0.3400, Validation Loss: 0.4805
	--> Epoch [27/100], Loss: 0.3431, Validation Loss: 0.4759
	--> Epoch [28/100], Loss: 0.3262, Validation Loss: 0.4709
	--> Epoch [29/100], Loss: 0.3237, Validation Loss: 0.4660
	--> Epoch [30/100], Loss: 0.3076, Validation Loss: 0.4627
	--> Epoch [31/100], Loss: 0.2853, Validation Loss: 0.4576
	--> Epoch [32/100], Loss: 0.2977, Validation Loss: 0.4537
	--> Epoch [33/100], Loss: 0.2986, Validation Loss: 0.4506
	--> Epoch [34/100], Loss: 0.2783, Validation Loss: 0.4472
	--> Epoch [35/100], Loss: 0.2675, Validation Loss: 0.4436
	--> Epoch [36/100], Loss: 0.2659, Validation Loss: 0.4403
	--> Epoch [37/100], Loss: 0.2667, Validation Loss: 0.4363
	--> Epoch [38/100], Loss: 0.2692, Validation Loss: 0.4325
	--> Epoch [39/100], Loss: 0.2580, Validation Loss: 0.4294
	--> Epoch [40/100], Loss: 0.2585, Validation Loss: 0.4267
	--> Epoch [41/100], Loss: 0.2582, Validation Loss: 0.4242
	--> Epoch [42/100], Loss: 0.2395, Validation Loss: 0.4212
	--> Epoch [43/100], Loss: 0.2454, Validation Loss: 0.4175
	--> Epoch [44/100], Loss: 0.2556, Validation Loss: 0.4161
	--> Epoch [45/100], Loss: 0.2317, Validation Loss: 0.4123
	--> Epoch [46/100], Loss: 0.2196, Validation Loss: 0.4095
	--> Epoch [47/100], Loss: 0.2393, Validation Loss: 0.4084
	--> Epoch [48/100], Loss: 0.1903, Validation Loss: 0.4061
	--> Epoch [49/100], Loss: 0.2201, Validation Loss: 0.4032
	--> Epoch [50/100], Loss: 0.2296, Validation Loss: 0.4015
	--> Epoch [51/100], Loss: 0.1692, Validation Loss: 0.3997
	--> Epoch [52/100], Loss: 0.1769, Validation Loss: 0.3984
	--> Epoch [53/100], Loss: 0.1801, Validation Loss: 0.3957
	--> Epoch [54/100], Loss: 0.1549, Validation Loss: 0.3934
	--> Epoch [55/100], Loss: 0.1886, Validation Loss: 0.3905
	--> Epoch [56/100], Loss: 0.1932, Validation Loss: 0.3884
	--> Epoch [57/100], Loss: 0.1837, Validation Loss: 0.3869
	--> Epoch [58/100], Loss: 0.1658, Validation Loss: 0.3854
	--> Epoch [59/100], Loss: 0.1454, Validation Loss: 0.3828
	--> Epoch [60/100], Loss: 0.1644, Validation Loss: 0.3813
	--> Epoch [61/100], Loss: 0.1876, Validation Loss: 0.3801
	--> Epoch [62/100], Loss: 0.1789, Validation Loss: 0.3776
	--> Epoch [63/100], Loss: 0.1302, Validation Loss: 0.3760
	--> Epoch [64/100], Loss: 0.1595, Validation Loss: 0.3745
	--> Epoch [65/100], Loss: 0.1493, Validation Loss: 0.3735
	--> Epoch [66/100], Loss: 0.1352, Validation Loss: 0.3716
	--> Epoch [67/100], Loss: 0.1493, Validation Loss: 0.3688
	--> Epoch [68/100], Loss: 0.1265, Validation Loss: 0.3669
	--> Epoch [69/100], Loss: 0.1642, Validation Loss: 0.3665
	--> Epoch [70/100], Loss: 0.1710, Validation Loss: 0.3647
	--> Epoch [71/100], Loss: 0.1204, Validation Loss: 0.3625
	--> Epoch [72/100], Loss: 0.1635, Validation Loss: 0.3617
	--> Epoch [73/100], Loss: 0.1098, Validation Loss: 0.3602
	--> Epoch [74/100], Loss: 0.1353, Validation Loss: 0.3587
	--> Epoch [75/100], Loss: 0.1237, Validation Loss: 0.3581
	--> Epoch [76/100], Loss: 0.1338, Validation Loss: 0.3574
	--> Epoch [77/100], Loss: 0.1232, Validation Loss: 0.3572
	--> Epoch [78/100], Loss: 0.1371, Validation Loss: 0.3552
	--> Epoch [79/100], Loss: 0.1237, Validation Loss: 0.3537
	--> Epoch [80/100], Loss: 0.0981, Validation Loss: 0.3529
	--> Epoch [81/100], Loss: 0.1186, Validation Loss: 0.3514
	--> Epoch [82/100], Loss: 0.1087, Validation Loss: 0.3485
	--> Epoch [83/100], Loss: 0.1177, Validation Loss: 0.3465
	--> Epoch [84/100], Loss: 0.1132, Validation Loss: 0.3448
	--> Epoch [85/100], Loss: 0.1043, Validation Loss: 0.3429
	--> Epoch [86/100], Loss: 0.0995, Validation Loss: 0.3430
	--> Epoch [87/100], Loss: 0.1096, Validation Loss: 0.3421
	--> Epoch [88/100], Loss: 0.1403, Validation Loss: 0.3410
	--> Epoch [89/100], Loss: 0.1301, Validation Loss: 0.3394
	--> Epoch [90/100], Loss: 0.0966, Validation Loss: 0.3389
	--> Epoch [91/100], Loss: 0.0983, Validation Loss: 0.3386
	--> Epoch [92/100], Loss: 0.0890, Validation Loss: 0.3385
	--> Epoch [93/100], Loss: 0.0963, Validation Loss: 0.3374
	--> Epoch [94/100], Loss: 0.1243, Validation Loss: 0.3369
	--> Epoch [95/100], Loss: 0.1048, Validation Loss: 0.3364
	--> Epoch [96/100], Loss: 0.1083, Validation Loss: 0.3351
	--> Epoch [97/100], Loss: 0.0951, Validation Loss: 0.3342
	--> Epoch [98/100], Loss: 0.1032, Validation Loss: 0.3337
	--> Epoch [99/100], Loss: 0.1067, Validation Loss: 0.3338
	--> Epoch [100/100], Loss: 0.0996, Validation Loss: 0.3329
	--> Training for Fold 3 took 0.3894369602203369 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6973, Validation Loss: 0.6130
	--> Epoch [2/100], Loss: 0.6919, Validation Loss: 0.6062
	--> Epoch [3/100], Loss: 0.6701, Validation Loss: 0.6004
	--> Epoch [4/100], Loss: 0.6593, Validation Loss: 0.5934
	--> Epoch [5/100], Loss: 0.6657, Validation Loss: 0.5863
	--> Epoch [6/100], Loss: 0.6372, Validation Loss: 0.5785
	--> Epoch [7/100], Loss: 0.6344, Validation Loss: 0.5721
	--> Epoch [8/100], Loss: 0.6245, Validation Loss: 0.5655
	--> Epoch [9/100], Loss: 0.6099, Validation Loss: 0.5583
	--> Epoch [10/100], Loss: 0.6122, Validation Loss: 0.5534
	--> Epoch [11/100], Loss: 0.6015, Validation Loss: 0.5459
	--> Epoch [12/100], Loss: 0.5897, Validation Loss: 0.5412
	--> Epoch [13/100], Loss: 0.5772, Validation Loss: 0.5370
	--> Epoch [14/100], Loss: 0.5507, Validation Loss: 0.5315
	--> Epoch [15/100], Loss: 0.5540, Validation Loss: 0.5255
	--> Epoch [16/100], Loss: 0.5282, Validation Loss: 0.5211
	--> Epoch [17/100], Loss: 0.5299, Validation Loss: 0.5145
	--> Epoch [18/100], Loss: 0.5237, Validation Loss: 0.5104
	--> Epoch [19/100], Loss: 0.5015, Validation Loss: 0.5066
	--> Epoch [20/100], Loss: 0.4959, Validation Loss: 0.5008
	--> Epoch [21/100], Loss: 0.4750, Validation Loss: 0.4934
	--> Epoch [22/100], Loss: 0.4692, Validation Loss: 0.4889
	--> Epoch [23/100], Loss: 0.4635, Validation Loss: 0.4829
	--> Epoch [24/100], Loss: 0.4602, Validation Loss: 0.4776
	--> Epoch [25/100], Loss: 0.4420, Validation Loss: 0.4707
	--> Epoch [26/100], Loss: 0.4441, Validation Loss: 0.4678
	--> Epoch [27/100], Loss: 0.4289, Validation Loss: 0.4634
	--> Epoch [28/100], Loss: 0.4038, Validation Loss: 0.4595
	--> Epoch [29/100], Loss: 0.4121, Validation Loss: 0.4543
	--> Epoch [30/100], Loss: 0.3960, Validation Loss: 0.4487
	--> Epoch [31/100], Loss: 0.4032, Validation Loss: 0.4440
	--> Epoch [32/100], Loss: 0.3794, Validation Loss: 0.4376
	--> Epoch [33/100], Loss: 0.3933, Validation Loss: 0.4317
	--> Epoch [34/100], Loss: 0.3660, Validation Loss: 0.4291
	--> Epoch [35/100], Loss: 0.3629, Validation Loss: 0.4238
	--> Epoch [36/100], Loss: 0.3261, Validation Loss: 0.4207
	--> Epoch [37/100], Loss: 0.3602, Validation Loss: 0.4164
	--> Epoch [38/100], Loss: 0.3369, Validation Loss: 0.4125
	--> Epoch [39/100], Loss: 0.3053, Validation Loss: 0.4094
	--> Epoch [40/100], Loss: 0.3202, Validation Loss: 0.4061
	--> Epoch [41/100], Loss: 0.3255, Validation Loss: 0.4021
	--> Epoch [42/100], Loss: 0.2857, Validation Loss: 0.4005
	--> Epoch [43/100], Loss: 0.3089, Validation Loss: 0.3957
	--> Epoch [44/100], Loss: 0.2771, Validation Loss: 0.3925
	--> Epoch [45/100], Loss: 0.2840, Validation Loss: 0.3896
	--> Epoch [46/100], Loss: 0.2829, Validation Loss: 0.3859
	--> Epoch [47/100], Loss: 0.2940, Validation Loss: 0.3847
	--> Epoch [48/100], Loss: 0.2803, Validation Loss: 0.3819
	--> Epoch [49/100], Loss: 0.2540, Validation Loss: 0.3796
	--> Epoch [50/100], Loss: 0.2610, Validation Loss: 0.3777
	--> Epoch [51/100], Loss: 0.2425, Validation Loss: 0.3741
	--> Epoch [52/100], Loss: 0.2518, Validation Loss: 0.3727
	--> Epoch [53/100], Loss: 0.2438, Validation Loss: 0.3705
	--> Epoch [54/100], Loss: 0.2595, Validation Loss: 0.3688
	--> Epoch [55/100], Loss: 0.2788, Validation Loss: 0.3678
	--> Epoch [56/100], Loss: 0.2435, Validation Loss: 0.3647
	--> Epoch [57/100], Loss: 0.2388, Validation Loss: 0.3652
	--> Epoch [58/100], Loss: 0.2303, Validation Loss: 0.3632
	--> Epoch [59/100], Loss: 0.1925, Validation Loss: 0.3624
	--> Epoch [60/100], Loss: 0.2234, Validation Loss: 0.3602
	--> Epoch [61/100], Loss: 0.2051, Validation Loss: 0.3593
	--> Epoch [62/100], Loss: 0.2078, Validation Loss: 0.3579
	--> Epoch [63/100], Loss: 0.1926, Validation Loss: 0.3556
	--> Epoch [64/100], Loss: 0.2063, Validation Loss: 0.3551
	--> Epoch [65/100], Loss: 0.2068, Validation Loss: 0.3546
	--> Epoch [66/100], Loss: 0.1905, Validation Loss: 0.3542
	--> Epoch [67/100], Loss: 0.1678, Validation Loss: 0.3527
	--> Epoch [68/100], Loss: 0.2040, Validation Loss: 0.3526
	--> Epoch [69/100], Loss: 0.1783, Validation Loss: 0.3515
	--> Epoch [70/100], Loss: 0.1691, Validation Loss: 0.3502
	--> Epoch [71/100], Loss: 0.1772, Validation Loss: 0.3488
	--> Epoch [72/100], Loss: 0.1488, Validation Loss: 0.3480
	--> Epoch [73/100], Loss: 0.1907, Validation Loss: 0.3474
	--> Epoch [74/100], Loss: 0.1847, Validation Loss: 0.3463
	--> Epoch [75/100], Loss: 0.1604, Validation Loss: 0.3451
	--> Epoch [76/100], Loss: 0.1600, Validation Loss: 0.3443
	--> Epoch [77/100], Loss: 0.1625, Validation Loss: 0.3437
	--> Epoch [78/100], Loss: 0.1585, Validation Loss: 0.3409
	--> Epoch [79/100], Loss: 0.1505, Validation Loss: 0.3410
	--> Epoch [80/100], Loss: 0.1524, Validation Loss: 0.3397
	--> Epoch [81/100], Loss: 0.1556, Validation Loss: 0.3373
	--> Epoch [82/100], Loss: 0.1652, Validation Loss: 0.3369
	--> Epoch [83/100], Loss: 0.1728, Validation Loss: 0.3361
	--> Epoch [84/100], Loss: 0.1246, Validation Loss: 0.3356
	--> Epoch [85/100], Loss: 0.1598, Validation Loss: 0.3338
	--> Epoch [86/100], Loss: 0.1689, Validation Loss: 0.3337
	--> Epoch [87/100], Loss: 0.1331, Validation Loss: 0.3330
	--> Epoch [88/100], Loss: 0.1279, Validation Loss: 0.3320
	--> Epoch [89/100], Loss: 0.1474, Validation Loss: 0.3319
	--> Epoch [90/100], Loss: 0.1578, Validation Loss: 0.3311
	--> Epoch [91/100], Loss: 0.1240, Validation Loss: 0.3312
	--> Epoch [92/100], Loss: 0.1483, Validation Loss: 0.3289
	--> Epoch [93/100], Loss: 0.1098, Validation Loss: 0.3274
	--> Epoch [94/100], Loss: 0.1344, Validation Loss: 0.3269
	--> Epoch [95/100], Loss: 0.1220, Validation Loss: 0.3263
	--> Epoch [96/100], Loss: 0.1425, Validation Loss: 0.3252
	--> Epoch [97/100], Loss: 0.1255, Validation Loss: 0.3233
	--> Epoch [98/100], Loss: 0.1154, Validation Loss: 0.3233
	--> Epoch [99/100], Loss: 0.0959, Validation Loss: 0.3230
	--> Epoch [100/100], Loss: 0.1243, Validation Loss: 0.3224
	--> Training for Fold 4 took 0.41806745529174805 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7463, Validation Loss: 0.6810
	--> Epoch [2/100], Loss: 0.7404, Validation Loss: 0.6750
	--> Epoch [3/100], Loss: 0.7180, Validation Loss: 0.6701
	--> Epoch [4/100], Loss: 0.7014, Validation Loss: 0.6652
	--> Epoch [5/100], Loss: 0.6870, Validation Loss: 0.6603
	--> Epoch [6/100], Loss: 0.6798, Validation Loss: 0.6527
	--> Epoch [7/100], Loss: 0.6645, Validation Loss: 0.6465
	--> Epoch [8/100], Loss: 0.6397, Validation Loss: 0.6405
	--> Epoch [9/100], Loss: 0.6329, Validation Loss: 0.6332
	--> Epoch [10/100], Loss: 0.5976, Validation Loss: 0.6282
	--> Epoch [11/100], Loss: 0.5910, Validation Loss: 0.6215
	--> Epoch [12/100], Loss: 0.5968, Validation Loss: 0.6164
	--> Epoch [13/100], Loss: 0.5893, Validation Loss: 0.6106
	--> Epoch [14/100], Loss: 0.5649, Validation Loss: 0.6047
	--> Epoch [15/100], Loss: 0.5490, Validation Loss: 0.6010
	--> Epoch [16/100], Loss: 0.5314, Validation Loss: 0.5968
	--> Epoch [17/100], Loss: 0.5331, Validation Loss: 0.5933
	--> Epoch [18/100], Loss: 0.4981, Validation Loss: 0.5896
	--> Epoch [19/100], Loss: 0.4788, Validation Loss: 0.5863
	--> Epoch [20/100], Loss: 0.5036, Validation Loss: 0.5820
	--> Epoch [21/100], Loss: 0.4623, Validation Loss: 0.5787
	--> Epoch [22/100], Loss: 0.4822, Validation Loss: 0.5757
	--> Epoch [23/100], Loss: 0.4381, Validation Loss: 0.5731
	--> Epoch [24/100], Loss: 0.4555, Validation Loss: 0.5693
	--> Epoch [25/100], Loss: 0.4326, Validation Loss: 0.5660
	--> Epoch [26/100], Loss: 0.4198, Validation Loss: 0.5629
	--> Epoch [27/100], Loss: 0.4432, Validation Loss: 0.5613
	--> Epoch [28/100], Loss: 0.3895, Validation Loss: 0.5585
	--> Epoch [29/100], Loss: 0.4063, Validation Loss: 0.5553
	--> Epoch [30/100], Loss: 0.4193, Validation Loss: 0.5532
	--> Epoch [31/100], Loss: 0.3798, Validation Loss: 0.5497
	--> Epoch [32/100], Loss: 0.3717, Validation Loss: 0.5484
	--> Epoch [33/100], Loss: 0.3620, Validation Loss: 0.5457
	--> Epoch [34/100], Loss: 0.3712, Validation Loss: 0.5446
	--> Epoch [35/100], Loss: 0.3805, Validation Loss: 0.5421
	--> Epoch [36/100], Loss: 0.3469, Validation Loss: 0.5406
	--> Epoch [37/100], Loss: 0.3285, Validation Loss: 0.5379
	--> Epoch [38/100], Loss: 0.3093, Validation Loss: 0.5373
	--> Epoch [39/100], Loss: 0.3066, Validation Loss: 0.5364
	--> Epoch [40/100], Loss: 0.2859, Validation Loss: 0.5350
	--> Epoch [41/100], Loss: 0.2965, Validation Loss: 0.5343
	--> Epoch [42/100], Loss: 0.3032, Validation Loss: 0.5334
	--> Epoch [43/100], Loss: 0.2853, Validation Loss: 0.5321
	--> Epoch [44/100], Loss: 0.2743, Validation Loss: 0.5309
	--> Epoch [45/100], Loss: 0.2974, Validation Loss: 0.5295
	--> Epoch [46/100], Loss: 0.2630, Validation Loss: 0.5277
	--> Epoch [47/100], Loss: 0.2672, Validation Loss: 0.5267
	--> Epoch [48/100], Loss: 0.2458, Validation Loss: 0.5251
	--> Epoch [49/100], Loss: 0.2624, Validation Loss: 0.5241
	--> Epoch [50/100], Loss: 0.2484, Validation Loss: 0.5228
	--> Epoch [51/100], Loss: 0.2501, Validation Loss: 0.5206
	--> Epoch [52/100], Loss: 0.2494, Validation Loss: 0.5199
	--> Epoch [53/100], Loss: 0.2386, Validation Loss: 0.5187
	--> Epoch [54/100], Loss: 0.2496, Validation Loss: 0.5173
	--> Epoch [55/100], Loss: 0.2258, Validation Loss: 0.5172
	--> Epoch [56/100], Loss: 0.2246, Validation Loss: 0.5175
	--> Epoch [57/100], Loss: 0.2296, Validation Loss: 0.5168
	--> Epoch [58/100], Loss: 0.2205, Validation Loss: 0.5159
	--> Epoch [59/100], Loss: 0.2137, Validation Loss: 0.5161
	--> Epoch [60/100], Loss: 0.2105, Validation Loss: 0.5149
	--> Epoch [61/100], Loss: 0.1966, Validation Loss: 0.5136
	--> Epoch [62/100], Loss: 0.2175, Validation Loss: 0.5140
	--> Epoch [63/100], Loss: 0.2003, Validation Loss: 0.5147
	--> Epoch [64/100], Loss: 0.2077, Validation Loss: 0.5137
Early stopping
	--> Training for Fold 5 took 0.2403264045715332 sec, using 64 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7296
	--> Final training Epoch [2/100], Loss: 0.6781
	--> Final training Epoch [3/100], Loss: 0.6837
	--> Final training Epoch [4/100], Loss: 0.6434
	--> Final training Epoch [5/100], Loss: 0.6325
	--> Final training Epoch [6/100], Loss: 0.5917
	--> Final training Epoch [7/100], Loss: 0.5989
	--> Final training Epoch [8/100], Loss: 0.5625
	--> Final training Epoch [9/100], Loss: 0.5297
	--> Final training Epoch [10/100], Loss: 0.5248
	--> Final training Epoch [11/100], Loss: 0.5438
	--> Final training Epoch [12/100], Loss: 0.4987
	--> Final training Epoch [13/100], Loss: 0.4983
	--> Final training Epoch [14/100], Loss: 0.4923
	--> Final training Epoch [15/100], Loss: 0.4728
	--> Final training Epoch [16/100], Loss: 0.4605
	--> Final training Epoch [17/100], Loss: 0.4492
	--> Final training Epoch [18/100], Loss: 0.4246
	--> Final training Epoch [19/100], Loss: 0.4198
	--> Final training Epoch [20/100], Loss: 0.4111
	--> Final training Epoch [21/100], Loss: 0.4105
	--> Final training Epoch [22/100], Loss: 0.3985
	--> Final training Epoch [23/100], Loss: 0.3959
	--> Final training Epoch [24/100], Loss: 0.3864
	--> Final training Epoch [25/100], Loss: 0.3684
	--> Final training Epoch [26/100], Loss: 0.3577
	--> Final training Epoch [27/100], Loss: 0.3668
	--> Final training Epoch [28/100], Loss: 0.3714
	--> Final training Epoch [29/100], Loss: 0.3511
	--> Final training Epoch [30/100], Loss: 0.3394
	--> Final training Epoch [31/100], Loss: 0.3290
	--> Final training Epoch [32/100], Loss: 0.3221
	--> Final training Epoch [33/100], Loss: 0.3391
	--> Final training Epoch [34/100], Loss: 0.3066
	--> Final training Epoch [35/100], Loss: 0.3204
	--> Final training Epoch [36/100], Loss: 0.2949
	--> Final training Epoch [37/100], Loss: 0.3000
	--> Final training Epoch [38/100], Loss: 0.3019
	--> Final training Epoch [39/100], Loss: 0.2746
	--> Final training Epoch [40/100], Loss: 0.2808
	--> Final training Epoch [41/100], Loss: 0.2703
	--> Final training Epoch [42/100], Loss: 0.2577
	--> Final training Epoch [43/100], Loss: 0.2647
	--> Final training Epoch [44/100], Loss: 0.2591
	--> Final training Epoch [45/100], Loss: 0.2646
	--> Final training Epoch [46/100], Loss: 0.2447
	--> Final training Epoch [47/100], Loss: 0.2301
	--> Final training Epoch [48/100], Loss: 0.2459
	--> Final training Epoch [49/100], Loss: 0.2267
	--> Final training Epoch [50/100], Loss: 0.2275
	--> Final training Epoch [51/100], Loss: 0.2634
	--> Final training Epoch [52/100], Loss: 0.2106
	--> Final training Epoch [53/100], Loss: 0.2235
	--> Final training Epoch [54/100], Loss: 0.1955
	--> Final training Epoch [55/100], Loss: 0.2207
	--> Final training Epoch [56/100], Loss: 0.2115
	--> Final training Epoch [57/100], Loss: 0.1988
	--> Final training Epoch [58/100], Loss: 0.2033
	--> Final training Epoch [59/100], Loss: 0.2198
	--> Final training Epoch [60/100], Loss: 0.1821
	--> Final training Epoch [61/100], Loss: 0.2092
	--> Final training Epoch [62/100], Loss: 0.1911
	--> Final training Epoch [63/100], Loss: 0.1694
	--> Final training Epoch [64/100], Loss: 0.1674
	--> Final training Epoch [65/100], Loss: 0.1980
	--> Final training Epoch [66/100], Loss: 0.1940
	--> Final training Epoch [67/100], Loss: 0.1856
	--> Final training Epoch [68/100], Loss: 0.1658
	--> Final training Epoch [69/100], Loss: 0.1920
	--> Final training Epoch [70/100], Loss: 0.1711
	--> Final training Epoch [71/100], Loss: 0.1590
	--> Final training Epoch [72/100], Loss: 0.1738
	--> Final training Epoch [73/100], Loss: 0.1617
	--> Final training Epoch [74/100], Loss: 0.1720
	--> Final training Epoch [75/100], Loss: 0.1563
	--> Final training Epoch [76/100], Loss: 0.1456
	--> Final training Epoch [77/100], Loss: 0.1599
	--> Final training Epoch [78/100], Loss: 0.1310
	--> Final training Epoch [79/100], Loss: 0.1463
	--> Final training Epoch [80/100], Loss: 0.1430
	--> Final training Epoch [81/100], Loss: 0.1639
	--> Final training Epoch [82/100], Loss: 0.1681
	--> Final training Epoch [83/100], Loss: 0.1664
	--> Final training Epoch [84/100], Loss: 0.1277
	--> Final training Epoch [85/100], Loss: 0.1400
	--> Final training Epoch [86/100], Loss: 0.1171
	--> Final training Epoch [87/100], Loss: 0.1466
	--> Final training Epoch [88/100], Loss: 0.1388
	--> Final training Epoch [89/100], Loss: 0.1511
	--> Final training Epoch [90/100], Loss: 0.1195
	--> Final training Epoch [91/100], Loss: 0.1282
	--> Final training Epoch [92/100], Loss: 0.1297
	--> Final training Epoch [93/100], Loss: 0.1181
	--> Final training Epoch [94/100], Loss: 0.1151
	--> Final training Epoch [95/100], Loss: 0.1298
	--> Final training Epoch [96/100], Loss: 0.1401
	--> Final training Epoch [97/100], Loss: 0.1184
	--> Final training Epoch [98/100], Loss: 0.1134
	--> Final training Epoch [99/100], Loss: 0.1540
	--> Final training Epoch [100/100], Loss: 0.1311

Final training took 0.3533766269683838 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.7855
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8170, Validation Loss: 0.3675,  Current Best Accuracy: 0.8170,  Current Best Validation Loss: 0.3675

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8184, Validation Loss: 0.6125
	--> Epoch [2/100], Loss: 0.8197, Validation Loss: 0.6014
	--> Epoch [3/100], Loss: 0.7851, Validation Loss: 0.5898
	--> Epoch [4/100], Loss: 0.7479, Validation Loss: 0.5794
	--> Epoch [5/100], Loss: 0.7260, Validation Loss: 0.5692
	--> Epoch [6/100], Loss: 0.7184, Validation Loss: 0.5585
	--> Epoch [7/100], Loss: 0.6855, Validation Loss: 0.5464
	--> Epoch [8/100], Loss: 0.6624, Validation Loss: 0.5367
	--> Epoch [9/100], Loss: 0.6579, Validation Loss: 0.5256
	--> Epoch [10/100], Loss: 0.6141, Validation Loss: 0.5174
	--> Epoch [11/100], Loss: 0.6069, Validation Loss: 0.5076
	--> Epoch [12/100], Loss: 0.6131, Validation Loss: 0.4995
	--> Epoch [13/100], Loss: 0.5814, Validation Loss: 0.4913
	--> Epoch [14/100], Loss: 0.5755, Validation Loss: 0.4820
	--> Epoch [15/100], Loss: 0.5411, Validation Loss: 0.4737
	--> Epoch [16/100], Loss: 0.5276, Validation Loss: 0.4657
	--> Epoch [17/100], Loss: 0.5110, Validation Loss: 0.4590
	--> Epoch [18/100], Loss: 0.4949, Validation Loss: 0.4521
	--> Epoch [19/100], Loss: 0.4629, Validation Loss: 0.4450
	--> Epoch [20/100], Loss: 0.4705, Validation Loss: 0.4370
	--> Epoch [21/100], Loss: 0.4594, Validation Loss: 0.4307
	--> Epoch [22/100], Loss: 0.4490, Validation Loss: 0.4253
	--> Epoch [23/100], Loss: 0.4227, Validation Loss: 0.4184
	--> Epoch [24/100], Loss: 0.4519, Validation Loss: 0.4124
	--> Epoch [25/100], Loss: 0.4321, Validation Loss: 0.4073
	--> Epoch [26/100], Loss: 0.3950, Validation Loss: 0.4030
	--> Epoch [27/100], Loss: 0.4017, Validation Loss: 0.3978
	--> Epoch [28/100], Loss: 0.3806, Validation Loss: 0.3925
	--> Epoch [29/100], Loss: 0.3972, Validation Loss: 0.3877
	--> Epoch [30/100], Loss: 0.3882, Validation Loss: 0.3832
	--> Epoch [31/100], Loss: 0.3783, Validation Loss: 0.3795
	--> Epoch [32/100], Loss: 0.3826, Validation Loss: 0.3754
	--> Epoch [33/100], Loss: 0.3257, Validation Loss: 0.3721
	--> Epoch [34/100], Loss: 0.3672, Validation Loss: 0.3679
	--> Epoch [35/100], Loss: 0.3261, Validation Loss: 0.3644
	--> Epoch [36/100], Loss: 0.3294, Validation Loss: 0.3609
	--> Epoch [37/100], Loss: 0.3297, Validation Loss: 0.3563
	--> Epoch [38/100], Loss: 0.3000, Validation Loss: 0.3524
	--> Epoch [39/100], Loss: 0.3176, Validation Loss: 0.3496
	--> Epoch [40/100], Loss: 0.2899, Validation Loss: 0.3465
	--> Epoch [41/100], Loss: 0.2912, Validation Loss: 0.3433
	--> Epoch [42/100], Loss: 0.2963, Validation Loss: 0.3399
	--> Epoch [43/100], Loss: 0.2788, Validation Loss: 0.3368
	--> Epoch [44/100], Loss: 0.3005, Validation Loss: 0.3337
	--> Epoch [45/100], Loss: 0.2898, Validation Loss: 0.3306
	--> Epoch [46/100], Loss: 0.2541, Validation Loss: 0.3281
	--> Epoch [47/100], Loss: 0.2540, Validation Loss: 0.3257
	--> Epoch [48/100], Loss: 0.2759, Validation Loss: 0.3232
	--> Epoch [49/100], Loss: 0.2842, Validation Loss: 0.3204
	--> Epoch [50/100], Loss: 0.2400, Validation Loss: 0.3170
	--> Epoch [51/100], Loss: 0.2402, Validation Loss: 0.3148
	--> Epoch [52/100], Loss: 0.2408, Validation Loss: 0.3129
	--> Epoch [53/100], Loss: 0.2338, Validation Loss: 0.3097
	--> Epoch [54/100], Loss: 0.2184, Validation Loss: 0.3083
	--> Epoch [55/100], Loss: 0.2394, Validation Loss: 0.3061
	--> Epoch [56/100], Loss: 0.2432, Validation Loss: 0.3053
	--> Epoch [57/100], Loss: 0.2228, Validation Loss: 0.3039
	--> Epoch [58/100], Loss: 0.2151, Validation Loss: 0.3020
	--> Epoch [59/100], Loss: 0.1958, Validation Loss: 0.2999
	--> Epoch [60/100], Loss: 0.1860, Validation Loss: 0.2981
	--> Epoch [61/100], Loss: 0.2042, Validation Loss: 0.2972
	--> Epoch [62/100], Loss: 0.2011, Validation Loss: 0.2956
	--> Epoch [63/100], Loss: 0.1951, Validation Loss: 0.2935
	--> Epoch [64/100], Loss: 0.1990, Validation Loss: 0.2931
	--> Epoch [65/100], Loss: 0.2017, Validation Loss: 0.2922
	--> Epoch [66/100], Loss: 0.1886, Validation Loss: 0.2906
	--> Epoch [67/100], Loss: 0.1885, Validation Loss: 0.2901
	--> Epoch [68/100], Loss: 0.1785, Validation Loss: 0.2884
	--> Epoch [69/100], Loss: 0.1553, Validation Loss: 0.2871
	--> Epoch [70/100], Loss: 0.1778, Validation Loss: 0.2854
	--> Epoch [71/100], Loss: 0.1853, Validation Loss: 0.2850
	--> Epoch [72/100], Loss: 0.1817, Validation Loss: 0.2838
	--> Epoch [73/100], Loss: 0.1615, Validation Loss: 0.2828
	--> Epoch [74/100], Loss: 0.1803, Validation Loss: 0.2814
	--> Epoch [75/100], Loss: 0.1739, Validation Loss: 0.2808
	--> Epoch [76/100], Loss: 0.1742, Validation Loss: 0.2794
	--> Epoch [77/100], Loss: 0.1892, Validation Loss: 0.2790
	--> Epoch [78/100], Loss: 0.1573, Validation Loss: 0.2782
	--> Epoch [79/100], Loss: 0.1514, Validation Loss: 0.2761
	--> Epoch [80/100], Loss: 0.1289, Validation Loss: 0.2742
	--> Epoch [81/100], Loss: 0.1715, Validation Loss: 0.2731
	--> Epoch [82/100], Loss: 0.1530, Validation Loss: 0.2717
	--> Epoch [83/100], Loss: 0.1611, Validation Loss: 0.2715
	--> Epoch [84/100], Loss: 0.1646, Validation Loss: 0.2703
	--> Epoch [85/100], Loss: 0.1216, Validation Loss: 0.2686
	--> Epoch [86/100], Loss: 0.1567, Validation Loss: 0.2683
	--> Epoch [87/100], Loss: 0.1348, Validation Loss: 0.2673
	--> Epoch [88/100], Loss: 0.1467, Validation Loss: 0.2671
	--> Epoch [89/100], Loss: 0.1592, Validation Loss: 0.2659
	--> Epoch [90/100], Loss: 0.1614, Validation Loss: 0.2648
	--> Epoch [91/100], Loss: 0.1697, Validation Loss: 0.2641
	--> Epoch [92/100], Loss: 0.1434, Validation Loss: 0.2630
	--> Epoch [93/100], Loss: 0.1285, Validation Loss: 0.2623
	--> Epoch [94/100], Loss: 0.1578, Validation Loss: 0.2611
	--> Epoch [95/100], Loss: 0.1200, Validation Loss: 0.2609
	--> Epoch [96/100], Loss: 0.1452, Validation Loss: 0.2604
	--> Epoch [97/100], Loss: 0.1155, Validation Loss: 0.2601
	--> Epoch [98/100], Loss: 0.1097, Validation Loss: 0.2602
	--> Epoch [99/100], Loss: 0.1244, Validation Loss: 0.2602
	--> Epoch [100/100], Loss: 0.1014, Validation Loss: 0.2584
	--> Training for Fold 1 took 0.3644425868988037 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6756, Validation Loss: 0.6220
	--> Epoch [2/100], Loss: 0.6551, Validation Loss: 0.6058
	--> Epoch [3/100], Loss: 0.6584, Validation Loss: 0.5901
	--> Epoch [4/100], Loss: 0.6489, Validation Loss: 0.5776
	--> Epoch [5/100], Loss: 0.6456, Validation Loss: 0.5668
	--> Epoch [6/100], Loss: 0.6123, Validation Loss: 0.5570
	--> Epoch [7/100], Loss: 0.5888, Validation Loss: 0.5456
	--> Epoch [8/100], Loss: 0.5669, Validation Loss: 0.5354
	--> Epoch [9/100], Loss: 0.5734, Validation Loss: 0.5258
	--> Epoch [10/100], Loss: 0.5631, Validation Loss: 0.5150
	--> Epoch [11/100], Loss: 0.5499, Validation Loss: 0.5051
	--> Epoch [12/100], Loss: 0.5127, Validation Loss: 0.4947
	--> Epoch [13/100], Loss: 0.5259, Validation Loss: 0.4859
	--> Epoch [14/100], Loss: 0.5202, Validation Loss: 0.4763
	--> Epoch [15/100], Loss: 0.5259, Validation Loss: 0.4671
	--> Epoch [16/100], Loss: 0.5020, Validation Loss: 0.4592
	--> Epoch [17/100], Loss: 0.4701, Validation Loss: 0.4496
	--> Epoch [18/100], Loss: 0.4837, Validation Loss: 0.4414
	--> Epoch [19/100], Loss: 0.4539, Validation Loss: 0.4328
	--> Epoch [20/100], Loss: 0.4540, Validation Loss: 0.4256
	--> Epoch [21/100], Loss: 0.4487, Validation Loss: 0.4187
	--> Epoch [22/100], Loss: 0.4517, Validation Loss: 0.4106
	--> Epoch [23/100], Loss: 0.4198, Validation Loss: 0.4027
	--> Epoch [24/100], Loss: 0.4305, Validation Loss: 0.3961
	--> Epoch [25/100], Loss: 0.4093, Validation Loss: 0.3899
	--> Epoch [26/100], Loss: 0.3764, Validation Loss: 0.3844
	--> Epoch [27/100], Loss: 0.4146, Validation Loss: 0.3778
	--> Epoch [28/100], Loss: 0.3767, Validation Loss: 0.3722
	--> Epoch [29/100], Loss: 0.3515, Validation Loss: 0.3663
	--> Epoch [30/100], Loss: 0.3741, Validation Loss: 0.3608
	--> Epoch [31/100], Loss: 0.4088, Validation Loss: 0.3560
	--> Epoch [32/100], Loss: 0.3573, Validation Loss: 0.3502
	--> Epoch [33/100], Loss: 0.3523, Validation Loss: 0.3440
	--> Epoch [34/100], Loss: 0.3535, Validation Loss: 0.3389
	--> Epoch [35/100], Loss: 0.3510, Validation Loss: 0.3344
	--> Epoch [36/100], Loss: 0.3237, Validation Loss: 0.3296
	--> Epoch [37/100], Loss: 0.3035, Validation Loss: 0.3257
	--> Epoch [38/100], Loss: 0.2998, Validation Loss: 0.3209
	--> Epoch [39/100], Loss: 0.3141, Validation Loss: 0.3179
	--> Epoch [40/100], Loss: 0.3196, Validation Loss: 0.3133
	--> Epoch [41/100], Loss: 0.2960, Validation Loss: 0.3091
	--> Epoch [42/100], Loss: 0.3020, Validation Loss: 0.3065
	--> Epoch [43/100], Loss: 0.2982, Validation Loss: 0.3028
	--> Epoch [44/100], Loss: 0.2775, Validation Loss: 0.2998
	--> Epoch [45/100], Loss: 0.2556, Validation Loss: 0.2970
	--> Epoch [46/100], Loss: 0.2895, Validation Loss: 0.2943
	--> Epoch [47/100], Loss: 0.2944, Validation Loss: 0.2910
	--> Epoch [48/100], Loss: 0.2762, Validation Loss: 0.2876
	--> Epoch [49/100], Loss: 0.2392, Validation Loss: 0.2854
	--> Epoch [50/100], Loss: 0.2616, Validation Loss: 0.2821
	--> Epoch [51/100], Loss: 0.2484, Validation Loss: 0.2796
	--> Epoch [52/100], Loss: 0.2459, Validation Loss: 0.2769
	--> Epoch [53/100], Loss: 0.2413, Validation Loss: 0.2742
	--> Epoch [54/100], Loss: 0.2326, Validation Loss: 0.2716
	--> Epoch [55/100], Loss: 0.2444, Validation Loss: 0.2699
	--> Epoch [56/100], Loss: 0.2452, Validation Loss: 0.2671
	--> Epoch [57/100], Loss: 0.2319, Validation Loss: 0.2658
	--> Epoch [58/100], Loss: 0.2236, Validation Loss: 0.2632
	--> Epoch [59/100], Loss: 0.2096, Validation Loss: 0.2605
	--> Epoch [60/100], Loss: 0.2036, Validation Loss: 0.2576
	--> Epoch [61/100], Loss: 0.2412, Validation Loss: 0.2560
	--> Epoch [62/100], Loss: 0.1971, Validation Loss: 0.2548
	--> Epoch [63/100], Loss: 0.2081, Validation Loss: 0.2532
	--> Epoch [64/100], Loss: 0.1723, Validation Loss: 0.2514
	--> Epoch [65/100], Loss: 0.2040, Validation Loss: 0.2507
	--> Epoch [66/100], Loss: 0.1886, Validation Loss: 0.2496
	--> Epoch [67/100], Loss: 0.1826, Validation Loss: 0.2483
	--> Epoch [68/100], Loss: 0.1879, Validation Loss: 0.2464
	--> Epoch [69/100], Loss: 0.1788, Validation Loss: 0.2448
	--> Epoch [70/100], Loss: 0.1919, Validation Loss: 0.2423
	--> Epoch [71/100], Loss: 0.1599, Validation Loss: 0.2411
	--> Epoch [72/100], Loss: 0.1708, Validation Loss: 0.2403
	--> Epoch [73/100], Loss: 0.1724, Validation Loss: 0.2390
	--> Epoch [74/100], Loss: 0.1724, Validation Loss: 0.2380
	--> Epoch [75/100], Loss: 0.1866, Validation Loss: 0.2371
	--> Epoch [76/100], Loss: 0.1718, Validation Loss: 0.2361
	--> Epoch [77/100], Loss: 0.1719, Validation Loss: 0.2337
	--> Epoch [78/100], Loss: 0.1619, Validation Loss: 0.2332
	--> Epoch [79/100], Loss: 0.1688, Validation Loss: 0.2312
	--> Epoch [80/100], Loss: 0.1450, Validation Loss: 0.2305
	--> Epoch [81/100], Loss: 0.1545, Validation Loss: 0.2294
	--> Epoch [82/100], Loss: 0.1565, Validation Loss: 0.2280
	--> Epoch [83/100], Loss: 0.1268, Validation Loss: 0.2270
	--> Epoch [84/100], Loss: 0.1366, Validation Loss: 0.2258
	--> Epoch [85/100], Loss: 0.1540, Validation Loss: 0.2244
	--> Epoch [86/100], Loss: 0.1525, Validation Loss: 0.2241
	--> Epoch [87/100], Loss: 0.1666, Validation Loss: 0.2252
	--> Epoch [88/100], Loss: 0.1388, Validation Loss: 0.2238
	--> Epoch [89/100], Loss: 0.1237, Validation Loss: 0.2229
	--> Epoch [90/100], Loss: 0.1539, Validation Loss: 0.2224
	--> Epoch [91/100], Loss: 0.1808, Validation Loss: 0.2206
	--> Epoch [92/100], Loss: 0.1375, Validation Loss: 0.2201
	--> Epoch [93/100], Loss: 0.1372, Validation Loss: 0.2190
	--> Epoch [94/100], Loss: 0.1456, Validation Loss: 0.2182
	--> Epoch [95/100], Loss: 0.1514, Validation Loss: 0.2179
	--> Epoch [96/100], Loss: 0.1314, Validation Loss: 0.2167
	--> Epoch [97/100], Loss: 0.1237, Validation Loss: 0.2163
	--> Epoch [98/100], Loss: 0.1307, Validation Loss: 0.2159
	--> Epoch [99/100], Loss: 0.1265, Validation Loss: 0.2152
	--> Epoch [100/100], Loss: 0.1234, Validation Loss: 0.2156
	--> Training for Fold 2 took 0.38135409355163574 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7310, Validation Loss: 0.6554
	--> Epoch [2/100], Loss: 0.7052, Validation Loss: 0.6441
	--> Epoch [3/100], Loss: 0.6578, Validation Loss: 0.6346
	--> Epoch [4/100], Loss: 0.6336, Validation Loss: 0.6259
	--> Epoch [5/100], Loss: 0.6325, Validation Loss: 0.6169
	--> Epoch [6/100], Loss: 0.6269, Validation Loss: 0.6070
	--> Epoch [7/100], Loss: 0.5674, Validation Loss: 0.5979
	--> Epoch [8/100], Loss: 0.5698, Validation Loss: 0.5884
	--> Epoch [9/100], Loss: 0.5520, Validation Loss: 0.5777
	--> Epoch [10/100], Loss: 0.5424, Validation Loss: 0.5694
	--> Epoch [11/100], Loss: 0.5073, Validation Loss: 0.5620
	--> Epoch [12/100], Loss: 0.5190, Validation Loss: 0.5534
	--> Epoch [13/100], Loss: 0.5340, Validation Loss: 0.5477
	--> Epoch [14/100], Loss: 0.4895, Validation Loss: 0.5404
	--> Epoch [15/100], Loss: 0.4876, Validation Loss: 0.5326
	--> Epoch [16/100], Loss: 0.4664, Validation Loss: 0.5267
	--> Epoch [17/100], Loss: 0.4613, Validation Loss: 0.5204
	--> Epoch [18/100], Loss: 0.4587, Validation Loss: 0.5146
	--> Epoch [19/100], Loss: 0.4202, Validation Loss: 0.5093
	--> Epoch [20/100], Loss: 0.4443, Validation Loss: 0.5049
	--> Epoch [21/100], Loss: 0.4041, Validation Loss: 0.4999
	--> Epoch [22/100], Loss: 0.3929, Validation Loss: 0.4932
	--> Epoch [23/100], Loss: 0.3917, Validation Loss: 0.4873
	--> Epoch [24/100], Loss: 0.3930, Validation Loss: 0.4826
	--> Epoch [25/100], Loss: 0.3865, Validation Loss: 0.4778
	--> Epoch [26/100], Loss: 0.3934, Validation Loss: 0.4727
	--> Epoch [27/100], Loss: 0.3634, Validation Loss: 0.4676
	--> Epoch [28/100], Loss: 0.3574, Validation Loss: 0.4642
	--> Epoch [29/100], Loss: 0.3511, Validation Loss: 0.4595
	--> Epoch [30/100], Loss: 0.3291, Validation Loss: 0.4552
	--> Epoch [31/100], Loss: 0.3277, Validation Loss: 0.4510
	--> Epoch [32/100], Loss: 0.3077, Validation Loss: 0.4465
	--> Epoch [33/100], Loss: 0.3076, Validation Loss: 0.4426
	--> Epoch [34/100], Loss: 0.3256, Validation Loss: 0.4382
	--> Epoch [35/100], Loss: 0.3087, Validation Loss: 0.4344
	--> Epoch [36/100], Loss: 0.2878, Validation Loss: 0.4295
	--> Epoch [37/100], Loss: 0.2906, Validation Loss: 0.4252
	--> Epoch [38/100], Loss: 0.2911, Validation Loss: 0.4219
	--> Epoch [39/100], Loss: 0.2849, Validation Loss: 0.4188
	--> Epoch [40/100], Loss: 0.2616, Validation Loss: 0.4154
	--> Epoch [41/100], Loss: 0.2848, Validation Loss: 0.4122
	--> Epoch [42/100], Loss: 0.2704, Validation Loss: 0.4083
	--> Epoch [43/100], Loss: 0.2634, Validation Loss: 0.4044
	--> Epoch [44/100], Loss: 0.2613, Validation Loss: 0.4017
	--> Epoch [45/100], Loss: 0.2786, Validation Loss: 0.3986
	--> Epoch [46/100], Loss: 0.2420, Validation Loss: 0.3952
	--> Epoch [47/100], Loss: 0.2249, Validation Loss: 0.3924
	--> Epoch [48/100], Loss: 0.2772, Validation Loss: 0.3888
	--> Epoch [49/100], Loss: 0.2424, Validation Loss: 0.3867
	--> Epoch [50/100], Loss: 0.2481, Validation Loss: 0.3842
	--> Epoch [51/100], Loss: 0.2222, Validation Loss: 0.3822
	--> Epoch [52/100], Loss: 0.2300, Validation Loss: 0.3789
	--> Epoch [53/100], Loss: 0.1824, Validation Loss: 0.3764
	--> Epoch [54/100], Loss: 0.2068, Validation Loss: 0.3739
	--> Epoch [55/100], Loss: 0.2119, Validation Loss: 0.3721
	--> Epoch [56/100], Loss: 0.2130, Validation Loss: 0.3692
	--> Epoch [57/100], Loss: 0.1974, Validation Loss: 0.3675
	--> Epoch [58/100], Loss: 0.1976, Validation Loss: 0.3650
	--> Epoch [59/100], Loss: 0.1987, Validation Loss: 0.3631
	--> Epoch [60/100], Loss: 0.2023, Validation Loss: 0.3600
	--> Epoch [61/100], Loss: 0.1833, Validation Loss: 0.3581
	--> Epoch [62/100], Loss: 0.1689, Validation Loss: 0.3564
	--> Epoch [63/100], Loss: 0.1770, Validation Loss: 0.3539
	--> Epoch [64/100], Loss: 0.1644, Validation Loss: 0.3524
	--> Epoch [65/100], Loss: 0.2066, Validation Loss: 0.3513
	--> Epoch [66/100], Loss: 0.1456, Validation Loss: 0.3494
	--> Epoch [67/100], Loss: 0.1637, Validation Loss: 0.3474
	--> Epoch [68/100], Loss: 0.1839, Validation Loss: 0.3462
	--> Epoch [69/100], Loss: 0.1624, Validation Loss: 0.3443
	--> Epoch [70/100], Loss: 0.1636, Validation Loss: 0.3423
	--> Epoch [71/100], Loss: 0.1662, Validation Loss: 0.3406
	--> Epoch [72/100], Loss: 0.1422, Validation Loss: 0.3387
	--> Epoch [73/100], Loss: 0.1770, Validation Loss: 0.3368
	--> Epoch [74/100], Loss: 0.1575, Validation Loss: 0.3350
	--> Epoch [75/100], Loss: 0.1502, Validation Loss: 0.3336
	--> Epoch [76/100], Loss: 0.1677, Validation Loss: 0.3331
	--> Epoch [77/100], Loss: 0.1377, Validation Loss: 0.3314
	--> Epoch [78/100], Loss: 0.1503, Validation Loss: 0.3304
	--> Epoch [79/100], Loss: 0.1357, Validation Loss: 0.3293
	--> Epoch [80/100], Loss: 0.1641, Validation Loss: 0.3278
	--> Epoch [81/100], Loss: 0.1598, Validation Loss: 0.3267
	--> Epoch [82/100], Loss: 0.1124, Validation Loss: 0.3261
	--> Epoch [83/100], Loss: 0.1118, Validation Loss: 0.3245
	--> Epoch [84/100], Loss: 0.1340, Validation Loss: 0.3232
	--> Epoch [85/100], Loss: 0.1329, Validation Loss: 0.3221
	--> Epoch [86/100], Loss: 0.1294, Validation Loss: 0.3216
	--> Epoch [87/100], Loss: 0.1454, Validation Loss: 0.3203
	--> Epoch [88/100], Loss: 0.1410, Validation Loss: 0.3192
	--> Epoch [89/100], Loss: 0.1410, Validation Loss: 0.3176
	--> Epoch [90/100], Loss: 0.1145, Validation Loss: 0.3166
	--> Epoch [91/100], Loss: 0.1094, Validation Loss: 0.3162
	--> Epoch [92/100], Loss: 0.1286, Validation Loss: 0.3149
	--> Epoch [93/100], Loss: 0.1503, Validation Loss: 0.3139
	--> Epoch [94/100], Loss: 0.1290, Validation Loss: 0.3131
	--> Epoch [95/100], Loss: 0.1115, Validation Loss: 0.3116
	--> Epoch [96/100], Loss: 0.1114, Validation Loss: 0.3116
	--> Epoch [97/100], Loss: 0.1221, Validation Loss: 0.3106
	--> Epoch [98/100], Loss: 0.1256, Validation Loss: 0.3096
	--> Epoch [99/100], Loss: 0.1031, Validation Loss: 0.3087
	--> Epoch [100/100], Loss: 0.1284, Validation Loss: 0.3072
	--> Training for Fold 3 took 0.3813502788543701 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6695, Validation Loss: 0.7599
	--> Epoch [2/100], Loss: 0.6617, Validation Loss: 0.7351
	--> Epoch [3/100], Loss: 0.6380, Validation Loss: 0.7148
	--> Epoch [4/100], Loss: 0.6279, Validation Loss: 0.6979
	--> Epoch [5/100], Loss: 0.6099, Validation Loss: 0.6811
	--> Epoch [6/100], Loss: 0.5956, Validation Loss: 0.6668
	--> Epoch [7/100], Loss: 0.5892, Validation Loss: 0.6542
	--> Epoch [8/100], Loss: 0.5838, Validation Loss: 0.6400
	--> Epoch [9/100], Loss: 0.5684, Validation Loss: 0.6298
	--> Epoch [10/100], Loss: 0.5653, Validation Loss: 0.6186
	--> Epoch [11/100], Loss: 0.5189, Validation Loss: 0.6098
	--> Epoch [12/100], Loss: 0.5082, Validation Loss: 0.5986
	--> Epoch [13/100], Loss: 0.5089, Validation Loss: 0.5861
	--> Epoch [14/100], Loss: 0.5451, Validation Loss: 0.5787
	--> Epoch [15/100], Loss: 0.4900, Validation Loss: 0.5699
	--> Epoch [16/100], Loss: 0.4894, Validation Loss: 0.5632
	--> Epoch [17/100], Loss: 0.4749, Validation Loss: 0.5565
	--> Epoch [18/100], Loss: 0.4623, Validation Loss: 0.5494
	--> Epoch [19/100], Loss: 0.4597, Validation Loss: 0.5417
	--> Epoch [20/100], Loss: 0.4528, Validation Loss: 0.5327
	--> Epoch [21/100], Loss: 0.4544, Validation Loss: 0.5269
	--> Epoch [22/100], Loss: 0.4240, Validation Loss: 0.5216
	--> Epoch [23/100], Loss: 0.4214, Validation Loss: 0.5149
	--> Epoch [24/100], Loss: 0.4146, Validation Loss: 0.5080
	--> Epoch [25/100], Loss: 0.4155, Validation Loss: 0.5036
	--> Epoch [26/100], Loss: 0.3953, Validation Loss: 0.5006
	--> Epoch [27/100], Loss: 0.3972, Validation Loss: 0.4941
	--> Epoch [28/100], Loss: 0.3767, Validation Loss: 0.4890
	--> Epoch [29/100], Loss: 0.3712, Validation Loss: 0.4844
	--> Epoch [30/100], Loss: 0.3616, Validation Loss: 0.4821
	--> Epoch [31/100], Loss: 0.3648, Validation Loss: 0.4757
	--> Epoch [32/100], Loss: 0.3602, Validation Loss: 0.4724
	--> Epoch [33/100], Loss: 0.3532, Validation Loss: 0.4698
	--> Epoch [34/100], Loss: 0.3712, Validation Loss: 0.4663
	--> Epoch [35/100], Loss: 0.3331, Validation Loss: 0.4639
	--> Epoch [36/100], Loss: 0.3295, Validation Loss: 0.4606
	--> Epoch [37/100], Loss: 0.3358, Validation Loss: 0.4577
	--> Epoch [38/100], Loss: 0.3173, Validation Loss: 0.4543
	--> Epoch [39/100], Loss: 0.3187, Validation Loss: 0.4523
	--> Epoch [40/100], Loss: 0.2935, Validation Loss: 0.4497
	--> Epoch [41/100], Loss: 0.3056, Validation Loss: 0.4455
	--> Epoch [42/100], Loss: 0.3066, Validation Loss: 0.4433
	--> Epoch [43/100], Loss: 0.2945, Validation Loss: 0.4406
	--> Epoch [44/100], Loss: 0.2758, Validation Loss: 0.4398
	--> Epoch [45/100], Loss: 0.2979, Validation Loss: 0.4381
	--> Epoch [46/100], Loss: 0.2803, Validation Loss: 0.4355
	--> Epoch [47/100], Loss: 0.2479, Validation Loss: 0.4319
	--> Epoch [48/100], Loss: 0.2675, Validation Loss: 0.4292
	--> Epoch [49/100], Loss: 0.2739, Validation Loss: 0.4275
	--> Epoch [50/100], Loss: 0.2650, Validation Loss: 0.4260
	--> Epoch [51/100], Loss: 0.2927, Validation Loss: 0.4235
	--> Epoch [52/100], Loss: 0.2449, Validation Loss: 0.4226
	--> Epoch [53/100], Loss: 0.2529, Validation Loss: 0.4215
	--> Epoch [54/100], Loss: 0.2322, Validation Loss: 0.4208
	--> Epoch [55/100], Loss: 0.2566, Validation Loss: 0.4171
	--> Epoch [56/100], Loss: 0.2439, Validation Loss: 0.4171
	--> Epoch [57/100], Loss: 0.2054, Validation Loss: 0.4171
	--> Epoch [58/100], Loss: 0.2018, Validation Loss: 0.4163
	--> Epoch [59/100], Loss: 0.2042, Validation Loss: 0.4144
	--> Epoch [60/100], Loss: 0.2046, Validation Loss: 0.4124
	--> Epoch [61/100], Loss: 0.2611, Validation Loss: 0.4115
	--> Epoch [62/100], Loss: 0.1805, Validation Loss: 0.4108
	--> Epoch [63/100], Loss: 0.1960, Validation Loss: 0.4103
	--> Epoch [64/100], Loss: 0.2068, Validation Loss: 0.4093
	--> Epoch [65/100], Loss: 0.1982, Validation Loss: 0.4096
	--> Epoch [66/100], Loss: 0.1890, Validation Loss: 0.4093
	--> Epoch [67/100], Loss: 0.1748, Validation Loss: 0.4091
	--> Epoch [68/100], Loss: 0.2266, Validation Loss: 0.4057
	--> Epoch [69/100], Loss: 0.1909, Validation Loss: 0.4049
	--> Epoch [70/100], Loss: 0.1830, Validation Loss: 0.4046
	--> Epoch [71/100], Loss: 0.1927, Validation Loss: 0.4043
	--> Epoch [72/100], Loss: 0.1587, Validation Loss: 0.4034
	--> Epoch [73/100], Loss: 0.1793, Validation Loss: 0.4041
	--> Epoch [74/100], Loss: 0.2099, Validation Loss: 0.4041
	--> Epoch [75/100], Loss: 0.1786, Validation Loss: 0.4017
	--> Epoch [76/100], Loss: 0.1903, Validation Loss: 0.4022
	--> Epoch [77/100], Loss: 0.1534, Validation Loss: 0.4021
	--> Epoch [78/100], Loss: 0.1806, Validation Loss: 0.4028
Early stopping
	--> Training for Fold 4 took 0.3044779300689697 sec, using 78 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7276, Validation Loss: 0.6294
	--> Epoch [2/100], Loss: 0.7037, Validation Loss: 0.6235
	--> Epoch [3/100], Loss: 0.6980, Validation Loss: 0.6186
	--> Epoch [4/100], Loss: 0.6884, Validation Loss: 0.6128
	--> Epoch [5/100], Loss: 0.6829, Validation Loss: 0.6075
	--> Epoch [6/100], Loss: 0.6551, Validation Loss: 0.6025
	--> Epoch [7/100], Loss: 0.6454, Validation Loss: 0.5970
	--> Epoch [8/100], Loss: 0.6272, Validation Loss: 0.5920
	--> Epoch [9/100], Loss: 0.6336, Validation Loss: 0.5877
	--> Epoch [10/100], Loss: 0.6247, Validation Loss: 0.5829
	--> Epoch [11/100], Loss: 0.5866, Validation Loss: 0.5790
	--> Epoch [12/100], Loss: 0.5912, Validation Loss: 0.5750
	--> Epoch [13/100], Loss: 0.5978, Validation Loss: 0.5714
	--> Epoch [14/100], Loss: 0.5552, Validation Loss: 0.5681
	--> Epoch [15/100], Loss: 0.5527, Validation Loss: 0.5641
	--> Epoch [16/100], Loss: 0.5378, Validation Loss: 0.5605
	--> Epoch [17/100], Loss: 0.5235, Validation Loss: 0.5566
	--> Epoch [18/100], Loss: 0.5155, Validation Loss: 0.5534
	--> Epoch [19/100], Loss: 0.5173, Validation Loss: 0.5497
	--> Epoch [20/100], Loss: 0.4847, Validation Loss: 0.5475
	--> Epoch [21/100], Loss: 0.4768, Validation Loss: 0.5445
	--> Epoch [22/100], Loss: 0.4808, Validation Loss: 0.5415
	--> Epoch [23/100], Loss: 0.4497, Validation Loss: 0.5388
	--> Epoch [24/100], Loss: 0.4813, Validation Loss: 0.5359
	--> Epoch [25/100], Loss: 0.4420, Validation Loss: 0.5323
	--> Epoch [26/100], Loss: 0.4275, Validation Loss: 0.5285
	--> Epoch [27/100], Loss: 0.4209, Validation Loss: 0.5253
	--> Epoch [28/100], Loss: 0.4049, Validation Loss: 0.5218
	--> Epoch [29/100], Loss: 0.3944, Validation Loss: 0.5176
	--> Epoch [30/100], Loss: 0.4193, Validation Loss: 0.5165
	--> Epoch [31/100], Loss: 0.3886, Validation Loss: 0.5136
	--> Epoch [32/100], Loss: 0.4134, Validation Loss: 0.5109
	--> Epoch [33/100], Loss: 0.3613, Validation Loss: 0.5077
	--> Epoch [34/100], Loss: 0.3702, Validation Loss: 0.5054
	--> Epoch [35/100], Loss: 0.3847, Validation Loss: 0.5038
	--> Epoch [36/100], Loss: 0.3872, Validation Loss: 0.5005
	--> Epoch [37/100], Loss: 0.3498, Validation Loss: 0.4991
	--> Epoch [38/100], Loss: 0.3843, Validation Loss: 0.4981
	--> Epoch [39/100], Loss: 0.3429, Validation Loss: 0.4949
	--> Epoch [40/100], Loss: 0.3433, Validation Loss: 0.4933
	--> Epoch [41/100], Loss: 0.3355, Validation Loss: 0.4915
	--> Epoch [42/100], Loss: 0.3370, Validation Loss: 0.4893
	--> Epoch [43/100], Loss: 0.3078, Validation Loss: 0.4896
	--> Epoch [44/100], Loss: 0.2972, Validation Loss: 0.4869
	--> Epoch [45/100], Loss: 0.3177, Validation Loss: 0.4850
	--> Epoch [46/100], Loss: 0.2779, Validation Loss: 0.4838
	--> Epoch [47/100], Loss: 0.2881, Validation Loss: 0.4815
	--> Epoch [48/100], Loss: 0.3060, Validation Loss: 0.4802
	--> Epoch [49/100], Loss: 0.2717, Validation Loss: 0.4798
	--> Epoch [50/100], Loss: 0.2900, Validation Loss: 0.4782
	--> Epoch [51/100], Loss: 0.2800, Validation Loss: 0.4760
	--> Epoch [52/100], Loss: 0.2448, Validation Loss: 0.4743
	--> Epoch [53/100], Loss: 0.2388, Validation Loss: 0.4734
	--> Epoch [54/100], Loss: 0.2656, Validation Loss: 0.4717
	--> Epoch [55/100], Loss: 0.2632, Validation Loss: 0.4719
	--> Epoch [56/100], Loss: 0.2170, Validation Loss: 0.4715
	--> Epoch [57/100], Loss: 0.2616, Validation Loss: 0.4701
	--> Epoch [58/100], Loss: 0.2541, Validation Loss: 0.4701
	--> Epoch [59/100], Loss: 0.2458, Validation Loss: 0.4686
	--> Epoch [60/100], Loss: 0.2349, Validation Loss: 0.4678
	--> Epoch [61/100], Loss: 0.2707, Validation Loss: 0.4672
	--> Epoch [62/100], Loss: 0.2488, Validation Loss: 0.4656
	--> Epoch [63/100], Loss: 0.1956, Validation Loss: 0.4662
	--> Epoch [64/100], Loss: 0.2173, Validation Loss: 0.4667
	--> Epoch [65/100], Loss: 0.2286, Validation Loss: 0.4659
Early stopping
	--> Training for Fold 5 took 0.2560880184173584 sec, using 65 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6524
	--> Final training Epoch [2/100], Loss: 0.6331
	--> Final training Epoch [3/100], Loss: 0.6215
	--> Final training Epoch [4/100], Loss: 0.5830
	--> Final training Epoch [5/100], Loss: 0.5791
	--> Final training Epoch [6/100], Loss: 0.5826
	--> Final training Epoch [7/100], Loss: 0.5641
	--> Final training Epoch [8/100], Loss: 0.5354
	--> Final training Epoch [9/100], Loss: 0.5161
	--> Final training Epoch [10/100], Loss: 0.4924
	--> Final training Epoch [11/100], Loss: 0.5106
	--> Final training Epoch [12/100], Loss: 0.5049
	--> Final training Epoch [13/100], Loss: 0.4742
	--> Final training Epoch [14/100], Loss: 0.4753
	--> Final training Epoch [15/100], Loss: 0.4485
	--> Final training Epoch [16/100], Loss: 0.4420
	--> Final training Epoch [17/100], Loss: 0.4703
	--> Final training Epoch [18/100], Loss: 0.4293
	--> Final training Epoch [19/100], Loss: 0.4513
	--> Final training Epoch [20/100], Loss: 0.4298
	--> Final training Epoch [21/100], Loss: 0.4022
	--> Final training Epoch [22/100], Loss: 0.4117
	--> Final training Epoch [23/100], Loss: 0.3746
	--> Final training Epoch [24/100], Loss: 0.3969
	--> Final training Epoch [25/100], Loss: 0.3803
	--> Final training Epoch [26/100], Loss: 0.3591
	--> Final training Epoch [27/100], Loss: 0.3734
	--> Final training Epoch [28/100], Loss: 0.3571
	--> Final training Epoch [29/100], Loss: 0.3455
	--> Final training Epoch [30/100], Loss: 0.3368
	--> Final training Epoch [31/100], Loss: 0.3486
	--> Final training Epoch [32/100], Loss: 0.3386
	--> Final training Epoch [33/100], Loss: 0.3298
	--> Final training Epoch [34/100], Loss: 0.3329
	--> Final training Epoch [35/100], Loss: 0.3060
	--> Final training Epoch [36/100], Loss: 0.2899
	--> Final training Epoch [37/100], Loss: 0.2857
	--> Final training Epoch [38/100], Loss: 0.2769
	--> Final training Epoch [39/100], Loss: 0.3125
	--> Final training Epoch [40/100], Loss: 0.2648
	--> Final training Epoch [41/100], Loss: 0.2730
	--> Final training Epoch [42/100], Loss: 0.2699
	--> Final training Epoch [43/100], Loss: 0.2339
	--> Final training Epoch [44/100], Loss: 0.2633
	--> Final training Epoch [45/100], Loss: 0.2343
	--> Final training Epoch [46/100], Loss: 0.2460
	--> Final training Epoch [47/100], Loss: 0.2363
	--> Final training Epoch [48/100], Loss: 0.2526
	--> Final training Epoch [49/100], Loss: 0.2267
	--> Final training Epoch [50/100], Loss: 0.2124
	--> Final training Epoch [51/100], Loss: 0.2209
	--> Final training Epoch [52/100], Loss: 0.2243
	--> Final training Epoch [53/100], Loss: 0.2086
	--> Final training Epoch [54/100], Loss: 0.2017
	--> Final training Epoch [55/100], Loss: 0.1847
	--> Final training Epoch [56/100], Loss: 0.1849
	--> Final training Epoch [57/100], Loss: 0.2138
	--> Final training Epoch [58/100], Loss: 0.2015
	--> Final training Epoch [59/100], Loss: 0.1758
	--> Final training Epoch [60/100], Loss: 0.1736
	--> Final training Epoch [61/100], Loss: 0.1976
	--> Final training Epoch [62/100], Loss: 0.1537
	--> Final training Epoch [63/100], Loss: 0.1779
	--> Final training Epoch [64/100], Loss: 0.1863
	--> Final training Epoch [65/100], Loss: 0.1659
	--> Final training Epoch [66/100], Loss: 0.1637
	--> Final training Epoch [67/100], Loss: 0.1666
	--> Final training Epoch [68/100], Loss: 0.1539
	--> Final training Epoch [69/100], Loss: 0.1615
	--> Final training Epoch [70/100], Loss: 0.1420
	--> Final training Epoch [71/100], Loss: 0.1615
	--> Final training Epoch [72/100], Loss: 0.1577
	--> Final training Epoch [73/100], Loss: 0.1571
	--> Final training Epoch [74/100], Loss: 0.1660
	--> Final training Epoch [75/100], Loss: 0.1704
	--> Final training Epoch [76/100], Loss: 0.1361
	--> Final training Epoch [77/100], Loss: 0.1440
	--> Final training Epoch [78/100], Loss: 0.1487
	--> Final training Epoch [79/100], Loss: 0.1464
	--> Final training Epoch [80/100], Loss: 0.1400
	--> Final training Epoch [81/100], Loss: 0.1355
	--> Final training Epoch [82/100], Loss: 0.1408
	--> Final training Epoch [83/100], Loss: 0.1551
	--> Final training Epoch [84/100], Loss: 0.1301
	--> Final training Epoch [85/100], Loss: 0.1386
	--> Final training Epoch [86/100], Loss: 0.1266
	--> Final training Epoch [87/100], Loss: 0.1195
	--> Final training Epoch [88/100], Loss: 0.1221
	--> Final training Epoch [89/100], Loss: 0.1047
	--> Final training Epoch [90/100], Loss: 0.1236
	--> Final training Epoch [91/100], Loss: 0.1213
	--> Final training Epoch [92/100], Loss: 0.1048
	--> Final training Epoch [93/100], Loss: 0.1389
	--> Final training Epoch [94/100], Loss: 0.1422
	--> Final training Epoch [95/100], Loss: 0.1005
	--> Final training Epoch [96/100], Loss: 0.1204
	--> Final training Epoch [97/100], Loss: 0.1133
	--> Final training Epoch [98/100], Loss: 0.1021
	--> Final training Epoch [99/100], Loss: 0.1190
	--> Final training Epoch [100/100], Loss: 0.1148

Final training took 0.3584423065185547 sec

TESTING
	--> Testing took 0.0104 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8526
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8287, Validation Loss: 0.3976,  Current Best Accuracy: 0.8287,  Current Best Validation Loss: 0.3976

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6759, Validation Loss: 0.6754
	--> Epoch [2/100], Loss: 0.7118, Validation Loss: 0.6641
	--> Epoch [3/100], Loss: 0.6565, Validation Loss: 0.6534
	--> Epoch [4/100], Loss: 0.6374, Validation Loss: 0.6447
	--> Epoch [5/100], Loss: 0.6173, Validation Loss: 0.6341
	--> Epoch [6/100], Loss: 0.6447, Validation Loss: 0.6274
	--> Epoch [7/100], Loss: 0.5673, Validation Loss: 0.6226
	--> Epoch [8/100], Loss: 0.5527, Validation Loss: 0.6132
	--> Epoch [9/100], Loss: 0.5636, Validation Loss: 0.6075
	--> Epoch [10/100], Loss: 0.5804, Validation Loss: 0.6009
	--> Epoch [11/100], Loss: 0.5639, Validation Loss: 0.5926
	--> Epoch [12/100], Loss: 0.5918, Validation Loss: 0.5877
	--> Epoch [13/100], Loss: 0.5350, Validation Loss: 0.5838
	--> Epoch [14/100], Loss: 0.5549, Validation Loss: 0.5745
	--> Epoch [15/100], Loss: 0.5159, Validation Loss: 0.5678
	--> Epoch [16/100], Loss: 0.4842, Validation Loss: 0.5611
	--> Epoch [17/100], Loss: 0.4612, Validation Loss: 0.5563
	--> Epoch [18/100], Loss: 0.5045, Validation Loss: 0.5487
	--> Epoch [19/100], Loss: 0.4935, Validation Loss: 0.5439
	--> Epoch [20/100], Loss: 0.4772, Validation Loss: 0.5339
	--> Epoch [21/100], Loss: 0.4860, Validation Loss: 0.5282
	--> Epoch [22/100], Loss: 0.4753, Validation Loss: 0.5234
	--> Epoch [23/100], Loss: 0.4430, Validation Loss: 0.5186
	--> Epoch [24/100], Loss: 0.4945, Validation Loss: 0.5148
	--> Epoch [25/100], Loss: 0.4214, Validation Loss: 0.5080
	--> Epoch [26/100], Loss: 0.4440, Validation Loss: 0.5040
	--> Epoch [27/100], Loss: 0.4341, Validation Loss: 0.4992
	--> Epoch [28/100], Loss: 0.4538, Validation Loss: 0.4941
	--> Epoch [29/100], Loss: 0.4113, Validation Loss: 0.4879
	--> Epoch [30/100], Loss: 0.4039, Validation Loss: 0.4823
	--> Epoch [31/100], Loss: 0.4178, Validation Loss: 0.4750
	--> Epoch [32/100], Loss: 0.4193, Validation Loss: 0.4690
	--> Epoch [33/100], Loss: 0.4066, Validation Loss: 0.4650
	--> Epoch [34/100], Loss: 0.4035, Validation Loss: 0.4598
	--> Epoch [35/100], Loss: 0.4145, Validation Loss: 0.4536
	--> Epoch [36/100], Loss: 0.3814, Validation Loss: 0.4470
	--> Epoch [37/100], Loss: 0.3565, Validation Loss: 0.4415
	--> Epoch [38/100], Loss: 0.3867, Validation Loss: 0.4360
	--> Epoch [39/100], Loss: 0.3121, Validation Loss: 0.4313
	--> Epoch [40/100], Loss: 0.3743, Validation Loss: 0.4275
	--> Epoch [41/100], Loss: 0.3505, Validation Loss: 0.4231
	--> Epoch [42/100], Loss: 0.3218, Validation Loss: 0.4190
	--> Epoch [43/100], Loss: 0.3416, Validation Loss: 0.4137
	--> Epoch [44/100], Loss: 0.3013, Validation Loss: 0.4072
	--> Epoch [45/100], Loss: 0.3531, Validation Loss: 0.4020
	--> Epoch [46/100], Loss: 0.3333, Validation Loss: 0.3969
	--> Epoch [47/100], Loss: 0.2818, Validation Loss: 0.3932
	--> Epoch [48/100], Loss: 0.3385, Validation Loss: 0.3883
	--> Epoch [49/100], Loss: 0.3167, Validation Loss: 0.3844
	--> Epoch [50/100], Loss: 0.3272, Validation Loss: 0.3807
	--> Epoch [51/100], Loss: 0.2951, Validation Loss: 0.3755
	--> Epoch [52/100], Loss: 0.2546, Validation Loss: 0.3723
	--> Epoch [53/100], Loss: 0.2854, Validation Loss: 0.3693
	--> Epoch [54/100], Loss: 0.2992, Validation Loss: 0.3641
	--> Epoch [55/100], Loss: 0.2744, Validation Loss: 0.3608
	--> Epoch [56/100], Loss: 0.2562, Validation Loss: 0.3561
	--> Epoch [57/100], Loss: 0.2894, Validation Loss: 0.3526
	--> Epoch [58/100], Loss: 0.2868, Validation Loss: 0.3494
	--> Epoch [59/100], Loss: 0.2406, Validation Loss: 0.3463
	--> Epoch [60/100], Loss: 0.2534, Validation Loss: 0.3435
	--> Epoch [61/100], Loss: 0.2320, Validation Loss: 0.3393
	--> Epoch [62/100], Loss: 0.2558, Validation Loss: 0.3363
	--> Epoch [63/100], Loss: 0.2324, Validation Loss: 0.3323
	--> Epoch [64/100], Loss: 0.2493, Validation Loss: 0.3298
	--> Epoch [65/100], Loss: 0.2498, Validation Loss: 0.3267
	--> Epoch [66/100], Loss: 0.1980, Validation Loss: 0.3251
	--> Epoch [67/100], Loss: 0.2575, Validation Loss: 0.3233
	--> Epoch [68/100], Loss: 0.2370, Validation Loss: 0.3195
	--> Epoch [69/100], Loss: 0.2107, Validation Loss: 0.3172
	--> Epoch [70/100], Loss: 0.2506, Validation Loss: 0.3133
	--> Epoch [71/100], Loss: 0.2166, Validation Loss: 0.3099
	--> Epoch [72/100], Loss: 0.2085, Validation Loss: 0.3085
	--> Epoch [73/100], Loss: 0.1919, Validation Loss: 0.3061
	--> Epoch [74/100], Loss: 0.2039, Validation Loss: 0.3047
	--> Epoch [75/100], Loss: 0.2510, Validation Loss: 0.3020
	--> Epoch [76/100], Loss: 0.2111, Validation Loss: 0.3009
	--> Epoch [77/100], Loss: 0.2128, Validation Loss: 0.2993
	--> Epoch [78/100], Loss: 0.2086, Validation Loss: 0.2979
	--> Epoch [79/100], Loss: 0.1754, Validation Loss: 0.2946
	--> Epoch [80/100], Loss: 0.2201, Validation Loss: 0.2915
	--> Epoch [81/100], Loss: 0.1906, Validation Loss: 0.2894
	--> Epoch [82/100], Loss: 0.1856, Validation Loss: 0.2867
	--> Epoch [83/100], Loss: 0.2014, Validation Loss: 0.2854
	--> Epoch [84/100], Loss: 0.1822, Validation Loss: 0.2828
	--> Epoch [85/100], Loss: 0.1905, Validation Loss: 0.2827
	--> Epoch [86/100], Loss: 0.2030, Validation Loss: 0.2824
	--> Epoch [87/100], Loss: 0.1994, Validation Loss: 0.2794
	--> Epoch [88/100], Loss: 0.2015, Validation Loss: 0.2772
	--> Epoch [89/100], Loss: 0.2173, Validation Loss: 0.2766
	--> Epoch [90/100], Loss: 0.1847, Validation Loss: 0.2761
	--> Epoch [91/100], Loss: 0.1674, Validation Loss: 0.2737
	--> Epoch [92/100], Loss: 0.2524, Validation Loss: 0.2733
	--> Epoch [93/100], Loss: 0.1731, Validation Loss: 0.2713
	--> Epoch [94/100], Loss: 0.1334, Validation Loss: 0.2700
	--> Epoch [95/100], Loss: 0.1687, Validation Loss: 0.2686
	--> Epoch [96/100], Loss: 0.1667, Validation Loss: 0.2677
	--> Epoch [97/100], Loss: 0.1712, Validation Loss: 0.2662
	--> Epoch [98/100], Loss: 0.1989, Validation Loss: 0.2648
	--> Epoch [99/100], Loss: 0.1919, Validation Loss: 0.2651
	--> Epoch [100/100], Loss: 0.2021, Validation Loss: 0.2642
	--> Training for Fold 1 took 0.41515493392944336 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7423, Validation Loss: 0.8022
	--> Epoch [2/100], Loss: 0.7333, Validation Loss: 0.7843
	--> Epoch [3/100], Loss: 0.7362, Validation Loss: 0.7626
	--> Epoch [4/100], Loss: 0.7026, Validation Loss: 0.7466
	--> Epoch [5/100], Loss: 0.6953, Validation Loss: 0.7257
	--> Epoch [6/100], Loss: 0.6665, Validation Loss: 0.7064
	--> Epoch [7/100], Loss: 0.6394, Validation Loss: 0.6842
	--> Epoch [8/100], Loss: 0.6298, Validation Loss: 0.6668
	--> Epoch [9/100], Loss: 0.6200, Validation Loss: 0.6533
	--> Epoch [10/100], Loss: 0.6181, Validation Loss: 0.6432
	--> Epoch [11/100], Loss: 0.5860, Validation Loss: 0.6316
	--> Epoch [12/100], Loss: 0.6112, Validation Loss: 0.6203
	--> Epoch [13/100], Loss: 0.5595, Validation Loss: 0.6044
	--> Epoch [14/100], Loss: 0.5782, Validation Loss: 0.5896
	--> Epoch [15/100], Loss: 0.5387, Validation Loss: 0.5754
	--> Epoch [16/100], Loss: 0.5473, Validation Loss: 0.5639
	--> Epoch [17/100], Loss: 0.5521, Validation Loss: 0.5522
	--> Epoch [18/100], Loss: 0.5268, Validation Loss: 0.5431
	--> Epoch [19/100], Loss: 0.5344, Validation Loss: 0.5325
	--> Epoch [20/100], Loss: 0.5027, Validation Loss: 0.5234
	--> Epoch [21/100], Loss: 0.4971, Validation Loss: 0.5119
	--> Epoch [22/100], Loss: 0.5277, Validation Loss: 0.5018
	--> Epoch [23/100], Loss: 0.4858, Validation Loss: 0.4942
	--> Epoch [24/100], Loss: 0.4747, Validation Loss: 0.4883
	--> Epoch [25/100], Loss: 0.4453, Validation Loss: 0.4813
	--> Epoch [26/100], Loss: 0.4987, Validation Loss: 0.4752
	--> Epoch [27/100], Loss: 0.4657, Validation Loss: 0.4682
	--> Epoch [28/100], Loss: 0.4221, Validation Loss: 0.4633
	--> Epoch [29/100], Loss: 0.4115, Validation Loss: 0.4580
	--> Epoch [30/100], Loss: 0.4167, Validation Loss: 0.4533
	--> Epoch [31/100], Loss: 0.4255, Validation Loss: 0.4479
	--> Epoch [32/100], Loss: 0.4403, Validation Loss: 0.4436
	--> Epoch [33/100], Loss: 0.4167, Validation Loss: 0.4399
	--> Epoch [34/100], Loss: 0.4406, Validation Loss: 0.4340
	--> Epoch [35/100], Loss: 0.4023, Validation Loss: 0.4304
	--> Epoch [36/100], Loss: 0.4110, Validation Loss: 0.4263
	--> Epoch [37/100], Loss: 0.3740, Validation Loss: 0.4218
	--> Epoch [38/100], Loss: 0.3830, Validation Loss: 0.4175
	--> Epoch [39/100], Loss: 0.3356, Validation Loss: 0.4134
	--> Epoch [40/100], Loss: 0.3467, Validation Loss: 0.4085
	--> Epoch [41/100], Loss: 0.3706, Validation Loss: 0.4043
	--> Epoch [42/100], Loss: 0.3857, Validation Loss: 0.4004
	--> Epoch [43/100], Loss: 0.3864, Validation Loss: 0.3957
	--> Epoch [44/100], Loss: 0.3219, Validation Loss: 0.3912
	--> Epoch [45/100], Loss: 0.3588, Validation Loss: 0.3878
	--> Epoch [46/100], Loss: 0.3463, Validation Loss: 0.3836
	--> Epoch [47/100], Loss: 0.3296, Validation Loss: 0.3811
	--> Epoch [48/100], Loss: 0.3090, Validation Loss: 0.3775
	--> Epoch [49/100], Loss: 0.3172, Validation Loss: 0.3731
	--> Epoch [50/100], Loss: 0.3016, Validation Loss: 0.3707
	--> Epoch [51/100], Loss: 0.3087, Validation Loss: 0.3676
	--> Epoch [52/100], Loss: 0.3026, Validation Loss: 0.3654
	--> Epoch [53/100], Loss: 0.3063, Validation Loss: 0.3641
	--> Epoch [54/100], Loss: 0.3017, Validation Loss: 0.3623
	--> Epoch [55/100], Loss: 0.2997, Validation Loss: 0.3589
	--> Epoch [56/100], Loss: 0.2703, Validation Loss: 0.3556
	--> Epoch [57/100], Loss: 0.3015, Validation Loss: 0.3542
	--> Epoch [58/100], Loss: 0.3162, Validation Loss: 0.3538
	--> Epoch [59/100], Loss: 0.2839, Validation Loss: 0.3511
	--> Epoch [60/100], Loss: 0.2801, Validation Loss: 0.3482
	--> Epoch [61/100], Loss: 0.3013, Validation Loss: 0.3466
	--> Epoch [62/100], Loss: 0.2437, Validation Loss: 0.3431
	--> Epoch [63/100], Loss: 0.2628, Validation Loss: 0.3407
	--> Epoch [64/100], Loss: 0.3225, Validation Loss: 0.3390
	--> Epoch [65/100], Loss: 0.2958, Validation Loss: 0.3367
	--> Epoch [66/100], Loss: 0.2755, Validation Loss: 0.3346
	--> Epoch [67/100], Loss: 0.2580, Validation Loss: 0.3322
	--> Epoch [68/100], Loss: 0.2959, Validation Loss: 0.3311
	--> Epoch [69/100], Loss: 0.2856, Validation Loss: 0.3303
	--> Epoch [70/100], Loss: 0.2907, Validation Loss: 0.3281
	--> Epoch [71/100], Loss: 0.2286, Validation Loss: 0.3269
	--> Epoch [72/100], Loss: 0.2667, Validation Loss: 0.3261
	--> Epoch [73/100], Loss: 0.2424, Validation Loss: 0.3233
	--> Epoch [74/100], Loss: 0.2550, Validation Loss: 0.3230
	--> Epoch [75/100], Loss: 0.2299, Validation Loss: 0.3219
	--> Epoch [76/100], Loss: 0.2823, Validation Loss: 0.3194
	--> Epoch [77/100], Loss: 0.2389, Validation Loss: 0.3173
	--> Epoch [78/100], Loss: 0.2005, Validation Loss: 0.3152
	--> Epoch [79/100], Loss: 0.2621, Validation Loss: 0.3138
	--> Epoch [80/100], Loss: 0.2407, Validation Loss: 0.3121
	--> Epoch [81/100], Loss: 0.1927, Validation Loss: 0.3117
	--> Epoch [82/100], Loss: 0.2047, Validation Loss: 0.3102
	--> Epoch [83/100], Loss: 0.2379, Validation Loss: 0.3097
	--> Epoch [84/100], Loss: 0.2098, Validation Loss: 0.3082
	--> Epoch [85/100], Loss: 0.2253, Validation Loss: 0.3062
	--> Epoch [86/100], Loss: 0.2182, Validation Loss: 0.3043
	--> Epoch [87/100], Loss: 0.2351, Validation Loss: 0.3030
	--> Epoch [88/100], Loss: 0.2431, Validation Loss: 0.3020
	--> Epoch [89/100], Loss: 0.2378, Validation Loss: 0.2997
	--> Epoch [90/100], Loss: 0.2158, Validation Loss: 0.2978
	--> Epoch [91/100], Loss: 0.1920, Validation Loss: 0.2961
	--> Epoch [92/100], Loss: 0.2394, Validation Loss: 0.2950
	--> Epoch [93/100], Loss: 0.2087, Validation Loss: 0.2945
	--> Epoch [94/100], Loss: 0.1840, Validation Loss: 0.2933
	--> Epoch [95/100], Loss: 0.2191, Validation Loss: 0.2918
	--> Epoch [96/100], Loss: 0.2030, Validation Loss: 0.2908
	--> Epoch [97/100], Loss: 0.1891, Validation Loss: 0.2896
	--> Epoch [98/100], Loss: 0.2042, Validation Loss: 0.2887
	--> Epoch [99/100], Loss: 0.1646, Validation Loss: 0.2884
	--> Epoch [100/100], Loss: 0.2030, Validation Loss: 0.2855
	--> Training for Fold 2 took 0.4312746524810791 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8228, Validation Loss: 0.7491
	--> Epoch [2/100], Loss: 0.8150, Validation Loss: 0.7326
	--> Epoch [3/100], Loss: 0.7950, Validation Loss: 0.7159
	--> Epoch [4/100], Loss: 0.7405, Validation Loss: 0.7005
	--> Epoch [5/100], Loss: 0.7648, Validation Loss: 0.6882
	--> Epoch [6/100], Loss: 0.6991, Validation Loss: 0.6807
	--> Epoch [7/100], Loss: 0.6890, Validation Loss: 0.6726
	--> Epoch [8/100], Loss: 0.6888, Validation Loss: 0.6632
	--> Epoch [9/100], Loss: 0.6764, Validation Loss: 0.6567
	--> Epoch [10/100], Loss: 0.6362, Validation Loss: 0.6504
	--> Epoch [11/100], Loss: 0.6531, Validation Loss: 0.6431
	--> Epoch [12/100], Loss: 0.6466, Validation Loss: 0.6377
	--> Epoch [13/100], Loss: 0.6119, Validation Loss: 0.6309
	--> Epoch [14/100], Loss: 0.6209, Validation Loss: 0.6247
	--> Epoch [15/100], Loss: 0.5973, Validation Loss: 0.6189
	--> Epoch [16/100], Loss: 0.5889, Validation Loss: 0.6146
	--> Epoch [17/100], Loss: 0.5735, Validation Loss: 0.6099
	--> Epoch [18/100], Loss: 0.5643, Validation Loss: 0.6063
	--> Epoch [19/100], Loss: 0.5611, Validation Loss: 0.5994
	--> Epoch [20/100], Loss: 0.5790, Validation Loss: 0.5946
	--> Epoch [21/100], Loss: 0.5653, Validation Loss: 0.5908
	--> Epoch [22/100], Loss: 0.5455, Validation Loss: 0.5863
	--> Epoch [23/100], Loss: 0.5301, Validation Loss: 0.5812
	--> Epoch [24/100], Loss: 0.5215, Validation Loss: 0.5765
	--> Epoch [25/100], Loss: 0.5023, Validation Loss: 0.5728
	--> Epoch [26/100], Loss: 0.5164, Validation Loss: 0.5697
	--> Epoch [27/100], Loss: 0.5490, Validation Loss: 0.5656
	--> Epoch [28/100], Loss: 0.5235, Validation Loss: 0.5604
	--> Epoch [29/100], Loss: 0.4633, Validation Loss: 0.5558
	--> Epoch [30/100], Loss: 0.4810, Validation Loss: 0.5502
	--> Epoch [31/100], Loss: 0.4709, Validation Loss: 0.5470
	--> Epoch [32/100], Loss: 0.4831, Validation Loss: 0.5428
	--> Epoch [33/100], Loss: 0.5084, Validation Loss: 0.5391
	--> Epoch [34/100], Loss: 0.4707, Validation Loss: 0.5337
	--> Epoch [35/100], Loss: 0.4925, Validation Loss: 0.5299
	--> Epoch [36/100], Loss: 0.4615, Validation Loss: 0.5264
	--> Epoch [37/100], Loss: 0.4594, Validation Loss: 0.5227
	--> Epoch [38/100], Loss: 0.4951, Validation Loss: 0.5206
	--> Epoch [39/100], Loss: 0.4834, Validation Loss: 0.5172
	--> Epoch [40/100], Loss: 0.4472, Validation Loss: 0.5137
	--> Epoch [41/100], Loss: 0.4722, Validation Loss: 0.5102
	--> Epoch [42/100], Loss: 0.4249, Validation Loss: 0.5055
	--> Epoch [43/100], Loss: 0.4076, Validation Loss: 0.5023
	--> Epoch [44/100], Loss: 0.4464, Validation Loss: 0.4981
	--> Epoch [45/100], Loss: 0.4292, Validation Loss: 0.4946
	--> Epoch [46/100], Loss: 0.4910, Validation Loss: 0.4918
	--> Epoch [47/100], Loss: 0.4739, Validation Loss: 0.4901
	--> Epoch [48/100], Loss: 0.4376, Validation Loss: 0.4863
	--> Epoch [49/100], Loss: 0.4460, Validation Loss: 0.4826
	--> Epoch [50/100], Loss: 0.4409, Validation Loss: 0.4788
	--> Epoch [51/100], Loss: 0.4322, Validation Loss: 0.4744
	--> Epoch [52/100], Loss: 0.4329, Validation Loss: 0.4711
	--> Epoch [53/100], Loss: 0.4035, Validation Loss: 0.4684
	--> Epoch [54/100], Loss: 0.4443, Validation Loss: 0.4652
	--> Epoch [55/100], Loss: 0.3781, Validation Loss: 0.4643
	--> Epoch [56/100], Loss: 0.3862, Validation Loss: 0.4616
	--> Epoch [57/100], Loss: 0.3685, Validation Loss: 0.4592
	--> Epoch [58/100], Loss: 0.3739, Validation Loss: 0.4559
	--> Epoch [59/100], Loss: 0.3350, Validation Loss: 0.4529
	--> Epoch [60/100], Loss: 0.3378, Validation Loss: 0.4502
	--> Epoch [61/100], Loss: 0.3790, Validation Loss: 0.4475
	--> Epoch [62/100], Loss: 0.3485, Validation Loss: 0.4445
	--> Epoch [63/100], Loss: 0.3420, Validation Loss: 0.4412
	--> Epoch [64/100], Loss: 0.3791, Validation Loss: 0.4384
	--> Epoch [65/100], Loss: 0.4054, Validation Loss: 0.4350
	--> Epoch [66/100], Loss: 0.3428, Validation Loss: 0.4330
	--> Epoch [67/100], Loss: 0.3674, Validation Loss: 0.4304
	--> Epoch [68/100], Loss: 0.3676, Validation Loss: 0.4279
	--> Epoch [69/100], Loss: 0.3880, Validation Loss: 0.4267
	--> Epoch [70/100], Loss: 0.3728, Validation Loss: 0.4240
	--> Epoch [71/100], Loss: 0.3803, Validation Loss: 0.4221
	--> Epoch [72/100], Loss: 0.3741, Validation Loss: 0.4188
	--> Epoch [73/100], Loss: 0.3816, Validation Loss: 0.4177
	--> Epoch [74/100], Loss: 0.3179, Validation Loss: 0.4160
	--> Epoch [75/100], Loss: 0.3563, Validation Loss: 0.4149
	--> Epoch [76/100], Loss: 0.3307, Validation Loss: 0.4123
	--> Epoch [77/100], Loss: 0.3250, Validation Loss: 0.4103
	--> Epoch [78/100], Loss: 0.3574, Validation Loss: 0.4084
	--> Epoch [79/100], Loss: 0.3826, Validation Loss: 0.4079
	--> Epoch [80/100], Loss: 0.3207, Validation Loss: 0.4059
	--> Epoch [81/100], Loss: 0.3298, Validation Loss: 0.4041
	--> Epoch [82/100], Loss: 0.3031, Validation Loss: 0.4029
	--> Epoch [83/100], Loss: 0.3185, Validation Loss: 0.4002
	--> Epoch [84/100], Loss: 0.3729, Validation Loss: 0.3993
	--> Epoch [85/100], Loss: 0.2816, Validation Loss: 0.3976
	--> Epoch [86/100], Loss: 0.3230, Validation Loss: 0.3958
	--> Epoch [87/100], Loss: 0.3755, Validation Loss: 0.3949
	--> Epoch [88/100], Loss: 0.3492, Validation Loss: 0.3938
	--> Epoch [89/100], Loss: 0.3501, Validation Loss: 0.3915
	--> Epoch [90/100], Loss: 0.3220, Validation Loss: 0.3900
	--> Epoch [91/100], Loss: 0.3330, Validation Loss: 0.3882
	--> Epoch [92/100], Loss: 0.2874, Validation Loss: 0.3874
	--> Epoch [93/100], Loss: 0.2456, Validation Loss: 0.3865
	--> Epoch [94/100], Loss: 0.3355, Validation Loss: 0.3856
	--> Epoch [95/100], Loss: 0.3425, Validation Loss: 0.3837
	--> Epoch [96/100], Loss: 0.3125, Validation Loss: 0.3834
	--> Epoch [97/100], Loss: 0.3043, Validation Loss: 0.3818
	--> Epoch [98/100], Loss: 0.2933, Validation Loss: 0.3803
	--> Epoch [99/100], Loss: 0.3490, Validation Loss: 0.3786
	--> Epoch [100/100], Loss: 0.3335, Validation Loss: 0.3752
	--> Training for Fold 3 took 0.37833595275878906 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6869, Validation Loss: 0.6814
	--> Epoch [2/100], Loss: 0.6735, Validation Loss: 0.6718
	--> Epoch [3/100], Loss: 0.6547, Validation Loss: 0.6615
	--> Epoch [4/100], Loss: 0.6134, Validation Loss: 0.6521
	--> Epoch [5/100], Loss: 0.6131, Validation Loss: 0.6451
	--> Epoch [6/100], Loss: 0.5988, Validation Loss: 0.6358
	--> Epoch [7/100], Loss: 0.5922, Validation Loss: 0.6289
	--> Epoch [8/100], Loss: 0.5618, Validation Loss: 0.6184
	--> Epoch [9/100], Loss: 0.5502, Validation Loss: 0.6103
	--> Epoch [10/100], Loss: 0.5749, Validation Loss: 0.6040
	--> Epoch [11/100], Loss: 0.5356, Validation Loss: 0.5948
	--> Epoch [12/100], Loss: 0.5550, Validation Loss: 0.5866
	--> Epoch [13/100], Loss: 0.5248, Validation Loss: 0.5810
	--> Epoch [14/100], Loss: 0.5443, Validation Loss: 0.5747
	--> Epoch [15/100], Loss: 0.5125, Validation Loss: 0.5662
	--> Epoch [16/100], Loss: 0.4868, Validation Loss: 0.5592
	--> Epoch [17/100], Loss: 0.4886, Validation Loss: 0.5501
	--> Epoch [18/100], Loss: 0.4982, Validation Loss: 0.5462
	--> Epoch [19/100], Loss: 0.4841, Validation Loss: 0.5391
	--> Epoch [20/100], Loss: 0.4770, Validation Loss: 0.5322
	--> Epoch [21/100], Loss: 0.4672, Validation Loss: 0.5249
	--> Epoch [22/100], Loss: 0.4885, Validation Loss: 0.5199
	--> Epoch [23/100], Loss: 0.4409, Validation Loss: 0.5138
	--> Epoch [24/100], Loss: 0.4546, Validation Loss: 0.5075
	--> Epoch [25/100], Loss: 0.4530, Validation Loss: 0.5012
	--> Epoch [26/100], Loss: 0.4200, Validation Loss: 0.4928
	--> Epoch [27/100], Loss: 0.4295, Validation Loss: 0.4876
	--> Epoch [28/100], Loss: 0.4340, Validation Loss: 0.4830
	--> Epoch [29/100], Loss: 0.4200, Validation Loss: 0.4781
	--> Epoch [30/100], Loss: 0.3885, Validation Loss: 0.4714
	--> Epoch [31/100], Loss: 0.3645, Validation Loss: 0.4695
	--> Epoch [32/100], Loss: 0.3402, Validation Loss: 0.4644
	--> Epoch [33/100], Loss: 0.4003, Validation Loss: 0.4610
	--> Epoch [34/100], Loss: 0.3787, Validation Loss: 0.4571
	--> Epoch [35/100], Loss: 0.3941, Validation Loss: 0.4533
	--> Epoch [36/100], Loss: 0.3457, Validation Loss: 0.4486
	--> Epoch [37/100], Loss: 0.3738, Validation Loss: 0.4411
	--> Epoch [38/100], Loss: 0.3810, Validation Loss: 0.4378
	--> Epoch [39/100], Loss: 0.3886, Validation Loss: 0.4318
	--> Epoch [40/100], Loss: 0.3387, Validation Loss: 0.4267
	--> Epoch [41/100], Loss: 0.3426, Validation Loss: 0.4218
	--> Epoch [42/100], Loss: 0.3349, Validation Loss: 0.4183
	--> Epoch [43/100], Loss: 0.3718, Validation Loss: 0.4124
	--> Epoch [44/100], Loss: 0.2912, Validation Loss: 0.4083
	--> Epoch [45/100], Loss: 0.2980, Validation Loss: 0.4052
	--> Epoch [46/100], Loss: 0.3262, Validation Loss: 0.3997
	--> Epoch [47/100], Loss: 0.3016, Validation Loss: 0.3971
	--> Epoch [48/100], Loss: 0.2813, Validation Loss: 0.3928
	--> Epoch [49/100], Loss: 0.2810, Validation Loss: 0.3882
	--> Epoch [50/100], Loss: 0.3047, Validation Loss: 0.3856
	--> Epoch [51/100], Loss: 0.3026, Validation Loss: 0.3816
	--> Epoch [52/100], Loss: 0.2758, Validation Loss: 0.3780
	--> Epoch [53/100], Loss: 0.3006, Validation Loss: 0.3767
	--> Epoch [54/100], Loss: 0.2964, Validation Loss: 0.3726
	--> Epoch [55/100], Loss: 0.2797, Validation Loss: 0.3699
	--> Epoch [56/100], Loss: 0.2397, Validation Loss: 0.3660
	--> Epoch [57/100], Loss: 0.2659, Validation Loss: 0.3638
	--> Epoch [58/100], Loss: 0.2655, Validation Loss: 0.3611
	--> Epoch [59/100], Loss: 0.2448, Validation Loss: 0.3578
	--> Epoch [60/100], Loss: 0.2248, Validation Loss: 0.3547
	--> Epoch [61/100], Loss: 0.2585, Validation Loss: 0.3523
	--> Epoch [62/100], Loss: 0.2334, Validation Loss: 0.3490
	--> Epoch [63/100], Loss: 0.2345, Validation Loss: 0.3467
	--> Epoch [64/100], Loss: 0.2538, Validation Loss: 0.3469
	--> Epoch [65/100], Loss: 0.2354, Validation Loss: 0.3455
	--> Epoch [66/100], Loss: 0.2203, Validation Loss: 0.3429
	--> Epoch [67/100], Loss: 0.2540, Validation Loss: 0.3392
	--> Epoch [68/100], Loss: 0.2509, Validation Loss: 0.3365
	--> Epoch [69/100], Loss: 0.2074, Validation Loss: 0.3344
	--> Epoch [70/100], Loss: 0.2605, Validation Loss: 0.3345
	--> Epoch [71/100], Loss: 0.1915, Validation Loss: 0.3336
	--> Epoch [72/100], Loss: 0.1913, Validation Loss: 0.3310
	--> Epoch [73/100], Loss: 0.2543, Validation Loss: 0.3295
	--> Epoch [74/100], Loss: 0.2159, Validation Loss: 0.3277
	--> Epoch [75/100], Loss: 0.2126, Validation Loss: 0.3244
	--> Epoch [76/100], Loss: 0.2201, Validation Loss: 0.3236
	--> Epoch [77/100], Loss: 0.2506, Validation Loss: 0.3232
	--> Epoch [78/100], Loss: 0.2333, Validation Loss: 0.3217
	--> Epoch [79/100], Loss: 0.2269, Validation Loss: 0.3197
	--> Epoch [80/100], Loss: 0.1936, Validation Loss: 0.3187
	--> Epoch [81/100], Loss: 0.1888, Validation Loss: 0.3159
	--> Epoch [82/100], Loss: 0.2060, Validation Loss: 0.3140
	--> Epoch [83/100], Loss: 0.2054, Validation Loss: 0.3144
	--> Epoch [84/100], Loss: 0.2114, Validation Loss: 0.3130
	--> Epoch [85/100], Loss: 0.1896, Validation Loss: 0.3111
	--> Epoch [86/100], Loss: 0.1662, Validation Loss: 0.3105
	--> Epoch [87/100], Loss: 0.2191, Validation Loss: 0.3084
	--> Epoch [88/100], Loss: 0.1604, Validation Loss: 0.3067
	--> Epoch [89/100], Loss: 0.2222, Validation Loss: 0.3072
	--> Epoch [90/100], Loss: 0.2145, Validation Loss: 0.3069
	--> Epoch [91/100], Loss: 0.1972, Validation Loss: 0.3051
	--> Epoch [92/100], Loss: 0.1639, Validation Loss: 0.3034
	--> Epoch [93/100], Loss: 0.1635, Validation Loss: 0.3025
	--> Epoch [94/100], Loss: 0.1469, Validation Loss: 0.3012
	--> Epoch [95/100], Loss: 0.2247, Validation Loss: 0.2993
	--> Epoch [96/100], Loss: 0.1834, Validation Loss: 0.2974
	--> Epoch [97/100], Loss: 0.1524, Validation Loss: 0.2958
	--> Epoch [98/100], Loss: 0.1678, Validation Loss: 0.2945
	--> Epoch [99/100], Loss: 0.1605, Validation Loss: 0.2928
	--> Epoch [100/100], Loss: 0.1272, Validation Loss: 0.2919
	--> Training for Fold 4 took 0.3842473030090332 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7383, Validation Loss: 0.6231
	--> Epoch [2/100], Loss: 0.7335, Validation Loss: 0.6160
	--> Epoch [3/100], Loss: 0.7320, Validation Loss: 0.6068
	--> Epoch [4/100], Loss: 0.6744, Validation Loss: 0.6011
	--> Epoch [5/100], Loss: 0.6732, Validation Loss: 0.5964
	--> Epoch [6/100], Loss: 0.6542, Validation Loss: 0.5886
	--> Epoch [7/100], Loss: 0.6261, Validation Loss: 0.5832
	--> Epoch [8/100], Loss: 0.6040, Validation Loss: 0.5762
	--> Epoch [9/100], Loss: 0.6040, Validation Loss: 0.5716
	--> Epoch [10/100], Loss: 0.5721, Validation Loss: 0.5659
	--> Epoch [11/100], Loss: 0.5717, Validation Loss: 0.5598
	--> Epoch [12/100], Loss: 0.5615, Validation Loss: 0.5570
	--> Epoch [13/100], Loss: 0.5498, Validation Loss: 0.5544
	--> Epoch [14/100], Loss: 0.5386, Validation Loss: 0.5524
	--> Epoch [15/100], Loss: 0.4952, Validation Loss: 0.5494
	--> Epoch [16/100], Loss: 0.5197, Validation Loss: 0.5463
	--> Epoch [17/100], Loss: 0.4847, Validation Loss: 0.5419
	--> Epoch [18/100], Loss: 0.5085, Validation Loss: 0.5384
	--> Epoch [19/100], Loss: 0.4926, Validation Loss: 0.5364
	--> Epoch [20/100], Loss: 0.4608, Validation Loss: 0.5328
	--> Epoch [21/100], Loss: 0.4537, Validation Loss: 0.5324
	--> Epoch [22/100], Loss: 0.4448, Validation Loss: 0.5313
	--> Epoch [23/100], Loss: 0.4195, Validation Loss: 0.5309
	--> Epoch [24/100], Loss: 0.3907, Validation Loss: 0.5282
	--> Epoch [25/100], Loss: 0.4334, Validation Loss: 0.5289
	--> Epoch [26/100], Loss: 0.4074, Validation Loss: 0.5277
	--> Epoch [27/100], Loss: 0.3811, Validation Loss: 0.5270
	--> Epoch [28/100], Loss: 0.4165, Validation Loss: 0.5271
	--> Epoch [29/100], Loss: 0.3672, Validation Loss: 0.5265
	--> Epoch [30/100], Loss: 0.3792, Validation Loss: 0.5243
	--> Epoch [31/100], Loss: 0.3859, Validation Loss: 0.5228
	--> Epoch [32/100], Loss: 0.4032, Validation Loss: 0.5221
	--> Epoch [33/100], Loss: 0.3750, Validation Loss: 0.5210
	--> Epoch [34/100], Loss: 0.3318, Validation Loss: 0.5204
	--> Epoch [35/100], Loss: 0.3533, Validation Loss: 0.5188
	--> Epoch [36/100], Loss: 0.3598, Validation Loss: 0.5174
	--> Epoch [37/100], Loss: 0.3725, Validation Loss: 0.5171
	--> Epoch [38/100], Loss: 0.3519, Validation Loss: 0.5158
	--> Epoch [39/100], Loss: 0.3196, Validation Loss: 0.5150
	--> Epoch [40/100], Loss: 0.3035, Validation Loss: 0.5129
	--> Epoch [41/100], Loss: 0.3000, Validation Loss: 0.5107
	--> Epoch [42/100], Loss: 0.3115, Validation Loss: 0.5093
	--> Epoch [43/100], Loss: 0.2984, Validation Loss: 0.5089
	--> Epoch [44/100], Loss: 0.3105, Validation Loss: 0.5068
	--> Epoch [45/100], Loss: 0.3210, Validation Loss: 0.5061
	--> Epoch [46/100], Loss: 0.2863, Validation Loss: 0.5046
	--> Epoch [47/100], Loss: 0.2982, Validation Loss: 0.5035
	--> Epoch [48/100], Loss: 0.2914, Validation Loss: 0.5030
	--> Epoch [49/100], Loss: 0.2641, Validation Loss: 0.5016
	--> Epoch [50/100], Loss: 0.2331, Validation Loss: 0.5002
	--> Epoch [51/100], Loss: 0.2464, Validation Loss: 0.4993
	--> Epoch [52/100], Loss: 0.2894, Validation Loss: 0.4995
	--> Epoch [53/100], Loss: 0.2602, Validation Loss: 0.5009
	--> Epoch [54/100], Loss: 0.2891, Validation Loss: 0.4990
	--> Epoch [55/100], Loss: 0.2783, Validation Loss: 0.4976
	--> Epoch [56/100], Loss: 0.2947, Validation Loss: 0.4979
	--> Epoch [57/100], Loss: 0.2728, Validation Loss: 0.4982
	--> Epoch [58/100], Loss: 0.2791, Validation Loss: 0.4983
Early stopping
	--> Training for Fold 5 took 0.2145068645477295 sec, using 58 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7363
	--> Final training Epoch [2/100], Loss: 0.6912
	--> Final training Epoch [3/100], Loss: 0.7021
	--> Final training Epoch [4/100], Loss: 0.6781
	--> Final training Epoch [5/100], Loss: 0.6252
	--> Final training Epoch [6/100], Loss: 0.6444
	--> Final training Epoch [7/100], Loss: 0.6264
	--> Final training Epoch [8/100], Loss: 0.5886
	--> Final training Epoch [9/100], Loss: 0.5885
	--> Final training Epoch [10/100], Loss: 0.5508
	--> Final training Epoch [11/100], Loss: 0.5588
	--> Final training Epoch [12/100], Loss: 0.5752
	--> Final training Epoch [13/100], Loss: 0.5585
	--> Final training Epoch [14/100], Loss: 0.5474
	--> Final training Epoch [15/100], Loss: 0.5038
	--> Final training Epoch [16/100], Loss: 0.5395
	--> Final training Epoch [17/100], Loss: 0.5036
	--> Final training Epoch [18/100], Loss: 0.4650
	--> Final training Epoch [19/100], Loss: 0.4810
	--> Final training Epoch [20/100], Loss: 0.4927
	--> Final training Epoch [21/100], Loss: 0.4907
	--> Final training Epoch [22/100], Loss: 0.4979
	--> Final training Epoch [23/100], Loss: 0.4646
	--> Final training Epoch [24/100], Loss: 0.4303
	--> Final training Epoch [25/100], Loss: 0.4221
	--> Final training Epoch [26/100], Loss: 0.4129
	--> Final training Epoch [27/100], Loss: 0.4460
	--> Final training Epoch [28/100], Loss: 0.4202
	--> Final training Epoch [29/100], Loss: 0.4183
	--> Final training Epoch [30/100], Loss: 0.4196
	--> Final training Epoch [31/100], Loss: 0.3731
	--> Final training Epoch [32/100], Loss: 0.3838
	--> Final training Epoch [33/100], Loss: 0.3525
	--> Final training Epoch [34/100], Loss: 0.3431
	--> Final training Epoch [35/100], Loss: 0.3514
	--> Final training Epoch [36/100], Loss: 0.3192
	--> Final training Epoch [37/100], Loss: 0.3578
	--> Final training Epoch [38/100], Loss: 0.3735
	--> Final training Epoch [39/100], Loss: 0.3420
	--> Final training Epoch [40/100], Loss: 0.3346
	--> Final training Epoch [41/100], Loss: 0.3038
	--> Final training Epoch [42/100], Loss: 0.3274
	--> Final training Epoch [43/100], Loss: 0.3532
	--> Final training Epoch [44/100], Loss: 0.3278
	--> Final training Epoch [45/100], Loss: 0.2923
	--> Final training Epoch [46/100], Loss: 0.2967
	--> Final training Epoch [47/100], Loss: 0.2736
	--> Final training Epoch [48/100], Loss: 0.3120
	--> Final training Epoch [49/100], Loss: 0.2965
	--> Final training Epoch [50/100], Loss: 0.2883
	--> Final training Epoch [51/100], Loss: 0.3515
	--> Final training Epoch [52/100], Loss: 0.3014
	--> Final training Epoch [53/100], Loss: 0.2787
	--> Final training Epoch [54/100], Loss: 0.2561
	--> Final training Epoch [55/100], Loss: 0.2748
	--> Final training Epoch [56/100], Loss: 0.2623
	--> Final training Epoch [57/100], Loss: 0.2922
	--> Final training Epoch [58/100], Loss: 0.2577
	--> Final training Epoch [59/100], Loss: 0.2422
	--> Final training Epoch [60/100], Loss: 0.2333
	--> Final training Epoch [61/100], Loss: 0.2246
	--> Final training Epoch [62/100], Loss: 0.2676
	--> Final training Epoch [63/100], Loss: 0.2196
	--> Final training Epoch [64/100], Loss: 0.2275
	--> Final training Epoch [65/100], Loss: 0.2455
	--> Final training Epoch [66/100], Loss: 0.2379
	--> Final training Epoch [67/100], Loss: 0.2506
	--> Final training Epoch [68/100], Loss: 0.2271
	--> Final training Epoch [69/100], Loss: 0.2273
	--> Final training Epoch [70/100], Loss: 0.2592
	--> Final training Epoch [71/100], Loss: 0.2681
	--> Final training Epoch [72/100], Loss: 0.2324
	--> Final training Epoch [73/100], Loss: 0.2151
	--> Final training Epoch [74/100], Loss: 0.2294
	--> Final training Epoch [75/100], Loss: 0.2686
	--> Final training Epoch [76/100], Loss: 0.1883
	--> Final training Epoch [77/100], Loss: 0.2170
	--> Final training Epoch [78/100], Loss: 0.2389
	--> Final training Epoch [79/100], Loss: 0.1859
	--> Final training Epoch [80/100], Loss: 0.2362
	--> Final training Epoch [81/100], Loss: 0.2138
	--> Final training Epoch [82/100], Loss: 0.2200
	--> Final training Epoch [83/100], Loss: 0.2075
	--> Final training Epoch [84/100], Loss: 0.1724
	--> Final training Epoch [85/100], Loss: 0.1858
	--> Final training Epoch [86/100], Loss: 0.2256
	--> Final training Epoch [87/100], Loss: 0.2005
	--> Final training Epoch [88/100], Loss: 0.1662
	--> Final training Epoch [89/100], Loss: 0.2222
	--> Final training Epoch [90/100], Loss: 0.1618
	--> Final training Epoch [91/100], Loss: 0.1632
	--> Final training Epoch [92/100], Loss: 0.1934
	--> Final training Epoch [93/100], Loss: 0.1658
	--> Final training Epoch [94/100], Loss: 0.2188
	--> Final training Epoch [95/100], Loss: 0.2193
	--> Final training Epoch [96/100], Loss: 0.1758
	--> Final training Epoch [97/100], Loss: 0.1915
	--> Final training Epoch [98/100], Loss: 0.1620
	--> Final training Epoch [99/100], Loss: 0.1764
	--> Final training Epoch [100/100], Loss: 0.1877

Final training took 0.3931288719177246 sec

TESTING
	--> Testing took 0.0095 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.7500
	--> Final Precision: 0.6923
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6923
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8164, Validation Loss: 0.3681,  Current Best Accuracy: 0.8164,  Current Best Validation Loss: 0.3681

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7981, Validation Loss: 0.6289
	--> Epoch [2/100], Loss: 0.7606, Validation Loss: 0.6151
	--> Epoch [3/100], Loss: 0.7383, Validation Loss: 0.6019
	--> Epoch [4/100], Loss: 0.7252, Validation Loss: 0.5909
	--> Epoch [5/100], Loss: 0.7358, Validation Loss: 0.5821
	--> Epoch [6/100], Loss: 0.7227, Validation Loss: 0.5728
	--> Epoch [7/100], Loss: 0.6903, Validation Loss: 0.5651
	--> Epoch [8/100], Loss: 0.6929, Validation Loss: 0.5594
	--> Epoch [9/100], Loss: 0.6921, Validation Loss: 0.5519
	--> Epoch [10/100], Loss: 0.6588, Validation Loss: 0.5435
	--> Epoch [11/100], Loss: 0.6504, Validation Loss: 0.5373
	--> Epoch [12/100], Loss: 0.6350, Validation Loss: 0.5305
	--> Epoch [13/100], Loss: 0.6275, Validation Loss: 0.5256
	--> Epoch [14/100], Loss: 0.6268, Validation Loss: 0.5212
	--> Epoch [15/100], Loss: 0.6169, Validation Loss: 0.5162
	--> Epoch [16/100], Loss: 0.6172, Validation Loss: 0.5118
	--> Epoch [17/100], Loss: 0.6080, Validation Loss: 0.5076
	--> Epoch [18/100], Loss: 0.6093, Validation Loss: 0.5034
	--> Epoch [19/100], Loss: 0.6199, Validation Loss: 0.4996
	--> Epoch [20/100], Loss: 0.5786, Validation Loss: 0.4956
	--> Epoch [21/100], Loss: 0.5655, Validation Loss: 0.4939
	--> Epoch [22/100], Loss: 0.5604, Validation Loss: 0.4903
	--> Epoch [23/100], Loss: 0.5558, Validation Loss: 0.4862
	--> Epoch [24/100], Loss: 0.5462, Validation Loss: 0.4838
	--> Epoch [25/100], Loss: 0.5535, Validation Loss: 0.4821
	--> Epoch [26/100], Loss: 0.5291, Validation Loss: 0.4779
	--> Epoch [27/100], Loss: 0.5172, Validation Loss: 0.4753
	--> Epoch [28/100], Loss: 0.5613, Validation Loss: 0.4730
	--> Epoch [29/100], Loss: 0.5521, Validation Loss: 0.4705
	--> Epoch [30/100], Loss: 0.5594, Validation Loss: 0.4677
	--> Epoch [31/100], Loss: 0.5408, Validation Loss: 0.4656
	--> Epoch [32/100], Loss: 0.5202, Validation Loss: 0.4632
	--> Epoch [33/100], Loss: 0.5056, Validation Loss: 0.4612
	--> Epoch [34/100], Loss: 0.5019, Validation Loss: 0.4567
	--> Epoch [35/100], Loss: 0.4925, Validation Loss: 0.4542
	--> Epoch [36/100], Loss: 0.5036, Validation Loss: 0.4514
	--> Epoch [37/100], Loss: 0.4858, Validation Loss: 0.4478
	--> Epoch [38/100], Loss: 0.5045, Validation Loss: 0.4459
	--> Epoch [39/100], Loss: 0.4962, Validation Loss: 0.4434
	--> Epoch [40/100], Loss: 0.4975, Validation Loss: 0.4405
	--> Epoch [41/100], Loss: 0.4557, Validation Loss: 0.4387
	--> Epoch [42/100], Loss: 0.4962, Validation Loss: 0.4369
	--> Epoch [43/100], Loss: 0.4997, Validation Loss: 0.4351
	--> Epoch [44/100], Loss: 0.4805, Validation Loss: 0.4334
	--> Epoch [45/100], Loss: 0.4505, Validation Loss: 0.4307
	--> Epoch [46/100], Loss: 0.4835, Validation Loss: 0.4279
	--> Epoch [47/100], Loss: 0.4605, Validation Loss: 0.4248
	--> Epoch [48/100], Loss: 0.4495, Validation Loss: 0.4225
	--> Epoch [49/100], Loss: 0.4446, Validation Loss: 0.4189
	--> Epoch [50/100], Loss: 0.4674, Validation Loss: 0.4165
	--> Epoch [51/100], Loss: 0.4400, Validation Loss: 0.4149
	--> Epoch [52/100], Loss: 0.4640, Validation Loss: 0.4122
	--> Epoch [53/100], Loss: 0.4045, Validation Loss: 0.4095
	--> Epoch [54/100], Loss: 0.4379, Validation Loss: 0.4054
	--> Epoch [55/100], Loss: 0.3834, Validation Loss: 0.4016
	--> Epoch [56/100], Loss: 0.4402, Validation Loss: 0.3985
	--> Epoch [57/100], Loss: 0.4189, Validation Loss: 0.3965
	--> Epoch [58/100], Loss: 0.4519, Validation Loss: 0.3941
	--> Epoch [59/100], Loss: 0.4192, Validation Loss: 0.3935
	--> Epoch [60/100], Loss: 0.4105, Validation Loss: 0.3913
	--> Epoch [61/100], Loss: 0.4171, Validation Loss: 0.3897
	--> Epoch [62/100], Loss: 0.3923, Validation Loss: 0.3889
	--> Epoch [63/100], Loss: 0.4110, Validation Loss: 0.3871
	--> Epoch [64/100], Loss: 0.3985, Validation Loss: 0.3848
	--> Epoch [65/100], Loss: 0.3727, Validation Loss: 0.3829
	--> Epoch [66/100], Loss: 0.3214, Validation Loss: 0.3817
	--> Epoch [67/100], Loss: 0.3892, Validation Loss: 0.3799
	--> Epoch [68/100], Loss: 0.3657, Validation Loss: 0.3770
	--> Epoch [69/100], Loss: 0.3752, Validation Loss: 0.3762
	--> Epoch [70/100], Loss: 0.4197, Validation Loss: 0.3749
	--> Epoch [71/100], Loss: 0.3824, Validation Loss: 0.3726
	--> Epoch [72/100], Loss: 0.3617, Validation Loss: 0.3713
	--> Epoch [73/100], Loss: 0.3720, Validation Loss: 0.3693
	--> Epoch [74/100], Loss: 0.3368, Validation Loss: 0.3678
	--> Epoch [75/100], Loss: 0.4198, Validation Loss: 0.3667
	--> Epoch [76/100], Loss: 0.3941, Validation Loss: 0.3655
	--> Epoch [77/100], Loss: 0.3874, Validation Loss: 0.3646
	--> Epoch [78/100], Loss: 0.3840, Validation Loss: 0.3643
	--> Epoch [79/100], Loss: 0.3650, Validation Loss: 0.3627
	--> Epoch [80/100], Loss: 0.3572, Validation Loss: 0.3613
	--> Epoch [81/100], Loss: 0.3680, Validation Loss: 0.3596
	--> Epoch [82/100], Loss: 0.3408, Validation Loss: 0.3587
	--> Epoch [83/100], Loss: 0.3111, Validation Loss: 0.3578
	--> Epoch [84/100], Loss: 0.3665, Validation Loss: 0.3553
	--> Epoch [85/100], Loss: 0.3436, Validation Loss: 0.3524
	--> Epoch [86/100], Loss: 0.3178, Validation Loss: 0.3524
	--> Epoch [87/100], Loss: 0.3770, Validation Loss: 0.3523
	--> Epoch [88/100], Loss: 0.3089, Validation Loss: 0.3514
	--> Epoch [89/100], Loss: 0.3043, Validation Loss: 0.3501
	--> Epoch [90/100], Loss: 0.3347, Validation Loss: 0.3504
	--> Epoch [91/100], Loss: 0.3401, Validation Loss: 0.3489
	--> Epoch [92/100], Loss: 0.3656, Validation Loss: 0.3479
	--> Epoch [93/100], Loss: 0.3691, Validation Loss: 0.3476
	--> Epoch [94/100], Loss: 0.3452, Validation Loss: 0.3462
	--> Epoch [95/100], Loss: 0.2795, Validation Loss: 0.3440
	--> Epoch [96/100], Loss: 0.3015, Validation Loss: 0.3427
	--> Epoch [97/100], Loss: 0.3334, Validation Loss: 0.3426
	--> Epoch [98/100], Loss: 0.2687, Validation Loss: 0.3425
	--> Epoch [99/100], Loss: 0.3686, Validation Loss: 0.3420
	--> Epoch [100/100], Loss: 0.3056, Validation Loss: 0.3406
	--> Training for Fold 1 took 0.3800945281982422 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7227, Validation Loss: 0.7020
	--> Epoch [2/100], Loss: 0.6858, Validation Loss: 0.6927
	--> Epoch [3/100], Loss: 0.6769, Validation Loss: 0.6810
	--> Epoch [4/100], Loss: 0.6843, Validation Loss: 0.6740
	--> Epoch [5/100], Loss: 0.6664, Validation Loss: 0.6626
	--> Epoch [6/100], Loss: 0.6750, Validation Loss: 0.6541
	--> Epoch [7/100], Loss: 0.6729, Validation Loss: 0.6495
	--> Epoch [8/100], Loss: 0.6567, Validation Loss: 0.6452
	--> Epoch [9/100], Loss: 0.6521, Validation Loss: 0.6359
	--> Epoch [10/100], Loss: 0.6087, Validation Loss: 0.6272
	--> Epoch [11/100], Loss: 0.6352, Validation Loss: 0.6153
	--> Epoch [12/100], Loss: 0.6054, Validation Loss: 0.6052
	--> Epoch [13/100], Loss: 0.5979, Validation Loss: 0.5990
	--> Epoch [14/100], Loss: 0.5544, Validation Loss: 0.5935
	--> Epoch [15/100], Loss: 0.6057, Validation Loss: 0.5880
	--> Epoch [16/100], Loss: 0.5673, Validation Loss: 0.5793
	--> Epoch [17/100], Loss: 0.5617, Validation Loss: 0.5711
	--> Epoch [18/100], Loss: 0.5475, Validation Loss: 0.5626
	--> Epoch [19/100], Loss: 0.5400, Validation Loss: 0.5558
	--> Epoch [20/100], Loss: 0.5347, Validation Loss: 0.5481
	--> Epoch [21/100], Loss: 0.5183, Validation Loss: 0.5411
	--> Epoch [22/100], Loss: 0.5166, Validation Loss: 0.5369
	--> Epoch [23/100], Loss: 0.5411, Validation Loss: 0.5304
	--> Epoch [24/100], Loss: 0.4656, Validation Loss: 0.5245
	--> Epoch [25/100], Loss: 0.4852, Validation Loss: 0.5175
	--> Epoch [26/100], Loss: 0.4521, Validation Loss: 0.5122
	--> Epoch [27/100], Loss: 0.4772, Validation Loss: 0.5042
	--> Epoch [28/100], Loss: 0.5254, Validation Loss: 0.4988
	--> Epoch [29/100], Loss: 0.4924, Validation Loss: 0.4945
	--> Epoch [30/100], Loss: 0.4701, Validation Loss: 0.4904
	--> Epoch [31/100], Loss: 0.4082, Validation Loss: 0.4869
	--> Epoch [32/100], Loss: 0.4591, Validation Loss: 0.4820
	--> Epoch [33/100], Loss: 0.3949, Validation Loss: 0.4774
	--> Epoch [34/100], Loss: 0.4096, Validation Loss: 0.4735
	--> Epoch [35/100], Loss: 0.4386, Validation Loss: 0.4707
	--> Epoch [36/100], Loss: 0.4089, Validation Loss: 0.4659
	--> Epoch [37/100], Loss: 0.4183, Validation Loss: 0.4606
	--> Epoch [38/100], Loss: 0.4319, Validation Loss: 0.4571
	--> Epoch [39/100], Loss: 0.3910, Validation Loss: 0.4516
	--> Epoch [40/100], Loss: 0.3891, Validation Loss: 0.4465
	--> Epoch [41/100], Loss: 0.4001, Validation Loss: 0.4453
	--> Epoch [42/100], Loss: 0.3323, Validation Loss: 0.4388
	--> Epoch [43/100], Loss: 0.3969, Validation Loss: 0.4320
	--> Epoch [44/100], Loss: 0.3541, Validation Loss: 0.4264
	--> Epoch [45/100], Loss: 0.3885, Validation Loss: 0.4219
	--> Epoch [46/100], Loss: 0.3435, Validation Loss: 0.4177
	--> Epoch [47/100], Loss: 0.3736, Validation Loss: 0.4130
	--> Epoch [48/100], Loss: 0.3236, Validation Loss: 0.4093
	--> Epoch [49/100], Loss: 0.3171, Validation Loss: 0.4072
	--> Epoch [50/100], Loss: 0.3312, Validation Loss: 0.4035
	--> Epoch [51/100], Loss: 0.3402, Validation Loss: 0.3985
	--> Epoch [52/100], Loss: 0.3087, Validation Loss: 0.3956
	--> Epoch [53/100], Loss: 0.3599, Validation Loss: 0.3919
	--> Epoch [54/100], Loss: 0.3228, Validation Loss: 0.3893
	--> Epoch [55/100], Loss: 0.3407, Validation Loss: 0.3860
	--> Epoch [56/100], Loss: 0.3090, Validation Loss: 0.3835
	--> Epoch [57/100], Loss: 0.3003, Validation Loss: 0.3807
	--> Epoch [58/100], Loss: 0.3289, Validation Loss: 0.3789
	--> Epoch [59/100], Loss: 0.3084, Validation Loss: 0.3778
	--> Epoch [60/100], Loss: 0.2616, Validation Loss: 0.3755
	--> Epoch [61/100], Loss: 0.3020, Validation Loss: 0.3744
	--> Epoch [62/100], Loss: 0.3269, Validation Loss: 0.3729
	--> Epoch [63/100], Loss: 0.3056, Validation Loss: 0.3704
	--> Epoch [64/100], Loss: 0.2709, Validation Loss: 0.3679
	--> Epoch [65/100], Loss: 0.2751, Validation Loss: 0.3678
	--> Epoch [66/100], Loss: 0.2795, Validation Loss: 0.3645
	--> Epoch [67/100], Loss: 0.2651, Validation Loss: 0.3624
	--> Epoch [68/100], Loss: 0.2706, Validation Loss: 0.3595
	--> Epoch [69/100], Loss: 0.2649, Validation Loss: 0.3565
	--> Epoch [70/100], Loss: 0.2691, Validation Loss: 0.3544
	--> Epoch [71/100], Loss: 0.2745, Validation Loss: 0.3528
	--> Epoch [72/100], Loss: 0.2720, Validation Loss: 0.3506
	--> Epoch [73/100], Loss: 0.2436, Validation Loss: 0.3492
	--> Epoch [74/100], Loss: 0.2637, Validation Loss: 0.3480
	--> Epoch [75/100], Loss: 0.2490, Validation Loss: 0.3454
	--> Epoch [76/100], Loss: 0.2746, Validation Loss: 0.3434
	--> Epoch [77/100], Loss: 0.2356, Validation Loss: 0.3410
	--> Epoch [78/100], Loss: 0.2366, Validation Loss: 0.3399
	--> Epoch [79/100], Loss: 0.2064, Validation Loss: 0.3388
	--> Epoch [80/100], Loss: 0.2052, Validation Loss: 0.3385
	--> Epoch [81/100], Loss: 0.2095, Validation Loss: 0.3361
	--> Epoch [82/100], Loss: 0.2463, Validation Loss: 0.3354
	--> Epoch [83/100], Loss: 0.2562, Validation Loss: 0.3341
	--> Epoch [84/100], Loss: 0.2048, Validation Loss: 0.3333
	--> Epoch [85/100], Loss: 0.1925, Validation Loss: 0.3327
	--> Epoch [86/100], Loss: 0.2604, Validation Loss: 0.3295
	--> Epoch [87/100], Loss: 0.2312, Validation Loss: 0.3286
	--> Epoch [88/100], Loss: 0.2230, Validation Loss: 0.3270
	--> Epoch [89/100], Loss: 0.2055, Validation Loss: 0.3257
	--> Epoch [90/100], Loss: 0.2208, Validation Loss: 0.3253
	--> Epoch [91/100], Loss: 0.2194, Validation Loss: 0.3238
	--> Epoch [92/100], Loss: 0.2149, Validation Loss: 0.3217
	--> Epoch [93/100], Loss: 0.1883, Validation Loss: 0.3208
	--> Epoch [94/100], Loss: 0.2003, Validation Loss: 0.3201
	--> Epoch [95/100], Loss: 0.1722, Validation Loss: 0.3192
	--> Epoch [96/100], Loss: 0.1863, Validation Loss: 0.3174
	--> Epoch [97/100], Loss: 0.2402, Validation Loss: 0.3168
	--> Epoch [98/100], Loss: 0.1996, Validation Loss: 0.3162
	--> Epoch [99/100], Loss: 0.1925, Validation Loss: 0.3147
	--> Epoch [100/100], Loss: 0.1918, Validation Loss: 0.3140
	--> Training for Fold 2 took 0.5428586006164551 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7291, Validation Loss: 0.6594
	--> Epoch [2/100], Loss: 0.7218, Validation Loss: 0.6499
	--> Epoch [3/100], Loss: 0.6943, Validation Loss: 0.6417
	--> Epoch [4/100], Loss: 0.7018, Validation Loss: 0.6348
	--> Epoch [5/100], Loss: 0.6600, Validation Loss: 0.6291
	--> Epoch [6/100], Loss: 0.6288, Validation Loss: 0.6244
	--> Epoch [7/100], Loss: 0.6254, Validation Loss: 0.6201
	--> Epoch [8/100], Loss: 0.6498, Validation Loss: 0.6146
	--> Epoch [9/100], Loss: 0.6264, Validation Loss: 0.6098
	--> Epoch [10/100], Loss: 0.6449, Validation Loss: 0.6024
	--> Epoch [11/100], Loss: 0.6025, Validation Loss: 0.5989
	--> Epoch [12/100], Loss: 0.5603, Validation Loss: 0.5933
	--> Epoch [13/100], Loss: 0.5843, Validation Loss: 0.5870
	--> Epoch [14/100], Loss: 0.5437, Validation Loss: 0.5819
	--> Epoch [15/100], Loss: 0.5340, Validation Loss: 0.5767
	--> Epoch [16/100], Loss: 0.5866, Validation Loss: 0.5714
	--> Epoch [17/100], Loss: 0.5459, Validation Loss: 0.5665
	--> Epoch [18/100], Loss: 0.5083, Validation Loss: 0.5603
	--> Epoch [19/100], Loss: 0.4816, Validation Loss: 0.5553
	--> Epoch [20/100], Loss: 0.5147, Validation Loss: 0.5500
	--> Epoch [21/100], Loss: 0.4818, Validation Loss: 0.5450
	--> Epoch [22/100], Loss: 0.5043, Validation Loss: 0.5398
	--> Epoch [23/100], Loss: 0.4501, Validation Loss: 0.5344
	--> Epoch [24/100], Loss: 0.4787, Validation Loss: 0.5311
	--> Epoch [25/100], Loss: 0.4194, Validation Loss: 0.5273
	--> Epoch [26/100], Loss: 0.4851, Validation Loss: 0.5232
	--> Epoch [27/100], Loss: 0.4286, Validation Loss: 0.5187
	--> Epoch [28/100], Loss: 0.4287, Validation Loss: 0.5130
	--> Epoch [29/100], Loss: 0.4473, Validation Loss: 0.5098
	--> Epoch [30/100], Loss: 0.4510, Validation Loss: 0.5057
	--> Epoch [31/100], Loss: 0.4418, Validation Loss: 0.5022
	--> Epoch [32/100], Loss: 0.3895, Validation Loss: 0.4995
	--> Epoch [33/100], Loss: 0.4317, Validation Loss: 0.4951
	--> Epoch [34/100], Loss: 0.3890, Validation Loss: 0.4903
	--> Epoch [35/100], Loss: 0.3571, Validation Loss: 0.4852
	--> Epoch [36/100], Loss: 0.4215, Validation Loss: 0.4812
	--> Epoch [37/100], Loss: 0.3920, Validation Loss: 0.4775
	--> Epoch [38/100], Loss: 0.3789, Validation Loss: 0.4739
	--> Epoch [39/100], Loss: 0.3809, Validation Loss: 0.4699
	--> Epoch [40/100], Loss: 0.3904, Validation Loss: 0.4659
	--> Epoch [41/100], Loss: 0.3243, Validation Loss: 0.4617
	--> Epoch [42/100], Loss: 0.3256, Validation Loss: 0.4583
	--> Epoch [43/100], Loss: 0.3565, Validation Loss: 0.4560
	--> Epoch [44/100], Loss: 0.3387, Validation Loss: 0.4533
	--> Epoch [45/100], Loss: 0.3337, Validation Loss: 0.4493
	--> Epoch [46/100], Loss: 0.3147, Validation Loss: 0.4468
	--> Epoch [47/100], Loss: 0.3159, Validation Loss: 0.4444
	--> Epoch [48/100], Loss: 0.3416, Validation Loss: 0.4405
	--> Epoch [49/100], Loss: 0.3420, Validation Loss: 0.4383
	--> Epoch [50/100], Loss: 0.2923, Validation Loss: 0.4353
	--> Epoch [51/100], Loss: 0.2885, Validation Loss: 0.4324
	--> Epoch [52/100], Loss: 0.2798, Validation Loss: 0.4289
	--> Epoch [53/100], Loss: 0.3129, Validation Loss: 0.4257
	--> Epoch [54/100], Loss: 0.2844, Validation Loss: 0.4241
	--> Epoch [55/100], Loss: 0.2717, Validation Loss: 0.4209
	--> Epoch [56/100], Loss: 0.3020, Validation Loss: 0.4194
	--> Epoch [57/100], Loss: 0.3287, Validation Loss: 0.4180
	--> Epoch [58/100], Loss: 0.3092, Validation Loss: 0.4156
	--> Epoch [59/100], Loss: 0.2591, Validation Loss: 0.4144
	--> Epoch [60/100], Loss: 0.3094, Validation Loss: 0.4102
	--> Epoch [61/100], Loss: 0.2378, Validation Loss: 0.4085
	--> Epoch [62/100], Loss: 0.2632, Validation Loss: 0.4078
	--> Epoch [63/100], Loss: 0.2076, Validation Loss: 0.4046
	--> Epoch [64/100], Loss: 0.2828, Validation Loss: 0.4024
	--> Epoch [65/100], Loss: 0.2289, Validation Loss: 0.4004
	--> Epoch [66/100], Loss: 0.2542, Validation Loss: 0.4000
	--> Epoch [67/100], Loss: 0.2628, Validation Loss: 0.3983
	--> Epoch [68/100], Loss: 0.2588, Validation Loss: 0.3958
	--> Epoch [69/100], Loss: 0.2412, Validation Loss: 0.3939
	--> Epoch [70/100], Loss: 0.2064, Validation Loss: 0.3912
	--> Epoch [71/100], Loss: 0.2267, Validation Loss: 0.3896
	--> Epoch [72/100], Loss: 0.2325, Validation Loss: 0.3874
	--> Epoch [73/100], Loss: 0.2065, Validation Loss: 0.3852
	--> Epoch [74/100], Loss: 0.2386, Validation Loss: 0.3838
	--> Epoch [75/100], Loss: 0.2638, Validation Loss: 0.3832
	--> Epoch [76/100], Loss: 0.2023, Validation Loss: 0.3812
	--> Epoch [77/100], Loss: 0.2164, Validation Loss: 0.3799
	--> Epoch [78/100], Loss: 0.2616, Validation Loss: 0.3780
	--> Epoch [79/100], Loss: 0.2591, Validation Loss: 0.3754
	--> Epoch [80/100], Loss: 0.2022, Validation Loss: 0.3716
	--> Epoch [81/100], Loss: 0.2300, Validation Loss: 0.3703
	--> Epoch [82/100], Loss: 0.2241, Validation Loss: 0.3687
	--> Epoch [83/100], Loss: 0.1637, Validation Loss: 0.3668
	--> Epoch [84/100], Loss: 0.1883, Validation Loss: 0.3654
	--> Epoch [85/100], Loss: 0.1915, Validation Loss: 0.3658
	--> Epoch [86/100], Loss: 0.1738, Validation Loss: 0.3640
	--> Epoch [87/100], Loss: 0.2179, Validation Loss: 0.3627
	--> Epoch [88/100], Loss: 0.1983, Validation Loss: 0.3616
	--> Epoch [89/100], Loss: 0.2196, Validation Loss: 0.3616
	--> Epoch [90/100], Loss: 0.1898, Validation Loss: 0.3589
	--> Epoch [91/100], Loss: 0.1926, Validation Loss: 0.3585
	--> Epoch [92/100], Loss: 0.1605, Validation Loss: 0.3561
	--> Epoch [93/100], Loss: 0.2090, Validation Loss: 0.3554
	--> Epoch [94/100], Loss: 0.1744, Validation Loss: 0.3537
	--> Epoch [95/100], Loss: 0.1598, Validation Loss: 0.3520
	--> Epoch [96/100], Loss: 0.1637, Validation Loss: 0.3518
	--> Epoch [97/100], Loss: 0.2100, Validation Loss: 0.3504
	--> Epoch [98/100], Loss: 0.1691, Validation Loss: 0.3483
	--> Epoch [99/100], Loss: 0.1866, Validation Loss: 0.3479
	--> Epoch [100/100], Loss: 0.2049, Validation Loss: 0.3460
	--> Training for Fold 3 took 0.5409183502197266 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6704, Validation Loss: 0.6516
	--> Epoch [2/100], Loss: 0.6838, Validation Loss: 0.6425
	--> Epoch [3/100], Loss: 0.6858, Validation Loss: 0.6341
	--> Epoch [4/100], Loss: 0.6410, Validation Loss: 0.6249
	--> Epoch [5/100], Loss: 0.6640, Validation Loss: 0.6179
	--> Epoch [6/100], Loss: 0.6307, Validation Loss: 0.6105
	--> Epoch [7/100], Loss: 0.6371, Validation Loss: 0.6006
	--> Epoch [8/100], Loss: 0.6123, Validation Loss: 0.5939
	--> Epoch [9/100], Loss: 0.5641, Validation Loss: 0.5848
	--> Epoch [10/100], Loss: 0.5987, Validation Loss: 0.5775
	--> Epoch [11/100], Loss: 0.5827, Validation Loss: 0.5678
	--> Epoch [12/100], Loss: 0.5742, Validation Loss: 0.5612
	--> Epoch [13/100], Loss: 0.5563, Validation Loss: 0.5528
	--> Epoch [14/100], Loss: 0.5571, Validation Loss: 0.5463
	--> Epoch [15/100], Loss: 0.5263, Validation Loss: 0.5364
	--> Epoch [16/100], Loss: 0.5278, Validation Loss: 0.5302
	--> Epoch [17/100], Loss: 0.4859, Validation Loss: 0.5209
	--> Epoch [18/100], Loss: 0.4968, Validation Loss: 0.5145
	--> Epoch [19/100], Loss: 0.4888, Validation Loss: 0.5099
	--> Epoch [20/100], Loss: 0.4721, Validation Loss: 0.5014
	--> Epoch [21/100], Loss: 0.4318, Validation Loss: 0.4955
	--> Epoch [22/100], Loss: 0.4487, Validation Loss: 0.4878
	--> Epoch [23/100], Loss: 0.4263, Validation Loss: 0.4812
	--> Epoch [24/100], Loss: 0.4379, Validation Loss: 0.4770
	--> Epoch [25/100], Loss: 0.4334, Validation Loss: 0.4712
	--> Epoch [26/100], Loss: 0.4289, Validation Loss: 0.4685
	--> Epoch [27/100], Loss: 0.4241, Validation Loss: 0.4639
	--> Epoch [28/100], Loss: 0.4292, Validation Loss: 0.4585
	--> Epoch [29/100], Loss: 0.4172, Validation Loss: 0.4536
	--> Epoch [30/100], Loss: 0.3535, Validation Loss: 0.4501
	--> Epoch [31/100], Loss: 0.3980, Validation Loss: 0.4447
	--> Epoch [32/100], Loss: 0.3870, Validation Loss: 0.4423
	--> Epoch [33/100], Loss: 0.3814, Validation Loss: 0.4387
	--> Epoch [34/100], Loss: 0.4117, Validation Loss: 0.4339
	--> Epoch [35/100], Loss: 0.3885, Validation Loss: 0.4316
	--> Epoch [36/100], Loss: 0.3373, Validation Loss: 0.4281
	--> Epoch [37/100], Loss: 0.3089, Validation Loss: 0.4246
	--> Epoch [38/100], Loss: 0.2882, Validation Loss: 0.4195
	--> Epoch [39/100], Loss: 0.3475, Validation Loss: 0.4142
	--> Epoch [40/100], Loss: 0.3419, Validation Loss: 0.4126
	--> Epoch [41/100], Loss: 0.3177, Validation Loss: 0.4100
	--> Epoch [42/100], Loss: 0.3366, Validation Loss: 0.4066
	--> Epoch [43/100], Loss: 0.3350, Validation Loss: 0.4058
	--> Epoch [44/100], Loss: 0.3210, Validation Loss: 0.4012
	--> Epoch [45/100], Loss: 0.3090, Validation Loss: 0.4001
	--> Epoch [46/100], Loss: 0.2631, Validation Loss: 0.3974
	--> Epoch [47/100], Loss: 0.2778, Validation Loss: 0.3951
	--> Epoch [48/100], Loss: 0.3129, Validation Loss: 0.3925
	--> Epoch [49/100], Loss: 0.2841, Validation Loss: 0.3898
	--> Epoch [50/100], Loss: 0.3438, Validation Loss: 0.3900
	--> Epoch [51/100], Loss: 0.2642, Validation Loss: 0.3859
	--> Epoch [52/100], Loss: 0.2614, Validation Loss: 0.3835
	--> Epoch [53/100], Loss: 0.2590, Validation Loss: 0.3823
	--> Epoch [54/100], Loss: 0.2644, Validation Loss: 0.3788
	--> Epoch [55/100], Loss: 0.3001, Validation Loss: 0.3774
	--> Epoch [56/100], Loss: 0.2962, Validation Loss: 0.3772
	--> Epoch [57/100], Loss: 0.2494, Validation Loss: 0.3759
	--> Epoch [58/100], Loss: 0.2652, Validation Loss: 0.3748
	--> Epoch [59/100], Loss: 0.2654, Validation Loss: 0.3739
	--> Epoch [60/100], Loss: 0.2239, Validation Loss: 0.3727
	--> Epoch [61/100], Loss: 0.2621, Validation Loss: 0.3704
	--> Epoch [62/100], Loss: 0.2272, Validation Loss: 0.3694
	--> Epoch [63/100], Loss: 0.2245, Validation Loss: 0.3673
	--> Epoch [64/100], Loss: 0.1964, Validation Loss: 0.3664
	--> Epoch [65/100], Loss: 0.2431, Validation Loss: 0.3646
	--> Epoch [66/100], Loss: 0.2241, Validation Loss: 0.3632
	--> Epoch [67/100], Loss: 0.2016, Validation Loss: 0.3615
	--> Epoch [68/100], Loss: 0.1861, Validation Loss: 0.3603
	--> Epoch [69/100], Loss: 0.2100, Validation Loss: 0.3584
	--> Epoch [70/100], Loss: 0.2030, Validation Loss: 0.3577
	--> Epoch [71/100], Loss: 0.2160, Validation Loss: 0.3571
	--> Epoch [72/100], Loss: 0.2330, Validation Loss: 0.3556
	--> Epoch [73/100], Loss: 0.2272, Validation Loss: 0.3541
	--> Epoch [74/100], Loss: 0.2104, Validation Loss: 0.3523
	--> Epoch [75/100], Loss: 0.2069, Validation Loss: 0.3520
	--> Epoch [76/100], Loss: 0.1989, Validation Loss: 0.3503
	--> Epoch [77/100], Loss: 0.1998, Validation Loss: 0.3491
	--> Epoch [78/100], Loss: 0.1820, Validation Loss: 0.3483
	--> Epoch [79/100], Loss: 0.1539, Validation Loss: 0.3480
	--> Epoch [80/100], Loss: 0.2071, Validation Loss: 0.3465
	--> Epoch [81/100], Loss: 0.1848, Validation Loss: 0.3444
	--> Epoch [82/100], Loss: 0.1525, Validation Loss: 0.3439
	--> Epoch [83/100], Loss: 0.2226, Validation Loss: 0.3437
	--> Epoch [84/100], Loss: 0.1852, Validation Loss: 0.3427
	--> Epoch [85/100], Loss: 0.1645, Validation Loss: 0.3412
	--> Epoch [86/100], Loss: 0.2152, Validation Loss: 0.3384
	--> Epoch [87/100], Loss: 0.1750, Validation Loss: 0.3372
	--> Epoch [88/100], Loss: 0.1936, Validation Loss: 0.3367
	--> Epoch [89/100], Loss: 0.1685, Validation Loss: 0.3355
	--> Epoch [90/100], Loss: 0.1512, Validation Loss: 0.3340
	--> Epoch [91/100], Loss: 0.2067, Validation Loss: 0.3327
	--> Epoch [92/100], Loss: 0.2041, Validation Loss: 0.3318
	--> Epoch [93/100], Loss: 0.1988, Validation Loss: 0.3315
	--> Epoch [94/100], Loss: 0.2135, Validation Loss: 0.3317
	--> Epoch [95/100], Loss: 0.1718, Validation Loss: 0.3304
	--> Epoch [96/100], Loss: 0.1857, Validation Loss: 0.3296
	--> Epoch [97/100], Loss: 0.1807, Validation Loss: 0.3289
	--> Epoch [98/100], Loss: 0.1320, Validation Loss: 0.3284
	--> Epoch [99/100], Loss: 0.1456, Validation Loss: 0.3278
	--> Epoch [100/100], Loss: 0.1493, Validation Loss: 0.3272
	--> Training for Fold 4 took 0.5531167984008789 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7139, Validation Loss: 0.6611
	--> Epoch [2/100], Loss: 0.6961, Validation Loss: 0.6527
	--> Epoch [3/100], Loss: 0.6937, Validation Loss: 0.6461
	--> Epoch [4/100], Loss: 0.6513, Validation Loss: 0.6396
	--> Epoch [5/100], Loss: 0.6256, Validation Loss: 0.6312
	--> Epoch [6/100], Loss: 0.5961, Validation Loss: 0.6235
	--> Epoch [7/100], Loss: 0.6264, Validation Loss: 0.6167
	--> Epoch [8/100], Loss: 0.5858, Validation Loss: 0.6122
	--> Epoch [9/100], Loss: 0.6027, Validation Loss: 0.6053
	--> Epoch [10/100], Loss: 0.5773, Validation Loss: 0.6000
	--> Epoch [11/100], Loss: 0.5437, Validation Loss: 0.5982
	--> Epoch [12/100], Loss: 0.5113, Validation Loss: 0.5965
	--> Epoch [13/100], Loss: 0.5492, Validation Loss: 0.5918
	--> Epoch [14/100], Loss: 0.5431, Validation Loss: 0.5877
	--> Epoch [15/100], Loss: 0.5218, Validation Loss: 0.5849
	--> Epoch [16/100], Loss: 0.4918, Validation Loss: 0.5825
	--> Epoch [17/100], Loss: 0.4823, Validation Loss: 0.5791
	--> Epoch [18/100], Loss: 0.4944, Validation Loss: 0.5760
	--> Epoch [19/100], Loss: 0.4780, Validation Loss: 0.5743
	--> Epoch [20/100], Loss: 0.4523, Validation Loss: 0.5714
	--> Epoch [21/100], Loss: 0.4815, Validation Loss: 0.5698
	--> Epoch [22/100], Loss: 0.4241, Validation Loss: 0.5670
	--> Epoch [23/100], Loss: 0.4560, Validation Loss: 0.5633
	--> Epoch [24/100], Loss: 0.4163, Validation Loss: 0.5607
	--> Epoch [25/100], Loss: 0.4254, Validation Loss: 0.5576
	--> Epoch [26/100], Loss: 0.4141, Validation Loss: 0.5569
	--> Epoch [27/100], Loss: 0.4259, Validation Loss: 0.5552
	--> Epoch [28/100], Loss: 0.3881, Validation Loss: 0.5529
	--> Epoch [29/100], Loss: 0.3703, Validation Loss: 0.5518
	--> Epoch [30/100], Loss: 0.3925, Validation Loss: 0.5501
	--> Epoch [31/100], Loss: 0.3916, Validation Loss: 0.5483
	--> Epoch [32/100], Loss: 0.4357, Validation Loss: 0.5464
	--> Epoch [33/100], Loss: 0.3701, Validation Loss: 0.5447
	--> Epoch [34/100], Loss: 0.4374, Validation Loss: 0.5438
	--> Epoch [35/100], Loss: 0.3477, Validation Loss: 0.5422
	--> Epoch [36/100], Loss: 0.3282, Validation Loss: 0.5387
	--> Epoch [37/100], Loss: 0.3222, Validation Loss: 0.5387
	--> Epoch [38/100], Loss: 0.3208, Validation Loss: 0.5377
	--> Epoch [39/100], Loss: 0.3267, Validation Loss: 0.5355
	--> Epoch [40/100], Loss: 0.3413, Validation Loss: 0.5327
	--> Epoch [41/100], Loss: 0.3687, Validation Loss: 0.5287
	--> Epoch [42/100], Loss: 0.3099, Validation Loss: 0.5270
	--> Epoch [43/100], Loss: 0.3438, Validation Loss: 0.5261
	--> Epoch [44/100], Loss: 0.3261, Validation Loss: 0.5263
	--> Epoch [45/100], Loss: 0.2985, Validation Loss: 0.5246
	--> Epoch [46/100], Loss: 0.3186, Validation Loss: 0.5233
	--> Epoch [47/100], Loss: 0.3261, Validation Loss: 0.5214
	--> Epoch [48/100], Loss: 0.2794, Validation Loss: 0.5210
	--> Epoch [49/100], Loss: 0.3230, Validation Loss: 0.5189
	--> Epoch [50/100], Loss: 0.2985, Validation Loss: 0.5166
	--> Epoch [51/100], Loss: 0.3050, Validation Loss: 0.5147
	--> Epoch [52/100], Loss: 0.2968, Validation Loss: 0.5128
	--> Epoch [53/100], Loss: 0.2315, Validation Loss: 0.5135
	--> Epoch [54/100], Loss: 0.2656, Validation Loss: 0.5119
	--> Epoch [55/100], Loss: 0.2828, Validation Loss: 0.5098
	--> Epoch [56/100], Loss: 0.3109, Validation Loss: 0.5087
	--> Epoch [57/100], Loss: 0.2721, Validation Loss: 0.5090
	--> Epoch [58/100], Loss: 0.2569, Validation Loss: 0.5080
	--> Epoch [59/100], Loss: 0.2912, Validation Loss: 0.5071
	--> Epoch [60/100], Loss: 0.2466, Validation Loss: 0.5070
	--> Epoch [61/100], Loss: 0.2890, Validation Loss: 0.5056
	--> Epoch [62/100], Loss: 0.2366, Validation Loss: 0.5055
	--> Epoch [63/100], Loss: 0.2736, Validation Loss: 0.5052
	--> Epoch [64/100], Loss: 0.2545, Validation Loss: 0.5031
	--> Epoch [65/100], Loss: 0.2564, Validation Loss: 0.5014
	--> Epoch [66/100], Loss: 0.2892, Validation Loss: 0.5008
	--> Epoch [67/100], Loss: 0.2153, Validation Loss: 0.4991
	--> Epoch [68/100], Loss: 0.2323, Validation Loss: 0.4993
	--> Epoch [69/100], Loss: 0.2454, Validation Loss: 0.4999
	--> Epoch [70/100], Loss: 0.2269, Validation Loss: 0.4993
Early stopping
	--> Training for Fold 5 took 0.30619382858276367 sec, using 70 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7167
	--> Final training Epoch [2/100], Loss: 0.7255
	--> Final training Epoch [3/100], Loss: 0.6890
	--> Final training Epoch [4/100], Loss: 0.6364
	--> Final training Epoch [5/100], Loss: 0.6475
	--> Final training Epoch [6/100], Loss: 0.6278
	--> Final training Epoch [7/100], Loss: 0.6207
	--> Final training Epoch [8/100], Loss: 0.5963
	--> Final training Epoch [9/100], Loss: 0.5564
	--> Final training Epoch [10/100], Loss: 0.5763
	--> Final training Epoch [11/100], Loss: 0.5812
	--> Final training Epoch [12/100], Loss: 0.5576
	--> Final training Epoch [13/100], Loss: 0.5446
	--> Final training Epoch [14/100], Loss: 0.5123
	--> Final training Epoch [15/100], Loss: 0.5241
	--> Final training Epoch [16/100], Loss: 0.5323
	--> Final training Epoch [17/100], Loss: 0.5121
	--> Final training Epoch [18/100], Loss: 0.4949
	--> Final training Epoch [19/100], Loss: 0.4866
	--> Final training Epoch [20/100], Loss: 0.4858
	--> Final training Epoch [21/100], Loss: 0.4952
	--> Final training Epoch [22/100], Loss: 0.4877
	--> Final training Epoch [23/100], Loss: 0.4342
	--> Final training Epoch [24/100], Loss: 0.4937
	--> Final training Epoch [25/100], Loss: 0.4630
	--> Final training Epoch [26/100], Loss: 0.4434
	--> Final training Epoch [27/100], Loss: 0.4421
	--> Final training Epoch [28/100], Loss: 0.4600
	--> Final training Epoch [29/100], Loss: 0.4374
	--> Final training Epoch [30/100], Loss: 0.4276
	--> Final training Epoch [31/100], Loss: 0.3949
	--> Final training Epoch [32/100], Loss: 0.4044
	--> Final training Epoch [33/100], Loss: 0.4056
	--> Final training Epoch [34/100], Loss: 0.3870
	--> Final training Epoch [35/100], Loss: 0.3955
	--> Final training Epoch [36/100], Loss: 0.3487
	--> Final training Epoch [37/100], Loss: 0.3792
	--> Final training Epoch [38/100], Loss: 0.3987
	--> Final training Epoch [39/100], Loss: 0.4227
	--> Final training Epoch [40/100], Loss: 0.3346
	--> Final training Epoch [41/100], Loss: 0.3260
	--> Final training Epoch [42/100], Loss: 0.3181
	--> Final training Epoch [43/100], Loss: 0.3177
	--> Final training Epoch [44/100], Loss: 0.3423
	--> Final training Epoch [45/100], Loss: 0.3177
	--> Final training Epoch [46/100], Loss: 0.3267
	--> Final training Epoch [47/100], Loss: 0.3459
	--> Final training Epoch [48/100], Loss: 0.3031
	--> Final training Epoch [49/100], Loss: 0.3197
	--> Final training Epoch [50/100], Loss: 0.3045
	--> Final training Epoch [51/100], Loss: 0.3361
	--> Final training Epoch [52/100], Loss: 0.3004
	--> Final training Epoch [53/100], Loss: 0.2769
	--> Final training Epoch [54/100], Loss: 0.3086
	--> Final training Epoch [55/100], Loss: 0.2801
	--> Final training Epoch [56/100], Loss: 0.3280
	--> Final training Epoch [57/100], Loss: 0.3340
	--> Final training Epoch [58/100], Loss: 0.2877
	--> Final training Epoch [59/100], Loss: 0.3396
	--> Final training Epoch [60/100], Loss: 0.3053
	--> Final training Epoch [61/100], Loss: 0.3437
	--> Final training Epoch [62/100], Loss: 0.2911
	--> Final training Epoch [63/100], Loss: 0.2784
	--> Final training Epoch [64/100], Loss: 0.2486
	--> Final training Epoch [65/100], Loss: 0.2763
	--> Final training Epoch [66/100], Loss: 0.2780
	--> Final training Epoch [67/100], Loss: 0.2594
	--> Final training Epoch [68/100], Loss: 0.2849
	--> Final training Epoch [69/100], Loss: 0.2621
	--> Final training Epoch [70/100], Loss: 0.2397
	--> Final training Epoch [71/100], Loss: 0.2571
	--> Final training Epoch [72/100], Loss: 0.2509
	--> Final training Epoch [73/100], Loss: 0.2447
	--> Final training Epoch [74/100], Loss: 0.2486
	--> Final training Epoch [75/100], Loss: 0.2480
	--> Final training Epoch [76/100], Loss: 0.2571
	--> Final training Epoch [77/100], Loss: 0.2301
	--> Final training Epoch [78/100], Loss: 0.2502
	--> Final training Epoch [79/100], Loss: 0.2552
	--> Final training Epoch [80/100], Loss: 0.2339
	--> Final training Epoch [81/100], Loss: 0.2079
	--> Final training Epoch [82/100], Loss: 0.2115
	--> Final training Epoch [83/100], Loss: 0.2400
	--> Final training Epoch [84/100], Loss: 0.2402
	--> Final training Epoch [85/100], Loss: 0.2720
	--> Final training Epoch [86/100], Loss: 0.2236
	--> Final training Epoch [87/100], Loss: 0.2175
	--> Final training Epoch [88/100], Loss: 0.2346
	--> Final training Epoch [89/100], Loss: 0.2159
	--> Final training Epoch [90/100], Loss: 0.2846
	--> Final training Epoch [91/100], Loss: 0.2666
	--> Final training Epoch [92/100], Loss: 0.2406
	--> Final training Epoch [93/100], Loss: 0.1998
	--> Final training Epoch [94/100], Loss: 0.2220
	--> Final training Epoch [95/100], Loss: 0.2537
	--> Final training Epoch [96/100], Loss: 0.1979
	--> Final training Epoch [97/100], Loss: 0.1899
	--> Final training Epoch [98/100], Loss: 0.2199
	--> Final training Epoch [99/100], Loss: 0.1924
	--> Final training Epoch [100/100], Loss: 0.2288

Final training took 0.3569958209991455 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.7267
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8924, Validation Loss: 0.3638,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3638

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6653, Validation Loss: 0.6948
	--> Epoch [2/100], Loss: 0.6432, Validation Loss: 0.6845
	--> Epoch [3/100], Loss: 0.6385, Validation Loss: 0.6731
	--> Epoch [4/100], Loss: 0.6010, Validation Loss: 0.6622
	--> Epoch [5/100], Loss: 0.6131, Validation Loss: 0.6516
	--> Epoch [6/100], Loss: 0.5989, Validation Loss: 0.6427
	--> Epoch [7/100], Loss: 0.5957, Validation Loss: 0.6355
	--> Epoch [8/100], Loss: 0.5696, Validation Loss: 0.6279
	--> Epoch [9/100], Loss: 0.5538, Validation Loss: 0.6201
	--> Epoch [10/100], Loss: 0.5633, Validation Loss: 0.6117
	--> Epoch [11/100], Loss: 0.5729, Validation Loss: 0.6057
	--> Epoch [12/100], Loss: 0.5434, Validation Loss: 0.5976
	--> Epoch [13/100], Loss: 0.5146, Validation Loss: 0.5911
	--> Epoch [14/100], Loss: 0.5415, Validation Loss: 0.5845
	--> Epoch [15/100], Loss: 0.5019, Validation Loss: 0.5764
	--> Epoch [16/100], Loss: 0.5231, Validation Loss: 0.5695
	--> Epoch [17/100], Loss: 0.5010, Validation Loss: 0.5631
	--> Epoch [18/100], Loss: 0.4704, Validation Loss: 0.5569
	--> Epoch [19/100], Loss: 0.5023, Validation Loss: 0.5509
	--> Epoch [20/100], Loss: 0.4769, Validation Loss: 0.5448
	--> Epoch [21/100], Loss: 0.4674, Validation Loss: 0.5415
	--> Epoch [22/100], Loss: 0.4446, Validation Loss: 0.5368
	--> Epoch [23/100], Loss: 0.4594, Validation Loss: 0.5326
	--> Epoch [24/100], Loss: 0.4531, Validation Loss: 0.5256
	--> Epoch [25/100], Loss: 0.4372, Validation Loss: 0.5200
	--> Epoch [26/100], Loss: 0.4375, Validation Loss: 0.5138
	--> Epoch [27/100], Loss: 0.4226, Validation Loss: 0.5093
	--> Epoch [28/100], Loss: 0.4071, Validation Loss: 0.5026
	--> Epoch [29/100], Loss: 0.3679, Validation Loss: 0.4984
	--> Epoch [30/100], Loss: 0.3759, Validation Loss: 0.4939
	--> Epoch [31/100], Loss: 0.3923, Validation Loss: 0.4934
	--> Epoch [32/100], Loss: 0.4022, Validation Loss: 0.4890
	--> Epoch [33/100], Loss: 0.3794, Validation Loss: 0.4852
	--> Epoch [34/100], Loss: 0.3623, Validation Loss: 0.4823
	--> Epoch [35/100], Loss: 0.3756, Validation Loss: 0.4780
	--> Epoch [36/100], Loss: 0.3661, Validation Loss: 0.4751
	--> Epoch [37/100], Loss: 0.3331, Validation Loss: 0.4705
	--> Epoch [38/100], Loss: 0.3887, Validation Loss: 0.4675
	--> Epoch [39/100], Loss: 0.3394, Validation Loss: 0.4635
	--> Epoch [40/100], Loss: 0.3505, Validation Loss: 0.4621
	--> Epoch [41/100], Loss: 0.3192, Validation Loss: 0.4569
	--> Epoch [42/100], Loss: 0.2961, Validation Loss: 0.4531
	--> Epoch [43/100], Loss: 0.3155, Validation Loss: 0.4506
	--> Epoch [44/100], Loss: 0.3054, Validation Loss: 0.4463
	--> Epoch [45/100], Loss: 0.3351, Validation Loss: 0.4431
	--> Epoch [46/100], Loss: 0.3030, Validation Loss: 0.4416
	--> Epoch [47/100], Loss: 0.3169, Validation Loss: 0.4389
	--> Epoch [48/100], Loss: 0.2771, Validation Loss: 0.4354
	--> Epoch [49/100], Loss: 0.3120, Validation Loss: 0.4322
	--> Epoch [50/100], Loss: 0.3246, Validation Loss: 0.4322
	--> Epoch [51/100], Loss: 0.2617, Validation Loss: 0.4290
	--> Epoch [52/100], Loss: 0.2858, Validation Loss: 0.4261
	--> Epoch [53/100], Loss: 0.3257, Validation Loss: 0.4225
	--> Epoch [54/100], Loss: 0.3140, Validation Loss: 0.4196
	--> Epoch [55/100], Loss: 0.3010, Validation Loss: 0.4164
	--> Epoch [56/100], Loss: 0.2966, Validation Loss: 0.4143
	--> Epoch [57/100], Loss: 0.2606, Validation Loss: 0.4112
	--> Epoch [58/100], Loss: 0.2506, Validation Loss: 0.4089
	--> Epoch [59/100], Loss: 0.2789, Validation Loss: 0.4065
	--> Epoch [60/100], Loss: 0.2505, Validation Loss: 0.4059
	--> Epoch [61/100], Loss: 0.2529, Validation Loss: 0.4048
	--> Epoch [62/100], Loss: 0.2063, Validation Loss: 0.4028
	--> Epoch [63/100], Loss: 0.2720, Validation Loss: 0.4002
	--> Epoch [64/100], Loss: 0.2371, Validation Loss: 0.3999
	--> Epoch [65/100], Loss: 0.2608, Validation Loss: 0.3978
	--> Epoch [66/100], Loss: 0.2483, Validation Loss: 0.3933
	--> Epoch [67/100], Loss: 0.1885, Validation Loss: 0.3917
	--> Epoch [68/100], Loss: 0.2429, Validation Loss: 0.3900
	--> Epoch [69/100], Loss: 0.1882, Validation Loss: 0.3879
	--> Epoch [70/100], Loss: 0.2251, Validation Loss: 0.3868
	--> Epoch [71/100], Loss: 0.2585, Validation Loss: 0.3856
	--> Epoch [72/100], Loss: 0.1853, Validation Loss: 0.3843
	--> Epoch [73/100], Loss: 0.1972, Validation Loss: 0.3843
	--> Epoch [74/100], Loss: 0.2469, Validation Loss: 0.3815
	--> Epoch [75/100], Loss: 0.2166, Validation Loss: 0.3814
	--> Epoch [76/100], Loss: 0.1934, Validation Loss: 0.3808
	--> Epoch [77/100], Loss: 0.1876, Validation Loss: 0.3798
	--> Epoch [78/100], Loss: 0.1894, Validation Loss: 0.3772
	--> Epoch [79/100], Loss: 0.1978, Validation Loss: 0.3764
	--> Epoch [80/100], Loss: 0.2152, Validation Loss: 0.3742
	--> Epoch [81/100], Loss: 0.2236, Validation Loss: 0.3718
	--> Epoch [82/100], Loss: 0.2032, Validation Loss: 0.3719
	--> Epoch [83/100], Loss: 0.2283, Validation Loss: 0.3704
	--> Epoch [84/100], Loss: 0.2398, Validation Loss: 0.3683
	--> Epoch [85/100], Loss: 0.1952, Validation Loss: 0.3679
	--> Epoch [86/100], Loss: 0.1961, Validation Loss: 0.3688
	--> Epoch [87/100], Loss: 0.2293, Validation Loss: 0.3664
	--> Epoch [88/100], Loss: 0.2067, Validation Loss: 0.3663
	--> Epoch [89/100], Loss: 0.2287, Validation Loss: 0.3666
	--> Epoch [90/100], Loss: 0.1291, Validation Loss: 0.3660
	--> Epoch [91/100], Loss: 0.1980, Validation Loss: 0.3657
	--> Epoch [92/100], Loss: 0.1953, Validation Loss: 0.3639
	--> Epoch [93/100], Loss: 0.1711, Validation Loss: 0.3631
	--> Epoch [94/100], Loss: 0.1614, Validation Loss: 0.3607
	--> Epoch [95/100], Loss: 0.1468, Validation Loss: 0.3600
	--> Epoch [96/100], Loss: 0.1597, Validation Loss: 0.3579
	--> Epoch [97/100], Loss: 0.1930, Validation Loss: 0.3555
	--> Epoch [98/100], Loss: 0.1521, Validation Loss: 0.3544
	--> Epoch [99/100], Loss: 0.1528, Validation Loss: 0.3542
	--> Epoch [100/100], Loss: 0.1609, Validation Loss: 0.3529
	--> Training for Fold 1 took 0.38420748710632324 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7342, Validation Loss: 0.7721
	--> Epoch [2/100], Loss: 0.7049, Validation Loss: 0.7588
	--> Epoch [3/100], Loss: 0.7108, Validation Loss: 0.7420
	--> Epoch [4/100], Loss: 0.6988, Validation Loss: 0.7260
	--> Epoch [5/100], Loss: 0.6842, Validation Loss: 0.7113
	--> Epoch [6/100], Loss: 0.6704, Validation Loss: 0.6921
	--> Epoch [7/100], Loss: 0.6619, Validation Loss: 0.6764
	--> Epoch [8/100], Loss: 0.6483, Validation Loss: 0.6602
	--> Epoch [9/100], Loss: 0.6446, Validation Loss: 0.6500
	--> Epoch [10/100], Loss: 0.6246, Validation Loss: 0.6358
	--> Epoch [11/100], Loss: 0.6381, Validation Loss: 0.6232
	--> Epoch [12/100], Loss: 0.5923, Validation Loss: 0.6094
	--> Epoch [13/100], Loss: 0.6104, Validation Loss: 0.5948
	--> Epoch [14/100], Loss: 0.5741, Validation Loss: 0.5804
	--> Epoch [15/100], Loss: 0.5893, Validation Loss: 0.5686
	--> Epoch [16/100], Loss: 0.5626, Validation Loss: 0.5580
	--> Epoch [17/100], Loss: 0.5467, Validation Loss: 0.5469
	--> Epoch [18/100], Loss: 0.5234, Validation Loss: 0.5367
	--> Epoch [19/100], Loss: 0.5501, Validation Loss: 0.5277
	--> Epoch [20/100], Loss: 0.5564, Validation Loss: 0.5162
	--> Epoch [21/100], Loss: 0.5134, Validation Loss: 0.5074
	--> Epoch [22/100], Loss: 0.4849, Validation Loss: 0.4964
	--> Epoch [23/100], Loss: 0.5013, Validation Loss: 0.4891
	--> Epoch [24/100], Loss: 0.4764, Validation Loss: 0.4809
	--> Epoch [25/100], Loss: 0.4803, Validation Loss: 0.4717
	--> Epoch [26/100], Loss: 0.5032, Validation Loss: 0.4655
	--> Epoch [27/100], Loss: 0.4625, Validation Loss: 0.4585
	--> Epoch [28/100], Loss: 0.4446, Validation Loss: 0.4513
	--> Epoch [29/100], Loss: 0.4731, Validation Loss: 0.4446
	--> Epoch [30/100], Loss: 0.4624, Validation Loss: 0.4383
	--> Epoch [31/100], Loss: 0.4258, Validation Loss: 0.4320
	--> Epoch [32/100], Loss: 0.4367, Validation Loss: 0.4260
	--> Epoch [33/100], Loss: 0.4010, Validation Loss: 0.4200
	--> Epoch [34/100], Loss: 0.4096, Validation Loss: 0.4149
	--> Epoch [35/100], Loss: 0.4055, Validation Loss: 0.4108
	--> Epoch [36/100], Loss: 0.4424, Validation Loss: 0.4065
	--> Epoch [37/100], Loss: 0.4111, Validation Loss: 0.4008
	--> Epoch [38/100], Loss: 0.4127, Validation Loss: 0.3949
	--> Epoch [39/100], Loss: 0.3664, Validation Loss: 0.3895
	--> Epoch [40/100], Loss: 0.4234, Validation Loss: 0.3837
	--> Epoch [41/100], Loss: 0.3964, Validation Loss: 0.3781
	--> Epoch [42/100], Loss: 0.3764, Validation Loss: 0.3729
	--> Epoch [43/100], Loss: 0.3635, Validation Loss: 0.3697
	--> Epoch [44/100], Loss: 0.3354, Validation Loss: 0.3662
	--> Epoch [45/100], Loss: 0.3165, Validation Loss: 0.3614
	--> Epoch [46/100], Loss: 0.3628, Validation Loss: 0.3575
	--> Epoch [47/100], Loss: 0.3221, Validation Loss: 0.3535
	--> Epoch [48/100], Loss: 0.3363, Validation Loss: 0.3514
	--> Epoch [49/100], Loss: 0.3359, Validation Loss: 0.3474
	--> Epoch [50/100], Loss: 0.3121, Validation Loss: 0.3426
	--> Epoch [51/100], Loss: 0.3340, Validation Loss: 0.3395
	--> Epoch [52/100], Loss: 0.3442, Validation Loss: 0.3365
	--> Epoch [53/100], Loss: 0.3129, Validation Loss: 0.3342
	--> Epoch [54/100], Loss: 0.3094, Validation Loss: 0.3302
	--> Epoch [55/100], Loss: 0.2949, Validation Loss: 0.3271
	--> Epoch [56/100], Loss: 0.2748, Validation Loss: 0.3242
	--> Epoch [57/100], Loss: 0.2621, Validation Loss: 0.3216
	--> Epoch [58/100], Loss: 0.2888, Validation Loss: 0.3167
	--> Epoch [59/100], Loss: 0.2641, Validation Loss: 0.3144
	--> Epoch [60/100], Loss: 0.3069, Validation Loss: 0.3099
	--> Epoch [61/100], Loss: 0.2701, Validation Loss: 0.3068
	--> Epoch [62/100], Loss: 0.2169, Validation Loss: 0.3052
	--> Epoch [63/100], Loss: 0.2846, Validation Loss: 0.3011
	--> Epoch [64/100], Loss: 0.2625, Validation Loss: 0.2991
	--> Epoch [65/100], Loss: 0.2475, Validation Loss: 0.2965
	--> Epoch [66/100], Loss: 0.2452, Validation Loss: 0.2936
	--> Epoch [67/100], Loss: 0.2938, Validation Loss: 0.2923
	--> Epoch [68/100], Loss: 0.2841, Validation Loss: 0.2905
	--> Epoch [69/100], Loss: 0.2453, Validation Loss: 0.2888
	--> Epoch [70/100], Loss: 0.2393, Validation Loss: 0.2867
	--> Epoch [71/100], Loss: 0.2379, Validation Loss: 0.2857
	--> Epoch [72/100], Loss: 0.2746, Validation Loss: 0.2836
	--> Epoch [73/100], Loss: 0.2117, Validation Loss: 0.2822
	--> Epoch [74/100], Loss: 0.2301, Validation Loss: 0.2805
	--> Epoch [75/100], Loss: 0.2319, Validation Loss: 0.2791
	--> Epoch [76/100], Loss: 0.2189, Validation Loss: 0.2774
	--> Epoch [77/100], Loss: 0.2015, Validation Loss: 0.2747
	--> Epoch [78/100], Loss: 0.2358, Validation Loss: 0.2745
	--> Epoch [79/100], Loss: 0.2235, Validation Loss: 0.2727
	--> Epoch [80/100], Loss: 0.2211, Validation Loss: 0.2714
	--> Epoch [81/100], Loss: 0.2398, Validation Loss: 0.2689
	--> Epoch [82/100], Loss: 0.2397, Validation Loss: 0.2666
	--> Epoch [83/100], Loss: 0.2046, Validation Loss: 0.2659
	--> Epoch [84/100], Loss: 0.2415, Validation Loss: 0.2646
	--> Epoch [85/100], Loss: 0.2370, Validation Loss: 0.2623
	--> Epoch [86/100], Loss: 0.2057, Validation Loss: 0.2638
	--> Epoch [87/100], Loss: 0.2362, Validation Loss: 0.2637
	--> Epoch [88/100], Loss: 0.2039, Validation Loss: 0.2610
	--> Epoch [89/100], Loss: 0.2177, Validation Loss: 0.2599
	--> Epoch [90/100], Loss: 0.1850, Validation Loss: 0.2588
	--> Epoch [91/100], Loss: 0.1914, Validation Loss: 0.2581
	--> Epoch [92/100], Loss: 0.2044, Validation Loss: 0.2572
	--> Epoch [93/100], Loss: 0.2227, Validation Loss: 0.2563
	--> Epoch [94/100], Loss: 0.1781, Validation Loss: 0.2554
	--> Epoch [95/100], Loss: 0.1689, Validation Loss: 0.2549
	--> Epoch [96/100], Loss: 0.1719, Validation Loss: 0.2545
	--> Epoch [97/100], Loss: 0.1833, Validation Loss: 0.2520
	--> Epoch [98/100], Loss: 0.1571, Validation Loss: 0.2512
	--> Epoch [99/100], Loss: 0.2072, Validation Loss: 0.2510
	--> Epoch [100/100], Loss: 0.1732, Validation Loss: 0.2502
	--> Training for Fold 2 took 0.3882603645324707 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7054, Validation Loss: 0.6865
	--> Epoch [2/100], Loss: 0.7010, Validation Loss: 0.6783
	--> Epoch [3/100], Loss: 0.7181, Validation Loss: 0.6710
	--> Epoch [4/100], Loss: 0.6934, Validation Loss: 0.6646
	--> Epoch [5/100], Loss: 0.6479, Validation Loss: 0.6565
	--> Epoch [6/100], Loss: 0.6671, Validation Loss: 0.6506
	--> Epoch [7/100], Loss: 0.6676, Validation Loss: 0.6451
	--> Epoch [8/100], Loss: 0.6360, Validation Loss: 0.6361
	--> Epoch [9/100], Loss: 0.6441, Validation Loss: 0.6321
	--> Epoch [10/100], Loss: 0.6225, Validation Loss: 0.6283
	--> Epoch [11/100], Loss: 0.6121, Validation Loss: 0.6218
	--> Epoch [12/100], Loss: 0.5878, Validation Loss: 0.6147
	--> Epoch [13/100], Loss: 0.5605, Validation Loss: 0.6118
	--> Epoch [14/100], Loss: 0.5586, Validation Loss: 0.6071
	--> Epoch [15/100], Loss: 0.5479, Validation Loss: 0.6024
	--> Epoch [16/100], Loss: 0.5561, Validation Loss: 0.5950
	--> Epoch [17/100], Loss: 0.5394, Validation Loss: 0.5901
	--> Epoch [18/100], Loss: 0.5482, Validation Loss: 0.5845
	--> Epoch [19/100], Loss: 0.5178, Validation Loss: 0.5810
	--> Epoch [20/100], Loss: 0.5117, Validation Loss: 0.5761
	--> Epoch [21/100], Loss: 0.5324, Validation Loss: 0.5685
	--> Epoch [22/100], Loss: 0.5191, Validation Loss: 0.5664
	--> Epoch [23/100], Loss: 0.4780, Validation Loss: 0.5614
	--> Epoch [24/100], Loss: 0.4714, Validation Loss: 0.5565
	--> Epoch [25/100], Loss: 0.5051, Validation Loss: 0.5538
	--> Epoch [26/100], Loss: 0.4591, Validation Loss: 0.5483
	--> Epoch [27/100], Loss: 0.5189, Validation Loss: 0.5453
	--> Epoch [28/100], Loss: 0.4572, Validation Loss: 0.5415
	--> Epoch [29/100], Loss: 0.4486, Validation Loss: 0.5385
	--> Epoch [30/100], Loss: 0.4465, Validation Loss: 0.5341
	--> Epoch [31/100], Loss: 0.4236, Validation Loss: 0.5316
	--> Epoch [32/100], Loss: 0.4495, Validation Loss: 0.5292
	--> Epoch [33/100], Loss: 0.3948, Validation Loss: 0.5254
	--> Epoch [34/100], Loss: 0.4163, Validation Loss: 0.5192
	--> Epoch [35/100], Loss: 0.4121, Validation Loss: 0.5156
	--> Epoch [36/100], Loss: 0.4458, Validation Loss: 0.5137
	--> Epoch [37/100], Loss: 0.3801, Validation Loss: 0.5095
	--> Epoch [38/100], Loss: 0.4131, Validation Loss: 0.5081
	--> Epoch [39/100], Loss: 0.4250, Validation Loss: 0.5053
	--> Epoch [40/100], Loss: 0.3782, Validation Loss: 0.5026
	--> Epoch [41/100], Loss: 0.3886, Validation Loss: 0.5002
	--> Epoch [42/100], Loss: 0.3465, Validation Loss: 0.4955
	--> Epoch [43/100], Loss: 0.4011, Validation Loss: 0.4916
	--> Epoch [44/100], Loss: 0.3878, Validation Loss: 0.4865
	--> Epoch [45/100], Loss: 0.3491, Validation Loss: 0.4833
	--> Epoch [46/100], Loss: 0.3647, Validation Loss: 0.4804
	--> Epoch [47/100], Loss: 0.3940, Validation Loss: 0.4784
	--> Epoch [48/100], Loss: 0.3581, Validation Loss: 0.4735
	--> Epoch [49/100], Loss: 0.3499, Validation Loss: 0.4713
	--> Epoch [50/100], Loss: 0.3517, Validation Loss: 0.4677
	--> Epoch [51/100], Loss: 0.3708, Validation Loss: 0.4644
	--> Epoch [52/100], Loss: 0.3309, Validation Loss: 0.4620
	--> Epoch [53/100], Loss: 0.3348, Validation Loss: 0.4590
	--> Epoch [54/100], Loss: 0.3821, Validation Loss: 0.4566
	--> Epoch [55/100], Loss: 0.3332, Validation Loss: 0.4524
	--> Epoch [56/100], Loss: 0.3522, Validation Loss: 0.4503
	--> Epoch [57/100], Loss: 0.3121, Validation Loss: 0.4487
	--> Epoch [58/100], Loss: 0.3361, Validation Loss: 0.4482
	--> Epoch [59/100], Loss: 0.3358, Validation Loss: 0.4451
	--> Epoch [60/100], Loss: 0.3358, Validation Loss: 0.4405
	--> Epoch [61/100], Loss: 0.3288, Validation Loss: 0.4373
	--> Epoch [62/100], Loss: 0.3202, Validation Loss: 0.4350
	--> Epoch [63/100], Loss: 0.2825, Validation Loss: 0.4323
	--> Epoch [64/100], Loss: 0.2674, Validation Loss: 0.4294
	--> Epoch [65/100], Loss: 0.3521, Validation Loss: 0.4261
	--> Epoch [66/100], Loss: 0.2891, Validation Loss: 0.4234
	--> Epoch [67/100], Loss: 0.2887, Validation Loss: 0.4215
	--> Epoch [68/100], Loss: 0.2965, Validation Loss: 0.4189
	--> Epoch [69/100], Loss: 0.2740, Validation Loss: 0.4166
	--> Epoch [70/100], Loss: 0.2540, Validation Loss: 0.4135
	--> Epoch [71/100], Loss: 0.3094, Validation Loss: 0.4122
	--> Epoch [72/100], Loss: 0.2958, Validation Loss: 0.4105
	--> Epoch [73/100], Loss: 0.2691, Validation Loss: 0.4075
	--> Epoch [74/100], Loss: 0.2589, Validation Loss: 0.4057
	--> Epoch [75/100], Loss: 0.2717, Validation Loss: 0.4028
	--> Epoch [76/100], Loss: 0.2729, Validation Loss: 0.4002
	--> Epoch [77/100], Loss: 0.2772, Validation Loss: 0.3984
	--> Epoch [78/100], Loss: 0.2799, Validation Loss: 0.3966
	--> Epoch [79/100], Loss: 0.2698, Validation Loss: 0.3943
	--> Epoch [80/100], Loss: 0.2630, Validation Loss: 0.3916
	--> Epoch [81/100], Loss: 0.2939, Validation Loss: 0.3906
	--> Epoch [82/100], Loss: 0.2378, Validation Loss: 0.3875
	--> Epoch [83/100], Loss: 0.2675, Validation Loss: 0.3856
	--> Epoch [84/100], Loss: 0.2544, Validation Loss: 0.3847
	--> Epoch [85/100], Loss: 0.2682, Validation Loss: 0.3823
	--> Epoch [86/100], Loss: 0.2314, Validation Loss: 0.3807
	--> Epoch [87/100], Loss: 0.2749, Validation Loss: 0.3793
	--> Epoch [88/100], Loss: 0.2096, Validation Loss: 0.3778
	--> Epoch [89/100], Loss: 0.2607, Validation Loss: 0.3768
	--> Epoch [90/100], Loss: 0.2237, Validation Loss: 0.3744
	--> Epoch [91/100], Loss: 0.2688, Validation Loss: 0.3731
	--> Epoch [92/100], Loss: 0.2804, Validation Loss: 0.3722
	--> Epoch [93/100], Loss: 0.2893, Validation Loss: 0.3709
	--> Epoch [94/100], Loss: 0.2518, Validation Loss: 0.3686
	--> Epoch [95/100], Loss: 0.2381, Validation Loss: 0.3677
	--> Epoch [96/100], Loss: 0.2664, Validation Loss: 0.3675
	--> Epoch [97/100], Loss: 0.2660, Validation Loss: 0.3662
	--> Epoch [98/100], Loss: 0.2753, Validation Loss: 0.3644
	--> Epoch [99/100], Loss: 0.2146, Validation Loss: 0.3631
	--> Epoch [100/100], Loss: 0.2501, Validation Loss: 0.3618
	--> Training for Fold 3 took 0.3828706741333008 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6886, Validation Loss: 0.7804
	--> Epoch [2/100], Loss: 0.6769, Validation Loss: 0.7693
	--> Epoch [3/100], Loss: 0.6270, Validation Loss: 0.7601
	--> Epoch [4/100], Loss: 0.6284, Validation Loss: 0.7501
	--> Epoch [5/100], Loss: 0.6182, Validation Loss: 0.7416
	--> Epoch [6/100], Loss: 0.6236, Validation Loss: 0.7333
	--> Epoch [7/100], Loss: 0.5947, Validation Loss: 0.7234
	--> Epoch [8/100], Loss: 0.6206, Validation Loss: 0.7139
	--> Epoch [9/100], Loss: 0.5721, Validation Loss: 0.7043
	--> Epoch [10/100], Loss: 0.5708, Validation Loss: 0.6977
	--> Epoch [11/100], Loss: 0.5867, Validation Loss: 0.6882
	--> Epoch [12/100], Loss: 0.5516, Validation Loss: 0.6775
	--> Epoch [13/100], Loss: 0.5515, Validation Loss: 0.6686
	--> Epoch [14/100], Loss: 0.5446, Validation Loss: 0.6635
	--> Epoch [15/100], Loss: 0.5363, Validation Loss: 0.6560
	--> Epoch [16/100], Loss: 0.5191, Validation Loss: 0.6503
	--> Epoch [17/100], Loss: 0.5089, Validation Loss: 0.6441
	--> Epoch [18/100], Loss: 0.4866, Validation Loss: 0.6399
	--> Epoch [19/100], Loss: 0.5003, Validation Loss: 0.6345
	--> Epoch [20/100], Loss: 0.4979, Validation Loss: 0.6311
	--> Epoch [21/100], Loss: 0.4636, Validation Loss: 0.6258
	--> Epoch [22/100], Loss: 0.4487, Validation Loss: 0.6179
	--> Epoch [23/100], Loss: 0.4657, Validation Loss: 0.6129
	--> Epoch [24/100], Loss: 0.4479, Validation Loss: 0.6074
	--> Epoch [25/100], Loss: 0.4425, Validation Loss: 0.6040
	--> Epoch [26/100], Loss: 0.4567, Validation Loss: 0.5991
	--> Epoch [27/100], Loss: 0.4228, Validation Loss: 0.5929
	--> Epoch [28/100], Loss: 0.4177, Validation Loss: 0.5902
	--> Epoch [29/100], Loss: 0.4216, Validation Loss: 0.5820
	--> Epoch [30/100], Loss: 0.3992, Validation Loss: 0.5771
	--> Epoch [31/100], Loss: 0.4350, Validation Loss: 0.5740
	--> Epoch [32/100], Loss: 0.4002, Validation Loss: 0.5695
	--> Epoch [33/100], Loss: 0.4250, Validation Loss: 0.5652
	--> Epoch [34/100], Loss: 0.4249, Validation Loss: 0.5621
	--> Epoch [35/100], Loss: 0.3951, Validation Loss: 0.5589
	--> Epoch [36/100], Loss: 0.3538, Validation Loss: 0.5525
	--> Epoch [37/100], Loss: 0.4042, Validation Loss: 0.5488
	--> Epoch [38/100], Loss: 0.3612, Validation Loss: 0.5431
	--> Epoch [39/100], Loss: 0.3360, Validation Loss: 0.5374
	--> Epoch [40/100], Loss: 0.3068, Validation Loss: 0.5306
	--> Epoch [41/100], Loss: 0.3410, Validation Loss: 0.5274
	--> Epoch [42/100], Loss: 0.3716, Validation Loss: 0.5243
	--> Epoch [43/100], Loss: 0.3576, Validation Loss: 0.5217
	--> Epoch [44/100], Loss: 0.3396, Validation Loss: 0.5182
	--> Epoch [45/100], Loss: 0.3517, Validation Loss: 0.5155
	--> Epoch [46/100], Loss: 0.3527, Validation Loss: 0.5141
	--> Epoch [47/100], Loss: 0.2939, Validation Loss: 0.5102
	--> Epoch [48/100], Loss: 0.3099, Validation Loss: 0.5084
	--> Epoch [49/100], Loss: 0.3250, Validation Loss: 0.5041
	--> Epoch [50/100], Loss: 0.2996, Validation Loss: 0.5021
	--> Epoch [51/100], Loss: 0.3506, Validation Loss: 0.4988
	--> Epoch [52/100], Loss: 0.3683, Validation Loss: 0.4984
	--> Epoch [53/100], Loss: 0.3235, Validation Loss: 0.4929
	--> Epoch [54/100], Loss: 0.2841, Validation Loss: 0.4905
	--> Epoch [55/100], Loss: 0.2933, Validation Loss: 0.4864
	--> Epoch [56/100], Loss: 0.3306, Validation Loss: 0.4842
	--> Epoch [57/100], Loss: 0.2671, Validation Loss: 0.4825
	--> Epoch [58/100], Loss: 0.2802, Validation Loss: 0.4786
	--> Epoch [59/100], Loss: 0.3151, Validation Loss: 0.4770
	--> Epoch [60/100], Loss: 0.2869, Validation Loss: 0.4749
	--> Epoch [61/100], Loss: 0.3393, Validation Loss: 0.4726
	--> Epoch [62/100], Loss: 0.2622, Validation Loss: 0.4718
	--> Epoch [63/100], Loss: 0.3174, Validation Loss: 0.4678
	--> Epoch [64/100], Loss: 0.2704, Validation Loss: 0.4655
	--> Epoch [65/100], Loss: 0.2913, Validation Loss: 0.4630
	--> Epoch [66/100], Loss: 0.2185, Validation Loss: 0.4597
	--> Epoch [67/100], Loss: 0.2527, Validation Loss: 0.4555
	--> Epoch [68/100], Loss: 0.2580, Validation Loss: 0.4560
	--> Epoch [69/100], Loss: 0.2770, Validation Loss: 0.4545
	--> Epoch [70/100], Loss: 0.2843, Validation Loss: 0.4521
	--> Epoch [71/100], Loss: 0.2410, Validation Loss: 0.4486
	--> Epoch [72/100], Loss: 0.2496, Validation Loss: 0.4475
	--> Epoch [73/100], Loss: 0.2587, Validation Loss: 0.4475
	--> Epoch [74/100], Loss: 0.2484, Validation Loss: 0.4444
	--> Epoch [75/100], Loss: 0.2470, Validation Loss: 0.4426
	--> Epoch [76/100], Loss: 0.2045, Validation Loss: 0.4398
	--> Epoch [77/100], Loss: 0.2422, Validation Loss: 0.4385
	--> Epoch [78/100], Loss: 0.2358, Validation Loss: 0.4367
	--> Epoch [79/100], Loss: 0.2661, Validation Loss: 0.4351
	--> Epoch [80/100], Loss: 0.1944, Validation Loss: 0.4339
	--> Epoch [81/100], Loss: 0.2078, Validation Loss: 0.4333
	--> Epoch [82/100], Loss: 0.2034, Validation Loss: 0.4316
	--> Epoch [83/100], Loss: 0.2241, Validation Loss: 0.4315
	--> Epoch [84/100], Loss: 0.2384, Validation Loss: 0.4301
	--> Epoch [85/100], Loss: 0.2244, Validation Loss: 0.4272
	--> Epoch [86/100], Loss: 0.2168, Validation Loss: 0.4255
	--> Epoch [87/100], Loss: 0.2337, Validation Loss: 0.4224
	--> Epoch [88/100], Loss: 0.2843, Validation Loss: 0.4224
	--> Epoch [89/100], Loss: 0.2216, Validation Loss: 0.4197
	--> Epoch [90/100], Loss: 0.2152, Validation Loss: 0.4176
	--> Epoch [91/100], Loss: 0.2213, Validation Loss: 0.4170
	--> Epoch [92/100], Loss: 0.2518, Validation Loss: 0.4167
	--> Epoch [93/100], Loss: 0.2119, Validation Loss: 0.4155
	--> Epoch [94/100], Loss: 0.2018, Validation Loss: 0.4150
	--> Epoch [95/100], Loss: 0.2467, Validation Loss: 0.4144
	--> Epoch [96/100], Loss: 0.2120, Validation Loss: 0.4131
	--> Epoch [97/100], Loss: 0.2164, Validation Loss: 0.4130
	--> Epoch [98/100], Loss: 0.2339, Validation Loss: 0.4126
	--> Epoch [99/100], Loss: 0.1996, Validation Loss: 0.4117
	--> Epoch [100/100], Loss: 0.2065, Validation Loss: 0.4105
	--> Training for Fold 4 took 0.3904306888580322 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7555, Validation Loss: 0.6597
	--> Epoch [2/100], Loss: 0.7658, Validation Loss: 0.6541
	--> Epoch [3/100], Loss: 0.7499, Validation Loss: 0.6489
	--> Epoch [4/100], Loss: 0.7397, Validation Loss: 0.6441
	--> Epoch [5/100], Loss: 0.7011, Validation Loss: 0.6402
	--> Epoch [6/100], Loss: 0.6783, Validation Loss: 0.6363
	--> Epoch [7/100], Loss: 0.6996, Validation Loss: 0.6348
	--> Epoch [8/100], Loss: 0.6651, Validation Loss: 0.6312
	--> Epoch [9/100], Loss: 0.6508, Validation Loss: 0.6258
	--> Epoch [10/100], Loss: 0.6685, Validation Loss: 0.6226
	--> Epoch [11/100], Loss: 0.6546, Validation Loss: 0.6183
	--> Epoch [12/100], Loss: 0.6023, Validation Loss: 0.6154
	--> Epoch [13/100], Loss: 0.6197, Validation Loss: 0.6147
	--> Epoch [14/100], Loss: 0.6144, Validation Loss: 0.6098
	--> Epoch [15/100], Loss: 0.5791, Validation Loss: 0.6076
	--> Epoch [16/100], Loss: 0.5778, Validation Loss: 0.6048
	--> Epoch [17/100], Loss: 0.5791, Validation Loss: 0.6018
	--> Epoch [18/100], Loss: 0.5456, Validation Loss: 0.6003
	--> Epoch [19/100], Loss: 0.5570, Validation Loss: 0.5980
	--> Epoch [20/100], Loss: 0.5018, Validation Loss: 0.5956
	--> Epoch [21/100], Loss: 0.5118, Validation Loss: 0.5915
	--> Epoch [22/100], Loss: 0.5076, Validation Loss: 0.5893
	--> Epoch [23/100], Loss: 0.4956, Validation Loss: 0.5859
	--> Epoch [24/100], Loss: 0.4936, Validation Loss: 0.5833
	--> Epoch [25/100], Loss: 0.4715, Validation Loss: 0.5805
	--> Epoch [26/100], Loss: 0.4883, Validation Loss: 0.5779
	--> Epoch [27/100], Loss: 0.4591, Validation Loss: 0.5764
	--> Epoch [28/100], Loss: 0.4583, Validation Loss: 0.5756
	--> Epoch [29/100], Loss: 0.4513, Validation Loss: 0.5733
	--> Epoch [30/100], Loss: 0.4419, Validation Loss: 0.5717
	--> Epoch [31/100], Loss: 0.4404, Validation Loss: 0.5697
	--> Epoch [32/100], Loss: 0.4364, Validation Loss: 0.5668
	--> Epoch [33/100], Loss: 0.4575, Validation Loss: 0.5641
	--> Epoch [34/100], Loss: 0.3908, Validation Loss: 0.5626
	--> Epoch [35/100], Loss: 0.4100, Validation Loss: 0.5608
	--> Epoch [36/100], Loss: 0.3792, Validation Loss: 0.5582
	--> Epoch [37/100], Loss: 0.3724, Validation Loss: 0.5568
	--> Epoch [38/100], Loss: 0.3619, Validation Loss: 0.5547
	--> Epoch [39/100], Loss: 0.3801, Validation Loss: 0.5510
	--> Epoch [40/100], Loss: 0.3599, Validation Loss: 0.5487
	--> Epoch [41/100], Loss: 0.4135, Validation Loss: 0.5466
	--> Epoch [42/100], Loss: 0.3657, Validation Loss: 0.5438
	--> Epoch [43/100], Loss: 0.3093, Validation Loss: 0.5426
	--> Epoch [44/100], Loss: 0.3527, Validation Loss: 0.5414
	--> Epoch [45/100], Loss: 0.3488, Validation Loss: 0.5397
	--> Epoch [46/100], Loss: 0.3138, Validation Loss: 0.5361
	--> Epoch [47/100], Loss: 0.3483, Validation Loss: 0.5354
	--> Epoch [48/100], Loss: 0.3119, Validation Loss: 0.5323
	--> Epoch [49/100], Loss: 0.3142, Validation Loss: 0.5316
	--> Epoch [50/100], Loss: 0.3397, Validation Loss: 0.5309
	--> Epoch [51/100], Loss: 0.2887, Validation Loss: 0.5292
	--> Epoch [52/100], Loss: 0.3260, Validation Loss: 0.5263
	--> Epoch [53/100], Loss: 0.3355, Validation Loss: 0.5256
	--> Epoch [54/100], Loss: 0.2921, Validation Loss: 0.5233
	--> Epoch [55/100], Loss: 0.2866, Validation Loss: 0.5229
	--> Epoch [56/100], Loss: 0.3085, Validation Loss: 0.5221
	--> Epoch [57/100], Loss: 0.3096, Validation Loss: 0.5216
	--> Epoch [58/100], Loss: 0.2445, Validation Loss: 0.5219
	--> Epoch [59/100], Loss: 0.2966, Validation Loss: 0.5217
	--> Epoch [60/100], Loss: 0.2950, Validation Loss: 0.5200
	--> Epoch [61/100], Loss: 0.3040, Validation Loss: 0.5184
	--> Epoch [62/100], Loss: 0.2672, Validation Loss: 0.5145
	--> Epoch [63/100], Loss: 0.2551, Validation Loss: 0.5126
	--> Epoch [64/100], Loss: 0.2577, Validation Loss: 0.5108
	--> Epoch [65/100], Loss: 0.3036, Validation Loss: 0.5099
	--> Epoch [66/100], Loss: 0.2566, Validation Loss: 0.5084
	--> Epoch [67/100], Loss: 0.2949, Validation Loss: 0.5075
	--> Epoch [68/100], Loss: 0.2564, Validation Loss: 0.5062
	--> Epoch [69/100], Loss: 0.2711, Validation Loss: 0.5060
	--> Epoch [70/100], Loss: 0.2355, Validation Loss: 0.5045
	--> Epoch [71/100], Loss: 0.2086, Validation Loss: 0.5032
	--> Epoch [72/100], Loss: 0.2296, Validation Loss: 0.5020
	--> Epoch [73/100], Loss: 0.2424, Validation Loss: 0.5028
	--> Epoch [74/100], Loss: 0.2222, Validation Loss: 0.5029
	--> Epoch [75/100], Loss: 0.2104, Validation Loss: 0.5014
	--> Epoch [76/100], Loss: 0.2472, Validation Loss: 0.5017
	--> Epoch [77/100], Loss: 0.2186, Validation Loss: 0.5014
	--> Epoch [78/100], Loss: 0.1954, Validation Loss: 0.5017
	--> Epoch [79/100], Loss: 0.2458, Validation Loss: 0.5014
	--> Epoch [80/100], Loss: 0.2429, Validation Loss: 0.5011
	--> Epoch [81/100], Loss: 0.2171, Validation Loss: 0.5007
	--> Epoch [82/100], Loss: 0.2341, Validation Loss: 0.5005
	--> Epoch [83/100], Loss: 0.2577, Validation Loss: 0.5002
	--> Epoch [84/100], Loss: 0.1952, Validation Loss: 0.4993
	--> Epoch [85/100], Loss: 0.2060, Validation Loss: 0.4995
	--> Epoch [86/100], Loss: 0.1890, Validation Loss: 0.4987
	--> Epoch [87/100], Loss: 0.2386, Validation Loss: 0.4984
	--> Epoch [88/100], Loss: 0.2376, Validation Loss: 0.4986
	--> Epoch [89/100], Loss: 0.2140, Validation Loss: 0.4975
	--> Epoch [90/100], Loss: 0.2126, Validation Loss: 0.4973
	--> Epoch [91/100], Loss: 0.2658, Validation Loss: 0.4979
	--> Epoch [92/100], Loss: 0.1702, Validation Loss: 0.4977
	--> Epoch [93/100], Loss: 0.1892, Validation Loss: 0.4977
Early stopping
	--> Training for Fold 5 took 0.349714994430542 sec, using 93 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.7374
	--> Final training Epoch [2/100], Loss: 0.7030
	--> Final training Epoch [3/100], Loss: 0.6690
	--> Final training Epoch [4/100], Loss: 0.6919
	--> Final training Epoch [5/100], Loss: 0.6450
	--> Final training Epoch [6/100], Loss: 0.6522
	--> Final training Epoch [7/100], Loss: 0.5956
	--> Final training Epoch [8/100], Loss: 0.6362
	--> Final training Epoch [9/100], Loss: 0.5857
	--> Final training Epoch [10/100], Loss: 0.5934
	--> Final training Epoch [11/100], Loss: 0.5918
	--> Final training Epoch [12/100], Loss: 0.5528
	--> Final training Epoch [13/100], Loss: 0.5687
	--> Final training Epoch [14/100], Loss: 0.5267
	--> Final training Epoch [15/100], Loss: 0.5352
	--> Final training Epoch [16/100], Loss: 0.5311
	--> Final training Epoch [17/100], Loss: 0.5182
	--> Final training Epoch [18/100], Loss: 0.5009
	--> Final training Epoch [19/100], Loss: 0.5005
	--> Final training Epoch [20/100], Loss: 0.5036
	--> Final training Epoch [21/100], Loss: 0.4794
	--> Final training Epoch [22/100], Loss: 0.4939
	--> Final training Epoch [23/100], Loss: 0.4651
	--> Final training Epoch [24/100], Loss: 0.4649
	--> Final training Epoch [25/100], Loss: 0.4249
	--> Final training Epoch [26/100], Loss: 0.4468
	--> Final training Epoch [27/100], Loss: 0.4491
	--> Final training Epoch [28/100], Loss: 0.4046
	--> Final training Epoch [29/100], Loss: 0.3901
	--> Final training Epoch [30/100], Loss: 0.3993
	--> Final training Epoch [31/100], Loss: 0.4564
	--> Final training Epoch [32/100], Loss: 0.3922
	--> Final training Epoch [33/100], Loss: 0.3821
	--> Final training Epoch [34/100], Loss: 0.4089
	--> Final training Epoch [35/100], Loss: 0.3623
	--> Final training Epoch [36/100], Loss: 0.3782
	--> Final training Epoch [37/100], Loss: 0.3708
	--> Final training Epoch [38/100], Loss: 0.3638
	--> Final training Epoch [39/100], Loss: 0.4193
	--> Final training Epoch [40/100], Loss: 0.3424
	--> Final training Epoch [41/100], Loss: 0.3757
	--> Final training Epoch [42/100], Loss: 0.3515
	--> Final training Epoch [43/100], Loss: 0.3515
	--> Final training Epoch [44/100], Loss: 0.2962
	--> Final training Epoch [45/100], Loss: 0.3366
	--> Final training Epoch [46/100], Loss: 0.3106
	--> Final training Epoch [47/100], Loss: 0.3127
	--> Final training Epoch [48/100], Loss: 0.2863
	--> Final training Epoch [49/100], Loss: 0.3174
	--> Final training Epoch [50/100], Loss: 0.2752
	--> Final training Epoch [51/100], Loss: 0.3074
	--> Final training Epoch [52/100], Loss: 0.2886
	--> Final training Epoch [53/100], Loss: 0.3200
	--> Final training Epoch [54/100], Loss: 0.2961
	--> Final training Epoch [55/100], Loss: 0.2903
	--> Final training Epoch [56/100], Loss: 0.2558
	--> Final training Epoch [57/100], Loss: 0.2640
	--> Final training Epoch [58/100], Loss: 0.2635
	--> Final training Epoch [59/100], Loss: 0.2728
	--> Final training Epoch [60/100], Loss: 0.2294
	--> Final training Epoch [61/100], Loss: 0.2779
	--> Final training Epoch [62/100], Loss: 0.2775
	--> Final training Epoch [63/100], Loss: 0.2742
	--> Final training Epoch [64/100], Loss: 0.2657
	--> Final training Epoch [65/100], Loss: 0.2518
	--> Final training Epoch [66/100], Loss: 0.2617
	--> Final training Epoch [67/100], Loss: 0.2345
	--> Final training Epoch [68/100], Loss: 0.2710
	--> Final training Epoch [69/100], Loss: 0.2636
	--> Final training Epoch [70/100], Loss: 0.2088
	--> Final training Epoch [71/100], Loss: 0.2413
	--> Final training Epoch [72/100], Loss: 0.2663
	--> Final training Epoch [73/100], Loss: 0.2319
	--> Final training Epoch [74/100], Loss: 0.2417
	--> Final training Epoch [75/100], Loss: 0.2416
	--> Final training Epoch [76/100], Loss: 0.2151
	--> Final training Epoch [77/100], Loss: 0.2180
	--> Final training Epoch [78/100], Loss: 0.2267
	--> Final training Epoch [79/100], Loss: 0.2212
	--> Final training Epoch [80/100], Loss: 0.2246
	--> Final training Epoch [81/100], Loss: 0.2138
	--> Final training Epoch [82/100], Loss: 0.2163
	--> Final training Epoch [83/100], Loss: 0.2346
	--> Final training Epoch [84/100], Loss: 0.2166
	--> Final training Epoch [85/100], Loss: 0.1811
	--> Final training Epoch [86/100], Loss: 0.2171
	--> Final training Epoch [87/100], Loss: 0.2253
	--> Final training Epoch [88/100], Loss: 0.2500
	--> Final training Epoch [89/100], Loss: 0.2286
	--> Final training Epoch [90/100], Loss: 0.2009
	--> Final training Epoch [91/100], Loss: 0.2097
	--> Final training Epoch [92/100], Loss: 0.1832
	--> Final training Epoch [93/100], Loss: 0.1792
	--> Final training Epoch [94/100], Loss: 0.2051
	--> Final training Epoch [95/100], Loss: 0.1967
	--> Final training Epoch [96/100], Loss: 0.1894
	--> Final training Epoch [97/100], Loss: 0.1836
	--> Final training Epoch [98/100], Loss: 0.1774
	--> Final training Epoch [99/100], Loss: 0.2195
	--> Final training Epoch [100/100], Loss: 0.2017

Final training took 0.3389015197753906 sec

TESTING
	--> Testing took 0.0085 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.7346
	--> Final Precision: 0.7143
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7407
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8608, Validation Loss: 0.3318,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3318
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8497, Validation Loss: 0.4030,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3318
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 0.4521,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3318
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3784,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3318
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3650,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3318

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7450, Validation Loss: 0.6417
	--> Epoch [2/100], Loss: 0.7147, Validation Loss: 0.6214
	--> Epoch [3/100], Loss: 0.6918, Validation Loss: 0.6038
	--> Epoch [4/100], Loss: 0.6855, Validation Loss: 0.5879
	--> Epoch [5/100], Loss: 0.6508, Validation Loss: 0.5742
	--> Epoch [6/100], Loss: 0.6244, Validation Loss: 0.5627
	--> Epoch [7/100], Loss: 0.6363, Validation Loss: 0.5518
	--> Epoch [8/100], Loss: 0.6096, Validation Loss: 0.5406
	--> Epoch [9/100], Loss: 0.5859, Validation Loss: 0.5298
	--> Epoch [10/100], Loss: 0.5851, Validation Loss: 0.5210
	--> Epoch [11/100], Loss: 0.5596, Validation Loss: 0.5132
	--> Epoch [12/100], Loss: 0.5342, Validation Loss: 0.5045
	--> Epoch [13/100], Loss: 0.5490, Validation Loss: 0.4963
	--> Epoch [14/100], Loss: 0.4988, Validation Loss: 0.4885
	--> Epoch [15/100], Loss: 0.4644, Validation Loss: 0.4806
	--> Epoch [16/100], Loss: 0.4946, Validation Loss: 0.4738
	--> Epoch [17/100], Loss: 0.4976, Validation Loss: 0.4676
	--> Epoch [18/100], Loss: 0.4868, Validation Loss: 0.4611
	--> Epoch [19/100], Loss: 0.4650, Validation Loss: 0.4557
	--> Epoch [20/100], Loss: 0.4622, Validation Loss: 0.4489
	--> Epoch [21/100], Loss: 0.4698, Validation Loss: 0.4441
	--> Epoch [22/100], Loss: 0.4027, Validation Loss: 0.4391
	--> Epoch [23/100], Loss: 0.4033, Validation Loss: 0.4346
	--> Epoch [24/100], Loss: 0.3985, Validation Loss: 0.4301
	--> Epoch [25/100], Loss: 0.4147, Validation Loss: 0.4260
	--> Epoch [26/100], Loss: 0.3839, Validation Loss: 0.4218
	--> Epoch [27/100], Loss: 0.4037, Validation Loss: 0.4176
	--> Epoch [28/100], Loss: 0.3533, Validation Loss: 0.4141
	--> Epoch [29/100], Loss: 0.3757, Validation Loss: 0.4108
	--> Epoch [30/100], Loss: 0.3846, Validation Loss: 0.4079
	--> Epoch [31/100], Loss: 0.3513, Validation Loss: 0.4042
	--> Epoch [32/100], Loss: 0.3648, Validation Loss: 0.4016
	--> Epoch [33/100], Loss: 0.3667, Validation Loss: 0.3980
	--> Epoch [34/100], Loss: 0.3248, Validation Loss: 0.3951
	--> Epoch [35/100], Loss: 0.3847, Validation Loss: 0.3930
	--> Epoch [36/100], Loss: 0.3527, Validation Loss: 0.3897
	--> Epoch [37/100], Loss: 0.3373, Validation Loss: 0.3865
	--> Epoch [38/100], Loss: 0.3228, Validation Loss: 0.3832
	--> Epoch [39/100], Loss: 0.2934, Validation Loss: 0.3808
	--> Epoch [40/100], Loss: 0.3360, Validation Loss: 0.3772
	--> Epoch [41/100], Loss: 0.3085, Validation Loss: 0.3737
	--> Epoch [42/100], Loss: 0.2718, Validation Loss: 0.3710
	--> Epoch [43/100], Loss: 0.2904, Validation Loss: 0.3683
	--> Epoch [44/100], Loss: 0.2739, Validation Loss: 0.3650
	--> Epoch [45/100], Loss: 0.3162, Validation Loss: 0.3624
	--> Epoch [46/100], Loss: 0.2723, Validation Loss: 0.3608
	--> Epoch [47/100], Loss: 0.2779, Validation Loss: 0.3585
	--> Epoch [48/100], Loss: 0.2481, Validation Loss: 0.3573
	--> Epoch [49/100], Loss: 0.2600, Validation Loss: 0.3551
	--> Epoch [50/100], Loss: 0.2675, Validation Loss: 0.3531
	--> Epoch [51/100], Loss: 0.2733, Validation Loss: 0.3510
	--> Epoch [52/100], Loss: 0.2316, Validation Loss: 0.3496
	--> Epoch [53/100], Loss: 0.2651, Validation Loss: 0.3478
	--> Epoch [54/100], Loss: 0.2549, Validation Loss: 0.3461
	--> Epoch [55/100], Loss: 0.1980, Validation Loss: 0.3442
	--> Epoch [56/100], Loss: 0.2366, Validation Loss: 0.3427
	--> Epoch [57/100], Loss: 0.2385, Validation Loss: 0.3406
	--> Epoch [58/100], Loss: 0.2355, Validation Loss: 0.3389
	--> Epoch [59/100], Loss: 0.2098, Validation Loss: 0.3370
	--> Epoch [60/100], Loss: 0.1900, Validation Loss: 0.3360
	--> Epoch [61/100], Loss: 0.1896, Validation Loss: 0.3341
	--> Epoch [62/100], Loss: 0.1975, Validation Loss: 0.3317
	--> Epoch [63/100], Loss: 0.2151, Validation Loss: 0.3309
	--> Epoch [64/100], Loss: 0.1959, Validation Loss: 0.3295
	--> Epoch [65/100], Loss: 0.1937, Validation Loss: 0.3284
	--> Epoch [66/100], Loss: 0.1864, Validation Loss: 0.3270
	--> Epoch [67/100], Loss: 0.1921, Validation Loss: 0.3252
	--> Epoch [68/100], Loss: 0.1808, Validation Loss: 0.3239
	--> Epoch [69/100], Loss: 0.1903, Validation Loss: 0.3221
	--> Epoch [70/100], Loss: 0.1832, Validation Loss: 0.3221
	--> Epoch [71/100], Loss: 0.2177, Validation Loss: 0.3194
	--> Epoch [72/100], Loss: 0.2078, Validation Loss: 0.3193
	--> Epoch [73/100], Loss: 0.2041, Validation Loss: 0.3188
	--> Epoch [74/100], Loss: 0.1752, Validation Loss: 0.3184
	--> Epoch [75/100], Loss: 0.1802, Validation Loss: 0.3179
	--> Epoch [76/100], Loss: 0.1890, Validation Loss: 0.3162
	--> Epoch [77/100], Loss: 0.1749, Validation Loss: 0.3163
	--> Epoch [78/100], Loss: 0.1860, Validation Loss: 0.3151
	--> Epoch [79/100], Loss: 0.1553, Validation Loss: 0.3143
	--> Epoch [80/100], Loss: 0.1838, Validation Loss: 0.3142
	--> Epoch [81/100], Loss: 0.1623, Validation Loss: 0.3142
	--> Epoch [82/100], Loss: 0.1626, Validation Loss: 0.3123
	--> Epoch [83/100], Loss: 0.1527, Validation Loss: 0.3106
	--> Epoch [84/100], Loss: 0.1406, Validation Loss: 0.3104
	--> Epoch [85/100], Loss: 0.1429, Validation Loss: 0.3098
	--> Epoch [86/100], Loss: 0.1516, Validation Loss: 0.3087
	--> Epoch [87/100], Loss: 0.1493, Validation Loss: 0.3084
	--> Epoch [88/100], Loss: 0.1455, Validation Loss: 0.3074
	--> Epoch [89/100], Loss: 0.1413, Validation Loss: 0.3073
	--> Epoch [90/100], Loss: 0.1536, Validation Loss: 0.3069
	--> Epoch [91/100], Loss: 0.1568, Validation Loss: 0.3062
	--> Epoch [92/100], Loss: 0.1551, Validation Loss: 0.3055
	--> Epoch [93/100], Loss: 0.1232, Validation Loss: 0.3061
	--> Epoch [94/100], Loss: 0.1337, Validation Loss: 0.3046
	--> Epoch [95/100], Loss: 0.1233, Validation Loss: 0.3036
	--> Epoch [96/100], Loss: 0.1629, Validation Loss: 0.3022
	--> Epoch [97/100], Loss: 0.1234, Validation Loss: 0.3024
	--> Epoch [98/100], Loss: 0.1410, Validation Loss: 0.3010
	--> Epoch [99/100], Loss: 0.1357, Validation Loss: 0.2995
	--> Epoch [100/100], Loss: 0.1572, Validation Loss: 0.2992
	--> Training for Fold 1 took 0.3946819305419922 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8015, Validation Loss: 0.7696
	--> Epoch [2/100], Loss: 0.7588, Validation Loss: 0.7542
	--> Epoch [3/100], Loss: 0.7581, Validation Loss: 0.7369
	--> Epoch [4/100], Loss: 0.7446, Validation Loss: 0.7202
	--> Epoch [5/100], Loss: 0.7324, Validation Loss: 0.7045
	--> Epoch [6/100], Loss: 0.7120, Validation Loss: 0.6842
	--> Epoch [7/100], Loss: 0.6593, Validation Loss: 0.6688
	--> Epoch [8/100], Loss: 0.6902, Validation Loss: 0.6517
	--> Epoch [9/100], Loss: 0.6460, Validation Loss: 0.6394
	--> Epoch [10/100], Loss: 0.6498, Validation Loss: 0.6279
	--> Epoch [11/100], Loss: 0.6289, Validation Loss: 0.6141
	--> Epoch [12/100], Loss: 0.6158, Validation Loss: 0.6001
	--> Epoch [13/100], Loss: 0.6078, Validation Loss: 0.5864
	--> Epoch [14/100], Loss: 0.5811, Validation Loss: 0.5722
	--> Epoch [15/100], Loss: 0.5857, Validation Loss: 0.5565
	--> Epoch [16/100], Loss: 0.5698, Validation Loss: 0.5442
	--> Epoch [17/100], Loss: 0.5703, Validation Loss: 0.5338
	--> Epoch [18/100], Loss: 0.5450, Validation Loss: 0.5220
	--> Epoch [19/100], Loss: 0.5110, Validation Loss: 0.5101
	--> Epoch [20/100], Loss: 0.5224, Validation Loss: 0.5006
	--> Epoch [21/100], Loss: 0.5034, Validation Loss: 0.4910
	--> Epoch [22/100], Loss: 0.5000, Validation Loss: 0.4841
	--> Epoch [23/100], Loss: 0.4875, Validation Loss: 0.4768
	--> Epoch [24/100], Loss: 0.4839, Validation Loss: 0.4684
	--> Epoch [25/100], Loss: 0.4901, Validation Loss: 0.4612
	--> Epoch [26/100], Loss: 0.4733, Validation Loss: 0.4537
	--> Epoch [27/100], Loss: 0.4407, Validation Loss: 0.4478
	--> Epoch [28/100], Loss: 0.4516, Validation Loss: 0.4406
	--> Epoch [29/100], Loss: 0.4412, Validation Loss: 0.4336
	--> Epoch [30/100], Loss: 0.4402, Validation Loss: 0.4273
	--> Epoch [31/100], Loss: 0.4225, Validation Loss: 0.4207
	--> Epoch [32/100], Loss: 0.3918, Validation Loss: 0.4151
	--> Epoch [33/100], Loss: 0.4187, Validation Loss: 0.4075
	--> Epoch [34/100], Loss: 0.3948, Validation Loss: 0.4016
	--> Epoch [35/100], Loss: 0.3796, Validation Loss: 0.3968
	--> Epoch [36/100], Loss: 0.3949, Validation Loss: 0.3914
	--> Epoch [37/100], Loss: 0.3715, Validation Loss: 0.3844
	--> Epoch [38/100], Loss: 0.3669, Validation Loss: 0.3784
	--> Epoch [39/100], Loss: 0.3664, Validation Loss: 0.3740
	--> Epoch [40/100], Loss: 0.3767, Validation Loss: 0.3687
	--> Epoch [41/100], Loss: 0.3486, Validation Loss: 0.3630
	--> Epoch [42/100], Loss: 0.3390, Validation Loss: 0.3583
	--> Epoch [43/100], Loss: 0.3188, Validation Loss: 0.3541
	--> Epoch [44/100], Loss: 0.3049, Validation Loss: 0.3497
	--> Epoch [45/100], Loss: 0.3129, Validation Loss: 0.3444
	--> Epoch [46/100], Loss: 0.3379, Validation Loss: 0.3402
	--> Epoch [47/100], Loss: 0.2884, Validation Loss: 0.3365
	--> Epoch [48/100], Loss: 0.3187, Validation Loss: 0.3320
	--> Epoch [49/100], Loss: 0.2967, Validation Loss: 0.3278
	--> Epoch [50/100], Loss: 0.3070, Validation Loss: 0.3243
	--> Epoch [51/100], Loss: 0.2870, Validation Loss: 0.3197
	--> Epoch [52/100], Loss: 0.2887, Validation Loss: 0.3166
	--> Epoch [53/100], Loss: 0.2822, Validation Loss: 0.3135
	--> Epoch [54/100], Loss: 0.2506, Validation Loss: 0.3103
	--> Epoch [55/100], Loss: 0.2445, Validation Loss: 0.3078
	--> Epoch [56/100], Loss: 0.2801, Validation Loss: 0.3047
	--> Epoch [57/100], Loss: 0.2626, Validation Loss: 0.3017
	--> Epoch [58/100], Loss: 0.2487, Validation Loss: 0.2983
	--> Epoch [59/100], Loss: 0.2513, Validation Loss: 0.2951
	--> Epoch [60/100], Loss: 0.2309, Validation Loss: 0.2928
	--> Epoch [61/100], Loss: 0.2482, Validation Loss: 0.2907
	--> Epoch [62/100], Loss: 0.2280, Validation Loss: 0.2883
	--> Epoch [63/100], Loss: 0.2384, Validation Loss: 0.2861
	--> Epoch [64/100], Loss: 0.2445, Validation Loss: 0.2839
	--> Epoch [65/100], Loss: 0.2224, Validation Loss: 0.2809
	--> Epoch [66/100], Loss: 0.2180, Validation Loss: 0.2784
	--> Epoch [67/100], Loss: 0.1983, Validation Loss: 0.2757
	--> Epoch [68/100], Loss: 0.2027, Validation Loss: 0.2737
	--> Epoch [69/100], Loss: 0.2025, Validation Loss: 0.2723
	--> Epoch [70/100], Loss: 0.2068, Validation Loss: 0.2700
	--> Epoch [71/100], Loss: 0.1966, Validation Loss: 0.2678
	--> Epoch [72/100], Loss: 0.1857, Validation Loss: 0.2658
	--> Epoch [73/100], Loss: 0.1738, Validation Loss: 0.2649
	--> Epoch [74/100], Loss: 0.1943, Validation Loss: 0.2631
	--> Epoch [75/100], Loss: 0.1966, Validation Loss: 0.2620
	--> Epoch [76/100], Loss: 0.1674, Validation Loss: 0.2602
	--> Epoch [77/100], Loss: 0.1771, Validation Loss: 0.2588
	--> Epoch [78/100], Loss: 0.1623, Validation Loss: 0.2577
	--> Epoch [79/100], Loss: 0.1657, Validation Loss: 0.2561
	--> Epoch [80/100], Loss: 0.1726, Validation Loss: 0.2553
	--> Epoch [81/100], Loss: 0.1742, Validation Loss: 0.2541
	--> Epoch [82/100], Loss: 0.1467, Validation Loss: 0.2517
	--> Epoch [83/100], Loss: 0.1337, Validation Loss: 0.2497
	--> Epoch [84/100], Loss: 0.1513, Validation Loss: 0.2487
	--> Epoch [85/100], Loss: 0.1546, Validation Loss: 0.2475
	--> Epoch [86/100], Loss: 0.1564, Validation Loss: 0.2464
	--> Epoch [87/100], Loss: 0.1367, Validation Loss: 0.2453
	--> Epoch [88/100], Loss: 0.1340, Validation Loss: 0.2444
	--> Epoch [89/100], Loss: 0.1514, Validation Loss: 0.2425
	--> Epoch [90/100], Loss: 0.1576, Validation Loss: 0.2413
	--> Epoch [91/100], Loss: 0.1657, Validation Loss: 0.2405
	--> Epoch [92/100], Loss: 0.1488, Validation Loss: 0.2395
	--> Epoch [93/100], Loss: 0.1701, Validation Loss: 0.2391
	--> Epoch [94/100], Loss: 0.1503, Validation Loss: 0.2387
	--> Epoch [95/100], Loss: 0.1151, Validation Loss: 0.2372
	--> Epoch [96/100], Loss: 0.1469, Validation Loss: 0.2365
	--> Epoch [97/100], Loss: 0.1572, Validation Loss: 0.2355
	--> Epoch [98/100], Loss: 0.1528, Validation Loss: 0.2346
	--> Epoch [99/100], Loss: 0.1272, Validation Loss: 0.2346
	--> Epoch [100/100], Loss: 0.1449, Validation Loss: 0.2331
	--> Training for Fold 2 took 0.43807029724121094 sec, using 100 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7000, Validation Loss: 0.7177
	--> Epoch [2/100], Loss: 0.6625, Validation Loss: 0.7056
	--> Epoch [3/100], Loss: 0.6572, Validation Loss: 0.6941
	--> Epoch [4/100], Loss: 0.6540, Validation Loss: 0.6857
	--> Epoch [5/100], Loss: 0.6198, Validation Loss: 0.6767
	--> Epoch [6/100], Loss: 0.6074, Validation Loss: 0.6643
	--> Epoch [7/100], Loss: 0.5997, Validation Loss: 0.6521
	--> Epoch [8/100], Loss: 0.5783, Validation Loss: 0.6436
	--> Epoch [9/100], Loss: 0.5673, Validation Loss: 0.6342
	--> Epoch [10/100], Loss: 0.5534, Validation Loss: 0.6262
	--> Epoch [11/100], Loss: 0.5456, Validation Loss: 0.6186
	--> Epoch [12/100], Loss: 0.5363, Validation Loss: 0.6126
	--> Epoch [13/100], Loss: 0.5063, Validation Loss: 0.6048
	--> Epoch [14/100], Loss: 0.5088, Validation Loss: 0.5978
	--> Epoch [15/100], Loss: 0.4994, Validation Loss: 0.5907
	--> Epoch [16/100], Loss: 0.4711, Validation Loss: 0.5843
	--> Epoch [17/100], Loss: 0.4610, Validation Loss: 0.5772
	--> Epoch [18/100], Loss: 0.4742, Validation Loss: 0.5698
	--> Epoch [19/100], Loss: 0.4324, Validation Loss: 0.5641
	--> Epoch [20/100], Loss: 0.4294, Validation Loss: 0.5561
	--> Epoch [21/100], Loss: 0.4033, Validation Loss: 0.5500
	--> Epoch [22/100], Loss: 0.4057, Validation Loss: 0.5436
	--> Epoch [23/100], Loss: 0.3885, Validation Loss: 0.5364
	--> Epoch [24/100], Loss: 0.3674, Validation Loss: 0.5307
	--> Epoch [25/100], Loss: 0.3923, Validation Loss: 0.5253
	--> Epoch [26/100], Loss: 0.3791, Validation Loss: 0.5204
	--> Epoch [27/100], Loss: 0.3779, Validation Loss: 0.5147
	--> Epoch [28/100], Loss: 0.3681, Validation Loss: 0.5090
	--> Epoch [29/100], Loss: 0.3420, Validation Loss: 0.5040
	--> Epoch [30/100], Loss: 0.3445, Validation Loss: 0.4973
	--> Epoch [31/100], Loss: 0.3746, Validation Loss: 0.4927
	--> Epoch [32/100], Loss: 0.3291, Validation Loss: 0.4873
	--> Epoch [33/100], Loss: 0.2999, Validation Loss: 0.4832
	--> Epoch [34/100], Loss: 0.2907, Validation Loss: 0.4792
	--> Epoch [35/100], Loss: 0.2953, Validation Loss: 0.4756
	--> Epoch [36/100], Loss: 0.3062, Validation Loss: 0.4700
	--> Epoch [37/100], Loss: 0.3009, Validation Loss: 0.4655
	--> Epoch [38/100], Loss: 0.3080, Validation Loss: 0.4608
	--> Epoch [39/100], Loss: 0.2841, Validation Loss: 0.4571
	--> Epoch [40/100], Loss: 0.2474, Validation Loss: 0.4527
	--> Epoch [41/100], Loss: 0.2744, Validation Loss: 0.4494
	--> Epoch [42/100], Loss: 0.2898, Validation Loss: 0.4455
	--> Epoch [43/100], Loss: 0.2571, Validation Loss: 0.4429
	--> Epoch [44/100], Loss: 0.2492, Validation Loss: 0.4401
	--> Epoch [45/100], Loss: 0.2629, Validation Loss: 0.4370
	--> Epoch [46/100], Loss: 0.2836, Validation Loss: 0.4333
	--> Epoch [47/100], Loss: 0.2532, Validation Loss: 0.4294
	--> Epoch [48/100], Loss: 0.2435, Validation Loss: 0.4254
	--> Epoch [49/100], Loss: 0.2242, Validation Loss: 0.4227
	--> Epoch [50/100], Loss: 0.2495, Validation Loss: 0.4203
	--> Epoch [51/100], Loss: 0.2142, Validation Loss: 0.4180
	--> Epoch [52/100], Loss: 0.2257, Validation Loss: 0.4145
	--> Epoch [53/100], Loss: 0.2287, Validation Loss: 0.4125
	--> Epoch [54/100], Loss: 0.2096, Validation Loss: 0.4089
	--> Epoch [55/100], Loss: 0.2132, Validation Loss: 0.4070
	--> Epoch [56/100], Loss: 0.1879, Validation Loss: 0.4040
	--> Epoch [57/100], Loss: 0.2248, Validation Loss: 0.4017
	--> Epoch [58/100], Loss: 0.1960, Validation Loss: 0.4001
	--> Epoch [59/100], Loss: 0.1764, Validation Loss: 0.3973
	--> Epoch [60/100], Loss: 0.1954, Validation Loss: 0.3962
	--> Epoch [61/100], Loss: 0.1977, Validation Loss: 0.3950
	--> Epoch [62/100], Loss: 0.1905, Validation Loss: 0.3935
	--> Epoch [63/100], Loss: 0.1806, Validation Loss: 0.3926
	--> Epoch [64/100], Loss: 0.1483, Validation Loss: 0.3895
	--> Epoch [65/100], Loss: 0.1565, Validation Loss: 0.3876
	--> Epoch [66/100], Loss: 0.1486, Validation Loss: 0.3855
	--> Epoch [67/100], Loss: 0.1605, Validation Loss: 0.3831
	--> Epoch [68/100], Loss: 0.1546, Validation Loss: 0.3806
	--> Epoch [69/100], Loss: 0.1469, Validation Loss: 0.3795
	--> Epoch [70/100], Loss: 0.1642, Validation Loss: 0.3765
	--> Epoch [71/100], Loss: 0.1688, Validation Loss: 0.3735
	--> Epoch [72/100], Loss: 0.1494, Validation Loss: 0.3712
	--> Epoch [73/100], Loss: 0.1552, Validation Loss: 0.3701
	--> Epoch [74/100], Loss: 0.1491, Validation Loss: 0.3686
	--> Epoch [75/100], Loss: 0.1492, Validation Loss: 0.3667
	--> Epoch [76/100], Loss: 0.1328, Validation Loss: 0.3656
	--> Epoch [77/100], Loss: 0.1357, Validation Loss: 0.3629
	--> Epoch [78/100], Loss: 0.1404, Validation Loss: 0.3609
	--> Epoch [79/100], Loss: 0.1229, Validation Loss: 0.3587
	--> Epoch [80/100], Loss: 0.1424, Validation Loss: 0.3565
	--> Epoch [81/100], Loss: 0.1189, Validation Loss: 0.3555
	--> Epoch [82/100], Loss: 0.1147, Validation Loss: 0.3541
	--> Epoch [83/100], Loss: 0.1404, Validation Loss: 0.3527
	--> Epoch [84/100], Loss: 0.1288, Validation Loss: 0.3517
	--> Epoch [85/100], Loss: 0.1220, Validation Loss: 0.3513
	--> Epoch [86/100], Loss: 0.1189, Validation Loss: 0.3496
	--> Epoch [87/100], Loss: 0.1524, Validation Loss: 0.3481
	--> Epoch [88/100], Loss: 0.1267, Validation Loss: 0.3464
	--> Epoch [89/100], Loss: 0.1122, Validation Loss: 0.3452
	--> Epoch [90/100], Loss: 0.1222, Validation Loss: 0.3438
	--> Epoch [91/100], Loss: 0.1145, Validation Loss: 0.3428
	--> Epoch [92/100], Loss: 0.1127, Validation Loss: 0.3422
	--> Epoch [93/100], Loss: 0.1213, Validation Loss: 0.3411
	--> Epoch [94/100], Loss: 0.1444, Validation Loss: 0.3401
	--> Epoch [95/100], Loss: 0.1211, Validation Loss: 0.3393
	--> Epoch [96/100], Loss: 0.0837, Validation Loss: 0.3385
	--> Epoch [97/100], Loss: 0.0873, Validation Loss: 0.3387
	--> Epoch [98/100], Loss: 0.0889, Validation Loss: 0.3373
	--> Epoch [99/100], Loss: 0.1105, Validation Loss: 0.3362
	--> Epoch [100/100], Loss: 0.0836, Validation Loss: 0.3352
	--> Training for Fold 3 took 0.3943641185760498 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7747, Validation Loss: 0.5743
	--> Epoch [2/100], Loss: 0.7359, Validation Loss: 0.5623
	--> Epoch [3/100], Loss: 0.7542, Validation Loss: 0.5529
	--> Epoch [4/100], Loss: 0.7165, Validation Loss: 0.5451
	--> Epoch [5/100], Loss: 0.7242, Validation Loss: 0.5373
	--> Epoch [6/100], Loss: 0.6652, Validation Loss: 0.5308
	--> Epoch [7/100], Loss: 0.6582, Validation Loss: 0.5220
	--> Epoch [8/100], Loss: 0.6243, Validation Loss: 0.5142
	--> Epoch [9/100], Loss: 0.6191, Validation Loss: 0.5067
	--> Epoch [10/100], Loss: 0.6000, Validation Loss: 0.5006
	--> Epoch [11/100], Loss: 0.5521, Validation Loss: 0.4961
	--> Epoch [12/100], Loss: 0.5728, Validation Loss: 0.4904
	--> Epoch [13/100], Loss: 0.5490, Validation Loss: 0.4861
	--> Epoch [14/100], Loss: 0.5358, Validation Loss: 0.4797
	--> Epoch [15/100], Loss: 0.5204, Validation Loss: 0.4750
	--> Epoch [16/100], Loss: 0.5143, Validation Loss: 0.4686
	--> Epoch [17/100], Loss: 0.5131, Validation Loss: 0.4661
	--> Epoch [18/100], Loss: 0.5052, Validation Loss: 0.4611
	--> Epoch [19/100], Loss: 0.4850, Validation Loss: 0.4550
	--> Epoch [20/100], Loss: 0.4809, Validation Loss: 0.4492
	--> Epoch [21/100], Loss: 0.4587, Validation Loss: 0.4439
	--> Epoch [22/100], Loss: 0.4992, Validation Loss: 0.4380
	--> Epoch [23/100], Loss: 0.4333, Validation Loss: 0.4349
	--> Epoch [24/100], Loss: 0.4310, Validation Loss: 0.4302
	--> Epoch [25/100], Loss: 0.4336, Validation Loss: 0.4256
	--> Epoch [26/100], Loss: 0.4355, Validation Loss: 0.4206
	--> Epoch [27/100], Loss: 0.4167, Validation Loss: 0.4175
	--> Epoch [28/100], Loss: 0.4018, Validation Loss: 0.4123
	--> Epoch [29/100], Loss: 0.3745, Validation Loss: 0.4083
	--> Epoch [30/100], Loss: 0.4021, Validation Loss: 0.4032
	--> Epoch [31/100], Loss: 0.3756, Validation Loss: 0.3989
	--> Epoch [32/100], Loss: 0.3691, Validation Loss: 0.3937
	--> Epoch [33/100], Loss: 0.3550, Validation Loss: 0.3897
	--> Epoch [34/100], Loss: 0.3475, Validation Loss: 0.3860
	--> Epoch [35/100], Loss: 0.3271, Validation Loss: 0.3831
	--> Epoch [36/100], Loss: 0.3170, Validation Loss: 0.3794
	--> Epoch [37/100], Loss: 0.3313, Validation Loss: 0.3769
	--> Epoch [38/100], Loss: 0.3420, Validation Loss: 0.3732
	--> Epoch [39/100], Loss: 0.3266, Validation Loss: 0.3710
	--> Epoch [40/100], Loss: 0.3388, Validation Loss: 0.3670
	--> Epoch [41/100], Loss: 0.3099, Validation Loss: 0.3633
	--> Epoch [42/100], Loss: 0.3050, Validation Loss: 0.3596
	--> Epoch [43/100], Loss: 0.2704, Validation Loss: 0.3566
	--> Epoch [44/100], Loss: 0.2616, Validation Loss: 0.3532
	--> Epoch [45/100], Loss: 0.3040, Validation Loss: 0.3493
	--> Epoch [46/100], Loss: 0.2903, Validation Loss: 0.3477
	--> Epoch [47/100], Loss: 0.2812, Validation Loss: 0.3443
	--> Epoch [48/100], Loss: 0.2851, Validation Loss: 0.3412
	--> Epoch [49/100], Loss: 0.2644, Validation Loss: 0.3380
	--> Epoch [50/100], Loss: 0.2541, Validation Loss: 0.3344
	--> Epoch [51/100], Loss: 0.2377, Validation Loss: 0.3326
	--> Epoch [52/100], Loss: 0.2717, Validation Loss: 0.3315
	--> Epoch [53/100], Loss: 0.2304, Validation Loss: 0.3288
	--> Epoch [54/100], Loss: 0.2110, Validation Loss: 0.3271
	--> Epoch [55/100], Loss: 0.2440, Validation Loss: 0.3249
	--> Epoch [56/100], Loss: 0.2232, Validation Loss: 0.3218
	--> Epoch [57/100], Loss: 0.2278, Validation Loss: 0.3180
	--> Epoch [58/100], Loss: 0.2052, Validation Loss: 0.3177
	--> Epoch [59/100], Loss: 0.2008, Validation Loss: 0.3155
	--> Epoch [60/100], Loss: 0.2327, Validation Loss: 0.3125
	--> Epoch [61/100], Loss: 0.1819, Validation Loss: 0.3114
	--> Epoch [62/100], Loss: 0.2337, Validation Loss: 0.3096
	--> Epoch [63/100], Loss: 0.2020, Validation Loss: 0.3078
	--> Epoch [64/100], Loss: 0.1863, Validation Loss: 0.3064
	--> Epoch [65/100], Loss: 0.1864, Validation Loss: 0.3048
	--> Epoch [66/100], Loss: 0.1783, Validation Loss: 0.3029
	--> Epoch [67/100], Loss: 0.1907, Validation Loss: 0.3016
	--> Epoch [68/100], Loss: 0.1679, Validation Loss: 0.3007
	--> Epoch [69/100], Loss: 0.1964, Validation Loss: 0.2989
	--> Epoch [70/100], Loss: 0.1931, Validation Loss: 0.2977
	--> Epoch [71/100], Loss: 0.1752, Validation Loss: 0.2975
	--> Epoch [72/100], Loss: 0.1576, Validation Loss: 0.2956
	--> Epoch [73/100], Loss: 0.1522, Validation Loss: 0.2945
	--> Epoch [74/100], Loss: 0.1829, Validation Loss: 0.2931
	--> Epoch [75/100], Loss: 0.1674, Validation Loss: 0.2926
	--> Epoch [76/100], Loss: 0.1514, Validation Loss: 0.2932
	--> Epoch [77/100], Loss: 0.1495, Validation Loss: 0.2908
	--> Epoch [78/100], Loss: 0.1594, Validation Loss: 0.2903
	--> Epoch [79/100], Loss: 0.1991, Validation Loss: 0.2882
	--> Epoch [80/100], Loss: 0.1652, Validation Loss: 0.2878
	--> Epoch [81/100], Loss: 0.1624, Validation Loss: 0.2866
	--> Epoch [82/100], Loss: 0.1237, Validation Loss: 0.2860
	--> Epoch [83/100], Loss: 0.1269, Validation Loss: 0.2848
	--> Epoch [84/100], Loss: 0.1392, Validation Loss: 0.2848
	--> Epoch [85/100], Loss: 0.1343, Validation Loss: 0.2854
	--> Epoch [86/100], Loss: 0.1300, Validation Loss: 0.2833
	--> Epoch [87/100], Loss: 0.1603, Validation Loss: 0.2822
	--> Epoch [88/100], Loss: 0.1474, Validation Loss: 0.2812
	--> Epoch [89/100], Loss: 0.1461, Validation Loss: 0.2811
	--> Epoch [90/100], Loss: 0.1419, Validation Loss: 0.2798
	--> Epoch [91/100], Loss: 0.1214, Validation Loss: 0.2798
	--> Epoch [92/100], Loss: 0.1523, Validation Loss: 0.2786
	--> Epoch [93/100], Loss: 0.1181, Validation Loss: 0.2781
	--> Epoch [94/100], Loss: 0.1594, Validation Loss: 0.2771
	--> Epoch [95/100], Loss: 0.1084, Validation Loss: 0.2767
	--> Epoch [96/100], Loss: 0.1334, Validation Loss: 0.2764
	--> Epoch [97/100], Loss: 0.1450, Validation Loss: 0.2754
	--> Epoch [98/100], Loss: 0.1098, Validation Loss: 0.2757
	--> Epoch [99/100], Loss: 0.0965, Validation Loss: 0.2754
	--> Epoch [100/100], Loss: 0.1405, Validation Loss: 0.2738
	--> Training for Fold 4 took 0.40064072608947754 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7185, Validation Loss: 0.7110
	--> Epoch [2/100], Loss: 0.6795, Validation Loss: 0.7058
	--> Epoch [3/100], Loss: 0.6698, Validation Loss: 0.7003
	--> Epoch [4/100], Loss: 0.6411, Validation Loss: 0.6949
	--> Epoch [5/100], Loss: 0.6453, Validation Loss: 0.6905
	--> Epoch [6/100], Loss: 0.6005, Validation Loss: 0.6874
	--> Epoch [7/100], Loss: 0.5914, Validation Loss: 0.6841
	--> Epoch [8/100], Loss: 0.5800, Validation Loss: 0.6810
	--> Epoch [9/100], Loss: 0.5434, Validation Loss: 0.6767
	--> Epoch [10/100], Loss: 0.5132, Validation Loss: 0.6719
	--> Epoch [11/100], Loss: 0.5311, Validation Loss: 0.6671
	--> Epoch [12/100], Loss: 0.5349, Validation Loss: 0.6595
	--> Epoch [13/100], Loss: 0.4722, Validation Loss: 0.6549
	--> Epoch [14/100], Loss: 0.4786, Validation Loss: 0.6479
	--> Epoch [15/100], Loss: 0.4434, Validation Loss: 0.6429
	--> Epoch [16/100], Loss: 0.4406, Validation Loss: 0.6400
	--> Epoch [17/100], Loss: 0.4380, Validation Loss: 0.6355
	--> Epoch [18/100], Loss: 0.4465, Validation Loss: 0.6321
	--> Epoch [19/100], Loss: 0.4233, Validation Loss: 0.6264
	--> Epoch [20/100], Loss: 0.3990, Validation Loss: 0.6213
	--> Epoch [21/100], Loss: 0.3935, Validation Loss: 0.6174
	--> Epoch [22/100], Loss: 0.3679, Validation Loss: 0.6133
	--> Epoch [23/100], Loss: 0.3788, Validation Loss: 0.6085
	--> Epoch [24/100], Loss: 0.3790, Validation Loss: 0.6054
	--> Epoch [25/100], Loss: 0.3575, Validation Loss: 0.6027
	--> Epoch [26/100], Loss: 0.3720, Validation Loss: 0.6000
	--> Epoch [27/100], Loss: 0.3559, Validation Loss: 0.5972
	--> Epoch [28/100], Loss: 0.3552, Validation Loss: 0.5946
	--> Epoch [29/100], Loss: 0.3470, Validation Loss: 0.5922
	--> Epoch [30/100], Loss: 0.3090, Validation Loss: 0.5881
	--> Epoch [31/100], Loss: 0.3454, Validation Loss: 0.5842
	--> Epoch [32/100], Loss: 0.2910, Validation Loss: 0.5820
	--> Epoch [33/100], Loss: 0.3007, Validation Loss: 0.5806
	--> Epoch [34/100], Loss: 0.2912, Validation Loss: 0.5770
	--> Epoch [35/100], Loss: 0.3224, Validation Loss: 0.5733
	--> Epoch [36/100], Loss: 0.2737, Validation Loss: 0.5722
	--> Epoch [37/100], Loss: 0.2880, Validation Loss: 0.5704
	--> Epoch [38/100], Loss: 0.2809, Validation Loss: 0.5652
	--> Epoch [39/100], Loss: 0.2560, Validation Loss: 0.5622
	--> Epoch [40/100], Loss: 0.2428, Validation Loss: 0.5610
	--> Epoch [41/100], Loss: 0.2681, Validation Loss: 0.5602
	--> Epoch [42/100], Loss: 0.2605, Validation Loss: 0.5574
	--> Epoch [43/100], Loss: 0.2851, Validation Loss: 0.5567
	--> Epoch [44/100], Loss: 0.2608, Validation Loss: 0.5532
	--> Epoch [45/100], Loss: 0.2454, Validation Loss: 0.5515
	--> Epoch [46/100], Loss: 0.2338, Validation Loss: 0.5506
	--> Epoch [47/100], Loss: 0.2457, Validation Loss: 0.5490
	--> Epoch [48/100], Loss: 0.2402, Validation Loss: 0.5485
	--> Epoch [49/100], Loss: 0.2490, Validation Loss: 0.5465
	--> Epoch [50/100], Loss: 0.2388, Validation Loss: 0.5435
	--> Epoch [51/100], Loss: 0.2147, Validation Loss: 0.5413
	--> Epoch [52/100], Loss: 0.1988, Validation Loss: 0.5396
	--> Epoch [53/100], Loss: 0.2010, Validation Loss: 0.5384
	--> Epoch [54/100], Loss: 0.1994, Validation Loss: 0.5388
	--> Epoch [55/100], Loss: 0.2125, Validation Loss: 0.5355
	--> Epoch [56/100], Loss: 0.1911, Validation Loss: 0.5345
	--> Epoch [57/100], Loss: 0.1877, Validation Loss: 0.5349
	--> Epoch [58/100], Loss: 0.1641, Validation Loss: 0.5342
	--> Epoch [59/100], Loss: 0.1877, Validation Loss: 0.5320
	--> Epoch [60/100], Loss: 0.1935, Validation Loss: 0.5308
	--> Epoch [61/100], Loss: 0.2261, Validation Loss: 0.5303
	--> Epoch [62/100], Loss: 0.1947, Validation Loss: 0.5289
	--> Epoch [63/100], Loss: 0.1901, Validation Loss: 0.5272
	--> Epoch [64/100], Loss: 0.1604, Validation Loss: 0.5258
	--> Epoch [65/100], Loss: 0.1543, Validation Loss: 0.5247
	--> Epoch [66/100], Loss: 0.1752, Validation Loss: 0.5248
	--> Epoch [67/100], Loss: 0.1642, Validation Loss: 0.5230
	--> Epoch [68/100], Loss: 0.1891, Validation Loss: 0.5230
	--> Epoch [69/100], Loss: 0.1387, Validation Loss: 0.5213
	--> Epoch [70/100], Loss: 0.1742, Validation Loss: 0.5210
	--> Epoch [71/100], Loss: 0.1603, Validation Loss: 0.5205
	--> Epoch [72/100], Loss: 0.1591, Validation Loss: 0.5200
	--> Epoch [73/100], Loss: 0.1755, Validation Loss: 0.5193
	--> Epoch [74/100], Loss: 0.1641, Validation Loss: 0.5181
	--> Epoch [75/100], Loss: 0.1598, Validation Loss: 0.5185
	--> Epoch [76/100], Loss: 0.1325, Validation Loss: 0.5174
	--> Epoch [77/100], Loss: 0.1445, Validation Loss: 0.5168
	--> Epoch [78/100], Loss: 0.1252, Validation Loss: 0.5170
	--> Epoch [79/100], Loss: 0.1229, Validation Loss: 0.5178
	--> Epoch [80/100], Loss: 0.1470, Validation Loss: 0.5188
Early stopping
	--> Training for Fold 5 took 0.3165757656097412 sec, using 80 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6870
	--> Final training Epoch [2/100], Loss: 0.6820
	--> Final training Epoch [3/100], Loss: 0.6574
	--> Final training Epoch [4/100], Loss: 0.6433
	--> Final training Epoch [5/100], Loss: 0.6332
	--> Final training Epoch [6/100], Loss: 0.6221
	--> Final training Epoch [7/100], Loss: 0.6028
	--> Final training Epoch [8/100], Loss: 0.5744
	--> Final training Epoch [9/100], Loss: 0.5789
	--> Final training Epoch [10/100], Loss: 0.5784
	--> Final training Epoch [11/100], Loss: 0.5527
	--> Final training Epoch [12/100], Loss: 0.5471
	--> Final training Epoch [13/100], Loss: 0.5311
	--> Final training Epoch [14/100], Loss: 0.5230
	--> Final training Epoch [15/100], Loss: 0.5254
	--> Final training Epoch [16/100], Loss: 0.5026
	--> Final training Epoch [17/100], Loss: 0.4916
	--> Final training Epoch [18/100], Loss: 0.4986
	--> Final training Epoch [19/100], Loss: 0.4962
	--> Final training Epoch [20/100], Loss: 0.4657
	--> Final training Epoch [21/100], Loss: 0.4720
	--> Final training Epoch [22/100], Loss: 0.4723
	--> Final training Epoch [23/100], Loss: 0.4406
	--> Final training Epoch [24/100], Loss: 0.4330
	--> Final training Epoch [25/100], Loss: 0.4287
	--> Final training Epoch [26/100], Loss: 0.4445
	--> Final training Epoch [27/100], Loss: 0.3937
	--> Final training Epoch [28/100], Loss: 0.3888
	--> Final training Epoch [29/100], Loss: 0.4033
	--> Final training Epoch [30/100], Loss: 0.3811
	--> Final training Epoch [31/100], Loss: 0.3766
	--> Final training Epoch [32/100], Loss: 0.3688
	--> Final training Epoch [33/100], Loss: 0.3621
	--> Final training Epoch [34/100], Loss: 0.3636
	--> Final training Epoch [35/100], Loss: 0.3388
	--> Final training Epoch [36/100], Loss: 0.3548
	--> Final training Epoch [37/100], Loss: 0.3540
	--> Final training Epoch [38/100], Loss: 0.3432
	--> Final training Epoch [39/100], Loss: 0.3727
	--> Final training Epoch [40/100], Loss: 0.2994
	--> Final training Epoch [41/100], Loss: 0.3194
	--> Final training Epoch [42/100], Loss: 0.3083
	--> Final training Epoch [43/100], Loss: 0.3333
	--> Final training Epoch [44/100], Loss: 0.2979
	--> Final training Epoch [45/100], Loss: 0.3085
	--> Final training Epoch [46/100], Loss: 0.2752
	--> Final training Epoch [47/100], Loss: 0.2825
	--> Final training Epoch [48/100], Loss: 0.2736
	--> Final training Epoch [49/100], Loss: 0.2724
	--> Final training Epoch [50/100], Loss: 0.2734
	--> Final training Epoch [51/100], Loss: 0.2726
	--> Final training Epoch [52/100], Loss: 0.2898
	--> Final training Epoch [53/100], Loss: 0.2415
	--> Final training Epoch [54/100], Loss: 0.2434
	--> Final training Epoch [55/100], Loss: 0.2537
	--> Final training Epoch [56/100], Loss: 0.2412
	--> Final training Epoch [57/100], Loss: 0.2304
	--> Final training Epoch [58/100], Loss: 0.2340
	--> Final training Epoch [59/100], Loss: 0.2357
	--> Final training Epoch [60/100], Loss: 0.2617
	--> Final training Epoch [61/100], Loss: 0.2192
	--> Final training Epoch [62/100], Loss: 0.2272
	--> Final training Epoch [63/100], Loss: 0.2188
	--> Final training Epoch [64/100], Loss: 0.2212
	--> Final training Epoch [65/100], Loss: 0.2104
	--> Final training Epoch [66/100], Loss: 0.2007
	--> Final training Epoch [67/100], Loss: 0.2100
	--> Final training Epoch [68/100], Loss: 0.2176
	--> Final training Epoch [69/100], Loss: 0.2316
	--> Final training Epoch [70/100], Loss: 0.2149
	--> Final training Epoch [71/100], Loss: 0.2122
	--> Final training Epoch [72/100], Loss: 0.1836
	--> Final training Epoch [73/100], Loss: 0.1844
	--> Final training Epoch [74/100], Loss: 0.1723
	--> Final training Epoch [75/100], Loss: 0.1967
	--> Final training Epoch [76/100], Loss: 0.2036
	--> Final training Epoch [77/100], Loss: 0.2000
	--> Final training Epoch [78/100], Loss: 0.1781
	--> Final training Epoch [79/100], Loss: 0.1558
	--> Final training Epoch [80/100], Loss: 0.1848
	--> Final training Epoch [81/100], Loss: 0.1710
	--> Final training Epoch [82/100], Loss: 0.1879
	--> Final training Epoch [83/100], Loss: 0.1867
	--> Final training Epoch [84/100], Loss: 0.1519
	--> Final training Epoch [85/100], Loss: 0.1538
	--> Final training Epoch [86/100], Loss: 0.1660
	--> Final training Epoch [87/100], Loss: 0.1635
	--> Final training Epoch [88/100], Loss: 0.1548
	--> Final training Epoch [89/100], Loss: 0.1576
	--> Final training Epoch [90/100], Loss: 0.1448
	--> Final training Epoch [91/100], Loss: 0.1513
	--> Final training Epoch [92/100], Loss: 0.1833
	--> Final training Epoch [93/100], Loss: 0.1395
	--> Final training Epoch [94/100], Loss: 0.1469
	--> Final training Epoch [95/100], Loss: 0.1268
	--> Final training Epoch [96/100], Loss: 0.1438
	--> Final training Epoch [97/100], Loss: 0.1650
	--> Final training Epoch [98/100], Loss: 0.1010
	--> Final training Epoch [99/100], Loss: 0.1402
	--> Final training Epoch [100/100], Loss: 0.1321

Final training took 0.36461687088012695 sec

TESTING
	--> Testing took 0.0085 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8154
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3443,  Current Best Accuracy: 0.8807,  Current Best Validation Loss: 0.3443

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8152, Validation Loss: 0.6464
	--> Epoch [2/100], Loss: 0.8090, Validation Loss: 0.6359
	--> Epoch [3/100], Loss: 0.7972, Validation Loss: 0.6234
	--> Epoch [4/100], Loss: 0.7699, Validation Loss: 0.6124
	--> Epoch [5/100], Loss: 0.7550, Validation Loss: 0.6029
	--> Epoch [6/100], Loss: 0.7283, Validation Loss: 0.5937
	--> Epoch [7/100], Loss: 0.7319, Validation Loss: 0.5834
	--> Epoch [8/100], Loss: 0.7434, Validation Loss: 0.5738
	--> Epoch [9/100], Loss: 0.7015, Validation Loss: 0.5655
	--> Epoch [10/100], Loss: 0.7078, Validation Loss: 0.5574
	--> Epoch [11/100], Loss: 0.6724, Validation Loss: 0.5473
	--> Epoch [12/100], Loss: 0.6886, Validation Loss: 0.5400
	--> Epoch [13/100], Loss: 0.6520, Validation Loss: 0.5314
	--> Epoch [14/100], Loss: 0.6297, Validation Loss: 0.5232
	--> Epoch [15/100], Loss: 0.6231, Validation Loss: 0.5148
	--> Epoch [16/100], Loss: 0.6185, Validation Loss: 0.5082
	--> Epoch [17/100], Loss: 0.6010, Validation Loss: 0.4992
	--> Epoch [18/100], Loss: 0.5823, Validation Loss: 0.4903
	--> Epoch [19/100], Loss: 0.5711, Validation Loss: 0.4814
	--> Epoch [20/100], Loss: 0.5818, Validation Loss: 0.4728
	--> Epoch [21/100], Loss: 0.5511, Validation Loss: 0.4652
	--> Epoch [22/100], Loss: 0.5523, Validation Loss: 0.4594
	--> Epoch [23/100], Loss: 0.5296, Validation Loss: 0.4528
	--> Epoch [24/100], Loss: 0.5253, Validation Loss: 0.4469
	--> Epoch [25/100], Loss: 0.4972, Validation Loss: 0.4423
	--> Epoch [26/100], Loss: 0.4876, Validation Loss: 0.4358
	--> Epoch [27/100], Loss: 0.4687, Validation Loss: 0.4300
	--> Epoch [28/100], Loss: 0.4821, Validation Loss: 0.4251
	--> Epoch [29/100], Loss: 0.4569, Validation Loss: 0.4204
	--> Epoch [30/100], Loss: 0.4537, Validation Loss: 0.4149
	--> Epoch [31/100], Loss: 0.4245, Validation Loss: 0.4098
	--> Epoch [32/100], Loss: 0.4747, Validation Loss: 0.4065
	--> Epoch [33/100], Loss: 0.4360, Validation Loss: 0.4025
	--> Epoch [34/100], Loss: 0.4440, Validation Loss: 0.4003
	--> Epoch [35/100], Loss: 0.4142, Validation Loss: 0.3960
	--> Epoch [36/100], Loss: 0.4336, Validation Loss: 0.3908
	--> Epoch [37/100], Loss: 0.4368, Validation Loss: 0.3873
	--> Epoch [38/100], Loss: 0.4490, Validation Loss: 0.3836
	--> Epoch [39/100], Loss: 0.4002, Validation Loss: 0.3789
	--> Epoch [40/100], Loss: 0.4028, Validation Loss: 0.3753
	--> Epoch [41/100], Loss: 0.3742, Validation Loss: 0.3726
	--> Epoch [42/100], Loss: 0.3487, Validation Loss: 0.3693
	--> Epoch [43/100], Loss: 0.4083, Validation Loss: 0.3664
	--> Epoch [44/100], Loss: 0.3774, Validation Loss: 0.3634
	--> Epoch [45/100], Loss: 0.3849, Validation Loss: 0.3600
	--> Epoch [46/100], Loss: 0.3558, Validation Loss: 0.3565
	--> Epoch [47/100], Loss: 0.3507, Validation Loss: 0.3554
	--> Epoch [48/100], Loss: 0.3654, Validation Loss: 0.3514
	--> Epoch [49/100], Loss: 0.3522, Validation Loss: 0.3494
	--> Epoch [50/100], Loss: 0.3602, Validation Loss: 0.3476
	--> Epoch [51/100], Loss: 0.3552, Validation Loss: 0.3446
	--> Epoch [52/100], Loss: 0.3002, Validation Loss: 0.3429
	--> Epoch [53/100], Loss: 0.3373, Validation Loss: 0.3396
	--> Epoch [54/100], Loss: 0.2882, Validation Loss: 0.3378
	--> Epoch [55/100], Loss: 0.3155, Validation Loss: 0.3358
	--> Epoch [56/100], Loss: 0.3029, Validation Loss: 0.3327
	--> Epoch [57/100], Loss: 0.3228, Validation Loss: 0.3287
	--> Epoch [58/100], Loss: 0.2953, Validation Loss: 0.3273
	--> Epoch [59/100], Loss: 0.3463, Validation Loss: 0.3255
	--> Epoch [60/100], Loss: 0.2428, Validation Loss: 0.3239
	--> Epoch [61/100], Loss: 0.2824, Validation Loss: 0.3223
	--> Epoch [62/100], Loss: 0.2771, Validation Loss: 0.3199
	--> Epoch [63/100], Loss: 0.3198, Validation Loss: 0.3174
	--> Epoch [64/100], Loss: 0.2712, Validation Loss: 0.3166
	--> Epoch [65/100], Loss: 0.3000, Validation Loss: 0.3146
	--> Epoch [66/100], Loss: 0.3038, Validation Loss: 0.3127
	--> Epoch [67/100], Loss: 0.2423, Validation Loss: 0.3108
	--> Epoch [68/100], Loss: 0.2673, Validation Loss: 0.3093
	--> Epoch [69/100], Loss: 0.2953, Validation Loss: 0.3074
	--> Epoch [70/100], Loss: 0.2274, Validation Loss: 0.3058
	--> Epoch [71/100], Loss: 0.2765, Validation Loss: 0.3044
	--> Epoch [72/100], Loss: 0.3136, Validation Loss: 0.3020
	--> Epoch [73/100], Loss: 0.2815, Validation Loss: 0.3013
	--> Epoch [74/100], Loss: 0.2220, Validation Loss: 0.2984
	--> Epoch [75/100], Loss: 0.2482, Validation Loss: 0.2963
	--> Epoch [76/100], Loss: 0.2760, Validation Loss: 0.2949
	--> Epoch [77/100], Loss: 0.2530, Validation Loss: 0.2923
	--> Epoch [78/100], Loss: 0.2229, Validation Loss: 0.2916
	--> Epoch [79/100], Loss: 0.2506, Validation Loss: 0.2909
	--> Epoch [80/100], Loss: 0.2296, Validation Loss: 0.2899
	--> Epoch [81/100], Loss: 0.1992, Validation Loss: 0.2877
	--> Epoch [82/100], Loss: 0.2495, Validation Loss: 0.2872
	--> Epoch [83/100], Loss: 0.2134, Validation Loss: 0.2851
	--> Epoch [84/100], Loss: 0.2264, Validation Loss: 0.2829
	--> Epoch [85/100], Loss: 0.2113, Validation Loss: 0.2819
	--> Epoch [86/100], Loss: 0.2543, Validation Loss: 0.2814
	--> Epoch [87/100], Loss: 0.2134, Validation Loss: 0.2801
	--> Epoch [88/100], Loss: 0.2311, Validation Loss: 0.2783
	--> Epoch [89/100], Loss: 0.2502, Validation Loss: 0.2757
	--> Epoch [90/100], Loss: 0.1786, Validation Loss: 0.2743
	--> Epoch [91/100], Loss: 0.2251, Validation Loss: 0.2730
	--> Epoch [92/100], Loss: 0.1826, Validation Loss: 0.2722
	--> Epoch [93/100], Loss: 0.2137, Validation Loss: 0.2709
	--> Epoch [94/100], Loss: 0.1910, Validation Loss: 0.2692
	--> Epoch [95/100], Loss: 0.2153, Validation Loss: 0.2669
	--> Epoch [96/100], Loss: 0.2464, Validation Loss: 0.2647
	--> Epoch [97/100], Loss: 0.1916, Validation Loss: 0.2637
	--> Epoch [98/100], Loss: 0.1714, Validation Loss: 0.2625
	--> Epoch [99/100], Loss: 0.2419, Validation Loss: 0.2623
	--> Epoch [100/100], Loss: 0.1749, Validation Loss: 0.2609
	--> Training for Fold 1 took 0.4695587158203125 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7006, Validation Loss: 0.6513
	--> Epoch [2/100], Loss: 0.6818, Validation Loss: 0.6392
	--> Epoch [3/100], Loss: 0.6714, Validation Loss: 0.6271
	--> Epoch [4/100], Loss: 0.6640, Validation Loss: 0.6153
	--> Epoch [5/100], Loss: 0.6358, Validation Loss: 0.6035
	--> Epoch [6/100], Loss: 0.6449, Validation Loss: 0.5914
	--> Epoch [7/100], Loss: 0.6247, Validation Loss: 0.5799
	--> Epoch [8/100], Loss: 0.6143, Validation Loss: 0.5700
	--> Epoch [9/100], Loss: 0.6051, Validation Loss: 0.5585
	--> Epoch [10/100], Loss: 0.5903, Validation Loss: 0.5481
	--> Epoch [11/100], Loss: 0.5886, Validation Loss: 0.5386
	--> Epoch [12/100], Loss: 0.5727, Validation Loss: 0.5271
	--> Epoch [13/100], Loss: 0.5587, Validation Loss: 0.5176
	--> Epoch [14/100], Loss: 0.5486, Validation Loss: 0.5068
	--> Epoch [15/100], Loss: 0.5437, Validation Loss: 0.4977
	--> Epoch [16/100], Loss: 0.5443, Validation Loss: 0.4905
	--> Epoch [17/100], Loss: 0.5191, Validation Loss: 0.4814
	--> Epoch [18/100], Loss: 0.5209, Validation Loss: 0.4743
	--> Epoch [19/100], Loss: 0.4942, Validation Loss: 0.4677
	--> Epoch [20/100], Loss: 0.4763, Validation Loss: 0.4599
	--> Epoch [21/100], Loss: 0.4782, Validation Loss: 0.4531
	--> Epoch [22/100], Loss: 0.4953, Validation Loss: 0.4466
	--> Epoch [23/100], Loss: 0.4596, Validation Loss: 0.4388
	--> Epoch [24/100], Loss: 0.4702, Validation Loss: 0.4311
	--> Epoch [25/100], Loss: 0.4508, Validation Loss: 0.4235
	--> Epoch [26/100], Loss: 0.4482, Validation Loss: 0.4173
	--> Epoch [27/100], Loss: 0.4470, Validation Loss: 0.4126
	--> Epoch [28/100], Loss: 0.4307, Validation Loss: 0.4071
	--> Epoch [29/100], Loss: 0.4184, Validation Loss: 0.4017
	--> Epoch [30/100], Loss: 0.4225, Validation Loss: 0.3962
	--> Epoch [31/100], Loss: 0.4219, Validation Loss: 0.3921
	--> Epoch [32/100], Loss: 0.3979, Validation Loss: 0.3868
	--> Epoch [33/100], Loss: 0.4005, Validation Loss: 0.3830
	--> Epoch [34/100], Loss: 0.3628, Validation Loss: 0.3788
	--> Epoch [35/100], Loss: 0.3623, Validation Loss: 0.3744
	--> Epoch [36/100], Loss: 0.3605, Validation Loss: 0.3702
	--> Epoch [37/100], Loss: 0.3392, Validation Loss: 0.3662
	--> Epoch [38/100], Loss: 0.3272, Validation Loss: 0.3630
	--> Epoch [39/100], Loss: 0.3521, Validation Loss: 0.3605
	--> Epoch [40/100], Loss: 0.3529, Validation Loss: 0.3575
	--> Epoch [41/100], Loss: 0.3307, Validation Loss: 0.3548
	--> Epoch [42/100], Loss: 0.3164, Validation Loss: 0.3521
	--> Epoch [43/100], Loss: 0.3169, Validation Loss: 0.3500
	--> Epoch [44/100], Loss: 0.3389, Validation Loss: 0.3479
	--> Epoch [45/100], Loss: 0.2985, Validation Loss: 0.3455
	--> Epoch [46/100], Loss: 0.3172, Validation Loss: 0.3440
	--> Epoch [47/100], Loss: 0.2930, Validation Loss: 0.3414
	--> Epoch [48/100], Loss: 0.2979, Validation Loss: 0.3386
	--> Epoch [49/100], Loss: 0.2938, Validation Loss: 0.3372
	--> Epoch [50/100], Loss: 0.2564, Validation Loss: 0.3343
	--> Epoch [51/100], Loss: 0.2935, Validation Loss: 0.3321
	--> Epoch [52/100], Loss: 0.2833, Validation Loss: 0.3298
	--> Epoch [53/100], Loss: 0.2682, Validation Loss: 0.3279
	--> Epoch [54/100], Loss: 0.2321, Validation Loss: 0.3264
	--> Epoch [55/100], Loss: 0.2382, Validation Loss: 0.3244
	--> Epoch [56/100], Loss: 0.2429, Validation Loss: 0.3236
	--> Epoch [57/100], Loss: 0.2277, Validation Loss: 0.3225
	--> Epoch [58/100], Loss: 0.2301, Validation Loss: 0.3210
	--> Epoch [59/100], Loss: 0.2380, Validation Loss: 0.3203
	--> Epoch [60/100], Loss: 0.2513, Validation Loss: 0.3186
	--> Epoch [61/100], Loss: 0.2194, Validation Loss: 0.3173
	--> Epoch [62/100], Loss: 0.2220, Validation Loss: 0.3156
	--> Epoch [63/100], Loss: 0.2371, Validation Loss: 0.3139
	--> Epoch [64/100], Loss: 0.2271, Validation Loss: 0.3131
	--> Epoch [65/100], Loss: 0.2199, Validation Loss: 0.3118
	--> Epoch [66/100], Loss: 0.2106, Validation Loss: 0.3102
	--> Epoch [67/100], Loss: 0.2102, Validation Loss: 0.3085
	--> Epoch [68/100], Loss: 0.2273, Validation Loss: 0.3079
	--> Epoch [69/100], Loss: 0.2129, Validation Loss: 0.3072
	--> Epoch [70/100], Loss: 0.1849, Validation Loss: 0.3051
	--> Epoch [71/100], Loss: 0.2015, Validation Loss: 0.3049
	--> Epoch [72/100], Loss: 0.1909, Validation Loss: 0.3039
	--> Epoch [73/100], Loss: 0.1975, Validation Loss: 0.3037
	--> Epoch [74/100], Loss: 0.1909, Validation Loss: 0.3034
	--> Epoch [75/100], Loss: 0.1604, Validation Loss: 0.3025
	--> Epoch [76/100], Loss: 0.1697, Validation Loss: 0.3026
	--> Epoch [77/100], Loss: 0.2283, Validation Loss: 0.3019
	--> Epoch [78/100], Loss: 0.1797, Validation Loss: 0.3004
	--> Epoch [79/100], Loss: 0.1773, Validation Loss: 0.2994
	--> Epoch [80/100], Loss: 0.1923, Validation Loss: 0.2970
	--> Epoch [81/100], Loss: 0.1738, Validation Loss: 0.2969
	--> Epoch [82/100], Loss: 0.1870, Validation Loss: 0.2967
	--> Epoch [83/100], Loss: 0.2031, Validation Loss: 0.2951
	--> Epoch [84/100], Loss: 0.1774, Validation Loss: 0.2946
	--> Epoch [85/100], Loss: 0.1836, Validation Loss: 0.2949
	--> Epoch [86/100], Loss: 0.1900, Validation Loss: 0.2955
	--> Epoch [87/100], Loss: 0.1559, Validation Loss: 0.2962
Early stopping
	--> Training for Fold 2 took 0.3621494770050049 sec, using 87 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7354, Validation Loss: 0.7165
	--> Epoch [2/100], Loss: 0.7147, Validation Loss: 0.7089
	--> Epoch [3/100], Loss: 0.6911, Validation Loss: 0.7035
	--> Epoch [4/100], Loss: 0.6817, Validation Loss: 0.6940
	--> Epoch [5/100], Loss: 0.6505, Validation Loss: 0.6836
	--> Epoch [6/100], Loss: 0.6590, Validation Loss: 0.6756
	--> Epoch [7/100], Loss: 0.6479, Validation Loss: 0.6666
	--> Epoch [8/100], Loss: 0.6166, Validation Loss: 0.6560
	--> Epoch [9/100], Loss: 0.6055, Validation Loss: 0.6473
	--> Epoch [10/100], Loss: 0.5745, Validation Loss: 0.6337
	--> Epoch [11/100], Loss: 0.5659, Validation Loss: 0.6246
	--> Epoch [12/100], Loss: 0.5455, Validation Loss: 0.6118
	--> Epoch [13/100], Loss: 0.5235, Validation Loss: 0.6006
	--> Epoch [14/100], Loss: 0.5057, Validation Loss: 0.5907
	--> Epoch [15/100], Loss: 0.5088, Validation Loss: 0.5813
	--> Epoch [16/100], Loss: 0.4855, Validation Loss: 0.5710
	--> Epoch [17/100], Loss: 0.4761, Validation Loss: 0.5612
	--> Epoch [18/100], Loss: 0.4672, Validation Loss: 0.5520
	--> Epoch [19/100], Loss: 0.4814, Validation Loss: 0.5428
	--> Epoch [20/100], Loss: 0.4429, Validation Loss: 0.5358
	--> Epoch [21/100], Loss: 0.4321, Validation Loss: 0.5272
	--> Epoch [22/100], Loss: 0.4029, Validation Loss: 0.5183
	--> Epoch [23/100], Loss: 0.4207, Validation Loss: 0.5101
	--> Epoch [24/100], Loss: 0.3993, Validation Loss: 0.5016
	--> Epoch [25/100], Loss: 0.3970, Validation Loss: 0.4952
	--> Epoch [26/100], Loss: 0.3723, Validation Loss: 0.4879
	--> Epoch [27/100], Loss: 0.3614, Validation Loss: 0.4803
	--> Epoch [28/100], Loss: 0.3724, Validation Loss: 0.4742
	--> Epoch [29/100], Loss: 0.3495, Validation Loss: 0.4685
	--> Epoch [30/100], Loss: 0.3458, Validation Loss: 0.4621
	--> Epoch [31/100], Loss: 0.3601, Validation Loss: 0.4564
	--> Epoch [32/100], Loss: 0.3486, Validation Loss: 0.4512
	--> Epoch [33/100], Loss: 0.3618, Validation Loss: 0.4451
	--> Epoch [34/100], Loss: 0.3283, Validation Loss: 0.4402
	--> Epoch [35/100], Loss: 0.3351, Validation Loss: 0.4361
	--> Epoch [36/100], Loss: 0.3073, Validation Loss: 0.4321
	--> Epoch [37/100], Loss: 0.2844, Validation Loss: 0.4278
	--> Epoch [38/100], Loss: 0.2882, Validation Loss: 0.4238
	--> Epoch [39/100], Loss: 0.2915, Validation Loss: 0.4192
	--> Epoch [40/100], Loss: 0.2857, Validation Loss: 0.4166
	--> Epoch [41/100], Loss: 0.3032, Validation Loss: 0.4128
	--> Epoch [42/100], Loss: 0.2602, Validation Loss: 0.4089
	--> Epoch [43/100], Loss: 0.2547, Validation Loss: 0.4052
	--> Epoch [44/100], Loss: 0.2527, Validation Loss: 0.4014
	--> Epoch [45/100], Loss: 0.2668, Validation Loss: 0.3977
	--> Epoch [46/100], Loss: 0.2582, Validation Loss: 0.3926
	--> Epoch [47/100], Loss: 0.2313, Validation Loss: 0.3893
	--> Epoch [48/100], Loss: 0.2446, Validation Loss: 0.3873
	--> Epoch [49/100], Loss: 0.2462, Validation Loss: 0.3842
	--> Epoch [50/100], Loss: 0.2154, Validation Loss: 0.3810
	--> Epoch [51/100], Loss: 0.2057, Validation Loss: 0.3772
	--> Epoch [52/100], Loss: 0.2296, Validation Loss: 0.3751
	--> Epoch [53/100], Loss: 0.2177, Validation Loss: 0.3722
	--> Epoch [54/100], Loss: 0.2292, Validation Loss: 0.3690
	--> Epoch [55/100], Loss: 0.1925, Validation Loss: 0.3668
	--> Epoch [56/100], Loss: 0.1967, Validation Loss: 0.3643
	--> Epoch [57/100], Loss: 0.1922, Validation Loss: 0.3618
	--> Epoch [58/100], Loss: 0.2222, Validation Loss: 0.3596
	--> Epoch [59/100], Loss: 0.2041, Validation Loss: 0.3567
	--> Epoch [60/100], Loss: 0.1991, Validation Loss: 0.3546
	--> Epoch [61/100], Loss: 0.1978, Validation Loss: 0.3516
	--> Epoch [62/100], Loss: 0.1799, Validation Loss: 0.3499
	--> Epoch [63/100], Loss: 0.1808, Validation Loss: 0.3471
	--> Epoch [64/100], Loss: 0.1825, Validation Loss: 0.3453
	--> Epoch [65/100], Loss: 0.1852, Validation Loss: 0.3428
	--> Epoch [66/100], Loss: 0.1780, Validation Loss: 0.3411
	--> Epoch [67/100], Loss: 0.1799, Validation Loss: 0.3382
	--> Epoch [68/100], Loss: 0.1494, Validation Loss: 0.3368
	--> Epoch [69/100], Loss: 0.1527, Validation Loss: 0.3345
	--> Epoch [70/100], Loss: 0.1759, Validation Loss: 0.3329
	--> Epoch [71/100], Loss: 0.1900, Validation Loss: 0.3306
	--> Epoch [72/100], Loss: 0.1627, Validation Loss: 0.3288
	--> Epoch [73/100], Loss: 0.1622, Validation Loss: 0.3270
	--> Epoch [74/100], Loss: 0.1298, Validation Loss: 0.3252
	--> Epoch [75/100], Loss: 0.1453, Validation Loss: 0.3234
	--> Epoch [76/100], Loss: 0.1667, Validation Loss: 0.3226
	--> Epoch [77/100], Loss: 0.1594, Validation Loss: 0.3212
	--> Epoch [78/100], Loss: 0.1615, Validation Loss: 0.3190
	--> Epoch [79/100], Loss: 0.1380, Validation Loss: 0.3172
	--> Epoch [80/100], Loss: 0.1627, Validation Loss: 0.3154
	--> Epoch [81/100], Loss: 0.1471, Validation Loss: 0.3139
	--> Epoch [82/100], Loss: 0.1243, Validation Loss: 0.3122
	--> Epoch [83/100], Loss: 0.1212, Validation Loss: 0.3105
	--> Epoch [84/100], Loss: 0.1197, Validation Loss: 0.3089
	--> Epoch [85/100], Loss: 0.1251, Validation Loss: 0.3078
	--> Epoch [86/100], Loss: 0.1402, Validation Loss: 0.3064
	--> Epoch [87/100], Loss: 0.1196, Validation Loss: 0.3044
	--> Epoch [88/100], Loss: 0.1277, Validation Loss: 0.3036
	--> Epoch [89/100], Loss: 0.1008, Validation Loss: 0.3023
	--> Epoch [90/100], Loss: 0.1337, Validation Loss: 0.3009
	--> Epoch [91/100], Loss: 0.1325, Validation Loss: 0.3001
	--> Epoch [92/100], Loss: 0.1001, Validation Loss: 0.2991
	--> Epoch [93/100], Loss: 0.1179, Validation Loss: 0.2976
	--> Epoch [94/100], Loss: 0.1029, Validation Loss: 0.2957
	--> Epoch [95/100], Loss: 0.1018, Validation Loss: 0.2945
	--> Epoch [96/100], Loss: 0.1230, Validation Loss: 0.2919
	--> Epoch [97/100], Loss: 0.1069, Validation Loss: 0.2906
	--> Epoch [98/100], Loss: 0.1070, Validation Loss: 0.2902
	--> Epoch [99/100], Loss: 0.1047, Validation Loss: 0.2895
	--> Epoch [100/100], Loss: 0.0894, Validation Loss: 0.2884
	--> Training for Fold 3 took 0.39149022102355957 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7038, Validation Loss: 0.6121
	--> Epoch [2/100], Loss: 0.6842, Validation Loss: 0.6036
	--> Epoch [3/100], Loss: 0.6846, Validation Loss: 0.5940
	--> Epoch [4/100], Loss: 0.6646, Validation Loss: 0.5868
	--> Epoch [5/100], Loss: 0.6534, Validation Loss: 0.5822
	--> Epoch [6/100], Loss: 0.6233, Validation Loss: 0.5765
	--> Epoch [7/100], Loss: 0.6212, Validation Loss: 0.5700
	--> Epoch [8/100], Loss: 0.5853, Validation Loss: 0.5620
	--> Epoch [9/100], Loss: 0.5865, Validation Loss: 0.5552
	--> Epoch [10/100], Loss: 0.5818, Validation Loss: 0.5500
	--> Epoch [11/100], Loss: 0.5699, Validation Loss: 0.5438
	--> Epoch [12/100], Loss: 0.5518, Validation Loss: 0.5373
	--> Epoch [13/100], Loss: 0.5451, Validation Loss: 0.5310
	--> Epoch [14/100], Loss: 0.5381, Validation Loss: 0.5264
	--> Epoch [15/100], Loss: 0.5329, Validation Loss: 0.5204
	--> Epoch [16/100], Loss: 0.5244, Validation Loss: 0.5118
	--> Epoch [17/100], Loss: 0.5035, Validation Loss: 0.5063
	--> Epoch [18/100], Loss: 0.4890, Validation Loss: 0.5013
	--> Epoch [19/100], Loss: 0.4897, Validation Loss: 0.4979
	--> Epoch [20/100], Loss: 0.4732, Validation Loss: 0.4939
	--> Epoch [21/100], Loss: 0.4729, Validation Loss: 0.4891
	--> Epoch [22/100], Loss: 0.4630, Validation Loss: 0.4855
	--> Epoch [23/100], Loss: 0.4365, Validation Loss: 0.4817
	--> Epoch [24/100], Loss: 0.4323, Validation Loss: 0.4753
	--> Epoch [25/100], Loss: 0.4087, Validation Loss: 0.4676
	--> Epoch [26/100], Loss: 0.4111, Validation Loss: 0.4630
	--> Epoch [27/100], Loss: 0.4070, Validation Loss: 0.4581
	--> Epoch [28/100], Loss: 0.3929, Validation Loss: 0.4548
	--> Epoch [29/100], Loss: 0.4093, Validation Loss: 0.4508
	--> Epoch [30/100], Loss: 0.3804, Validation Loss: 0.4461
	--> Epoch [31/100], Loss: 0.3912, Validation Loss: 0.4434
	--> Epoch [32/100], Loss: 0.3985, Validation Loss: 0.4400
	--> Epoch [33/100], Loss: 0.3776, Validation Loss: 0.4356
	--> Epoch [34/100], Loss: 0.3569, Validation Loss: 0.4318
	--> Epoch [35/100], Loss: 0.3589, Validation Loss: 0.4254
	--> Epoch [36/100], Loss: 0.3170, Validation Loss: 0.4211
	--> Epoch [37/100], Loss: 0.3126, Validation Loss: 0.4168
	--> Epoch [38/100], Loss: 0.3182, Validation Loss: 0.4119
	--> Epoch [39/100], Loss: 0.3446, Validation Loss: 0.4096
	--> Epoch [40/100], Loss: 0.3072, Validation Loss: 0.4052
	--> Epoch [41/100], Loss: 0.3367, Validation Loss: 0.4010
	--> Epoch [42/100], Loss: 0.2935, Validation Loss: 0.3981
	--> Epoch [43/100], Loss: 0.2938, Validation Loss: 0.3950
	--> Epoch [44/100], Loss: 0.2696, Validation Loss: 0.3899
	--> Epoch [45/100], Loss: 0.2992, Validation Loss: 0.3885
	--> Epoch [46/100], Loss: 0.2670, Validation Loss: 0.3842
	--> Epoch [47/100], Loss: 0.2684, Validation Loss: 0.3820
	--> Epoch [48/100], Loss: 0.2376, Validation Loss: 0.3782
	--> Epoch [49/100], Loss: 0.2595, Validation Loss: 0.3755
	--> Epoch [50/100], Loss: 0.2355, Validation Loss: 0.3735
	--> Epoch [51/100], Loss: 0.2218, Validation Loss: 0.3732
	--> Epoch [52/100], Loss: 0.2525, Validation Loss: 0.3687
	--> Epoch [53/100], Loss: 0.2212, Validation Loss: 0.3658
	--> Epoch [54/100], Loss: 0.2190, Validation Loss: 0.3656
	--> Epoch [55/100], Loss: 0.2452, Validation Loss: 0.3644
	--> Epoch [56/100], Loss: 0.2643, Validation Loss: 0.3614
	--> Epoch [57/100], Loss: 0.1998, Validation Loss: 0.3607
	--> Epoch [58/100], Loss: 0.1795, Validation Loss: 0.3582
	--> Epoch [59/100], Loss: 0.1790, Validation Loss: 0.3576
	--> Epoch [60/100], Loss: 0.2038, Validation Loss: 0.3556
	--> Epoch [61/100], Loss: 0.1883, Validation Loss: 0.3547
	--> Epoch [62/100], Loss: 0.1984, Validation Loss: 0.3536
	--> Epoch [63/100], Loss: 0.2008, Validation Loss: 0.3506
	--> Epoch [64/100], Loss: 0.1684, Validation Loss: 0.3510
	--> Epoch [65/100], Loss: 0.1994, Validation Loss: 0.3480
	--> Epoch [66/100], Loss: 0.1776, Validation Loss: 0.3461
	--> Epoch [67/100], Loss: 0.1966, Validation Loss: 0.3444
	--> Epoch [68/100], Loss: 0.1777, Validation Loss: 0.3428
	--> Epoch [69/100], Loss: 0.1755, Validation Loss: 0.3419
	--> Epoch [70/100], Loss: 0.1613, Validation Loss: 0.3412
	--> Epoch [71/100], Loss: 0.1737, Validation Loss: 0.3400
	--> Epoch [72/100], Loss: 0.1681, Validation Loss: 0.3396
	--> Epoch [73/100], Loss: 0.1448, Validation Loss: 0.3374
	--> Epoch [74/100], Loss: 0.1554, Validation Loss: 0.3364
	--> Epoch [75/100], Loss: 0.1609, Validation Loss: 0.3351
	--> Epoch [76/100], Loss: 0.1271, Validation Loss: 0.3337
	--> Epoch [77/100], Loss: 0.1441, Validation Loss: 0.3319
	--> Epoch [78/100], Loss: 0.1205, Validation Loss: 0.3327
	--> Epoch [79/100], Loss: 0.1514, Validation Loss: 0.3309
	--> Epoch [80/100], Loss: 0.1458, Validation Loss: 0.3302
	--> Epoch [81/100], Loss: 0.1513, Validation Loss: 0.3293
	--> Epoch [82/100], Loss: 0.1542, Validation Loss: 0.3284
	--> Epoch [83/100], Loss: 0.1347, Validation Loss: 0.3274
	--> Epoch [84/100], Loss: 0.1344, Validation Loss: 0.3274
	--> Epoch [85/100], Loss: 0.1361, Validation Loss: 0.3251
	--> Epoch [86/100], Loss: 0.1271, Validation Loss: 0.3248
	--> Epoch [87/100], Loss: 0.1385, Validation Loss: 0.3251
	--> Epoch [88/100], Loss: 0.1244, Validation Loss: 0.3244
	--> Epoch [89/100], Loss: 0.1021, Validation Loss: 0.3248
	--> Epoch [90/100], Loss: 0.1204, Validation Loss: 0.3244
	--> Epoch [91/100], Loss: 0.1359, Validation Loss: 0.3232
	--> Epoch [92/100], Loss: 0.1281, Validation Loss: 0.3215
	--> Epoch [93/100], Loss: 0.1185, Validation Loss: 0.3215
	--> Epoch [94/100], Loss: 0.1202, Validation Loss: 0.3199
	--> Epoch [95/100], Loss: 0.1383, Validation Loss: 0.3188
	--> Epoch [96/100], Loss: 0.1069, Validation Loss: 0.3192
	--> Epoch [97/100], Loss: 0.1374, Validation Loss: 0.3185
	--> Epoch [98/100], Loss: 0.1152, Validation Loss: 0.3192
	--> Epoch [99/100], Loss: 0.1038, Validation Loss: 0.3193
	--> Epoch [100/100], Loss: 0.0861, Validation Loss: 0.3200
Early stopping
	--> Training for Fold 4 took 0.45769238471984863 sec, using 100 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7312, Validation Loss: 0.6990
	--> Epoch [2/100], Loss: 0.6878, Validation Loss: 0.6936
	--> Epoch [3/100], Loss: 0.6719, Validation Loss: 0.6877
	--> Epoch [4/100], Loss: 0.6544, Validation Loss: 0.6819
	--> Epoch [5/100], Loss: 0.6352, Validation Loss: 0.6768
	--> Epoch [6/100], Loss: 0.5953, Validation Loss: 0.6716
	--> Epoch [7/100], Loss: 0.6059, Validation Loss: 0.6677
	--> Epoch [8/100], Loss: 0.5698, Validation Loss: 0.6626
	--> Epoch [9/100], Loss: 0.5560, Validation Loss: 0.6566
	--> Epoch [10/100], Loss: 0.5394, Validation Loss: 0.6541
	--> Epoch [11/100], Loss: 0.5334, Validation Loss: 0.6500
	--> Epoch [12/100], Loss: 0.5191, Validation Loss: 0.6462
	--> Epoch [13/100], Loss: 0.4916, Validation Loss: 0.6423
	--> Epoch [14/100], Loss: 0.4687, Validation Loss: 0.6387
	--> Epoch [15/100], Loss: 0.4936, Validation Loss: 0.6356
	--> Epoch [16/100], Loss: 0.4673, Validation Loss: 0.6313
	--> Epoch [17/100], Loss: 0.4443, Validation Loss: 0.6292
	--> Epoch [18/100], Loss: 0.4404, Validation Loss: 0.6262
	--> Epoch [19/100], Loss: 0.4273, Validation Loss: 0.6233
	--> Epoch [20/100], Loss: 0.4221, Validation Loss: 0.6209
	--> Epoch [21/100], Loss: 0.4132, Validation Loss: 0.6203
	--> Epoch [22/100], Loss: 0.3912, Validation Loss: 0.6195
	--> Epoch [23/100], Loss: 0.3995, Validation Loss: 0.6155
	--> Epoch [24/100], Loss: 0.3826, Validation Loss: 0.6127
	--> Epoch [25/100], Loss: 0.3479, Validation Loss: 0.6113
	--> Epoch [26/100], Loss: 0.3621, Validation Loss: 0.6098
	--> Epoch [27/100], Loss: 0.3523, Validation Loss: 0.6093
	--> Epoch [28/100], Loss: 0.3521, Validation Loss: 0.6075
	--> Epoch [29/100], Loss: 0.3239, Validation Loss: 0.6070
	--> Epoch [30/100], Loss: 0.3544, Validation Loss: 0.6061
	--> Epoch [31/100], Loss: 0.3313, Validation Loss: 0.6045
	--> Epoch [32/100], Loss: 0.3283, Validation Loss: 0.6032
	--> Epoch [33/100], Loss: 0.3039, Validation Loss: 0.6025
	--> Epoch [34/100], Loss: 0.2906, Validation Loss: 0.6022
	--> Epoch [35/100], Loss: 0.3053, Validation Loss: 0.6014
	--> Epoch [36/100], Loss: 0.2910, Validation Loss: 0.5994
	--> Epoch [37/100], Loss: 0.2634, Validation Loss: 0.5988
	--> Epoch [38/100], Loss: 0.2831, Validation Loss: 0.5954
	--> Epoch [39/100], Loss: 0.2854, Validation Loss: 0.5950
	--> Epoch [40/100], Loss: 0.2750, Validation Loss: 0.5947
	--> Epoch [41/100], Loss: 0.2303, Validation Loss: 0.5932
	--> Epoch [42/100], Loss: 0.2628, Validation Loss: 0.5911
	--> Epoch [43/100], Loss: 0.2578, Validation Loss: 0.5886
	--> Epoch [44/100], Loss: 0.2561, Validation Loss: 0.5888
	--> Epoch [45/100], Loss: 0.2412, Validation Loss: 0.5869
	--> Epoch [46/100], Loss: 0.2445, Validation Loss: 0.5854
	--> Epoch [47/100], Loss: 0.2112, Validation Loss: 0.5829
	--> Epoch [48/100], Loss: 0.2236, Validation Loss: 0.5838
	--> Epoch [49/100], Loss: 0.2192, Validation Loss: 0.5835
	--> Epoch [50/100], Loss: 0.2135, Validation Loss: 0.5822
	--> Epoch [51/100], Loss: 0.2303, Validation Loss: 0.5822
	--> Epoch [52/100], Loss: 0.2326, Validation Loss: 0.5795
	--> Epoch [53/100], Loss: 0.2161, Validation Loss: 0.5780
	--> Epoch [54/100], Loss: 0.2026, Validation Loss: 0.5794
	--> Epoch [55/100], Loss: 0.1972, Validation Loss: 0.5809
	--> Epoch [56/100], Loss: 0.1909, Validation Loss: 0.5812
Early stopping
	--> Training for Fold 5 took 0.22683143615722656 sec, using 56 epochs

Median number of epochs used: 100 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/100], Loss: 0.6892
	--> Final training Epoch [2/100], Loss: 0.6916
	--> Final training Epoch [3/100], Loss: 0.6501
	--> Final training Epoch [4/100], Loss: 0.6362
	--> Final training Epoch [5/100], Loss: 0.6272
	--> Final training Epoch [6/100], Loss: 0.6245
	--> Final training Epoch [7/100], Loss: 0.6081
	--> Final training Epoch [8/100], Loss: 0.6065
	--> Final training Epoch [9/100], Loss: 0.5851
	--> Final training Epoch [10/100], Loss: 0.5651
	--> Final training Epoch [11/100], Loss: 0.5621
	--> Final training Epoch [12/100], Loss: 0.5361
	--> Final training Epoch [13/100], Loss: 0.5276
	--> Final training Epoch [14/100], Loss: 0.5246
	--> Final training Epoch [15/100], Loss: 0.4974
	--> Final training Epoch [16/100], Loss: 0.4789
	--> Final training Epoch [17/100], Loss: 0.4955
	--> Final training Epoch [18/100], Loss: 0.4689
	--> Final training Epoch [19/100], Loss: 0.4615
	--> Final training Epoch [20/100], Loss: 0.4568
	--> Final training Epoch [21/100], Loss: 0.4508
	--> Final training Epoch [22/100], Loss: 0.4151
	--> Final training Epoch [23/100], Loss: 0.4485
	--> Final training Epoch [24/100], Loss: 0.4132
	--> Final training Epoch [25/100], Loss: 0.3992
	--> Final training Epoch [26/100], Loss: 0.3926
	--> Final training Epoch [27/100], Loss: 0.4051
	--> Final training Epoch [28/100], Loss: 0.4022
	--> Final training Epoch [29/100], Loss: 0.3992
	--> Final training Epoch [30/100], Loss: 0.3704
	--> Final training Epoch [31/100], Loss: 0.3628
	--> Final training Epoch [32/100], Loss: 0.3468
	--> Final training Epoch [33/100], Loss: 0.3652
	--> Final training Epoch [34/100], Loss: 0.3210
	--> Final training Epoch [35/100], Loss: 0.3327
	--> Final training Epoch [36/100], Loss: 0.3150
	--> Final training Epoch [37/100], Loss: 0.3057
	--> Final training Epoch [38/100], Loss: 0.3128
	--> Final training Epoch [39/100], Loss: 0.3172
	--> Final training Epoch [40/100], Loss: 0.3027
	--> Final training Epoch [41/100], Loss: 0.3117
	--> Final training Epoch [42/100], Loss: 0.2633
	--> Final training Epoch [43/100], Loss: 0.2842
	--> Final training Epoch [44/100], Loss: 0.3091
	--> Final training Epoch [45/100], Loss: 0.2678
	--> Final training Epoch [46/100], Loss: 0.2825
	--> Final training Epoch [47/100], Loss: 0.2958
	--> Final training Epoch [48/100], Loss: 0.2793
	--> Final training Epoch [49/100], Loss: 0.2405
	--> Final training Epoch [50/100], Loss: 0.2485
	--> Final training Epoch [51/100], Loss: 0.2448
	--> Final training Epoch [52/100], Loss: 0.2280
	--> Final training Epoch [53/100], Loss: 0.2256
	--> Final training Epoch [54/100], Loss: 0.2357
	--> Final training Epoch [55/100], Loss: 0.2152
	--> Final training Epoch [56/100], Loss: 0.2303
	--> Final training Epoch [57/100], Loss: 0.2151
	--> Final training Epoch [58/100], Loss: 0.2175
	--> Final training Epoch [59/100], Loss: 0.2160
	--> Final training Epoch [60/100], Loss: 0.2137
	--> Final training Epoch [61/100], Loss: 0.2063
	--> Final training Epoch [62/100], Loss: 0.2115
	--> Final training Epoch [63/100], Loss: 0.2190
	--> Final training Epoch [64/100], Loss: 0.1871
	--> Final training Epoch [65/100], Loss: 0.1927
	--> Final training Epoch [66/100], Loss: 0.2088
	--> Final training Epoch [67/100], Loss: 0.1744
	--> Final training Epoch [68/100], Loss: 0.1795
	--> Final training Epoch [69/100], Loss: 0.1706
	--> Final training Epoch [70/100], Loss: 0.1655
	--> Final training Epoch [71/100], Loss: 0.1814
	--> Final training Epoch [72/100], Loss: 0.1981
	--> Final training Epoch [73/100], Loss: 0.1614
	--> Final training Epoch [74/100], Loss: 0.1605
	--> Final training Epoch [75/100], Loss: 0.1621
	--> Final training Epoch [76/100], Loss: 0.1818
	--> Final training Epoch [77/100], Loss: 0.1384
	--> Final training Epoch [78/100], Loss: 0.1401
	--> Final training Epoch [79/100], Loss: 0.1752
	--> Final training Epoch [80/100], Loss: 0.1495
	--> Final training Epoch [81/100], Loss: 0.1788
	--> Final training Epoch [82/100], Loss: 0.1375
	--> Final training Epoch [83/100], Loss: 0.1732
	--> Final training Epoch [84/100], Loss: 0.1246
	--> Final training Epoch [85/100], Loss: 0.1292
	--> Final training Epoch [86/100], Loss: 0.1278
	--> Final training Epoch [87/100], Loss: 0.1570
	--> Final training Epoch [88/100], Loss: 0.1062
	--> Final training Epoch [89/100], Loss: 0.1355
	--> Final training Epoch [90/100], Loss: 0.1395
	--> Final training Epoch [91/100], Loss: 0.1230
	--> Final training Epoch [92/100], Loss: 0.1208
	--> Final training Epoch [93/100], Loss: 0.1398
	--> Final training Epoch [94/100], Loss: 0.1550
	--> Final training Epoch [95/100], Loss: 0.1214
	--> Final training Epoch [96/100], Loss: 0.1345
	--> Final training Epoch [97/100], Loss: 0.1313
	--> Final training Epoch [98/100], Loss: 0.1275
	--> Final training Epoch [99/100], Loss: 0.1064
	--> Final training Epoch [100/100], Loss: 0.1137

Final training took 0.3563053607940674 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.7179
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8918, Validation Loss: 0.3368,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3368
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3639,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3368
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8819, Validation Loss: 0.3483,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3368

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8236, Validation Loss: 0.7311
	--> Epoch [2/100], Loss: 0.7352, Validation Loss: 0.7095
	--> Epoch [3/100], Loss: 0.7346, Validation Loss: 0.6858
	--> Epoch [4/100], Loss: 0.7117, Validation Loss: 0.6681
	--> Epoch [5/100], Loss: 0.6692, Validation Loss: 0.6491
	--> Epoch [6/100], Loss: 0.6812, Validation Loss: 0.6396
	--> Epoch [7/100], Loss: 0.6340, Validation Loss: 0.6258
	--> Epoch [8/100], Loss: 0.6286, Validation Loss: 0.6093
	--> Epoch [9/100], Loss: 0.6084, Validation Loss: 0.5969
	--> Epoch [10/100], Loss: 0.6057, Validation Loss: 0.5854
	--> Epoch [11/100], Loss: 0.5854, Validation Loss: 0.5726
	--> Epoch [12/100], Loss: 0.5760, Validation Loss: 0.5607
	--> Epoch [13/100], Loss: 0.5796, Validation Loss: 0.5510
	--> Epoch [14/100], Loss: 0.5368, Validation Loss: 0.5401
	--> Epoch [15/100], Loss: 0.5168, Validation Loss: 0.5309
	--> Epoch [16/100], Loss: 0.5125, Validation Loss: 0.5238
	--> Epoch [17/100], Loss: 0.5523, Validation Loss: 0.5169
	--> Epoch [18/100], Loss: 0.4859, Validation Loss: 0.5087
	--> Epoch [19/100], Loss: 0.5083, Validation Loss: 0.5023
	--> Epoch [20/100], Loss: 0.4862, Validation Loss: 0.4963
	--> Epoch [21/100], Loss: 0.4660, Validation Loss: 0.4906
	--> Epoch [22/100], Loss: 0.4881, Validation Loss: 0.4861
	--> Epoch [23/100], Loss: 0.4996, Validation Loss: 0.4813
	--> Epoch [24/100], Loss: 0.4667, Validation Loss: 0.4775
	--> Epoch [25/100], Loss: 0.4373, Validation Loss: 0.4723
	--> Epoch [26/100], Loss: 0.4469, Validation Loss: 0.4675
	--> Epoch [27/100], Loss: 0.3974, Validation Loss: 0.4606
	--> Epoch [28/100], Loss: 0.4111, Validation Loss: 0.4541
	--> Epoch [29/100], Loss: 0.3914, Validation Loss: 0.4502
	--> Epoch [30/100], Loss: 0.4135, Validation Loss: 0.4454
	--> Epoch [31/100], Loss: 0.4151, Validation Loss: 0.4417
	--> Epoch [32/100], Loss: 0.3913, Validation Loss: 0.4374
	--> Epoch [33/100], Loss: 0.3881, Validation Loss: 0.4345
	--> Epoch [34/100], Loss: 0.3648, Validation Loss: 0.4306
	--> Epoch [35/100], Loss: 0.3918, Validation Loss: 0.4265
	--> Epoch [36/100], Loss: 0.3725, Validation Loss: 0.4229
	--> Epoch [37/100], Loss: 0.3783, Validation Loss: 0.4196
	--> Epoch [38/100], Loss: 0.3765, Validation Loss: 0.4149
	--> Epoch [39/100], Loss: 0.3406, Validation Loss: 0.4126
	--> Epoch [40/100], Loss: 0.3158, Validation Loss: 0.4085
	--> Epoch [41/100], Loss: 0.3287, Validation Loss: 0.4055
	--> Epoch [42/100], Loss: 0.3536, Validation Loss: 0.4017
	--> Epoch [43/100], Loss: 0.3309, Validation Loss: 0.3970
	--> Epoch [44/100], Loss: 0.3192, Validation Loss: 0.3943
	--> Epoch [45/100], Loss: 0.2683, Validation Loss: 0.3921
	--> Epoch [46/100], Loss: 0.3428, Validation Loss: 0.3901
	--> Epoch [47/100], Loss: 0.2920, Validation Loss: 0.3876
	--> Epoch [48/100], Loss: 0.3105, Validation Loss: 0.3845
	--> Epoch [49/100], Loss: 0.2644, Validation Loss: 0.3812
	--> Epoch [50/100], Loss: 0.2977, Validation Loss: 0.3791
	--> Epoch [51/100], Loss: 0.3045, Validation Loss: 0.3756
	--> Epoch [52/100], Loss: 0.3101, Validation Loss: 0.3734
	--> Epoch [53/100], Loss: 0.2580, Validation Loss: 0.3723
	--> Epoch [54/100], Loss: 0.2937, Validation Loss: 0.3700
	--> Epoch [55/100], Loss: 0.3014, Validation Loss: 0.3670
	--> Epoch [56/100], Loss: 0.2367, Validation Loss: 0.3644
	--> Epoch [57/100], Loss: 0.3011, Validation Loss: 0.3623
	--> Epoch [58/100], Loss: 0.2937, Validation Loss: 0.3602
	--> Epoch [59/100], Loss: 0.2858, Validation Loss: 0.3589
	--> Epoch [60/100], Loss: 0.2519, Validation Loss: 0.3567
	--> Epoch [61/100], Loss: 0.2936, Validation Loss: 0.3542
	--> Epoch [62/100], Loss: 0.2506, Validation Loss: 0.3525
	--> Epoch [63/100], Loss: 0.2450, Validation Loss: 0.3514
	--> Epoch [64/100], Loss: 0.2461, Validation Loss: 0.3507
	--> Epoch [65/100], Loss: 0.2447, Validation Loss: 0.3483
	--> Epoch [66/100], Loss: 0.2586, Validation Loss: 0.3470
	--> Epoch [67/100], Loss: 0.2213, Validation Loss: 0.3455
	--> Epoch [68/100], Loss: 0.2179, Validation Loss: 0.3427
	--> Epoch [69/100], Loss: 0.2563, Validation Loss: 0.3412
	--> Epoch [70/100], Loss: 0.2456, Validation Loss: 0.3403
	--> Epoch [71/100], Loss: 0.2312, Validation Loss: 0.3389
	--> Epoch [72/100], Loss: 0.2640, Validation Loss: 0.3377
	--> Epoch [73/100], Loss: 0.2779, Validation Loss: 0.3348
	--> Epoch [74/100], Loss: 0.2454, Validation Loss: 0.3334
	--> Epoch [75/100], Loss: 0.2073, Validation Loss: 0.3326
	--> Epoch [76/100], Loss: 0.2341, Validation Loss: 0.3316
	--> Epoch [77/100], Loss: 0.1878, Validation Loss: 0.3304
	--> Epoch [78/100], Loss: 0.2206, Validation Loss: 0.3295
	--> Epoch [79/100], Loss: 0.2246, Validation Loss: 0.3288
	--> Epoch [80/100], Loss: 0.2204, Validation Loss: 0.3273
	--> Epoch [81/100], Loss: 0.2290, Validation Loss: 0.3263
	--> Epoch [82/100], Loss: 0.2063, Validation Loss: 0.3260
	--> Epoch [83/100], Loss: 0.2283, Validation Loss: 0.3239
	--> Epoch [84/100], Loss: 0.1992, Validation Loss: 0.3246
	--> Epoch [85/100], Loss: 0.1894, Validation Loss: 0.3233
	--> Epoch [86/100], Loss: 0.1753, Validation Loss: 0.3229
	--> Epoch [87/100], Loss: 0.2261, Validation Loss: 0.3229
	--> Epoch [88/100], Loss: 0.1770, Validation Loss: 0.3222
	--> Epoch [89/100], Loss: 0.1841, Validation Loss: 0.3216
	--> Epoch [90/100], Loss: 0.2059, Validation Loss: 0.3210
	--> Epoch [91/100], Loss: 0.2383, Validation Loss: 0.3196
	--> Epoch [92/100], Loss: 0.2001, Validation Loss: 0.3197
	--> Epoch [93/100], Loss: 0.1899, Validation Loss: 0.3184
	--> Epoch [94/100], Loss: 0.1806, Validation Loss: 0.3179
	--> Epoch [95/100], Loss: 0.2040, Validation Loss: 0.3170
	--> Epoch [96/100], Loss: 0.2186, Validation Loss: 0.3158
	--> Epoch [97/100], Loss: 0.1761, Validation Loss: 0.3156
	--> Epoch [98/100], Loss: 0.2151, Validation Loss: 0.3134
	--> Epoch [99/100], Loss: 0.2078, Validation Loss: 0.3117
	--> Epoch [100/100], Loss: 0.1827, Validation Loss: 0.3095
	--> Training for Fold 1 took 0.3915724754333496 sec, using 100 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6627, Validation Loss: 0.6718
	--> Epoch [2/100], Loss: 0.7130, Validation Loss: 0.6603
	--> Epoch [3/100], Loss: 0.6696, Validation Loss: 0.6492
	--> Epoch [4/100], Loss: 0.6525, Validation Loss: 0.6330
	--> Epoch [5/100], Loss: 0.6675, Validation Loss: 0.6195
	--> Epoch [6/100], Loss: 0.6312, Validation Loss: 0.6064
	--> Epoch [7/100], Loss: 0.5815, Validation Loss: 0.5947
	--> Epoch [8/100], Loss: 0.5828, Validation Loss: 0.5830
	--> Epoch [9/100], Loss: 0.5710, Validation Loss: 0.5752
	--> Epoch [10/100], Loss: 0.5865, Validation Loss: 0.5648
	--> Epoch [11/100], Loss: 0.5199, Validation Loss: 0.5560
	--> Epoch [12/100], Loss: 0.5665, Validation Loss: 0.5464
	--> Epoch [13/100], Loss: 0.5353, Validation Loss: 0.5380
	--> Epoch [14/100], Loss: 0.5237, Validation Loss: 0.5307
	--> Epoch [15/100], Loss: 0.5243, Validation Loss: 0.5204
	--> Epoch [16/100], Loss: 0.4747, Validation Loss: 0.5105
	--> Epoch [17/100], Loss: 0.4795, Validation Loss: 0.5019
	--> Epoch [18/100], Loss: 0.4654, Validation Loss: 0.4924
	--> Epoch [19/100], Loss: 0.4627, Validation Loss: 0.4816
	--> Epoch [20/100], Loss: 0.4587, Validation Loss: 0.4738
	--> Epoch [21/100], Loss: 0.4501, Validation Loss: 0.4639
	--> Epoch [22/100], Loss: 0.4508, Validation Loss: 0.4578
	--> Epoch [23/100], Loss: 0.4087, Validation Loss: 0.4545
	--> Epoch [24/100], Loss: 0.4034, Validation Loss: 0.4479
	--> Epoch [25/100], Loss: 0.4100, Validation Loss: 0.4437
	--> Epoch [26/100], Loss: 0.4187, Validation Loss: 0.4388
	--> Epoch [27/100], Loss: 0.4097, Validation Loss: 0.4336
	--> Epoch [28/100], Loss: 0.3819, Validation Loss: 0.4301
	--> Epoch [29/100], Loss: 0.3713, Validation Loss: 0.4262
	--> Epoch [30/100], Loss: 0.3887, Validation Loss: 0.4224
	--> Epoch [31/100], Loss: 0.3892, Validation Loss: 0.4186
	--> Epoch [32/100], Loss: 0.3505, Validation Loss: 0.4148
	--> Epoch [33/100], Loss: 0.3157, Validation Loss: 0.4115
	--> Epoch [34/100], Loss: 0.3666, Validation Loss: 0.4089
	--> Epoch [35/100], Loss: 0.3782, Validation Loss: 0.4036
	--> Epoch [36/100], Loss: 0.3501, Validation Loss: 0.3998
	--> Epoch [37/100], Loss: 0.3571, Validation Loss: 0.3955
	--> Epoch [38/100], Loss: 0.3371, Validation Loss: 0.3935
	--> Epoch [39/100], Loss: 0.3353, Validation Loss: 0.3891
	--> Epoch [40/100], Loss: 0.3043, Validation Loss: 0.3867
	--> Epoch [41/100], Loss: 0.3037, Validation Loss: 0.3846
	--> Epoch [42/100], Loss: 0.3141, Validation Loss: 0.3807
	--> Epoch [43/100], Loss: 0.3160, Validation Loss: 0.3774
	--> Epoch [44/100], Loss: 0.3111, Validation Loss: 0.3756
	--> Epoch [45/100], Loss: 0.2665, Validation Loss: 0.3729
	--> Epoch [46/100], Loss: 0.3159, Validation Loss: 0.3704
	--> Epoch [47/100], Loss: 0.2977, Validation Loss: 0.3676
	--> Epoch [48/100], Loss: 0.2774, Validation Loss: 0.3641
	--> Epoch [49/100], Loss: 0.3134, Validation Loss: 0.3611
	--> Epoch [50/100], Loss: 0.3159, Validation Loss: 0.3600
	--> Epoch [51/100], Loss: 0.2620, Validation Loss: 0.3597
	--> Epoch [52/100], Loss: 0.2529, Validation Loss: 0.3575
	--> Epoch [53/100], Loss: 0.2988, Validation Loss: 0.3548
	--> Epoch [54/100], Loss: 0.2517, Validation Loss: 0.3530
	--> Epoch [55/100], Loss: 0.2691, Validation Loss: 0.3513
	--> Epoch [56/100], Loss: 0.2451, Validation Loss: 0.3501
	--> Epoch [57/100], Loss: 0.2225, Validation Loss: 0.3489
	--> Epoch [58/100], Loss: 0.2615, Validation Loss: 0.3458
	--> Epoch [59/100], Loss: 0.2520, Validation Loss: 0.3443
	--> Epoch [60/100], Loss: 0.2825, Validation Loss: 0.3441
	--> Epoch [61/100], Loss: 0.2424, Validation Loss: 0.3406
	--> Epoch [62/100], Loss: 0.2832, Validation Loss: 0.3385
	--> Epoch [63/100], Loss: 0.2123, Validation Loss: 0.3381
	--> Epoch [64/100], Loss: 0.2258, Validation Loss: 0.3380
	--> Epoch [65/100], Loss: 0.2110, Validation Loss: 0.3356
	--> Epoch [66/100], Loss: 0.2274, Validation Loss: 0.3342
	--> Epoch [67/100], Loss: 0.2414, Validation Loss: 0.3323
	--> Epoch [68/100], Loss: 0.2101, Validation Loss: 0.3318
	--> Epoch [69/100], Loss: 0.2577, Validation Loss: 0.3291
	--> Epoch [70/100], Loss: 0.2177, Validation Loss: 0.3288
	--> Epoch [71/100], Loss: 0.2184, Validation Loss: 0.3300
	--> Epoch [72/100], Loss: 0.1741, Validation Loss: 0.3300
	--> Epoch [73/100], Loss: 0.2289, Validation Loss: 0.3293
Early stopping
	--> Training for Fold 2 took 0.2750420570373535 sec, using 73 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7283, Validation Loss: 0.7260
	--> Epoch [2/100], Loss: 0.7101, Validation Loss: 0.7115
	--> Epoch [3/100], Loss: 0.6936, Validation Loss: 0.6982
	--> Epoch [4/100], Loss: 0.6579, Validation Loss: 0.6863
	--> Epoch [5/100], Loss: 0.6491, Validation Loss: 0.6756
	--> Epoch [6/100], Loss: 0.6554, Validation Loss: 0.6670
	--> Epoch [7/100], Loss: 0.6411, Validation Loss: 0.6567
	--> Epoch [8/100], Loss: 0.5918, Validation Loss: 0.6483
	--> Epoch [9/100], Loss: 0.6053, Validation Loss: 0.6413
	--> Epoch [10/100], Loss: 0.5754, Validation Loss: 0.6336
	--> Epoch [11/100], Loss: 0.6271, Validation Loss: 0.6274
	--> Epoch [12/100], Loss: 0.6004, Validation Loss: 0.6190
	--> Epoch [13/100], Loss: 0.5581, Validation Loss: 0.6117
	--> Epoch [14/100], Loss: 0.5545, Validation Loss: 0.6016
	--> Epoch [15/100], Loss: 0.5099, Validation Loss: 0.5947
	--> Epoch [16/100], Loss: 0.5322, Validation Loss: 0.5911
	--> Epoch [17/100], Loss: 0.5267, Validation Loss: 0.5860
	--> Epoch [18/100], Loss: 0.5073, Validation Loss: 0.5819
	--> Epoch [19/100], Loss: 0.4563, Validation Loss: 0.5753
	--> Epoch [20/100], Loss: 0.5159, Validation Loss: 0.5694
	--> Epoch [21/100], Loss: 0.4837, Validation Loss: 0.5627
	--> Epoch [22/100], Loss: 0.4517, Validation Loss: 0.5553
	--> Epoch [23/100], Loss: 0.4391, Validation Loss: 0.5486
	--> Epoch [24/100], Loss: 0.4625, Validation Loss: 0.5473
	--> Epoch [25/100], Loss: 0.4362, Validation Loss: 0.5427
	--> Epoch [26/100], Loss: 0.4052, Validation Loss: 0.5387
	--> Epoch [27/100], Loss: 0.4298, Validation Loss: 0.5328
	--> Epoch [28/100], Loss: 0.3980, Validation Loss: 0.5260
	--> Epoch [29/100], Loss: 0.4105, Validation Loss: 0.5214
	--> Epoch [30/100], Loss: 0.3922, Validation Loss: 0.5167
	--> Epoch [31/100], Loss: 0.4426, Validation Loss: 0.5151
	--> Epoch [32/100], Loss: 0.3829, Validation Loss: 0.5096
	--> Epoch [33/100], Loss: 0.3845, Validation Loss: 0.5051
	--> Epoch [34/100], Loss: 0.3605, Validation Loss: 0.4995
	--> Epoch [35/100], Loss: 0.3509, Validation Loss: 0.4946
	--> Epoch [36/100], Loss: 0.3456, Validation Loss: 0.4917
	--> Epoch [37/100], Loss: 0.3730, Validation Loss: 0.4884
	--> Epoch [38/100], Loss: 0.4132, Validation Loss: 0.4854
	--> Epoch [39/100], Loss: 0.3397, Validation Loss: 0.4822
	--> Epoch [40/100], Loss: 0.3441, Validation Loss: 0.4785
	--> Epoch [41/100], Loss: 0.2862, Validation Loss: 0.4738
	--> Epoch [42/100], Loss: 0.3111, Validation Loss: 0.4710
	--> Epoch [43/100], Loss: 0.3323, Validation Loss: 0.4688
	--> Epoch [44/100], Loss: 0.3335, Validation Loss: 0.4657
	--> Epoch [45/100], Loss: 0.2984, Validation Loss: 0.4623
	--> Epoch [46/100], Loss: 0.2731, Validation Loss: 0.4582
	--> Epoch [47/100], Loss: 0.3062, Validation Loss: 0.4547
	--> Epoch [48/100], Loss: 0.2971, Validation Loss: 0.4532
	--> Epoch [49/100], Loss: 0.2857, Validation Loss: 0.4510
	--> Epoch [50/100], Loss: 0.2813, Validation Loss: 0.4491
	--> Epoch [51/100], Loss: 0.2699, Validation Loss: 0.4461
	--> Epoch [52/100], Loss: 0.3005, Validation Loss: 0.4433
	--> Epoch [53/100], Loss: 0.2878, Validation Loss: 0.4416
	--> Epoch [54/100], Loss: 0.2680, Validation Loss: 0.4392
	--> Epoch [55/100], Loss: 0.2529, Validation Loss: 0.4378
	--> Epoch [56/100], Loss: 0.2397, Validation Loss: 0.4359
	--> Epoch [57/100], Loss: 0.2668, Validation Loss: 0.4342
	--> Epoch [58/100], Loss: 0.2682, Validation Loss: 0.4340
	--> Epoch [59/100], Loss: 0.2741, Validation Loss: 0.4325
	--> Epoch [60/100], Loss: 0.2486, Validation Loss: 0.4320
	--> Epoch [61/100], Loss: 0.2282, Validation Loss: 0.4300
	--> Epoch [62/100], Loss: 0.2860, Validation Loss: 0.4271
	--> Epoch [63/100], Loss: 0.2561, Validation Loss: 0.4274
	--> Epoch [64/100], Loss: 0.2272, Validation Loss: 0.4251
	--> Epoch [65/100], Loss: 0.2804, Validation Loss: 0.4236
	--> Epoch [66/100], Loss: 0.2425, Validation Loss: 0.4217
	--> Epoch [67/100], Loss: 0.2111, Validation Loss: 0.4198
	--> Epoch [68/100], Loss: 0.2348, Validation Loss: 0.4172
	--> Epoch [69/100], Loss: 0.1927, Validation Loss: 0.4157
	--> Epoch [70/100], Loss: 0.2238, Validation Loss: 0.4142
	--> Epoch [71/100], Loss: 0.2249, Validation Loss: 0.4133
	--> Epoch [72/100], Loss: 0.2637, Validation Loss: 0.4115
	--> Epoch [73/100], Loss: 0.2281, Validation Loss: 0.4106
	--> Epoch [74/100], Loss: 0.1959, Validation Loss: 0.4095
	--> Epoch [75/100], Loss: 0.2019, Validation Loss: 0.4075
	--> Epoch [76/100], Loss: 0.2003, Validation Loss: 0.4063
	--> Epoch [77/100], Loss: 0.2316, Validation Loss: 0.4041
	--> Epoch [78/100], Loss: 0.1867, Validation Loss: 0.4028
	--> Epoch [79/100], Loss: 0.2579, Validation Loss: 0.3996
	--> Epoch [80/100], Loss: 0.2435, Validation Loss: 0.3983
	--> Epoch [81/100], Loss: 0.2407, Validation Loss: 0.3972
	--> Epoch [82/100], Loss: 0.1889, Validation Loss: 0.3965
	--> Epoch [83/100], Loss: 0.1729, Validation Loss: 0.3949
	--> Epoch [84/100], Loss: 0.1677, Validation Loss: 0.3948
	--> Epoch [85/100], Loss: 0.2423, Validation Loss: 0.3953
	--> Epoch [86/100], Loss: 0.1758, Validation Loss: 0.3943
	--> Epoch [87/100], Loss: 0.1885, Validation Loss: 0.3925
	--> Epoch [88/100], Loss: 0.1997, Validation Loss: 0.3924
	--> Epoch [89/100], Loss: 0.1621, Validation Loss: 0.3927
	--> Epoch [90/100], Loss: 0.1869, Validation Loss: 0.3917
	--> Epoch [91/100], Loss: 0.1938, Validation Loss: 0.3919
	--> Epoch [92/100], Loss: 0.1331, Validation Loss: 0.3910
	--> Epoch [93/100], Loss: 0.1581, Validation Loss: 0.3893
	--> Epoch [94/100], Loss: 0.1647, Validation Loss: 0.3890
	--> Epoch [95/100], Loss: 0.1730, Validation Loss: 0.3887
	--> Epoch [96/100], Loss: 0.1660, Validation Loss: 0.3889
	--> Epoch [97/100], Loss: 0.1772, Validation Loss: 0.3888
	--> Epoch [98/100], Loss: 0.1928, Validation Loss: 0.3875
	--> Epoch [99/100], Loss: 0.1606, Validation Loss: 0.3870
	--> Epoch [100/100], Loss: 0.1494, Validation Loss: 0.3868
	--> Training for Fold 3 took 0.3700551986694336 sec, using 100 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7121, Validation Loss: 0.8587
	--> Epoch [2/100], Loss: 0.7104, Validation Loss: 0.8484
	--> Epoch [3/100], Loss: 0.6885, Validation Loss: 0.8363
	--> Epoch [4/100], Loss: 0.6915, Validation Loss: 0.8253
	--> Epoch [5/100], Loss: 0.6604, Validation Loss: 0.8143
	--> Epoch [6/100], Loss: 0.6518, Validation Loss: 0.8067
	--> Epoch [7/100], Loss: 0.6464, Validation Loss: 0.7993
	--> Epoch [8/100], Loss: 0.6417, Validation Loss: 0.7925
	--> Epoch [9/100], Loss: 0.6457, Validation Loss: 0.7869
	--> Epoch [10/100], Loss: 0.6252, Validation Loss: 0.7824
	--> Epoch [11/100], Loss: 0.6050, Validation Loss: 0.7772
	--> Epoch [12/100], Loss: 0.6146, Validation Loss: 0.7727
	--> Epoch [13/100], Loss: 0.6080, Validation Loss: 0.7668
	--> Epoch [14/100], Loss: 0.5865, Validation Loss: 0.7605
	--> Epoch [15/100], Loss: 0.5865, Validation Loss: 0.7548
	--> Epoch [16/100], Loss: 0.5596, Validation Loss: 0.7491
	--> Epoch [17/100], Loss: 0.5716, Validation Loss: 0.7401
	--> Epoch [18/100], Loss: 0.5492, Validation Loss: 0.7300
	--> Epoch [19/100], Loss: 0.5466, Validation Loss: 0.7221
	--> Epoch [20/100], Loss: 0.5453, Validation Loss: 0.7113
	--> Epoch [21/100], Loss: 0.5338, Validation Loss: 0.7029
	--> Epoch [22/100], Loss: 0.5234, Validation Loss: 0.6972
	--> Epoch [23/100], Loss: 0.4863, Validation Loss: 0.6893
	--> Epoch [24/100], Loss: 0.5231, Validation Loss: 0.6831
	--> Epoch [25/100], Loss: 0.4816, Validation Loss: 0.6768
	--> Epoch [26/100], Loss: 0.4961, Validation Loss: 0.6697
	--> Epoch [27/100], Loss: 0.4692, Validation Loss: 0.6634
	--> Epoch [28/100], Loss: 0.4749, Validation Loss: 0.6547
	--> Epoch [29/100], Loss: 0.4863, Validation Loss: 0.6462
	--> Epoch [30/100], Loss: 0.4605, Validation Loss: 0.6358
	--> Epoch [31/100], Loss: 0.4004, Validation Loss: 0.6265
	--> Epoch [32/100], Loss: 0.4464, Validation Loss: 0.6180
	--> Epoch [33/100], Loss: 0.4204, Validation Loss: 0.6081
	--> Epoch [34/100], Loss: 0.4202, Validation Loss: 0.6006
	--> Epoch [35/100], Loss: 0.4601, Validation Loss: 0.5927
	--> Epoch [36/100], Loss: 0.3858, Validation Loss: 0.5824
	--> Epoch [37/100], Loss: 0.4028, Validation Loss: 0.5745
	--> Epoch [38/100], Loss: 0.4024, Validation Loss: 0.5668
	--> Epoch [39/100], Loss: 0.3896, Validation Loss: 0.5615
	--> Epoch [40/100], Loss: 0.3513, Validation Loss: 0.5570
	--> Epoch [41/100], Loss: 0.3825, Validation Loss: 0.5512
	--> Epoch [42/100], Loss: 0.3791, Validation Loss: 0.5440
	--> Epoch [43/100], Loss: 0.3955, Validation Loss: 0.5372
	--> Epoch [44/100], Loss: 0.3337, Validation Loss: 0.5298
	--> Epoch [45/100], Loss: 0.3697, Validation Loss: 0.5213
	--> Epoch [46/100], Loss: 0.3358, Validation Loss: 0.5153
	--> Epoch [47/100], Loss: 0.3238, Validation Loss: 0.5101
	--> Epoch [48/100], Loss: 0.3306, Validation Loss: 0.5036
	--> Epoch [49/100], Loss: 0.3659, Validation Loss: 0.4986
	--> Epoch [50/100], Loss: 0.3535, Validation Loss: 0.4950
	--> Epoch [51/100], Loss: 0.3392, Validation Loss: 0.4934
	--> Epoch [52/100], Loss: 0.3261, Validation Loss: 0.4891
	--> Epoch [53/100], Loss: 0.3229, Validation Loss: 0.4847
	--> Epoch [54/100], Loss: 0.3135, Validation Loss: 0.4816
	--> Epoch [55/100], Loss: 0.2733, Validation Loss: 0.4755
	--> Epoch [56/100], Loss: 0.2956, Validation Loss: 0.4695
	--> Epoch [57/100], Loss: 0.2987, Validation Loss: 0.4669
	--> Epoch [58/100], Loss: 0.2698, Validation Loss: 0.4632
	--> Epoch [59/100], Loss: 0.2823, Validation Loss: 0.4600
	--> Epoch [60/100], Loss: 0.2585, Validation Loss: 0.4567
	--> Epoch [61/100], Loss: 0.2726, Validation Loss: 0.4536
	--> Epoch [62/100], Loss: 0.2556, Validation Loss: 0.4517
	--> Epoch [63/100], Loss: 0.2823, Validation Loss: 0.4489
	--> Epoch [64/100], Loss: 0.2714, Validation Loss: 0.4495
	--> Epoch [65/100], Loss: 0.2655, Validation Loss: 0.4462
	--> Epoch [66/100], Loss: 0.2401, Validation Loss: 0.4424
	--> Epoch [67/100], Loss: 0.2373, Validation Loss: 0.4372
	--> Epoch [68/100], Loss: 0.2677, Validation Loss: 0.4351
	--> Epoch [69/100], Loss: 0.2732, Validation Loss: 0.4345
	--> Epoch [70/100], Loss: 0.2257, Validation Loss: 0.4322
	--> Epoch [71/100], Loss: 0.2317, Validation Loss: 0.4295
	--> Epoch [72/100], Loss: 0.2205, Validation Loss: 0.4294
	--> Epoch [73/100], Loss: 0.2957, Validation Loss: 0.4268
	--> Epoch [74/100], Loss: 0.2187, Validation Loss: 0.4244
	--> Epoch [75/100], Loss: 0.2480, Validation Loss: 0.4223
	--> Epoch [76/100], Loss: 0.2323, Validation Loss: 0.4211
	--> Epoch [77/100], Loss: 0.2462, Validation Loss: 0.4215
	--> Epoch [78/100], Loss: 0.2155, Validation Loss: 0.4188
	--> Epoch [79/100], Loss: 0.2398, Validation Loss: 0.4191
	--> Epoch [80/100], Loss: 0.2303, Validation Loss: 0.4190
	--> Epoch [81/100], Loss: 0.2377, Validation Loss: 0.4180
	--> Epoch [82/100], Loss: 0.2195, Validation Loss: 0.4150
	--> Epoch [83/100], Loss: 0.2094, Validation Loss: 0.4131
	--> Epoch [84/100], Loss: 0.2278, Validation Loss: 0.4113
	--> Epoch [85/100], Loss: 0.2075, Validation Loss: 0.4082
	--> Epoch [86/100], Loss: 0.1870, Validation Loss: 0.4077
	--> Epoch [87/100], Loss: 0.1878, Validation Loss: 0.4059
	--> Epoch [88/100], Loss: 0.1687, Validation Loss: 0.4028
	--> Epoch [89/100], Loss: 0.1933, Validation Loss: 0.4009
	--> Epoch [90/100], Loss: 0.1802, Validation Loss: 0.4003
	--> Epoch [91/100], Loss: 0.1722, Validation Loss: 0.3992
	--> Epoch [92/100], Loss: 0.2002, Validation Loss: 0.3974
	--> Epoch [93/100], Loss: 0.2156, Validation Loss: 0.3979
	--> Epoch [94/100], Loss: 0.2157, Validation Loss: 0.3974
	--> Epoch [95/100], Loss: 0.1950, Validation Loss: 0.3964
	--> Epoch [96/100], Loss: 0.1735, Validation Loss: 0.3977
	--> Epoch [97/100], Loss: 0.1916, Validation Loss: 0.3999
	--> Epoch [98/100], Loss: 0.1723, Validation Loss: 0.3981
Early stopping
	--> Training for Fold 4 took 0.3635447025299072 sec, using 98 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6613, Validation Loss: 0.7254
	--> Epoch [2/100], Loss: 0.6424, Validation Loss: 0.7120
	--> Epoch [3/100], Loss: 0.6876, Validation Loss: 0.7008
	--> Epoch [4/100], Loss: 0.6168, Validation Loss: 0.6932
	--> Epoch [5/100], Loss: 0.6041, Validation Loss: 0.6851
	--> Epoch [6/100], Loss: 0.5904, Validation Loss: 0.6778
	--> Epoch [7/100], Loss: 0.5895, Validation Loss: 0.6691
	--> Epoch [8/100], Loss: 0.5681, Validation Loss: 0.6607
	--> Epoch [9/100], Loss: 0.5290, Validation Loss: 0.6564
	--> Epoch [10/100], Loss: 0.5369, Validation Loss: 0.6528
	--> Epoch [11/100], Loss: 0.5117, Validation Loss: 0.6463
	--> Epoch [12/100], Loss: 0.5064, Validation Loss: 0.6407
	--> Epoch [13/100], Loss: 0.4811, Validation Loss: 0.6352
	--> Epoch [14/100], Loss: 0.4942, Validation Loss: 0.6313
	--> Epoch [15/100], Loss: 0.4510, Validation Loss: 0.6291
	--> Epoch [16/100], Loss: 0.4565, Validation Loss: 0.6284
	--> Epoch [17/100], Loss: 0.4310, Validation Loss: 0.6241
	--> Epoch [18/100], Loss: 0.4200, Validation Loss: 0.6203
	--> Epoch [19/100], Loss: 0.4205, Validation Loss: 0.6171
	--> Epoch [20/100], Loss: 0.4001, Validation Loss: 0.6155
	--> Epoch [21/100], Loss: 0.4277, Validation Loss: 0.6114
	--> Epoch [22/100], Loss: 0.4055, Validation Loss: 0.6081
	--> Epoch [23/100], Loss: 0.4108, Validation Loss: 0.6055
	--> Epoch [24/100], Loss: 0.4140, Validation Loss: 0.6032
	--> Epoch [25/100], Loss: 0.3668, Validation Loss: 0.6009
	--> Epoch [26/100], Loss: 0.3821, Validation Loss: 0.5989
	--> Epoch [27/100], Loss: 0.3391, Validation Loss: 0.5965
	--> Epoch [28/100], Loss: 0.3683, Validation Loss: 0.5945
	--> Epoch [29/100], Loss: 0.3341, Validation Loss: 0.5942
	--> Epoch [30/100], Loss: 0.3684, Validation Loss: 0.5941
	--> Epoch [31/100], Loss: 0.3816, Validation Loss: 0.5941
	--> Epoch [32/100], Loss: 0.3176, Validation Loss: 0.5937
	--> Epoch [33/100], Loss: 0.3398, Validation Loss: 0.5910
	--> Epoch [34/100], Loss: 0.2724, Validation Loss: 0.5896
	--> Epoch [35/100], Loss: 0.3478, Validation Loss: 0.5886
	--> Epoch [36/100], Loss: 0.3094, Validation Loss: 0.5870
	--> Epoch [37/100], Loss: 0.3230, Validation Loss: 0.5873
	--> Epoch [38/100], Loss: 0.2814, Validation Loss: 0.5861
	--> Epoch [39/100], Loss: 0.3105, Validation Loss: 0.5845
	--> Epoch [40/100], Loss: 0.3164, Validation Loss: 0.5821
	--> Epoch [41/100], Loss: 0.2858, Validation Loss: 0.5793
	--> Epoch [42/100], Loss: 0.3086, Validation Loss: 0.5803
	--> Epoch [43/100], Loss: 0.3171, Validation Loss: 0.5791
	--> Epoch [44/100], Loss: 0.2768, Validation Loss: 0.5785
	--> Epoch [45/100], Loss: 0.2510, Validation Loss: 0.5785
	--> Epoch [46/100], Loss: 0.2962, Validation Loss: 0.5768
	--> Epoch [47/100], Loss: 0.3122, Validation Loss: 0.5768
	--> Epoch [48/100], Loss: 0.2723, Validation Loss: 0.5777
	--> Epoch [49/100], Loss: 0.2557, Validation Loss: 0.5782
	--> Epoch [50/100], Loss: 0.2512, Validation Loss: 0.5779
Early stopping
	--> Training for Fold 5 took 0.18747186660766602 sec, using 50 epochs

Median number of epochs used: 98 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/98], Loss: 0.6932
	--> Final training Epoch [2/98], Loss: 0.6735
	--> Final training Epoch [3/98], Loss: 0.6639
	--> Final training Epoch [4/98], Loss: 0.6431
	--> Final training Epoch [5/98], Loss: 0.6177
	--> Final training Epoch [6/98], Loss: 0.5995
	--> Final training Epoch [7/98], Loss: 0.6055
	--> Final training Epoch [8/98], Loss: 0.5859
	--> Final training Epoch [9/98], Loss: 0.5805
	--> Final training Epoch [10/98], Loss: 0.5481
	--> Final training Epoch [11/98], Loss: 0.5343
	--> Final training Epoch [12/98], Loss: 0.5526
	--> Final training Epoch [13/98], Loss: 0.5192
	--> Final training Epoch [14/98], Loss: 0.5191
	--> Final training Epoch [15/98], Loss: 0.5220
	--> Final training Epoch [16/98], Loss: 0.5140
	--> Final training Epoch [17/98], Loss: 0.5045
	--> Final training Epoch [18/98], Loss: 0.4902
	--> Final training Epoch [19/98], Loss: 0.5099
	--> Final training Epoch [20/98], Loss: 0.4775
	--> Final training Epoch [21/98], Loss: 0.4968
	--> Final training Epoch [22/98], Loss: 0.4323
	--> Final training Epoch [23/98], Loss: 0.4524
	--> Final training Epoch [24/98], Loss: 0.4559
	--> Final training Epoch [25/98], Loss: 0.4497
	--> Final training Epoch [26/98], Loss: 0.4186
	--> Final training Epoch [27/98], Loss: 0.4153
	--> Final training Epoch [28/98], Loss: 0.4445
	--> Final training Epoch [29/98], Loss: 0.4093
	--> Final training Epoch [30/98], Loss: 0.4009
	--> Final training Epoch [31/98], Loss: 0.4000
	--> Final training Epoch [32/98], Loss: 0.3680
	--> Final training Epoch [33/98], Loss: 0.3760
	--> Final training Epoch [34/98], Loss: 0.3692
	--> Final training Epoch [35/98], Loss: 0.3657
	--> Final training Epoch [36/98], Loss: 0.3519
	--> Final training Epoch [37/98], Loss: 0.3297
	--> Final training Epoch [38/98], Loss: 0.3569
	--> Final training Epoch [39/98], Loss: 0.3420
	--> Final training Epoch [40/98], Loss: 0.3312
	--> Final training Epoch [41/98], Loss: 0.3504
	--> Final training Epoch [42/98], Loss: 0.3105
	--> Final training Epoch [43/98], Loss: 0.3193
	--> Final training Epoch [44/98], Loss: 0.3536
	--> Final training Epoch [45/98], Loss: 0.3324
	--> Final training Epoch [46/98], Loss: 0.2951
	--> Final training Epoch [47/98], Loss: 0.3230
	--> Final training Epoch [48/98], Loss: 0.3064
	--> Final training Epoch [49/98], Loss: 0.3055
	--> Final training Epoch [50/98], Loss: 0.2664
	--> Final training Epoch [51/98], Loss: 0.2787
	--> Final training Epoch [52/98], Loss: 0.3157
	--> Final training Epoch [53/98], Loss: 0.2797
	--> Final training Epoch [54/98], Loss: 0.3173
	--> Final training Epoch [55/98], Loss: 0.2816
	--> Final training Epoch [56/98], Loss: 0.2796
	--> Final training Epoch [57/98], Loss: 0.2844
	--> Final training Epoch [58/98], Loss: 0.2981
	--> Final training Epoch [59/98], Loss: 0.2494
	--> Final training Epoch [60/98], Loss: 0.2501
	--> Final training Epoch [61/98], Loss: 0.2457
	--> Final training Epoch [62/98], Loss: 0.2333
	--> Final training Epoch [63/98], Loss: 0.2350
	--> Final training Epoch [64/98], Loss: 0.2551
	--> Final training Epoch [65/98], Loss: 0.2717
	--> Final training Epoch [66/98], Loss: 0.2387
	--> Final training Epoch [67/98], Loss: 0.2765
	--> Final training Epoch [68/98], Loss: 0.2628
	--> Final training Epoch [69/98], Loss: 0.2248
	--> Final training Epoch [70/98], Loss: 0.2075
	--> Final training Epoch [71/98], Loss: 0.2731
	--> Final training Epoch [72/98], Loss: 0.2346
	--> Final training Epoch [73/98], Loss: 0.2582
	--> Final training Epoch [74/98], Loss: 0.2168
	--> Final training Epoch [75/98], Loss: 0.2082
	--> Final training Epoch [76/98], Loss: 0.2128
	--> Final training Epoch [77/98], Loss: 0.1988
	--> Final training Epoch [78/98], Loss: 0.2066
	--> Final training Epoch [79/98], Loss: 0.2342
	--> Final training Epoch [80/98], Loss: 0.2031
	--> Final training Epoch [81/98], Loss: 0.1998
	--> Final training Epoch [82/98], Loss: 0.1973
	--> Final training Epoch [83/98], Loss: 0.2009
	--> Final training Epoch [84/98], Loss: 0.2339
	--> Final training Epoch [85/98], Loss: 0.1904
	--> Final training Epoch [86/98], Loss: 0.1980
	--> Final training Epoch [87/98], Loss: 0.2107
	--> Final training Epoch [88/98], Loss: 0.1707
	--> Final training Epoch [89/98], Loss: 0.2096
	--> Final training Epoch [90/98], Loss: 0.1837
	--> Final training Epoch [91/98], Loss: 0.1900
	--> Final training Epoch [92/98], Loss: 0.2186
	--> Final training Epoch [93/98], Loss: 0.1776
	--> Final training Epoch [94/98], Loss: 0.1722
	--> Final training Epoch [95/98], Loss: 0.1888
	--> Final training Epoch [96/98], Loss: 0.2161
	--> Final training Epoch [97/98], Loss: 0.1935
	--> Final training Epoch [98/98], Loss: 0.1810

Final training took 0.3410160541534424 sec

TESTING
	--> Testing took 0.0085 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8079
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8813, Validation Loss: 0.3258,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8497, Validation Loss: 0.3863,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7836, Validation Loss: 0.4050,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8047, Validation Loss: 0.3836,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 0.4249,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7836, Validation Loss: 0.4172,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7222, Validation Loss: 0.4517,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.4424,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8175, Validation Loss: 0.4142,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7953, Validation Loss: 0.4551,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7836, Validation Loss: 0.4657,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8170, Validation Loss: 0.4879,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8287, Validation Loss: 0.4632,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8064, Validation Loss: 0.4183,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.4273,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3788,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4446,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8398, Validation Loss: 0.4120,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.4537,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7620, Validation Loss: 0.5152,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.4608,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.4566,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.3894,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8181, Validation Loss: 0.4108,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8287, Validation Loss: 0.4059,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8053, Validation Loss: 0.4596,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.4216,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.4200,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8053, Validation Loss: 0.4959,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8064, Validation Loss: 0.4931,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4616,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8064, Validation Loss: 0.4253,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3856,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3959,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4282,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3722,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8064, Validation Loss: 0.3923,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7725, Validation Loss: 0.4705,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7953, Validation Loss: 0.4867,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8263, Validation Loss: 0.4898,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8269, Validation Loss: 0.3984,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8386, Validation Loss: 0.3991,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7848, Validation Loss: 0.3971,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7749, Validation Loss: 0.4652,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3906,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3847,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7947, Validation Loss: 0.4696,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 0.4760,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.4812,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.4492,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7626, Validation Loss: 0.4782,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.4284,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7626, Validation Loss: 0.4998,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8070, Validation Loss: 0.4916,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4537,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7632, Validation Loss: 0.5236,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7515, Validation Loss: 0.5402,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7205, Validation Loss: 0.5480,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8158, Validation Loss: 0.4374,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8070, Validation Loss: 0.4504,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.4313,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7743, Validation Loss: 0.4904,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7854, Validation Loss: 0.4907,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4599,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.5082,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.5165,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8064, Validation Loss: 0.4929,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.4486,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7953, Validation Loss: 0.4370,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4330,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7620, Validation Loss: 0.4623,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8175, Validation Loss: 0.4604,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 0.4860,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7199, Validation Loss: 0.5573,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7743, Validation Loss: 0.4948,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.4888,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.4466,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.4221,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.4102,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8164, Validation Loss: 0.4802,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.4524,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8064, Validation Loss: 0.4652,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.5253,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7959, Validation Loss: 0.5225,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4841,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.4380,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.4231,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.4246,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8251, Validation Loss: 0.4799,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 0.4891,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.4704,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7292, Validation Loss: 0.5376,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7632, Validation Loss: 0.5139,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7509, Validation Loss: 0.5273,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7643, Validation Loss: 0.5057,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.4384,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8064, Validation Loss: 0.5102,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8041, Validation Loss: 0.5621,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 0.4903,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7526, Validation Loss: 0.5022,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6567, Validation Loss: 0.5958,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6228, Validation Loss: 0.6212,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7269, Validation Loss: 0.5963,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8064, Validation Loss: 0.4602,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.4751,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.4817,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7649, Validation Loss: 0.5125,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 0.5297,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.4916,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7310, Validation Loss: 0.5763,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6316, Validation Loss: 0.6124,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7012, Validation Loss: 0.5932,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7953, Validation Loss: 0.4864,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7953, Validation Loss: 0.5085,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7942, Validation Loss: 0.5037,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7298, Validation Loss: 0.5401,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7515, Validation Loss: 0.5420,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8175, Validation Loss: 0.5102,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7105, Validation Loss: 0.5611,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6901, Validation Loss: 0.5721,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7725, Validation Loss: 0.5252,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7737, Validation Loss: 0.5249,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.4967,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7842, Validation Loss: 0.4806,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7515, Validation Loss: 0.5152,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.4936,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7725, Validation Loss: 0.5623,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7737, Validation Loss: 0.5278,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7953, Validation Loss: 0.5436,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7626, Validation Loss: 0.5513,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7842, Validation Loss: 0.4832,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7626, Validation Loss: 0.5134,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.4884,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7427, Validation Loss: 0.5332,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.5238,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8287, Validation Loss: 0.5109,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7105, Validation Loss: 0.5669,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6977, Validation Loss: 0.5766,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7860, Validation Loss: 0.5579,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7292, Validation Loss: 0.6069,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.4973,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6211, Validation Loss: 0.6244,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7006, Validation Loss: 0.5793,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.5492,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7205, Validation Loss: 0.5707,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7544, Validation Loss: 0.5960,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7737, Validation Loss: 0.5794,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6988, Validation Loss: 0.5626,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7737, Validation Loss: 0.5532,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7421, Validation Loss: 0.5679,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7427, Validation Loss: 0.5429,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6883, Validation Loss: 0.5892,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7082, Validation Loss: 0.5575,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6953, Validation Loss: 0.5938,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.5550,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6883, Validation Loss: 0.6112,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6860, Validation Loss: 0.6035,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7526, Validation Loss: 0.5814,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8047, Validation Loss: 0.5415,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7205, Validation Loss: 0.5597,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6971, Validation Loss: 0.5767,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7520, Validation Loss: 0.5434,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7497, Validation Loss: 0.5585,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6556, Validation Loss: 0.6208,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7082, Validation Loss: 0.6035,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6620, Validation Loss: 0.6261,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6456, Validation Loss: 0.5860,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7298, Validation Loss: 0.5640,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7211, Validation Loss: 0.6034,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.5700,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6883, Validation Loss: 0.5898,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6959, Validation Loss: 0.6026,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7848, Validation Loss: 0.5564,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6661, Validation Loss: 0.6094,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7322, Validation Loss: 0.5711,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7953, Validation Loss: 0.5192,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7520, Validation Loss: 0.5520,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7526, Validation Loss: 0.5484,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7620, Validation Loss: 0.5829,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7959, Validation Loss: 0.5640,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7105, Validation Loss: 0.5729,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6772, Validation Loss: 0.6294,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6567, Validation Loss: 0.6262,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7725, Validation Loss: 0.5716,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7298, Validation Loss: 0.5758,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7076, Validation Loss: 0.6082,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6889, Validation Loss: 0.5670,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.5766, Validation Loss: 0.6556,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7749, Validation Loss: 0.5723,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7088, Validation Loss: 0.6188,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7526, Validation Loss: 0.6182,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.5906, Validation Loss: 0.6917,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6801, Validation Loss: 0.6237,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6754, Validation Loss: 0.6097,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.6901, Validation Loss: 0.5802,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6772, Validation Loss: 0.5764,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6544, Validation Loss: 0.6106,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6234, Validation Loss: 0.6160,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5924, Validation Loss: 0.6360,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6029, Validation Loss: 0.6168,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7316, Validation Loss: 0.5943,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6678, Validation Loss: 0.6051,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6971, Validation Loss: 0.5818,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.6205, Validation Loss: 0.6206,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6988, Validation Loss: 0.5876,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6135, Validation Loss: 0.6431,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6766, Validation Loss: 0.6130,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6801, Validation Loss: 0.5954,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6784, Validation Loss: 0.6201,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6310, Validation Loss: 0.6289,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6661, Validation Loss: 0.6317,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7099, Validation Loss: 0.5861,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7199, Validation Loss: 0.6143,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.5702, Validation Loss: 0.6301,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.5912, Validation Loss: 0.6493,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6626, Validation Loss: 0.6155,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6655, Validation Loss: 0.6182,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5789, Validation Loss: 0.6618,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.4380, Validation Loss: 0.6806,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7099, Validation Loss: 0.5915,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7304, Validation Loss: 0.5720,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.5883, Validation Loss: 0.6616,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7076, Validation Loss: 0.5773,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.5614, Validation Loss: 0.6643,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6544, Validation Loss: 0.6133,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6135, Validation Loss: 0.6379,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6889, Validation Loss: 0.6176,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.5924, Validation Loss: 0.6331,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6333, Validation Loss: 0.6384,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.5889, Validation Loss: 0.6407,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.5470,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.5462, Validation Loss: 0.6677,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6994, Validation Loss: 0.6134,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7643, Validation Loss: 0.5773,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6526, Validation Loss: 0.6449,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6550, Validation Loss: 0.6675,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7433, Validation Loss: 0.5998,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7187, Validation Loss: 0.6163,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6994, Validation Loss: 0.5702,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7193, Validation Loss: 0.5798,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7439, Validation Loss: 0.5466,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7421, Validation Loss: 0.5920,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6895, Validation Loss: 0.5924,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7632, Validation Loss: 0.5913,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6743, Validation Loss: 0.6155,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6374, Validation Loss: 0.6139,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6784, Validation Loss: 0.6025,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6684, Validation Loss: 0.6131,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7520, Validation Loss: 0.5469,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6427, Validation Loss: 0.5988,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6906, Validation Loss: 0.6327,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6357, Validation Loss: 0.6448,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6047, Validation Loss: 0.6550,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5924, Validation Loss: 0.6685,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6439, Validation Loss: 0.6314,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6573, Validation Loss: 0.6330,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7322, Validation Loss: 0.6141,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7322, Validation Loss: 0.6076,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6971, Validation Loss: 0.6051,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7743, Validation Loss: 0.6002,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6561, Validation Loss: 0.6283,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7099, Validation Loss: 0.6032,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6257, Validation Loss: 0.6208,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6883, Validation Loss: 0.6254,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7526, Validation Loss: 0.5832,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7175, Validation Loss: 0.6032,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7105, Validation Loss: 0.6024,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7743, Validation Loss: 0.5636,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7532, Validation Loss: 0.6212,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7526, Validation Loss: 0.5901,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7310, Validation Loss: 0.5521,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5275, Validation Loss: 0.6543,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7398, Validation Loss: 0.6130,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6994, Validation Loss: 0.6201,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.4918, Validation Loss: 0.6844,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.5012, Validation Loss: 0.6779,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6749, Validation Loss: 0.6300,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6462, Validation Loss: 0.6373,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6023, Validation Loss: 0.6370,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5912, Validation Loss: 0.6813,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5789, Validation Loss: 0.6393,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6228, Validation Loss: 0.6496,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5485, Validation Loss: 0.7082,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.5392, Validation Loss: 0.7119,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7643, Validation Loss: 0.6058,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6012, Validation Loss: 0.6506,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6363, Validation Loss: 0.6512,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.5474, Validation Loss: 0.6828,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5825, Validation Loss: 0.6455,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6462, Validation Loss: 0.6261,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.5906, Validation Loss: 0.6548,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.4684, Validation Loss: 0.6967,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6456, Validation Loss: 0.6524,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.6988, Validation Loss: 0.6276,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6667, Validation Loss: 0.6194,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6310, Validation Loss: 0.6342,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6357, Validation Loss: 0.6329,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5825, Validation Loss: 0.6632,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6877, Validation Loss: 0.6414,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.5930, Validation Loss: 0.6670,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5474, Validation Loss: 0.6761,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7322, Validation Loss: 0.6166,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.6462, Validation Loss: 0.6295,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6439, Validation Loss: 0.6548,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6982, Validation Loss: 0.6305,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6474, Validation Loss: 0.6275,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6012, Validation Loss: 0.6495,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5942, Validation Loss: 0.6563,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6012, Validation Loss: 0.6361,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5152, Validation Loss: 0.7061,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6012, Validation Loss: 0.6531,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.6778, Validation Loss: 0.6122,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6000, Validation Loss: 0.6875,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6234, Validation Loss: 0.6561,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6240, Validation Loss: 0.6608,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5836, Validation Loss: 0.6353,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5257, Validation Loss: 0.6733,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6754, Validation Loss: 0.6516,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5719, Validation Loss: 0.6802,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.5257, Validation Loss: 0.6531,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.5608, Validation Loss: 0.6880,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6556, Validation Loss: 0.6453,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6351, Validation Loss: 0.6280,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6784, Validation Loss: 0.6240,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5825, Validation Loss: 0.6589,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.4807, Validation Loss: 0.6979,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.4830, Validation Loss: 0.7205,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5468, Validation Loss: 0.6842,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.5251, Validation Loss: 0.6899,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.6146, Validation Loss: 0.6653,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6222, Validation Loss: 0.6423,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.4696, Validation Loss: 0.6913,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6789, Validation Loss: 0.6419,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5813, Validation Loss: 0.6593,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6667, Validation Loss: 0.6328,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.4269, Validation Loss: 0.7115,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6135, Validation Loss: 0.6688,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.4825, Validation Loss: 0.6886,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.5924, Validation Loss: 0.6537,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6152, Validation Loss: 0.6569,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.4626, Validation Loss: 0.7218,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.4912, Validation Loss: 0.7148,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7199, Validation Loss: 0.6272,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6474, Validation Loss: 0.6607,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6667, Validation Loss: 0.6517,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5497, Validation Loss: 0.6782,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.5047, Validation Loss: 0.6885,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.6591, Validation Loss: 0.6212,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6158, Validation Loss: 0.6488,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7327, Validation Loss: 0.6375,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6117, Validation Loss: 0.6491,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5883, Validation Loss: 0.6571,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6684, Validation Loss: 0.6302,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.5099, Validation Loss: 0.6981,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5690, Validation Loss: 0.6770,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.4725, Validation Loss: 0.7164,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.5719, Validation Loss: 0.6563,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.6567, Validation Loss: 0.6373,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6889, Validation Loss: 0.6239,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6673, Validation Loss: 0.6409,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6491, Validation Loss: 0.6577,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5614, Validation Loss: 0.6969,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.5117, Validation Loss: 0.7219,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5257, Validation Loss: 0.6954,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.5784, Validation Loss: 0.6651,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.6468, Validation Loss: 0.6302,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.5170, Validation Loss: 0.6966,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6561, Validation Loss: 0.6445,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.4164, Validation Loss: 0.7347,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.5491, Validation Loss: 0.6838,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5053, Validation Loss: 0.7246,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.5485, Validation Loss: 0.6761,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.4982, Validation Loss: 0.6899,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
	--> Hidden Size: [8], Learning Rate: 1e-05, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.4708, Validation Loss: 0.7130,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3258
