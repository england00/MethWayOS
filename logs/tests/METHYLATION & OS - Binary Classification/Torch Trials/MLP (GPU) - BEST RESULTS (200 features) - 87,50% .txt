Accuracy in testing: 0.8750
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4718, Validation Loss: 0.7651,  Current Best Accuracy: 0.4718,  Current Best Validation Loss: 0.7651
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4526, Validation Loss: 0.7748,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7748


Accuracy in testing: 0.8125
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4821, Validation Loss: 1.0066,  Current Best Accuracy: 0.4821,  Current Best Validation Loss: 1.0066
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.4679, Validation Loss: 0.7477,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.7477
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.5474, Validation Loss: 0.7131,  Current Best Accuracy: 0.5474,  Current Best Validation Loss: 0.7131
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4859, Validation Loss: 0.7476,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.7476
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.5026, Validation Loss: 0.7252,  Current Best Accuracy: 0.5026,  Current Best Validation Loss: 0.7252
Hidden Size: [5], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.5013, Validation Loss: 0.7126,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7126
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4718, Validation Loss: 0.7468,  Current Best Accuracy: 0.4718,  Current Best Validation Loss: 0.7468
Hidden Size: [4, 2], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4987, Validation Loss: 0.7264,  Current Best Accuracy: 0.4987,  Current Best Validation Loss: 0.7264
Hidden Size: [5, 3], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.5013, Validation Loss: 0.8690,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.8690
Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.5500, Validation Loss: 0.6896,  Current Best Accuracy: 0.5500,  Current Best Validation Loss: 0.6896
Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5628, Validation Loss: 0.6988,  Current Best Accuracy: 0.5628,  Current Best Validation Loss: 0.6988
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.4692, Validation Loss: 0.7065,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 0.7065
Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.5474, Validation Loss: 0.7075,  Current Best Accuracy: 0.5474,  Current Best Validation Loss: 0.7075


Accuracy in testing: 0.7500
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5154, Validation Loss: 1.1642,  Current Best Accuracy: 0.5154,  Current Best Validation Loss: 1.1642
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.5295, Validation Loss: 1.0941,  Current Best Accuracy: 0.5295,  Current Best Validation Loss: 1.0941
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4551, Validation Loss: 0.8486,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.8486
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.4692, Validation Loss: 0.7728,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 0.7728
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.5936, Validation Loss: 0.7117,  Current Best Accuracy: 0.5936,  Current Best Validation Loss: 0.7117
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.5179, Validation Loss: 0.7147,  Current Best Accuracy: 0.5179,  Current Best Validation Loss: 0.7147
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.4526, Validation Loss: 0.7387,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7387
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4679, Validation Loss: 0.7597,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.7597
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.5154, Validation Loss: 0.7761,  Current Best Accuracy: 0.5154,  Current Best Validation Loss: 0.7761
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.5923, Validation Loss: 0.7139,  Current Best Accuracy: 0.5923,  Current Best Validation Loss: 0.7139
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.4833, Validation Loss: 0.6979,  Current Best Accuracy: 0.4833,  Current Best Validation Loss: 0.6979
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.5628, Validation Loss: 0.7391,  Current Best Accuracy: 0.5628,  Current Best Validation Loss: 0.7391
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.4397, Validation Loss: 0.7220,  Current Best Accuracy: 0.4397,  Current Best Validation Loss: 0.7220
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4526, Validation Loss: 0.7300,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7300
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4872, Validation Loss: 0.7630,  Current Best Accuracy: 0.4872,  Current Best Validation Loss: 0.7630
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4718, Validation Loss: 0.8331,  Current Best Accuracy: 0.4718,  Current Best Validation Loss: 0.8331
Hidden Size: [4], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4551, Validation Loss: 0.7220,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7220
Hidden Size: [4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.4859, Validation Loss: 0.6927,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.6927
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5462, Validation Loss: 0.7536,  Current Best Accuracy: 0.5462,  Current Best Validation Loss: 0.7536
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4385, Validation Loss: 0.7284,  Current Best Accuracy: 0.4385,  Current Best Validation Loss: 0.7284
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.5167, Validation Loss: 0.7524,  Current Best Accuracy: 0.5167,  Current Best Validation Loss: 0.7524
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.5179, Validation Loss: 0.6974,  Current Best Accuracy: 0.5179,  Current Best Validation Loss: 0.6974
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.5013, Validation Loss: 0.7257,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7257
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4551, Validation Loss: 0.7439,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7439
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.5154, Validation Loss: 0.6972,  Current Best Accuracy: 0.5154,  Current Best Validation Loss: 0.6972
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.5013, Validation Loss: 0.7102,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7102
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4859, Validation Loss: 0.7110,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.7110
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.4551, Validation Loss: 0.7321,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7321
Hidden Size: [5], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.4846, Validation Loss: 1.5615,  Current Best Accuracy: 0.4846,  Current Best Validation Loss: 1.5615
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4885, Validation Loss: 0.7035,  Current Best Accuracy: 0.4885,  Current Best Validation Loss: 0.7035
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.4551, Validation Loss: 0.7436,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7436
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4526, Validation Loss: 0.7294,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7294
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.5949, Validation Loss: 0.7078,  Current Best Accuracy: 0.5949,  Current Best Validation Loss: 0.7078
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.5449, Validation Loss: 0.6982,  Current Best Accuracy: 0.5449,  Current Best Validation Loss: 0.6982
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.5782, Validation Loss: 0.6566,  Current Best Accuracy: 0.5782,  Current Best Validation Loss: 0.6566
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4859, Validation Loss: 0.6920,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.6920
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5821, Validation Loss: 0.6747,  Current Best Accuracy: 0.5821,  Current Best Validation Loss: 0.6747
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.4679, Validation Loss: 0.7198,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.7198
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.5474, Validation Loss: 0.6939,  Current Best Accuracy: 0.5474,  Current Best Validation Loss: 0.6939
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.5474, Validation Loss: 0.6939,  Current Best Accuracy: 0.5474,  Current Best Validation Loss: 0.6939
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.5795, Validation Loss: 0.7013,  Current Best Accuracy: 0.5795,  Current Best Validation Loss: 0.7013
Hidden Size: [5], Learning Rate: 0.0001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.5474, Validation Loss: 0.7030,  Current Best Accuracy: 0.5474,  Current Best Validation Loss: 0.7030
Hidden Size: [5], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.4551, Validation Loss: 0.7683,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7683
Hidden Size: [5], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.5462, Validation Loss: 0.6797,  Current Best Accuracy: 0.5462,  Current Best Validation Loss: 0.6797
Hidden Size: [5], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.5782, Validation Loss: 0.7041,  Current Best Accuracy: 0.5782,  Current Best Validation Loss: 0.7041
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4705, Validation Loss: 1.2082,  Current Best Accuracy: 0.4705,  Current Best Validation Loss: 1.2082
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4526, Validation Loss: 0.7469,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7469
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4256, Validation Loss: 0.7408,  Current Best Accuracy: 0.4256,  Current Best Validation Loss: 0.7408
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4423, Validation Loss: 1.1549,  Current Best Accuracy: 0.4423,  Current Best Validation Loss: 1.1549
Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4859, Validation Loss: 0.7362,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.7362
Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4859, Validation Loss: 0.7102,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.7102
Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4231, Validation Loss: 0.7441,  Current Best Accuracy: 0.4231,  Current Best Validation Loss: 0.7441
Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.3744, Validation Loss: 0.7171,  Current Best Accuracy: 0.3744,  Current Best Validation Loss: 0.7171
Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.5641, Validation Loss: 0.7016,  Current Best Accuracy: 0.5641,  Current Best Validation Loss: 0.7016
Hidden Size: [8], Learning Rate: 0.001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.5013, Validation Loss: 0.7068,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7068
Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.5667, Validation Loss: 0.6660,  Current Best Accuracy: 0.5667,  Current Best Validation Loss: 0.6660
Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.4705, Validation Loss: 0.7388,  Current Best Accuracy: 0.4705,  Current Best Validation Loss: 0.7388
Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.1, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4692, Validation Loss: 0.7290,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 0.7290
Hidden Size: [8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.5000, Validation Loss: 0.7173,  Current Best Accuracy: 0.5000,  Current Best Validation Loss: 0.7173
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5359, Validation Loss: 0.7996,  Current Best Accuracy: 0.5359,  Current Best Validation Loss: 0.7996
Hidden Size: [4, 2], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4385, Validation Loss: 0.7131,  Current Best Accuracy: 0.4385,  Current Best Validation Loss: 0.7131
Hidden Size: [4, 2], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.4859, Validation Loss: 0.7484,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.7484
Hidden Size: [4, 2], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4705, Validation Loss: 0.7013,  Current Best Accuracy: 0.4705,  Current Best Validation Loss: 0.7013
Hidden Size: [4, 2], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.5346, Validation Loss: 0.7077,  Current Best Accuracy: 0.5346,  Current Best Validation Loss: 0.7077
Hidden Size: [4, 2], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.4551, Validation Loss: 0.7172,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7172
Hidden Size: [4, 2], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.5167, Validation Loss: 0.7189,  Current Best Accuracy: 0.5167,  Current Best Validation Loss: 0.7189
Hidden Size: [4, 2], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4218, Validation Loss: 0.7254,  Current Best Accuracy: 0.4218,  Current Best Validation Loss: 0.7254
Hidden Size: [4, 2], Learning Rate: 0.001, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5795, Validation Loss: 0.6816,  Current Best Accuracy: 0.5795,  Current Best Validation Loss: 0.6816
Hidden Size: [4, 2], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.5346, Validation Loss: 0.6751,  Current Best Accuracy: 0.5346,  Current Best Validation Loss: 0.6751
Hidden Size: [4, 2], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4359, Validation Loss: 0.7161,  Current Best Accuracy: 0.4359,  Current Best Validation Loss: 0.7161
Hidden Size: [4, 2], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5628, Validation Loss: 0.7009,  Current Best Accuracy: 0.5628,  Current Best Validation Loss: 0.7009
Hidden Size: [5, 3], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.5782, Validation Loss: 0.8013,  Current Best Accuracy: 0.5782,  Current Best Validation Loss: 0.8013
Hidden Size: [5, 3], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.4859, Validation Loss: 0.7190,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.7190
Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.4410, Validation Loss: 0.7846,  Current Best Accuracy: 0.4410,  Current Best Validation Loss: 0.7846
Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4385, Validation Loss: 0.7745,  Current Best Accuracy: 0.4385,  Current Best Validation Loss: 0.7745
Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.4385, Validation Loss: 0.7122,  Current Best Accuracy: 0.4385,  Current Best Validation Loss: 0.7122
Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.5038, Validation Loss: 0.7512,  Current Best Accuracy: 0.5038,  Current Best Validation Loss: 0.7512
Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4551, Validation Loss: 0.7007,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7007
Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.5167, Validation Loss: 0.6897,  Current Best Accuracy: 0.5167,  Current Best Validation Loss: 0.6897
Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4526, Validation Loss: 0.7121,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7121
Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.5641, Validation Loss: 0.6938,  Current Best Accuracy: 0.5641,  Current Best Validation Loss: 0.6938
Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4526, Validation Loss: 0.6998,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.6998
Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.5295, Validation Loss: 0.7220,  Current Best Accuracy: 0.5295,  Current Best Validation Loss: 0.7220
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.5782, Validation Loss: 1.1672,  Current Best Accuracy: 0.5782,  Current Best Validation Loss: 1.1672
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5167, Validation Loss: 0.7341,  Current Best Accuracy: 0.5167,  Current Best Validation Loss: 0.7341
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4872, Validation Loss: 1.1198,  Current Best Accuracy: 0.4872,  Current Best Validation Loss: 1.1198
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4551, Validation Loss: 0.7563,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7563
Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4859, Validation Loss: 0.7239,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.7239
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4551, Validation Loss: 0.7086,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.7086
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.5167, Validation Loss: 0.7035,  Current Best Accuracy: 0.5167,  Current Best Validation Loss: 0.7035
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.4526, Validation Loss: 0.7026,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7026
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.4679, Validation Loss: 0.6976,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.6976
Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4821, Validation Loss: 0.7088,  Current Best Accuracy: 0.4821,  Current Best Validation Loss: 0.7088
Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5949, Validation Loss: 0.7006,  Current Best Accuracy: 0.5949,  Current Best Validation Loss: 0.7006
Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5013, Validation Loss: 0.7244,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7244
Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5013, Validation Loss: 0.7244,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7244

Configuration:
    return {
        "alpha": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],
        "batch_size": [4, 8, 16, 32, 64],
        "dropout": [0.0, 0.3, 0.5, 0.7],
        "hidden_layers_configuration": [[16, 8, 4], [32, 16, 8], [64, 32, 16]],
        "learning_rate": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],
        "weight_decay": [1e-1, 1e-2, 1e-3],
        "max_epochs_number": 100}