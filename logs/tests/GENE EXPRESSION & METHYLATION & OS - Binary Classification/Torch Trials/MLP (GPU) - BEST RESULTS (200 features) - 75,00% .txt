Accuracy in testing: 0.7500
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.7179, Validation Loss: 0.5305,  Current Best Accuracy: 0.7179,  Current Best Validation Loss: 0.5305
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.7987, Validation Loss: 0.4275,  Current Best Accuracy: 0.7987,  Current Best Validation Loss: 0.4275
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.7987, Validation Loss: 0.4275,  Current Best Accuracy: 0.7987,  Current Best Validation Loss: 0.4275
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3563,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.3563
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3563,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.3563
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.7808, Validation Loss: 0.4374,  Current Best Accuracy: 0.7808,  Current Best Validation Loss: 0.4374
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5808, Validation Loss: 0.6702,  Current Best Accuracy: 0.5808,  Current Best Validation Loss: 0.6702
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.6679, Validation Loss: 0.5802,  Current Best Accuracy: 0.6679,  Current Best Validation Loss: 0.5802
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.6244, Validation Loss: 0.6079,  Current Best Accuracy: 0.6244,  Current Best Validation Loss: 0.6079
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.7987, Validation Loss: 0.4275,  Current Best Accuracy: 0.7987,  Current Best Validation Loss: 0.4275
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3563,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.3563
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.7808, Validation Loss: 0.4374,  Current Best Accuracy: 0.7808,  Current Best Validation Loss: 0.4374
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5808, Validation Loss: 0.6702,  Current Best Accuracy: 0.5808,  Current Best Validation Loss: 0.6702
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.6679, Validation Loss: 0.5802,  Current Best Accuracy: 0.6679,  Current Best Validation Loss: 0.5802
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.6244, Validation Loss: 0.6079,  Current Best Accuracy: 0.6244,  Current Best Validation Loss: 0.6079
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.7987, Validation Loss: 0.4275,  Current Best Accuracy: 0.7987,  Current Best Validation Loss: 0.4275

Configuration:
    return {
        "alpha": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],
        "batch_size": [4, 8, 16, 32, 64],
        "dropout": [0.0, 0.25, 0.5],
        "hidden_layers_configuration": [[2], [4], [5], [8], [4, 2], [5, 3], [8, 4]],
        "learning_rate": [1e-1, 1e-2, 1e-3, 1e-4],
        "weight_decay": [1e-2, 1e-3, 1e-4, 1e-5],
        "max_epochs_number": 500}
 