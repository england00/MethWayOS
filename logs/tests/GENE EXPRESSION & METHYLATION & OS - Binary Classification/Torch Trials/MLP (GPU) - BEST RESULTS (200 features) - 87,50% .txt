Accuracy in testing: 0.8750
Hidden Size: [4], Learning Rate: 0.001, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.3910, Validation Loss: 0.7279,  Current Best Accuracy: 0.3910,  Current Best Validation Loss: 0.7279


Accuracy in testing: 0.8125
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5795, Validation Loss: 1.0238,  Current Best Accuracy: 0.5795,  Current Best Validation Loss: 1.0238
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4679, Validation Loss: 0.9882,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.9882
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.4205, Validation Loss: 0.8168,  Current Best Accuracy: 0.4205,  Current Best Validation Loss: 0.8168
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.5013, Validation Loss: 0.7399,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7399
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4064, Validation Loss: 0.7478,  Current Best Accuracy: 0.4064,  Current Best Validation Loss: 0.7478
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5321, Validation Loss: 0.7050,  Current Best Accuracy: 0.5321,  Current Best Validation Loss: 0.7050
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.5013, Validation Loss: 0.7365,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7365
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.4372, Validation Loss: 0.8286,  Current Best Accuracy: 0.4372,  Current Best Validation Loss: 0.8286
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4192, Validation Loss: 0.7413,  Current Best Accuracy: 0.4192,  Current Best Validation Loss: 0.7413
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4872, Validation Loss: 0.6760,  Current Best Accuracy: 0.4872,  Current Best Validation Loss: 0.6760
Hidden Size: [4], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.5782, Validation Loss: 0.7036,  Current Best Accuracy: 0.5782,  Current Best Validation Loss: 0.7036
Hidden Size: [4], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.4372, Validation Loss: 0.7389,  Current Best Accuracy: 0.4372,  Current Best Validation Loss: 0.7389
Hidden Size: [5], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.6244, Validation Loss: 1.0898,  Current Best Accuracy: 0.6244,  Current Best Validation Loss: 1.0898
Hidden Size: [5], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.4705, Validation Loss: 1.4889,  Current Best Accuracy: 0.4705,  Current Best Validation Loss: 1.4889
Hidden Size: [5], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4692, Validation Loss: 0.9680,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 0.9680
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4679, Validation Loss: 0.7403,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.7403
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4526, Validation Loss: 1.0483,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 1.0483
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4526, Validation Loss: 1.0483,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 1.0483
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.5000, Validation Loss: 0.7104,  Current Best Accuracy: 0.5000,  Current Best Validation Loss: 0.7104
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4987, Validation Loss: 0.8439,  Current Best Accuracy: 0.4987,  Current Best Validation Loss: 0.8439
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4821, Validation Loss: 0.7452,  Current Best Accuracy: 0.4821,  Current Best Validation Loss: 0.7452
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4679, Validation Loss: 0.9096,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.9096
Hidden Size: [4, 2], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4526, Validation Loss: 0.7969,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7969
Hidden Size: [4, 2], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5295, Validation Loss: 0.7375,  Current Best Accuracy: 0.5295,  Current Best Validation Loss: 0.7375
Hidden Size: [4, 2], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4859, Validation Loss: 0.7356,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 0.7356
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4987, Validation Loss: 0.8439,  Current Best Accuracy: 0.4987,  Current Best Validation Loss: 0.8439
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.5462, Validation Loss: 0.9860,  Current Best Accuracy: 0.5462,  Current Best Validation Loss: 0.9860
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.5756, Validation Loss: 0.8747,  Current Best Accuracy: 0.5756,  Current Best Validation Loss: 0.8747
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.4833, Validation Loss: 0.7177,  Current Best Accuracy: 0.4833,  Current Best Validation Loss: 0.7177



Accuracy in testing: 0.7500
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.7179, Validation Loss: 0.5305,  Current Best Accuracy: 0.7179,  Current Best Validation Loss: 0.5305
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.7987, Validation Loss: 0.4275,  Current Best Accuracy: 0.7987,  Current Best Validation Loss: 0.4275
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.7987, Validation Loss: 0.4275,  Current Best Accuracy: 0.7987,  Current Best Validation Loss: 0.4275
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3563,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.3563
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3563,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.3563
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.7808, Validation Loss: 0.4374,  Current Best Accuracy: 0.7808,  Current Best Validation Loss: 0.4374
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5808, Validation Loss: 0.6702,  Current Best Accuracy: 0.5808,  Current Best Validation Loss: 0.6702
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.6679, Validation Loss: 0.5802,  Current Best Accuracy: 0.6679,  Current Best Validation Loss: 0.5802
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.6244, Validation Loss: 0.6079,  Current Best Accuracy: 0.6244,  Current Best Validation Loss: 0.6079
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.7987, Validation Loss: 0.4275,  Current Best Accuracy: 0.7987,  Current Best Validation Loss: 0.4275
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3563,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.3563
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.7808, Validation Loss: 0.4374,  Current Best Accuracy: 0.7808,  Current Best Validation Loss: 0.4374
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5808, Validation Loss: 0.6702,  Current Best Accuracy: 0.5808,  Current Best Validation Loss: 0.6702
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.6679, Validation Loss: 0.5802,  Current Best Accuracy: 0.6679,  Current Best Validation Loss: 0.5802
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.6244, Validation Loss: 0.6079,  Current Best Accuracy: 0.6244,  Current Best Validation Loss: 0.6079
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.7987, Validation Loss: 0.4275,  Current Best Accuracy: 0.7987,  Current Best Validation Loss: 0.4275
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4859, Validation Loss: 1.4915,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 1.4915
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5321, Validation Loss: 0.8037,  Current Best Accuracy: 0.5321,  Current Best Validation Loss: 0.8037
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.5782, Validation Loss: 0.9585,  Current Best Accuracy: 0.5782,  Current Best Validation Loss: 0.9585
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5628, Validation Loss: 1.0400,  Current Best Accuracy: 0.5628,  Current Best Validation Loss: 1.0400
Hidden Size: [2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.4987, Validation Loss: 0.8568,  Current Best Accuracy: 0.4987,  Current Best Validation Loss: 0.8568
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.3756, Validation Loss: 0.8167,  Current Best Accuracy: 0.3756,  Current Best Validation Loss: 0.8167
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4692, Validation Loss: 0.7783,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 0.7783
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4692, Validation Loss: 0.7501,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 0.7501
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5590, Validation Loss: 0.7629,  Current Best Accuracy: 0.5590,  Current Best Validation Loss: 0.7629
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.5615, Validation Loss: 0.7505,  Current Best Accuracy: 0.5615,  Current Best Validation Loss: 0.7505
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.5000, Validation Loss: 0.6984,  Current Best Accuracy: 0.5000,  Current Best Validation Loss: 0.6984
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5295, Validation Loss: 0.7287,  Current Best Accuracy: 0.5295,  Current Best Validation Loss: 0.7287
Hidden Size: [2], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4679, Validation Loss: 0.7923,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.7923
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.4705, Validation Loss: 0.7440,  Current Best Accuracy: 0.4705,  Current Best Validation Loss: 0.7440
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.5321, Validation Loss: 0.6701,  Current Best Accuracy: 0.5321,  Current Best Validation Loss: 0.6701
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.5500, Validation Loss: 0.7509,  Current Best Accuracy: 0.5500,  Current Best Validation Loss: 0.7509
Hidden Size: [2], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.5449, Validation Loss: 0.7921,  Current Best Accuracy: 0.5449,  Current Best Validation Loss: 0.7921
Hidden Size: [2], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4679, Validation Loss: 0.7262,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.7262
Hidden Size: [4], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4692, Validation Loss: 1.3810,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 1.3810
Hidden Size: [4], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4372, Validation Loss: 1.0777,  Current Best Accuracy: 0.4372,  Current Best Validation Loss: 1.0777
Hidden Size: [4], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.4500, Validation Loss: 1.0556,  Current Best Accuracy: 0.4500,  Current Best Validation Loss: 1.0556
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.4372, Validation Loss: 0.8044,  Current Best Accuracy: 0.4372,  Current Best Validation Loss: 0.8044
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.5141, Validation Loss: 0.8401,  Current Best Accuracy: 0.5141,  Current Best Validation Loss: 0.8401
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4372, Validation Loss: 0.8033,  Current Best Accuracy: 0.4372,  Current Best Validation Loss: 0.8033
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5167, Validation Loss: 0.7327,  Current Best Accuracy: 0.5167,  Current Best Validation Loss: 0.7327
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5487, Validation Loss: 0.6866,  Current Best Accuracy: 0.5487,  Current Best Validation Loss: 0.6866
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5000, Validation Loss: 0.7327,  Current Best Accuracy: 0.5000,  Current Best Validation Loss: 0.7327
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.5321, Validation Loss: 0.7107,  Current Best Accuracy: 0.5321,  Current Best Validation Loss: 0.7107
Hidden Size: [4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.5154, Validation Loss: 0.6992,  Current Best Accuracy: 0.5154,  Current Best Validation Loss: 0.6992
Hidden Size: [4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.5013, Validation Loss: 0.7353,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 0.7353
Hidden Size: [4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4833, Validation Loss: 0.7068,  Current Best Accuracy: 0.4833,  Current Best Validation Loss: 0.7068
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4692, Validation Loss: 0.7366,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 0.7366
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.5154, Validation Loss: 0.7389,  Current Best Accuracy: 0.5154,  Current Best Validation Loss: 0.7389
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5474, Validation Loss: 0.7175,  Current Best Accuracy: 0.5474,  Current Best Validation Loss: 0.7175
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.1, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.5615, Validation Loss: 0.7146,  Current Best Accuracy: 0.5615,  Current Best Validation Loss: 0.7146
Hidden Size: [4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4397, Validation Loss: 0.7297,  Current Best Accuracy: 0.4397,  Current Best Validation Loss: 0.7297
Hidden Size: [5], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4346, Validation Loss: 1.1768,  Current Best Accuracy: 0.4346,  Current Best Validation Loss: 1.1768
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.3282, Validation Loss: 0.7852,  Current Best Accuracy: 0.3282,  Current Best Validation Loss: 0.7852
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.3910, Validation Loss: 0.7550,  Current Best Accuracy: 0.3910,  Current Best Validation Loss: 0.7550
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4231, Validation Loss: 0.7205,  Current Best Accuracy: 0.4231,  Current Best Validation Loss: 0.7205
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4064, Validation Loss: 0.7325,  Current Best Accuracy: 0.4064,  Current Best Validation Loss: 0.7325
Hidden Size: [5], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.5628, Validation Loss: 0.7097,  Current Best Accuracy: 0.5628,  Current Best Validation Loss: 0.7097
Hidden Size: [5], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.25, Weight Decay: 0.01, Accuracy: 0.4526, Validation Loss: 0.7092,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7092
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.5141, Validation Loss: 1.8766,  Current Best Accuracy: 0.5141,  Current Best Validation Loss: 1.8766
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.5013, Validation Loss: 1.7312,  Current Best Accuracy: 0.5013,  Current Best Validation Loss: 1.7312
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.001, Accuracy: 0.5949, Validation Loss: 1.6913,  Current Best Accuracy: 0.5949,  Current Best Validation Loss: 1.6913
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4333, Validation Loss: 1.2646,  Current Best Accuracy: 0.4333,  Current Best Validation Loss: 1.2646
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4205, Validation Loss: 1.1033,  Current Best Accuracy: 0.4205,  Current Best Validation Loss: 1.1033
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.4064, Validation Loss: 1.0827,  Current Best Accuracy: 0.4064,  Current Best Validation Loss: 1.0827
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4359, Validation Loss: 1.4184,  Current Best Accuracy: 0.4359,  Current Best Validation Loss: 1.4184
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.3718, Validation Loss: 1.2873,  Current Best Accuracy: 0.3718,  Current Best Validation Loss: 1.2873
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weight Decay: 0.01, Accuracy: 0.4692, Validation Loss: 1.0341,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 1.0341
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.4487, Validation Loss: 1.1279,  Current Best Accuracy: 0.4487,  Current Best Validation Loss: 1.1279
Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4833, Validation Loss: 1.0965,  Current Best Accuracy: 0.4833,  Current Best Validation Loss: 1.0965
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4538, Validation Loss: 0.9181,  Current Best Accuracy: 0.4538,  Current Best Validation Loss: 0.9181
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4064, Validation Loss: 0.8232,  Current Best Accuracy: 0.4064,  Current Best Validation Loss: 0.8232
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.3897, Validation Loss: 0.8123,  Current Best Accuracy: 0.3897,  Current Best Validation Loss: 0.8123
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4667, Validation Loss: 0.8778,  Current Best Accuracy: 0.4667,  Current Best Validation Loss: 0.8778
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4692, Validation Loss: 0.7546,  Current Best Accuracy: 0.4692,  Current Best Validation Loss: 0.7546
Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.4718, Validation Loss: 0.7228,  Current Best Accuracy: 0.4718,  Current Best Validation Loss: 0.7228
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.5474, Validation Loss: 0.9734,  Current Best Accuracy: 0.5474,  Current Best Validation Loss: 0.9734
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4718, Validation Loss: 0.7270,  Current Best Accuracy: 0.4718,  Current Best Validation Loss: 0.7270
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4385, Validation Loss: 0.9100,  Current Best Accuracy: 0.4385,  Current Best Validation Loss: 0.9100
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.5474, Validation Loss: 1.0902,  Current Best Accuracy: 0.5474,  Current Best Validation Loss: 1.0902
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 0.0001, Accuracy: 0.4705, Validation Loss: 0.8665,  Current Best Accuracy: 0.4705,  Current Best Validation Loss: 0.8665
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.25, Weight Decay: 0.001, Accuracy: 0.4821, Validation Loss: 0.7452,  Current Best Accuracy: 0.4821,  Current Best Validation Loss: 0.7452
Hidden Size: [4, 2], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4679, Validation Loss: 0.9096,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.9096
Hidden Size: [4, 2], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.0, Weight Decay: 0.0001, Accuracy: 0.4526, Validation Loss: 0.7969,  Current Best Accuracy: 0.4526,  Current Best Validation Loss: 0.7969
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Weight Decay: 1e-05, Accuracy: 0.4859, Validation Loss: 1.0067,  Current Best Accuracy: 0.4859,  Current Best Validation Loss: 1.0067
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.0, Weight Decay: 0.01, Accuracy: 0.4500, Validation Loss: 1.1905,  Current Best Accuracy: 0.4500,  Current Best Validation Loss: 1.1905
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4846, Validation Loss: 0.8097,  Current Best Accuracy: 0.4846,  Current Best Validation Loss: 0.8097
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.5628, Validation Loss: 0.7768,  Current Best Accuracy: 0.5628,  Current Best Validation Loss: 0.7768
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weight Decay: 1e-05, Accuracy: 0.4679, Validation Loss: 0.7420,  Current Best Accuracy: 0.4679,  Current Best Validation Loss: 0.7420
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.4346, Validation Loss: 0.7588,  Current Best Accuracy: 0.4346,  Current Best Validation Loss: 0.7588
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4551, Validation Loss: 0.8521,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.8521
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weight Decay: 0.0001, Accuracy: 0.5795, Validation Loss: 0.6938,  Current Best Accuracy: 0.5795,  Current Best Validation Loss: 0.6938
Hidden Size: [8, 4], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.4551, Validation Loss: 0.8521,  Current Best Accuracy: 0.4551,  Current Best Validation Loss: 0.8521
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.3936, Validation Loss: 0.7804,  Current Best Accuracy: 0.3936,  Current Best Validation Loss: 0.7804
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.25, Weight Decay: 1e-05, Accuracy: 0.5603, Validation Loss: 0.7193,  Current Best Accuracy: 0.5603,  Current Best Validation Loss: 0.7193
Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weight Decay: 0.001, Accuracy: 0.5769, Validation Loss: 0.7288,  Current Best Accuracy: 0.5769,  Current Best Validation Loss: 0.7288



Configuration:
    return {
        "alpha": [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],
        "batch_size": [4, 8, 16, 32, 64],
        "dropout": [0.0, 0.25, 0.5],
        "hidden_layers_configuration": [[2], [4], [5], [8], [4, 2], [5, 3], [8, 4]],
        "learning_rate": [1e-1, 1e-2, 1e-3, 1e-4],
        "weight_decay": [1e-2, 1e-3, 1e-4, 1e-5],
        "max_epochs_number": 500}