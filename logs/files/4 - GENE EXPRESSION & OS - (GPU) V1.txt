[36m 
############################### DATA ACQUISITION ############################### [39m
Data has been correctly loaded from ../../config/files/dataset_paths.yaml file
Data has been correctly loaded from ../../config/files/json_paths.yaml file
Data has been correctly loaded from ../../json_dir/indexes/gene_expression_names.json file
Data has been correctly loaded from ../../data/datasets/gene_expression_and_overall_survival_dataset.csv file
DIMENSIONS:
	--> Training Set: 223
	--> Testing Set: 56
[36m 
########################### TRAINING SET MANAGEMENT ############################ [39m
[36m 
################### EXPLORATORY DATA ANALYSIS with RAW DATA #################### [39m
[36m 
############################ FEATURES PREPROCESSING ############################ [39m
ADMITTED SAMPLES VALUES:
	--> 43 samples with a label lower than 1000
	--> 50 samples with a label bigger than 3000
[36m 
############################## FEATURES SELECTION ############################## [39m
VARIANCE SELECTION:
	--> New Feature Space Dimension: 2000
CORRELATION FILTER:
	--> New Feature Space Dimension: 250
[36m 
############################ TESTING SET MANAGEMENT ############################ [39m
[36m 
################### EXPLORATORY DATA ANALYSIS with RAW DATA #################### [39m
[36m 
############################ FEATURES PREPROCESSING ############################ [39m
ADMITTED SAMPLES VALUES:
	--> 10 samples with a label lower than 1000
	--> 13 samples with a label bigger than 3000
[36m 
############################## FEATURES SELECTION ############################## [39m
TOP FEATURES SELECTION:
	--> New Feature Space Dimension: 250
[36m 
############################### SKLEARN TO TORCH ############################### [39m
[36m 
################################# GRID SEARCH ################################## [39m

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.3874, Validation Loss: 0.4741
	--> Epoch [2/100], Loss: 0.0000, Validation Loss: 0.3106
	--> Epoch [3/100], Loss: 0.0000, Validation Loss: 0.8562
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.3635
	--> Epoch [5/100], Loss: 0.0197, Validation Loss: 0.4837
Early stopping
	--> Training for Fold 1 took 0.19580745697021484 sec, using 5 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.0902, Validation Loss: 0.5285
	--> Epoch [2/100], Loss: 0.0000, Validation Loss: 7.1422
	--> Epoch [3/100], Loss: 0.0000, Validation Loss: 7.6071
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 2.1873
Early stopping
	--> Training for Fold 2 took 0.2040855884552002 sec, using 4 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7592, Validation Loss: 1.5350
	--> Epoch [2/100], Loss: 0.3142, Validation Loss: 0.6436
	--> Epoch [3/100], Loss: 0.0105, Validation Loss: 0.5947
	--> Epoch [4/100], Loss: 0.0005, Validation Loss: 10.6369
	--> Epoch [5/100], Loss: 2.4117, Validation Loss: 6.3176
	--> Epoch [6/100], Loss: 0.0148, Validation Loss: 7.9370
Early stopping
	--> Training for Fold 3 took 0.3074815273284912 sec, using 6 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 2.1239, Validation Loss: 0.5761
	--> Epoch [2/100], Loss: 2.4478, Validation Loss: 3.8229
	--> Epoch [3/100], Loss: 2.0161, Validation Loss: 0.5743
	--> Epoch [4/100], Loss: 3.3333, Validation Loss: 1.2066
	--> Epoch [5/100], Loss: 3.4274, Validation Loss: 1.2823
	--> Epoch [6/100], Loss: 0.0220, Validation Loss: 3.6007
Early stopping
	--> Training for Fold 4 took 0.3200533390045166 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 2.8279, Validation Loss: 1.7901
	--> Epoch [2/100], Loss: 0.0257, Validation Loss: 2.8272
	--> Epoch [3/100], Loss: 0.0727, Validation Loss: 1.5914
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 3.1765
	--> Epoch [5/100], Loss: 0.2130, Validation Loss: 1.7031
	--> Epoch [6/100], Loss: 0.0067, Validation Loss: 1.1731
	--> Epoch [7/100], Loss: 2.0944, Validation Loss: 1.9911
	--> Epoch [8/100], Loss: 0.0572, Validation Loss: 2.0017
	--> Epoch [9/100], Loss: 0.0618, Validation Loss: 0.7267
	--> Epoch [10/100], Loss: 0.0723, Validation Loss: 0.5972
	--> Epoch [11/100], Loss: 5.3925, Validation Loss: 1.7065
	--> Epoch [12/100], Loss: 0.0385, Validation Loss: 0.4351
	--> Epoch [13/100], Loss: 0.0540, Validation Loss: 1.4805
	--> Epoch [14/100], Loss: 0.0861, Validation Loss: 0.4838
	--> Epoch [15/100], Loss: 1.3851, Validation Loss: 0.7011
Early stopping
	--> Training for Fold 5 took 0.8548336029052734 sec, using 15 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 9.5434
	--> Final training Epoch [2/6], Loss: 4.0642
	--> Final training Epoch [3/6], Loss: 2.1140
	--> Final training Epoch [4/6], Loss: 0.1771
	--> Final training Epoch [5/6], Loss: 0.0132
	--> Final training Epoch [6/6], Loss: 0.0032

Final training took 0.4635465145111084 sec

TESTING
	--> Testing took 0.0106 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.5042
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8076, Validation Loss: 1.7787,  Current Best Accuracy: 0.8076,  Current Best Validation Loss: 1.7787
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7608, Validation Loss: 2.2216,  Current Best Accuracy: 0.8076,  Current Best Validation Loss: 1.7787
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7427, Validation Loss: 3.6950,  Current Best Accuracy: 0.8076,  Current Best Validation Loss: 1.7787

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5004, Validation Loss: 0.2449
	--> Epoch [2/100], Loss: 0.9790, Validation Loss: 0.7594
	--> Epoch [3/100], Loss: 12.3879, Validation Loss: 0.2886
	--> Epoch [4/100], Loss: 0.3049, Validation Loss: 0.5328
Early stopping
	--> Training for Fold 1 took 0.2795066833496094 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.4257, Validation Loss: 2.8542
	--> Epoch [2/100], Loss: 11.5614, Validation Loss: 1.2229
	--> Epoch [3/100], Loss: 0.0195, Validation Loss: 0.6081
	--> Epoch [4/100], Loss: 0.1331, Validation Loss: 0.4196
	--> Epoch [5/100], Loss: 0.1355, Validation Loss: 0.6955
	--> Epoch [6/100], Loss: 0.0001, Validation Loss: 6.2846
	--> Epoch [7/100], Loss: 0.1412, Validation Loss: 5.1489
Early stopping
	--> Training for Fold 2 took 0.4247467517852783 sec, using 7 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 2.8275, Validation Loss: 4.5389
	--> Epoch [2/100], Loss: 0.1878, Validation Loss: 0.9031
	--> Epoch [3/100], Loss: 4.3043, Validation Loss: 2.4482
	--> Epoch [4/100], Loss: 0.0235, Validation Loss: 2.9457
	--> Epoch [5/100], Loss: 0.0979, Validation Loss: 1.8599
Early stopping
	--> Training for Fold 3 took 0.31568241119384766 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 2.0021, Validation Loss: 1.7524
	--> Epoch [2/100], Loss: 0.2595, Validation Loss: 1.2404
	--> Epoch [3/100], Loss: 0.1621, Validation Loss: 2.2779
	--> Epoch [4/100], Loss: 0.1082, Validation Loss: 4.9852
	--> Epoch [5/100], Loss: 0.1623, Validation Loss: 1.6081
Early stopping
	--> Training for Fold 4 took 0.3355579376220703 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4542, Validation Loss: 0.5552
	--> Epoch [2/100], Loss: 4.3077, Validation Loss: 0.3569
	--> Epoch [3/100], Loss: 0.3301, Validation Loss: 4.0456
	--> Epoch [4/100], Loss: 0.0233, Validation Loss: 2.1067
	--> Epoch [5/100], Loss: 0.0080, Validation Loss: 0.9381
Early stopping
	--> Training for Fold 5 took 0.31790781021118164 sec, using 5 epochs

Median number of epochs used: 5 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/5], Loss: 0.6766
	--> Final training Epoch [2/5], Loss: 0.9488
	--> Final training Epoch [3/5], Loss: 0.7152
	--> Final training Epoch [4/5], Loss: 0.1951
	--> Final training Epoch [5/5], Loss: 0.3047

Final training took 0.4513571262359619 sec

TESTING
	--> Testing took 0.0178 sec
	--> Final Accuracy: 0.4783
	--> Final Loss: 4.5785
	--> Final Precision: 0.5455
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5000
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7327, Validation Loss: 1.2790,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7544, Validation Loss: 3.8014,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7965, Validation Loss: 3.4808,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5883, Validation Loss: 4.0848,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7310, Validation Loss: 2.4896,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7193, Validation Loss: 3.0395,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6743, Validation Loss: 4.7675,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 2.1086,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 2.3906,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6579, Validation Loss: 2.0475,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6544, Validation Loss: 3.5589,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6006, Validation Loss: 4.7097,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6632, Validation Loss: 4.0054,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7544, Validation Loss: 6.8127,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7193, Validation Loss: 5.1672,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7421, Validation Loss: 3.8345,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8064, Validation Loss: 4.3270,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 2.7276,  Current Best Accuracy: 0.7327,  Current Best Validation Loss: 1.2790

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.0224, Validation Loss: 0.4603
	--> Epoch [2/100], Loss: 0.3875, Validation Loss: 0.2308
	--> Epoch [3/100], Loss: 0.0001, Validation Loss: 0.8524
	--> Epoch [4/100], Loss: 0.2034, Validation Loss: 1.8237
	--> Epoch [5/100], Loss: 0.0357, Validation Loss: 3.7037
Early stopping
	--> Training for Fold 1 took 0.24410510063171387 sec, using 5 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 3.5149, Validation Loss: 2.5414
	--> Epoch [2/100], Loss: 0.0019, Validation Loss: 2.0388
	--> Epoch [3/100], Loss: 26.6326, Validation Loss: 4.5862
	--> Epoch [4/100], Loss: 0.6602, Validation Loss: 15.8181
	--> Epoch [5/100], Loss: 0.0837, Validation Loss: 2.3233
Early stopping
	--> Training for Fold 2 took 0.22856688499450684 sec, using 5 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4077, Validation Loss: 3.0164
	--> Epoch [2/100], Loss: 10.0287, Validation Loss: 0.6227
	--> Epoch [3/100], Loss: 0.4400, Validation Loss: 2.7295
	--> Epoch [4/100], Loss: 0.3512, Validation Loss: 0.9129
	--> Epoch [5/100], Loss: 0.2999, Validation Loss: 2.7794
Early stopping
	--> Training for Fold 3 took 0.23814606666564941 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.0310, Validation Loss: 1.3779
	--> Epoch [2/100], Loss: 1.7737, Validation Loss: 1.7283
	--> Epoch [3/100], Loss: 2.0724, Validation Loss: 6.5791
	--> Epoch [4/100], Loss: 0.6359, Validation Loss: 1.2934
	--> Epoch [5/100], Loss: 0.1231, Validation Loss: 3.1164
	--> Epoch [6/100], Loss: 0.0665, Validation Loss: 1.7314
	--> Epoch [7/100], Loss: 0.1115, Validation Loss: 1.6757
Early stopping
	--> Training for Fold 4 took 0.3612358570098877 sec, using 7 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 1.4959, Validation Loss: 0.7091
	--> Epoch [2/100], Loss: 2.7643, Validation Loss: 0.4176
	--> Epoch [3/100], Loss: 0.0454, Validation Loss: 2.5836
	--> Epoch [4/100], Loss: 0.0422, Validation Loss: 0.9366
	--> Epoch [5/100], Loss: 0.0379, Validation Loss: 0.7307
Early stopping
	--> Training for Fold 5 took 0.26818156242370605 sec, using 5 epochs

Median number of epochs used: 5 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/5], Loss: 0.9723
	--> Final training Epoch [2/5], Loss: 0.9923
	--> Final training Epoch [3/5], Loss: 0.1340
	--> Final training Epoch [4/5], Loss: 0.1918
	--> Final training Epoch [5/5], Loss: 0.9669

Final training took 0.2949957847595215 sec

TESTING
	--> Testing took 0.0094 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 6.5333
	--> Final Precision: 0.8750
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7205, Validation Loss: 1.1382,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6421, Validation Loss: 4.2033,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7725, Validation Loss: 3.2228,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7187, Validation Loss: 3.0058,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7298, Validation Loss: 2.8215,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6854, Validation Loss: 5.2351,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.6895, Validation Loss: 5.0003,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7327, Validation Loss: 3.3332,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 2.9983,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7731, Validation Loss: 2.4701,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 2.7607,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7620, Validation Loss: 1.9445,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7053, Validation Loss: 4.1615,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7532, Validation Loss: 3.9406,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6351, Validation Loss: 9.4727,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7392, Validation Loss: 4.3998,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 4.9774,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 2.4035,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6573, Validation Loss: 6.8039,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6865, Validation Loss: 3.9106,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7404, Validation Loss: 4.3783,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6211, Validation Loss: 4.6127,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6889, Validation Loss: 6.0942,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7632, Validation Loss: 2.4557,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7725, Validation Loss: 1.6448,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7532, Validation Loss: 3.2839,  Current Best Accuracy: 0.7205,  Current Best Validation Loss: 1.1382

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 1.5214, Validation Loss: 1.6487
	--> Epoch [2/100], Loss: 0.8239, Validation Loss: 0.4689
	--> Epoch [3/100], Loss: 0.0082, Validation Loss: 0.4728
	--> Epoch [4/100], Loss: 0.4028, Validation Loss: 0.4590
	--> Epoch [5/100], Loss: 0.0074, Validation Loss: 0.4883
	--> Epoch [6/100], Loss: 0.0008, Validation Loss: 1.9539
	--> Epoch [7/100], Loss: 0.0455, Validation Loss: 0.5652
Early stopping
	--> Training for Fold 1 took 0.15714192390441895 sec, using 7 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.0393, Validation Loss: 1.3233
	--> Epoch [2/100], Loss: 3.2700, Validation Loss: 0.5901
	--> Epoch [3/100], Loss: 0.3814, Validation Loss: 7.4849
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.9090
	--> Epoch [5/100], Loss: 0.0000, Validation Loss: 0.3200
	--> Epoch [6/100], Loss: 0.0000, Validation Loss: 0.8844
	--> Epoch [7/100], Loss: 0.1346, Validation Loss: 1.9245
	--> Epoch [8/100], Loss: 0.0000, Validation Loss: 7.3458
Early stopping
	--> Training for Fold 2 took 0.18671441078186035 sec, using 8 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.0590, Validation Loss: 1.1629
	--> Epoch [2/100], Loss: 0.1756, Validation Loss: 1.0297
	--> Epoch [3/100], Loss: 0.0000, Validation Loss: 4.7036
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 2.7390
	--> Epoch [5/100], Loss: 0.0001, Validation Loss: 2.8763
Early stopping
	--> Training for Fold 3 took 0.12207746505737305 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.4598, Validation Loss: 1.6709
	--> Epoch [2/100], Loss: 1.0442, Validation Loss: 1.5433
	--> Epoch [3/100], Loss: 0.3030, Validation Loss: 2.8375
	--> Epoch [4/100], Loss: 0.2577, Validation Loss: 1.7928
	--> Epoch [5/100], Loss: 0.4111, Validation Loss: 3.0442
Early stopping
	--> Training for Fold 4 took 0.15590906143188477 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.0117, Validation Loss: 1.0812
	--> Epoch [2/100], Loss: 0.1521, Validation Loss: 2.6256
	--> Epoch [3/100], Loss: 0.0032, Validation Loss: 0.5147
	--> Epoch [4/100], Loss: 0.3089, Validation Loss: 3.8999
	--> Epoch [5/100], Loss: 0.1499, Validation Loss: 3.1187
	--> Epoch [6/100], Loss: 0.1417, Validation Loss: 3.9007
Early stopping
	--> Training for Fold 5 took 0.14947175979614258 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.3683
	--> Final training Epoch [2/6], Loss: 0.1937
	--> Final training Epoch [3/6], Loss: 0.0005
	--> Final training Epoch [4/6], Loss: 0.0001
	--> Final training Epoch [5/6], Loss: 0.0000
	--> Final training Epoch [6/6], Loss: 0.0553

Final training took 0.1667497158050537 sec

TESTING
	--> Testing took 0.0074 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 5.9403
	--> Final Precision: 0.6923
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6923
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7959, Validation Loss: 1.2371,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7626, Validation Loss: 1.4618,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 1.4646,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7287, Validation Loss: 3.1127,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7088, Validation Loss: 2.4299,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7175, Validation Loss: 1.9966,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6421, Validation Loss: 2.0483,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 2.4265,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8070, Validation Loss: 1.4345,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7088, Validation Loss: 2.0649,  Current Best Accuracy: 0.7959,  Current Best Validation Loss: 1.2371

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 3.8038, Validation Loss: 0.4874
	--> Epoch [2/100], Loss: 1.0448, Validation Loss: 0.7356
	--> Epoch [3/100], Loss: 4.9783, Validation Loss: 0.5997
	--> Epoch [4/100], Loss: 0.1394, Validation Loss: 0.2591
	--> Epoch [5/100], Loss: 0.1964, Validation Loss: 0.2255
	--> Epoch [6/100], Loss: 0.1160, Validation Loss: 0.3499
	--> Epoch [7/100], Loss: 0.2264, Validation Loss: 0.1191
	--> Epoch [8/100], Loss: 0.2771, Validation Loss: 1.3934
	--> Epoch [9/100], Loss: 0.0890, Validation Loss: 3.3922
	--> Epoch [10/100], Loss: 0.0593, Validation Loss: 1.8827
Early stopping
	--> Training for Fold 1 took 0.22598910331726074 sec, using 10 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 3.4195, Validation Loss: 0.9661
	--> Epoch [2/100], Loss: 3.5133, Validation Loss: 0.6118
	--> Epoch [3/100], Loss: 3.6146, Validation Loss: 0.9096
	--> Epoch [4/100], Loss: 0.1733, Validation Loss: 0.7992
	--> Epoch [5/100], Loss: 0.1929, Validation Loss: 0.8991
Early stopping
	--> Training for Fold 2 took 0.11872720718383789 sec, using 5 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.0035, Validation Loss: 0.8249
	--> Epoch [2/100], Loss: 1.8060, Validation Loss: 0.5858
	--> Epoch [3/100], Loss: 0.0983, Validation Loss: 1.1805
	--> Epoch [4/100], Loss: 0.0004, Validation Loss: 0.6772
	--> Epoch [5/100], Loss: 0.0000, Validation Loss: 2.4763
Early stopping
	--> Training for Fold 3 took 0.11793994903564453 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.1131, Validation Loss: 1.7658
	--> Epoch [2/100], Loss: 0.2109, Validation Loss: 0.6784
	--> Epoch [3/100], Loss: 0.5347, Validation Loss: 1.0836
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.2864
	--> Epoch [5/100], Loss: 0.2128, Validation Loss: 1.1486
	--> Epoch [6/100], Loss: 0.2111, Validation Loss: 0.9650
	--> Epoch [7/100], Loss: 0.6329, Validation Loss: 1.0002
Early stopping
	--> Training for Fold 4 took 0.16623687744140625 sec, using 7 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4209, Validation Loss: 0.7624
	--> Epoch [2/100], Loss: 0.2082, Validation Loss: 1.0753
	--> Epoch [3/100], Loss: 0.2137, Validation Loss: 0.6751
	--> Epoch [4/100], Loss: 0.1003, Validation Loss: 1.3174
	--> Epoch [5/100], Loss: 0.3231, Validation Loss: 1.4733
	--> Epoch [6/100], Loss: 0.2262, Validation Loss: 1.9993
Early stopping
	--> Training for Fold 5 took 0.1417980194091797 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 1.0149
	--> Final training Epoch [2/6], Loss: 0.3621
	--> Final training Epoch [3/6], Loss: 0.0000
	--> Final training Epoch [4/6], Loss: 1.8185
	--> Final training Epoch [5/6], Loss: 0.4707
	--> Final training Epoch [6/6], Loss: 0.0001

Final training took 0.16875123977661133 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 4.4124
	--> Final Precision: 0.7143
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7407
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 1.1605,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7404, Validation Loss: 1.4521,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7094, Validation Loss: 2.5578,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6105, Validation Loss: 2.3424,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8076, Validation Loss: 1.9728,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7632, Validation Loss: 1.5482,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7965, Validation Loss: 1.6292,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 1.4097,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7515, Validation Loss: 1.5333,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6801, Validation Loss: 1.6042,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7936, Validation Loss: 1.4973,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8058, Validation Loss: 2.2893,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6994, Validation Loss: 2.3784,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6333, Validation Loss: 2.0308,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6982, Validation Loss: 2.2767,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1605

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 2.4802, Validation Loss: 0.7210
	--> Epoch [2/100], Loss: 0.2514, Validation Loss: 0.7032
	--> Epoch [3/100], Loss: 0.0024, Validation Loss: 0.1572
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.0834
	--> Epoch [5/100], Loss: 0.7159, Validation Loss: 0.2379
	--> Epoch [6/100], Loss: 0.2654, Validation Loss: 0.8493
	--> Epoch [7/100], Loss: 0.6802, Validation Loss: 0.2337
Early stopping
	--> Training for Fold 1 took 0.16176581382751465 sec, using 7 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.0305, Validation Loss: 1.0702
	--> Epoch [2/100], Loss: 0.1629, Validation Loss: 0.4605
	--> Epoch [3/100], Loss: 0.3275, Validation Loss: 0.2520
	--> Epoch [4/100], Loss: 0.0240, Validation Loss: 0.2859
	--> Epoch [5/100], Loss: 0.0001, Validation Loss: 0.2336
	--> Epoch [6/100], Loss: 0.3540, Validation Loss: 1.2847
	--> Epoch [7/100], Loss: 0.0441, Validation Loss: 0.1638
	--> Epoch [8/100], Loss: 0.2268, Validation Loss: 0.6105
	--> Epoch [9/100], Loss: 0.0000, Validation Loss: 0.3563
	--> Epoch [10/100], Loss: 0.0000, Validation Loss: 0.9009
Early stopping
	--> Training for Fold 2 took 0.2273404598236084 sec, using 10 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 2.5895, Validation Loss: 0.6852
	--> Epoch [2/100], Loss: 0.0183, Validation Loss: 0.9347
	--> Epoch [3/100], Loss: 0.0033, Validation Loss: 1.3791
	--> Epoch [4/100], Loss: 0.0000, Validation Loss: 0.6129
	--> Epoch [5/100], Loss: 0.3170, Validation Loss: 0.9532
	--> Epoch [6/100], Loss: 0.0002, Validation Loss: 1.7398
	--> Epoch [7/100], Loss: 0.0000, Validation Loss: 1.2813
Early stopping
	--> Training for Fold 3 took 0.1687183380126953 sec, using 7 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.2364, Validation Loss: 0.2777
	--> Epoch [2/100], Loss: 0.0684, Validation Loss: 0.7004
	--> Epoch [3/100], Loss: 0.3930, Validation Loss: 0.8189
	--> Epoch [4/100], Loss: 0.0555, Validation Loss: 1.1044
Early stopping
	--> Training for Fold 4 took 0.0938408374786377 sec, using 4 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.2795, Validation Loss: 0.5597
	--> Epoch [2/100], Loss: 0.2018, Validation Loss: 1.0797
	--> Epoch [3/100], Loss: 0.0478, Validation Loss: 1.1925
	--> Epoch [4/100], Loss: 0.0003, Validation Loss: 1.0585
Early stopping
	--> Training for Fold 5 took 0.09415864944458008 sec, using 4 epochs

Median number of epochs used: 7 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/7], Loss: 0.5866
	--> Final training Epoch [2/7], Loss: 0.2317
	--> Final training Epoch [3/7], Loss: 0.9263
	--> Final training Epoch [4/7], Loss: 0.0450
	--> Final training Epoch [5/7], Loss: 0.0003
	--> Final training Epoch [6/7], Loss: 0.0056
	--> Final training Epoch [7/7], Loss: 0.0000

Final training took 0.18835735321044922 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 3.0536
	--> Final Precision: 0.6429
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7427, Validation Loss: 1.0579,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 2.3615,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8181, Validation Loss: 1.1579,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6632, Validation Loss: 2.1880,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7310, Validation Loss: 3.0750,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7538, Validation Loss: 2.6075,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6860, Validation Loss: 3.4810,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7433, Validation Loss: 2.7527,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7860, Validation Loss: 1.8797,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7433, Validation Loss: 1.6440,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7626, Validation Loss: 1.7875,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8801, Validation Loss: 1.7298,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7737, Validation Loss: 2.6816,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 1.2643,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7515, Validation Loss: 1.4759,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6023, Validation Loss: 2.6110,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7509, Validation Loss: 3.3647,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6760, Validation Loss: 3.7766,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8047, Validation Loss: 1.6880,  Current Best Accuracy: 0.7427,  Current Best Validation Loss: 1.0579

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.3115, Validation Loss: 0.3689
	--> Epoch [2/100], Loss: 0.4054, Validation Loss: 0.2073
	--> Epoch [3/100], Loss: 0.1665, Validation Loss: 0.1373
	--> Epoch [4/100], Loss: 0.1181, Validation Loss: 0.1722
	--> Epoch [5/100], Loss: 0.4486, Validation Loss: 0.5944
	--> Epoch [6/100], Loss: 0.2650, Validation Loss: 0.5178
Early stopping
	--> Training for Fold 1 took 0.08009004592895508 sec, using 6 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.2886, Validation Loss: 1.7204
	--> Epoch [2/100], Loss: 0.9396, Validation Loss: 1.5827
	--> Epoch [3/100], Loss: 0.1963, Validation Loss: 0.5077
	--> Epoch [4/100], Loss: 0.2089, Validation Loss: 0.9690
	--> Epoch [5/100], Loss: 0.0275, Validation Loss: 0.7389
	--> Epoch [6/100], Loss: 0.0004, Validation Loss: 0.3346
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.4244
	--> Epoch [8/100], Loss: 0.0000, Validation Loss: 0.4490
	--> Epoch [9/100], Loss: 0.1535, Validation Loss: 0.2961
	--> Epoch [10/100], Loss: 0.1294, Validation Loss: 0.5688
	--> Epoch [11/100], Loss: 0.0746, Validation Loss: 0.4970
	--> Epoch [12/100], Loss: 0.0056, Validation Loss: 0.7171
Early stopping
	--> Training for Fold 2 took 0.19916939735412598 sec, using 12 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8194, Validation Loss: 1.4800
	--> Epoch [2/100], Loss: 0.0580, Validation Loss: 0.5166
	--> Epoch [3/100], Loss: 0.2563, Validation Loss: 0.6894
	--> Epoch [4/100], Loss: 0.0869, Validation Loss: 1.2013
	--> Epoch [5/100], Loss: 0.0003, Validation Loss: 0.9452
Early stopping
	--> Training for Fold 3 took 0.06463956832885742 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6989, Validation Loss: 0.5399
	--> Epoch [2/100], Loss: 0.8195, Validation Loss: 1.6071
	--> Epoch [3/100], Loss: 0.3134, Validation Loss: 0.5333
	--> Epoch [4/100], Loss: 0.1489, Validation Loss: 1.4462
	--> Epoch [5/100], Loss: 0.0163, Validation Loss: 1.5854
	--> Epoch [6/100], Loss: 0.1285, Validation Loss: 0.9514
Early stopping
	--> Training for Fold 4 took 0.07752346992492676 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4713, Validation Loss: 1.1495
	--> Epoch [2/100], Loss: 1.0011, Validation Loss: 1.3532
	--> Epoch [3/100], Loss: 0.0203, Validation Loss: 1.1232
	--> Epoch [4/100], Loss: 0.0952, Validation Loss: 1.0796
	--> Epoch [5/100], Loss: 0.4626, Validation Loss: 0.3225
	--> Epoch [6/100], Loss: 0.0393, Validation Loss: 1.1556
	--> Epoch [7/100], Loss: 2.6920, Validation Loss: 2.8041
	--> Epoch [8/100], Loss: 0.1419, Validation Loss: 2.3106
Early stopping
	--> Training for Fold 5 took 0.10433459281921387 sec, using 8 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 1.0219
	--> Final training Epoch [2/6], Loss: 1.0038
	--> Final training Epoch [3/6], Loss: 0.2641
	--> Final training Epoch [4/6], Loss: 0.1422
	--> Final training Epoch [5/6], Loss: 1.2881
	--> Final training Epoch [6/6], Loss: 0.5201

Final training took 0.09768819808959961 sec

TESTING
	--> Testing took 0.0111 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 7.0296
	--> Final Precision: 0.6923
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6923
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 1.1197,  Current Best Accuracy: 0.8058,  Current Best Validation Loss: 1.1197

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.2339, Validation Loss: 0.4214
	--> Epoch [2/100], Loss: 0.1437, Validation Loss: 1.9264
	--> Epoch [3/100], Loss: 0.0370, Validation Loss: 0.5229
	--> Epoch [4/100], Loss: 0.5446, Validation Loss: 0.1430
	--> Epoch [5/100], Loss: 0.3036, Validation Loss: 0.5558
	--> Epoch [6/100], Loss: 1.3027, Validation Loss: 1.4667
	--> Epoch [7/100], Loss: 0.4014, Validation Loss: 0.5343
Early stopping
	--> Training for Fold 1 took 0.08533501625061035 sec, using 7 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 1.4515, Validation Loss: 1.5933
	--> Epoch [2/100], Loss: 1.0752, Validation Loss: 1.7281
	--> Epoch [3/100], Loss: 0.2911, Validation Loss: 0.6961
	--> Epoch [4/100], Loss: 1.0662, Validation Loss: 0.6540
	--> Epoch [5/100], Loss: 0.1429, Validation Loss: 0.3252
	--> Epoch [6/100], Loss: 0.3702, Validation Loss: 0.6460
	--> Epoch [7/100], Loss: 0.2883, Validation Loss: 0.3410
	--> Epoch [8/100], Loss: 0.2857, Validation Loss: 0.3729
Early stopping
	--> Training for Fold 2 took 0.09595155715942383 sec, using 8 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8302, Validation Loss: 1.1944
	--> Epoch [2/100], Loss: 0.8715, Validation Loss: 0.3790
	--> Epoch [3/100], Loss: 0.0927, Validation Loss: 0.5633
	--> Epoch [4/100], Loss: 0.0558, Validation Loss: 0.6426
	--> Epoch [5/100], Loss: 0.0763, Validation Loss: 0.6236
Early stopping
	--> Training for Fold 3 took 0.06740832328796387 sec, using 5 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.6277, Validation Loss: 1.4560
	--> Epoch [2/100], Loss: 0.1512, Validation Loss: 0.7388
	--> Epoch [3/100], Loss: 0.3638, Validation Loss: 0.6457
	--> Epoch [4/100], Loss: 0.0401, Validation Loss: 0.9939
	--> Epoch [5/100], Loss: 0.5451, Validation Loss: 1.5902
	--> Epoch [6/100], Loss: 0.0000, Validation Loss: 0.7003
Early stopping
	--> Training for Fold 4 took 0.08592915534973145 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7416, Validation Loss: 1.6531
	--> Epoch [2/100], Loss: 0.2705, Validation Loss: 0.6617
	--> Epoch [3/100], Loss: 0.0858, Validation Loss: 0.6899
	--> Epoch [4/100], Loss: 0.1635, Validation Loss: 1.8195
	--> Epoch [5/100], Loss: 0.3463, Validation Loss: 4.1054
Early stopping
	--> Training for Fold 5 took 0.09352803230285645 sec, using 5 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.2936
	--> Final training Epoch [2/6], Loss: 1.5158
	--> Final training Epoch [3/6], Loss: 2.4752
	--> Final training Epoch [4/6], Loss: 0.2115
	--> Final training Epoch [5/6], Loss: 0.6042
	--> Final training Epoch [6/6], Loss: 0.2800

Final training took 0.0929555892944336 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.4783
	--> Final Loss: 1.7581
	--> Final Precision: 0.5556
	--> Final Recall: 0.3846
	--> Final F1 Score: 0.4545
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8175, Validation Loss: 1.1188,  Current Best Accuracy: 0.8175,  Current Best Validation Loss: 1.1188

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8542, Validation Loss: 0.8969
	--> Epoch [2/100], Loss: 0.5817, Validation Loss: 0.7305
	--> Epoch [3/100], Loss: 0.8219, Validation Loss: 0.1341
	--> Epoch [4/100], Loss: 0.2416, Validation Loss: 0.1862
	--> Epoch [5/100], Loss: 0.0867, Validation Loss: 0.1683
	--> Epoch [6/100], Loss: 0.1689, Validation Loss: 0.1151
	--> Epoch [7/100], Loss: 0.2734, Validation Loss: 0.4240
	--> Epoch [8/100], Loss: 0.0319, Validation Loss: 0.3193
	--> Epoch [9/100], Loss: 0.2849, Validation Loss: 0.2976
Early stopping
	--> Training for Fold 1 took 0.10994887351989746 sec, using 9 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 2.0177, Validation Loss: 0.8178
	--> Epoch [2/100], Loss: 0.9105, Validation Loss: 1.7469
	--> Epoch [3/100], Loss: 0.3086, Validation Loss: 0.2287
	--> Epoch [4/100], Loss: 0.4241, Validation Loss: 0.5238
	--> Epoch [5/100], Loss: 0.0802, Validation Loss: 0.3108
	--> Epoch [6/100], Loss: 0.6438, Validation Loss: 0.1852
	--> Epoch [7/100], Loss: 0.0745, Validation Loss: 0.6032
	--> Epoch [8/100], Loss: 0.1663, Validation Loss: 0.5058
	--> Epoch [9/100], Loss: 0.2929, Validation Loss: 0.5416
Early stopping
	--> Training for Fold 2 took 0.13295722007751465 sec, using 9 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 1.0469, Validation Loss: 0.9991
	--> Epoch [2/100], Loss: 0.2251, Validation Loss: 0.7306
	--> Epoch [3/100], Loss: 0.1083, Validation Loss: 0.6686
	--> Epoch [4/100], Loss: 0.8869, Validation Loss: 0.8452
	--> Epoch [5/100], Loss: 0.2354, Validation Loss: 0.6302
	--> Epoch [6/100], Loss: 0.1635, Validation Loss: 0.5979
	--> Epoch [7/100], Loss: 0.1765, Validation Loss: 1.0213
	--> Epoch [8/100], Loss: 0.2082, Validation Loss: 0.5989
	--> Epoch [9/100], Loss: 0.2102, Validation Loss: 0.4256
	--> Epoch [10/100], Loss: 0.1404, Validation Loss: 1.0827
	--> Epoch [11/100], Loss: 0.1924, Validation Loss: 1.4249
	--> Epoch [12/100], Loss: 0.0001, Validation Loss: 1.0630
Early stopping
	--> Training for Fold 3 took 0.1529688835144043 sec, using 12 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.3098, Validation Loss: 1.1914
	--> Epoch [2/100], Loss: 0.7341, Validation Loss: 0.5391
	--> Epoch [3/100], Loss: 2.3868, Validation Loss: 3.4308
	--> Epoch [4/100], Loss: 0.7157, Validation Loss: 1.0338
	--> Epoch [5/100], Loss: 1.8870, Validation Loss: 1.6745
Early stopping
	--> Training for Fold 4 took 0.07029294967651367 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 1.0902, Validation Loss: 2.3529
	--> Epoch [2/100], Loss: 0.5164, Validation Loss: 0.6144
	--> Epoch [3/100], Loss: 0.4647, Validation Loss: 0.9010
	--> Epoch [4/100], Loss: 1.1228, Validation Loss: 0.9428
	--> Epoch [5/100], Loss: 0.3114, Validation Loss: 1.4345
Early stopping
	--> Training for Fold 5 took 0.05958390235900879 sec, using 5 epochs

Median number of epochs used: 9 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/9], Loss: 1.6741
	--> Final training Epoch [2/9], Loss: 0.5513
	--> Final training Epoch [3/9], Loss: 0.5144
	--> Final training Epoch [4/9], Loss: 0.8321
	--> Final training Epoch [5/9], Loss: 0.6216
	--> Final training Epoch [6/9], Loss: 0.1489
	--> Final training Epoch [7/9], Loss: 0.0833
	--> Final training Epoch [8/9], Loss: 0.1739
	--> Final training Epoch [9/9], Loss: 0.1073

Final training took 0.13803458213806152 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.5217
	--> Final Loss: 3.7302
	--> Final Precision: 0.7500
	--> Final Recall: 0.2308
	--> Final F1 Score: 0.3529
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.6032,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 1.0196,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7643, Validation Loss: 0.7890,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6871, Validation Loss: 2.0207,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7129, Validation Loss: 1.1306,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6304, Validation Loss: 2.4182,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.9998,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.7304,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 1.0877,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 1.1446,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7848, Validation Loss: 1.0613,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7181, Validation Loss: 1.5775,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6871, Validation Loss: 2.3622,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7105, Validation Loss: 2.2896,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7626, Validation Loss: 1.6788,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7842, Validation Loss: 0.7426,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8175, Validation Loss: 1.1368,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8064, Validation Loss: 1.1497,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8164, Validation Loss: 0.8762,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7731, Validation Loss: 1.0136,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.7986,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7292, Validation Loss: 0.9010,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6883, Validation Loss: 1.6487,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7737, Validation Loss: 1.5316,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7602, Validation Loss: 1.9003,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.9312,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7509, Validation Loss: 2.4422,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7310, Validation Loss: 0.8819,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.6649, Validation Loss: 1.6344,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7842, Validation Loss: 0.7131,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6988, Validation Loss: 1.1487,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6006, Validation Loss: 2.0578,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7743, Validation Loss: 0.9939,  Current Best Accuracy: 0.8392,  Current Best Validation Loss: 0.6032

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 1.3317, Validation Loss: 1.1672
	--> Epoch [2/100], Loss: 0.4726, Validation Loss: 0.2167
	--> Epoch [3/100], Loss: 0.2439, Validation Loss: 0.1738
	--> Epoch [4/100], Loss: 0.1552, Validation Loss: 0.1688
	--> Epoch [5/100], Loss: 0.2329, Validation Loss: 0.1999
	--> Epoch [6/100], Loss: 0.3295, Validation Loss: 0.1032
	--> Epoch [7/100], Loss: 0.1146, Validation Loss: 0.1238
	--> Epoch [8/100], Loss: 0.1646, Validation Loss: 0.1159
	--> Epoch [9/100], Loss: 0.1032, Validation Loss: 0.0695
	--> Epoch [10/100], Loss: 0.1911, Validation Loss: 0.1404
	--> Epoch [11/100], Loss: 0.0001, Validation Loss: 0.0504
	--> Epoch [12/100], Loss: 0.4225, Validation Loss: 0.0733
	--> Epoch [13/100], Loss: 0.0113, Validation Loss: 0.0941
	--> Epoch [14/100], Loss: 0.0024, Validation Loss: 0.0416
	--> Epoch [15/100], Loss: 0.0011, Validation Loss: 0.6257
	--> Epoch [16/100], Loss: 0.0002, Validation Loss: 0.1923
	--> Epoch [17/100], Loss: 0.0050, Validation Loss: 0.1549
Early stopping
	--> Training for Fold 1 took 0.2031998634338379 sec, using 17 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 3.1750, Validation Loss: 2.4510
	--> Epoch [2/100], Loss: 0.2611, Validation Loss: 0.3694
	--> Epoch [3/100], Loss: 0.1553, Validation Loss: 0.3966
	--> Epoch [4/100], Loss: 0.8033, Validation Loss: 0.4060
	--> Epoch [5/100], Loss: 0.1086, Validation Loss: 0.1885
	--> Epoch [6/100], Loss: 0.3402, Validation Loss: 0.1755
	--> Epoch [7/100], Loss: 0.3843, Validation Loss: 0.2016
	--> Epoch [8/100], Loss: 0.1194, Validation Loss: 0.2740
	--> Epoch [9/100], Loss: 0.4130, Validation Loss: 0.4750
Early stopping
	--> Training for Fold 2 took 0.15242791175842285 sec, using 9 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 1.0646, Validation Loss: 1.2839
	--> Epoch [2/100], Loss: 1.3267, Validation Loss: 0.7689
	--> Epoch [3/100], Loss: 0.6578, Validation Loss: 1.3782
	--> Epoch [4/100], Loss: 0.4142, Validation Loss: 0.8388
	--> Epoch [5/100], Loss: 0.1460, Validation Loss: 0.7495
	--> Epoch [6/100], Loss: 0.2494, Validation Loss: 0.6376
	--> Epoch [7/100], Loss: 0.0990, Validation Loss: 0.5380
	--> Epoch [8/100], Loss: 0.2079, Validation Loss: 0.6848
	--> Epoch [9/100], Loss: 0.1437, Validation Loss: 0.7953
	--> Epoch [10/100], Loss: 0.0962, Validation Loss: 0.7658
Early stopping
	--> Training for Fold 3 took 0.14372563362121582 sec, using 10 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 1.0972, Validation Loss: 0.7138
	--> Epoch [2/100], Loss: 1.7010, Validation Loss: 1.0634
	--> Epoch [3/100], Loss: 0.0700, Validation Loss: 0.6161
	--> Epoch [4/100], Loss: 0.0473, Validation Loss: 0.5758
	--> Epoch [5/100], Loss: 0.0174, Validation Loss: 0.5379
	--> Epoch [6/100], Loss: 0.0007, Validation Loss: 0.4924
	--> Epoch [7/100], Loss: 0.0098, Validation Loss: 0.4233
	--> Epoch [8/100], Loss: 0.0093, Validation Loss: 0.6844
	--> Epoch [9/100], Loss: 1.7888, Validation Loss: 1.1704
	--> Epoch [10/100], Loss: 0.7532, Validation Loss: 3.0121
Early stopping
	--> Training for Fold 4 took 0.12256813049316406 sec, using 10 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4361, Validation Loss: 1.4882
	--> Epoch [2/100], Loss: 0.1996, Validation Loss: 0.6770
	--> Epoch [3/100], Loss: 0.1652, Validation Loss: 0.7780
	--> Epoch [4/100], Loss: 0.0547, Validation Loss: 0.7164
	--> Epoch [5/100], Loss: 0.0804, Validation Loss: 0.6584
	--> Epoch [6/100], Loss: 0.0045, Validation Loss: 0.4215
	--> Epoch [7/100], Loss: 0.1140, Validation Loss: 0.4687
	--> Epoch [8/100], Loss: 0.0474, Validation Loss: 0.5668
	--> Epoch [9/100], Loss: 0.0209, Validation Loss: 0.7382
Early stopping
	--> Training for Fold 5 took 0.1130828857421875 sec, using 9 epochs

Median number of epochs used: 10 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/10], Loss: 0.5079
	--> Final training Epoch [2/10], Loss: 1.6783
	--> Final training Epoch [3/10], Loss: 0.3505
	--> Final training Epoch [4/10], Loss: 0.1380
	--> Final training Epoch [5/10], Loss: 0.1221
	--> Final training Epoch [6/10], Loss: 0.1654
	--> Final training Epoch [7/10], Loss: 0.3422
	--> Final training Epoch [8/10], Loss: 0.1435
	--> Final training Epoch [9/10], Loss: 0.5479
	--> Final training Epoch [10/10], Loss: 0.4285

Final training took 0.14211153984069824 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 3.9780
	--> Final Precision: 0.8000
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6957
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8269, Validation Loss: 0.4209,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7649, Validation Loss: 1.8898,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8058, Validation Loss: 1.0794,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7842, Validation Loss: 0.6857,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7386, Validation Loss: 1.5194,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7409, Validation Loss: 1.3874,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7427, Validation Loss: 1.1168,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6345, Validation Loss: 1.4120,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7310, Validation Loss: 1.6141,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7947, Validation Loss: 0.6496,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.5490,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.6114,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7374, Validation Loss: 0.5073,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7643, Validation Loss: 0.8142,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8158, Validation Loss: 0.8155,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7632, Validation Loss: 0.8013,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7848, Validation Loss: 0.8397,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7310, Validation Loss: 0.7651,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7187, Validation Loss: 1.0032,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.7812,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.6737,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7415, Validation Loss: 1.0281,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7614, Validation Loss: 0.9750,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7304, Validation Loss: 0.6854,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6404, Validation Loss: 1.3883,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7439, Validation Loss: 1.2658,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7111, Validation Loss: 1.1450,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7936, Validation Loss: 0.7190,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 0.8736,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8187, Validation Loss: 0.7201,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7532, Validation Loss: 0.5596,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8064, Validation Loss: 0.7290,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.6643, Validation Loss: 1.9300,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6222, Validation Loss: 1.6013,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6673, Validation Loss: 1.1112,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6310, Validation Loss: 1.5173,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8690, Validation Loss: 0.5493,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7947, Validation Loss: 0.6827,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7532, Validation Loss: 0.9595,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8175, Validation Loss: 0.5423,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.6148,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7854, Validation Loss: 0.5928,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6439, Validation Loss: 1.6972,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6637, Validation Loss: 2.0602,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7421, Validation Loss: 0.7284,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.5866,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.7987,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7942, Validation Loss: 0.9777,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8076, Validation Loss: 0.6051,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7298, Validation Loss: 1.0250,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7503, Validation Loss: 1.1648,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6023, Validation Loss: 1.1313,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7842, Validation Loss: 0.7265,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6795, Validation Loss: 1.0849,  Current Best Accuracy: 0.8269,  Current Best Validation Loss: 0.4209

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.4715, Validation Loss: 1.0186
	--> Epoch [2/100], Loss: 0.5768, Validation Loss: 0.6840
	--> Epoch [3/100], Loss: 0.0057, Validation Loss: 0.1500
	--> Epoch [4/100], Loss: 0.0173, Validation Loss: 0.1654
	--> Epoch [5/100], Loss: 0.2749, Validation Loss: 0.1154
	--> Epoch [6/100], Loss: 0.0005, Validation Loss: 0.1150
	--> Epoch [7/100], Loss: 0.0006, Validation Loss: 0.1292
	--> Epoch [8/100], Loss: 0.0011, Validation Loss: 0.1229
	--> Epoch [9/100], Loss: 0.0059, Validation Loss: 0.1260
Early stopping
	--> Training for Fold 1 took 0.06523990631103516 sec, using 9 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.2689, Validation Loss: 0.5276
	--> Epoch [2/100], Loss: 1.3595, Validation Loss: 0.1100
	--> Epoch [3/100], Loss: 0.0499, Validation Loss: 0.1351
	--> Epoch [4/100], Loss: 0.0337, Validation Loss: 0.2466
	--> Epoch [5/100], Loss: 0.1398, Validation Loss: 0.1797
Early stopping
	--> Training for Fold 2 took 0.0307769775390625 sec, using 5 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 1.2821, Validation Loss: 0.8225
	--> Epoch [2/100], Loss: 0.2195, Validation Loss: 0.4152
	--> Epoch [3/100], Loss: 1.2951, Validation Loss: 0.4165
	--> Epoch [4/100], Loss: 0.1586, Validation Loss: 0.4203
	--> Epoch [5/100], Loss: 0.2329, Validation Loss: 0.3071
	--> Epoch [6/100], Loss: 0.1655, Validation Loss: 0.3740
	--> Epoch [7/100], Loss: 0.1588, Validation Loss: 0.3838
	--> Epoch [8/100], Loss: 0.1527, Validation Loss: 0.3752
Early stopping
	--> Training for Fold 3 took 0.052700042724609375 sec, using 8 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.4242, Validation Loss: 2.1848
	--> Epoch [2/100], Loss: 1.1732, Validation Loss: 0.3978
	--> Epoch [3/100], Loss: 0.1198, Validation Loss: 0.4844
	--> Epoch [4/100], Loss: 0.1468, Validation Loss: 0.4729
	--> Epoch [5/100], Loss: 0.0596, Validation Loss: 0.4773
Early stopping
	--> Training for Fold 4 took 0.03291034698486328 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5206, Validation Loss: 1.3615
	--> Epoch [2/100], Loss: 0.7931, Validation Loss: 1.3384
	--> Epoch [3/100], Loss: 0.2331, Validation Loss: 1.0302
	--> Epoch [4/100], Loss: 0.1181, Validation Loss: 1.4012
	--> Epoch [5/100], Loss: 0.0718, Validation Loss: 1.3537
	--> Epoch [6/100], Loss: 0.0647, Validation Loss: 1.2551
Early stopping
	--> Training for Fold 5 took 0.038573265075683594 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.5143
	--> Final training Epoch [2/6], Loss: 0.7233
	--> Final training Epoch [3/6], Loss: 0.8170
	--> Final training Epoch [4/6], Loss: 0.1491
	--> Final training Epoch [5/6], Loss: 0.1129
	--> Final training Epoch [6/6], Loss: 0.0641

Final training took 0.03825545310974121 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 2.0735
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8585, Validation Loss: 0.4018,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.4018
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7614, Validation Loss: 1.0496,  Current Best Accuracy: 0.8585,  Current Best Validation Loss: 0.4018

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 1.2583, Validation Loss: 0.3558
	--> Epoch [2/100], Loss: 0.2908, Validation Loss: 0.9290
	--> Epoch [3/100], Loss: 0.0540, Validation Loss: 0.4987
	--> Epoch [4/100], Loss: 0.0096, Validation Loss: 0.3818
Early stopping
	--> Training for Fold 1 took 0.025847673416137695 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8196, Validation Loss: 0.3743
	--> Epoch [2/100], Loss: 0.1015, Validation Loss: 0.0624
	--> Epoch [3/100], Loss: 0.8890, Validation Loss: 0.8000
	--> Epoch [4/100], Loss: 0.0140, Validation Loss: 0.1803
	--> Epoch [5/100], Loss: 0.0028, Validation Loss: 0.1268
Early stopping
	--> Training for Fold 2 took 0.030321836471557617 sec, using 5 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.3717, Validation Loss: 1.6268
	--> Epoch [2/100], Loss: 0.3434, Validation Loss: 0.5391
	--> Epoch [3/100], Loss: 1.2500, Validation Loss: 0.4444
	--> Epoch [4/100], Loss: 0.0724, Validation Loss: 0.4648
	--> Epoch [5/100], Loss: 0.1147, Validation Loss: 0.3848
	--> Epoch [6/100], Loss: 0.1732, Validation Loss: 0.4167
	--> Epoch [7/100], Loss: 0.1445, Validation Loss: 0.3282
	--> Epoch [8/100], Loss: 0.1452, Validation Loss: 0.5471
	--> Epoch [9/100], Loss: 0.0643, Validation Loss: 0.5336
	--> Epoch [10/100], Loss: 0.1392, Validation Loss: 0.5089
Early stopping
	--> Training for Fold 3 took 0.05836915969848633 sec, using 10 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5231, Validation Loss: 3.0389
	--> Epoch [2/100], Loss: 0.2627, Validation Loss: 0.3119
	--> Epoch [3/100], Loss: 0.0718, Validation Loss: 0.3522
	--> Epoch [4/100], Loss: 0.0385, Validation Loss: 0.3696
	--> Epoch [5/100], Loss: 0.0358, Validation Loss: 0.2732
	--> Epoch [6/100], Loss: 0.0014, Validation Loss: 0.2825
	--> Epoch [7/100], Loss: 0.0188, Validation Loss: 0.2757
	--> Epoch [8/100], Loss: 0.0474, Validation Loss: 0.2542
	--> Epoch [9/100], Loss: 0.0693, Validation Loss: 0.1839
	--> Epoch [10/100], Loss: 0.0014, Validation Loss: 0.1969
	--> Epoch [11/100], Loss: 0.0006, Validation Loss: 0.2701
	--> Epoch [12/100], Loss: 0.0075, Validation Loss: 0.2580
Early stopping
	--> Training for Fold 4 took 0.07880806922912598 sec, using 12 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6747, Validation Loss: 0.4549
	--> Epoch [2/100], Loss: 0.4217, Validation Loss: 0.7513
	--> Epoch [3/100], Loss: 0.6891, Validation Loss: 0.9268
	--> Epoch [4/100], Loss: 0.2632, Validation Loss: 0.5878
Early stopping
	--> Training for Fold 5 took 0.0399937629699707 sec, using 4 epochs

Median number of epochs used: 5 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/5], Loss: 0.7313
	--> Final training Epoch [2/5], Loss: 0.4002
	--> Final training Epoch [3/5], Loss: 0.1321
	--> Final training Epoch [4/5], Loss: 0.3413
	--> Final training Epoch [5/5], Loss: 0.2762

Final training took 0.04085969924926758 sec

TESTING
	--> Testing took 0.0110 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.4285
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8906, Validation Loss: 0.3639,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8579, Validation Loss: 0.6252,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7836, Validation Loss: 0.7966,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7936, Validation Loss: 0.7110,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7398, Validation Loss: 0.5683,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6649, Validation Loss: 0.8866,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6784, Validation Loss: 0.9577,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8690, Validation Loss: 0.4525,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8591, Validation Loss: 0.4289,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8807, Validation Loss: 0.4804,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.9448,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.8061,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8146, Validation Loss: 0.8478,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.6784, Validation Loss: 1.0076,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6965, Validation Loss: 0.7692,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7614, Validation Loss: 1.1458,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.7503, Validation Loss: 0.5819,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.4751,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8807, Validation Loss: 0.4711,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8579, Validation Loss: 0.4188,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7117, Validation Loss: 1.1902,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.5551,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.4746,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6234, Validation Loss: 1.1847,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5579, Validation Loss: 1.5372,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8801, Validation Loss: 0.4364,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7830, Validation Loss: 1.4354,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.7690, Validation Loss: 1.3710,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8690, Validation Loss: 0.5076,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7708, Validation Loss: 0.6817,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.6990,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.5614, Validation Loss: 1.4166,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.6345, Validation Loss: 1.4058,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.6345, Validation Loss: 0.8327,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8801, Validation Loss: 0.8287,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8053, Validation Loss: 0.6302,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.8431,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.6421, Validation Loss: 1.0026,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7620, Validation Loss: 0.9119,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 0.7719,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7181, Validation Loss: 0.7349,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7415, Validation Loss: 1.3198,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.5591, Validation Loss: 1.7664,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.4564,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8386, Validation Loss: 0.4335,  Current Best Accuracy: 0.8906,  Current Best Validation Loss: 0.3639

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7445, Validation Loss: 0.1941
	--> Epoch [2/100], Loss: 0.3790, Validation Loss: 0.2525
	--> Epoch [3/100], Loss: 0.2591, Validation Loss: 0.2228
	--> Epoch [4/100], Loss: 0.1232, Validation Loss: 0.3536
Early stopping
	--> Training for Fold 1 took 0.01530313491821289 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6936, Validation Loss: 0.5586
	--> Epoch [2/100], Loss: 0.5061, Validation Loss: 0.3749
	--> Epoch [3/100], Loss: 0.2555, Validation Loss: 0.4662
	--> Epoch [4/100], Loss: 0.1902, Validation Loss: 0.3836
	--> Epoch [5/100], Loss: 0.1150, Validation Loss: 0.3073
	--> Epoch [6/100], Loss: 0.0878, Validation Loss: 0.2800
	--> Epoch [7/100], Loss: 0.2896, Validation Loss: 0.4948
	--> Epoch [8/100], Loss: 0.1798, Validation Loss: 0.4871
	--> Epoch [9/100], Loss: 0.0980, Validation Loss: 1.0067
Early stopping
	--> Training for Fold 2 took 0.03474283218383789 sec, using 9 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6980, Validation Loss: 0.5327
	--> Epoch [2/100], Loss: 0.4100, Validation Loss: 0.5452
	--> Epoch [3/100], Loss: 0.2443, Validation Loss: 0.3747
	--> Epoch [4/100], Loss: 0.1922, Validation Loss: 0.4870
	--> Epoch [5/100], Loss: 0.1194, Validation Loss: 0.3651
	--> Epoch [6/100], Loss: 0.0983, Validation Loss: 0.3925
	--> Epoch [7/100], Loss: 0.0393, Validation Loss: 0.4105
	--> Epoch [8/100], Loss: 0.1012, Validation Loss: 0.4636
Early stopping
	--> Training for Fold 3 took 0.02875375747680664 sec, using 8 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6956, Validation Loss: 0.3897
	--> Epoch [2/100], Loss: 0.3363, Validation Loss: 0.7404
	--> Epoch [3/100], Loss: 0.2624, Validation Loss: 0.7082
	--> Epoch [4/100], Loss: 0.1724, Validation Loss: 1.3124
Early stopping
	--> Training for Fold 4 took 0.01896047592163086 sec, using 4 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6794, Validation Loss: 0.6007
	--> Epoch [2/100], Loss: 0.3208, Validation Loss: 0.7075
	--> Epoch [3/100], Loss: 0.1422, Validation Loss: 0.5801
	--> Epoch [4/100], Loss: 0.1047, Validation Loss: 0.7931
	--> Epoch [5/100], Loss: 0.0764, Validation Loss: 0.7813
	--> Epoch [6/100], Loss: 0.0553, Validation Loss: 0.8055
Early stopping
	--> Training for Fold 5 took 0.023682832717895508 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.7318
	--> Final training Epoch [2/6], Loss: 0.4132
	--> Final training Epoch [3/6], Loss: 0.3473
	--> Final training Epoch [4/6], Loss: 0.1877
	--> Final training Epoch [5/6], Loss: 0.1606
	--> Final training Epoch [6/6], Loss: 0.1457

Final training took 0.022202730178833008 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.5217
	--> Final Loss: 1.4056
	--> Final Precision: 0.6000
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5217
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3344,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.6419,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.5204,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4067,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7439, Validation Loss: 0.6167,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8287, Validation Loss: 0.4555,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7199, Validation Loss: 0.5617,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8807, Validation Loss: 0.4591,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.6273,  Current Best Accuracy: 0.8386,  Current Best Validation Loss: 0.3344

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7272, Validation Loss: 0.2592
	--> Epoch [2/100], Loss: 0.4135, Validation Loss: 0.2754
	--> Epoch [3/100], Loss: 0.3731, Validation Loss: 0.3420
	--> Epoch [4/100], Loss: 0.4289, Validation Loss: 0.6407
Early stopping
	--> Training for Fold 1 took 0.013511419296264648 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6909, Validation Loss: 0.9567
	--> Epoch [2/100], Loss: 0.7907, Validation Loss: 0.4144
	--> Epoch [3/100], Loss: 0.5607, Validation Loss: 0.4430
	--> Epoch [4/100], Loss: 0.2531, Validation Loss: 0.2665
	--> Epoch [5/100], Loss: 0.1445, Validation Loss: 0.2918
	--> Epoch [6/100], Loss: 0.1832, Validation Loss: 0.2221
	--> Epoch [7/100], Loss: 0.1492, Validation Loss: 0.4202
	--> Epoch [8/100], Loss: 0.1722, Validation Loss: 0.4820
	--> Epoch [9/100], Loss: 0.1178, Validation Loss: 0.3392
Early stopping
	--> Training for Fold 2 took 0.03244924545288086 sec, using 9 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7861, Validation Loss: 0.4721
	--> Epoch [2/100], Loss: 0.3865, Validation Loss: 0.3623
	--> Epoch [3/100], Loss: 0.2621, Validation Loss: 0.5516
	--> Epoch [4/100], Loss: 0.1497, Validation Loss: 0.5629
	--> Epoch [5/100], Loss: 0.2010, Validation Loss: 0.3265
	--> Epoch [6/100], Loss: 0.1294, Validation Loss: 0.4088
	--> Epoch [7/100], Loss: 0.1126, Validation Loss: 0.3413
	--> Epoch [8/100], Loss: 0.0888, Validation Loss: 0.6708
Early stopping
	--> Training for Fold 3 took 0.02849292755126953 sec, using 8 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7135, Validation Loss: 0.9223
	--> Epoch [2/100], Loss: 0.7674, Validation Loss: 0.3459
	--> Epoch [3/100], Loss: 0.3963, Validation Loss: 0.3519
	--> Epoch [4/100], Loss: 0.1324, Validation Loss: 0.3664
	--> Epoch [5/100], Loss: 0.1732, Validation Loss: 0.4500
Early stopping
	--> Training for Fold 4 took 0.01655864715576172 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6392, Validation Loss: 0.7349
	--> Epoch [2/100], Loss: 0.4187, Validation Loss: 0.5334
	--> Epoch [3/100], Loss: 0.3286, Validation Loss: 0.4055
	--> Epoch [4/100], Loss: 0.1011, Validation Loss: 0.4706
	--> Epoch [5/100], Loss: 0.0450, Validation Loss: 0.5636
	--> Epoch [6/100], Loss: 0.0446, Validation Loss: 0.6074
Early stopping
	--> Training for Fold 5 took 0.022005319595336914 sec, using 6 epochs

Median number of epochs used: 6 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/6], Loss: 0.7086
	--> Final training Epoch [2/6], Loss: 0.3720
	--> Final training Epoch [3/6], Loss: 0.1998
	--> Final training Epoch [4/6], Loss: 0.1482
	--> Final training Epoch [5/6], Loss: 0.0953
	--> Final training Epoch [6/6], Loss: 0.0744

Final training took 0.021317005157470703 sec

TESTING
	--> Testing took 0.0075 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.5274
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.4008,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4791,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.4723,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.4018,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7117, Validation Loss: 0.5484,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7404, Validation Loss: 0.4870,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.5198,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8064, Validation Loss: 0.5459,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.4240,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.4448,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.4208,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.4008

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7168, Validation Loss: 0.2717
	--> Epoch [2/100], Loss: 0.3563, Validation Loss: 0.3106
	--> Epoch [3/100], Loss: 0.6087, Validation Loss: 0.5568
	--> Epoch [4/100], Loss: 0.4988, Validation Loss: 0.8084
Early stopping
	--> Training for Fold 1 took 0.016593456268310547 sec, using 4 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7541, Validation Loss: 0.4393
	--> Epoch [2/100], Loss: 0.5731, Validation Loss: 0.4067
	--> Epoch [3/100], Loss: 0.9380, Validation Loss: 0.3988
	--> Epoch [4/100], Loss: 0.5556, Validation Loss: 0.2205
	--> Epoch [5/100], Loss: 0.3236, Validation Loss: 0.1829
	--> Epoch [6/100], Loss: 0.2823, Validation Loss: 0.4914
	--> Epoch [7/100], Loss: 0.3192, Validation Loss: 0.3474
	--> Epoch [8/100], Loss: 0.1823, Validation Loss: 0.6416
Early stopping
	--> Training for Fold 2 took 0.030186176300048828 sec, using 8 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7362, Validation Loss: 0.6072
	--> Epoch [2/100], Loss: 1.0426, Validation Loss: 0.3601
	--> Epoch [3/100], Loss: 0.4145, Validation Loss: 0.2339
	--> Epoch [4/100], Loss: 0.2296, Validation Loss: 0.4680
	--> Epoch [5/100], Loss: 0.4386, Validation Loss: 0.3167
	--> Epoch [6/100], Loss: 0.2697, Validation Loss: 0.2925
Early stopping
	--> Training for Fold 3 took 0.021658897399902344 sec, using 6 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7209, Validation Loss: 0.3623
	--> Epoch [2/100], Loss: 0.5447, Validation Loss: 0.4010
	--> Epoch [3/100], Loss: 0.3081, Validation Loss: 0.3620
	--> Epoch [4/100], Loss: 0.2420, Validation Loss: 0.2812
	--> Epoch [5/100], Loss: 0.2665, Validation Loss: 0.2857
	--> Epoch [6/100], Loss: 0.3411, Validation Loss: 0.4157
	--> Epoch [7/100], Loss: 0.2057, Validation Loss: 0.5205
Early stopping
	--> Training for Fold 4 took 0.026825428009033203 sec, using 7 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7414, Validation Loss: 0.5564
	--> Epoch [2/100], Loss: 0.6011, Validation Loss: 0.6716
	--> Epoch [3/100], Loss: 0.3494, Validation Loss: 0.3957
	--> Epoch [4/100], Loss: 0.2711, Validation Loss: 0.3704
	--> Epoch [5/100], Loss: 0.2729, Validation Loss: 0.4248
	--> Epoch [6/100], Loss: 0.1872, Validation Loss: 0.6508
	--> Epoch [7/100], Loss: 0.1497, Validation Loss: 0.6445
Early stopping
	--> Training for Fold 5 took 0.024566173553466797 sec, using 7 epochs

Median number of epochs used: 7 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/7], Loss: 0.7261
	--> Final training Epoch [2/7], Loss: 0.6651
	--> Final training Epoch [3/7], Loss: 0.5226
	--> Final training Epoch [4/7], Loss: 0.2549
	--> Final training Epoch [5/7], Loss: 0.2382
	--> Final training Epoch [6/7], Loss: 0.2592
	--> Final training Epoch [7/7], Loss: 0.2279

Final training took 0.023348569869995117 sec

TESTING
	--> Testing took 0.0080 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.5606
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8819, Validation Loss: 0.3425,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7977, Validation Loss: 0.5055,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.5950,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7269, Validation Loss: 0.5430,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7327, Validation Loss: 0.6386,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.4172,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3425

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6765, Validation Loss: 0.3033
	--> Epoch [2/100], Loss: 0.3461, Validation Loss: 0.7549
	--> Epoch [3/100], Loss: 0.4887, Validation Loss: 0.3468
	--> Epoch [4/100], Loss: 0.2957, Validation Loss: 0.2913
	--> Epoch [5/100], Loss: 0.1531, Validation Loss: 0.2306
	--> Epoch [6/100], Loss: 0.2235, Validation Loss: 0.3763
	--> Epoch [7/100], Loss: 0.1406, Validation Loss: 0.3469
	--> Epoch [8/100], Loss: 0.1203, Validation Loss: 0.3190
Early stopping
	--> Training for Fold 1 took 0.031252384185791016 sec, using 8 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6745, Validation Loss: 0.2897
	--> Epoch [2/100], Loss: 0.3858, Validation Loss: 0.1384
	--> Epoch [3/100], Loss: 0.2992, Validation Loss: 0.5228
	--> Epoch [4/100], Loss: 0.4283, Validation Loss: 0.1000
	--> Epoch [5/100], Loss: 0.2682, Validation Loss: 0.3628
	--> Epoch [6/100], Loss: 0.1957, Validation Loss: 0.2871
	--> Epoch [7/100], Loss: 0.1323, Validation Loss: 0.5086
Early stopping
	--> Training for Fold 2 took 0.028832197189331055 sec, using 7 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6715, Validation Loss: 0.7974
	--> Epoch [2/100], Loss: 0.5698, Validation Loss: 0.3885
	--> Epoch [3/100], Loss: 0.3973, Validation Loss: 0.2724
	--> Epoch [4/100], Loss: 0.2838, Validation Loss: 0.4469
	--> Epoch [5/100], Loss: 0.1388, Validation Loss: 0.2836
	--> Epoch [6/100], Loss: 0.0928, Validation Loss: 0.2683
	--> Epoch [7/100], Loss: 0.0781, Validation Loss: 0.3262
	--> Epoch [8/100], Loss: 0.0510, Validation Loss: 0.3278
	--> Epoch [9/100], Loss: 0.0466, Validation Loss: 0.3178
Early stopping
	--> Training for Fold 3 took 0.035547494888305664 sec, using 9 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6883, Validation Loss: 0.9045
	--> Epoch [2/100], Loss: 0.5359, Validation Loss: 0.2986
	--> Epoch [3/100], Loss: 0.3200, Validation Loss: 0.7683
	--> Epoch [4/100], Loss: 0.1480, Validation Loss: 0.6194
	--> Epoch [5/100], Loss: 0.1936, Validation Loss: 0.7489
Early stopping
	--> Training for Fold 4 took 0.02044677734375 sec, using 5 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7135, Validation Loss: 0.8327
	--> Epoch [2/100], Loss: 0.4268, Validation Loss: 1.0469
	--> Epoch [3/100], Loss: 0.2309, Validation Loss: 0.1595
	--> Epoch [4/100], Loss: 0.2658, Validation Loss: 1.3395
	--> Epoch [5/100], Loss: 0.1393, Validation Loss: 0.7444
	--> Epoch [6/100], Loss: 0.0907, Validation Loss: 0.9672
Early stopping
	--> Training for Fold 5 took 0.022871732711791992 sec, using 6 epochs

Median number of epochs used: 7 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/7], Loss: 0.7121
	--> Final training Epoch [2/7], Loss: 0.5476
	--> Final training Epoch [3/7], Loss: 0.7490
	--> Final training Epoch [4/7], Loss: 0.3138
	--> Final training Epoch [5/7], Loss: 0.1434
	--> Final training Epoch [6/7], Loss: 0.0777
	--> Final training Epoch [7/7], Loss: 0.0352

Final training took 0.02300572395324707 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 1.5137
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8912, Validation Loss: 0.2968,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.4377,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4643,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8386, Validation Loss: 0.4067,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7959, Validation Loss: 0.5020,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8181, Validation Loss: 0.5590,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7298, Validation Loss: 0.5941,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7848, Validation Loss: 0.5609,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.4201,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.4032,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.4134,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.4965,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7649, Validation Loss: 0.5676,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.4887,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7211, Validation Loss: 0.5402,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8170, Validation Loss: 0.4175,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.1, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7310, Validation Loss: 0.5168,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.4380,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.3175,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3925,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3897,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 0.3879,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8064, Validation Loss: 0.4741,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4154,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3844,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7971, Validation Loss: 0.4125,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3973,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8374, Validation Loss: 0.4473,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3839,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8480, Validation Loss: 0.4221,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3925,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.3745,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3610,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.3852,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.4162,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3444,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3859,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.4560,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3948,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8374, Validation Loss: 0.3937,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.4052,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7848, Validation Loss: 0.4594,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3494,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7947, Validation Loss: 0.4308,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8269, Validation Loss: 0.3742,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 0.4597,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8368, Validation Loss: 0.4283,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3818,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.3837,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.3852,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7942, Validation Loss: 0.4363,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7836, Validation Loss: 0.3802,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.3991,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8807, Validation Loss: 0.3326,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.4028,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8807, Validation Loss: 0.4168,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3657,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3353,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.4396,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8585, Validation Loss: 0.3722,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.4264,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8158, Validation Loss: 0.3717,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3598,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3530,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8374, Validation Loss: 0.3628,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4262,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.4096,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 0.3989,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7637, Validation Loss: 0.4557,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3814,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.2968

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 1.0061, Validation Loss: 0.5719
	--> Epoch [2/100], Loss: 0.3746, Validation Loss: 0.5727
	--> Epoch [3/100], Loss: 0.2726, Validation Loss: 0.5295
	--> Epoch [4/100], Loss: 0.2591, Validation Loss: 0.4878
	--> Epoch [5/100], Loss: 0.3614, Validation Loss: 0.4025
	--> Epoch [6/100], Loss: 0.7250, Validation Loss: 0.3365
	--> Epoch [7/100], Loss: 0.2505, Validation Loss: 0.3395
	--> Epoch [8/100], Loss: 0.2175, Validation Loss: 0.3180
	--> Epoch [9/100], Loss: 0.5476, Validation Loss: 0.3438
	--> Epoch [10/100], Loss: 0.7456, Validation Loss: 0.3752
	--> Epoch [11/100], Loss: 0.2050, Validation Loss: 0.3766
Early stopping
	--> Training for Fold 1 took 0.2708885669708252 sec, using 11 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7208, Validation Loss: 0.4164
	--> Epoch [2/100], Loss: 0.6403, Validation Loss: 0.3561
	--> Epoch [3/100], Loss: 0.3195, Validation Loss: 0.3072
	--> Epoch [4/100], Loss: 0.3095, Validation Loss: 0.2375
	--> Epoch [5/100], Loss: 0.2489, Validation Loss: 0.2057
	--> Epoch [6/100], Loss: 0.7065, Validation Loss: 0.1698
	--> Epoch [7/100], Loss: 0.0010, Validation Loss: 0.1633
	--> Epoch [8/100], Loss: 0.0310, Validation Loss: 0.1991
	--> Epoch [9/100], Loss: 0.0579, Validation Loss: 0.1950
	--> Epoch [10/100], Loss: 0.2386, Validation Loss: 0.2055
Early stopping
	--> Training for Fold 2 took 0.2909047603607178 sec, using 10 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4846, Validation Loss: 0.5454
	--> Epoch [2/100], Loss: 0.3862, Validation Loss: 0.4717
	--> Epoch [3/100], Loss: 0.6944, Validation Loss: 0.4459
	--> Epoch [4/100], Loss: 0.0723, Validation Loss: 0.4185
	--> Epoch [5/100], Loss: 0.6958, Validation Loss: 0.3888
	--> Epoch [6/100], Loss: 0.0041, Validation Loss: 0.3781
	--> Epoch [7/100], Loss: 0.3719, Validation Loss: 0.3898
	--> Epoch [8/100], Loss: 0.0038, Validation Loss: 0.3418
	--> Epoch [9/100], Loss: 0.0013, Validation Loss: 0.3336
	--> Epoch [10/100], Loss: 0.0025, Validation Loss: 0.3152
	--> Epoch [11/100], Loss: 0.3062, Validation Loss: 0.3441
	--> Epoch [12/100], Loss: 0.0191, Validation Loss: 0.3488
	--> Epoch [13/100], Loss: 0.2764, Validation Loss: 0.3566
Early stopping
	--> Training for Fold 3 took 0.3950228691101074 sec, using 13 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.4946, Validation Loss: 0.4675
	--> Epoch [2/100], Loss: 0.4348, Validation Loss: 0.4047
	--> Epoch [3/100], Loss: 0.6759, Validation Loss: 0.4772
	--> Epoch [4/100], Loss: 0.1912, Validation Loss: 0.3381
	--> Epoch [5/100], Loss: 0.5459, Validation Loss: 0.2787
	--> Epoch [6/100], Loss: 0.3275, Validation Loss: 0.4058
	--> Epoch [7/100], Loss: 0.4816, Validation Loss: 0.3496
	--> Epoch [8/100], Loss: 0.1671, Validation Loss: 0.3660
Early stopping
	--> Training for Fold 4 took 0.23089051246643066 sec, using 8 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.2165, Validation Loss: 0.6306
	--> Epoch [2/100], Loss: 0.1807, Validation Loss: 0.5920
	--> Epoch [3/100], Loss: 0.3719, Validation Loss: 0.5541
	--> Epoch [4/100], Loss: 0.1872, Validation Loss: 0.5487
	--> Epoch [5/100], Loss: 0.3650, Validation Loss: 0.5268
	--> Epoch [6/100], Loss: 0.2732, Validation Loss: 0.4955
	--> Epoch [7/100], Loss: 0.3484, Validation Loss: 0.5332
	--> Epoch [8/100], Loss: 0.0341, Validation Loss: 0.5272
	--> Epoch [9/100], Loss: 0.0242, Validation Loss: 0.4884
	--> Epoch [10/100], Loss: 0.0032, Validation Loss: 0.4984
	--> Epoch [11/100], Loss: 0.2025, Validation Loss: 0.4892
	--> Epoch [12/100], Loss: 0.0387, Validation Loss: 0.5007
Early stopping
	--> Training for Fold 5 took 0.33445072174072266 sec, using 12 epochs

Median number of epochs used: 11 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/11], Loss: 0.4297
	--> Final training Epoch [2/11], Loss: 0.3589
	--> Final training Epoch [3/11], Loss: 0.1553
	--> Final training Epoch [4/11], Loss: 0.2650
	--> Final training Epoch [5/11], Loss: 0.1583
	--> Final training Epoch [6/11], Loss: 0.2994
	--> Final training Epoch [7/11], Loss: 0.2835
	--> Final training Epoch [8/11], Loss: 0.1821
	--> Final training Epoch [9/11], Loss: 0.2360
	--> Final training Epoch [10/11], Loss: 0.0601
	--> Final training Epoch [11/11], Loss: 0.2867

Final training took 0.37847471237182617 sec

TESTING
	--> Testing took 0.0099 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8992
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.2909,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8076, Validation Loss: 0.4300,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.4766,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3685,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4070,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.2909

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8366, Validation Loss: 0.4769
	--> Epoch [2/100], Loss: 0.2516, Validation Loss: 0.3494
	--> Epoch [3/100], Loss: 0.0937, Validation Loss: 0.2610
	--> Epoch [4/100], Loss: 0.0320, Validation Loss: 0.2412
	--> Epoch [5/100], Loss: 0.0055, Validation Loss: 0.2281
	--> Epoch [6/100], Loss: 0.0118, Validation Loss: 0.2253
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.2279
	--> Epoch [8/100], Loss: 0.0010, Validation Loss: 0.2145
	--> Epoch [9/100], Loss: 0.0030, Validation Loss: 0.2123
	--> Epoch [10/100], Loss: 0.0016, Validation Loss: 0.2019
	--> Epoch [11/100], Loss: 0.1578, Validation Loss: 0.2174
	--> Epoch [12/100], Loss: 0.0022, Validation Loss: 0.1909
	--> Epoch [13/100], Loss: 0.1456, Validation Loss: 0.1942
	--> Epoch [14/100], Loss: 0.0002, Validation Loss: 0.1655
	--> Epoch [15/100], Loss: 0.0000, Validation Loss: 0.1603
	--> Epoch [16/100], Loss: 0.0006, Validation Loss: 0.1492
	--> Epoch [17/100], Loss: 0.0001, Validation Loss: 0.1737
	--> Epoch [18/100], Loss: 0.0034, Validation Loss: 0.1673
	--> Epoch [19/100], Loss: 0.0001, Validation Loss: 0.1861
Early stopping
	--> Training for Fold 1 took 0.5203313827514648 sec, using 19 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5276, Validation Loss: 0.3896
	--> Epoch [2/100], Loss: 0.1568, Validation Loss: 0.3533
	--> Epoch [3/100], Loss: 0.3784, Validation Loss: 0.2926
	--> Epoch [4/100], Loss: 0.3798, Validation Loss: 0.2696
	--> Epoch [5/100], Loss: 0.0289, Validation Loss: 0.1808
	--> Epoch [6/100], Loss: 0.0351, Validation Loss: 0.1765
	--> Epoch [7/100], Loss: 0.3108, Validation Loss: 0.1360
	--> Epoch [8/100], Loss: 0.0005, Validation Loss: 0.1155
	--> Epoch [9/100], Loss: 0.2949, Validation Loss: 0.1416
	--> Epoch [10/100], Loss: 0.2836, Validation Loss: 0.0993
	--> Epoch [11/100], Loss: 0.0002, Validation Loss: 0.1130
	--> Epoch [12/100], Loss: 0.0000, Validation Loss: 0.1505
	--> Epoch [13/100], Loss: 0.0000, Validation Loss: 0.2196
Early stopping
	--> Training for Fold 2 took 0.3726322650909424 sec, using 13 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.3893, Validation Loss: 0.6699
	--> Epoch [2/100], Loss: 0.3319, Validation Loss: 0.6294
	--> Epoch [3/100], Loss: 0.2954, Validation Loss: 0.6289
	--> Epoch [4/100], Loss: 0.2598, Validation Loss: 0.6153
	--> Epoch [5/100], Loss: 0.2319, Validation Loss: 0.6118
	--> Epoch [6/100], Loss: 0.2096, Validation Loss: 0.5836
	--> Epoch [7/100], Loss: 0.1872, Validation Loss: 0.6255
	--> Epoch [8/100], Loss: 0.1717, Validation Loss: 0.5998
	--> Epoch [9/100], Loss: 0.1690, Validation Loss: 0.6074
Early stopping
	--> Training for Fold 3 took 0.2703697681427002 sec, using 9 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.4495, Validation Loss: 0.4177
	--> Epoch [2/100], Loss: 0.3174, Validation Loss: 0.4659
	--> Epoch [3/100], Loss: 0.0233, Validation Loss: 0.3540
	--> Epoch [4/100], Loss: 0.2160, Validation Loss: 0.2961
	--> Epoch [5/100], Loss: 0.3151, Validation Loss: 0.2827
	--> Epoch [6/100], Loss: 0.0145, Validation Loss: 0.2655
	--> Epoch [7/100], Loss: 0.0005, Validation Loss: 0.3240
	--> Epoch [8/100], Loss: 0.4742, Validation Loss: 0.3508
	--> Epoch [9/100], Loss: 0.1765, Validation Loss: 0.3826
Early stopping
	--> Training for Fold 4 took 0.2665097713470459 sec, using 9 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4797, Validation Loss: 0.7503
	--> Epoch [2/100], Loss: 0.1315, Validation Loss: 0.6064
	--> Epoch [3/100], Loss: 0.3986, Validation Loss: 0.6339
	--> Epoch [4/100], Loss: 0.0139, Validation Loss: 0.5821
	--> Epoch [5/100], Loss: 0.0008, Validation Loss: 0.6633
	--> Epoch [6/100], Loss: 0.2021, Validation Loss: 0.5737
	--> Epoch [7/100], Loss: 0.0214, Validation Loss: 0.5937
	--> Epoch [8/100], Loss: 0.0001, Validation Loss: 0.5550
	--> Epoch [9/100], Loss: 0.0004, Validation Loss: 0.4947
	--> Epoch [10/100], Loss: 0.0022, Validation Loss: 0.5707
	--> Epoch [11/100], Loss: 0.0000, Validation Loss: 0.6038
	--> Epoch [12/100], Loss: 0.0003, Validation Loss: 0.5695
Early stopping
	--> Training for Fold 5 took 0.3681309223175049 sec, using 12 epochs

Median number of epochs used: 12 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/12], Loss: 0.4583
	--> Final training Epoch [2/12], Loss: 0.2795
	--> Final training Epoch [3/12], Loss: 0.0335
	--> Final training Epoch [4/12], Loss: 0.1017
	--> Final training Epoch [5/12], Loss: 0.0746
	--> Final training Epoch [6/12], Loss: 0.1024
	--> Final training Epoch [7/12], Loss: 0.0014
	--> Final training Epoch [8/12], Loss: 0.1012
	--> Final training Epoch [9/12], Loss: 0.0932
	--> Final training Epoch [10/12], Loss: 0.0094
	--> Final training Epoch [11/12], Loss: 0.0747
	--> Final training Epoch [12/12], Loss: 0.1140

Final training took 0.42096829414367676 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 1.5963
	--> Final Precision: 0.6667
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5455
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3515,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3736,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8287, Validation Loss: 0.3830,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7953, Validation Loss: 0.3885,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3535,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3749,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.4112,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3627,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3859,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8480, Validation Loss: 0.3875,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3834,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.3590,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3819,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.3889,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3515

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.3411, Validation Loss: 0.4097
	--> Epoch [2/100], Loss: 0.0732, Validation Loss: 0.3109
	--> Epoch [3/100], Loss: 0.3685, Validation Loss: 0.3390
	--> Epoch [4/100], Loss: 0.0217, Validation Loss: 0.3488
	--> Epoch [5/100], Loss: 0.0074, Validation Loss: 0.3277
Early stopping
	--> Training for Fold 1 took 0.11365652084350586 sec, using 5 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.3708, Validation Loss: 0.4695
	--> Epoch [2/100], Loss: 0.0338, Validation Loss: 0.3418
	--> Epoch [3/100], Loss: 0.0087, Validation Loss: 0.3116
	--> Epoch [4/100], Loss: 0.0033, Validation Loss: 0.2910
	--> Epoch [5/100], Loss: 0.0013, Validation Loss: 0.2373
	--> Epoch [6/100], Loss: 0.0115, Validation Loss: 0.2296
	--> Epoch [7/100], Loss: 0.0081, Validation Loss: 0.2511
	--> Epoch [8/100], Loss: 0.2700, Validation Loss: 0.2205
	--> Epoch [9/100], Loss: 0.0002, Validation Loss: 0.2041
	--> Epoch [10/100], Loss: 0.0000, Validation Loss: 0.1542
	--> Epoch [11/100], Loss: 0.0018, Validation Loss: 0.1585
	--> Epoch [12/100], Loss: 0.0172, Validation Loss: 0.1460
	--> Epoch [13/100], Loss: 0.0001, Validation Loss: 0.1552
	--> Epoch [14/100], Loss: 0.0000, Validation Loss: 0.1615
	--> Epoch [15/100], Loss: 0.0001, Validation Loss: 0.1149
	--> Epoch [16/100], Loss: 0.0074, Validation Loss: 0.1065
	--> Epoch [17/100], Loss: 0.0012, Validation Loss: 0.1574
	--> Epoch [18/100], Loss: 0.0124, Validation Loss: 0.1603
	--> Epoch [19/100], Loss: 0.0000, Validation Loss: 0.1553
Early stopping
	--> Training for Fold 2 took 0.5137357711791992 sec, using 19 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4560, Validation Loss: 0.4436
	--> Epoch [2/100], Loss: 0.0164, Validation Loss: 0.3431
	--> Epoch [3/100], Loss: 0.0614, Validation Loss: 0.3390
	--> Epoch [4/100], Loss: 0.0484, Validation Loss: 0.3088
	--> Epoch [5/100], Loss: 0.0002, Validation Loss: 0.2725
	--> Epoch [6/100], Loss: 0.0026, Validation Loss: 0.2589
	--> Epoch [7/100], Loss: 0.0031, Validation Loss: 0.2869
	--> Epoch [8/100], Loss: 0.0001, Validation Loss: 0.2612
	--> Epoch [9/100], Loss: 0.3265, Validation Loss: 0.2624
Early stopping
	--> Training for Fold 3 took 0.25231122970581055 sec, using 9 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.4053, Validation Loss: 0.4346
	--> Epoch [2/100], Loss: 0.1574, Validation Loss: 0.3547
	--> Epoch [3/100], Loss: 0.0231, Validation Loss: 0.2597
	--> Epoch [4/100], Loss: 0.0537, Validation Loss: 0.2663
	--> Epoch [5/100], Loss: 0.0027, Validation Loss: 0.2289
	--> Epoch [6/100], Loss: 0.0004, Validation Loss: 0.2122
	--> Epoch [7/100], Loss: 0.0019, Validation Loss: 0.2844
	--> Epoch [8/100], Loss: 0.0006, Validation Loss: 0.3265
	--> Epoch [9/100], Loss: 0.0004, Validation Loss: 0.3757
Early stopping
	--> Training for Fold 4 took 0.2698028087615967 sec, using 9 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.1633, Validation Loss: 0.6292
	--> Epoch [2/100], Loss: 0.0104, Validation Loss: 0.6225
	--> Epoch [3/100], Loss: 0.0169, Validation Loss: 0.5661
	--> Epoch [4/100], Loss: 0.1439, Validation Loss: 0.6189
	--> Epoch [5/100], Loss: 0.0192, Validation Loss: 0.6148
	--> Epoch [6/100], Loss: 0.0336, Validation Loss: 0.5870
Early stopping
	--> Training for Fold 5 took 0.16640233993530273 sec, using 6 epochs

Median number of epochs used: 9 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/9], Loss: 0.2402
	--> Final training Epoch [2/9], Loss: 0.1617
	--> Final training Epoch [3/9], Loss: 0.1734
	--> Final training Epoch [4/9], Loss: 0.0108
	--> Final training Epoch [5/9], Loss: 0.0122
	--> Final training Epoch [6/9], Loss: 0.0090
	--> Final training Epoch [7/9], Loss: 0.0616
	--> Final training Epoch [8/9], Loss: 0.1394
	--> Final training Epoch [9/9], Loss: 0.0029

Final training took 0.30916285514831543 sec

TESTING
	--> Testing took 0.0073 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.1980
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8807, Validation Loss: 0.3698,  Current Best Accuracy: 0.8807,  Current Best Validation Loss: 0.3698

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7872, Validation Loss: 0.4746
	--> Epoch [2/100], Loss: 0.0936, Validation Loss: 0.3507
	--> Epoch [3/100], Loss: 0.0275, Validation Loss: 0.3351
	--> Epoch [4/100], Loss: 0.0145, Validation Loss: 0.3232
	--> Epoch [5/100], Loss: 0.0192, Validation Loss: 0.2902
	--> Epoch [6/100], Loss: 0.0473, Validation Loss: 0.2746
	--> Epoch [7/100], Loss: 0.3361, Validation Loss: 0.2746
	--> Epoch [8/100], Loss: 0.0016, Validation Loss: 0.2787
	--> Epoch [9/100], Loss: 0.0000, Validation Loss: 0.2600
	--> Epoch [10/100], Loss: 0.0000, Validation Loss: 0.2705
	--> Epoch [11/100], Loss: 0.0004, Validation Loss: 0.2277
	--> Epoch [12/100], Loss: 0.0010, Validation Loss: 0.2287
	--> Epoch [13/100], Loss: 0.0001, Validation Loss: 0.2168
	--> Epoch [14/100], Loss: 0.2334, Validation Loss: 0.2374
	--> Epoch [15/100], Loss: 0.0002, Validation Loss: 0.2886
	--> Epoch [16/100], Loss: 0.0000, Validation Loss: 0.2732
Early stopping
	--> Training for Fold 1 took 0.40215253829956055 sec, using 16 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.3650, Validation Loss: 0.4481
	--> Epoch [2/100], Loss: 0.0087, Validation Loss: 0.3015
	--> Epoch [3/100], Loss: 0.0318, Validation Loss: 0.2113
	--> Epoch [4/100], Loss: 0.0080, Validation Loss: 0.1703
	--> Epoch [5/100], Loss: 0.0046, Validation Loss: 0.1432
	--> Epoch [6/100], Loss: 0.5241, Validation Loss: 0.1691
	--> Epoch [7/100], Loss: 0.0052, Validation Loss: 0.1487
	--> Epoch [8/100], Loss: 0.0002, Validation Loss: 0.1420
	--> Epoch [9/100], Loss: 0.0048, Validation Loss: 0.1337
	--> Epoch [10/100], Loss: 0.0197, Validation Loss: 0.1419
	--> Epoch [11/100], Loss: 0.0016, Validation Loss: 0.1655
	--> Epoch [12/100], Loss: 0.0000, Validation Loss: 0.1765
Early stopping
	--> Training for Fold 2 took 0.3446981906890869 sec, using 12 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6016, Validation Loss: 0.5393
	--> Epoch [2/100], Loss: 0.1486, Validation Loss: 0.4648
	--> Epoch [3/100], Loss: 0.0057, Validation Loss: 0.3744
	--> Epoch [4/100], Loss: 0.0003, Validation Loss: 0.3566
	--> Epoch [5/100], Loss: 0.0847, Validation Loss: 0.3326
	--> Epoch [6/100], Loss: 0.0128, Validation Loss: 0.3343
	--> Epoch [7/100], Loss: 0.1502, Validation Loss: 0.4437
	--> Epoch [8/100], Loss: 0.0000, Validation Loss: 0.3508
Early stopping
	--> Training for Fold 3 took 0.23267865180969238 sec, using 8 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5884, Validation Loss: 0.3995
	--> Epoch [2/100], Loss: 0.2019, Validation Loss: 0.3340
	--> Epoch [3/100], Loss: 0.0118, Validation Loss: 0.3123
	--> Epoch [4/100], Loss: 0.0085, Validation Loss: 0.2746
	--> Epoch [5/100], Loss: 0.0029, Validation Loss: 0.2451
	--> Epoch [6/100], Loss: 0.0034, Validation Loss: 0.2879
	--> Epoch [7/100], Loss: 0.0026, Validation Loss: 0.3074
	--> Epoch [8/100], Loss: 0.0010, Validation Loss: 0.2924
Early stopping
	--> Training for Fold 4 took 0.2376718521118164 sec, using 8 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.2771, Validation Loss: 0.8109
	--> Epoch [2/100], Loss: 0.0083, Validation Loss: 0.7750
	--> Epoch [3/100], Loss: 0.0390, Validation Loss: 0.7809
	--> Epoch [4/100], Loss: 0.0040, Validation Loss: 0.7597
	--> Epoch [5/100], Loss: 0.0035, Validation Loss: 0.7932
	--> Epoch [6/100], Loss: 0.0021, Validation Loss: 0.7846
	--> Epoch [7/100], Loss: 0.0219, Validation Loss: 1.0201
Early stopping
	--> Training for Fold 5 took 0.20516133308410645 sec, using 7 epochs

Median number of epochs used: 8 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/8], Loss: 0.4748
	--> Final training Epoch [2/8], Loss: 0.2775
	--> Final training Epoch [3/8], Loss: 0.0100
	--> Final training Epoch [4/8], Loss: 0.1158
	--> Final training Epoch [5/8], Loss: 0.0067
	--> Final training Epoch [6/8], Loss: 0.1980
	--> Final training Epoch [7/8], Loss: 0.0002
	--> Final training Epoch [8/8], Loss: 0.0736

Final training took 0.28839564323425293 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 1.1508
	--> Final Precision: 0.6667
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5455
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8480, Validation Loss: 0.3561,  Current Best Accuracy: 0.8480,  Current Best Validation Loss: 0.3561

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.3481, Validation Loss: 0.4098
	--> Epoch [2/100], Loss: 0.3246, Validation Loss: 0.3432
	--> Epoch [3/100], Loss: 0.3305, Validation Loss: 0.2779
	--> Epoch [4/100], Loss: 0.0207, Validation Loss: 0.2766
	--> Epoch [5/100], Loss: 0.2219, Validation Loss: 0.2238
	--> Epoch [6/100], Loss: 0.0011, Validation Loss: 0.3344
	--> Epoch [7/100], Loss: 0.0006, Validation Loss: 0.3219
	--> Epoch [8/100], Loss: 0.0027, Validation Loss: 0.3094
Early stopping
	--> Training for Fold 1 took 0.1793994903564453 sec, using 8 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6523, Validation Loss: 0.4058
	--> Epoch [2/100], Loss: 0.1361, Validation Loss: 0.3483
	--> Epoch [3/100], Loss: 0.0524, Validation Loss: 0.2682
	--> Epoch [4/100], Loss: 0.0006, Validation Loss: 0.2911
	--> Epoch [5/100], Loss: 0.0003, Validation Loss: 0.2888
	--> Epoch [6/100], Loss: 0.1008, Validation Loss: 0.2284
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.2201
	--> Epoch [8/100], Loss: 0.0117, Validation Loss: 0.2169
	--> Epoch [9/100], Loss: 0.0000, Validation Loss: 0.1960
	--> Epoch [10/100], Loss: 0.0000, Validation Loss: 0.1641
	--> Epoch [11/100], Loss: 0.1156, Validation Loss: 0.1759
	--> Epoch [12/100], Loss: 0.0000, Validation Loss: 0.1739
	--> Epoch [13/100], Loss: 0.0000, Validation Loss: 0.1674
Early stopping
	--> Training for Fold 2 took 0.3771250247955322 sec, using 13 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4409, Validation Loss: 0.4454
	--> Epoch [2/100], Loss: 0.0035, Validation Loss: 0.3689
	--> Epoch [3/100], Loss: 0.0230, Validation Loss: 0.3309
	--> Epoch [4/100], Loss: 0.0161, Validation Loss: 0.3024
	--> Epoch [5/100], Loss: 0.0091, Validation Loss: 0.3284
	--> Epoch [6/100], Loss: 0.0187, Validation Loss: 0.2373
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.2431
	--> Epoch [8/100], Loss: 0.0173, Validation Loss: 0.2249
	--> Epoch [9/100], Loss: 0.0000, Validation Loss: 0.2220
	--> Epoch [10/100], Loss: 0.3137, Validation Loss: 0.2487
	--> Epoch [11/100], Loss: 0.0001, Validation Loss: 0.2720
	--> Epoch [12/100], Loss: 0.0074, Validation Loss: 0.3166
Early stopping
	--> Training for Fold 3 took 0.35239624977111816 sec, using 12 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5437, Validation Loss: 0.7022
	--> Epoch [2/100], Loss: 0.4773, Validation Loss: 0.7055
	--> Epoch [3/100], Loss: 0.4045, Validation Loss: 0.6321
	--> Epoch [4/100], Loss: 0.3922, Validation Loss: 0.6760
	--> Epoch [5/100], Loss: 0.3157, Validation Loss: 0.6218
	--> Epoch [6/100], Loss: 0.2808, Validation Loss: 0.6293
	--> Epoch [7/100], Loss: 0.2647, Validation Loss: 0.5814
	--> Epoch [8/100], Loss: 0.2302, Validation Loss: 0.5859
	--> Epoch [9/100], Loss: 0.2019, Validation Loss: 0.6110
	--> Epoch [10/100], Loss: 0.1843, Validation Loss: 0.6222
Early stopping
	--> Training for Fold 4 took 0.2835259437561035 sec, using 10 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4026, Validation Loss: 0.7589
	--> Epoch [2/100], Loss: 0.0098, Validation Loss: 0.6367
	--> Epoch [3/100], Loss: 0.0042, Validation Loss: 0.6329
	--> Epoch [4/100], Loss: 0.0034, Validation Loss: 0.7039
	--> Epoch [5/100], Loss: 0.9033, Validation Loss: 0.7890
	--> Epoch [6/100], Loss: 0.0031, Validation Loss: 0.7778
Early stopping
	--> Training for Fold 5 took 0.1718616485595703 sec, using 6 epochs

Median number of epochs used: 10 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/10], Loss: 0.3704
	--> Final training Epoch [2/10], Loss: 0.1075
	--> Final training Epoch [3/10], Loss: 0.1128
	--> Final training Epoch [4/10], Loss: 0.0937
	--> Final training Epoch [5/10], Loss: 0.0301
	--> Final training Epoch [6/10], Loss: 0.1580
	--> Final training Epoch [7/10], Loss: 0.0016
	--> Final training Epoch [8/10], Loss: 0.1824
	--> Final training Epoch [9/10], Loss: 0.0245
	--> Final training Epoch [10/10], Loss: 0.0621

Final training took 0.33599209785461426 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.5552
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.2956,  Current Best Accuracy: 0.8497,  Current Best Validation Loss: 0.2956

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.4544, Validation Loss: 0.4727
	--> Epoch [2/100], Loss: 0.1649, Validation Loss: 0.3307
	--> Epoch [3/100], Loss: 0.0090, Validation Loss: 0.2796
	--> Epoch [4/100], Loss: 0.0095, Validation Loss: 0.2603
	--> Epoch [5/100], Loss: 0.0003, Validation Loss: 0.2389
	--> Epoch [6/100], Loss: 0.0555, Validation Loss: 0.2343
	--> Epoch [7/100], Loss: 0.0012, Validation Loss: 0.2361
	--> Epoch [8/100], Loss: 0.0010, Validation Loss: 0.2466
	--> Epoch [9/100], Loss: 0.0146, Validation Loss: 0.2371
Early stopping
	--> Training for Fold 1 took 0.20566129684448242 sec, using 9 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.4578, Validation Loss: 0.5271
	--> Epoch [2/100], Loss: 0.3399, Validation Loss: 0.4036
	--> Epoch [3/100], Loss: 0.3188, Validation Loss: 0.2999
	--> Epoch [4/100], Loss: 0.0286, Validation Loss: 0.3274
	--> Epoch [5/100], Loss: 0.0034, Validation Loss: 0.2858
	--> Epoch [6/100], Loss: 0.0011, Validation Loss: 0.2814
	--> Epoch [7/100], Loss: 0.0009, Validation Loss: 0.2532
	--> Epoch [8/100], Loss: 0.2133, Validation Loss: 0.2381
	--> Epoch [9/100], Loss: 0.2025, Validation Loss: 0.2465
	--> Epoch [10/100], Loss: 0.1881, Validation Loss: 0.2234
	--> Epoch [11/100], Loss: 0.0001, Validation Loss: 0.2143
	--> Epoch [12/100], Loss: 0.1000, Validation Loss: 0.2213
	--> Epoch [13/100], Loss: 0.0000, Validation Loss: 0.2282
	--> Epoch [14/100], Loss: 0.0000, Validation Loss: 0.2269
Early stopping
	--> Training for Fold 2 took 0.41666364669799805 sec, using 14 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4140, Validation Loss: 0.5169
	--> Epoch [2/100], Loss: 0.3871, Validation Loss: 0.4390
	--> Epoch [3/100], Loss: 0.0414, Validation Loss: 0.3766
	--> Epoch [4/100], Loss: 0.2595, Validation Loss: 0.3078
	--> Epoch [5/100], Loss: 0.2285, Validation Loss: 0.3085
	--> Epoch [6/100], Loss: 0.0532, Validation Loss: 0.3156
	--> Epoch [7/100], Loss: 0.0001, Validation Loss: 0.3163
Early stopping
	--> Training for Fold 3 took 0.18801331520080566 sec, using 7 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.3161, Validation Loss: 0.5125
	--> Epoch [2/100], Loss: 0.1211, Validation Loss: 0.4697
	--> Epoch [3/100], Loss: 0.0241, Validation Loss: 0.4547
	--> Epoch [4/100], Loss: 0.2256, Validation Loss: 0.4825
	--> Epoch [5/100], Loss: 0.0083, Validation Loss: 0.5186
	--> Epoch [6/100], Loss: 0.0039, Validation Loss: 0.4040
	--> Epoch [7/100], Loss: 0.0214, Validation Loss: 0.4365
	--> Epoch [8/100], Loss: 0.0036, Validation Loss: 0.4799
	--> Epoch [9/100], Loss: 0.0001, Validation Loss: 0.4946
Early stopping
	--> Training for Fold 4 took 0.25760412216186523 sec, using 9 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.3144, Validation Loss: 0.7327
	--> Epoch [2/100], Loss: 0.3178, Validation Loss: 0.7356
	--> Epoch [3/100], Loss: 0.1212, Validation Loss: 0.6942
	--> Epoch [4/100], Loss: 0.0031, Validation Loss: 0.6283
	--> Epoch [5/100], Loss: 0.0246, Validation Loss: 0.7489
	--> Epoch [6/100], Loss: 0.1817, Validation Loss: 0.7330
	--> Epoch [7/100], Loss: 0.0002, Validation Loss: 0.7917
Early stopping
	--> Training for Fold 5 took 0.1820671558380127 sec, using 7 epochs

Median number of epochs used: 9 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/9], Loss: 0.3769
	--> Final training Epoch [2/9], Loss: 0.2448
	--> Final training Epoch [3/9], Loss: 0.0563
	--> Final training Epoch [4/9], Loss: 0.2600
	--> Final training Epoch [5/9], Loss: 0.0415
	--> Final training Epoch [6/9], Loss: 0.0092
	--> Final training Epoch [7/9], Loss: 0.1509
	--> Final training Epoch [8/9], Loss: 0.2904
	--> Final training Epoch [9/9], Loss: 0.1500

Final training took 0.3169534206390381 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.3118
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3300,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3808,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8608, Validation Loss: 0.3626,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4152,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.3819,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7947, Validation Loss: 0.3892,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3300

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5715, Validation Loss: 0.4237
	--> Epoch [2/100], Loss: 0.1497, Validation Loss: 0.3761
	--> Epoch [3/100], Loss: 0.0166, Validation Loss: 0.3281
	--> Epoch [4/100], Loss: 0.0216, Validation Loss: 0.2747
	--> Epoch [5/100], Loss: 0.0012, Validation Loss: 0.2573
	--> Epoch [6/100], Loss: 0.0056, Validation Loss: 0.2483
	--> Epoch [7/100], Loss: 0.0012, Validation Loss: 0.2676
	--> Epoch [8/100], Loss: 0.0037, Validation Loss: 0.2618
	--> Epoch [9/100], Loss: 0.0009, Validation Loss: 0.2812
Early stopping
	--> Training for Fold 1 took 0.20745563507080078 sec, using 9 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.4238, Validation Loss: 0.4705
	--> Epoch [2/100], Loss: 0.0570, Validation Loss: 0.3391
	--> Epoch [3/100], Loss: 0.0080, Validation Loss: 0.2307
	--> Epoch [4/100], Loss: 0.0041, Validation Loss: 0.2318
	--> Epoch [5/100], Loss: 0.0127, Validation Loss: 0.1932
	--> Epoch [6/100], Loss: 0.0009, Validation Loss: 0.1929
	--> Epoch [7/100], Loss: 0.0005, Validation Loss: 0.2069
	--> Epoch [8/100], Loss: 0.0008, Validation Loss: 0.1725
	--> Epoch [9/100], Loss: 0.0008, Validation Loss: 0.1558
	--> Epoch [10/100], Loss: 0.0003, Validation Loss: 0.1689
	--> Epoch [11/100], Loss: 0.0099, Validation Loss: 0.1638
	--> Epoch [12/100], Loss: 0.0001, Validation Loss: 0.1559
Early stopping
	--> Training for Fold 2 took 0.34967041015625 sec, using 12 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.2732, Validation Loss: 0.4639
	--> Epoch [2/100], Loss: 0.0238, Validation Loss: 0.3865
	--> Epoch [3/100], Loss: 0.2974, Validation Loss: 0.3754
	--> Epoch [4/100], Loss: 0.0037, Validation Loss: 0.4227
	--> Epoch [5/100], Loss: 0.0151, Validation Loss: 0.4228
	--> Epoch [6/100], Loss: 0.0117, Validation Loss: 0.4692
Early stopping
	--> Training for Fold 3 took 0.17578721046447754 sec, using 6 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.3700, Validation Loss: 0.4594
	--> Epoch [2/100], Loss: 0.0874, Validation Loss: 0.4137
	--> Epoch [3/100], Loss: 0.0260, Validation Loss: 0.4196
	--> Epoch [4/100], Loss: 0.0200, Validation Loss: 0.3858
	--> Epoch [5/100], Loss: 0.0044, Validation Loss: 0.3756
	--> Epoch [6/100], Loss: 0.0047, Validation Loss: 0.4105
	--> Epoch [7/100], Loss: 0.0045, Validation Loss: 0.3801
	--> Epoch [8/100], Loss: 0.0002, Validation Loss: 0.3754
	--> Epoch [9/100], Loss: 0.0011, Validation Loss: 0.3766
	--> Epoch [10/100], Loss: 0.0267, Validation Loss: 0.4270
	--> Epoch [11/100], Loss: 0.0050, Validation Loss: 0.4292
Early stopping
	--> Training for Fold 4 took 0.3264598846435547 sec, using 11 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.1594, Validation Loss: 0.6972
	--> Epoch [2/100], Loss: 0.2766, Validation Loss: 0.5672
	--> Epoch [3/100], Loss: 0.0012, Validation Loss: 0.6004
	--> Epoch [4/100], Loss: 0.0164, Validation Loss: 0.6176
	--> Epoch [5/100], Loss: 0.0043, Validation Loss: 0.6213
Early stopping
	--> Training for Fold 5 took 0.15617942810058594 sec, using 5 epochs

Median number of epochs used: 9 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/9], Loss: 0.4838
	--> Final training Epoch [2/9], Loss: 0.4208
	--> Final training Epoch [3/9], Loss: 0.0378
	--> Final training Epoch [4/9], Loss: 0.0837
	--> Final training Epoch [5/9], Loss: 0.1424
	--> Final training Epoch [6/9], Loss: 0.0094
	--> Final training Epoch [7/9], Loss: 0.1323
	--> Final training Epoch [8/9], Loss: 0.1282
	--> Final training Epoch [9/9], Loss: 0.0102

Final training took 0.3160858154296875 sec

TESTING
	--> Testing took 0.0119 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 1.2735
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3199,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3378,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8801, Validation Loss: 0.3817,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8713, Validation Loss: 0.3453,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.3781,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3665,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.3846,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7947, Validation Loss: 0.4241,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8152, Validation Loss: 0.4121,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3629,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3476,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3498,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3199

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6224, Validation Loss: 0.4730
	--> Epoch [2/100], Loss: 0.3514, Validation Loss: 0.4103
	--> Epoch [3/100], Loss: 0.3161, Validation Loss: 0.3058
	--> Epoch [4/100], Loss: 0.1919, Validation Loss: 0.2978
	--> Epoch [5/100], Loss: 0.2631, Validation Loss: 0.2589
	--> Epoch [6/100], Loss: 0.1888, Validation Loss: 0.2771
	--> Epoch [7/100], Loss: 0.0741, Validation Loss: 0.2654
	--> Epoch [8/100], Loss: 0.0387, Validation Loss: 0.2708
Early stopping
	--> Training for Fold 1 took 0.09170913696289062 sec, using 8 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.4956, Validation Loss: 0.5212
	--> Epoch [2/100], Loss: 0.6903, Validation Loss: 0.3433
	--> Epoch [3/100], Loss: 0.2603, Validation Loss: 0.2575
	--> Epoch [4/100], Loss: 0.3273, Validation Loss: 0.2392
	--> Epoch [5/100], Loss: 0.2472, Validation Loss: 0.2045
	--> Epoch [6/100], Loss: 0.1358, Validation Loss: 0.2022
	--> Epoch [7/100], Loss: 0.2760, Validation Loss: 0.1793
	--> Epoch [8/100], Loss: 0.1485, Validation Loss: 0.1967
	--> Epoch [9/100], Loss: 0.1631, Validation Loss: 0.2004
	--> Epoch [10/100], Loss: 0.0690, Validation Loss: 0.1967
Early stopping
	--> Training for Fold 2 took 0.12308526039123535 sec, using 10 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.3883, Validation Loss: 0.7298
	--> Epoch [2/100], Loss: 0.3242, Validation Loss: 0.6403
	--> Epoch [3/100], Loss: 0.2970, Validation Loss: 0.4906
	--> Epoch [4/100], Loss: 0.2074, Validation Loss: 0.4900
	--> Epoch [5/100], Loss: 0.2072, Validation Loss: 0.4220
	--> Epoch [6/100], Loss: 0.5507, Validation Loss: 0.4023
	--> Epoch [7/100], Loss: 0.1341, Validation Loss: 0.4032
	--> Epoch [8/100], Loss: 0.1452, Validation Loss: 0.3781
	--> Epoch [9/100], Loss: 0.0919, Validation Loss: 0.3940
	--> Epoch [10/100], Loss: 0.1475, Validation Loss: 0.3781
	--> Epoch [11/100], Loss: 0.0746, Validation Loss: 0.3480
	--> Epoch [12/100], Loss: 0.0715, Validation Loss: 0.3468
	--> Epoch [13/100], Loss: 0.1538, Validation Loss: 0.3795
	--> Epoch [14/100], Loss: 0.0649, Validation Loss: 0.3582
	--> Epoch [15/100], Loss: 0.1401, Validation Loss: 0.3869
Early stopping
	--> Training for Fold 3 took 0.19577980041503906 sec, using 15 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6018, Validation Loss: 0.5277
	--> Epoch [2/100], Loss: 0.4170, Validation Loss: 0.3915
	--> Epoch [3/100], Loss: 0.4383, Validation Loss: 0.3900
	--> Epoch [4/100], Loss: 0.1731, Validation Loss: 0.4040
	--> Epoch [5/100], Loss: 0.1394, Validation Loss: 0.4111
	--> Epoch [6/100], Loss: 0.0736, Validation Loss: 0.3989
Early stopping
	--> Training for Fold 4 took 0.07582259178161621 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5785, Validation Loss: 0.6044
	--> Epoch [2/100], Loss: 0.3573, Validation Loss: 0.5493
	--> Epoch [3/100], Loss: 0.1750, Validation Loss: 0.5610
	--> Epoch [4/100], Loss: 0.1449, Validation Loss: 0.5308
	--> Epoch [5/100], Loss: 0.1567, Validation Loss: 0.5830
	--> Epoch [6/100], Loss: 0.3045, Validation Loss: 0.6606
	--> Epoch [7/100], Loss: 0.1538, Validation Loss: 0.6273
Early stopping
	--> Training for Fold 5 took 0.07936263084411621 sec, using 7 epochs

Median number of epochs used: 8 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/8], Loss: 0.6213
	--> Final training Epoch [2/8], Loss: 0.4980
	--> Final training Epoch [3/8], Loss: 0.3007
	--> Final training Epoch [4/8], Loss: 0.3654
	--> Final training Epoch [5/8], Loss: 0.3816
	--> Final training Epoch [6/8], Loss: 0.2410
	--> Final training Epoch [7/8], Loss: 0.1316
	--> Final training Epoch [8/8], Loss: 0.3211

Final training took 0.10863256454467773 sec

TESTING
	--> Testing took 0.0071 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 0.7780
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8918, Validation Loss: 0.2760,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8696, Validation Loss: 0.3413,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8158, Validation Loss: 0.3724,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3627,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.3586,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7947, Validation Loss: 0.4055,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3231,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3187,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3207,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8164, Validation Loss: 0.3669,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8579, Validation Loss: 0.3121,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.3354,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7620, Validation Loss: 0.4154,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8287, Validation Loss: 0.3654,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3600,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3612,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8696, Validation Loss: 0.3147,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3374,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3399,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3562,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8585, Validation Loss: 0.3853,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8585, Validation Loss: 0.3738,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8170, Validation Loss: 0.4244,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3355,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3819,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.2760

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7166, Validation Loss: 0.4661
	--> Epoch [2/100], Loss: 0.3366, Validation Loss: 0.3073
	--> Epoch [3/100], Loss: 0.1758, Validation Loss: 0.2706
	--> Epoch [4/100], Loss: 0.0933, Validation Loss: 0.2437
	--> Epoch [5/100], Loss: 0.1385, Validation Loss: 0.2345
	--> Epoch [6/100], Loss: 0.0950, Validation Loss: 0.2392
	--> Epoch [7/100], Loss: 0.0873, Validation Loss: 0.2106
	--> Epoch [8/100], Loss: 0.0726, Validation Loss: 0.2378
	--> Epoch [9/100], Loss: 0.0633, Validation Loss: 0.2132
	--> Epoch [10/100], Loss: 0.1665, Validation Loss: 0.2075
	--> Epoch [11/100], Loss: 0.0759, Validation Loss: 0.2182
	--> Epoch [12/100], Loss: 0.0680, Validation Loss: 0.2279
	--> Epoch [13/100], Loss: 0.0596, Validation Loss: 0.2037
	--> Epoch [14/100], Loss: 0.0594, Validation Loss: 0.1997
	--> Epoch [15/100], Loss: 0.0628, Validation Loss: 0.1973
	--> Epoch [16/100], Loss: 0.0622, Validation Loss: 0.1802
	--> Epoch [17/100], Loss: 0.0648, Validation Loss: 0.2071
	--> Epoch [18/100], Loss: 0.1215, Validation Loss: 0.1886
	--> Epoch [19/100], Loss: 0.0612, Validation Loss: 0.1648
	--> Epoch [20/100], Loss: 0.0598, Validation Loss: 0.1734
	--> Epoch [21/100], Loss: 0.0621, Validation Loss: 0.1534
	--> Epoch [22/100], Loss: 0.0641, Validation Loss: 0.1828
	--> Epoch [23/100], Loss: 0.1426, Validation Loss: 0.1750
	--> Epoch [24/100], Loss: 0.0633, Validation Loss: 0.1742
Early stopping
	--> Training for Fold 1 took 0.28949952125549316 sec, using 24 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7901, Validation Loss: 0.3964
	--> Epoch [2/100], Loss: 0.3589, Validation Loss: 0.3189
	--> Epoch [3/100], Loss: 0.1815, Validation Loss: 0.2578
	--> Epoch [4/100], Loss: 0.1393, Validation Loss: 0.2351
	--> Epoch [5/100], Loss: 0.1535, Validation Loss: 0.2200
	--> Epoch [6/100], Loss: 0.1537, Validation Loss: 0.2020
	--> Epoch [7/100], Loss: 0.1282, Validation Loss: 0.1710
	--> Epoch [8/100], Loss: 0.1091, Validation Loss: 0.1566
	--> Epoch [9/100], Loss: 0.1500, Validation Loss: 0.1464
	--> Epoch [10/100], Loss: 0.1758, Validation Loss: 0.1415
	--> Epoch [11/100], Loss: 0.1065, Validation Loss: 0.1426
	--> Epoch [12/100], Loss: 0.1193, Validation Loss: 0.1382
	--> Epoch [13/100], Loss: 0.1067, Validation Loss: 0.1218
	--> Epoch [14/100], Loss: 0.1925, Validation Loss: 0.1179
	--> Epoch [15/100], Loss: 0.1287, Validation Loss: 0.1168
	--> Epoch [16/100], Loss: 0.1106, Validation Loss: 0.1177
	--> Epoch [17/100], Loss: 0.1137, Validation Loss: 0.1489
	--> Epoch [18/100], Loss: 0.1119, Validation Loss: 0.1325
Early stopping
	--> Training for Fold 2 took 0.22784662246704102 sec, using 18 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6347, Validation Loss: 0.5405
	--> Epoch [2/100], Loss: 0.4152, Validation Loss: 0.4624
	--> Epoch [3/100], Loss: 0.2304, Validation Loss: 0.3702
	--> Epoch [4/100], Loss: 0.2046, Validation Loss: 0.3525
	--> Epoch [5/100], Loss: 0.2038, Validation Loss: 0.3647
	--> Epoch [6/100], Loss: 0.1876, Validation Loss: 0.3991
	--> Epoch [7/100], Loss: 0.1737, Validation Loss: 0.4165
Early stopping
	--> Training for Fold 3 took 0.08296799659729004 sec, using 7 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5140, Validation Loss: 0.5780
	--> Epoch [2/100], Loss: 0.3644, Validation Loss: 0.4825
	--> Epoch [3/100], Loss: 0.1345, Validation Loss: 0.3729
	--> Epoch [4/100], Loss: 0.1116, Validation Loss: 0.4683
	--> Epoch [5/100], Loss: 0.0683, Validation Loss: 0.4066
	--> Epoch [6/100], Loss: 0.0121, Validation Loss: 0.4170
Early stopping
	--> Training for Fold 4 took 0.07626128196716309 sec, using 6 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5873, Validation Loss: 0.5658
	--> Epoch [2/100], Loss: 0.3704, Validation Loss: 0.5205
	--> Epoch [3/100], Loss: 0.2206, Validation Loss: 0.5157
	--> Epoch [4/100], Loss: 0.1126, Validation Loss: 0.5557
	--> Epoch [5/100], Loss: 0.0874, Validation Loss: 0.6210
	--> Epoch [6/100], Loss: 0.1268, Validation Loss: 0.5399
Early stopping
	--> Training for Fold 5 took 0.07067394256591797 sec, using 6 epochs

Median number of epochs used: 7 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/7], Loss: 0.7212
	--> Final training Epoch [2/7], Loss: 0.3384
	--> Final training Epoch [3/7], Loss: 0.2001
	--> Final training Epoch [4/7], Loss: 0.2077
	--> Final training Epoch [5/7], Loss: 0.2244
	--> Final training Epoch [6/7], Loss: 0.0932
	--> Final training Epoch [7/7], Loss: 0.0331

Final training took 0.1025078296661377 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9642
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.9018, Validation Loss: 0.2951,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3597,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3617,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3150,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3268,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8503, Validation Loss: 0.3780,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3999,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3387,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3952,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3634,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3421,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3141,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3862,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8819, Validation Loss: 0.3190,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 0.4126,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.4019,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 16, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8047, Validation Loss: 0.3734,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3369,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3211,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3843,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8713, Validation Loss: 0.3673,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3608,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.3531,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.4028,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.4035,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.4493,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8924, Validation Loss: 0.3180,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8918, Validation Loss: 0.3392,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8585, Validation Loss: 0.3679,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8690, Validation Loss: 0.3136,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.3831,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3403,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8474, Validation Loss: 0.3423,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.4039,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7836, Validation Loss: 0.4516,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8924, Validation Loss: 0.3121,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8368, Validation Loss: 0.3719,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8819, Validation Loss: 0.3020,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8053, Validation Loss: 0.4281,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8819, Validation Loss: 0.3133,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3523,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3834,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3402,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3792,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8480, Validation Loss: 0.3278,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3347,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3771,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3670,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8713, Validation Loss: 0.3198,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3613,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.4051,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 0.4174,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8696, Validation Loss: 0.3542,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3437,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8801, Validation Loss: 0.3421,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3889,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3571,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8591, Validation Loss: 0.3455,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3762,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.3540,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.3565,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 32, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.4254,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8158, Validation Loss: 0.3486,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3956,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8713, Validation Loss: 0.3600,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8269, Validation Loss: 0.3389,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.3980,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3384,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7842, Validation Loss: 0.4324,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8170, Validation Loss: 0.4936,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7836, Validation Loss: 0.4592,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8035, Validation Loss: 0.3501,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3514,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3267,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.4134,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3960,  Current Best Accuracy: 0.9018,  Current Best Validation Loss: 0.2951

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6492, Validation Loss: 0.5683
	--> Epoch [2/100], Loss: 0.4659, Validation Loss: 0.4757
	--> Epoch [3/100], Loss: 0.3484, Validation Loss: 0.3937
	--> Epoch [4/100], Loss: 0.3227, Validation Loss: 0.3521
	--> Epoch [5/100], Loss: 0.1910, Validation Loss: 0.3613
	--> Epoch [6/100], Loss: 0.0833, Validation Loss: 0.3152
	--> Epoch [7/100], Loss: 0.1224, Validation Loss: 0.2861
	--> Epoch [8/100], Loss: 0.1728, Validation Loss: 0.2865
	--> Epoch [9/100], Loss: 0.0881, Validation Loss: 0.2632
	--> Epoch [10/100], Loss: 0.0226, Validation Loss: 0.2666
	--> Epoch [11/100], Loss: 0.0592, Validation Loss: 0.2649
	--> Epoch [12/100], Loss: 0.0716, Validation Loss: 0.2495
	--> Epoch [13/100], Loss: 0.0799, Validation Loss: 0.2522
	--> Epoch [14/100], Loss: 0.0938, Validation Loss: 0.2457
	--> Epoch [15/100], Loss: 0.0778, Validation Loss: 0.2551
	--> Epoch [16/100], Loss: 0.0170, Validation Loss: 0.2535
	--> Epoch [17/100], Loss: 0.0075, Validation Loss: 0.2570
Early stopping
	--> Training for Fold 1 took 0.09631800651550293 sec, using 17 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6817, Validation Loss: 0.5761
	--> Epoch [2/100], Loss: 0.4921, Validation Loss: 0.5214
	--> Epoch [3/100], Loss: 0.3403, Validation Loss: 0.4358
	--> Epoch [4/100], Loss: 0.2793, Validation Loss: 0.4183
	--> Epoch [5/100], Loss: 0.2535, Validation Loss: 0.3777
	--> Epoch [6/100], Loss: 0.1436, Validation Loss: 0.3373
	--> Epoch [7/100], Loss: 0.2069, Validation Loss: 0.3051
	--> Epoch [8/100], Loss: 0.1510, Validation Loss: 0.2755
	--> Epoch [9/100], Loss: 0.0317, Validation Loss: 0.2579
	--> Epoch [10/100], Loss: 0.1742, Validation Loss: 0.2440
	--> Epoch [11/100], Loss: 0.0090, Validation Loss: 0.2216
	--> Epoch [12/100], Loss: 0.0926, Validation Loss: 0.2174
	--> Epoch [13/100], Loss: 0.1430, Validation Loss: 0.2277
	--> Epoch [14/100], Loss: 0.2174, Validation Loss: 0.2270
	--> Epoch [15/100], Loss: 0.0116, Validation Loss: 0.2280
Early stopping
	--> Training for Fold 2 took 0.08288359642028809 sec, using 15 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4926, Validation Loss: 0.6099
	--> Epoch [2/100], Loss: 0.3523, Validation Loss: 0.6064
	--> Epoch [3/100], Loss: 0.1470, Validation Loss: 0.5301
	--> Epoch [4/100], Loss: 0.2611, Validation Loss: 0.4835
	--> Epoch [5/100], Loss: 0.2709, Validation Loss: 0.4696
	--> Epoch [6/100], Loss: 0.0915, Validation Loss: 0.4634
	--> Epoch [7/100], Loss: 0.1327, Validation Loss: 0.4327
	--> Epoch [8/100], Loss: 0.0923, Validation Loss: 0.4284
	--> Epoch [9/100], Loss: 0.0971, Validation Loss: 0.4122
	--> Epoch [10/100], Loss: 0.2276, Validation Loss: 0.3653
	--> Epoch [11/100], Loss: 0.1233, Validation Loss: 0.3637
	--> Epoch [12/100], Loss: 0.0114, Validation Loss: 0.3564
	--> Epoch [13/100], Loss: 0.1397, Validation Loss: 0.3497
	--> Epoch [14/100], Loss: 0.2622, Validation Loss: 0.3804
	--> Epoch [15/100], Loss: 0.1515, Validation Loss: 0.3696
	--> Epoch [16/100], Loss: 0.0041, Validation Loss: 0.3618
Early stopping
	--> Training for Fold 3 took 0.12740063667297363 sec, using 16 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5355, Validation Loss: 0.6405
	--> Epoch [2/100], Loss: 0.3869, Validation Loss: 0.5667
	--> Epoch [3/100], Loss: 0.2995, Validation Loss: 0.5107
	--> Epoch [4/100], Loss: 0.2871, Validation Loss: 0.5265
	--> Epoch [5/100], Loss: 0.2844, Validation Loss: 0.4478
	--> Epoch [6/100], Loss: 0.1422, Validation Loss: 0.3961
	--> Epoch [7/100], Loss: 0.2600, Validation Loss: 0.3829
	--> Epoch [8/100], Loss: 0.1322, Validation Loss: 0.3647
	--> Epoch [9/100], Loss: 0.1156, Validation Loss: 0.3570
	--> Epoch [10/100], Loss: 0.1749, Validation Loss: 0.3405
	--> Epoch [11/100], Loss: 0.0169, Validation Loss: 0.3345
	--> Epoch [12/100], Loss: 0.0965, Validation Loss: 0.3181
	--> Epoch [13/100], Loss: 0.0997, Validation Loss: 0.3235
	--> Epoch [14/100], Loss: 0.0600, Validation Loss: 0.3005
	--> Epoch [15/100], Loss: 0.0496, Validation Loss: 0.2823
	--> Epoch [16/100], Loss: 0.0027, Validation Loss: 0.2935
	--> Epoch [17/100], Loss: 0.0126, Validation Loss: 0.2971
	--> Epoch [18/100], Loss: 0.1093, Validation Loss: 0.3494
Early stopping
	--> Training for Fold 4 took 0.12421488761901855 sec, using 18 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4786, Validation Loss: 0.6559
	--> Epoch [2/100], Loss: 0.2913, Validation Loss: 0.6522
	--> Epoch [3/100], Loss: 0.2746, Validation Loss: 0.6525
	--> Epoch [4/100], Loss: 0.2125, Validation Loss: 0.5990
	--> Epoch [5/100], Loss: 0.2100, Validation Loss: 0.5358
	--> Epoch [6/100], Loss: 0.1262, Validation Loss: 0.5261
	--> Epoch [7/100], Loss: 0.2404, Validation Loss: 0.5295
	--> Epoch [8/100], Loss: 0.3076, Validation Loss: 0.5535
	--> Epoch [9/100], Loss: 0.2329, Validation Loss: 0.5446
Early stopping
	--> Training for Fold 5 took 0.08517813682556152 sec, using 9 epochs

Median number of epochs used: 16 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/16], Loss: 0.6369
	--> Final training Epoch [2/16], Loss: 0.5338
	--> Final training Epoch [3/16], Loss: 0.3718
	--> Final training Epoch [4/16], Loss: 0.3365
	--> Final training Epoch [5/16], Loss: 0.2721
	--> Final training Epoch [6/16], Loss: 0.2665
	--> Final training Epoch [7/16], Loss: 0.2154
	--> Final training Epoch [8/16], Loss: 0.1897
	--> Final training Epoch [9/16], Loss: 0.1622
	--> Final training Epoch [10/16], Loss: 0.1391
	--> Final training Epoch [11/16], Loss: 0.1393
	--> Final training Epoch [12/16], Loss: 0.1047
	--> Final training Epoch [13/16], Loss: 0.0477
	--> Final training Epoch [14/16], Loss: 0.1005
	--> Final training Epoch [15/16], Loss: 0.1083
	--> Final training Epoch [16/16], Loss: 0.1430

Final training took 0.09762907028198242 sec

TESTING
	--> Testing took 0.0120 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.1375
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8398, Validation Loss: 0.2950,  Current Best Accuracy: 0.8398,  Current Best Validation Loss: 0.2950
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8035, Validation Loss: 0.4599,  Current Best Accuracy: 0.8398,  Current Best Validation Loss: 0.2950
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3862,  Current Best Accuracy: 0.8398,  Current Best Validation Loss: 0.2950
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7959, Validation Loss: 0.4801,  Current Best Accuracy: 0.8398,  Current Best Validation Loss: 0.2950

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6253, Validation Loss: 0.5113
	--> Epoch [2/100], Loss: 0.3533, Validation Loss: 0.3966
	--> Epoch [3/100], Loss: 0.2653, Validation Loss: 0.3265
	--> Epoch [4/100], Loss: 0.1710, Validation Loss: 0.2883
	--> Epoch [5/100], Loss: 0.2166, Validation Loss: 0.2774
	--> Epoch [6/100], Loss: 0.0816, Validation Loss: 0.2583
	--> Epoch [7/100], Loss: 0.0661, Validation Loss: 0.2497
	--> Epoch [8/100], Loss: 0.1117, Validation Loss: 0.2512
	--> Epoch [9/100], Loss: 0.1133, Validation Loss: 0.2394
	--> Epoch [10/100], Loss: 0.0632, Validation Loss: 0.2275
	--> Epoch [11/100], Loss: 0.1651, Validation Loss: 0.2210
	--> Epoch [12/100], Loss: 0.0635, Validation Loss: 0.2228
	--> Epoch [13/100], Loss: 0.1232, Validation Loss: 0.2219
	--> Epoch [14/100], Loss: 0.0782, Validation Loss: 0.2299
Early stopping
	--> Training for Fold 1 took 0.07707071304321289 sec, using 14 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6047, Validation Loss: 0.5221
	--> Epoch [2/100], Loss: 0.4136, Validation Loss: 0.4275
	--> Epoch [3/100], Loss: 0.2530, Validation Loss: 0.3734
	--> Epoch [4/100], Loss: 0.2580, Validation Loss: 0.3331
	--> Epoch [5/100], Loss: 0.1646, Validation Loss: 0.2957
	--> Epoch [6/100], Loss: 0.1660, Validation Loss: 0.2603
	--> Epoch [7/100], Loss: 0.0845, Validation Loss: 0.2408
	--> Epoch [8/100], Loss: 0.1509, Validation Loss: 0.2302
	--> Epoch [9/100], Loss: 0.2036, Validation Loss: 0.2082
	--> Epoch [10/100], Loss: 0.1591, Validation Loss: 0.2180
	--> Epoch [11/100], Loss: 0.1360, Validation Loss: 0.2020
	--> Epoch [12/100], Loss: 0.0804, Validation Loss: 0.1912
	--> Epoch [13/100], Loss: 0.0810, Validation Loss: 0.2007
	--> Epoch [14/100], Loss: 0.1449, Validation Loss: 0.1744
	--> Epoch [15/100], Loss: 0.0627, Validation Loss: 0.1744
	--> Epoch [16/100], Loss: 0.1355, Validation Loss: 0.1757
	--> Epoch [17/100], Loss: 0.0638, Validation Loss: 0.1635
	--> Epoch [18/100], Loss: 0.0650, Validation Loss: 0.1439
	--> Epoch [19/100], Loss: 0.1209, Validation Loss: 0.1472
	--> Epoch [20/100], Loss: 0.0568, Validation Loss: 0.1407
	--> Epoch [21/100], Loss: 0.0585, Validation Loss: 0.1484
	--> Epoch [22/100], Loss: 0.0573, Validation Loss: 0.1463
	--> Epoch [23/100], Loss: 0.0557, Validation Loss: 0.1500
Early stopping
	--> Training for Fold 2 took 0.13334059715270996 sec, using 23 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6591, Validation Loss: 0.6531
	--> Epoch [2/100], Loss: 0.3491, Validation Loss: 0.5660
	--> Epoch [3/100], Loss: 0.2109, Validation Loss: 0.5182
	--> Epoch [4/100], Loss: 0.2069, Validation Loss: 0.4576
	--> Epoch [5/100], Loss: 0.1362, Validation Loss: 0.4313
	--> Epoch [6/100], Loss: 0.1006, Validation Loss: 0.4084
	--> Epoch [7/100], Loss: 0.1262, Validation Loss: 0.3852
	--> Epoch [8/100], Loss: 0.0462, Validation Loss: 0.3891
	--> Epoch [9/100], Loss: 0.1007, Validation Loss: 0.3625
	--> Epoch [10/100], Loss: 0.1304, Validation Loss: 0.3538
	--> Epoch [11/100], Loss: 0.0753, Validation Loss: 0.3236
	--> Epoch [12/100], Loss: 0.0118, Validation Loss: 0.3199
	--> Epoch [13/100], Loss: 0.0580, Validation Loss: 0.3172
	--> Epoch [14/100], Loss: 0.0591, Validation Loss: 0.3162
	--> Epoch [15/100], Loss: 0.0623, Validation Loss: 0.3084
	--> Epoch [16/100], Loss: 0.0546, Validation Loss: 0.3195
	--> Epoch [17/100], Loss: 0.0034, Validation Loss: 0.3268
	--> Epoch [18/100], Loss: 0.0091, Validation Loss: 0.3269
Early stopping
	--> Training for Fold 3 took 0.14599132537841797 sec, using 18 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7374, Validation Loss: 0.5191
	--> Epoch [2/100], Loss: 0.5443, Validation Loss: 0.4826
	--> Epoch [3/100], Loss: 0.2638, Validation Loss: 0.3950
	--> Epoch [4/100], Loss: 0.1467, Validation Loss: 0.3401
	--> Epoch [5/100], Loss: 0.0635, Validation Loss: 0.3404
	--> Epoch [6/100], Loss: 0.0445, Validation Loss: 0.3012
	--> Epoch [7/100], Loss: 0.0426, Validation Loss: 0.2900
	--> Epoch [8/100], Loss: 0.1169, Validation Loss: 0.2876
	--> Epoch [9/100], Loss: 0.1045, Validation Loss: 0.2822
	--> Epoch [10/100], Loss: 0.0122, Validation Loss: 0.2777
	--> Epoch [11/100], Loss: 0.0063, Validation Loss: 0.2676
	--> Epoch [12/100], Loss: 0.0229, Validation Loss: 0.2726
	--> Epoch [13/100], Loss: 0.0162, Validation Loss: 0.2651
	--> Epoch [14/100], Loss: 0.0054, Validation Loss: 0.2662
	--> Epoch [15/100], Loss: 0.0110, Validation Loss: 0.2675
	--> Epoch [16/100], Loss: 0.0684, Validation Loss: 0.2686
Early stopping
	--> Training for Fold 4 took 0.11647796630859375 sec, using 16 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4859, Validation Loss: 0.6877
	--> Epoch [2/100], Loss: 0.2596, Validation Loss: 0.7316
	--> Epoch [3/100], Loss: 0.1700, Validation Loss: 0.7662
	--> Epoch [4/100], Loss: 0.1572, Validation Loss: 0.7933
Early stopping
	--> Training for Fold 5 took 0.036499738693237305 sec, using 4 epochs

Median number of epochs used: 16 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/16], Loss: 0.5881
	--> Final training Epoch [2/16], Loss: 0.4600
	--> Final training Epoch [3/16], Loss: 0.3494
	--> Final training Epoch [4/16], Loss: 0.3429
	--> Final training Epoch [5/16], Loss: 0.2567
	--> Final training Epoch [6/16], Loss: 0.2498
	--> Final training Epoch [7/16], Loss: 0.2038
	--> Final training Epoch [8/16], Loss: 0.2411
	--> Final training Epoch [9/16], Loss: 0.1333
	--> Final training Epoch [10/16], Loss: 0.1385
	--> Final training Epoch [11/16], Loss: 0.2221
	--> Final training Epoch [12/16], Loss: 0.1241
	--> Final training Epoch [13/16], Loss: 0.0890
	--> Final training Epoch [14/16], Loss: 0.0438
	--> Final training Epoch [15/16], Loss: 0.0502
	--> Final training Epoch [16/16], Loss: 0.1762

Final training took 0.09284234046936035 sec

TESTING
	--> Testing took 0.0102 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9957
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3277,  Current Best Accuracy: 0.8591,  Current Best Validation Loss: 0.3277

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7140, Validation Loss: 0.5159
	--> Epoch [2/100], Loss: 0.4063, Validation Loss: 0.4240
	--> Epoch [3/100], Loss: 0.3686, Validation Loss: 0.3394
	--> Epoch [4/100], Loss: 0.2811, Validation Loss: 0.3215
	--> Epoch [5/100], Loss: 0.1295, Validation Loss: 0.2952
	--> Epoch [6/100], Loss: 0.1162, Validation Loss: 0.2832
	--> Epoch [7/100], Loss: 0.1365, Validation Loss: 0.2895
	--> Epoch [8/100], Loss: 0.1045, Validation Loss: 0.2877
	--> Epoch [9/100], Loss: 0.1919, Validation Loss: 0.2651
	--> Epoch [10/100], Loss: 0.1055, Validation Loss: 0.2776
	--> Epoch [11/100], Loss: 0.0782, Validation Loss: 0.2696
	--> Epoch [12/100], Loss: 0.0798, Validation Loss: 0.2579
	--> Epoch [13/100], Loss: 0.0868, Validation Loss: 0.2581
	--> Epoch [14/100], Loss: 0.0839, Validation Loss: 0.2609
	--> Epoch [15/100], Loss: 0.0901, Validation Loss: 0.2792
Early stopping
	--> Training for Fold 1 took 0.08370518684387207 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5526, Validation Loss: 0.4636
	--> Epoch [2/100], Loss: 0.3732, Validation Loss: 0.3972
	--> Epoch [3/100], Loss: 0.2794, Validation Loss: 0.3429
	--> Epoch [4/100], Loss: 0.1276, Validation Loss: 0.3097
	--> Epoch [5/100], Loss: 0.0966, Validation Loss: 0.2786
	--> Epoch [6/100], Loss: 0.0956, Validation Loss: 0.2445
	--> Epoch [7/100], Loss: 0.1307, Validation Loss: 0.2186
	--> Epoch [8/100], Loss: 0.1646, Validation Loss: 0.2132
	--> Epoch [9/100], Loss: 0.1758, Validation Loss: 0.2099
	--> Epoch [10/100], Loss: 0.1007, Validation Loss: 0.1993
	--> Epoch [11/100], Loss: 0.0620, Validation Loss: 0.1974
	--> Epoch [12/100], Loss: 0.0726, Validation Loss: 0.1829
	--> Epoch [13/100], Loss: 0.0634, Validation Loss: 0.1842
	--> Epoch [14/100], Loss: 0.0621, Validation Loss: 0.1741
	--> Epoch [15/100], Loss: 0.0634, Validation Loss: 0.1684
	--> Epoch [16/100], Loss: 0.0591, Validation Loss: 0.1662
	--> Epoch [17/100], Loss: 0.0695, Validation Loss: 0.1680
	--> Epoch [18/100], Loss: 0.0593, Validation Loss: 0.1679
	--> Epoch [19/100], Loss: 0.0640, Validation Loss: 0.1575
	--> Epoch [20/100], Loss: 0.0755, Validation Loss: 0.1493
	--> Epoch [21/100], Loss: 0.0575, Validation Loss: 0.1528
	--> Epoch [22/100], Loss: 0.0605, Validation Loss: 0.1580
	--> Epoch [23/100], Loss: 0.0577, Validation Loss: 0.1504
Early stopping
	--> Training for Fold 2 took 0.13634252548217773 sec, using 23 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6228, Validation Loss: 0.5863
	--> Epoch [2/100], Loss: 0.5234, Validation Loss: 0.5589
	--> Epoch [3/100], Loss: 0.3267, Validation Loss: 0.4931
	--> Epoch [4/100], Loss: 0.1877, Validation Loss: 0.4434
	--> Epoch [5/100], Loss: 0.1866, Validation Loss: 0.4123
	--> Epoch [6/100], Loss: 0.0882, Validation Loss: 0.3890
	--> Epoch [7/100], Loss: 0.1418, Validation Loss: 0.3954
	--> Epoch [8/100], Loss: 0.2225, Validation Loss: 0.3751
	--> Epoch [9/100], Loss: 0.1412, Validation Loss: 0.3505
	--> Epoch [10/100], Loss: 0.1383, Validation Loss: 0.3457
	--> Epoch [11/100], Loss: 0.0792, Validation Loss: 0.3647
	--> Epoch [12/100], Loss: 0.0714, Validation Loss: 0.3645
	--> Epoch [13/100], Loss: 0.0592, Validation Loss: 0.3652
Early stopping
	--> Training for Fold 3 took 0.1101987361907959 sec, using 13 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5807, Validation Loss: 0.5838
	--> Epoch [2/100], Loss: 0.3261, Validation Loss: 0.5652
	--> Epoch [3/100], Loss: 0.2287, Validation Loss: 0.5185
	--> Epoch [4/100], Loss: 0.1160, Validation Loss: 0.4852
	--> Epoch [5/100], Loss: 0.0625, Validation Loss: 0.4570
	--> Epoch [6/100], Loss: 0.1028, Validation Loss: 0.4234
	--> Epoch [7/100], Loss: 0.1181, Validation Loss: 0.4044
	--> Epoch [8/100], Loss: 0.1348, Validation Loss: 0.4585
	--> Epoch [9/100], Loss: 0.1870, Validation Loss: 0.4548
	--> Epoch [10/100], Loss: 0.0582, Validation Loss: 0.4447
Early stopping
	--> Training for Fold 4 took 0.056702613830566406 sec, using 10 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6859, Validation Loss: 0.6014
	--> Epoch [2/100], Loss: 0.5605, Validation Loss: 0.6096
	--> Epoch [3/100], Loss: 0.2875, Validation Loss: 0.5838
	--> Epoch [4/100], Loss: 0.2424, Validation Loss: 0.6020
	--> Epoch [5/100], Loss: 0.2321, Validation Loss: 0.6275
	--> Epoch [6/100], Loss: 0.1423, Validation Loss: 0.6455
Early stopping
	--> Training for Fold 5 took 0.05010795593261719 sec, using 6 epochs

Median number of epochs used: 13 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/13], Loss: 0.5893
	--> Final training Epoch [2/13], Loss: 0.4155
	--> Final training Epoch [3/13], Loss: 0.2819
	--> Final training Epoch [4/13], Loss: 0.2013
	--> Final training Epoch [5/13], Loss: 0.1434
	--> Final training Epoch [6/13], Loss: 0.1139
	--> Final training Epoch [7/13], Loss: 0.0964
	--> Final training Epoch [8/13], Loss: 0.1172
	--> Final training Epoch [9/13], Loss: 0.1347
	--> Final training Epoch [10/13], Loss: 0.0539
	--> Final training Epoch [11/13], Loss: 0.1058
	--> Final training Epoch [12/13], Loss: 0.0546
	--> Final training Epoch [13/13], Loss: 0.0865

Final training took 0.09706711769104004 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 1.0995
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3204,  Current Best Accuracy: 0.8485,  Current Best Validation Loss: 0.3204

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8468, Validation Loss: 0.6185
	--> Epoch [2/100], Loss: 0.5539, Validation Loss: 0.4997
	--> Epoch [3/100], Loss: 0.4731, Validation Loss: 0.4779
	--> Epoch [4/100], Loss: 0.3049, Validation Loss: 0.3770
	--> Epoch [5/100], Loss: 0.2064, Validation Loss: 0.3336
	--> Epoch [6/100], Loss: 0.1172, Validation Loss: 0.3215
	--> Epoch [7/100], Loss: 0.2088, Validation Loss: 0.3230
	--> Epoch [8/100], Loss: 0.2585, Validation Loss: 0.3150
	--> Epoch [9/100], Loss: 0.1137, Validation Loss: 0.3040
	--> Epoch [10/100], Loss: 0.1779, Validation Loss: 0.3337
	--> Epoch [11/100], Loss: 0.0898, Validation Loss: 0.3116
	--> Epoch [12/100], Loss: 0.0891, Validation Loss: 0.3213
Early stopping
	--> Training for Fold 1 took 0.06821060180664062 sec, using 12 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7025, Validation Loss: 0.4888
	--> Epoch [2/100], Loss: 0.5067, Validation Loss: 0.4201
	--> Epoch [3/100], Loss: 0.4869, Validation Loss: 0.3916
	--> Epoch [4/100], Loss: 0.2679, Validation Loss: 0.3450
	--> Epoch [5/100], Loss: 0.2473, Validation Loss: 0.3163
	--> Epoch [6/100], Loss: 0.2191, Validation Loss: 0.2945
	--> Epoch [7/100], Loss: 0.1420, Validation Loss: 0.2729
	--> Epoch [8/100], Loss: 0.1674, Validation Loss: 0.2552
	--> Epoch [9/100], Loss: 0.0860, Validation Loss: 0.2401
	--> Epoch [10/100], Loss: 0.0833, Validation Loss: 0.2289
	--> Epoch [11/100], Loss: 0.0861, Validation Loss: 0.2216
	--> Epoch [12/100], Loss: 0.1455, Validation Loss: 0.2137
	--> Epoch [13/100], Loss: 0.0926, Validation Loss: 0.2132
	--> Epoch [14/100], Loss: 0.2138, Validation Loss: 0.2037
	--> Epoch [15/100], Loss: 0.1358, Validation Loss: 0.1964
	--> Epoch [16/100], Loss: 0.0719, Validation Loss: 0.1857
	--> Epoch [17/100], Loss: 0.0678, Validation Loss: 0.1815
	--> Epoch [18/100], Loss: 0.0666, Validation Loss: 0.1833
	--> Epoch [19/100], Loss: 0.1263, Validation Loss: 0.1736
	--> Epoch [20/100], Loss: 0.0684, Validation Loss: 0.1735
	--> Epoch [21/100], Loss: 0.0630, Validation Loss: 0.1860
	--> Epoch [22/100], Loss: 0.0632, Validation Loss: 0.1845
	--> Epoch [23/100], Loss: 0.0627, Validation Loss: 0.1789
Early stopping
	--> Training for Fold 2 took 0.13103103637695312 sec, using 23 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8311, Validation Loss: 0.5419
	--> Epoch [2/100], Loss: 0.5098, Validation Loss: 0.5078
	--> Epoch [3/100], Loss: 0.2916, Validation Loss: 0.4753
	--> Epoch [4/100], Loss: 0.2807, Validation Loss: 0.4486
	--> Epoch [5/100], Loss: 0.1588, Validation Loss: 0.4415
	--> Epoch [6/100], Loss: 0.0721, Validation Loss: 0.4047
	--> Epoch [7/100], Loss: 0.0247, Validation Loss: 0.4044
	--> Epoch [8/100], Loss: 0.0911, Validation Loss: 0.3873
	--> Epoch [9/100], Loss: 0.0186, Validation Loss: 0.3801
	--> Epoch [10/100], Loss: 0.0399, Validation Loss: 0.3795
	--> Epoch [11/100], Loss: 0.0200, Validation Loss: 0.3720
	--> Epoch [12/100], Loss: 0.0768, Validation Loss: 0.3689
	--> Epoch [13/100], Loss: 0.1664, Validation Loss: 0.3526
	--> Epoch [14/100], Loss: 0.2219, Validation Loss: 0.3555
	--> Epoch [15/100], Loss: 0.0087, Validation Loss: 0.3631
	--> Epoch [16/100], Loss: 0.0134, Validation Loss: 0.3490
	--> Epoch [17/100], Loss: 0.0141, Validation Loss: 0.3752
	--> Epoch [18/100], Loss: 0.0040, Validation Loss: 0.3612
	--> Epoch [19/100], Loss: 0.0939, Validation Loss: 0.3512
Early stopping
	--> Training for Fold 3 took 0.1488802433013916 sec, using 19 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6017, Validation Loss: 0.5541
	--> Epoch [2/100], Loss: 0.3317, Validation Loss: 0.4928
	--> Epoch [3/100], Loss: 0.2536, Validation Loss: 0.4008
	--> Epoch [4/100], Loss: 0.2243, Validation Loss: 0.3527
	--> Epoch [5/100], Loss: 0.1514, Validation Loss: 0.3971
	--> Epoch [6/100], Loss: 0.2606, Validation Loss: 0.3174
	--> Epoch [7/100], Loss: 0.0988, Validation Loss: 0.3050
	--> Epoch [8/100], Loss: 0.0757, Validation Loss: 0.2969
	--> Epoch [9/100], Loss: 0.0867, Validation Loss: 0.3098
	--> Epoch [10/100], Loss: 0.0856, Validation Loss: 0.2854
	--> Epoch [11/100], Loss: 0.1189, Validation Loss: 0.2952
	--> Epoch [12/100], Loss: 0.1225, Validation Loss: 0.3103
	--> Epoch [13/100], Loss: 0.1217, Validation Loss: 0.2861
Early stopping
	--> Training for Fold 4 took 0.08979916572570801 sec, using 13 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5582, Validation Loss: 0.6281
	--> Epoch [2/100], Loss: 0.2449, Validation Loss: 0.5990
	--> Epoch [3/100], Loss: 0.2738, Validation Loss: 0.6079
	--> Epoch [4/100], Loss: 0.1563, Validation Loss: 0.5948
	--> Epoch [5/100], Loss: 0.1849, Validation Loss: 0.6014
	--> Epoch [6/100], Loss: 0.0815, Validation Loss: 0.6301
	--> Epoch [7/100], Loss: 0.0220, Validation Loss: 0.6178
Early stopping
	--> Training for Fold 5 took 0.06893229484558105 sec, using 7 epochs

Median number of epochs used: 13 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/13], Loss: 0.6113
	--> Final training Epoch [2/13], Loss: 0.4111
	--> Final training Epoch [3/13], Loss: 0.3218
	--> Final training Epoch [4/13], Loss: 0.1899
	--> Final training Epoch [5/13], Loss: 0.1553
	--> Final training Epoch [6/13], Loss: 0.1348
	--> Final training Epoch [7/13], Loss: 0.1046
	--> Final training Epoch [8/13], Loss: 0.1347
	--> Final training Epoch [9/13], Loss: 0.1034
	--> Final training Epoch [10/13], Loss: 0.0661
	--> Final training Epoch [11/13], Loss: 0.1056
	--> Final training Epoch [12/13], Loss: 0.0440
	--> Final training Epoch [13/13], Loss: 0.0272

Final training took 0.07598447799682617 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0816
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3399,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3399
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.7947, Validation Loss: 0.3769,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3399

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5066, Validation Loss: 0.5231
	--> Epoch [2/100], Loss: 0.4089, Validation Loss: 0.4393
	--> Epoch [3/100], Loss: 0.2241, Validation Loss: 0.4031
	--> Epoch [4/100], Loss: 0.2816, Validation Loss: 0.3813
	--> Epoch [5/100], Loss: 0.4188, Validation Loss: 0.3584
	--> Epoch [6/100], Loss: 0.1124, Validation Loss: 0.3299
	--> Epoch [7/100], Loss: 0.1411, Validation Loss: 0.3141
	--> Epoch [8/100], Loss: 0.0867, Validation Loss: 0.3108
	--> Epoch [9/100], Loss: 0.2896, Validation Loss: 0.3077
	--> Epoch [10/100], Loss: 0.0720, Validation Loss: 0.3210
	--> Epoch [11/100], Loss: 0.2084, Validation Loss: 0.3083
	--> Epoch [12/100], Loss: 0.1271, Validation Loss: 0.3169
Early stopping
	--> Training for Fold 1 took 0.07049703598022461 sec, using 12 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6828, Validation Loss: 0.5801
	--> Epoch [2/100], Loss: 0.5921, Validation Loss: 0.4890
	--> Epoch [3/100], Loss: 0.4305, Validation Loss: 0.4025
	--> Epoch [4/100], Loss: 0.5111, Validation Loss: 0.3589
	--> Epoch [5/100], Loss: 0.4080, Validation Loss: 0.3384
	--> Epoch [6/100], Loss: 0.3853, Validation Loss: 0.2991
	--> Epoch [7/100], Loss: 0.2323, Validation Loss: 0.2777
	--> Epoch [8/100], Loss: 0.3523, Validation Loss: 0.2630
	--> Epoch [9/100], Loss: 0.3639, Validation Loss: 0.2330
	--> Epoch [10/100], Loss: 0.2833, Validation Loss: 0.2173
	--> Epoch [11/100], Loss: 0.2645, Validation Loss: 0.2148
	--> Epoch [12/100], Loss: 0.3767, Validation Loss: 0.1953
	--> Epoch [13/100], Loss: 0.1418, Validation Loss: 0.1925
	--> Epoch [14/100], Loss: 0.3603, Validation Loss: 0.1845
	--> Epoch [15/100], Loss: 0.1882, Validation Loss: 0.1734
	--> Epoch [16/100], Loss: 0.1718, Validation Loss: 0.1657
	--> Epoch [17/100], Loss: 0.2242, Validation Loss: 0.1485
	--> Epoch [18/100], Loss: 0.2217, Validation Loss: 0.1469
	--> Epoch [19/100], Loss: 0.2172, Validation Loss: 0.1440
	--> Epoch [20/100], Loss: 0.1594, Validation Loss: 0.1510
	--> Epoch [21/100], Loss: 0.2574, Validation Loss: 0.1412
	--> Epoch [22/100], Loss: 0.3001, Validation Loss: 0.1382
	--> Epoch [23/100], Loss: 0.1479, Validation Loss: 0.1402
	--> Epoch [24/100], Loss: 0.0968, Validation Loss: 0.1408
	--> Epoch [25/100], Loss: 0.0954, Validation Loss: 0.1443
Early stopping
	--> Training for Fold 2 took 0.1467287540435791 sec, using 25 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5282, Validation Loss: 0.5897
	--> Epoch [2/100], Loss: 0.4688, Validation Loss: 0.5382
	--> Epoch [3/100], Loss: 0.3429, Validation Loss: 0.4991
	--> Epoch [4/100], Loss: 0.2595, Validation Loss: 0.4672
	--> Epoch [5/100], Loss: 0.2781, Validation Loss: 0.4613
	--> Epoch [6/100], Loss: 0.1654, Validation Loss: 0.4486
	--> Epoch [7/100], Loss: 0.1393, Validation Loss: 0.4222
	--> Epoch [8/100], Loss: 0.0700, Validation Loss: 0.4092
	--> Epoch [9/100], Loss: 0.0828, Validation Loss: 0.3886
	--> Epoch [10/100], Loss: 0.1271, Validation Loss: 0.3895
	--> Epoch [11/100], Loss: 0.1665, Validation Loss: 0.3894
	--> Epoch [12/100], Loss: 0.0737, Validation Loss: 0.3733
	--> Epoch [13/100], Loss: 0.0931, Validation Loss: 0.4238
	--> Epoch [14/100], Loss: 0.1563, Validation Loss: 0.4005
	--> Epoch [15/100], Loss: 0.1432, Validation Loss: 0.3751
Early stopping
	--> Training for Fold 3 took 0.12620830535888672 sec, using 15 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6756, Validation Loss: 0.5803
	--> Epoch [2/100], Loss: 0.4505, Validation Loss: 0.4915
	--> Epoch [3/100], Loss: 0.3465, Validation Loss: 0.4384
	--> Epoch [4/100], Loss: 0.3526, Validation Loss: 0.3966
	--> Epoch [5/100], Loss: 0.0973, Validation Loss: 0.3720
	--> Epoch [6/100], Loss: 0.0712, Validation Loss: 0.3368
	--> Epoch [7/100], Loss: 0.0849, Validation Loss: 0.3294
	--> Epoch [8/100], Loss: 0.2046, Validation Loss: 0.3026
	--> Epoch [9/100], Loss: 0.1672, Validation Loss: 0.3132
	--> Epoch [10/100], Loss: 0.0631, Validation Loss: 0.3485
	--> Epoch [11/100], Loss: 0.1565, Validation Loss: 0.3139
Early stopping
	--> Training for Fold 4 took 0.0711050033569336 sec, using 11 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6152, Validation Loss: 0.5694
	--> Epoch [2/100], Loss: 0.4813, Validation Loss: 0.5534
	--> Epoch [3/100], Loss: 0.3503, Validation Loss: 0.5840
	--> Epoch [4/100], Loss: 0.2022, Validation Loss: 0.5807
	--> Epoch [5/100], Loss: 0.1072, Validation Loss: 0.5905
Early stopping
	--> Training for Fold 5 took 0.04916977882385254 sec, using 5 epochs

Median number of epochs used: 12 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/12], Loss: 0.6592
	--> Final training Epoch [2/12], Loss: 0.5313
	--> Final training Epoch [3/12], Loss: 0.4423
	--> Final training Epoch [4/12], Loss: 0.3113
	--> Final training Epoch [5/12], Loss: 0.3666
	--> Final training Epoch [6/12], Loss: 0.2139
	--> Final training Epoch [7/12], Loss: 0.1995
	--> Final training Epoch [8/12], Loss: 0.2141
	--> Final training Epoch [9/12], Loss: 0.1381
	--> Final training Epoch [10/12], Loss: 0.2003
	--> Final training Epoch [11/12], Loss: 0.2306
	--> Final training Epoch [12/12], Loss: 0.1383

Final training took 0.08343124389648438 sec

TESTING
	--> Testing took 0.0073 sec
	--> Final Accuracy: 0.7391
	--> Final Loss: 0.8317
	--> Final Precision: 0.7692
	--> Final Recall: 0.7692
	--> Final F1 Score: 0.7692
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3255,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3671,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.4099,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8269, Validation Loss: 0.4357,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8170, Validation Loss: 0.4002,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3255

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.5566, Validation Loss: 0.5020
	--> Epoch [2/100], Loss: 0.3350, Validation Loss: 0.4294
	--> Epoch [3/100], Loss: 0.2119, Validation Loss: 0.3981
	--> Epoch [4/100], Loss: 0.1329, Validation Loss: 0.3355
	--> Epoch [5/100], Loss: 0.0777, Validation Loss: 0.2977
	--> Epoch [6/100], Loss: 0.1070, Validation Loss: 0.2907
	--> Epoch [7/100], Loss: 0.1517, Validation Loss: 0.2698
	--> Epoch [8/100], Loss: 0.0236, Validation Loss: 0.2441
	--> Epoch [9/100], Loss: 0.0675, Validation Loss: 0.2395
	--> Epoch [10/100], Loss: 0.0873, Validation Loss: 0.2349
	--> Epoch [11/100], Loss: 0.0546, Validation Loss: 0.2215
	--> Epoch [12/100], Loss: 0.0570, Validation Loss: 0.2288
	--> Epoch [13/100], Loss: 0.0609, Validation Loss: 0.2366
	--> Epoch [14/100], Loss: 0.0101, Validation Loss: 0.2383
Early stopping
	--> Training for Fold 1 took 0.07781481742858887 sec, using 14 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6419, Validation Loss: 0.5012
	--> Epoch [2/100], Loss: 0.4919, Validation Loss: 0.3945
	--> Epoch [3/100], Loss: 0.3098, Validation Loss: 0.3372
	--> Epoch [4/100], Loss: 0.2616, Validation Loss: 0.3053
	--> Epoch [5/100], Loss: 0.1385, Validation Loss: 0.2869
	--> Epoch [6/100], Loss: 0.2097, Validation Loss: 0.2731
	--> Epoch [7/100], Loss: 0.1839, Validation Loss: 0.2466
	--> Epoch [8/100], Loss: 0.3235, Validation Loss: 0.2297
	--> Epoch [9/100], Loss: 0.1159, Validation Loss: 0.2267
	--> Epoch [10/100], Loss: 0.2335, Validation Loss: 0.2229
	--> Epoch [11/100], Loss: 0.0882, Validation Loss: 0.2165
	--> Epoch [12/100], Loss: 0.0851, Validation Loss: 0.2096
	--> Epoch [13/100], Loss: 0.1531, Validation Loss: 0.2057
	--> Epoch [14/100], Loss: 0.0792, Validation Loss: 0.1985
	--> Epoch [15/100], Loss: 0.1414, Validation Loss: 0.1975
	--> Epoch [16/100], Loss: 0.2739, Validation Loss: 0.2002
	--> Epoch [17/100], Loss: 0.1688, Validation Loss: 0.2026
	--> Epoch [18/100], Loss: 0.0659, Validation Loss: 0.1900
	--> Epoch [19/100], Loss: 0.0932, Validation Loss: 0.1839
	--> Epoch [20/100], Loss: 0.0747, Validation Loss: 0.1713
	--> Epoch [21/100], Loss: 0.1355, Validation Loss: 0.1717
	--> Epoch [22/100], Loss: 0.1263, Validation Loss: 0.1656
	--> Epoch [23/100], Loss: 0.0636, Validation Loss: 0.1651
	--> Epoch [24/100], Loss: 0.1237, Validation Loss: 0.1618
	--> Epoch [25/100], Loss: 0.1786, Validation Loss: 0.1598
	--> Epoch [26/100], Loss: 0.1765, Validation Loss: 0.1584
	--> Epoch [27/100], Loss: 0.0637, Validation Loss: 0.1558
	--> Epoch [28/100], Loss: 0.0637, Validation Loss: 0.1554
	--> Epoch [29/100], Loss: 0.0560, Validation Loss: 0.1511
	--> Epoch [30/100], Loss: 0.1107, Validation Loss: 0.1521
	--> Epoch [31/100], Loss: 0.0673, Validation Loss: 0.1489
	--> Epoch [32/100], Loss: 0.0545, Validation Loss: 0.1454
	--> Epoch [33/100], Loss: 0.0551, Validation Loss: 0.1495
	--> Epoch [34/100], Loss: 0.0550, Validation Loss: 0.1502
	--> Epoch [35/100], Loss: 0.0527, Validation Loss: 0.1460
Early stopping
	--> Training for Fold 2 took 0.24668359756469727 sec, using 35 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6344, Validation Loss: 0.5775
	--> Epoch [2/100], Loss: 0.4609, Validation Loss: 0.5376
	--> Epoch [3/100], Loss: 0.2507, Validation Loss: 0.5147
	--> Epoch [4/100], Loss: 0.1876, Validation Loss: 0.4800
	--> Epoch [5/100], Loss: 0.1549, Validation Loss: 0.4643
	--> Epoch [6/100], Loss: 0.2266, Validation Loss: 0.4508
	--> Epoch [7/100], Loss: 0.0927, Validation Loss: 0.4333
	--> Epoch [8/100], Loss: 0.0819, Validation Loss: 0.4153
	--> Epoch [9/100], Loss: 0.1369, Validation Loss: 0.4335
	--> Epoch [10/100], Loss: 0.1096, Validation Loss: 0.4201
	--> Epoch [11/100], Loss: 0.1722, Validation Loss: 0.4178
Early stopping
	--> Training for Fold 3 took 0.07248377799987793 sec, using 11 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.5268, Validation Loss: 0.6219
	--> Epoch [2/100], Loss: 0.2584, Validation Loss: 0.5152
	--> Epoch [3/100], Loss: 0.2579, Validation Loss: 0.5334
	--> Epoch [4/100], Loss: 0.0635, Validation Loss: 0.4436
	--> Epoch [5/100], Loss: 0.1107, Validation Loss: 0.3938
	--> Epoch [6/100], Loss: 0.0645, Validation Loss: 0.4143
	--> Epoch [7/100], Loss: 0.0826, Validation Loss: 0.3761
	--> Epoch [8/100], Loss: 0.1437, Validation Loss: 0.3702
	--> Epoch [9/100], Loss: 0.0552, Validation Loss: 0.3701
	--> Epoch [10/100], Loss: 0.0036, Validation Loss: 0.3650
	--> Epoch [11/100], Loss: 0.0130, Validation Loss: 0.3694
	--> Epoch [12/100], Loss: 0.1270, Validation Loss: 0.3452
	--> Epoch [13/100], Loss: 0.0083, Validation Loss: 0.3085
	--> Epoch [14/100], Loss: 0.0067, Validation Loss: 0.3083
	--> Epoch [15/100], Loss: 0.0594, Validation Loss: 0.3041
	--> Epoch [16/100], Loss: 0.0209, Validation Loss: 0.3017
	--> Epoch [17/100], Loss: 0.0026, Validation Loss: 0.3060
	--> Epoch [18/100], Loss: 0.1424, Validation Loss: 0.3854
	--> Epoch [19/100], Loss: 0.1328, Validation Loss: 0.3753
Early stopping
	--> Training for Fold 4 took 0.17087841033935547 sec, using 19 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6492, Validation Loss: 0.6160
	--> Epoch [2/100], Loss: 0.4638, Validation Loss: 0.6132
	--> Epoch [3/100], Loss: 0.3298, Validation Loss: 0.5816
	--> Epoch [4/100], Loss: 0.2198, Validation Loss: 0.5746
	--> Epoch [5/100], Loss: 0.2122, Validation Loss: 0.5502
	--> Epoch [6/100], Loss: 0.0701, Validation Loss: 0.5393
	--> Epoch [7/100], Loss: 0.1098, Validation Loss: 0.5719
	--> Epoch [8/100], Loss: 0.0443, Validation Loss: 0.5625
	--> Epoch [9/100], Loss: 0.0729, Validation Loss: 0.5466
Early stopping
	--> Training for Fold 5 took 0.07052350044250488 sec, using 9 epochs

Median number of epochs used: 14 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/14], Loss: 0.7403
	--> Final training Epoch [2/14], Loss: 0.5840
	--> Final training Epoch [3/14], Loss: 0.4086
	--> Final training Epoch [4/14], Loss: 0.2910
	--> Final training Epoch [5/14], Loss: 0.2220
	--> Final training Epoch [6/14], Loss: 0.2095
	--> Final training Epoch [7/14], Loss: 0.2057
	--> Final training Epoch [8/14], Loss: 0.2220
	--> Final training Epoch [9/14], Loss: 0.1305
	--> Final training Epoch [10/14], Loss: 0.1701
	--> Final training Epoch [11/14], Loss: 0.1270
	--> Final training Epoch [12/14], Loss: 0.1359
	--> Final training Epoch [13/14], Loss: 0.1465
	--> Final training Epoch [14/14], Loss: 0.1355

Final training took 0.11551952362060547 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.7826
	--> Final Loss: 0.8847
	--> Final Precision: 0.7500
	--> Final Recall: 0.9231
	--> Final F1 Score: 0.8276
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8912, Validation Loss: 0.3367,  Current Best Accuracy: 0.8912,  Current Best Validation Loss: 0.3367

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.4693, Validation Loss: 0.4510
	--> Epoch [2/100], Loss: 0.2841, Validation Loss: 0.3886
	--> Epoch [3/100], Loss: 0.2365, Validation Loss: 0.3208
	--> Epoch [4/100], Loss: 0.1087, Validation Loss: 0.2775
	--> Epoch [5/100], Loss: 0.2490, Validation Loss: 0.3010
	--> Epoch [6/100], Loss: 0.0992, Validation Loss: 0.2540
	--> Epoch [7/100], Loss: 0.0859, Validation Loss: 0.2274
	--> Epoch [8/100], Loss: 0.0821, Validation Loss: 0.2178
	--> Epoch [9/100], Loss: 0.0702, Validation Loss: 0.2045
	--> Epoch [10/100], Loss: 0.0698, Validation Loss: 0.2016
	--> Epoch [11/100], Loss: 0.1023, Validation Loss: 0.1844
	--> Epoch [12/100], Loss: 0.0692, Validation Loss: 0.1801
	--> Epoch [13/100], Loss: 0.0742, Validation Loss: 0.1811
	--> Epoch [14/100], Loss: 0.0653, Validation Loss: 0.1784
	--> Epoch [15/100], Loss: 0.0705, Validation Loss: 0.1804
	--> Epoch [16/100], Loss: 0.0651, Validation Loss: 0.1821
	--> Epoch [17/100], Loss: 0.0691, Validation Loss: 0.1884
Early stopping
	--> Training for Fold 1 took 0.09399843215942383 sec, using 17 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7265, Validation Loss: 0.5489
	--> Epoch [2/100], Loss: 0.4987, Validation Loss: 0.4990
	--> Epoch [3/100], Loss: 0.3438, Validation Loss: 0.4603
	--> Epoch [4/100], Loss: 0.2836, Validation Loss: 0.4159
	--> Epoch [5/100], Loss: 0.3072, Validation Loss: 0.3991
	--> Epoch [6/100], Loss: 0.2415, Validation Loss: 0.3492
	--> Epoch [7/100], Loss: 0.2410, Validation Loss: 0.3609
	--> Epoch [8/100], Loss: 0.2718, Validation Loss: 0.3211
	--> Epoch [9/100], Loss: 0.2019, Validation Loss: 0.3277
	--> Epoch [10/100], Loss: 0.2672, Validation Loss: 0.3175
	--> Epoch [11/100], Loss: 0.2678, Validation Loss: 0.3112
	--> Epoch [12/100], Loss: 0.1992, Validation Loss: 0.3105
	--> Epoch [13/100], Loss: 0.2632, Validation Loss: 0.3072
	--> Epoch [14/100], Loss: 0.3556, Validation Loss: 0.3061
	--> Epoch [15/100], Loss: 0.1828, Validation Loss: 0.3085
	--> Epoch [16/100], Loss: 0.1367, Validation Loss: 0.2838
	--> Epoch [17/100], Loss: 0.0869, Validation Loss: 0.2768
	--> Epoch [18/100], Loss: 0.1206, Validation Loss: 0.2742
	--> Epoch [19/100], Loss: 0.0592, Validation Loss: 0.2701
	--> Epoch [20/100], Loss: 0.3414, Validation Loss: 0.2770
	--> Epoch [21/100], Loss: 0.1664, Validation Loss: 0.2681
	--> Epoch [22/100], Loss: 0.1609, Validation Loss: 0.2666
	--> Epoch [23/100], Loss: 0.1069, Validation Loss: 0.2556
	--> Epoch [24/100], Loss: 0.0536, Validation Loss: 0.2956
	--> Epoch [25/100], Loss: 0.1038, Validation Loss: 0.2872
	--> Epoch [26/100], Loss: 0.1026, Validation Loss: 0.2842
Early stopping
	--> Training for Fold 2 took 0.17276382446289062 sec, using 26 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5437, Validation Loss: 0.5988
	--> Epoch [2/100], Loss: 0.5000, Validation Loss: 0.5365
	--> Epoch [3/100], Loss: 0.1840, Validation Loss: 0.4842
	--> Epoch [4/100], Loss: 0.1330, Validation Loss: 0.4670
	--> Epoch [5/100], Loss: 0.1465, Validation Loss: 0.4617
	--> Epoch [6/100], Loss: 0.1061, Validation Loss: 0.4339
	--> Epoch [7/100], Loss: 0.1540, Validation Loss: 0.4153
	--> Epoch [8/100], Loss: 0.0885, Validation Loss: 0.4072
	--> Epoch [9/100], Loss: 0.0843, Validation Loss: 0.4005
	--> Epoch [10/100], Loss: 0.0350, Validation Loss: 0.4100
	--> Epoch [11/100], Loss: 0.2391, Validation Loss: 0.4181
	--> Epoch [12/100], Loss: 0.0111, Validation Loss: 0.4098
Early stopping
	--> Training for Fold 3 took 0.08967328071594238 sec, using 12 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6374, Validation Loss: 0.5166
	--> Epoch [2/100], Loss: 0.3408, Validation Loss: 0.4814
	--> Epoch [3/100], Loss: 0.2313, Validation Loss: 0.4266
	--> Epoch [4/100], Loss: 0.1554, Validation Loss: 0.4019
	--> Epoch [5/100], Loss: 0.0689, Validation Loss: 0.3898
	--> Epoch [6/100], Loss: 0.0337, Validation Loss: 0.3643
	--> Epoch [7/100], Loss: 0.0442, Validation Loss: 0.3505
	--> Epoch [8/100], Loss: 0.0971, Validation Loss: 0.3387
	--> Epoch [9/100], Loss: 0.0294, Validation Loss: 0.3328
	--> Epoch [10/100], Loss: 0.0846, Validation Loss: 0.3777
	--> Epoch [11/100], Loss: 0.0070, Validation Loss: 0.3655
	--> Epoch [12/100], Loss: 0.0297, Validation Loss: 0.3488
Early stopping
	--> Training for Fold 4 took 0.08003520965576172 sec, using 12 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6022, Validation Loss: 0.5658
	--> Epoch [2/100], Loss: 0.3682, Validation Loss: 0.5635
	--> Epoch [3/100], Loss: 0.2595, Validation Loss: 0.5462
	--> Epoch [4/100], Loss: 0.2628, Validation Loss: 0.5697
	--> Epoch [5/100], Loss: 0.0808, Validation Loss: 0.6039
	--> Epoch [6/100], Loss: 0.1094, Validation Loss: 0.5999
Early stopping
	--> Training for Fold 5 took 0.055214881896972656 sec, using 6 epochs

Median number of epochs used: 12 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/12], Loss: 0.6673
	--> Final training Epoch [2/12], Loss: 0.4284
	--> Final training Epoch [3/12], Loss: 0.3929
	--> Final training Epoch [4/12], Loss: 0.3361
	--> Final training Epoch [5/12], Loss: 0.2432
	--> Final training Epoch [6/12], Loss: 0.1975
	--> Final training Epoch [7/12], Loss: 0.1614
	--> Final training Epoch [8/12], Loss: 0.0940
	--> Final training Epoch [9/12], Loss: 0.0461
	--> Final training Epoch [10/12], Loss: 0.0638
	--> Final training Epoch [11/12], Loss: 0.1104
	--> Final training Epoch [12/12], Loss: 0.0346

Final training took 0.0797884464263916 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.9555
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3142,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3475,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3556,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 0.3907,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7947, Validation Loss: 0.3591,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3651,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8474, Validation Loss: 0.3594,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3619,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3677,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3518,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3812,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3591,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8152, Validation Loss: 0.3916,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8374, Validation Loss: 0.3496,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8047, Validation Loss: 0.4110,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8041, Validation Loss: 0.4971,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 64, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.7830, Validation Loss: 0.4276,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3142

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7302, Validation Loss: 0.6201
	--> Epoch [2/100], Loss: 0.6242, Validation Loss: 0.5388
	--> Epoch [3/100], Loss: 0.5085, Validation Loss: 0.4609
	--> Epoch [4/100], Loss: 0.4033, Validation Loss: 0.4144
	--> Epoch [5/100], Loss: 0.3632, Validation Loss: 0.3721
	--> Epoch [6/100], Loss: 0.3053, Validation Loss: 0.3433
	--> Epoch [7/100], Loss: 0.2625, Validation Loss: 0.3176
	--> Epoch [8/100], Loss: 0.2184, Validation Loss: 0.3044
	--> Epoch [9/100], Loss: 0.1729, Validation Loss: 0.2914
	--> Epoch [10/100], Loss: 0.1511, Validation Loss: 0.2892
	--> Epoch [11/100], Loss: 0.1307, Validation Loss: 0.2836
	--> Epoch [12/100], Loss: 0.1162, Validation Loss: 0.2810
	--> Epoch [13/100], Loss: 0.1150, Validation Loss: 0.2748
	--> Epoch [14/100], Loss: 0.1072, Validation Loss: 0.2717
	--> Epoch [15/100], Loss: 0.0800, Validation Loss: 0.2696
	--> Epoch [16/100], Loss: 0.0694, Validation Loss: 0.2646
	--> Epoch [17/100], Loss: 0.0916, Validation Loss: 0.2585
	--> Epoch [18/100], Loss: 0.0941, Validation Loss: 0.2591
	--> Epoch [19/100], Loss: 0.0696, Validation Loss: 0.2503
	--> Epoch [20/100], Loss: 0.0641, Validation Loss: 0.2471
	--> Epoch [21/100], Loss: 0.0541, Validation Loss: 0.2476
	--> Epoch [22/100], Loss: 0.0709, Validation Loss: 0.2454
	--> Epoch [23/100], Loss: 0.0416, Validation Loss: 0.2662
	--> Epoch [24/100], Loss: 0.0481, Validation Loss: 0.2689
	--> Epoch [25/100], Loss: 0.0578, Validation Loss: 0.2652
Early stopping
	--> Training for Fold 1 took 0.1079702377319336 sec, using 25 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7618, Validation Loss: 0.5026
	--> Epoch [2/100], Loss: 0.5524, Validation Loss: 0.4232
	--> Epoch [3/100], Loss: 0.4604, Validation Loss: 0.3676
	--> Epoch [4/100], Loss: 0.3591, Validation Loss: 0.3295
	--> Epoch [5/100], Loss: 0.2846, Validation Loss: 0.3116
	--> Epoch [6/100], Loss: 0.2548, Validation Loss: 0.2863
	--> Epoch [7/100], Loss: 0.2145, Validation Loss: 0.2739
	--> Epoch [8/100], Loss: 0.1753, Validation Loss: 0.2604
	--> Epoch [9/100], Loss: 0.1828, Validation Loss: 0.2627
	--> Epoch [10/100], Loss: 0.1265, Validation Loss: 0.2519
	--> Epoch [11/100], Loss: 0.1137, Validation Loss: 0.2403
	--> Epoch [12/100], Loss: 0.0922, Validation Loss: 0.2230
	--> Epoch [13/100], Loss: 0.1345, Validation Loss: 0.2115
	--> Epoch [14/100], Loss: 0.1116, Validation Loss: 0.2090
	--> Epoch [15/100], Loss: 0.0974, Validation Loss: 0.2026
	--> Epoch [16/100], Loss: 0.0886, Validation Loss: 0.2106
	--> Epoch [17/100], Loss: 0.0856, Validation Loss: 0.2021
	--> Epoch [18/100], Loss: 0.0771, Validation Loss: 0.1987
	--> Epoch [19/100], Loss: 0.1104, Validation Loss: 0.2053
	--> Epoch [20/100], Loss: 0.1284, Validation Loss: 0.2035
	--> Epoch [21/100], Loss: 0.0691, Validation Loss: 0.2005
Early stopping
	--> Training for Fold 2 took 0.10688567161560059 sec, using 21 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7337, Validation Loss: 0.6352
	--> Epoch [2/100], Loss: 0.5436, Validation Loss: 0.5354
	--> Epoch [3/100], Loss: 0.4435, Validation Loss: 0.4649
	--> Epoch [4/100], Loss: 0.3599, Validation Loss: 0.4219
	--> Epoch [5/100], Loss: 0.2792, Validation Loss: 0.3908
	--> Epoch [6/100], Loss: 0.2530, Validation Loss: 0.3603
	--> Epoch [7/100], Loss: 0.2203, Validation Loss: 0.3467
	--> Epoch [8/100], Loss: 0.1712, Validation Loss: 0.3283
	--> Epoch [9/100], Loss: 0.1607, Validation Loss: 0.3233
	--> Epoch [10/100], Loss: 0.1588, Validation Loss: 0.3188
	--> Epoch [11/100], Loss: 0.1642, Validation Loss: 0.3054
	--> Epoch [12/100], Loss: 0.0863, Validation Loss: 0.2968
	--> Epoch [13/100], Loss: 0.1263, Validation Loss: 0.2897
	--> Epoch [14/100], Loss: 0.0987, Validation Loss: 0.2926
	--> Epoch [15/100], Loss: 0.0830, Validation Loss: 0.2973
	--> Epoch [16/100], Loss: 0.0655, Validation Loss: 0.3008
Early stopping
	--> Training for Fold 3 took 0.06491398811340332 sec, using 16 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7157, Validation Loss: 0.6339
	--> Epoch [2/100], Loss: 0.6340, Validation Loss: 0.5812
	--> Epoch [3/100], Loss: 0.5731, Validation Loss: 0.5176
	--> Epoch [4/100], Loss: 0.4759, Validation Loss: 0.4578
	--> Epoch [5/100], Loss: 0.4060, Validation Loss: 0.3956
	--> Epoch [6/100], Loss: 0.3264, Validation Loss: 0.3679
	--> Epoch [7/100], Loss: 0.2450, Validation Loss: 0.3406
	--> Epoch [8/100], Loss: 0.2103, Validation Loss: 0.3087
	--> Epoch [9/100], Loss: 0.1655, Validation Loss: 0.2907
	--> Epoch [10/100], Loss: 0.1375, Validation Loss: 0.2858
	--> Epoch [11/100], Loss: 0.1411, Validation Loss: 0.2774
	--> Epoch [12/100], Loss: 0.1033, Validation Loss: 0.2660
	--> Epoch [13/100], Loss: 0.0921, Validation Loss: 0.2690
	--> Epoch [14/100], Loss: 0.0996, Validation Loss: 0.2645
	--> Epoch [15/100], Loss: 0.1033, Validation Loss: 0.2637
	--> Epoch [16/100], Loss: 0.0895, Validation Loss: 0.2744
	--> Epoch [17/100], Loss: 0.0746, Validation Loss: 0.2829
	--> Epoch [18/100], Loss: 0.0972, Validation Loss: 0.2848
Early stopping
	--> Training for Fold 4 took 0.06699800491333008 sec, using 18 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7423, Validation Loss: 0.6798
	--> Epoch [2/100], Loss: 0.5169, Validation Loss: 0.6336
	--> Epoch [3/100], Loss: 0.4437, Validation Loss: 0.6078
	--> Epoch [4/100], Loss: 0.3323, Validation Loss: 0.5990
	--> Epoch [5/100], Loss: 0.2703, Validation Loss: 0.5796
	--> Epoch [6/100], Loss: 0.2125, Validation Loss: 0.5741
	--> Epoch [7/100], Loss: 0.1876, Validation Loss: 0.5685
	--> Epoch [8/100], Loss: 0.1932, Validation Loss: 0.5762
	--> Epoch [9/100], Loss: 0.1496, Validation Loss: 0.5445
	--> Epoch [10/100], Loss: 0.1549, Validation Loss: 0.5539
	--> Epoch [11/100], Loss: 0.1113, Validation Loss: 0.5307
	--> Epoch [12/100], Loss: 0.1315, Validation Loss: 0.5355
	--> Epoch [13/100], Loss: 0.0849, Validation Loss: 0.5457
	--> Epoch [14/100], Loss: 0.0863, Validation Loss: 0.5350
Early stopping
	--> Training for Fold 5 took 0.049567461013793945 sec, using 14 epochs

Median number of epochs used: 18 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/18], Loss: 0.7187
	--> Final training Epoch [2/18], Loss: 0.5214
	--> Final training Epoch [3/18], Loss: 0.4199
	--> Final training Epoch [4/18], Loss: 0.3424
	--> Final training Epoch [5/18], Loss: 0.2657
	--> Final training Epoch [6/18], Loss: 0.2270
	--> Final training Epoch [7/18], Loss: 0.1919
	--> Final training Epoch [8/18], Loss: 0.1597
	--> Final training Epoch [9/18], Loss: 0.1378
	--> Final training Epoch [10/18], Loss: 0.1103
	--> Final training Epoch [11/18], Loss: 0.1011
	--> Final training Epoch [12/18], Loss: 0.1000
	--> Final training Epoch [13/18], Loss: 0.1098
	--> Final training Epoch [14/18], Loss: 0.0958
	--> Final training Epoch [15/18], Loss: 0.0710
	--> Final training Epoch [16/18], Loss: 0.0612
	--> Final training Epoch [17/18], Loss: 0.0525
	--> Final training Epoch [18/18], Loss: 0.0444

Final training took 0.06632447242736816 sec

TESTING
	--> Testing took 0.0083 sec
	--> Final Accuracy: 0.6957
	--> Final Loss: 0.9620
	--> Final Precision: 0.7500
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.7200
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8924, Validation Loss: 0.3194,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3194
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3411,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3194

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6716, Validation Loss: 0.5531
	--> Epoch [2/100], Loss: 0.5665, Validation Loss: 0.5011
	--> Epoch [3/100], Loss: 0.5000, Validation Loss: 0.4312
	--> Epoch [4/100], Loss: 0.4207, Validation Loss: 0.3921
	--> Epoch [5/100], Loss: 0.3520, Validation Loss: 0.3551
	--> Epoch [6/100], Loss: 0.2920, Validation Loss: 0.3333
	--> Epoch [7/100], Loss: 0.2622, Validation Loss: 0.3075
	--> Epoch [8/100], Loss: 0.2433, Validation Loss: 0.3026
	--> Epoch [9/100], Loss: 0.1857, Validation Loss: 0.2935
	--> Epoch [10/100], Loss: 0.1713, Validation Loss: 0.2874
	--> Epoch [11/100], Loss: 0.1342, Validation Loss: 0.2913
	--> Epoch [12/100], Loss: 0.1023, Validation Loss: 0.2941
	--> Epoch [13/100], Loss: 0.1181, Validation Loss: 0.2875
Early stopping
	--> Training for Fold 1 took 0.047756195068359375 sec, using 13 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6859, Validation Loss: 0.5180
	--> Epoch [2/100], Loss: 0.5428, Validation Loss: 0.4692
	--> Epoch [3/100], Loss: 0.4589, Validation Loss: 0.4091
	--> Epoch [4/100], Loss: 0.3785, Validation Loss: 0.3911
	--> Epoch [5/100], Loss: 0.2757, Validation Loss: 0.3576
	--> Epoch [6/100], Loss: 0.2334, Validation Loss: 0.3345
	--> Epoch [7/100], Loss: 0.1998, Validation Loss: 0.3188
	--> Epoch [8/100], Loss: 0.1810, Validation Loss: 0.3110
	--> Epoch [9/100], Loss: 0.1731, Validation Loss: 0.3034
	--> Epoch [10/100], Loss: 0.1570, Validation Loss: 0.2673
	--> Epoch [11/100], Loss: 0.1368, Validation Loss: 0.2649
	--> Epoch [12/100], Loss: 0.1146, Validation Loss: 0.2610
	--> Epoch [13/100], Loss: 0.1102, Validation Loss: 0.2580
	--> Epoch [14/100], Loss: 0.1008, Validation Loss: 0.2470
	--> Epoch [15/100], Loss: 0.0835, Validation Loss: 0.2431
	--> Epoch [16/100], Loss: 0.1312, Validation Loss: 0.2555
	--> Epoch [17/100], Loss: 0.1202, Validation Loss: 0.2494
	--> Epoch [18/100], Loss: 0.0863, Validation Loss: 0.2448
Early stopping
	--> Training for Fold 2 took 0.06619048118591309 sec, using 18 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7445, Validation Loss: 0.6875
	--> Epoch [2/100], Loss: 0.5971, Validation Loss: 0.6288
	--> Epoch [3/100], Loss: 0.5047, Validation Loss: 0.5769
	--> Epoch [4/100], Loss: 0.4344, Validation Loss: 0.5234
	--> Epoch [5/100], Loss: 0.3531, Validation Loss: 0.4877
	--> Epoch [6/100], Loss: 0.3035, Validation Loss: 0.4567
	--> Epoch [7/100], Loss: 0.2102, Validation Loss: 0.4299
	--> Epoch [8/100], Loss: 0.2200, Validation Loss: 0.4181
	--> Epoch [9/100], Loss: 0.1921, Validation Loss: 0.3981
	--> Epoch [10/100], Loss: 0.1550, Validation Loss: 0.3885
	--> Epoch [11/100], Loss: 0.1040, Validation Loss: 0.3828
	--> Epoch [12/100], Loss: 0.1410, Validation Loss: 0.3719
	--> Epoch [13/100], Loss: 0.0904, Validation Loss: 0.3591
	--> Epoch [14/100], Loss: 0.1060, Validation Loss: 0.3583
	--> Epoch [15/100], Loss: 0.0877, Validation Loss: 0.3552
	--> Epoch [16/100], Loss: 0.0942, Validation Loss: 0.3502
	--> Epoch [17/100], Loss: 0.0760, Validation Loss: 0.3501
	--> Epoch [18/100], Loss: 0.0740, Validation Loss: 0.3623
	--> Epoch [19/100], Loss: 0.0796, Validation Loss: 0.3558
	--> Epoch [20/100], Loss: 0.1056, Validation Loss: 0.3560
Early stopping
	--> Training for Fold 3 took 0.07459115982055664 sec, using 20 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7133, Validation Loss: 0.5243
	--> Epoch [2/100], Loss: 0.5523, Validation Loss: 0.4647
	--> Epoch [3/100], Loss: 0.4310, Validation Loss: 0.4195
	--> Epoch [4/100], Loss: 0.3623, Validation Loss: 0.3972
	--> Epoch [5/100], Loss: 0.3065, Validation Loss: 0.3735
	--> Epoch [6/100], Loss: 0.2224, Validation Loss: 0.3501
	--> Epoch [7/100], Loss: 0.2174, Validation Loss: 0.3478
	--> Epoch [8/100], Loss: 0.2069, Validation Loss: 0.3287
	--> Epoch [9/100], Loss: 0.1706, Validation Loss: 0.3232
	--> Epoch [10/100], Loss: 0.1603, Validation Loss: 0.3162
	--> Epoch [11/100], Loss: 0.1173, Validation Loss: 0.3118
	--> Epoch [12/100], Loss: 0.1260, Validation Loss: 0.2954
	--> Epoch [13/100], Loss: 0.1311, Validation Loss: 0.3058
	--> Epoch [14/100], Loss: 0.0700, Validation Loss: 0.3093
	--> Epoch [15/100], Loss: 0.1066, Validation Loss: 0.3065
Early stopping
	--> Training for Fold 4 took 0.05877947807312012 sec, using 15 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7768, Validation Loss: 0.6072
	--> Epoch [2/100], Loss: 0.5606, Validation Loss: 0.5750
	--> Epoch [3/100], Loss: 0.4548, Validation Loss: 0.5444
	--> Epoch [4/100], Loss: 0.3722, Validation Loss: 0.5238
	--> Epoch [5/100], Loss: 0.2978, Validation Loss: 0.5194
	--> Epoch [6/100], Loss: 0.2765, Validation Loss: 0.5038
	--> Epoch [7/100], Loss: 0.2312, Validation Loss: 0.5042
	--> Epoch [8/100], Loss: 0.2050, Validation Loss: 0.4999
	--> Epoch [9/100], Loss: 0.1602, Validation Loss: 0.5089
	--> Epoch [10/100], Loss: 0.1646, Validation Loss: 0.5001
	--> Epoch [11/100], Loss: 0.1410, Validation Loss: 0.5090
Early stopping
	--> Training for Fold 5 took 0.04276442527770996 sec, using 11 epochs

Median number of epochs used: 15 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/15], Loss: 0.7574
	--> Final training Epoch [2/15], Loss: 0.5491
	--> Final training Epoch [3/15], Loss: 0.4671
	--> Final training Epoch [4/15], Loss: 0.3870
	--> Final training Epoch [5/15], Loss: 0.3125
	--> Final training Epoch [6/15], Loss: 0.2802
	--> Final training Epoch [7/15], Loss: 0.2250
	--> Final training Epoch [8/15], Loss: 0.1806
	--> Final training Epoch [9/15], Loss: 0.1741
	--> Final training Epoch [10/15], Loss: 0.1189
	--> Final training Epoch [11/15], Loss: 0.1187
	--> Final training Epoch [12/15], Loss: 0.1296
	--> Final training Epoch [13/15], Loss: 0.0949
	--> Final training Epoch [14/15], Loss: 0.0963
	--> Final training Epoch [15/15], Loss: 0.1038

Final training took 0.05049467086791992 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.9208
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8813, Validation Loss: 0.3175,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3546,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.3350,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8380, Validation Loss: 0.3791,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 0.3862,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3533,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.3515,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8708, Validation Loss: 0.3314,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8602, Validation Loss: 0.3270,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3175

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7268, Validation Loss: 0.5170
	--> Epoch [2/100], Loss: 0.5384, Validation Loss: 0.4499
	--> Epoch [3/100], Loss: 0.4465, Validation Loss: 0.4137
	--> Epoch [4/100], Loss: 0.3625, Validation Loss: 0.3790
	--> Epoch [5/100], Loss: 0.2769, Validation Loss: 0.3424
	--> Epoch [6/100], Loss: 0.2454, Validation Loss: 0.3101
	--> Epoch [7/100], Loss: 0.1976, Validation Loss: 0.2887
	--> Epoch [8/100], Loss: 0.1986, Validation Loss: 0.2586
	--> Epoch [9/100], Loss: 0.1690, Validation Loss: 0.2617
	--> Epoch [10/100], Loss: 0.1509, Validation Loss: 0.2511
	--> Epoch [11/100], Loss: 0.1150, Validation Loss: 0.2359
	--> Epoch [12/100], Loss: 0.1471, Validation Loss: 0.2317
	--> Epoch [13/100], Loss: 0.1207, Validation Loss: 0.2381
	--> Epoch [14/100], Loss: 0.1512, Validation Loss: 0.2335
	--> Epoch [15/100], Loss: 0.0872, Validation Loss: 0.2441
Early stopping
	--> Training for Fold 1 took 0.0532984733581543 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7792, Validation Loss: 0.6289
	--> Epoch [2/100], Loss: 0.5584, Validation Loss: 0.4756
	--> Epoch [3/100], Loss: 0.4630, Validation Loss: 0.3809
	--> Epoch [4/100], Loss: 0.3560, Validation Loss: 0.3388
	--> Epoch [5/100], Loss: 0.3054, Validation Loss: 0.3102
	--> Epoch [6/100], Loss: 0.2830, Validation Loss: 0.2954
	--> Epoch [7/100], Loss: 0.2055, Validation Loss: 0.2986
	--> Epoch [8/100], Loss: 0.1691, Validation Loss: 0.2706
	--> Epoch [9/100], Loss: 0.1540, Validation Loss: 0.2677
	--> Epoch [10/100], Loss: 0.1501, Validation Loss: 0.2538
	--> Epoch [11/100], Loss: 0.1226, Validation Loss: 0.2471
	--> Epoch [12/100], Loss: 0.0912, Validation Loss: 0.2440
	--> Epoch [13/100], Loss: 0.1060, Validation Loss: 0.2342
	--> Epoch [14/100], Loss: 0.0969, Validation Loss: 0.2148
	--> Epoch [15/100], Loss: 0.0884, Validation Loss: 0.2131
	--> Epoch [16/100], Loss: 0.0587, Validation Loss: 0.2088
	--> Epoch [17/100], Loss: 0.0812, Validation Loss: 0.2106
	--> Epoch [18/100], Loss: 0.0721, Validation Loss: 0.2077
	--> Epoch [19/100], Loss: 0.0463, Validation Loss: 0.2102
	--> Epoch [20/100], Loss: 0.0431, Validation Loss: 0.2049
	--> Epoch [21/100], Loss: 0.0300, Validation Loss: 0.2010
	--> Epoch [22/100], Loss: 0.0476, Validation Loss: 0.1847
	--> Epoch [23/100], Loss: 0.0222, Validation Loss: 0.1845
	--> Epoch [24/100], Loss: 0.0742, Validation Loss: 0.1855
	--> Epoch [25/100], Loss: 0.0718, Validation Loss: 0.1794
	--> Epoch [26/100], Loss: 0.0826, Validation Loss: 0.1810
	--> Epoch [27/100], Loss: 0.0651, Validation Loss: 0.1805
	--> Epoch [28/100], Loss: 0.0415, Validation Loss: 0.1859
Early stopping
	--> Training for Fold 2 took 0.1005859375 sec, using 28 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7340, Validation Loss: 0.6282
	--> Epoch [2/100], Loss: 0.5207, Validation Loss: 0.5456
	--> Epoch [3/100], Loss: 0.3991, Validation Loss: 0.4975
	--> Epoch [4/100], Loss: 0.3446, Validation Loss: 0.4663
	--> Epoch [5/100], Loss: 0.2757, Validation Loss: 0.4303
	--> Epoch [6/100], Loss: 0.2290, Validation Loss: 0.4081
	--> Epoch [7/100], Loss: 0.2180, Validation Loss: 0.4000
	--> Epoch [8/100], Loss: 0.1617, Validation Loss: 0.3934
	--> Epoch [9/100], Loss: 0.1448, Validation Loss: 0.3784
	--> Epoch [10/100], Loss: 0.1463, Validation Loss: 0.3668
	--> Epoch [11/100], Loss: 0.1102, Validation Loss: 0.3654
	--> Epoch [12/100], Loss: 0.1646, Validation Loss: 0.3604
	--> Epoch [13/100], Loss: 0.1140, Validation Loss: 0.3483
	--> Epoch [14/100], Loss: 0.1036, Validation Loss: 0.3430
	--> Epoch [15/100], Loss: 0.1078, Validation Loss: 0.3446
	--> Epoch [16/100], Loss: 0.0934, Validation Loss: 0.3434
	--> Epoch [17/100], Loss: 0.1229, Validation Loss: 0.3403
	--> Epoch [18/100], Loss: 0.0758, Validation Loss: 0.3391
	--> Epoch [19/100], Loss: 0.0526, Validation Loss: 0.3374
	--> Epoch [20/100], Loss: 0.0737, Validation Loss: 0.3420
	--> Epoch [21/100], Loss: 0.0708, Validation Loss: 0.3417
	--> Epoch [22/100], Loss: 0.0705, Validation Loss: 0.3351
	--> Epoch [23/100], Loss: 0.0607, Validation Loss: 0.3214
	--> Epoch [24/100], Loss: 0.0611, Validation Loss: 0.3175
	--> Epoch [25/100], Loss: 0.0736, Validation Loss: 0.3154
	--> Epoch [26/100], Loss: 0.0859, Validation Loss: 0.2999
	--> Epoch [27/100], Loss: 0.0746, Validation Loss: 0.2957
	--> Epoch [28/100], Loss: 0.0594, Validation Loss: 0.2917
	--> Epoch [29/100], Loss: 0.0716, Validation Loss: 0.2798
	--> Epoch [30/100], Loss: 0.0786, Validation Loss: 0.3002
	--> Epoch [31/100], Loss: 0.0386, Validation Loss: 0.2949
	--> Epoch [32/100], Loss: 0.0549, Validation Loss: 0.2964
Early stopping
	--> Training for Fold 3 took 0.11905622482299805 sec, using 32 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7221, Validation Loss: 0.4928
	--> Epoch [2/100], Loss: 0.5570, Validation Loss: 0.3856
	--> Epoch [3/100], Loss: 0.5033, Validation Loss: 0.3490
	--> Epoch [4/100], Loss: 0.3819, Validation Loss: 0.3157
	--> Epoch [5/100], Loss: 0.3444, Validation Loss: 0.2820
	--> Epoch [6/100], Loss: 0.2486, Validation Loss: 0.2537
	--> Epoch [7/100], Loss: 0.2468, Validation Loss: 0.2422
	--> Epoch [8/100], Loss: 0.2259, Validation Loss: 0.2382
	--> Epoch [9/100], Loss: 0.1615, Validation Loss: 0.2303
	--> Epoch [10/100], Loss: 0.1653, Validation Loss: 0.2185
	--> Epoch [11/100], Loss: 0.1507, Validation Loss: 0.2083
	--> Epoch [12/100], Loss: 0.1191, Validation Loss: 0.2079
	--> Epoch [13/100], Loss: 0.1168, Validation Loss: 0.2016
	--> Epoch [14/100], Loss: 0.0901, Validation Loss: 0.2009
	--> Epoch [15/100], Loss: 0.0822, Validation Loss: 0.2014
	--> Epoch [16/100], Loss: 0.0737, Validation Loss: 0.1974
	--> Epoch [17/100], Loss: 0.0761, Validation Loss: 0.1945
	--> Epoch [18/100], Loss: 0.0772, Validation Loss: 0.2039
	--> Epoch [19/100], Loss: 0.0828, Validation Loss: 0.1997
	--> Epoch [20/100], Loss: 0.0780, Validation Loss: 0.2024
Early stopping
	--> Training for Fold 4 took 0.09641385078430176 sec, using 20 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7736, Validation Loss: 0.5950
	--> Epoch [2/100], Loss: 0.6408, Validation Loss: 0.5530
	--> Epoch [3/100], Loss: 0.5431, Validation Loss: 0.5271
	--> Epoch [4/100], Loss: 0.4600, Validation Loss: 0.5168
	--> Epoch [5/100], Loss: 0.3954, Validation Loss: 0.4915
	--> Epoch [6/100], Loss: 0.3269, Validation Loss: 0.4800
	--> Epoch [7/100], Loss: 0.2810, Validation Loss: 0.4714
	--> Epoch [8/100], Loss: 0.2358, Validation Loss: 0.4543
	--> Epoch [9/100], Loss: 0.2463, Validation Loss: 0.4555
	--> Epoch [10/100], Loss: 0.2206, Validation Loss: 0.4552
	--> Epoch [11/100], Loss: 0.1684, Validation Loss: 0.4541
	--> Epoch [12/100], Loss: 0.1805, Validation Loss: 0.4651
	--> Epoch [13/100], Loss: 0.1630, Validation Loss: 0.4697
	--> Epoch [14/100], Loss: 0.1559, Validation Loss: 0.4703
Early stopping
	--> Training for Fold 5 took 0.07161474227905273 sec, using 14 epochs

Median number of epochs used: 20 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/20], Loss: 0.7341
	--> Final training Epoch [2/20], Loss: 0.5607
	--> Final training Epoch [3/20], Loss: 0.4347
	--> Final training Epoch [4/20], Loss: 0.3520
	--> Final training Epoch [5/20], Loss: 0.2965
	--> Final training Epoch [6/20], Loss: 0.2442
	--> Final training Epoch [7/20], Loss: 0.2304
	--> Final training Epoch [8/20], Loss: 0.1596
	--> Final training Epoch [9/20], Loss: 0.1790
	--> Final training Epoch [10/20], Loss: 0.1526
	--> Final training Epoch [11/20], Loss: 0.1243
	--> Final training Epoch [12/20], Loss: 0.1168
	--> Final training Epoch [13/20], Loss: 0.0894
	--> Final training Epoch [14/20], Loss: 0.1064
	--> Final training Epoch [15/20], Loss: 0.0892
	--> Final training Epoch [16/20], Loss: 0.0888
	--> Final training Epoch [17/20], Loss: 0.1115
	--> Final training Epoch [18/20], Loss: 0.0617
	--> Final training Epoch [19/20], Loss: 0.0738
	--> Final training Epoch [20/20], Loss: 0.0680

Final training took 0.06960606575012207 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.2442
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8819, Validation Loss: 0.3116,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3116
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8608, Validation Loss: 0.3216,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3116
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8696, Validation Loss: 0.3349,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3116

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7067, Validation Loss: 0.6059
	--> Epoch [2/100], Loss: 0.5366, Validation Loss: 0.5049
	--> Epoch [3/100], Loss: 0.4357, Validation Loss: 0.4673
	--> Epoch [4/100], Loss: 0.4093, Validation Loss: 0.4241
	--> Epoch [5/100], Loss: 0.3273, Validation Loss: 0.3858
	--> Epoch [6/100], Loss: 0.2746, Validation Loss: 0.3559
	--> Epoch [7/100], Loss: 0.2423, Validation Loss: 0.3342
	--> Epoch [8/100], Loss: 0.2963, Validation Loss: 0.3217
	--> Epoch [9/100], Loss: 0.1953, Validation Loss: 0.3251
	--> Epoch [10/100], Loss: 0.2048, Validation Loss: 0.2937
	--> Epoch [11/100], Loss: 0.1941, Validation Loss: 0.2825
	--> Epoch [12/100], Loss: 0.2192, Validation Loss: 0.2762
	--> Epoch [13/100], Loss: 0.2339, Validation Loss: 0.2604
	--> Epoch [14/100], Loss: 0.1292, Validation Loss: 0.2431
	--> Epoch [15/100], Loss: 0.1667, Validation Loss: 0.2299
	--> Epoch [16/100], Loss: 0.1168, Validation Loss: 0.2267
	--> Epoch [17/100], Loss: 0.1277, Validation Loss: 0.2142
	--> Epoch [18/100], Loss: 0.1053, Validation Loss: 0.2114
	--> Epoch [19/100], Loss: 0.1297, Validation Loss: 0.2050
	--> Epoch [20/100], Loss: 0.0922, Validation Loss: 0.2002
	--> Epoch [21/100], Loss: 0.0963, Validation Loss: 0.1902
	--> Epoch [22/100], Loss: 0.0977, Validation Loss: 0.1878
	--> Epoch [23/100], Loss: 0.1316, Validation Loss: 0.1925
	--> Epoch [24/100], Loss: 0.1224, Validation Loss: 0.1936
	--> Epoch [25/100], Loss: 0.0711, Validation Loss: 0.1937
Early stopping
	--> Training for Fold 1 took 0.0992891788482666 sec, using 25 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7433, Validation Loss: 0.5721
	--> Epoch [2/100], Loss: 0.6320, Validation Loss: 0.4824
	--> Epoch [3/100], Loss: 0.4896, Validation Loss: 0.4098
	--> Epoch [4/100], Loss: 0.4352, Validation Loss: 0.3620
	--> Epoch [5/100], Loss: 0.3702, Validation Loss: 0.3202
	--> Epoch [6/100], Loss: 0.3534, Validation Loss: 0.3118
	--> Epoch [7/100], Loss: 0.3261, Validation Loss: 0.3032
	--> Epoch [8/100], Loss: 0.2239, Validation Loss: 0.2870
	--> Epoch [9/100], Loss: 0.2907, Validation Loss: 0.2753
	--> Epoch [10/100], Loss: 0.2431, Validation Loss: 0.2598
	--> Epoch [11/100], Loss: 0.2105, Validation Loss: 0.2470
	--> Epoch [12/100], Loss: 0.2048, Validation Loss: 0.2432
	--> Epoch [13/100], Loss: 0.1774, Validation Loss: 0.2275
	--> Epoch [14/100], Loss: 0.1328, Validation Loss: 0.2193
	--> Epoch [15/100], Loss: 0.1606, Validation Loss: 0.2371
	--> Epoch [16/100], Loss: 0.1602, Validation Loss: 0.2116
	--> Epoch [17/100], Loss: 0.1639, Validation Loss: 0.2076
	--> Epoch [18/100], Loss: 0.1361, Validation Loss: 0.2221
	--> Epoch [19/100], Loss: 0.1366, Validation Loss: 0.2184
	--> Epoch [20/100], Loss: 0.1208, Validation Loss: 0.2138
Early stopping
	--> Training for Fold 2 took 0.07781052589416504 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7862, Validation Loss: 0.6041
	--> Epoch [2/100], Loss: 0.5650, Validation Loss: 0.5331
	--> Epoch [3/100], Loss: 0.4780, Validation Loss: 0.5044
	--> Epoch [4/100], Loss: 0.3973, Validation Loss: 0.4607
	--> Epoch [5/100], Loss: 0.3474, Validation Loss: 0.4195
	--> Epoch [6/100], Loss: 0.2664, Validation Loss: 0.3991
	--> Epoch [7/100], Loss: 0.2215, Validation Loss: 0.3913
	--> Epoch [8/100], Loss: 0.2323, Validation Loss: 0.3652
	--> Epoch [9/100], Loss: 0.2110, Validation Loss: 0.3691
	--> Epoch [10/100], Loss: 0.1999, Validation Loss: 0.3533
	--> Epoch [11/100], Loss: 0.1413, Validation Loss: 0.3397
	--> Epoch [12/100], Loss: 0.1823, Validation Loss: 0.3189
	--> Epoch [13/100], Loss: 0.1551, Validation Loss: 0.3203
	--> Epoch [14/100], Loss: 0.1331, Validation Loss: 0.3282
	--> Epoch [15/100], Loss: 0.1342, Validation Loss: 0.3106
	--> Epoch [16/100], Loss: 0.1194, Validation Loss: 0.2970
	--> Epoch [17/100], Loss: 0.1508, Validation Loss: 0.2954
	--> Epoch [18/100], Loss: 0.1096, Validation Loss: 0.2931
	--> Epoch [19/100], Loss: 0.1160, Validation Loss: 0.2929
	--> Epoch [20/100], Loss: 0.0931, Validation Loss: 0.2844
	--> Epoch [21/100], Loss: 0.1064, Validation Loss: 0.2840
	--> Epoch [22/100], Loss: 0.1259, Validation Loss: 0.2827
	--> Epoch [23/100], Loss: 0.0992, Validation Loss: 0.2818
	--> Epoch [24/100], Loss: 0.1208, Validation Loss: 0.2867
	--> Epoch [25/100], Loss: 0.0680, Validation Loss: 0.2783
	--> Epoch [26/100], Loss: 0.1485, Validation Loss: 0.2795
	--> Epoch [27/100], Loss: 0.1191, Validation Loss: 0.2740
	--> Epoch [28/100], Loss: 0.0856, Validation Loss: 0.2747
	--> Epoch [29/100], Loss: 0.0791, Validation Loss: 0.2798
	--> Epoch [30/100], Loss: 0.0859, Validation Loss: 0.2838
Early stopping
	--> Training for Fold 3 took 0.11116194725036621 sec, using 30 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7014, Validation Loss: 0.6568
	--> Epoch [2/100], Loss: 0.6144, Validation Loss: 0.5540
	--> Epoch [3/100], Loss: 0.5088, Validation Loss: 0.5055
	--> Epoch [4/100], Loss: 0.4751, Validation Loss: 0.4553
	--> Epoch [5/100], Loss: 0.4248, Validation Loss: 0.4307
	--> Epoch [6/100], Loss: 0.3103, Validation Loss: 0.4049
	--> Epoch [7/100], Loss: 0.2697, Validation Loss: 0.3679
	--> Epoch [8/100], Loss: 0.2871, Validation Loss: 0.3789
	--> Epoch [9/100], Loss: 0.1886, Validation Loss: 0.3663
	--> Epoch [10/100], Loss: 0.2455, Validation Loss: 0.3568
	--> Epoch [11/100], Loss: 0.1705, Validation Loss: 0.3323
	--> Epoch [12/100], Loss: 0.1645, Validation Loss: 0.3365
	--> Epoch [13/100], Loss: 0.1532, Validation Loss: 0.3420
	--> Epoch [14/100], Loss: 0.1725, Validation Loss: 0.3363
Early stopping
	--> Training for Fold 4 took 0.04989957809448242 sec, using 14 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7040, Validation Loss: 0.5240
	--> Epoch [2/100], Loss: 0.5126, Validation Loss: 0.5056
	--> Epoch [3/100], Loss: 0.3998, Validation Loss: 0.5029
	--> Epoch [4/100], Loss: 0.3332, Validation Loss: 0.4745
	--> Epoch [5/100], Loss: 0.2948, Validation Loss: 0.4676
	--> Epoch [6/100], Loss: 0.2751, Validation Loss: 0.4708
	--> Epoch [7/100], Loss: 0.1900, Validation Loss: 0.4517
	--> Epoch [8/100], Loss: 0.2003, Validation Loss: 0.4354
	--> Epoch [9/100], Loss: 0.2113, Validation Loss: 0.4521
	--> Epoch [10/100], Loss: 0.1570, Validation Loss: 0.4513
	--> Epoch [11/100], Loss: 0.1821, Validation Loss: 0.4636
Early stopping
	--> Training for Fold 5 took 0.040926456451416016 sec, using 11 epochs

Median number of epochs used: 20 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/20], Loss: 0.6962
	--> Final training Epoch [2/20], Loss: 0.5552
	--> Final training Epoch [3/20], Loss: 0.4594
	--> Final training Epoch [4/20], Loss: 0.4186
	--> Final training Epoch [5/20], Loss: 0.3998
	--> Final training Epoch [6/20], Loss: 0.3047
	--> Final training Epoch [7/20], Loss: 0.2751
	--> Final training Epoch [8/20], Loss: 0.2473
	--> Final training Epoch [9/20], Loss: 0.2274
	--> Final training Epoch [10/20], Loss: 0.2470
	--> Final training Epoch [11/20], Loss: 0.1673
	--> Final training Epoch [12/20], Loss: 0.1827
	--> Final training Epoch [13/20], Loss: 0.1226
	--> Final training Epoch [14/20], Loss: 0.1813
	--> Final training Epoch [15/20], Loss: 0.1198
	--> Final training Epoch [16/20], Loss: 0.1630
	--> Final training Epoch [17/20], Loss: 0.1065
	--> Final training Epoch [18/20], Loss: 0.1199
	--> Final training Epoch [19/20], Loss: 0.1061
	--> Final training Epoch [20/20], Loss: 0.1238

Final training took 0.07093524932861328 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0289
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8918, Validation Loss: 0.3609,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3609

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7116, Validation Loss: 0.6125
	--> Epoch [2/100], Loss: 0.6405, Validation Loss: 0.5466
	--> Epoch [3/100], Loss: 0.5963, Validation Loss: 0.5285
	--> Epoch [4/100], Loss: 0.4969, Validation Loss: 0.4793
	--> Epoch [5/100], Loss: 0.4717, Validation Loss: 0.4357
	--> Epoch [6/100], Loss: 0.4112, Validation Loss: 0.4061
	--> Epoch [7/100], Loss: 0.4202, Validation Loss: 0.3835
	--> Epoch [8/100], Loss: 0.3515, Validation Loss: 0.3671
	--> Epoch [9/100], Loss: 0.3498, Validation Loss: 0.3451
	--> Epoch [10/100], Loss: 0.3243, Validation Loss: 0.3253
	--> Epoch [11/100], Loss: 0.3542, Validation Loss: 0.3203
	--> Epoch [12/100], Loss: 0.2826, Validation Loss: 0.3176
	--> Epoch [13/100], Loss: 0.3075, Validation Loss: 0.3091
	--> Epoch [14/100], Loss: 0.2841, Validation Loss: 0.2996
	--> Epoch [15/100], Loss: 0.2598, Validation Loss: 0.2991
	--> Epoch [16/100], Loss: 0.2942, Validation Loss: 0.2919
	--> Epoch [17/100], Loss: 0.2472, Validation Loss: 0.2883
	--> Epoch [18/100], Loss: 0.1854, Validation Loss: 0.2840
	--> Epoch [19/100], Loss: 0.2839, Validation Loss: 0.2749
	--> Epoch [20/100], Loss: 0.2993, Validation Loss: 0.2819
	--> Epoch [21/100], Loss: 0.2317, Validation Loss: 0.2675
	--> Epoch [22/100], Loss: 0.3208, Validation Loss: 0.2599
	--> Epoch [23/100], Loss: 0.2620, Validation Loss: 0.2520
	--> Epoch [24/100], Loss: 0.2649, Validation Loss: 0.2604
	--> Epoch [25/100], Loss: 0.2450, Validation Loss: 0.2625
	--> Epoch [26/100], Loss: 0.2565, Validation Loss: 0.2592
Early stopping
	--> Training for Fold 1 took 0.09388613700866699 sec, using 26 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7171, Validation Loss: 0.5521
	--> Epoch [2/100], Loss: 0.5878, Validation Loss: 0.4742
	--> Epoch [3/100], Loss: 0.5320, Validation Loss: 0.4443
	--> Epoch [4/100], Loss: 0.5333, Validation Loss: 0.4032
	--> Epoch [5/100], Loss: 0.4457, Validation Loss: 0.3669
	--> Epoch [6/100], Loss: 0.4281, Validation Loss: 0.3325
	--> Epoch [7/100], Loss: 0.3564, Validation Loss: 0.3371
	--> Epoch [8/100], Loss: 0.3931, Validation Loss: 0.3188
	--> Epoch [9/100], Loss: 0.3827, Validation Loss: 0.2913
	--> Epoch [10/100], Loss: 0.3693, Validation Loss: 0.2706
	--> Epoch [11/100], Loss: 0.3295, Validation Loss: 0.2684
	--> Epoch [12/100], Loss: 0.2835, Validation Loss: 0.2622
	--> Epoch [13/100], Loss: 0.2945, Validation Loss: 0.2662
	--> Epoch [14/100], Loss: 0.3333, Validation Loss: 0.2502
	--> Epoch [15/100], Loss: 0.3091, Validation Loss: 0.2451
	--> Epoch [16/100], Loss: 0.2550, Validation Loss: 0.2459
	--> Epoch [17/100], Loss: 0.2506, Validation Loss: 0.2371
	--> Epoch [18/100], Loss: 0.3029, Validation Loss: 0.2207
	--> Epoch [19/100], Loss: 0.1759, Validation Loss: 0.2192
	--> Epoch [20/100], Loss: 0.1784, Validation Loss: 0.2187
	--> Epoch [21/100], Loss: 0.3250, Validation Loss: 0.2168
	--> Epoch [22/100], Loss: 0.2828, Validation Loss: 0.2151
	--> Epoch [23/100], Loss: 0.2891, Validation Loss: 0.2033
	--> Epoch [24/100], Loss: 0.1743, Validation Loss: 0.2022
	--> Epoch [25/100], Loss: 0.2321, Validation Loss: 0.2034
	--> Epoch [26/100], Loss: 0.2417, Validation Loss: 0.2016
	--> Epoch [27/100], Loss: 0.2195, Validation Loss: 0.1988
	--> Epoch [28/100], Loss: 0.2743, Validation Loss: 0.2174
	--> Epoch [29/100], Loss: 0.2540, Validation Loss: 0.2248
	--> Epoch [30/100], Loss: 0.1678, Validation Loss: 0.2235
Early stopping
	--> Training for Fold 2 took 0.11292290687561035 sec, using 30 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7534, Validation Loss: 0.6555
	--> Epoch [2/100], Loss: 0.6623, Validation Loss: 0.5954
	--> Epoch [3/100], Loss: 0.5751, Validation Loss: 0.5724
	--> Epoch [4/100], Loss: 0.5158, Validation Loss: 0.5263
	--> Epoch [5/100], Loss: 0.4495, Validation Loss: 0.5015
	--> Epoch [6/100], Loss: 0.4403, Validation Loss: 0.4590
	--> Epoch [7/100], Loss: 0.4041, Validation Loss: 0.4244
	--> Epoch [8/100], Loss: 0.3380, Validation Loss: 0.4076
	--> Epoch [9/100], Loss: 0.3432, Validation Loss: 0.3865
	--> Epoch [10/100], Loss: 0.3929, Validation Loss: 0.4009
	--> Epoch [11/100], Loss: 0.3513, Validation Loss: 0.3712
	--> Epoch [12/100], Loss: 0.3553, Validation Loss: 0.3616
	--> Epoch [13/100], Loss: 0.3417, Validation Loss: 0.3528
	--> Epoch [14/100], Loss: 0.2798, Validation Loss: 0.3332
	--> Epoch [15/100], Loss: 0.2630, Validation Loss: 0.3139
	--> Epoch [16/100], Loss: 0.2767, Validation Loss: 0.3029
	--> Epoch [17/100], Loss: 0.2848, Validation Loss: 0.3101
	--> Epoch [18/100], Loss: 0.2265, Validation Loss: 0.3004
	--> Epoch [19/100], Loss: 0.2328, Validation Loss: 0.2973
	--> Epoch [20/100], Loss: 0.2380, Validation Loss: 0.2895
	--> Epoch [21/100], Loss: 0.2296, Validation Loss: 0.2823
	--> Epoch [22/100], Loss: 0.2629, Validation Loss: 0.3055
	--> Epoch [23/100], Loss: 0.2000, Validation Loss: 0.2983
	--> Epoch [24/100], Loss: 0.2758, Validation Loss: 0.2959
Early stopping
	--> Training for Fold 3 took 0.09357595443725586 sec, using 24 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8412, Validation Loss: 0.6585
	--> Epoch [2/100], Loss: 0.6116, Validation Loss: 0.5556
	--> Epoch [3/100], Loss: 0.5775, Validation Loss: 0.5555
	--> Epoch [4/100], Loss: 0.4494, Validation Loss: 0.4820
	--> Epoch [5/100], Loss: 0.5153, Validation Loss: 0.4343
	--> Epoch [6/100], Loss: 0.4135, Validation Loss: 0.4071
	--> Epoch [7/100], Loss: 0.3695, Validation Loss: 0.4009
	--> Epoch [8/100], Loss: 0.3686, Validation Loss: 0.3492
	--> Epoch [9/100], Loss: 0.3527, Validation Loss: 0.3383
	--> Epoch [10/100], Loss: 0.3204, Validation Loss: 0.3448
	--> Epoch [11/100], Loss: 0.3005, Validation Loss: 0.3396
	--> Epoch [12/100], Loss: 0.2632, Validation Loss: 0.3325
	--> Epoch [13/100], Loss: 0.3333, Validation Loss: 0.3445
	--> Epoch [14/100], Loss: 0.2765, Validation Loss: 0.3234
	--> Epoch [15/100], Loss: 0.2405, Validation Loss: 0.3474
	--> Epoch [16/100], Loss: 0.2954, Validation Loss: 0.3591
	--> Epoch [17/100], Loss: 0.2412, Validation Loss: 0.3414
Early stopping
	--> Training for Fold 4 took 0.062253475189208984 sec, using 17 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7398, Validation Loss: 0.6338
	--> Epoch [2/100], Loss: 0.5830, Validation Loss: 0.5869
	--> Epoch [3/100], Loss: 0.5324, Validation Loss: 0.5699
	--> Epoch [4/100], Loss: 0.5240, Validation Loss: 0.5548
	--> Epoch [5/100], Loss: 0.4596, Validation Loss: 0.5198
	--> Epoch [6/100], Loss: 0.4380, Validation Loss: 0.5016
	--> Epoch [7/100], Loss: 0.3985, Validation Loss: 0.5042
	--> Epoch [8/100], Loss: 0.3126, Validation Loss: 0.4890
	--> Epoch [9/100], Loss: 0.3352, Validation Loss: 0.4836
	--> Epoch [10/100], Loss: 0.3483, Validation Loss: 0.4776
	--> Epoch [11/100], Loss: 0.2897, Validation Loss: 0.4850
	--> Epoch [12/100], Loss: 0.2810, Validation Loss: 0.4780
	--> Epoch [13/100], Loss: 0.2626, Validation Loss: 0.4520
	--> Epoch [14/100], Loss: 0.2655, Validation Loss: 0.4486
	--> Epoch [15/100], Loss: 0.2317, Validation Loss: 0.4587
	--> Epoch [16/100], Loss: 0.2774, Validation Loss: 0.4251
	--> Epoch [17/100], Loss: 0.2533, Validation Loss: 0.4356
	--> Epoch [18/100], Loss: 0.2949, Validation Loss: 0.4191
	--> Epoch [19/100], Loss: 0.2423, Validation Loss: 0.4200
	--> Epoch [20/100], Loss: 0.2177, Validation Loss: 0.4173
	--> Epoch [21/100], Loss: 0.2559, Validation Loss: 0.4087
	--> Epoch [22/100], Loss: 0.2250, Validation Loss: 0.4171
	--> Epoch [23/100], Loss: 0.2353, Validation Loss: 0.4126
	--> Epoch [24/100], Loss: 0.1976, Validation Loss: 0.4134
Early stopping
	--> Training for Fold 5 took 0.08951663970947266 sec, using 24 epochs

Median number of epochs used: 24 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/24], Loss: 0.7869
	--> Final training Epoch [2/24], Loss: 0.6683
	--> Final training Epoch [3/24], Loss: 0.5689
	--> Final training Epoch [4/24], Loss: 0.5390
	--> Final training Epoch [5/24], Loss: 0.4737
	--> Final training Epoch [6/24], Loss: 0.4665
	--> Final training Epoch [7/24], Loss: 0.4365
	--> Final training Epoch [8/24], Loss: 0.3584
	--> Final training Epoch [9/24], Loss: 0.3447
	--> Final training Epoch [10/24], Loss: 0.3692
	--> Final training Epoch [11/24], Loss: 0.3688
	--> Final training Epoch [12/24], Loss: 0.3326
	--> Final training Epoch [13/24], Loss: 0.2932
	--> Final training Epoch [14/24], Loss: 0.2263
	--> Final training Epoch [15/24], Loss: 0.3194
	--> Final training Epoch [16/24], Loss: 0.2431
	--> Final training Epoch [17/24], Loss: 0.2634
	--> Final training Epoch [18/24], Loss: 0.2148
	--> Final training Epoch [19/24], Loss: 0.2463
	--> Final training Epoch [20/24], Loss: 0.2461
	--> Final training Epoch [21/24], Loss: 0.1864
	--> Final training Epoch [22/24], Loss: 0.2342
	--> Final training Epoch [23/24], Loss: 0.2689
	--> Final training Epoch [24/24], Loss: 0.2273

Final training took 0.07715582847595215 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9361
	--> Final Precision: 0.6667
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6400
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3528,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3528
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8480, Validation Loss: 0.3593,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3528
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3573,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3528

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7567, Validation Loss: 0.5691
	--> Epoch [2/100], Loss: 0.5759, Validation Loss: 0.4839
	--> Epoch [3/100], Loss: 0.4541, Validation Loss: 0.4170
	--> Epoch [4/100], Loss: 0.4156, Validation Loss: 0.3709
	--> Epoch [5/100], Loss: 0.3410, Validation Loss: 0.3443
	--> Epoch [6/100], Loss: 0.2831, Validation Loss: 0.3146
	--> Epoch [7/100], Loss: 0.2549, Validation Loss: 0.3058
	--> Epoch [8/100], Loss: 0.2036, Validation Loss: 0.2881
	--> Epoch [9/100], Loss: 0.1805, Validation Loss: 0.2753
	--> Epoch [10/100], Loss: 0.1573, Validation Loss: 0.2623
	--> Epoch [11/100], Loss: 0.1417, Validation Loss: 0.2662
	--> Epoch [12/100], Loss: 0.0990, Validation Loss: 0.2565
	--> Epoch [13/100], Loss: 0.1059, Validation Loss: 0.2499
	--> Epoch [14/100], Loss: 0.0688, Validation Loss: 0.2467
	--> Epoch [15/100], Loss: 0.0558, Validation Loss: 0.2416
	--> Epoch [16/100], Loss: 0.0641, Validation Loss: 0.2409
	--> Epoch [17/100], Loss: 0.0407, Validation Loss: 0.2402
	--> Epoch [18/100], Loss: 0.0418, Validation Loss: 0.2353
	--> Epoch [19/100], Loss: 0.0533, Validation Loss: 0.2477
	--> Epoch [20/100], Loss: 0.0759, Validation Loss: 0.2640
	--> Epoch [21/100], Loss: 0.0809, Validation Loss: 0.2579
Early stopping
	--> Training for Fold 1 took 0.08023190498352051 sec, using 21 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6889, Validation Loss: 0.5160
	--> Epoch [2/100], Loss: 0.5672, Validation Loss: 0.4262
	--> Epoch [3/100], Loss: 0.4574, Validation Loss: 0.3749
	--> Epoch [4/100], Loss: 0.3843, Validation Loss: 0.3338
	--> Epoch [5/100], Loss: 0.2961, Validation Loss: 0.3141
	--> Epoch [6/100], Loss: 0.2822, Validation Loss: 0.2954
	--> Epoch [7/100], Loss: 0.2207, Validation Loss: 0.2754
	--> Epoch [8/100], Loss: 0.1659, Validation Loss: 0.2542
	--> Epoch [9/100], Loss: 0.1366, Validation Loss: 0.2353
	--> Epoch [10/100], Loss: 0.1293, Validation Loss: 0.2549
	--> Epoch [11/100], Loss: 0.1068, Validation Loss: 0.2335
	--> Epoch [12/100], Loss: 0.1474, Validation Loss: 0.2402
	--> Epoch [13/100], Loss: 0.1210, Validation Loss: 0.2305
	--> Epoch [14/100], Loss: 0.0900, Validation Loss: 0.2169
	--> Epoch [15/100], Loss: 0.0788, Validation Loss: 0.2193
	--> Epoch [16/100], Loss: 0.0349, Validation Loss: 0.2062
	--> Epoch [17/100], Loss: 0.0926, Validation Loss: 0.2145
	--> Epoch [18/100], Loss: 0.0396, Validation Loss: 0.2088
	--> Epoch [19/100], Loss: 0.0453, Validation Loss: 0.2134
Early stopping
	--> Training for Fold 2 took 0.06729626655578613 sec, using 19 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7544, Validation Loss: 0.5953
	--> Epoch [2/100], Loss: 0.5478, Validation Loss: 0.5310
	--> Epoch [3/100], Loss: 0.4458, Validation Loss: 0.4932
	--> Epoch [4/100], Loss: 0.3918, Validation Loss: 0.4583
	--> Epoch [5/100], Loss: 0.3135, Validation Loss: 0.4316
	--> Epoch [6/100], Loss: 0.2512, Validation Loss: 0.4126
	--> Epoch [7/100], Loss: 0.2095, Validation Loss: 0.3753
	--> Epoch [8/100], Loss: 0.1621, Validation Loss: 0.3527
	--> Epoch [9/100], Loss: 0.1425, Validation Loss: 0.3385
	--> Epoch [10/100], Loss: 0.1165, Validation Loss: 0.3241
	--> Epoch [11/100], Loss: 0.1064, Validation Loss: 0.3156
	--> Epoch [12/100], Loss: 0.1171, Validation Loss: 0.3009
	--> Epoch [13/100], Loss: 0.1076, Validation Loss: 0.2998
	--> Epoch [14/100], Loss: 0.0924, Validation Loss: 0.2970
	--> Epoch [15/100], Loss: 0.0711, Validation Loss: 0.2934
	--> Epoch [16/100], Loss: 0.0691, Validation Loss: 0.2917
	--> Epoch [17/100], Loss: 0.0591, Validation Loss: 0.2819
	--> Epoch [18/100], Loss: 0.0771, Validation Loss: 0.2879
	--> Epoch [19/100], Loss: 0.0540, Validation Loss: 0.2733
	--> Epoch [20/100], Loss: 0.0535, Validation Loss: 0.2711
	--> Epoch [21/100], Loss: 0.0348, Validation Loss: 0.2675
	--> Epoch [22/100], Loss: 0.0707, Validation Loss: 0.2743
	--> Epoch [23/100], Loss: 0.0346, Validation Loss: 0.2593
	--> Epoch [24/100], Loss: 0.0565, Validation Loss: 0.2494
	--> Epoch [25/100], Loss: 0.0475, Validation Loss: 0.2510
	--> Epoch [26/100], Loss: 0.0339, Validation Loss: 0.2569
	--> Epoch [27/100], Loss: 0.0300, Validation Loss: 0.2576
Early stopping
	--> Training for Fold 3 took 0.10253095626831055 sec, using 27 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7457, Validation Loss: 0.4956
	--> Epoch [2/100], Loss: 0.5787, Validation Loss: 0.4645
	--> Epoch [3/100], Loss: 0.4698, Validation Loss: 0.4248
	--> Epoch [4/100], Loss: 0.4418, Validation Loss: 0.4037
	--> Epoch [5/100], Loss: 0.3884, Validation Loss: 0.3585
	--> Epoch [6/100], Loss: 0.3099, Validation Loss: 0.3686
	--> Epoch [7/100], Loss: 0.2826, Validation Loss: 0.3402
	--> Epoch [8/100], Loss: 0.2603, Validation Loss: 0.3209
	--> Epoch [9/100], Loss: 0.2350, Validation Loss: 0.3157
	--> Epoch [10/100], Loss: 0.2180, Validation Loss: 0.3170
	--> Epoch [11/100], Loss: 0.1980, Validation Loss: 0.3105
	--> Epoch [12/100], Loss: 0.1856, Validation Loss: 0.3000
	--> Epoch [13/100], Loss: 0.1922, Validation Loss: 0.2978
	--> Epoch [14/100], Loss: 0.1660, Validation Loss: 0.2897
	--> Epoch [15/100], Loss: 0.2177, Validation Loss: 0.3041
	--> Epoch [16/100], Loss: 0.1517, Validation Loss: 0.2925
	--> Epoch [17/100], Loss: 0.1773, Validation Loss: 0.3144
Early stopping
	--> Training for Fold 4 took 0.06562304496765137 sec, using 17 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7397, Validation Loss: 0.5818
	--> Epoch [2/100], Loss: 0.5683, Validation Loss: 0.5577
	--> Epoch [3/100], Loss: 0.4453, Validation Loss: 0.5404
	--> Epoch [4/100], Loss: 0.3486, Validation Loss: 0.5279
	--> Epoch [5/100], Loss: 0.3030, Validation Loss: 0.5058
	--> Epoch [6/100], Loss: 0.2616, Validation Loss: 0.4903
	--> Epoch [7/100], Loss: 0.2251, Validation Loss: 0.4906
	--> Epoch [8/100], Loss: 0.2066, Validation Loss: 0.5035
	--> Epoch [9/100], Loss: 0.1676, Validation Loss: 0.4883
	--> Epoch [10/100], Loss: 0.1402, Validation Loss: 0.4826
	--> Epoch [11/100], Loss: 0.0928, Validation Loss: 0.4922
	--> Epoch [12/100], Loss: 0.0928, Validation Loss: 0.5182
	--> Epoch [13/100], Loss: 0.1074, Validation Loss: 0.5248
Early stopping
	--> Training for Fold 5 took 0.05086636543273926 sec, using 13 epochs

Median number of epochs used: 19 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/19], Loss: 0.6700
	--> Final training Epoch [2/19], Loss: 0.5121
	--> Final training Epoch [3/19], Loss: 0.4043
	--> Final training Epoch [4/19], Loss: 0.3256
	--> Final training Epoch [5/19], Loss: 0.2813
	--> Final training Epoch [6/19], Loss: 0.2479
	--> Final training Epoch [7/19], Loss: 0.2180
	--> Final training Epoch [8/19], Loss: 0.1939
	--> Final training Epoch [9/19], Loss: 0.1849
	--> Final training Epoch [10/19], Loss: 0.1454
	--> Final training Epoch [11/19], Loss: 0.1153
	--> Final training Epoch [12/19], Loss: 0.1494
	--> Final training Epoch [13/19], Loss: 0.1255
	--> Final training Epoch [14/19], Loss: 0.1014
	--> Final training Epoch [15/19], Loss: 0.0804
	--> Final training Epoch [16/19], Loss: 0.0967
	--> Final training Epoch [17/19], Loss: 0.1004
	--> Final training Epoch [18/19], Loss: 0.0717
	--> Final training Epoch [19/19], Loss: 0.0791

Final training took 0.07432055473327637 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0571
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3468,  Current Best Accuracy: 0.8275,  Current Best Validation Loss: 0.3468

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7227, Validation Loss: 0.5140
	--> Epoch [2/100], Loss: 0.5712, Validation Loss: 0.4573
	--> Epoch [3/100], Loss: 0.4641, Validation Loss: 0.3983
	--> Epoch [4/100], Loss: 0.3644, Validation Loss: 0.3707
	--> Epoch [5/100], Loss: 0.3326, Validation Loss: 0.3432
	--> Epoch [6/100], Loss: 0.2668, Validation Loss: 0.3025
	--> Epoch [7/100], Loss: 0.2001, Validation Loss: 0.2867
	--> Epoch [8/100], Loss: 0.1663, Validation Loss: 0.2726
	--> Epoch [9/100], Loss: 0.2012, Validation Loss: 0.2600
	--> Epoch [10/100], Loss: 0.1471, Validation Loss: 0.2543
	--> Epoch [11/100], Loss: 0.1394, Validation Loss: 0.2367
	--> Epoch [12/100], Loss: 0.1061, Validation Loss: 0.2330
	--> Epoch [13/100], Loss: 0.0974, Validation Loss: 0.2340
	--> Epoch [14/100], Loss: 0.0899, Validation Loss: 0.2253
	--> Epoch [15/100], Loss: 0.0673, Validation Loss: 0.2127
	--> Epoch [16/100], Loss: 0.0859, Validation Loss: 0.2173
	--> Epoch [17/100], Loss: 0.0756, Validation Loss: 0.2204
	--> Epoch [18/100], Loss: 0.0691, Validation Loss: 0.2255
Early stopping
	--> Training for Fold 1 took 0.07355117797851562 sec, using 18 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7512, Validation Loss: 0.5284
	--> Epoch [2/100], Loss: 0.5848, Validation Loss: 0.4363
	--> Epoch [3/100], Loss: 0.4993, Validation Loss: 0.3782
	--> Epoch [4/100], Loss: 0.3885, Validation Loss: 0.3328
	--> Epoch [5/100], Loss: 0.2980, Validation Loss: 0.3001
	--> Epoch [6/100], Loss: 0.2522, Validation Loss: 0.2829
	--> Epoch [7/100], Loss: 0.2014, Validation Loss: 0.2533
	--> Epoch [8/100], Loss: 0.1846, Validation Loss: 0.2368
	--> Epoch [9/100], Loss: 0.1774, Validation Loss: 0.2380
	--> Epoch [10/100], Loss: 0.1661, Validation Loss: 0.2471
	--> Epoch [11/100], Loss: 0.1165, Validation Loss: 0.2294
	--> Epoch [12/100], Loss: 0.0908, Validation Loss: 0.2157
	--> Epoch [13/100], Loss: 0.1381, Validation Loss: 0.2174
	--> Epoch [14/100], Loss: 0.1083, Validation Loss: 0.2150
	--> Epoch [15/100], Loss: 0.0933, Validation Loss: 0.2120
	--> Epoch [16/100], Loss: 0.0873, Validation Loss: 0.2138
	--> Epoch [17/100], Loss: 0.0712, Validation Loss: 0.1974
	--> Epoch [18/100], Loss: 0.0754, Validation Loss: 0.2052
	--> Epoch [19/100], Loss: 0.0755, Validation Loss: 0.2044
	--> Epoch [20/100], Loss: 0.0803, Validation Loss: 0.1988
Early stopping
	--> Training for Fold 2 took 0.07796239852905273 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7115, Validation Loss: 0.6051
	--> Epoch [2/100], Loss: 0.5055, Validation Loss: 0.5276
	--> Epoch [3/100], Loss: 0.4171, Validation Loss: 0.4712
	--> Epoch [4/100], Loss: 0.2930, Validation Loss: 0.4340
	--> Epoch [5/100], Loss: 0.2733, Validation Loss: 0.3934
	--> Epoch [6/100], Loss: 0.2059, Validation Loss: 0.3731
	--> Epoch [7/100], Loss: 0.1863, Validation Loss: 0.3558
	--> Epoch [8/100], Loss: 0.1673, Validation Loss: 0.3336
	--> Epoch [9/100], Loss: 0.1325, Validation Loss: 0.3273
	--> Epoch [10/100], Loss: 0.1678, Validation Loss: 0.3186
	--> Epoch [11/100], Loss: 0.1015, Validation Loss: 0.3075
	--> Epoch [12/100], Loss: 0.1043, Validation Loss: 0.2781
	--> Epoch [13/100], Loss: 0.1023, Validation Loss: 0.2768
	--> Epoch [14/100], Loss: 0.0693, Validation Loss: 0.2798
	--> Epoch [15/100], Loss: 0.0833, Validation Loss: 0.2687
	--> Epoch [16/100], Loss: 0.0455, Validation Loss: 0.2686
	--> Epoch [17/100], Loss: 0.0545, Validation Loss: 0.2716
	--> Epoch [18/100], Loss: 0.0490, Validation Loss: 0.2606
	--> Epoch [19/100], Loss: 0.0643, Validation Loss: 0.2569
	--> Epoch [20/100], Loss: 0.0473, Validation Loss: 0.2713
	--> Epoch [21/100], Loss: 0.0513, Validation Loss: 0.2696
	--> Epoch [22/100], Loss: 0.0368, Validation Loss: 0.2668
Early stopping
	--> Training for Fold 3 took 0.0857698917388916 sec, using 22 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7146, Validation Loss: 0.5382
	--> Epoch [2/100], Loss: 0.5575, Validation Loss: 0.4945
	--> Epoch [3/100], Loss: 0.4724, Validation Loss: 0.4503
	--> Epoch [4/100], Loss: 0.4143, Validation Loss: 0.4007
	--> Epoch [5/100], Loss: 0.3265, Validation Loss: 0.3716
	--> Epoch [6/100], Loss: 0.3102, Validation Loss: 0.3590
	--> Epoch [7/100], Loss: 0.2698, Validation Loss: 0.3203
	--> Epoch [8/100], Loss: 0.2275, Validation Loss: 0.3215
	--> Epoch [9/100], Loss: 0.1702, Validation Loss: 0.3196
	--> Epoch [10/100], Loss: 0.2146, Validation Loss: 0.2966
	--> Epoch [11/100], Loss: 0.1528, Validation Loss: 0.2946
	--> Epoch [12/100], Loss: 0.1197, Validation Loss: 0.2883
	--> Epoch [13/100], Loss: 0.1413, Validation Loss: 0.2882
	--> Epoch [14/100], Loss: 0.1399, Validation Loss: 0.2920
	--> Epoch [15/100], Loss: 0.1365, Validation Loss: 0.2938
	--> Epoch [16/100], Loss: 0.1055, Validation Loss: 0.2983
Early stopping
	--> Training for Fold 4 took 0.06057548522949219 sec, using 16 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6680, Validation Loss: 0.7020
	--> Epoch [2/100], Loss: 0.5403, Validation Loss: 0.6638
	--> Epoch [3/100], Loss: 0.4524, Validation Loss: 0.6547
	--> Epoch [4/100], Loss: 0.3698, Validation Loss: 0.6153
	--> Epoch [5/100], Loss: 0.2841, Validation Loss: 0.5783
	--> Epoch [6/100], Loss: 0.2678, Validation Loss: 0.5667
	--> Epoch [7/100], Loss: 0.2035, Validation Loss: 0.5700
	--> Epoch [8/100], Loss: 0.1792, Validation Loss: 0.5552
	--> Epoch [9/100], Loss: 0.1959, Validation Loss: 0.5440
	--> Epoch [10/100], Loss: 0.1723, Validation Loss: 0.5484
	--> Epoch [11/100], Loss: 0.1924, Validation Loss: 0.5297
	--> Epoch [12/100], Loss: 0.1501, Validation Loss: 0.5467
	--> Epoch [13/100], Loss: 0.1603, Validation Loss: 0.5593
	--> Epoch [14/100], Loss: 0.1321, Validation Loss: 0.5502
Early stopping
	--> Training for Fold 5 took 0.05195760726928711 sec, using 14 epochs

Median number of epochs used: 18 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/18], Loss: 0.7433
	--> Final training Epoch [2/18], Loss: 0.5281
	--> Final training Epoch [3/18], Loss: 0.4072
	--> Final training Epoch [4/18], Loss: 0.3715
	--> Final training Epoch [5/18], Loss: 0.3167
	--> Final training Epoch [6/18], Loss: 0.2696
	--> Final training Epoch [7/18], Loss: 0.2061
	--> Final training Epoch [8/18], Loss: 0.2053
	--> Final training Epoch [9/18], Loss: 0.1593
	--> Final training Epoch [10/18], Loss: 0.1467
	--> Final training Epoch [11/18], Loss: 0.1294
	--> Final training Epoch [12/18], Loss: 0.1142
	--> Final training Epoch [13/18], Loss: 0.1138
	--> Final training Epoch [14/18], Loss: 0.0853
	--> Final training Epoch [15/18], Loss: 0.0963
	--> Final training Epoch [16/18], Loss: 0.0978
	--> Final training Epoch [17/18], Loss: 0.0691
	--> Final training Epoch [18/18], Loss: 0.0564

Final training took 0.062293052673339844 sec

TESTING
	--> Testing took 0.0080 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0823
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3383,  Current Best Accuracy: 0.8708,  Current Best Validation Loss: 0.3383

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8232, Validation Loss: 0.5443
	--> Epoch [2/100], Loss: 0.6277, Validation Loss: 0.4701
	--> Epoch [3/100], Loss: 0.5300, Validation Loss: 0.4147
	--> Epoch [4/100], Loss: 0.4305, Validation Loss: 0.3803
	--> Epoch [5/100], Loss: 0.3766, Validation Loss: 0.3537
	--> Epoch [6/100], Loss: 0.3579, Validation Loss: 0.3146
	--> Epoch [7/100], Loss: 0.2955, Validation Loss: 0.2967
	--> Epoch [8/100], Loss: 0.2425, Validation Loss: 0.2757
	--> Epoch [9/100], Loss: 0.2776, Validation Loss: 0.2776
	--> Epoch [10/100], Loss: 0.1904, Validation Loss: 0.2700
	--> Epoch [11/100], Loss: 0.1985, Validation Loss: 0.2503
	--> Epoch [12/100], Loss: 0.1723, Validation Loss: 0.2384
	--> Epoch [13/100], Loss: 0.1538, Validation Loss: 0.2409
	--> Epoch [14/100], Loss: 0.1484, Validation Loss: 0.2458
	--> Epoch [15/100], Loss: 0.1539, Validation Loss: 0.2528
Early stopping
	--> Training for Fold 1 took 0.05300450325012207 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6931, Validation Loss: 0.5786
	--> Epoch [2/100], Loss: 0.6038, Validation Loss: 0.5220
	--> Epoch [3/100], Loss: 0.5242, Validation Loss: 0.4716
	--> Epoch [4/100], Loss: 0.4545, Validation Loss: 0.4224
	--> Epoch [5/100], Loss: 0.4147, Validation Loss: 0.3865
	--> Epoch [6/100], Loss: 0.3925, Validation Loss: 0.3596
	--> Epoch [7/100], Loss: 0.3409, Validation Loss: 0.3223
	--> Epoch [8/100], Loss: 0.3487, Validation Loss: 0.3044
	--> Epoch [9/100], Loss: 0.2821, Validation Loss: 0.2893
	--> Epoch [10/100], Loss: 0.2495, Validation Loss: 0.2826
	--> Epoch [11/100], Loss: 0.2528, Validation Loss: 0.2742
	--> Epoch [12/100], Loss: 0.1983, Validation Loss: 0.2730
	--> Epoch [13/100], Loss: 0.2186, Validation Loss: 0.2653
	--> Epoch [14/100], Loss: 0.2071, Validation Loss: 0.2562
	--> Epoch [15/100], Loss: 0.2008, Validation Loss: 0.2588
	--> Epoch [16/100], Loss: 0.1965, Validation Loss: 0.2414
	--> Epoch [17/100], Loss: 0.1714, Validation Loss: 0.2366
	--> Epoch [18/100], Loss: 0.1736, Validation Loss: 0.2425
	--> Epoch [19/100], Loss: 0.1381, Validation Loss: 0.2525
	--> Epoch [20/100], Loss: 0.1352, Validation Loss: 0.2442
Early stopping
	--> Training for Fold 2 took 0.06989073753356934 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6852, Validation Loss: 0.6581
	--> Epoch [2/100], Loss: 0.5792, Validation Loss: 0.5826
	--> Epoch [3/100], Loss: 0.4625, Validation Loss: 0.5160
	--> Epoch [4/100], Loss: 0.3714, Validation Loss: 0.4669
	--> Epoch [5/100], Loss: 0.3209, Validation Loss: 0.4366
	--> Epoch [6/100], Loss: 0.2894, Validation Loss: 0.4078
	--> Epoch [7/100], Loss: 0.2388, Validation Loss: 0.3854
	--> Epoch [8/100], Loss: 0.1829, Validation Loss: 0.3699
	--> Epoch [9/100], Loss: 0.1819, Validation Loss: 0.3478
	--> Epoch [10/100], Loss: 0.1679, Validation Loss: 0.3487
	--> Epoch [11/100], Loss: 0.1477, Validation Loss: 0.3213
	--> Epoch [12/100], Loss: 0.0912, Validation Loss: 0.3139
	--> Epoch [13/100], Loss: 0.1160, Validation Loss: 0.3110
	--> Epoch [14/100], Loss: 0.0992, Validation Loss: 0.3099
	--> Epoch [15/100], Loss: 0.0789, Validation Loss: 0.3048
	--> Epoch [16/100], Loss: 0.0998, Validation Loss: 0.2949
	--> Epoch [17/100], Loss: 0.0953, Validation Loss: 0.2943
	--> Epoch [18/100], Loss: 0.0494, Validation Loss: 0.2826
	--> Epoch [19/100], Loss: 0.0636, Validation Loss: 0.2803
	--> Epoch [20/100], Loss: 0.0676, Validation Loss: 0.2779
	--> Epoch [21/100], Loss: 0.0498, Validation Loss: 0.2731
	--> Epoch [22/100], Loss: 0.0680, Validation Loss: 0.2661
	--> Epoch [23/100], Loss: 0.0750, Validation Loss: 0.2752
	--> Epoch [24/100], Loss: 0.0477, Validation Loss: 0.2845
	--> Epoch [25/100], Loss: 0.0459, Validation Loss: 0.2906
Early stopping
	--> Training for Fold 3 took 0.0953817367553711 sec, using 25 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7095, Validation Loss: 0.6979
	--> Epoch [2/100], Loss: 0.5356, Validation Loss: 0.6267
	--> Epoch [3/100], Loss: 0.4781, Validation Loss: 0.5974
	--> Epoch [4/100], Loss: 0.3983, Validation Loss: 0.5129
	--> Epoch [5/100], Loss: 0.3351, Validation Loss: 0.4668
	--> Epoch [6/100], Loss: 0.2665, Validation Loss: 0.4288
	--> Epoch [7/100], Loss: 0.2536, Validation Loss: 0.4114
	--> Epoch [8/100], Loss: 0.1961, Validation Loss: 0.3806
	--> Epoch [9/100], Loss: 0.1952, Validation Loss: 0.3759
	--> Epoch [10/100], Loss: 0.1138, Validation Loss: 0.3620
	--> Epoch [11/100], Loss: 0.1262, Validation Loss: 0.3506
	--> Epoch [12/100], Loss: 0.1014, Validation Loss: 0.3653
	--> Epoch [13/100], Loss: 0.0740, Validation Loss: 0.3537
	--> Epoch [14/100], Loss: 0.0816, Validation Loss: 0.3223
	--> Epoch [15/100], Loss: 0.1047, Validation Loss: 0.3180
	--> Epoch [16/100], Loss: 0.0627, Validation Loss: 0.3182
	--> Epoch [17/100], Loss: 0.0664, Validation Loss: 0.3095
	--> Epoch [18/100], Loss: 0.0952, Validation Loss: 0.3175
	--> Epoch [19/100], Loss: 0.1135, Validation Loss: 0.3126
	--> Epoch [20/100], Loss: 0.0868, Validation Loss: 0.3171
Early stopping
	--> Training for Fold 4 took 0.07519364356994629 sec, using 20 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6828, Validation Loss: 0.6409
	--> Epoch [2/100], Loss: 0.5646, Validation Loss: 0.5832
	--> Epoch [3/100], Loss: 0.4783, Validation Loss: 0.5392
	--> Epoch [4/100], Loss: 0.4249, Validation Loss: 0.5034
	--> Epoch [5/100], Loss: 0.3673, Validation Loss: 0.4792
	--> Epoch [6/100], Loss: 0.3044, Validation Loss: 0.4733
	--> Epoch [7/100], Loss: 0.3005, Validation Loss: 0.4625
	--> Epoch [8/100], Loss: 0.2507, Validation Loss: 0.4495
	--> Epoch [9/100], Loss: 0.2167, Validation Loss: 0.4369
	--> Epoch [10/100], Loss: 0.1973, Validation Loss: 0.4272
	--> Epoch [11/100], Loss: 0.2424, Validation Loss: 0.4265
	--> Epoch [12/100], Loss: 0.2043, Validation Loss: 0.4096
	--> Epoch [13/100], Loss: 0.1351, Validation Loss: 0.4093
	--> Epoch [14/100], Loss: 0.1988, Validation Loss: 0.4208
	--> Epoch [15/100], Loss: 0.1464, Validation Loss: 0.4214
	--> Epoch [16/100], Loss: 0.1731, Validation Loss: 0.4133
Early stopping
	--> Training for Fold 5 took 0.05830526351928711 sec, using 16 epochs

Median number of epochs used: 20 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/20], Loss: 0.6914
	--> Final training Epoch [2/20], Loss: 0.5800
	--> Final training Epoch [3/20], Loss: 0.4842
	--> Final training Epoch [4/20], Loss: 0.3956
	--> Final training Epoch [5/20], Loss: 0.3219
	--> Final training Epoch [6/20], Loss: 0.2721
	--> Final training Epoch [7/20], Loss: 0.2360
	--> Final training Epoch [8/20], Loss: 0.1907
	--> Final training Epoch [9/20], Loss: 0.1492
	--> Final training Epoch [10/20], Loss: 0.1342
	--> Final training Epoch [11/20], Loss: 0.1153
	--> Final training Epoch [12/20], Loss: 0.1348
	--> Final training Epoch [13/20], Loss: 0.1187
	--> Final training Epoch [14/20], Loss: 0.1071
	--> Final training Epoch [15/20], Loss: 0.0962
	--> Final training Epoch [16/20], Loss: 0.0842
	--> Final training Epoch [17/20], Loss: 0.0713
	--> Final training Epoch [18/20], Loss: 0.0739
	--> Final training Epoch [19/20], Loss: 0.0656
	--> Final training Epoch [20/20], Loss: 0.0576

Final training took 0.06766080856323242 sec

TESTING
	--> Testing took 0.0089 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 1.2222
	--> Final Precision: 0.6154
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6154
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8608, Validation Loss: 0.3166,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3166
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8602, Validation Loss: 0.3293,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3166
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7942, Validation Loss: 0.3970,  Current Best Accuracy: 0.8608,  Current Best Validation Loss: 0.3166

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6683, Validation Loss: 0.5920
	--> Epoch [2/100], Loss: 0.5515, Validation Loss: 0.5487
	--> Epoch [3/100], Loss: 0.4916, Validation Loss: 0.5107
	--> Epoch [4/100], Loss: 0.4124, Validation Loss: 0.4621
	--> Epoch [5/100], Loss: 0.3629, Validation Loss: 0.4192
	--> Epoch [6/100], Loss: 0.3199, Validation Loss: 0.4083
	--> Epoch [7/100], Loss: 0.2614, Validation Loss: 0.3940
	--> Epoch [8/100], Loss: 0.2374, Validation Loss: 0.3831
	--> Epoch [9/100], Loss: 0.2337, Validation Loss: 0.3778
	--> Epoch [10/100], Loss: 0.1821, Validation Loss: 0.3464
	--> Epoch [11/100], Loss: 0.1966, Validation Loss: 0.3434
	--> Epoch [12/100], Loss: 0.1293, Validation Loss: 0.3248
	--> Epoch [13/100], Loss: 0.1276, Validation Loss: 0.3388
	--> Epoch [14/100], Loss: 0.1831, Validation Loss: 0.3413
	--> Epoch [15/100], Loss: 0.2164, Validation Loss: 0.3402
Early stopping
	--> Training for Fold 1 took 0.05317258834838867 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7189, Validation Loss: 0.5867
	--> Epoch [2/100], Loss: 0.6131, Validation Loss: 0.4872
	--> Epoch [3/100], Loss: 0.5398, Validation Loss: 0.4241
	--> Epoch [4/100], Loss: 0.4639, Validation Loss: 0.3798
	--> Epoch [5/100], Loss: 0.3895, Validation Loss: 0.3487
	--> Epoch [6/100], Loss: 0.3693, Validation Loss: 0.3372
	--> Epoch [7/100], Loss: 0.2912, Validation Loss: 0.3310
	--> Epoch [8/100], Loss: 0.2658, Validation Loss: 0.2974
	--> Epoch [9/100], Loss: 0.1870, Validation Loss: 0.2873
	--> Epoch [10/100], Loss: 0.1984, Validation Loss: 0.2782
	--> Epoch [11/100], Loss: 0.2085, Validation Loss: 0.2699
	--> Epoch [12/100], Loss: 0.1833, Validation Loss: 0.2627
	--> Epoch [13/100], Loss: 0.1888, Validation Loss: 0.2581
	--> Epoch [14/100], Loss: 0.1591, Validation Loss: 0.2504
	--> Epoch [15/100], Loss: 0.1634, Validation Loss: 0.2347
	--> Epoch [16/100], Loss: 0.0956, Validation Loss: 0.2387
	--> Epoch [17/100], Loss: 0.1253, Validation Loss: 0.2329
	--> Epoch [18/100], Loss: 0.1422, Validation Loss: 0.2377
	--> Epoch [19/100], Loss: 0.1554, Validation Loss: 0.2517
	--> Epoch [20/100], Loss: 0.1245, Validation Loss: 0.2533
Early stopping
	--> Training for Fold 2 took 0.06882023811340332 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7338, Validation Loss: 0.6108
	--> Epoch [2/100], Loss: 0.6137, Validation Loss: 0.5581
	--> Epoch [3/100], Loss: 0.5345, Validation Loss: 0.5149
	--> Epoch [4/100], Loss: 0.4570, Validation Loss: 0.4874
	--> Epoch [5/100], Loss: 0.4102, Validation Loss: 0.4517
	--> Epoch [6/100], Loss: 0.3864, Validation Loss: 0.4144
	--> Epoch [7/100], Loss: 0.2769, Validation Loss: 0.3944
	--> Epoch [8/100], Loss: 0.2903, Validation Loss: 0.3734
	--> Epoch [9/100], Loss: 0.2460, Validation Loss: 0.3594
	--> Epoch [10/100], Loss: 0.2038, Validation Loss: 0.3543
	--> Epoch [11/100], Loss: 0.2177, Validation Loss: 0.3569
	--> Epoch [12/100], Loss: 0.1896, Validation Loss: 0.3416
	--> Epoch [13/100], Loss: 0.2071, Validation Loss: 0.3365
	--> Epoch [14/100], Loss: 0.1933, Validation Loss: 0.3218
	--> Epoch [15/100], Loss: 0.1158, Validation Loss: 0.3060
	--> Epoch [16/100], Loss: 0.1497, Validation Loss: 0.3036
	--> Epoch [17/100], Loss: 0.1589, Validation Loss: 0.3002
	--> Epoch [18/100], Loss: 0.1320, Validation Loss: 0.2993
	--> Epoch [19/100], Loss: 0.1191, Validation Loss: 0.2846
	--> Epoch [20/100], Loss: 0.1168, Validation Loss: 0.2765
	--> Epoch [21/100], Loss: 0.1796, Validation Loss: 0.2779
	--> Epoch [22/100], Loss: 0.1618, Validation Loss: 0.2622
	--> Epoch [23/100], Loss: 0.0814, Validation Loss: 0.2652
	--> Epoch [24/100], Loss: 0.1379, Validation Loss: 0.2648
	--> Epoch [25/100], Loss: 0.0989, Validation Loss: 0.2692
Early stopping
	--> Training for Fold 3 took 0.09320878982543945 sec, using 25 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7340, Validation Loss: 0.5255
	--> Epoch [2/100], Loss: 0.5715, Validation Loss: 0.4807
	--> Epoch [3/100], Loss: 0.4965, Validation Loss: 0.4377
	--> Epoch [4/100], Loss: 0.4411, Validation Loss: 0.3845
	--> Epoch [5/100], Loss: 0.3591, Validation Loss: 0.3632
	--> Epoch [6/100], Loss: 0.3257, Validation Loss: 0.3413
	--> Epoch [7/100], Loss: 0.3052, Validation Loss: 0.3345
	--> Epoch [8/100], Loss: 0.2596, Validation Loss: 0.3259
	--> Epoch [9/100], Loss: 0.2533, Validation Loss: 0.3188
	--> Epoch [10/100], Loss: 0.2065, Validation Loss: 0.3236
	--> Epoch [11/100], Loss: 0.2078, Validation Loss: 0.3097
	--> Epoch [12/100], Loss: 0.1866, Validation Loss: 0.3035
	--> Epoch [13/100], Loss: 0.2294, Validation Loss: 0.2984
	--> Epoch [14/100], Loss: 0.1474, Validation Loss: 0.3289
	--> Epoch [15/100], Loss: 0.1709, Validation Loss: 0.3250
	--> Epoch [16/100], Loss: 0.1582, Validation Loss: 0.3014
Early stopping
	--> Training for Fold 4 took 0.060976505279541016 sec, using 16 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.9053, Validation Loss: 0.5357
	--> Epoch [2/100], Loss: 0.6606, Validation Loss: 0.5244
	--> Epoch [3/100], Loss: 0.5583, Validation Loss: 0.5098
	--> Epoch [4/100], Loss: 0.4686, Validation Loss: 0.5115
	--> Epoch [5/100], Loss: 0.3729, Validation Loss: 0.5174
	--> Epoch [6/100], Loss: 0.3455, Validation Loss: 0.5241
Early stopping
	--> Training for Fold 5 took 0.023244857788085938 sec, using 6 epochs

Median number of epochs used: 16 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/16], Loss: 0.7143
	--> Final training Epoch [2/16], Loss: 0.6090
	--> Final training Epoch [3/16], Loss: 0.5326
	--> Final training Epoch [4/16], Loss: 0.4317
	--> Final training Epoch [5/16], Loss: 0.3773
	--> Final training Epoch [6/16], Loss: 0.3175
	--> Final training Epoch [7/16], Loss: 0.2894
	--> Final training Epoch [8/16], Loss: 0.2540
	--> Final training Epoch [9/16], Loss: 0.2107
	--> Final training Epoch [10/16], Loss: 0.2187
	--> Final training Epoch [11/16], Loss: 0.1943
	--> Final training Epoch [12/16], Loss: 0.1972
	--> Final training Epoch [13/16], Loss: 0.1549
	--> Final training Epoch [14/16], Loss: 0.1652
	--> Final training Epoch [15/16], Loss: 0.1695
	--> Final training Epoch [16/16], Loss: 0.1092

Final training took 0.05369377136230469 sec

TESTING
	--> Testing took 0.0090 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.9274
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8918, Validation Loss: 0.3316,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3518,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8591, Validation Loss: 0.3677,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3628,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3444,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8497, Validation Loss: 0.3618,  Current Best Accuracy: 0.8918,  Current Best Validation Loss: 0.3316

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7103, Validation Loss: 0.6540
	--> Epoch [2/100], Loss: 0.6063, Validation Loss: 0.5925
	--> Epoch [3/100], Loss: 0.5010, Validation Loss: 0.5272
	--> Epoch [4/100], Loss: 0.4410, Validation Loss: 0.4762
	--> Epoch [5/100], Loss: 0.3607, Validation Loss: 0.4322
	--> Epoch [6/100], Loss: 0.3121, Validation Loss: 0.3740
	--> Epoch [7/100], Loss: 0.2676, Validation Loss: 0.3559
	--> Epoch [8/100], Loss: 0.2366, Validation Loss: 0.3202
	--> Epoch [9/100], Loss: 0.2172, Validation Loss: 0.3058
	--> Epoch [10/100], Loss: 0.1416, Validation Loss: 0.2936
	--> Epoch [11/100], Loss: 0.1618, Validation Loss: 0.2796
	--> Epoch [12/100], Loss: 0.1586, Validation Loss: 0.2704
	--> Epoch [13/100], Loss: 0.1308, Validation Loss: 0.2732
	--> Epoch [14/100], Loss: 0.1417, Validation Loss: 0.2638
	--> Epoch [15/100], Loss: 0.1062, Validation Loss: 0.2586
	--> Epoch [16/100], Loss: 0.1438, Validation Loss: 0.2560
	--> Epoch [17/100], Loss: 0.1207, Validation Loss: 0.2524
	--> Epoch [18/100], Loss: 0.0784, Validation Loss: 0.2552
	--> Epoch [19/100], Loss: 0.1018, Validation Loss: 0.2506
	--> Epoch [20/100], Loss: 0.1143, Validation Loss: 0.2553
	--> Epoch [21/100], Loss: 0.0899, Validation Loss: 0.2567
	--> Epoch [22/100], Loss: 0.0830, Validation Loss: 0.2540
Early stopping
	--> Training for Fold 1 took 0.07973718643188477 sec, using 22 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7285, Validation Loss: 0.4837
	--> Epoch [2/100], Loss: 0.5414, Validation Loss: 0.4108
	--> Epoch [3/100], Loss: 0.4268, Validation Loss: 0.3258
	--> Epoch [4/100], Loss: 0.3337, Validation Loss: 0.2921
	--> Epoch [5/100], Loss: 0.2738, Validation Loss: 0.2699
	--> Epoch [6/100], Loss: 0.2256, Validation Loss: 0.2545
	--> Epoch [7/100], Loss: 0.1974, Validation Loss: 0.2419
	--> Epoch [8/100], Loss: 0.1617, Validation Loss: 0.2275
	--> Epoch [9/100], Loss: 0.1479, Validation Loss: 0.2248
	--> Epoch [10/100], Loss: 0.1250, Validation Loss: 0.2226
	--> Epoch [11/100], Loss: 0.1446, Validation Loss: 0.2158
	--> Epoch [12/100], Loss: 0.0759, Validation Loss: 0.2070
	--> Epoch [13/100], Loss: 0.0841, Validation Loss: 0.2010
	--> Epoch [14/100], Loss: 0.0743, Validation Loss: 0.1979
	--> Epoch [15/100], Loss: 0.0739, Validation Loss: 0.2002
	--> Epoch [16/100], Loss: 0.0775, Validation Loss: 0.2055
	--> Epoch [17/100], Loss: 0.0567, Validation Loss: 0.1978
	--> Epoch [18/100], Loss: 0.0514, Validation Loss: 0.2018
	--> Epoch [19/100], Loss: 0.0757, Validation Loss: 0.2106
	--> Epoch [20/100], Loss: 0.0248, Validation Loss: 0.2068
Early stopping
	--> Training for Fold 2 took 0.07395005226135254 sec, using 20 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7033, Validation Loss: 0.5780
	--> Epoch [2/100], Loss: 0.5357, Validation Loss: 0.5328
	--> Epoch [3/100], Loss: 0.4327, Validation Loss: 0.4845
	--> Epoch [4/100], Loss: 0.3519, Validation Loss: 0.4365
	--> Epoch [5/100], Loss: 0.2988, Validation Loss: 0.4154
	--> Epoch [6/100], Loss: 0.2457, Validation Loss: 0.3852
	--> Epoch [7/100], Loss: 0.2180, Validation Loss: 0.3750
	--> Epoch [8/100], Loss: 0.1978, Validation Loss: 0.3613
	--> Epoch [9/100], Loss: 0.1337, Validation Loss: 0.3542
	--> Epoch [10/100], Loss: 0.1391, Validation Loss: 0.3479
	--> Epoch [11/100], Loss: 0.1111, Validation Loss: 0.3372
	--> Epoch [12/100], Loss: 0.0837, Validation Loss: 0.3306
	--> Epoch [13/100], Loss: 0.0653, Validation Loss: 0.3195
	--> Epoch [14/100], Loss: 0.0931, Validation Loss: 0.3223
	--> Epoch [15/100], Loss: 0.0848, Validation Loss: 0.3211
	--> Epoch [16/100], Loss: 0.0990, Validation Loss: 0.3137
	--> Epoch [17/100], Loss: 0.0602, Validation Loss: 0.3140
	--> Epoch [18/100], Loss: 0.0683, Validation Loss: 0.3190
	--> Epoch [19/100], Loss: 0.0741, Validation Loss: 0.3268
Early stopping
	--> Training for Fold 3 took 0.07423067092895508 sec, using 19 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7281, Validation Loss: 0.6568
	--> Epoch [2/100], Loss: 0.5394, Validation Loss: 0.5377
	--> Epoch [3/100], Loss: 0.4389, Validation Loss: 0.4727
	--> Epoch [4/100], Loss: 0.3455, Validation Loss: 0.4019
	--> Epoch [5/100], Loss: 0.2877, Validation Loss: 0.3693
	--> Epoch [6/100], Loss: 0.1934, Validation Loss: 0.3614
	--> Epoch [7/100], Loss: 0.1857, Validation Loss: 0.3506
	--> Epoch [8/100], Loss: 0.1445, Validation Loss: 0.3365
	--> Epoch [9/100], Loss: 0.1519, Validation Loss: 0.3165
	--> Epoch [10/100], Loss: 0.1025, Validation Loss: 0.3108
	--> Epoch [11/100], Loss: 0.0926, Validation Loss: 0.3170
	--> Epoch [12/100], Loss: 0.0915, Validation Loss: 0.3136
	--> Epoch [13/100], Loss: 0.0758, Validation Loss: 0.3161
Early stopping
	--> Training for Fold 4 took 0.04864954948425293 sec, using 13 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7490, Validation Loss: 0.8546
	--> Epoch [2/100], Loss: 0.5830, Validation Loss: 0.8192
	--> Epoch [3/100], Loss: 0.4982, Validation Loss: 0.7921
	--> Epoch [4/100], Loss: 0.4231, Validation Loss: 0.7334
	--> Epoch [5/100], Loss: 0.3391, Validation Loss: 0.7043
	--> Epoch [6/100], Loss: 0.2880, Validation Loss: 0.6682
	--> Epoch [7/100], Loss: 0.2701, Validation Loss: 0.6591
	--> Epoch [8/100], Loss: 0.2089, Validation Loss: 0.6595
	--> Epoch [9/100], Loss: 0.2019, Validation Loss: 0.6383
	--> Epoch [10/100], Loss: 0.1793, Validation Loss: 0.6356
	--> Epoch [11/100], Loss: 0.1562, Validation Loss: 0.6305
	--> Epoch [12/100], Loss: 0.1857, Validation Loss: 0.6348
	--> Epoch [13/100], Loss: 0.1750, Validation Loss: 0.6363
	--> Epoch [14/100], Loss: 0.1073, Validation Loss: 0.6558
Early stopping
	--> Training for Fold 5 took 0.05457758903503418 sec, using 14 epochs

Median number of epochs used: 19 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/19], Loss: 0.7145
	--> Final training Epoch [2/19], Loss: 0.5301
	--> Final training Epoch [3/19], Loss: 0.4308
	--> Final training Epoch [4/19], Loss: 0.3569
	--> Final training Epoch [5/19], Loss: 0.3338
	--> Final training Epoch [6/19], Loss: 0.2455
	--> Final training Epoch [7/19], Loss: 0.2111
	--> Final training Epoch [8/19], Loss: 0.1751
	--> Final training Epoch [9/19], Loss: 0.1310
	--> Final training Epoch [10/19], Loss: 0.1379
	--> Final training Epoch [11/19], Loss: 0.1227
	--> Final training Epoch [12/19], Loss: 0.1108
	--> Final training Epoch [13/19], Loss: 0.1074
	--> Final training Epoch [14/19], Loss: 0.1030
	--> Final training Epoch [15/19], Loss: 0.0828
	--> Final training Epoch [16/19], Loss: 0.0962
	--> Final training Epoch [17/19], Loss: 0.0890
	--> Final training Epoch [18/19], Loss: 0.0779
	--> Final training Epoch [19/19], Loss: 0.0576

Final training took 0.05989813804626465 sec

TESTING
	--> Testing took 0.0080 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0479
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3008,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3676,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8164, Validation Loss: 0.3641,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3106,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3692,  Current Best Accuracy: 0.8602,  Current Best Validation Loss: 0.3008

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8115, Validation Loss: 0.5462
	--> Epoch [2/100], Loss: 0.7870, Validation Loss: 0.4890
	--> Epoch [3/100], Loss: 0.6599, Validation Loss: 0.4341
	--> Epoch [4/100], Loss: 0.5679, Validation Loss: 0.3967
	--> Epoch [5/100], Loss: 0.5244, Validation Loss: 0.3723
	--> Epoch [6/100], Loss: 0.4836, Validation Loss: 0.3612
	--> Epoch [7/100], Loss: 0.4242, Validation Loss: 0.3392
	--> Epoch [8/100], Loss: 0.4365, Validation Loss: 0.3055
	--> Epoch [9/100], Loss: 0.3922, Validation Loss: 0.2966
	--> Epoch [10/100], Loss: 0.3798, Validation Loss: 0.2855
	--> Epoch [11/100], Loss: 0.3714, Validation Loss: 0.2754
	--> Epoch [12/100], Loss: 0.3287, Validation Loss: 0.2655
	--> Epoch [13/100], Loss: 0.4135, Validation Loss: 0.2632
	--> Epoch [14/100], Loss: 0.3489, Validation Loss: 0.2556
	--> Epoch [15/100], Loss: 0.3073, Validation Loss: 0.2524
	--> Epoch [16/100], Loss: 0.3286, Validation Loss: 0.2467
	--> Epoch [17/100], Loss: 0.2972, Validation Loss: 0.2354
	--> Epoch [18/100], Loss: 0.3434, Validation Loss: 0.2295
	--> Epoch [19/100], Loss: 0.2786, Validation Loss: 0.2286
	--> Epoch [20/100], Loss: 0.3117, Validation Loss: 0.2220
	--> Epoch [21/100], Loss: 0.2678, Validation Loss: 0.2148
	--> Epoch [22/100], Loss: 0.3299, Validation Loss: 0.2158
	--> Epoch [23/100], Loss: 0.2915, Validation Loss: 0.2163
	--> Epoch [24/100], Loss: 0.3009, Validation Loss: 0.2152
Early stopping
	--> Training for Fold 1 took 0.08725118637084961 sec, using 24 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7191, Validation Loss: 0.6137
	--> Epoch [2/100], Loss: 0.6403, Validation Loss: 0.5057
	--> Epoch [3/100], Loss: 0.6569, Validation Loss: 0.4755
	--> Epoch [4/100], Loss: 0.5521, Validation Loss: 0.4280
	--> Epoch [5/100], Loss: 0.5112, Validation Loss: 0.4028
	--> Epoch [6/100], Loss: 0.4684, Validation Loss: 0.3907
	--> Epoch [7/100], Loss: 0.4706, Validation Loss: 0.3555
	--> Epoch [8/100], Loss: 0.3999, Validation Loss: 0.3238
	--> Epoch [9/100], Loss: 0.3433, Validation Loss: 0.3102
	--> Epoch [10/100], Loss: 0.3728, Validation Loss: 0.3165
	--> Epoch [11/100], Loss: 0.3392, Validation Loss: 0.3249
	--> Epoch [12/100], Loss: 0.2970, Validation Loss: 0.2972
	--> Epoch [13/100], Loss: 0.3010, Validation Loss: 0.2846
	--> Epoch [14/100], Loss: 0.3394, Validation Loss: 0.2866
	--> Epoch [15/100], Loss: 0.2709, Validation Loss: 0.2777
	--> Epoch [16/100], Loss: 0.3404, Validation Loss: 0.2732
	--> Epoch [17/100], Loss: 0.2311, Validation Loss: 0.2715
	--> Epoch [18/100], Loss: 0.2551, Validation Loss: 0.2387
	--> Epoch [19/100], Loss: 0.2774, Validation Loss: 0.2549
	--> Epoch [20/100], Loss: 0.2223, Validation Loss: 0.2559
	--> Epoch [21/100], Loss: 0.2556, Validation Loss: 0.2518
Early stopping
	--> Training for Fold 2 took 0.07558751106262207 sec, using 21 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6741, Validation Loss: 0.5844
	--> Epoch [2/100], Loss: 0.6044, Validation Loss: 0.5661
	--> Epoch [3/100], Loss: 0.5621, Validation Loss: 0.5211
	--> Epoch [4/100], Loss: 0.5041, Validation Loss: 0.4860
	--> Epoch [5/100], Loss: 0.4619, Validation Loss: 0.4562
	--> Epoch [6/100], Loss: 0.4118, Validation Loss: 0.4389
	--> Epoch [7/100], Loss: 0.4222, Validation Loss: 0.4224
	--> Epoch [8/100], Loss: 0.3246, Validation Loss: 0.3887
	--> Epoch [9/100], Loss: 0.3212, Validation Loss: 0.3805
	--> Epoch [10/100], Loss: 0.3744, Validation Loss: 0.3778
	--> Epoch [11/100], Loss: 0.3280, Validation Loss: 0.3616
	--> Epoch [12/100], Loss: 0.2440, Validation Loss: 0.3460
	--> Epoch [13/100], Loss: 0.2686, Validation Loss: 0.3526
	--> Epoch [14/100], Loss: 0.2955, Validation Loss: 0.3471
	--> Epoch [15/100], Loss: 0.2720, Validation Loss: 0.3556
Early stopping
	--> Training for Fold 3 took 0.05664181709289551 sec, using 15 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7313, Validation Loss: 0.5804
	--> Epoch [2/100], Loss: 0.7298, Validation Loss: 0.5234
	--> Epoch [3/100], Loss: 0.6006, Validation Loss: 0.4856
	--> Epoch [4/100], Loss: 0.5431, Validation Loss: 0.4557
	--> Epoch [5/100], Loss: 0.5312, Validation Loss: 0.4286
	--> Epoch [6/100], Loss: 0.4460, Validation Loss: 0.4198
	--> Epoch [7/100], Loss: 0.4346, Validation Loss: 0.3865
	--> Epoch [8/100], Loss: 0.3763, Validation Loss: 0.3571
	--> Epoch [9/100], Loss: 0.3922, Validation Loss: 0.3620
	--> Epoch [10/100], Loss: 0.3814, Validation Loss: 0.3588
	--> Epoch [11/100], Loss: 0.3378, Validation Loss: 0.3552
	--> Epoch [12/100], Loss: 0.3318, Validation Loss: 0.3430
	--> Epoch [13/100], Loss: 0.3033, Validation Loss: 0.3236
	--> Epoch [14/100], Loss: 0.3431, Validation Loss: 0.3165
	--> Epoch [15/100], Loss: 0.2893, Validation Loss: 0.3123
	--> Epoch [16/100], Loss: 0.2548, Validation Loss: 0.3065
	--> Epoch [17/100], Loss: 0.2399, Validation Loss: 0.2908
	--> Epoch [18/100], Loss: 0.2383, Validation Loss: 0.2813
	--> Epoch [19/100], Loss: 0.2884, Validation Loss: 0.2896
	--> Epoch [20/100], Loss: 0.2230, Validation Loss: 0.2830
	--> Epoch [21/100], Loss: 0.2685, Validation Loss: 0.2881
Early stopping
	--> Training for Fold 4 took 0.07644820213317871 sec, using 21 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7141, Validation Loss: 0.6758
	--> Epoch [2/100], Loss: 0.6706, Validation Loss: 0.6523
	--> Epoch [3/100], Loss: 0.5875, Validation Loss: 0.6515
	--> Epoch [4/100], Loss: 0.5341, Validation Loss: 0.6631
	--> Epoch [5/100], Loss: 0.4819, Validation Loss: 0.6712
	--> Epoch [6/100], Loss: 0.5257, Validation Loss: 0.6540
Early stopping
	--> Training for Fold 5 took 0.020227670669555664 sec, using 6 epochs

Median number of epochs used: 21 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/21], Loss: 0.7290
	--> Final training Epoch [2/21], Loss: 0.5561
	--> Final training Epoch [3/21], Loss: 0.5098
	--> Final training Epoch [4/21], Loss: 0.5361
	--> Final training Epoch [5/21], Loss: 0.4111
	--> Final training Epoch [6/21], Loss: 0.3941
	--> Final training Epoch [7/21], Loss: 0.3642
	--> Final training Epoch [8/21], Loss: 0.3783
	--> Final training Epoch [9/21], Loss: 0.2977
	--> Final training Epoch [10/21], Loss: 0.3474
	--> Final training Epoch [11/21], Loss: 0.2789
	--> Final training Epoch [12/21], Loss: 0.2888
	--> Final training Epoch [13/21], Loss: 0.3279
	--> Final training Epoch [14/21], Loss: 0.2918
	--> Final training Epoch [15/21], Loss: 0.2746
	--> Final training Epoch [16/21], Loss: 0.2313
	--> Final training Epoch [17/21], Loss: 0.2670
	--> Final training Epoch [18/21], Loss: 0.2897
	--> Final training Epoch [19/21], Loss: 0.2703
	--> Final training Epoch [20/21], Loss: 0.3039
	--> Final training Epoch [21/21], Loss: 0.2370

Final training took 0.07116532325744629 sec

TESTING
	--> Testing took 0.0076 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8711
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3225,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3225
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3445,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.3225

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7002, Validation Loss: 0.5752
	--> Epoch [2/100], Loss: 0.5396, Validation Loss: 0.4865
	--> Epoch [3/100], Loss: 0.4400, Validation Loss: 0.4285
	--> Epoch [4/100], Loss: 0.3524, Validation Loss: 0.3978
	--> Epoch [5/100], Loss: 0.2893, Validation Loss: 0.3636
	--> Epoch [6/100], Loss: 0.2288, Validation Loss: 0.3586
	--> Epoch [7/100], Loss: 0.2088, Validation Loss: 0.3239
	--> Epoch [8/100], Loss: 0.1789, Validation Loss: 0.3251
	--> Epoch [9/100], Loss: 0.1504, Validation Loss: 0.3041
	--> Epoch [10/100], Loss: 0.1215, Validation Loss: 0.2940
	--> Epoch [11/100], Loss: 0.1128, Validation Loss: 0.2842
	--> Epoch [12/100], Loss: 0.1193, Validation Loss: 0.2832
	--> Epoch [13/100], Loss: 0.1421, Validation Loss: 0.2982
	--> Epoch [14/100], Loss: 0.1182, Validation Loss: 0.2917
	--> Epoch [15/100], Loss: 0.1092, Validation Loss: 0.2880
Early stopping
	--> Training for Fold 1 took 0.0629417896270752 sec, using 15 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7214, Validation Loss: 0.6232
	--> Epoch [2/100], Loss: 0.5567, Validation Loss: 0.5491
	--> Epoch [3/100], Loss: 0.5010, Validation Loss: 0.5001
	--> Epoch [4/100], Loss: 0.4256, Validation Loss: 0.4706
	--> Epoch [5/100], Loss: 0.3621, Validation Loss: 0.3944
	--> Epoch [6/100], Loss: 0.3112, Validation Loss: 0.3800
	--> Epoch [7/100], Loss: 0.2599, Validation Loss: 0.3511
	--> Epoch [8/100], Loss: 0.2600, Validation Loss: 0.3341
	--> Epoch [9/100], Loss: 0.2141, Validation Loss: 0.3194
	--> Epoch [10/100], Loss: 0.1978, Validation Loss: 0.3048
	--> Epoch [11/100], Loss: 0.1532, Validation Loss: 0.3083
	--> Epoch [12/100], Loss: 0.2102, Validation Loss: 0.2887
	--> Epoch [13/100], Loss: 0.1806, Validation Loss: 0.2770
	--> Epoch [14/100], Loss: 0.1648, Validation Loss: 0.2833
	--> Epoch [15/100], Loss: 0.1602, Validation Loss: 0.2774
	--> Epoch [16/100], Loss: 0.1593, Validation Loss: 0.2717
	--> Epoch [17/100], Loss: 0.1385, Validation Loss: 0.2572
	--> Epoch [18/100], Loss: 0.1693, Validation Loss: 0.2562
	--> Epoch [19/100], Loss: 0.1116, Validation Loss: 0.2598
	--> Epoch [20/100], Loss: 0.1397, Validation Loss: 0.2471
	--> Epoch [21/100], Loss: 0.1613, Validation Loss: 0.2442
	--> Epoch [22/100], Loss: 0.1463, Validation Loss: 0.2265
	--> Epoch [23/100], Loss: 0.0759, Validation Loss: 0.2379
	--> Epoch [24/100], Loss: 0.1448, Validation Loss: 0.2417
	--> Epoch [25/100], Loss: 0.0994, Validation Loss: 0.2453
Early stopping
	--> Training for Fold 2 took 0.09597897529602051 sec, using 25 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6699, Validation Loss: 0.5659
	--> Epoch [2/100], Loss: 0.5325, Validation Loss: 0.5069
	--> Epoch [3/100], Loss: 0.4624, Validation Loss: 0.4434
	--> Epoch [4/100], Loss: 0.3479, Validation Loss: 0.3937
	--> Epoch [5/100], Loss: 0.2663, Validation Loss: 0.3557
	--> Epoch [6/100], Loss: 0.2515, Validation Loss: 0.3292
	--> Epoch [7/100], Loss: 0.2202, Validation Loss: 0.3044
	--> Epoch [8/100], Loss: 0.1854, Validation Loss: 0.2800
	--> Epoch [9/100], Loss: 0.1329, Validation Loss: 0.2810
	--> Epoch [10/100], Loss: 0.1351, Validation Loss: 0.2797
	--> Epoch [11/100], Loss: 0.1330, Validation Loss: 0.2718
	--> Epoch [12/100], Loss: 0.1215, Validation Loss: 0.2617
	--> Epoch [13/100], Loss: 0.1133, Validation Loss: 0.2600
	--> Epoch [14/100], Loss: 0.1115, Validation Loss: 0.2287
	--> Epoch [15/100], Loss: 0.1162, Validation Loss: 0.2311
	--> Epoch [16/100], Loss: 0.1077, Validation Loss: 0.2342
	--> Epoch [17/100], Loss: 0.0865, Validation Loss: 0.2187
	--> Epoch [18/100], Loss: 0.1050, Validation Loss: 0.2278
	--> Epoch [19/100], Loss: 0.0517, Validation Loss: 0.2265
	--> Epoch [20/100], Loss: 0.0816, Validation Loss: 0.2300
Early stopping
	--> Training for Fold 3 took 0.07751822471618652 sec, using 20 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7115, Validation Loss: 0.6330
	--> Epoch [2/100], Loss: 0.5619, Validation Loss: 0.5414
	--> Epoch [3/100], Loss: 0.4655, Validation Loss: 0.4988
	--> Epoch [4/100], Loss: 0.3665, Validation Loss: 0.4276
	--> Epoch [5/100], Loss: 0.3430, Validation Loss: 0.4094
	--> Epoch [6/100], Loss: 0.3034, Validation Loss: 0.3964
	--> Epoch [7/100], Loss: 0.2298, Validation Loss: 0.3772
	--> Epoch [8/100], Loss: 0.2402, Validation Loss: 0.3580
	--> Epoch [9/100], Loss: 0.1651, Validation Loss: 0.3541
	--> Epoch [10/100], Loss: 0.1401, Validation Loss: 0.3474
	--> Epoch [11/100], Loss: 0.1208, Validation Loss: 0.3380
	--> Epoch [12/100], Loss: 0.1247, Validation Loss: 0.3331
	--> Epoch [13/100], Loss: 0.0902, Validation Loss: 0.3361
	--> Epoch [14/100], Loss: 0.0667, Validation Loss: 0.3366
	--> Epoch [15/100], Loss: 0.0884, Validation Loss: 0.3441
Early stopping
	--> Training for Fold 4 took 0.057772159576416016 sec, using 15 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6746, Validation Loss: 0.7109
	--> Epoch [2/100], Loss: 0.5439, Validation Loss: 0.6797
	--> Epoch [3/100], Loss: 0.4477, Validation Loss: 0.6488
	--> Epoch [4/100], Loss: 0.3726, Validation Loss: 0.6319
	--> Epoch [5/100], Loss: 0.2884, Validation Loss: 0.6088
	--> Epoch [6/100], Loss: 0.2633, Validation Loss: 0.5969
	--> Epoch [7/100], Loss: 0.2281, Validation Loss: 0.5855
	--> Epoch [8/100], Loss: 0.1727, Validation Loss: 0.5791
	--> Epoch [9/100], Loss: 0.1673, Validation Loss: 0.5736
	--> Epoch [10/100], Loss: 0.1616, Validation Loss: 0.5555
	--> Epoch [11/100], Loss: 0.1405, Validation Loss: 0.5717
	--> Epoch [12/100], Loss: 0.1171, Validation Loss: 0.5973
	--> Epoch [13/100], Loss: 0.0907, Validation Loss: 0.6043
Early stopping
	--> Training for Fold 5 took 0.0471651554107666 sec, using 13 epochs

Median number of epochs used: 15 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/15], Loss: 0.7073
	--> Final training Epoch [2/15], Loss: 0.5758
	--> Final training Epoch [3/15], Loss: 0.4438
	--> Final training Epoch [4/15], Loss: 0.3844
	--> Final training Epoch [5/15], Loss: 0.3262
	--> Final training Epoch [6/15], Loss: 0.2786
	--> Final training Epoch [7/15], Loss: 0.2108
	--> Final training Epoch [8/15], Loss: 0.1790
	--> Final training Epoch [9/15], Loss: 0.1589
	--> Final training Epoch [10/15], Loss: 0.1430
	--> Final training Epoch [11/15], Loss: 0.1507
	--> Final training Epoch [12/15], Loss: 0.1358
	--> Final training Epoch [13/15], Loss: 0.1107
	--> Final training Epoch [14/15], Loss: 0.0846
	--> Final training Epoch [15/15], Loss: 0.1033

Final training took 0.04893755912780762 sec

TESTING
	--> Testing took 0.0087 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9631
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8924, Validation Loss: 0.3070,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3121,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.3366,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3539,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8713, Validation Loss: 0.3432,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8696, Validation Loss: 0.3677,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3483,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3583,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.01, Batch Size: 128, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3445,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3209,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3532,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8480, Validation Loss: 0.3504,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3619,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8708, Validation Loss: 0.3190,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3350,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8263, Validation Loss: 0.3252,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8047, Validation Loss: 0.3749,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3888,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8708, Validation Loss: 0.3389,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8813, Validation Loss: 0.3186,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8275, Validation Loss: 0.4039,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8386, Validation Loss: 0.3209,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 0.3747,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8386, Validation Loss: 0.3234,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3234,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8158, Validation Loss: 0.3694,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8924, Validation Loss: 0.3596,  Current Best Accuracy: 0.8924,  Current Best Validation Loss: 0.3070

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.9283, Validation Loss: 0.5745
	--> Epoch [2/100], Loss: 0.7066, Validation Loss: 0.5037
	--> Epoch [3/100], Loss: 0.4351, Validation Loss: 0.4584
	--> Epoch [4/100], Loss: 0.3157, Validation Loss: 0.4239
	--> Epoch [5/100], Loss: 0.4368, Validation Loss: 0.3922
	--> Epoch [6/100], Loss: 0.1816, Validation Loss: 0.3693
	--> Epoch [7/100], Loss: 0.2682, Validation Loss: 0.3521
	--> Epoch [8/100], Loss: 0.1603, Validation Loss: 0.3318
	--> Epoch [9/100], Loss: 0.1578, Validation Loss: 0.3175
	--> Epoch [10/100], Loss: 0.2021, Validation Loss: 0.3094
	--> Epoch [11/100], Loss: 0.3811, Validation Loss: 0.3044
	--> Epoch [12/100], Loss: 0.0239, Validation Loss: 0.2991
	--> Epoch [13/100], Loss: 0.0217, Validation Loss: 0.2939
	--> Epoch [14/100], Loss: 0.1669, Validation Loss: 0.2936
	--> Epoch [15/100], Loss: 0.0135, Validation Loss: 0.2965
	--> Epoch [16/100], Loss: 0.0265, Validation Loss: 0.2962
	--> Epoch [17/100], Loss: 0.0711, Validation Loss: 0.2969
Early stopping
	--> Training for Fold 1 took 0.8361239433288574 sec, using 17 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8613, Validation Loss: 0.6808
	--> Epoch [2/100], Loss: 0.6535, Validation Loss: 0.5735
	--> Epoch [3/100], Loss: 0.5450, Validation Loss: 0.5079
	--> Epoch [4/100], Loss: 0.4978, Validation Loss: 0.4585
	--> Epoch [5/100], Loss: 0.5136, Validation Loss: 0.4190
	--> Epoch [6/100], Loss: 0.1581, Validation Loss: 0.3796
	--> Epoch [7/100], Loss: 0.1057, Validation Loss: 0.3592
	--> Epoch [8/100], Loss: 0.0544, Validation Loss: 0.3405
	--> Epoch [9/100], Loss: 0.2316, Validation Loss: 0.3230
	--> Epoch [10/100], Loss: 0.0604, Validation Loss: 0.3075
	--> Epoch [11/100], Loss: 0.0739, Validation Loss: 0.2935
	--> Epoch [12/100], Loss: 0.2261, Validation Loss: 0.2810
	--> Epoch [13/100], Loss: 0.0116, Validation Loss: 0.2710
	--> Epoch [14/100], Loss: 0.0463, Validation Loss: 0.2624
	--> Epoch [15/100], Loss: 0.1451, Validation Loss: 0.2586
	--> Epoch [16/100], Loss: 0.0562, Validation Loss: 0.2544
	--> Epoch [17/100], Loss: 0.2291, Validation Loss: 0.2484
	--> Epoch [18/100], Loss: 0.0818, Validation Loss: 0.2456
	--> Epoch [19/100], Loss: 0.0653, Validation Loss: 0.2486
	--> Epoch [20/100], Loss: 0.0079, Validation Loss: 0.2424
	--> Epoch [21/100], Loss: 0.0089, Validation Loss: 0.2333
	--> Epoch [22/100], Loss: 0.0036, Validation Loss: 0.2245
	--> Epoch [23/100], Loss: 0.0162, Validation Loss: 0.2259
	--> Epoch [24/100], Loss: 0.0121, Validation Loss: 0.2345
	--> Epoch [25/100], Loss: 0.4137, Validation Loss: 0.2310
Early stopping
	--> Training for Fold 2 took 1.2488622665405273 sec, using 25 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7180, Validation Loss: 0.6392
	--> Epoch [2/100], Loss: 0.6094, Validation Loss: 0.6157
	--> Epoch [3/100], Loss: 0.4843, Validation Loss: 0.5881
	--> Epoch [4/100], Loss: 0.3484, Validation Loss: 0.5577
	--> Epoch [5/100], Loss: 0.2522, Validation Loss: 0.5266
	--> Epoch [6/100], Loss: 0.1997, Validation Loss: 0.4954
	--> Epoch [7/100], Loss: 0.1632, Validation Loss: 0.4678
	--> Epoch [8/100], Loss: 0.2142, Validation Loss: 0.4405
	--> Epoch [9/100], Loss: 0.0851, Validation Loss: 0.4187
	--> Epoch [10/100], Loss: 0.0583, Validation Loss: 0.4025
	--> Epoch [11/100], Loss: 0.1093, Validation Loss: 0.3891
	--> Epoch [12/100], Loss: 0.1115, Validation Loss: 0.3786
	--> Epoch [13/100], Loss: 0.0390, Validation Loss: 0.3657
	--> Epoch [14/100], Loss: 0.0695, Validation Loss: 0.3576
	--> Epoch [15/100], Loss: 0.0047, Validation Loss: 0.3551
	--> Epoch [16/100], Loss: 0.0386, Validation Loss: 0.3530
	--> Epoch [17/100], Loss: 0.0077, Validation Loss: 0.3571
	--> Epoch [18/100], Loss: 0.0166, Validation Loss: 0.3548
	--> Epoch [19/100], Loss: 0.0295, Validation Loss: 0.3478
	--> Epoch [20/100], Loss: 0.0241, Validation Loss: 0.3501
	--> Epoch [21/100], Loss: 0.0138, Validation Loss: 0.3475
	--> Epoch [22/100], Loss: 0.0071, Validation Loss: 0.3442
	--> Epoch [23/100], Loss: 0.0032, Validation Loss: 0.3432
	--> Epoch [24/100], Loss: 0.0021, Validation Loss: 0.3425
	--> Epoch [25/100], Loss: 0.0401, Validation Loss: 0.3440
	--> Epoch [26/100], Loss: 0.0060, Validation Loss: 0.3439
	--> Epoch [27/100], Loss: 0.0119, Validation Loss: 0.3426
Early stopping
	--> Training for Fold 3 took 1.3561620712280273 sec, using 27 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6197, Validation Loss: 0.5880
	--> Epoch [2/100], Loss: 0.5077, Validation Loss: 0.5335
	--> Epoch [3/100], Loss: 0.4300, Validation Loss: 0.4922
	--> Epoch [4/100], Loss: 0.3218, Validation Loss: 0.4610
	--> Epoch [5/100], Loss: 0.2616, Validation Loss: 0.4413
	--> Epoch [6/100], Loss: 0.2448, Validation Loss: 0.4245
	--> Epoch [7/100], Loss: 0.1954, Validation Loss: 0.3996
	--> Epoch [8/100], Loss: 0.1975, Validation Loss: 0.3812
	--> Epoch [9/100], Loss: 0.1496, Validation Loss: 0.3779
	--> Epoch [10/100], Loss: 0.0409, Validation Loss: 0.3618
	--> Epoch [11/100], Loss: 0.0950, Validation Loss: 0.3545
	--> Epoch [12/100], Loss: 0.0799, Validation Loss: 0.3511
	--> Epoch [13/100], Loss: 0.1427, Validation Loss: 0.3488
	--> Epoch [14/100], Loss: 0.0420, Validation Loss: 0.3437
	--> Epoch [15/100], Loss: 0.0166, Validation Loss: 0.3367
	--> Epoch [16/100], Loss: 0.0558, Validation Loss: 0.3366
	--> Epoch [17/100], Loss: 0.0281, Validation Loss: 0.3306
	--> Epoch [18/100], Loss: 0.0099, Validation Loss: 0.3339
	--> Epoch [19/100], Loss: 0.0231, Validation Loss: 0.3274
	--> Epoch [20/100], Loss: 0.0145, Validation Loss: 0.3323
	--> Epoch [21/100], Loss: 0.0795, Validation Loss: 0.3318
	--> Epoch [22/100], Loss: 0.0105, Validation Loss: 0.3372
Early stopping
	--> Training for Fold 4 took 1.0858399868011475 sec, using 22 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.5332, Validation Loss: 0.6578
	--> Epoch [2/100], Loss: 0.4573, Validation Loss: 0.6272
	--> Epoch [3/100], Loss: 0.3417, Validation Loss: 0.6082
	--> Epoch [4/100], Loss: 0.3087, Validation Loss: 0.5880
	--> Epoch [5/100], Loss: 0.2169, Validation Loss: 0.5788
	--> Epoch [6/100], Loss: 0.2004, Validation Loss: 0.5756
	--> Epoch [7/100], Loss: 0.1342, Validation Loss: 0.5712
	--> Epoch [8/100], Loss: 0.1173, Validation Loss: 0.5602
	--> Epoch [9/100], Loss: 0.1235, Validation Loss: 0.5556
	--> Epoch [10/100], Loss: 0.1206, Validation Loss: 0.5551
	--> Epoch [11/100], Loss: 0.0251, Validation Loss: 0.5469
	--> Epoch [12/100], Loss: 0.0494, Validation Loss: 0.5510
	--> Epoch [13/100], Loss: 0.0523, Validation Loss: 0.5531
	--> Epoch [14/100], Loss: 0.0996, Validation Loss: 0.5652
Early stopping
	--> Training for Fold 5 took 0.701026201248169 sec, using 14 epochs

Median number of epochs used: 22 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/22], Loss: 0.9972
	--> Final training Epoch [2/22], Loss: 0.7355
	--> Final training Epoch [3/22], Loss: 0.5894
	--> Final training Epoch [4/22], Loss: 0.4658
	--> Final training Epoch [5/22], Loss: 0.3542
	--> Final training Epoch [6/22], Loss: 0.1729
	--> Final training Epoch [7/22], Loss: 0.1095
	--> Final training Epoch [8/22], Loss: 0.3056
	--> Final training Epoch [9/22], Loss: 0.1801
	--> Final training Epoch [10/22], Loss: 0.0202
	--> Final training Epoch [11/22], Loss: 0.1469
	--> Final training Epoch [12/22], Loss: 0.0105
	--> Final training Epoch [13/22], Loss: 0.0081
	--> Final training Epoch [14/22], Loss: 0.7175
	--> Final training Epoch [15/22], Loss: 0.0641
	--> Final training Epoch [16/22], Loss: 0.0039
	--> Final training Epoch [17/22], Loss: 0.0444
	--> Final training Epoch [18/22], Loss: 0.0722
	--> Final training Epoch [19/22], Loss: 0.0019
	--> Final training Epoch [20/22], Loss: 0.0542
	--> Final training Epoch [21/22], Loss: 0.0426
	--> Final training Epoch [22/22], Loss: 0.6720

Final training took 1.314497947692871 sec

TESTING
	--> Testing took 0.0159 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 1.0611
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.9023, Validation Loss: 0.3096,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.3405,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8708, Validation Loss: 0.3501,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3568,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3293,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8497, Validation Loss: 0.3743,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8608, Validation Loss: 0.3449,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8058, Validation Loss: 0.3864,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.3239,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8480, Validation Loss: 0.3285,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8596, Validation Loss: 0.3166,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8702, Validation Loss: 0.3430,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8608, Validation Loss: 0.3426,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8491, Validation Loss: 0.3463,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.4012,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3432,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.3533,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8175, Validation Loss: 0.3985,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3313,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8807, Validation Loss: 0.3348,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8591, Validation Loss: 0.3309,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3503,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3350,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.3992,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8708, Validation Loss: 0.3752,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.4332,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 4, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3445,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3452,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8374, Validation Loss: 0.3217,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.3386,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.3361,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.7830, Validation Loss: 0.4019,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8819, Validation Loss: 0.3449,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3911,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7959, Validation Loss: 0.3811,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8269, Validation Loss: 0.3703,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3096

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7121, Validation Loss: 0.5880
	--> Epoch [2/100], Loss: 0.5727, Validation Loss: 0.5538
	--> Epoch [3/100], Loss: 0.5481, Validation Loss: 0.5293
	--> Epoch [4/100], Loss: 0.3991, Validation Loss: 0.4975
	--> Epoch [5/100], Loss: 0.4998, Validation Loss: 0.4714
	--> Epoch [6/100], Loss: 0.3561, Validation Loss: 0.4496
	--> Epoch [7/100], Loss: 0.2217, Validation Loss: 0.4246
	--> Epoch [8/100], Loss: 0.2233, Validation Loss: 0.4006
	--> Epoch [9/100], Loss: 0.3690, Validation Loss: 0.3881
	--> Epoch [10/100], Loss: 0.4315, Validation Loss: 0.3729
	--> Epoch [11/100], Loss: 0.0946, Validation Loss: 0.3596
	--> Epoch [12/100], Loss: 0.0548, Validation Loss: 0.3518
	--> Epoch [13/100], Loss: 0.0258, Validation Loss: 0.3452
	--> Epoch [14/100], Loss: 0.0558, Validation Loss: 0.3344
	--> Epoch [15/100], Loss: 0.1503, Validation Loss: 0.3267
	--> Epoch [16/100], Loss: 0.0259, Validation Loss: 0.3217
	--> Epoch [17/100], Loss: 0.0095, Validation Loss: 0.3217
	--> Epoch [18/100], Loss: 0.0281, Validation Loss: 0.3199
	--> Epoch [19/100], Loss: 0.0219, Validation Loss: 0.3191
	--> Epoch [20/100], Loss: 0.0163, Validation Loss: 0.3225
	--> Epoch [21/100], Loss: 0.0234, Validation Loss: 0.3244
	--> Epoch [22/100], Loss: 0.0179, Validation Loss: 0.3236
Early stopping
	--> Training for Fold 1 took 0.514739990234375 sec, using 22 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5719, Validation Loss: 0.5587
	--> Epoch [2/100], Loss: 0.6725, Validation Loss: 0.5148
	--> Epoch [3/100], Loss: 0.4276, Validation Loss: 0.4671
	--> Epoch [4/100], Loss: 0.3372, Validation Loss: 0.4263
	--> Epoch [5/100], Loss: 0.2818, Validation Loss: 0.3958
	--> Epoch [6/100], Loss: 0.1861, Validation Loss: 0.3729
	--> Epoch [7/100], Loss: 0.3594, Validation Loss: 0.3560
	--> Epoch [8/100], Loss: 0.3083, Validation Loss: 0.3403
	--> Epoch [9/100], Loss: 0.4165, Validation Loss: 0.3299
	--> Epoch [10/100], Loss: 0.0552, Validation Loss: 0.3179
	--> Epoch [11/100], Loss: 0.0694, Validation Loss: 0.3101
	--> Epoch [12/100], Loss: 0.0725, Validation Loss: 0.3021
	--> Epoch [13/100], Loss: 0.2439, Validation Loss: 0.2942
	--> Epoch [14/100], Loss: 0.0145, Validation Loss: 0.2884
	--> Epoch [15/100], Loss: 0.0145, Validation Loss: 0.2787
	--> Epoch [16/100], Loss: 0.0258, Validation Loss: 0.2782
	--> Epoch [17/100], Loss: 0.0238, Validation Loss: 0.2718
	--> Epoch [18/100], Loss: 0.0070, Validation Loss: 0.2648
	--> Epoch [19/100], Loss: 0.0184, Validation Loss: 0.2596
	--> Epoch [20/100], Loss: 0.0157, Validation Loss: 0.2575
	--> Epoch [21/100], Loss: 0.0408, Validation Loss: 0.2558
	--> Epoch [22/100], Loss: 0.0554, Validation Loss: 0.2459
	--> Epoch [23/100], Loss: 0.0278, Validation Loss: 0.2441
	--> Epoch [24/100], Loss: 0.0027, Validation Loss: 0.2494
	--> Epoch [25/100], Loss: 0.0657, Validation Loss: 0.2453
	--> Epoch [26/100], Loss: 0.0273, Validation Loss: 0.2416
	--> Epoch [27/100], Loss: 0.0208, Validation Loss: 0.2419
	--> Epoch [28/100], Loss: 0.0170, Validation Loss: 0.2399
	--> Epoch [29/100], Loss: 0.0042, Validation Loss: 0.2355
	--> Epoch [30/100], Loss: 0.0081, Validation Loss: 0.2360
	--> Epoch [31/100], Loss: 0.3647, Validation Loss: 0.2296
	--> Epoch [32/100], Loss: 0.0163, Validation Loss: 0.2283
	--> Epoch [33/100], Loss: 0.0089, Validation Loss: 0.2285
	--> Epoch [34/100], Loss: 0.0017, Validation Loss: 0.2255
	--> Epoch [35/100], Loss: 0.0079, Validation Loss: 0.2233
	--> Epoch [36/100], Loss: 0.0010, Validation Loss: 0.2193
	--> Epoch [37/100], Loss: 0.0486, Validation Loss: 0.2205
	--> Epoch [38/100], Loss: 0.1485, Validation Loss: 0.2185
	--> Epoch [39/100], Loss: 0.0028, Validation Loss: 0.2169
	--> Epoch [40/100], Loss: 0.0046, Validation Loss: 0.2142
	--> Epoch [41/100], Loss: 0.0038, Validation Loss: 0.2133
	--> Epoch [42/100], Loss: 0.0004, Validation Loss: 0.2134
	--> Epoch [43/100], Loss: 0.3445, Validation Loss: 0.2113
	--> Epoch [44/100], Loss: 0.0008, Validation Loss: 0.2109
	--> Epoch [45/100], Loss: 0.0204, Validation Loss: 0.2105
	--> Epoch [46/100], Loss: 0.0002, Validation Loss: 0.2070
	--> Epoch [47/100], Loss: 0.0001, Validation Loss: 0.2061
	--> Epoch [48/100], Loss: 0.0398, Validation Loss: 0.2050
	--> Epoch [49/100], Loss: 0.0012, Validation Loss: 0.2068
	--> Epoch [50/100], Loss: 0.0010, Validation Loss: 0.2055
	--> Epoch [51/100], Loss: 0.0017, Validation Loss: 0.2046
	--> Epoch [52/100], Loss: 0.0019, Validation Loss: 0.2043
	--> Epoch [53/100], Loss: 0.0001, Validation Loss: 0.1982
	--> Epoch [54/100], Loss: 0.0021, Validation Loss: 0.1965
	--> Epoch [55/100], Loss: 0.0017, Validation Loss: 0.1916
	--> Epoch [56/100], Loss: 0.0497, Validation Loss: 0.1930
	--> Epoch [57/100], Loss: 0.0006, Validation Loss: 0.1859
	--> Epoch [58/100], Loss: 0.0008, Validation Loss: 0.1822
	--> Epoch [59/100], Loss: 0.0010, Validation Loss: 0.1838
	--> Epoch [60/100], Loss: 0.0006, Validation Loss: 0.1844
	--> Epoch [61/100], Loss: 0.0209, Validation Loss: 0.1844
Early stopping
	--> Training for Fold 2 took 1.46848726272583 sec, using 61 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7535, Validation Loss: 0.6455
	--> Epoch [2/100], Loss: 0.5110, Validation Loss: 0.6169
	--> Epoch [3/100], Loss: 0.2911, Validation Loss: 0.5923
	--> Epoch [4/100], Loss: 0.3700, Validation Loss: 0.5725
	--> Epoch [5/100], Loss: 0.2116, Validation Loss: 0.5554
	--> Epoch [6/100], Loss: 0.2092, Validation Loss: 0.5386
	--> Epoch [7/100], Loss: 0.0890, Validation Loss: 0.5215
	--> Epoch [8/100], Loss: 0.1957, Validation Loss: 0.5078
	--> Epoch [9/100], Loss: 0.0350, Validation Loss: 0.4937
	--> Epoch [10/100], Loss: 0.2732, Validation Loss: 0.4867
	--> Epoch [11/100], Loss: 0.0205, Validation Loss: 0.4709
	--> Epoch [12/100], Loss: 0.1959, Validation Loss: 0.4611
	--> Epoch [13/100], Loss: 0.0818, Validation Loss: 0.4531
	--> Epoch [14/100], Loss: 0.0096, Validation Loss: 0.4478
	--> Epoch [15/100], Loss: 0.0141, Validation Loss: 0.4371
	--> Epoch [16/100], Loss: 0.0182, Validation Loss: 0.4314
	--> Epoch [17/100], Loss: 0.0854, Validation Loss: 0.4251
	--> Epoch [18/100], Loss: 0.0454, Validation Loss: 0.4215
	--> Epoch [19/100], Loss: 0.1700, Validation Loss: 0.4176
	--> Epoch [20/100], Loss: 0.0065, Validation Loss: 0.4139
	--> Epoch [21/100], Loss: 0.0504, Validation Loss: 0.4138
	--> Epoch [22/100], Loss: 0.0333, Validation Loss: 0.4070
	--> Epoch [23/100], Loss: 0.0041, Validation Loss: 0.4048
	--> Epoch [24/100], Loss: 0.0034, Validation Loss: 0.4079
	--> Epoch [25/100], Loss: 0.0393, Validation Loss: 0.4020
	--> Epoch [26/100], Loss: 0.0221, Validation Loss: 0.4000
	--> Epoch [27/100], Loss: 0.0038, Validation Loss: 0.3984
	--> Epoch [28/100], Loss: 0.0875, Validation Loss: 0.3961
	--> Epoch [29/100], Loss: 0.0024, Validation Loss: 0.3972
	--> Epoch [30/100], Loss: 0.0899, Validation Loss: 0.3993
	--> Epoch [31/100], Loss: 0.0800, Validation Loss: 0.3935
	--> Epoch [32/100], Loss: 0.0550, Validation Loss: 0.3966
	--> Epoch [33/100], Loss: 0.0007, Validation Loss: 0.3983
	--> Epoch [34/100], Loss: 0.0080, Validation Loss: 0.3985
Early stopping
	--> Training for Fold 3 took 0.8674445152282715 sec, using 34 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6002, Validation Loss: 0.6515
	--> Epoch [2/100], Loss: 0.6247, Validation Loss: 0.5943
	--> Epoch [3/100], Loss: 0.5481, Validation Loss: 0.5654
	--> Epoch [4/100], Loss: 0.5357, Validation Loss: 0.5336
	--> Epoch [5/100], Loss: 0.3850, Validation Loss: 0.4992
	--> Epoch [6/100], Loss: 0.3153, Validation Loss: 0.4677
	--> Epoch [7/100], Loss: 0.1612, Validation Loss: 0.4386
	--> Epoch [8/100], Loss: 0.1920, Validation Loss: 0.4259
	--> Epoch [9/100], Loss: 0.1901, Validation Loss: 0.4067
	--> Epoch [10/100], Loss: 0.1265, Validation Loss: 0.3967
	--> Epoch [11/100], Loss: 0.0684, Validation Loss: 0.3858
	--> Epoch [12/100], Loss: 0.1401, Validation Loss: 0.3752
	--> Epoch [13/100], Loss: 0.0271, Validation Loss: 0.3712
	--> Epoch [14/100], Loss: 0.1169, Validation Loss: 0.3692
	--> Epoch [15/100], Loss: 0.0131, Validation Loss: 0.3682
	--> Epoch [16/100], Loss: 0.0622, Validation Loss: 0.3677
	--> Epoch [17/100], Loss: 0.0348, Validation Loss: 0.3619
	--> Epoch [18/100], Loss: 0.0763, Validation Loss: 0.3654
	--> Epoch [19/100], Loss: 0.0153, Validation Loss: 0.3667
	--> Epoch [20/100], Loss: 0.0553, Validation Loss: 0.3696
Early stopping
	--> Training for Fold 4 took 0.5409901142120361 sec, using 20 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.4159, Validation Loss: 0.7472
	--> Epoch [2/100], Loss: 0.4534, Validation Loss: 0.7288
	--> Epoch [3/100], Loss: 0.5144, Validation Loss: 0.7149
	--> Epoch [4/100], Loss: 0.2342, Validation Loss: 0.7100
	--> Epoch [5/100], Loss: 0.2776, Validation Loss: 0.6982
	--> Epoch [6/100], Loss: 0.1352, Validation Loss: 0.6836
	--> Epoch [7/100], Loss: 0.0874, Validation Loss: 0.6722
	--> Epoch [8/100], Loss: 0.1716, Validation Loss: 0.6591
	--> Epoch [9/100], Loss: 0.1335, Validation Loss: 0.6477
	--> Epoch [10/100], Loss: 0.0942, Validation Loss: 0.6323
	--> Epoch [11/100], Loss: 0.0499, Validation Loss: 0.6245
	--> Epoch [12/100], Loss: 0.0561, Validation Loss: 0.6159
	--> Epoch [13/100], Loss: 0.0609, Validation Loss: 0.6076
	--> Epoch [14/100], Loss: 0.1878, Validation Loss: 0.6082
	--> Epoch [15/100], Loss: 0.0151, Validation Loss: 0.6081
	--> Epoch [16/100], Loss: 0.0258, Validation Loss: 0.6076
Early stopping
	--> Training for Fold 5 took 0.4126718044281006 sec, using 16 epochs

Median number of epochs used: 22 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/22], Loss: 0.5463
	--> Final training Epoch [2/22], Loss: 0.5050
	--> Final training Epoch [3/22], Loss: 0.4064
	--> Final training Epoch [4/22], Loss: 0.4115
	--> Final training Epoch [5/22], Loss: 0.2306
	--> Final training Epoch [6/22], Loss: 0.3842
	--> Final training Epoch [7/22], Loss: 0.2034
	--> Final training Epoch [8/22], Loss: 0.1011
	--> Final training Epoch [9/22], Loss: 0.2328
	--> Final training Epoch [10/22], Loss: 0.0945
	--> Final training Epoch [11/22], Loss: 0.1403
	--> Final training Epoch [12/22], Loss: 0.1328
	--> Final training Epoch [13/22], Loss: 0.2785
	--> Final training Epoch [14/22], Loss: 0.0439
	--> Final training Epoch [15/22], Loss: 0.0501
	--> Final training Epoch [16/22], Loss: 0.2088
	--> Final training Epoch [17/22], Loss: 0.0675
	--> Final training Epoch [18/22], Loss: 0.0299
	--> Final training Epoch [19/22], Loss: 0.1116
	--> Final training Epoch [20/22], Loss: 0.1736
	--> Final training Epoch [21/22], Loss: 0.1656
	--> Final training Epoch [22/22], Loss: 0.0184

Final training took 0.7628252506256104 sec

TESTING
	--> Testing took 0.0096 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.8246
	--> Final Precision: 0.6667
	--> Final Recall: 0.4615
	--> Final F1 Score: 0.5455
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8813, Validation Loss: 0.2936,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8175, Validation Loss: 0.3518,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8491, Validation Loss: 0.3269,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8047, Validation Loss: 0.3893,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3540,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7942, Validation Loss: 0.4270,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8392, Validation Loss: 0.3807,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.4046,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8485, Validation Loss: 0.4120,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8491, Validation Loss: 0.3519,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8702, Validation Loss: 0.3616,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8374, Validation Loss: 0.3724,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8380, Validation Loss: 0.3689,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8275, Validation Loss: 0.3646,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8602, Validation Loss: 0.3260,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8170, Validation Loss: 0.3633,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8281, Validation Loss: 0.3461,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8035, Validation Loss: 0.4302,  Current Best Accuracy: 0.8813,  Current Best Validation Loss: 0.2936

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8145, Validation Loss: 0.8484
	--> Epoch [2/100], Loss: 0.7197, Validation Loss: 0.7848
	--> Epoch [3/100], Loss: 0.6003, Validation Loss: 0.7370
	--> Epoch [4/100], Loss: 0.4357, Validation Loss: 0.6976
	--> Epoch [5/100], Loss: 0.4092, Validation Loss: 0.6566
	--> Epoch [6/100], Loss: 0.4021, Validation Loss: 0.6185
	--> Epoch [7/100], Loss: 0.2621, Validation Loss: 0.5904
	--> Epoch [8/100], Loss: 0.4113, Validation Loss: 0.5556
	--> Epoch [9/100], Loss: 0.4380, Validation Loss: 0.5302
	--> Epoch [10/100], Loss: 0.5801, Validation Loss: 0.5061
	--> Epoch [11/100], Loss: 0.1623, Validation Loss: 0.4746
	--> Epoch [12/100], Loss: 0.1295, Validation Loss: 0.4431
	--> Epoch [13/100], Loss: 0.4222, Validation Loss: 0.4259
	--> Epoch [14/100], Loss: 0.4211, Validation Loss: 0.4077
	--> Epoch [15/100], Loss: 0.0766, Validation Loss: 0.3892
	--> Epoch [16/100], Loss: 0.0710, Validation Loss: 0.3757
	--> Epoch [17/100], Loss: 0.0814, Validation Loss: 0.3662
	--> Epoch [18/100], Loss: 0.3782, Validation Loss: 0.3547
	--> Epoch [19/100], Loss: 0.3705, Validation Loss: 0.3438
	--> Epoch [20/100], Loss: 0.0398, Validation Loss: 0.3348
	--> Epoch [21/100], Loss: 0.0342, Validation Loss: 0.3291
	--> Epoch [22/100], Loss: 0.0322, Validation Loss: 0.3224
	--> Epoch [23/100], Loss: 0.3644, Validation Loss: 0.3135
	--> Epoch [24/100], Loss: 0.3601, Validation Loss: 0.3132
	--> Epoch [25/100], Loss: 0.3616, Validation Loss: 0.3097
	--> Epoch [26/100], Loss: 0.0219, Validation Loss: 0.3052
	--> Epoch [27/100], Loss: 0.0245, Validation Loss: 0.2983
	--> Epoch [28/100], Loss: 0.3647, Validation Loss: 0.2923
	--> Epoch [29/100], Loss: 0.0137, Validation Loss: 0.2910
	--> Epoch [30/100], Loss: 0.0123, Validation Loss: 0.2890
	--> Epoch [31/100], Loss: 0.3579, Validation Loss: 0.2805
	--> Epoch [32/100], Loss: 0.3460, Validation Loss: 0.2815
	--> Epoch [33/100], Loss: 0.3508, Validation Loss: 0.2762
	--> Epoch [34/100], Loss: 0.1017, Validation Loss: 0.2766
	--> Epoch [35/100], Loss: 0.0151, Validation Loss: 0.2754
	--> Epoch [36/100], Loss: 0.0087, Validation Loss: 0.2720
	--> Epoch [37/100], Loss: 0.3359, Validation Loss: 0.2704
	--> Epoch [38/100], Loss: 0.3336, Validation Loss: 0.2685
	--> Epoch [39/100], Loss: 0.0862, Validation Loss: 0.2665
	--> Epoch [40/100], Loss: 0.0057, Validation Loss: 0.2633
	--> Epoch [41/100], Loss: 0.0094, Validation Loss: 0.2619
	--> Epoch [42/100], Loss: 0.0087, Validation Loss: 0.2613
	--> Epoch [43/100], Loss: 0.0662, Validation Loss: 0.2615
	--> Epoch [44/100], Loss: 0.0047, Validation Loss: 0.2583
	--> Epoch [45/100], Loss: 0.3664, Validation Loss: 0.2531
	--> Epoch [46/100], Loss: 0.3215, Validation Loss: 0.2573
	--> Epoch [47/100], Loss: 0.0039, Validation Loss: 0.2553
	--> Epoch [48/100], Loss: 0.0035, Validation Loss: 0.2537
Early stopping
	--> Training for Fold 1 took 1.2975263595581055 sec, using 48 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5613, Validation Loss: 0.7023
	--> Epoch [2/100], Loss: 0.4423, Validation Loss: 0.6580
	--> Epoch [3/100], Loss: 0.3907, Validation Loss: 0.6189
	--> Epoch [4/100], Loss: 0.2802, Validation Loss: 0.5784
	--> Epoch [5/100], Loss: 0.4212, Validation Loss: 0.5501
	--> Epoch [6/100], Loss: 0.1397, Validation Loss: 0.5239
	--> Epoch [7/100], Loss: 0.1385, Validation Loss: 0.4916
	--> Epoch [8/100], Loss: 0.0758, Validation Loss: 0.4679
	--> Epoch [9/100], Loss: 0.0701, Validation Loss: 0.4526
	--> Epoch [10/100], Loss: 0.0733, Validation Loss: 0.4346
	--> Epoch [11/100], Loss: 0.1382, Validation Loss: 0.4167
	--> Epoch [12/100], Loss: 0.1745, Validation Loss: 0.4050
	--> Epoch [13/100], Loss: 0.0476, Validation Loss: 0.3933
	--> Epoch [14/100], Loss: 0.0361, Validation Loss: 0.3806
	--> Epoch [15/100], Loss: 0.0761, Validation Loss: 0.3738
	--> Epoch [16/100], Loss: 0.0887, Validation Loss: 0.3705
	--> Epoch [17/100], Loss: 0.0100, Validation Loss: 0.3630
	--> Epoch [18/100], Loss: 0.0724, Validation Loss: 0.3585
	--> Epoch [19/100], Loss: 0.0123, Validation Loss: 0.3504
	--> Epoch [20/100], Loss: 0.1069, Validation Loss: 0.3471
	--> Epoch [21/100], Loss: 0.0141, Validation Loss: 0.3433
	--> Epoch [22/100], Loss: 0.0191, Validation Loss: 0.3390
	--> Epoch [23/100], Loss: 0.0254, Validation Loss: 0.3408
	--> Epoch [24/100], Loss: 0.0080, Validation Loss: 0.3346
	--> Epoch [25/100], Loss: 0.0368, Validation Loss: 0.3293
	--> Epoch [26/100], Loss: 0.0319, Validation Loss: 0.3291
	--> Epoch [27/100], Loss: 0.0225, Validation Loss: 0.3284
	--> Epoch [28/100], Loss: 0.0073, Validation Loss: 0.3200
	--> Epoch [29/100], Loss: 0.0011, Validation Loss: 0.3174
	--> Epoch [30/100], Loss: 0.0017, Validation Loss: 0.3133
	--> Epoch [31/100], Loss: 0.0005, Validation Loss: 0.3082
	--> Epoch [32/100], Loss: 0.0008, Validation Loss: 0.3067
	--> Epoch [33/100], Loss: 0.0092, Validation Loss: 0.3040
	--> Epoch [34/100], Loss: 0.0159, Validation Loss: 0.3007
	--> Epoch [35/100], Loss: 0.0006, Validation Loss: 0.2991
	--> Epoch [36/100], Loss: 0.1566, Validation Loss: 0.2881
	--> Epoch [37/100], Loss: 0.0130, Validation Loss: 0.2776
	--> Epoch [38/100], Loss: 0.0486, Validation Loss: 0.2793
	--> Epoch [39/100], Loss: 0.0177, Validation Loss: 0.2787
	--> Epoch [40/100], Loss: 0.0142, Validation Loss: 0.2747
	--> Epoch [41/100], Loss: 0.0003, Validation Loss: 0.2731
	--> Epoch [42/100], Loss: 0.0009, Validation Loss: 0.2751
	--> Epoch [43/100], Loss: 0.0029, Validation Loss: 0.2717
	--> Epoch [44/100], Loss: 0.0063, Validation Loss: 0.2698
	--> Epoch [45/100], Loss: 0.0002, Validation Loss: 0.2612
	--> Epoch [46/100], Loss: 0.0075, Validation Loss: 0.2606
	--> Epoch [47/100], Loss: 0.0006, Validation Loss: 0.2665
	--> Epoch [48/100], Loss: 0.0080, Validation Loss: 0.2654
	--> Epoch [49/100], Loss: 0.0011, Validation Loss: 0.2588
	--> Epoch [50/100], Loss: 0.0017, Validation Loss: 0.2559
	--> Epoch [51/100], Loss: 0.0017, Validation Loss: 0.2560
	--> Epoch [52/100], Loss: 0.0017, Validation Loss: 0.2546
	--> Epoch [53/100], Loss: 0.0559, Validation Loss: 0.2570
	--> Epoch [54/100], Loss: 0.0000, Validation Loss: 0.2574
	--> Epoch [55/100], Loss: 0.0008, Validation Loss: 0.2570
Early stopping
	--> Training for Fold 2 took 1.5787794589996338 sec, using 55 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.4558, Validation Loss: 0.7081
	--> Epoch [2/100], Loss: 0.5041, Validation Loss: 0.6752
	--> Epoch [3/100], Loss: 0.3786, Validation Loss: 0.6502
	--> Epoch [4/100], Loss: 0.2986, Validation Loss: 0.6191
	--> Epoch [5/100], Loss: 0.4047, Validation Loss: 0.5925
	--> Epoch [6/100], Loss: 0.1711, Validation Loss: 0.5673
	--> Epoch [7/100], Loss: 0.1963, Validation Loss: 0.5472
	--> Epoch [8/100], Loss: 0.2563, Validation Loss: 0.5274
	--> Epoch [9/100], Loss: 0.4152, Validation Loss: 0.5171
	--> Epoch [10/100], Loss: 0.1916, Validation Loss: 0.4965
	--> Epoch [11/100], Loss: 0.1737, Validation Loss: 0.4833
	--> Epoch [12/100], Loss: 0.1604, Validation Loss: 0.4713
	--> Epoch [13/100], Loss: 0.0240, Validation Loss: 0.4626
	--> Epoch [14/100], Loss: 0.1337, Validation Loss: 0.4556
	--> Epoch [15/100], Loss: 0.0950, Validation Loss: 0.4491
	--> Epoch [16/100], Loss: 0.0152, Validation Loss: 0.4444
	--> Epoch [17/100], Loss: 0.1224, Validation Loss: 0.4394
	--> Epoch [18/100], Loss: 0.0058, Validation Loss: 0.4331
	--> Epoch [19/100], Loss: 0.0152, Validation Loss: 0.4284
	--> Epoch [20/100], Loss: 0.0134, Validation Loss: 0.4247
	--> Epoch [21/100], Loss: 0.0826, Validation Loss: 0.4204
	--> Epoch [22/100], Loss: 0.0098, Validation Loss: 0.4214
	--> Epoch [23/100], Loss: 0.0197, Validation Loss: 0.4221
	--> Epoch [24/100], Loss: 0.0093, Validation Loss: 0.4221
Early stopping
	--> Training for Fold 3 took 0.7016968727111816 sec, using 24 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8901, Validation Loss: 0.6538
	--> Epoch [2/100], Loss: 0.7987, Validation Loss: 0.6116
	--> Epoch [3/100], Loss: 0.5547, Validation Loss: 0.5700
	--> Epoch [4/100], Loss: 0.5715, Validation Loss: 0.5258
	--> Epoch [5/100], Loss: 0.4522, Validation Loss: 0.4911
	--> Epoch [6/100], Loss: 0.3380, Validation Loss: 0.4702
	--> Epoch [7/100], Loss: 0.2798, Validation Loss: 0.4421
	--> Epoch [8/100], Loss: 0.3553, Validation Loss: 0.4209
	--> Epoch [9/100], Loss: 0.1679, Validation Loss: 0.3977
	--> Epoch [10/100], Loss: 0.3760, Validation Loss: 0.3892
	--> Epoch [11/100], Loss: 0.2125, Validation Loss: 0.3754
	--> Epoch [12/100], Loss: 0.1952, Validation Loss: 0.3633
	--> Epoch [13/100], Loss: 0.1208, Validation Loss: 0.3511
	--> Epoch [14/100], Loss: 0.1372, Validation Loss: 0.3450
	--> Epoch [15/100], Loss: 0.0851, Validation Loss: 0.3364
	--> Epoch [16/100], Loss: 0.3001, Validation Loss: 0.3250
	--> Epoch [17/100], Loss: 0.2147, Validation Loss: 0.3212
	--> Epoch [18/100], Loss: 0.0768, Validation Loss: 0.3166
	--> Epoch [19/100], Loss: 0.1177, Validation Loss: 0.3146
	--> Epoch [20/100], Loss: 0.1029, Validation Loss: 0.3101
	--> Epoch [21/100], Loss: 0.0419, Validation Loss: 0.3073
	--> Epoch [22/100], Loss: 0.1767, Validation Loss: 0.2980
	--> Epoch [23/100], Loss: 0.0930, Validation Loss: 0.2974
	--> Epoch [24/100], Loss: 0.0571, Validation Loss: 0.2937
	--> Epoch [25/100], Loss: 0.0076, Validation Loss: 0.2862
	--> Epoch [26/100], Loss: 0.0403, Validation Loss: 0.2879
	--> Epoch [27/100], Loss: 0.0361, Validation Loss: 0.2860
	--> Epoch [28/100], Loss: 0.2087, Validation Loss: 0.2846
	--> Epoch [29/100], Loss: 0.0223, Validation Loss: 0.2838
	--> Epoch [30/100], Loss: 0.0296, Validation Loss: 0.2845
	--> Epoch [31/100], Loss: 0.0402, Validation Loss: 0.2782
	--> Epoch [32/100], Loss: 0.0283, Validation Loss: 0.2759
	--> Epoch [33/100], Loss: 0.0134, Validation Loss: 0.2783
	--> Epoch [34/100], Loss: 0.2998, Validation Loss: 0.2761
	--> Epoch [35/100], Loss: 0.0193, Validation Loss: 0.2730
	--> Epoch [36/100], Loss: 0.0017, Validation Loss: 0.2731
	--> Epoch [37/100], Loss: 0.0170, Validation Loss: 0.2724
	--> Epoch [38/100], Loss: 0.0205, Validation Loss: 0.2713
	--> Epoch [39/100], Loss: 0.0185, Validation Loss: 0.2721
	--> Epoch [40/100], Loss: 0.0175, Validation Loss: 0.2738
	--> Epoch [41/100], Loss: 0.0264, Validation Loss: 0.2796
Early stopping
	--> Training for Fold 4 took 1.3311150074005127 sec, using 41 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7408, Validation Loss: 0.6512
	--> Epoch [2/100], Loss: 0.7286, Validation Loss: 0.6322
	--> Epoch [3/100], Loss: 0.6943, Validation Loss: 0.6157
	--> Epoch [4/100], Loss: 0.6869, Validation Loss: 0.6014
	--> Epoch [5/100], Loss: 0.6423, Validation Loss: 0.5870
	--> Epoch [6/100], Loss: 0.6737, Validation Loss: 0.5740
	--> Epoch [7/100], Loss: 0.5464, Validation Loss: 0.5687
	--> Epoch [8/100], Loss: 0.5934, Validation Loss: 0.5577
	--> Epoch [9/100], Loss: 0.3667, Validation Loss: 0.5459
	--> Epoch [10/100], Loss: 0.4473, Validation Loss: 0.5386
	--> Epoch [11/100], Loss: 0.3362, Validation Loss: 0.5311
	--> Epoch [12/100], Loss: 0.5353, Validation Loss: 0.5301
	--> Epoch [13/100], Loss: 0.1675, Validation Loss: 0.5273
	--> Epoch [14/100], Loss: 0.1378, Validation Loss: 0.5256
	--> Epoch [15/100], Loss: 0.3028, Validation Loss: 0.5214
	--> Epoch [16/100], Loss: 0.2400, Validation Loss: 0.5173
	--> Epoch [17/100], Loss: 0.2309, Validation Loss: 0.5135
	--> Epoch [18/100], Loss: 0.4155, Validation Loss: 0.5102
	--> Epoch [19/100], Loss: 0.4554, Validation Loss: 0.5054
	--> Epoch [20/100], Loss: 0.5956, Validation Loss: 0.5036
	--> Epoch [21/100], Loss: 0.2465, Validation Loss: 0.5010
	--> Epoch [22/100], Loss: 0.2395, Validation Loss: 0.4980
	--> Epoch [23/100], Loss: 0.2325, Validation Loss: 0.5003
	--> Epoch [24/100], Loss: 0.0404, Validation Loss: 0.4946
	--> Epoch [25/100], Loss: 0.1976, Validation Loss: 0.4915
	--> Epoch [26/100], Loss: 0.0336, Validation Loss: 0.4917
	--> Epoch [27/100], Loss: 0.0307, Validation Loss: 0.4932
	--> Epoch [28/100], Loss: 0.3958, Validation Loss: 0.4877
	--> Epoch [29/100], Loss: 0.2089, Validation Loss: 0.4844
	--> Epoch [30/100], Loss: 0.2054, Validation Loss: 0.4811
	--> Epoch [31/100], Loss: 0.1854, Validation Loss: 0.4824
	--> Epoch [32/100], Loss: 0.1836, Validation Loss: 0.4804
	--> Epoch [33/100], Loss: 0.3582, Validation Loss: 0.4844
	--> Epoch [34/100], Loss: 0.3689, Validation Loss: 0.4851
	--> Epoch [35/100], Loss: 0.1893, Validation Loss: 0.4855
Early stopping
	--> Training for Fold 5 took 1.0966603755950928 sec, using 35 epochs

Median number of epochs used: 41 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/41], Loss: 0.7848
	--> Final training Epoch [2/41], Loss: 0.4748
	--> Final training Epoch [3/41], Loss: 0.4572
	--> Final training Epoch [4/41], Loss: 0.3718
	--> Final training Epoch [5/41], Loss: 0.2566
	--> Final training Epoch [6/41], Loss: 0.3804
	--> Final training Epoch [7/41], Loss: 0.1518
	--> Final training Epoch [8/41], Loss: 0.3065
	--> Final training Epoch [9/41], Loss: 0.0937
	--> Final training Epoch [10/41], Loss: 0.0924
	--> Final training Epoch [11/41], Loss: 0.1386
	--> Final training Epoch [12/41], Loss: 0.1504
	--> Final training Epoch [13/41], Loss: 0.0529
	--> Final training Epoch [14/41], Loss: 0.0792
	--> Final training Epoch [15/41], Loss: 0.0522
	--> Final training Epoch [16/41], Loss: 0.0248
	--> Final training Epoch [17/41], Loss: 0.0476
	--> Final training Epoch [18/41], Loss: 0.0971
	--> Final training Epoch [19/41], Loss: 0.0199
	--> Final training Epoch [20/41], Loss: 0.0093
	--> Final training Epoch [21/41], Loss: 0.0263
	--> Final training Epoch [22/41], Loss: 0.0094
	--> Final training Epoch [23/41], Loss: 0.0430
	--> Final training Epoch [24/41], Loss: 0.0264
	--> Final training Epoch [25/41], Loss: 0.0049
	--> Final training Epoch [26/41], Loss: 0.0037
	--> Final training Epoch [27/41], Loss: 0.0222
	--> Final training Epoch [28/41], Loss: 0.0205
	--> Final training Epoch [29/41], Loss: 0.0080
	--> Final training Epoch [30/41], Loss: 0.0120
	--> Final training Epoch [31/41], Loss: 0.1632
	--> Final training Epoch [32/41], Loss: 0.0096
	--> Final training Epoch [33/41], Loss: 0.0192
	--> Final training Epoch [34/41], Loss: 0.0174
	--> Final training Epoch [35/41], Loss: 0.0253
	--> Final training Epoch [36/41], Loss: 0.0163
	--> Final training Epoch [37/41], Loss: 0.0175
	--> Final training Epoch [38/41], Loss: 0.0097
	--> Final training Epoch [39/41], Loss: 0.0422
	--> Final training Epoch [40/41], Loss: 0.0128
	--> Final training Epoch [41/41], Loss: 0.1271

Final training took 1.4986650943756104 sec

TESTING
	--> Testing took 0.0126 sec
	--> Final Accuracy: 0.8261
	--> Final Loss: 0.8682
	--> Final Precision: 0.8000
	--> Final Recall: 0.9231
	--> Final F1 Score: 0.8571
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8819, Validation Loss: 0.3088,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3253,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8053, Validation Loss: 0.3575,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8281, Validation Loss: 0.3391,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8608, Validation Loss: 0.3782,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.7836, Validation Loss: 0.3794,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8596, Validation Loss: 0.3677,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.7848, Validation Loss: 0.4194,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3543,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8591, Validation Loss: 0.3365,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.7725, Validation Loss: 0.4002,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8281, Validation Loss: 0.3476,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8058, Validation Loss: 0.3768,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8263, Validation Loss: 0.3493,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8392, Validation Loss: 0.3336,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.7854, Validation Loss: 0.4135,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8392, Validation Loss: 0.3721,  Current Best Accuracy: 0.8819,  Current Best Validation Loss: 0.3088

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6183, Validation Loss: 0.6787
	--> Epoch [2/100], Loss: 0.6632, Validation Loss: 0.6634
	--> Epoch [3/100], Loss: 0.6856, Validation Loss: 0.6496
	--> Epoch [4/100], Loss: 0.6903, Validation Loss: 0.6323
	--> Epoch [5/100], Loss: 0.6893, Validation Loss: 0.6148
	--> Epoch [6/100], Loss: 0.6132, Validation Loss: 0.5944
	--> Epoch [7/100], Loss: 0.4193, Validation Loss: 0.5806
	--> Epoch [8/100], Loss: 0.5324, Validation Loss: 0.5630
	--> Epoch [9/100], Loss: 0.5025, Validation Loss: 0.5465
	--> Epoch [10/100], Loss: 0.5490, Validation Loss: 0.5334
	--> Epoch [11/100], Loss: 0.5159, Validation Loss: 0.5148
	--> Epoch [12/100], Loss: 0.4243, Validation Loss: 0.5068
	--> Epoch [13/100], Loss: 0.4448, Validation Loss: 0.4910
	--> Epoch [14/100], Loss: 0.6944, Validation Loss: 0.4769
	--> Epoch [15/100], Loss: 0.4757, Validation Loss: 0.4646
	--> Epoch [16/100], Loss: 0.3869, Validation Loss: 0.4543
	--> Epoch [17/100], Loss: 0.4401, Validation Loss: 0.4390
	--> Epoch [18/100], Loss: 0.4413, Validation Loss: 0.4287
	--> Epoch [19/100], Loss: 0.1081, Validation Loss: 0.4223
	--> Epoch [20/100], Loss: 0.0897, Validation Loss: 0.4095
	--> Epoch [21/100], Loss: 0.0697, Validation Loss: 0.4002
	--> Epoch [22/100], Loss: 0.1085, Validation Loss: 0.3910
	--> Epoch [23/100], Loss: 0.3472, Validation Loss: 0.3828
	--> Epoch [24/100], Loss: 0.6939, Validation Loss: 0.3784
	--> Epoch [25/100], Loss: 0.1523, Validation Loss: 0.3704
	--> Epoch [26/100], Loss: 0.0573, Validation Loss: 0.3643
	--> Epoch [27/100], Loss: 0.6938, Validation Loss: 0.3597
	--> Epoch [28/100], Loss: 0.3511, Validation Loss: 0.3552
	--> Epoch [29/100], Loss: 0.0234, Validation Loss: 0.3490
	--> Epoch [30/100], Loss: 0.0142, Validation Loss: 0.3460
	--> Epoch [31/100], Loss: 0.2469, Validation Loss: 0.3416
	--> Epoch [32/100], Loss: 0.1328, Validation Loss: 0.3435
	--> Epoch [33/100], Loss: 0.0116, Validation Loss: 0.3452
	--> Epoch [34/100], Loss: 0.3325, Validation Loss: 0.3457
Early stopping
	--> Training for Fold 1 took 0.9109964370727539 sec, using 34 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7608, Validation Loss: 0.6912
	--> Epoch [2/100], Loss: 0.6993, Validation Loss: 0.6467
	--> Epoch [3/100], Loss: 0.3282, Validation Loss: 0.6140
	--> Epoch [4/100], Loss: 0.1843, Validation Loss: 0.5979
	--> Epoch [5/100], Loss: 0.7177, Validation Loss: 0.5858
	--> Epoch [6/100], Loss: 0.4863, Validation Loss: 0.5736
	--> Epoch [7/100], Loss: 0.4901, Validation Loss: 0.5408
	--> Epoch [8/100], Loss: 0.5928, Validation Loss: 0.5204
	--> Epoch [9/100], Loss: 0.2822, Validation Loss: 0.5002
	--> Epoch [10/100], Loss: 0.3399, Validation Loss: 0.4898
	--> Epoch [11/100], Loss: 0.4021, Validation Loss: 0.4677
	--> Epoch [12/100], Loss: 0.3083, Validation Loss: 0.4554
	--> Epoch [13/100], Loss: 0.2906, Validation Loss: 0.4438
	--> Epoch [14/100], Loss: 0.3311, Validation Loss: 0.4386
	--> Epoch [15/100], Loss: 0.1869, Validation Loss: 0.4246
	--> Epoch [16/100], Loss: 0.2970, Validation Loss: 0.4144
	--> Epoch [17/100], Loss: 0.0238, Validation Loss: 0.4080
	--> Epoch [18/100], Loss: 0.0400, Validation Loss: 0.3928
	--> Epoch [19/100], Loss: 0.5327, Validation Loss: 0.3779
	--> Epoch [20/100], Loss: 0.0421, Validation Loss: 0.3707
	--> Epoch [21/100], Loss: 0.4853, Validation Loss: 0.3661
	--> Epoch [22/100], Loss: 0.0018, Validation Loss: 0.3513
	--> Epoch [23/100], Loss: 0.2786, Validation Loss: 0.3521
	--> Epoch [24/100], Loss: 0.4674, Validation Loss: 0.3434
	--> Epoch [25/100], Loss: 0.4138, Validation Loss: 0.3457
	--> Epoch [26/100], Loss: 0.0437, Validation Loss: 0.3448
	--> Epoch [27/100], Loss: 0.4684, Validation Loss: 0.3378
	--> Epoch [28/100], Loss: 0.4070, Validation Loss: 0.3326
	--> Epoch [29/100], Loss: 0.0522, Validation Loss: 0.3207
	--> Epoch [30/100], Loss: 0.4630, Validation Loss: 0.3159
	--> Epoch [31/100], Loss: 0.0002, Validation Loss: 0.3134
	--> Epoch [32/100], Loss: 0.4571, Validation Loss: 0.3113
	--> Epoch [33/100], Loss: 0.0310, Validation Loss: 0.3091
	--> Epoch [34/100], Loss: 0.0347, Validation Loss: 0.3073
	--> Epoch [35/100], Loss: 0.0102, Validation Loss: 0.3042
	--> Epoch [36/100], Loss: 0.0210, Validation Loss: 0.3012
	--> Epoch [37/100], Loss: 0.2580, Validation Loss: 0.3006
	--> Epoch [38/100], Loss: 0.0043, Validation Loss: 0.2961
	--> Epoch [39/100], Loss: 0.0044, Validation Loss: 0.2887
	--> Epoch [40/100], Loss: 0.2546, Validation Loss: 0.2906
	--> Epoch [41/100], Loss: 0.0130, Validation Loss: 0.2802
	--> Epoch [42/100], Loss: 0.0032, Validation Loss: 0.2791
	--> Epoch [43/100], Loss: 0.0028, Validation Loss: 0.2775
	--> Epoch [44/100], Loss: 0.4626, Validation Loss: 0.2751
	--> Epoch [45/100], Loss: 0.0018, Validation Loss: 0.2806
	--> Epoch [46/100], Loss: 0.0045, Validation Loss: 0.2790
	--> Epoch [47/100], Loss: 0.0027, Validation Loss: 0.2816
Early stopping
	--> Training for Fold 2 took 1.302825689315796 sec, using 47 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.5437, Validation Loss: 0.6721
	--> Epoch [2/100], Loss: 0.7208, Validation Loss: 0.6490
	--> Epoch [3/100], Loss: 0.4830, Validation Loss: 0.6296
	--> Epoch [4/100], Loss: 0.5144, Validation Loss: 0.6111
	--> Epoch [5/100], Loss: 0.5565, Validation Loss: 0.5919
	--> Epoch [6/100], Loss: 0.5278, Validation Loss: 0.5720
	--> Epoch [7/100], Loss: 0.4208, Validation Loss: 0.5528
	--> Epoch [8/100], Loss: 0.5288, Validation Loss: 0.5368
	--> Epoch [9/100], Loss: 0.1402, Validation Loss: 0.5282
	--> Epoch [10/100], Loss: 0.4080, Validation Loss: 0.5153
	--> Epoch [11/100], Loss: 0.4102, Validation Loss: 0.4927
	--> Epoch [12/100], Loss: 0.3120, Validation Loss: 0.4794
	--> Epoch [13/100], Loss: 0.3229, Validation Loss: 0.4778
	--> Epoch [14/100], Loss: 0.1503, Validation Loss: 0.4634
	--> Epoch [15/100], Loss: 0.3713, Validation Loss: 0.4520
	--> Epoch [16/100], Loss: 0.3069, Validation Loss: 0.4380
	--> Epoch [17/100], Loss: 0.3761, Validation Loss: 0.4334
	--> Epoch [18/100], Loss: 0.4290, Validation Loss: 0.4320
	--> Epoch [19/100], Loss: 0.0373, Validation Loss: 0.4253
	--> Epoch [20/100], Loss: 0.4207, Validation Loss: 0.4131
	--> Epoch [21/100], Loss: 0.3327, Validation Loss: 0.4044
	--> Epoch [22/100], Loss: 0.4093, Validation Loss: 0.4006
	--> Epoch [23/100], Loss: 0.0417, Validation Loss: 0.3922
	--> Epoch [24/100], Loss: 0.0103, Validation Loss: 0.3851
	--> Epoch [25/100], Loss: 0.4129, Validation Loss: 0.3753
	--> Epoch [26/100], Loss: 0.3979, Validation Loss: 0.3712
	--> Epoch [27/100], Loss: 0.3143, Validation Loss: 0.3774
	--> Epoch [28/100], Loss: 0.6979, Validation Loss: 0.3703
	--> Epoch [29/100], Loss: 0.5457, Validation Loss: 0.3645
	--> Epoch [30/100], Loss: 0.3984, Validation Loss: 0.3602
	--> Epoch [31/100], Loss: 0.0716, Validation Loss: 0.3610
	--> Epoch [32/100], Loss: 0.4061, Validation Loss: 0.3576
	--> Epoch [33/100], Loss: 0.0080, Validation Loss: 0.3512
	--> Epoch [34/100], Loss: 0.4067, Validation Loss: 0.3512
	--> Epoch [35/100], Loss: 0.2982, Validation Loss: 0.3481
	--> Epoch [36/100], Loss: 0.0207, Validation Loss: 0.3479
	--> Epoch [37/100], Loss: 0.6989, Validation Loss: 0.3482
	--> Epoch [38/100], Loss: 0.6989, Validation Loss: 0.3462
	--> Epoch [39/100], Loss: 0.2946, Validation Loss: 0.3419
	--> Epoch [40/100], Loss: 0.0364, Validation Loss: 0.3372
	--> Epoch [41/100], Loss: 0.0048, Validation Loss: 0.3344
	--> Epoch [42/100], Loss: 0.0040, Validation Loss: 0.3366
	--> Epoch [43/100], Loss: 0.4054, Validation Loss: 0.3329
	--> Epoch [44/100], Loss: 0.0041, Validation Loss: 0.3308
	--> Epoch [45/100], Loss: 0.0527, Validation Loss: 0.3332
	--> Epoch [46/100], Loss: 0.0031, Validation Loss: 0.3346
	--> Epoch [47/100], Loss: 0.3009, Validation Loss: 0.3324
Early stopping
	--> Training for Fold 3 took 1.388120412826538 sec, using 47 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7355, Validation Loss: 0.7512
	--> Epoch [2/100], Loss: 0.7139, Validation Loss: 0.7283
	--> Epoch [3/100], Loss: 0.6846, Validation Loss: 0.6984
	--> Epoch [4/100], Loss: 0.7881, Validation Loss: 0.6866
	--> Epoch [5/100], Loss: 0.6787, Validation Loss: 0.6618
	--> Epoch [6/100], Loss: 0.6243, Validation Loss: 0.6449
	--> Epoch [7/100], Loss: 0.4806, Validation Loss: 0.6275
	--> Epoch [8/100], Loss: 0.5768, Validation Loss: 0.6130
	--> Epoch [9/100], Loss: 0.6030, Validation Loss: 0.5982
	--> Epoch [10/100], Loss: 0.3764, Validation Loss: 0.5743
	--> Epoch [11/100], Loss: 0.2436, Validation Loss: 0.5464
	--> Epoch [12/100], Loss: 0.3179, Validation Loss: 0.5289
	--> Epoch [13/100], Loss: 0.1664, Validation Loss: 0.5183
	--> Epoch [14/100], Loss: 0.1237, Validation Loss: 0.5076
	--> Epoch [15/100], Loss: 0.4859, Validation Loss: 0.4986
	--> Epoch [16/100], Loss: 0.2452, Validation Loss: 0.4816
	--> Epoch [17/100], Loss: 0.1123, Validation Loss: 0.4675
	--> Epoch [18/100], Loss: 0.1793, Validation Loss: 0.4521
	--> Epoch [19/100], Loss: 0.3291, Validation Loss: 0.4415
	--> Epoch [20/100], Loss: 0.6956, Validation Loss: 0.4307
	--> Epoch [21/100], Loss: 0.2464, Validation Loss: 0.4216
	--> Epoch [22/100], Loss: 0.4729, Validation Loss: 0.4314
	--> Epoch [23/100], Loss: 0.2435, Validation Loss: 0.4282
	--> Epoch [24/100], Loss: 0.4625, Validation Loss: 0.4239
Early stopping
	--> Training for Fold 4 took 0.6895120143890381 sec, using 24 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8990, Validation Loss: 0.6087
	--> Epoch [2/100], Loss: 0.7283, Validation Loss: 0.5939
	--> Epoch [3/100], Loss: 0.6693, Validation Loss: 0.5886
	--> Epoch [4/100], Loss: 0.5450, Validation Loss: 0.5849
	--> Epoch [5/100], Loss: 0.5287, Validation Loss: 0.5818
	--> Epoch [6/100], Loss: 0.6583, Validation Loss: 0.5886
	--> Epoch [7/100], Loss: 0.4129, Validation Loss: 0.5961
	--> Epoch [8/100], Loss: 0.3467, Validation Loss: 0.5997
Early stopping
	--> Training for Fold 5 took 0.2414994239807129 sec, using 8 epochs

Median number of epochs used: 34 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/34], Loss: 0.6049
	--> Final training Epoch [2/34], Loss: 0.5124
	--> Final training Epoch [3/34], Loss: 0.3648
	--> Final training Epoch [4/34], Loss: 0.4868
	--> Final training Epoch [5/34], Loss: 0.6008
	--> Final training Epoch [6/34], Loss: 0.5869
	--> Final training Epoch [7/34], Loss: 0.8877
	--> Final training Epoch [8/34], Loss: 0.3676
	--> Final training Epoch [9/34], Loss: 0.5303
	--> Final training Epoch [10/34], Loss: 0.3309
	--> Final training Epoch [11/34], Loss: 0.5782
	--> Final training Epoch [12/34], Loss: 0.2583
	--> Final training Epoch [13/34], Loss: 0.4235
	--> Final training Epoch [14/34], Loss: 0.2845
	--> Final training Epoch [15/34], Loss: 0.5636
	--> Final training Epoch [16/34], Loss: 0.4607
	--> Final training Epoch [17/34], Loss: 0.4243
	--> Final training Epoch [18/34], Loss: 0.1402
	--> Final training Epoch [19/34], Loss: 0.4169
	--> Final training Epoch [20/34], Loss: 0.5940
	--> Final training Epoch [21/34], Loss: 0.3462
	--> Final training Epoch [22/34], Loss: 0.3966
	--> Final training Epoch [23/34], Loss: 0.3340
	--> Final training Epoch [24/34], Loss: 0.2283
	--> Final training Epoch [25/34], Loss: 0.4055
	--> Final training Epoch [26/34], Loss: 0.3904
	--> Final training Epoch [27/34], Loss: 0.1227
	--> Final training Epoch [28/34], Loss: 0.2661
	--> Final training Epoch [29/34], Loss: 0.3881
	--> Final training Epoch [30/34], Loss: 0.2284
	--> Final training Epoch [31/34], Loss: 0.1903
	--> Final training Epoch [32/34], Loss: 0.2500
	--> Final training Epoch [33/34], Loss: 0.2233
	--> Final training Epoch [34/34], Loss: 0.2315

Final training took 1.1310577392578125 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.7816
	--> Final Precision: 0.7778
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6364
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 8, Alpha: 1e-05, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.9023, Validation Loss: 0.3485,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3485
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8070, Validation Loss: 0.4286,  Current Best Accuracy: 0.9023,  Current Best Validation Loss: 0.3485

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6262, Validation Loss: 0.6295
	--> Epoch [2/100], Loss: 0.4893, Validation Loss: 0.6021
	--> Epoch [3/100], Loss: 0.5306, Validation Loss: 0.5805
	--> Epoch [4/100], Loss: 0.4171, Validation Loss: 0.5569
	--> Epoch [5/100], Loss: 0.4610, Validation Loss: 0.5360
	--> Epoch [6/100], Loss: 0.5003, Validation Loss: 0.5197
	--> Epoch [7/100], Loss: 0.4298, Validation Loss: 0.5077
	--> Epoch [8/100], Loss: 0.3788, Validation Loss: 0.4938
	--> Epoch [9/100], Loss: 0.3254, Validation Loss: 0.4778
	--> Epoch [10/100], Loss: 0.3568, Validation Loss: 0.4636
	--> Epoch [11/100], Loss: 0.2509, Validation Loss: 0.4500
	--> Epoch [12/100], Loss: 0.3905, Validation Loss: 0.4376
	--> Epoch [13/100], Loss: 0.2025, Validation Loss: 0.4298
	--> Epoch [14/100], Loss: 0.2761, Validation Loss: 0.4228
	--> Epoch [15/100], Loss: 0.3630, Validation Loss: 0.4146
	--> Epoch [16/100], Loss: 0.2973, Validation Loss: 0.4069
	--> Epoch [17/100], Loss: 0.2953, Validation Loss: 0.3966
	--> Epoch [18/100], Loss: 0.2176, Validation Loss: 0.3876
	--> Epoch [19/100], Loss: 0.1870, Validation Loss: 0.3826
	--> Epoch [20/100], Loss: 0.1780, Validation Loss: 0.3759
	--> Epoch [21/100], Loss: 0.1655, Validation Loss: 0.3701
	--> Epoch [22/100], Loss: 0.2775, Validation Loss: 0.3623
	--> Epoch [23/100], Loss: 0.2765, Validation Loss: 0.3562
	--> Epoch [24/100], Loss: 0.2074, Validation Loss: 0.3516
	--> Epoch [25/100], Loss: 0.0879, Validation Loss: 0.3435
	--> Epoch [26/100], Loss: 0.0921, Validation Loss: 0.3377
	--> Epoch [27/100], Loss: 0.0489, Validation Loss: 0.3319
	--> Epoch [28/100], Loss: 0.2942, Validation Loss: 0.3264
	--> Epoch [29/100], Loss: 0.1274, Validation Loss: 0.3251
	--> Epoch [30/100], Loss: 0.1798, Validation Loss: 0.3216
	--> Epoch [31/100], Loss: 0.0653, Validation Loss: 0.3177
	--> Epoch [32/100], Loss: 0.1842, Validation Loss: 0.3133
	--> Epoch [33/100], Loss: 0.1396, Validation Loss: 0.3075
	--> Epoch [34/100], Loss: 0.1570, Validation Loss: 0.3081
	--> Epoch [35/100], Loss: 0.0489, Validation Loss: 0.3054
	--> Epoch [36/100], Loss: 0.0920, Validation Loss: 0.3034
	--> Epoch [37/100], Loss: 0.0268, Validation Loss: 0.3014
	--> Epoch [38/100], Loss: 0.1578, Validation Loss: 0.3011
	--> Epoch [39/100], Loss: 0.1372, Validation Loss: 0.2999
	--> Epoch [40/100], Loss: 0.2016, Validation Loss: 0.2970
	--> Epoch [41/100], Loss: 0.0101, Validation Loss: 0.2968
	--> Epoch [42/100], Loss: 0.1143, Validation Loss: 0.2946
	--> Epoch [43/100], Loss: 0.0711, Validation Loss: 0.2937
	--> Epoch [44/100], Loss: 0.0877, Validation Loss: 0.2936
	--> Epoch [45/100], Loss: 0.0837, Validation Loss: 0.2911
	--> Epoch [46/100], Loss: 0.0477, Validation Loss: 0.2881
	--> Epoch [47/100], Loss: 0.0230, Validation Loss: 0.2863
	--> Epoch [48/100], Loss: 0.0328, Validation Loss: 0.2865
	--> Epoch [49/100], Loss: 0.0380, Validation Loss: 0.2853
	--> Epoch [50/100], Loss: 0.0833, Validation Loss: 0.2834
	--> Epoch [51/100], Loss: 0.0762, Validation Loss: 0.2825
	--> Epoch [52/100], Loss: 0.0331, Validation Loss: 0.2820
	--> Epoch [53/100], Loss: 0.0131, Validation Loss: 0.2809
	--> Epoch [54/100], Loss: 0.0208, Validation Loss: 0.2798
	--> Epoch [55/100], Loss: 0.0539, Validation Loss: 0.2793
	--> Epoch [56/100], Loss: 0.0125, Validation Loss: 0.2735
	--> Epoch [57/100], Loss: 0.0326, Validation Loss: 0.2741
	--> Epoch [58/100], Loss: 0.0081, Validation Loss: 0.2733
	--> Epoch [59/100], Loss: 0.1170, Validation Loss: 0.2715
	--> Epoch [60/100], Loss: 0.0402, Validation Loss: 0.2701
	--> Epoch [61/100], Loss: 0.0079, Validation Loss: 0.2691
	--> Epoch [62/100], Loss: 0.0225, Validation Loss: 0.2664
	--> Epoch [63/100], Loss: 0.0225, Validation Loss: 0.2657
	--> Epoch [64/100], Loss: 0.1045, Validation Loss: 0.2623
	--> Epoch [65/100], Loss: 0.0097, Validation Loss: 0.2609
	--> Epoch [66/100], Loss: 0.0204, Validation Loss: 0.2597
	--> Epoch [67/100], Loss: 0.0107, Validation Loss: 0.2602
	--> Epoch [68/100], Loss: 0.0172, Validation Loss: 0.2581
	--> Epoch [69/100], Loss: 0.0948, Validation Loss: 0.2557
	--> Epoch [70/100], Loss: 0.0204, Validation Loss: 0.2536
	--> Epoch [71/100], Loss: 0.0326, Validation Loss: 0.2533
	--> Epoch [72/100], Loss: 0.1092, Validation Loss: 0.2546
	--> Epoch [73/100], Loss: 0.0057, Validation Loss: 0.2511
	--> Epoch [74/100], Loss: 0.0151, Validation Loss: 0.2506
	--> Epoch [75/100], Loss: 0.0946, Validation Loss: 0.2514
	--> Epoch [76/100], Loss: 0.0042, Validation Loss: 0.2526
	--> Epoch [77/100], Loss: 0.0184, Validation Loss: 0.2534
Early stopping
	--> Training for Fold 1 took 1.0259323120117188 sec, using 77 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.8569, Validation Loss: 0.6019
	--> Epoch [2/100], Loss: 0.7822, Validation Loss: 0.5801
	--> Epoch [3/100], Loss: 0.7245, Validation Loss: 0.5590
	--> Epoch [4/100], Loss: 0.6800, Validation Loss: 0.5392
	--> Epoch [5/100], Loss: 0.6787, Validation Loss: 0.5206
	--> Epoch [6/100], Loss: 0.5885, Validation Loss: 0.5011
	--> Epoch [7/100], Loss: 0.5570, Validation Loss: 0.4793
	--> Epoch [8/100], Loss: 0.5434, Validation Loss: 0.4638
	--> Epoch [9/100], Loss: 0.4374, Validation Loss: 0.4429
	--> Epoch [10/100], Loss: 0.4020, Validation Loss: 0.4231
	--> Epoch [11/100], Loss: 0.3773, Validation Loss: 0.4045
	--> Epoch [12/100], Loss: 0.4048, Validation Loss: 0.3878
	--> Epoch [13/100], Loss: 0.2646, Validation Loss: 0.3727
	--> Epoch [14/100], Loss: 0.3346, Validation Loss: 0.3599
	--> Epoch [15/100], Loss: 0.2801, Validation Loss: 0.3496
	--> Epoch [16/100], Loss: 0.2475, Validation Loss: 0.3393
	--> Epoch [17/100], Loss: 0.2249, Validation Loss: 0.3288
	--> Epoch [18/100], Loss: 0.1542, Validation Loss: 0.3162
	--> Epoch [19/100], Loss: 0.2978, Validation Loss: 0.3071
	--> Epoch [20/100], Loss: 0.1906, Validation Loss: 0.2992
	--> Epoch [21/100], Loss: 0.1820, Validation Loss: 0.2900
	--> Epoch [22/100], Loss: 0.1593, Validation Loss: 0.2822
	--> Epoch [23/100], Loss: 0.1105, Validation Loss: 0.2755
	--> Epoch [24/100], Loss: 0.3803, Validation Loss: 0.2692
	--> Epoch [25/100], Loss: 0.1608, Validation Loss: 0.2599
	--> Epoch [26/100], Loss: 0.1325, Validation Loss: 0.2546
	--> Epoch [27/100], Loss: 0.0956, Validation Loss: 0.2506
	--> Epoch [28/100], Loss: 0.0629, Validation Loss: 0.2450
	--> Epoch [29/100], Loss: 0.1774, Validation Loss: 0.2413
	--> Epoch [30/100], Loss: 0.1391, Validation Loss: 0.2352
	--> Epoch [31/100], Loss: 0.1161, Validation Loss: 0.2305
	--> Epoch [32/100], Loss: 0.0569, Validation Loss: 0.2263
	--> Epoch [33/100], Loss: 0.0855, Validation Loss: 0.2210
	--> Epoch [34/100], Loss: 0.0782, Validation Loss: 0.2184
	--> Epoch [35/100], Loss: 0.0992, Validation Loss: 0.2149
	--> Epoch [36/100], Loss: 0.0777, Validation Loss: 0.2096
	--> Epoch [37/100], Loss: 0.1080, Validation Loss: 0.2052
	--> Epoch [38/100], Loss: 0.0646, Validation Loss: 0.2010
	--> Epoch [39/100], Loss: 0.1094, Validation Loss: 0.1955
	--> Epoch [40/100], Loss: 0.1127, Validation Loss: 0.1920
	--> Epoch [41/100], Loss: 0.0589, Validation Loss: 0.1895
	--> Epoch [42/100], Loss: 0.1330, Validation Loss: 0.1866
	--> Epoch [43/100], Loss: 0.0561, Validation Loss: 0.1845
	--> Epoch [44/100], Loss: 0.1256, Validation Loss: 0.1838
	--> Epoch [45/100], Loss: 0.1223, Validation Loss: 0.1825
	--> Epoch [46/100], Loss: 0.1615, Validation Loss: 0.1781
	--> Epoch [47/100], Loss: 0.0487, Validation Loss: 0.1761
	--> Epoch [48/100], Loss: 0.0947, Validation Loss: 0.1761
	--> Epoch [49/100], Loss: 0.0442, Validation Loss: 0.1741
	--> Epoch [50/100], Loss: 0.0490, Validation Loss: 0.1723
	--> Epoch [51/100], Loss: 0.0190, Validation Loss: 0.1717
	--> Epoch [52/100], Loss: 0.0427, Validation Loss: 0.1707
	--> Epoch [53/100], Loss: 0.0184, Validation Loss: 0.1707
	--> Epoch [54/100], Loss: 0.1069, Validation Loss: 0.1695
	--> Epoch [55/100], Loss: 0.0214, Validation Loss: 0.1678
	--> Epoch [56/100], Loss: 0.0323, Validation Loss: 0.1637
	--> Epoch [57/100], Loss: 0.0378, Validation Loss: 0.1616
	--> Epoch [58/100], Loss: 0.0385, Validation Loss: 0.1596
	--> Epoch [59/100], Loss: 0.0792, Validation Loss: 0.1577
	--> Epoch [60/100], Loss: 0.0441, Validation Loss: 0.1589
	--> Epoch [61/100], Loss: 0.0271, Validation Loss: 0.1565
	--> Epoch [62/100], Loss: 0.0297, Validation Loss: 0.1556
	--> Epoch [63/100], Loss: 0.0384, Validation Loss: 0.1547
	--> Epoch [64/100], Loss: 0.0208, Validation Loss: 0.1541
	--> Epoch [65/100], Loss: 0.0898, Validation Loss: 0.1532
	--> Epoch [66/100], Loss: 0.0874, Validation Loss: 0.1530
	--> Epoch [67/100], Loss: 0.1162, Validation Loss: 0.1522
	--> Epoch [68/100], Loss: 0.0101, Validation Loss: 0.1514
	--> Epoch [69/100], Loss: 0.0293, Validation Loss: 0.1509
	--> Epoch [70/100], Loss: 0.0282, Validation Loss: 0.1517
	--> Epoch [71/100], Loss: 0.0235, Validation Loss: 0.1504
	--> Epoch [72/100], Loss: 0.0377, Validation Loss: 0.1478
	--> Epoch [73/100], Loss: 0.0138, Validation Loss: 0.1493
	--> Epoch [74/100], Loss: 0.0200, Validation Loss: 0.1502
	--> Epoch [75/100], Loss: 0.1006, Validation Loss: 0.1495
Early stopping
	--> Training for Fold 2 took 0.9789848327636719 sec, using 75 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7858, Validation Loss: 0.6087
	--> Epoch [2/100], Loss: 0.8016, Validation Loss: 0.5927
	--> Epoch [3/100], Loss: 0.8341, Validation Loss: 0.5819
	--> Epoch [4/100], Loss: 0.7416, Validation Loss: 0.5736
	--> Epoch [5/100], Loss: 0.7338, Validation Loss: 0.5632
	--> Epoch [6/100], Loss: 0.7150, Validation Loss: 0.5519
	--> Epoch [7/100], Loss: 0.6863, Validation Loss: 0.5395
	--> Epoch [8/100], Loss: 0.6972, Validation Loss: 0.5288
	--> Epoch [9/100], Loss: 0.6476, Validation Loss: 0.5182
	--> Epoch [10/100], Loss: 0.5978, Validation Loss: 0.5059
	--> Epoch [11/100], Loss: 0.5766, Validation Loss: 0.4927
	--> Epoch [12/100], Loss: 0.5783, Validation Loss: 0.4817
	--> Epoch [13/100], Loss: 0.5572, Validation Loss: 0.4683
	--> Epoch [14/100], Loss: 0.5159, Validation Loss: 0.4586
	--> Epoch [15/100], Loss: 0.5793, Validation Loss: 0.4506
	--> Epoch [16/100], Loss: 0.5078, Validation Loss: 0.4412
	--> Epoch [17/100], Loss: 0.4067, Validation Loss: 0.4290
	--> Epoch [18/100], Loss: 0.4435, Validation Loss: 0.4187
	--> Epoch [19/100], Loss: 0.4790, Validation Loss: 0.4094
	--> Epoch [20/100], Loss: 0.4314, Validation Loss: 0.4017
	--> Epoch [21/100], Loss: 0.4107, Validation Loss: 0.3944
	--> Epoch [22/100], Loss: 0.3340, Validation Loss: 0.3871
	--> Epoch [23/100], Loss: 0.4325, Validation Loss: 0.3796
	--> Epoch [24/100], Loss: 0.3456, Validation Loss: 0.3718
	--> Epoch [25/100], Loss: 0.3436, Validation Loss: 0.3641
	--> Epoch [26/100], Loss: 0.3310, Validation Loss: 0.3576
	--> Epoch [27/100], Loss: 0.3101, Validation Loss: 0.3513
	--> Epoch [28/100], Loss: 0.3427, Validation Loss: 0.3479
	--> Epoch [29/100], Loss: 0.2796, Validation Loss: 0.3433
	--> Epoch [30/100], Loss: 0.3388, Validation Loss: 0.3415
	--> Epoch [31/100], Loss: 0.3366, Validation Loss: 0.3367
	--> Epoch [32/100], Loss: 0.3366, Validation Loss: 0.3312
	--> Epoch [33/100], Loss: 0.2723, Validation Loss: 0.3257
	--> Epoch [34/100], Loss: 0.3317, Validation Loss: 0.3233
	--> Epoch [35/100], Loss: 0.3221, Validation Loss: 0.3199
	--> Epoch [36/100], Loss: 0.3037, Validation Loss: 0.3160
	--> Epoch [37/100], Loss: 0.2389, Validation Loss: 0.3128
	--> Epoch [38/100], Loss: 0.2296, Validation Loss: 0.3094
	--> Epoch [39/100], Loss: 0.2894, Validation Loss: 0.3080
	--> Epoch [40/100], Loss: 0.0961, Validation Loss: 0.3039
	--> Epoch [41/100], Loss: 0.3211, Validation Loss: 0.3018
	--> Epoch [42/100], Loss: 0.1019, Validation Loss: 0.2991
	--> Epoch [43/100], Loss: 0.2583, Validation Loss: 0.2971
	--> Epoch [44/100], Loss: 0.1283, Validation Loss: 0.2944
	--> Epoch [45/100], Loss: 0.1902, Validation Loss: 0.2937
	--> Epoch [46/100], Loss: 0.1884, Validation Loss: 0.2927
	--> Epoch [47/100], Loss: 0.1749, Validation Loss: 0.2894
	--> Epoch [48/100], Loss: 0.1712, Validation Loss: 0.2885
	--> Epoch [49/100], Loss: 0.2776, Validation Loss: 0.2873
	--> Epoch [50/100], Loss: 0.2164, Validation Loss: 0.2844
	--> Epoch [51/100], Loss: 0.1730, Validation Loss: 0.2842
	--> Epoch [52/100], Loss: 0.0897, Validation Loss: 0.2826
	--> Epoch [53/100], Loss: 0.2983, Validation Loss: 0.2807
	--> Epoch [54/100], Loss: 0.2146, Validation Loss: 0.2807
	--> Epoch [55/100], Loss: 0.2122, Validation Loss: 0.2797
	--> Epoch [56/100], Loss: 0.2076, Validation Loss: 0.2770
	--> Epoch [57/100], Loss: 0.2593, Validation Loss: 0.2761
	--> Epoch [58/100], Loss: 0.2703, Validation Loss: 0.2743
	--> Epoch [59/100], Loss: 0.0422, Validation Loss: 0.2729
	--> Epoch [60/100], Loss: 0.2622, Validation Loss: 0.2724
	--> Epoch [61/100], Loss: 0.1430, Validation Loss: 0.2720
	--> Epoch [62/100], Loss: 0.1445, Validation Loss: 0.2710
	--> Epoch [63/100], Loss: 0.0894, Validation Loss: 0.2700
	--> Epoch [64/100], Loss: 0.0827, Validation Loss: 0.2683
	--> Epoch [65/100], Loss: 0.1386, Validation Loss: 0.2668
	--> Epoch [66/100], Loss: 0.1378, Validation Loss: 0.2662
	--> Epoch [67/100], Loss: 0.0791, Validation Loss: 0.2645
	--> Epoch [68/100], Loss: 0.2465, Validation Loss: 0.2640
	--> Epoch [69/100], Loss: 0.0772, Validation Loss: 0.2645
	--> Epoch [70/100], Loss: 0.1830, Validation Loss: 0.2626
	--> Epoch [71/100], Loss: 0.0741, Validation Loss: 0.2617
	--> Epoch [72/100], Loss: 0.1854, Validation Loss: 0.2609
	--> Epoch [73/100], Loss: 0.1238, Validation Loss: 0.2593
	--> Epoch [74/100], Loss: 0.1792, Validation Loss: 0.2569
	--> Epoch [75/100], Loss: 0.1779, Validation Loss: 0.2559
	--> Epoch [76/100], Loss: 0.1759, Validation Loss: 0.2549
	--> Epoch [77/100], Loss: 0.2905, Validation Loss: 0.2545
	--> Epoch [78/100], Loss: 0.1252, Validation Loss: 0.2535
	--> Epoch [79/100], Loss: 0.1163, Validation Loss: 0.2521
	--> Epoch [80/100], Loss: 0.2310, Validation Loss: 0.2512
	--> Epoch [81/100], Loss: 0.2290, Validation Loss: 0.2514
	--> Epoch [82/100], Loss: 0.1748, Validation Loss: 0.2511
	--> Epoch [83/100], Loss: 0.1740, Validation Loss: 0.2503
	--> Epoch [84/100], Loss: 0.2787, Validation Loss: 0.2501
	--> Epoch [85/100], Loss: 0.1712, Validation Loss: 0.2487
	--> Epoch [86/100], Loss: 0.2473, Validation Loss: 0.2490
	--> Epoch [87/100], Loss: 0.1167, Validation Loss: 0.2490
	--> Epoch [88/100], Loss: 0.1662, Validation Loss: 0.2456
	--> Epoch [89/100], Loss: 0.1154, Validation Loss: 0.2461
	--> Epoch [90/100], Loss: 0.2183, Validation Loss: 0.2480
	--> Epoch [91/100], Loss: 0.0619, Validation Loss: 0.2511
Early stopping
	--> Training for Fold 3 took 1.1792950630187988 sec, using 91 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7096, Validation Loss: 0.6091
	--> Epoch [2/100], Loss: 0.5853, Validation Loss: 0.5774
	--> Epoch [3/100], Loss: 0.5276, Validation Loss: 0.5530
	--> Epoch [4/100], Loss: 0.5179, Validation Loss: 0.5327
	--> Epoch [5/100], Loss: 0.4201, Validation Loss: 0.5070
	--> Epoch [6/100], Loss: 0.4000, Validation Loss: 0.4905
	--> Epoch [7/100], Loss: 0.4749, Validation Loss: 0.4753
	--> Epoch [8/100], Loss: 0.3302, Validation Loss: 0.4611
	--> Epoch [9/100], Loss: 0.2985, Validation Loss: 0.4493
	--> Epoch [10/100], Loss: 0.3094, Validation Loss: 0.4380
	--> Epoch [11/100], Loss: 0.3124, Validation Loss: 0.4271
	--> Epoch [12/100], Loss: 0.2780, Validation Loss: 0.4160
	--> Epoch [13/100], Loss: 0.2886, Validation Loss: 0.4074
	--> Epoch [14/100], Loss: 0.2200, Validation Loss: 0.4019
	--> Epoch [15/100], Loss: 0.2529, Validation Loss: 0.3962
	--> Epoch [16/100], Loss: 0.2989, Validation Loss: 0.3920
	--> Epoch [17/100], Loss: 0.1641, Validation Loss: 0.3839
	--> Epoch [18/100], Loss: 0.1699, Validation Loss: 0.3792
	--> Epoch [19/100], Loss: 0.1577, Validation Loss: 0.3787
	--> Epoch [20/100], Loss: 0.1843, Validation Loss: 0.3736
	--> Epoch [21/100], Loss: 0.2462, Validation Loss: 0.3672
	--> Epoch [22/100], Loss: 0.1621, Validation Loss: 0.3640
	--> Epoch [23/100], Loss: 0.1123, Validation Loss: 0.3592
	--> Epoch [24/100], Loss: 0.1579, Validation Loss: 0.3545
	--> Epoch [25/100], Loss: 0.1305, Validation Loss: 0.3493
	--> Epoch [26/100], Loss: 0.0937, Validation Loss: 0.3474
	--> Epoch [27/100], Loss: 0.2045, Validation Loss: 0.3453
	--> Epoch [28/100], Loss: 0.0832, Validation Loss: 0.3411
	--> Epoch [29/100], Loss: 0.1254, Validation Loss: 0.3426
	--> Epoch [30/100], Loss: 0.1019, Validation Loss: 0.3450
	--> Epoch [31/100], Loss: 0.1192, Validation Loss: 0.3411
	--> Epoch [32/100], Loss: 0.0773, Validation Loss: 0.3401
	--> Epoch [33/100], Loss: 0.1065, Validation Loss: 0.3395
	--> Epoch [34/100], Loss: 0.1141, Validation Loss: 0.3381
	--> Epoch [35/100], Loss: 0.0653, Validation Loss: 0.3389
	--> Epoch [36/100], Loss: 0.1161, Validation Loss: 0.3378
	--> Epoch [37/100], Loss: 0.1133, Validation Loss: 0.3370
	--> Epoch [38/100], Loss: 0.1183, Validation Loss: 0.3359
	--> Epoch [39/100], Loss: 0.0922, Validation Loss: 0.3335
	--> Epoch [40/100], Loss: 0.0949, Validation Loss: 0.3316
	--> Epoch [41/100], Loss: 0.0485, Validation Loss: 0.3316
	--> Epoch [42/100], Loss: 0.0387, Validation Loss: 0.3319
	--> Epoch [43/100], Loss: 0.0742, Validation Loss: 0.3319
	--> Epoch [44/100], Loss: 0.0483, Validation Loss: 0.3313
	--> Epoch [45/100], Loss: 0.0379, Validation Loss: 0.3304
	--> Epoch [46/100], Loss: 0.0485, Validation Loss: 0.3308
	--> Epoch [47/100], Loss: 0.0322, Validation Loss: 0.3313
	--> Epoch [48/100], Loss: 0.1174, Validation Loss: 0.3314
Early stopping
	--> Training for Fold 4 took 0.723726749420166 sec, using 48 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6895, Validation Loss: 0.6074
	--> Epoch [2/100], Loss: 0.6821, Validation Loss: 0.5882
	--> Epoch [3/100], Loss: 0.6385, Validation Loss: 0.5720
	--> Epoch [4/100], Loss: 0.6204, Validation Loss: 0.5587
	--> Epoch [5/100], Loss: 0.6012, Validation Loss: 0.5479
	--> Epoch [6/100], Loss: 0.5689, Validation Loss: 0.5396
	--> Epoch [7/100], Loss: 0.5059, Validation Loss: 0.5308
	--> Epoch [8/100], Loss: 0.4849, Validation Loss: 0.5261
	--> Epoch [9/100], Loss: 0.4400, Validation Loss: 0.5161
	--> Epoch [10/100], Loss: 0.4191, Validation Loss: 0.5116
	--> Epoch [11/100], Loss: 0.4228, Validation Loss: 0.5059
	--> Epoch [12/100], Loss: 0.3999, Validation Loss: 0.5022
	--> Epoch [13/100], Loss: 0.3432, Validation Loss: 0.5012
	--> Epoch [14/100], Loss: 0.3495, Validation Loss: 0.4989
	--> Epoch [15/100], Loss: 0.3858, Validation Loss: 0.4934
	--> Epoch [16/100], Loss: 0.3352, Validation Loss: 0.4927
	--> Epoch [17/100], Loss: 0.2170, Validation Loss: 0.4904
	--> Epoch [18/100], Loss: 0.2579, Validation Loss: 0.4883
	--> Epoch [19/100], Loss: 0.2331, Validation Loss: 0.4899
	--> Epoch [20/100], Loss: 0.2383, Validation Loss: 0.4901
	--> Epoch [21/100], Loss: 0.2021, Validation Loss: 0.4869
	--> Epoch [22/100], Loss: 0.1290, Validation Loss: 0.4825
	--> Epoch [23/100], Loss: 0.1821, Validation Loss: 0.4804
	--> Epoch [24/100], Loss: 0.1922, Validation Loss: 0.4816
	--> Epoch [25/100], Loss: 0.3128, Validation Loss: 0.4806
	--> Epoch [26/100], Loss: 0.1498, Validation Loss: 0.4804
Early stopping
	--> Training for Fold 5 took 0.35732245445251465 sec, using 26 epochs

Median number of epochs used: 75 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/75], Loss: 0.5945
	--> Final training Epoch [2/75], Loss: 0.5628
	--> Final training Epoch [3/75], Loss: 0.5291
	--> Final training Epoch [4/75], Loss: 0.5703
	--> Final training Epoch [5/75], Loss: 0.4793
	--> Final training Epoch [6/75], Loss: 0.5105
	--> Final training Epoch [7/75], Loss: 0.4441
	--> Final training Epoch [8/75], Loss: 0.4226
	--> Final training Epoch [9/75], Loss: 0.3935
	--> Final training Epoch [10/75], Loss: 0.3367
	--> Final training Epoch [11/75], Loss: 0.3157
	--> Final training Epoch [12/75], Loss: 0.2549
	--> Final training Epoch [13/75], Loss: 0.3480
	--> Final training Epoch [14/75], Loss: 0.2446
	--> Final training Epoch [15/75], Loss: 0.2943
	--> Final training Epoch [16/75], Loss: 0.2481
	--> Final training Epoch [17/75], Loss: 0.2263
	--> Final training Epoch [18/75], Loss: 0.2265
	--> Final training Epoch [19/75], Loss: 0.1783
	--> Final training Epoch [20/75], Loss: 0.1290
	--> Final training Epoch [21/75], Loss: 0.1989
	--> Final training Epoch [22/75], Loss: 0.1774
	--> Final training Epoch [23/75], Loss: 0.2035
	--> Final training Epoch [24/75], Loss: 0.1331
	--> Final training Epoch [25/75], Loss: 0.0834
	--> Final training Epoch [26/75], Loss: 0.0904
	--> Final training Epoch [27/75], Loss: 0.0970
	--> Final training Epoch [28/75], Loss: 0.1473
	--> Final training Epoch [29/75], Loss: 0.0457
	--> Final training Epoch [30/75], Loss: 0.1414
	--> Final training Epoch [31/75], Loss: 0.1174
	--> Final training Epoch [32/75], Loss: 0.0673
	--> Final training Epoch [33/75], Loss: 0.0524
	--> Final training Epoch [34/75], Loss: 0.0925
	--> Final training Epoch [35/75], Loss: 0.0381
	--> Final training Epoch [36/75], Loss: 0.1292
	--> Final training Epoch [37/75], Loss: 0.1167
	--> Final training Epoch [38/75], Loss: 0.0387
	--> Final training Epoch [39/75], Loss: 0.0647
	--> Final training Epoch [40/75], Loss: 0.0289
	--> Final training Epoch [41/75], Loss: 0.1036
	--> Final training Epoch [42/75], Loss: 0.0210
	--> Final training Epoch [43/75], Loss: 0.0669
	--> Final training Epoch [44/75], Loss: 0.0316
	--> Final training Epoch [45/75], Loss: 0.1674
	--> Final training Epoch [46/75], Loss: 0.0636
	--> Final training Epoch [47/75], Loss: 0.0934
	--> Final training Epoch [48/75], Loss: 0.0171
	--> Final training Epoch [49/75], Loss: 0.0890
	--> Final training Epoch [50/75], Loss: 0.0717
	--> Final training Epoch [51/75], Loss: 0.0139
	--> Final training Epoch [52/75], Loss: 0.0702
	--> Final training Epoch [53/75], Loss: 0.0705
	--> Final training Epoch [54/75], Loss: 0.0259
	--> Final training Epoch [55/75], Loss: 0.0836
	--> Final training Epoch [56/75], Loss: 0.0688
	--> Final training Epoch [57/75], Loss: 0.0352
	--> Final training Epoch [58/75], Loss: 0.0882
	--> Final training Epoch [59/75], Loss: 0.0369
	--> Final training Epoch [60/75], Loss: 0.0149
	--> Final training Epoch [61/75], Loss: 0.0695
	--> Final training Epoch [62/75], Loss: 0.0922
	--> Final training Epoch [63/75], Loss: 0.2032
	--> Final training Epoch [64/75], Loss: 0.0143
	--> Final training Epoch [65/75], Loss: 0.0691
	--> Final training Epoch [66/75], Loss: 0.0636
	--> Final training Epoch [67/75], Loss: 0.0134
	--> Final training Epoch [68/75], Loss: 0.0229
	--> Final training Epoch [69/75], Loss: 0.0333
	--> Final training Epoch [70/75], Loss: 0.0640
	--> Final training Epoch [71/75], Loss: 0.0632
	--> Final training Epoch [72/75], Loss: 0.1103
	--> Final training Epoch [73/75], Loss: 0.0086
	--> Final training Epoch [74/75], Loss: 0.0701
	--> Final training Epoch [75/75], Loss: 0.0126

Final training took 1.2040281295776367 sec

TESTING
	--> Testing took 0.0105 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 1.0455
	--> Final Precision: 0.7273
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6667
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.01, Accuracy: 0.8485, Validation Loss: 0.3211,  Current Best Accuracy: 0.8485,  Current Best Validation Loss: 0.3211
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.3, Weigh Decay: 0.001, Accuracy: 0.8164, Validation Loss: 0.3762,  Current Best Accuracy: 0.8485,  Current Best Validation Loss: 0.3211

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8484, Validation Loss: 0.7541
	--> Epoch [2/100], Loss: 0.9597, Validation Loss: 0.7304
	--> Epoch [3/100], Loss: 0.7799, Validation Loss: 0.7035
	--> Epoch [4/100], Loss: 0.8148, Validation Loss: 0.6835
	--> Epoch [5/100], Loss: 0.7403, Validation Loss: 0.6600
	--> Epoch [6/100], Loss: 0.7052, Validation Loss: 0.6422
	--> Epoch [7/100], Loss: 0.6271, Validation Loss: 0.6222
	--> Epoch [8/100], Loss: 0.6187, Validation Loss: 0.6102
	--> Epoch [9/100], Loss: 0.5512, Validation Loss: 0.5949
	--> Epoch [10/100], Loss: 0.6207, Validation Loss: 0.5791
	--> Epoch [11/100], Loss: 0.5021, Validation Loss: 0.5601
	--> Epoch [12/100], Loss: 0.5509, Validation Loss: 0.5482
	--> Epoch [13/100], Loss: 0.4308, Validation Loss: 0.5329
	--> Epoch [14/100], Loss: 0.5132, Validation Loss: 0.5237
	--> Epoch [15/100], Loss: 0.6184, Validation Loss: 0.5155
	--> Epoch [16/100], Loss: 0.4740, Validation Loss: 0.5070
	--> Epoch [17/100], Loss: 0.4427, Validation Loss: 0.4958
	--> Epoch [18/100], Loss: 0.4854, Validation Loss: 0.4855
	--> Epoch [19/100], Loss: 0.3637, Validation Loss: 0.4737
	--> Epoch [20/100], Loss: 0.3907, Validation Loss: 0.4658
	--> Epoch [21/100], Loss: 0.6099, Validation Loss: 0.4583
	--> Epoch [22/100], Loss: 0.3322, Validation Loss: 0.4488
	--> Epoch [23/100], Loss: 0.4588, Validation Loss: 0.4408
	--> Epoch [24/100], Loss: 0.4407, Validation Loss: 0.4332
	--> Epoch [25/100], Loss: 0.5702, Validation Loss: 0.4337
	--> Epoch [26/100], Loss: 0.3489, Validation Loss: 0.4227
	--> Epoch [27/100], Loss: 0.3610, Validation Loss: 0.4183
	--> Epoch [28/100], Loss: 0.4682, Validation Loss: 0.4147
	--> Epoch [29/100], Loss: 0.4303, Validation Loss: 0.4089
	--> Epoch [30/100], Loss: 0.3556, Validation Loss: 0.4043
	--> Epoch [31/100], Loss: 0.3372, Validation Loss: 0.3988
	--> Epoch [32/100], Loss: 0.3604, Validation Loss: 0.3950
	--> Epoch [33/100], Loss: 0.2040, Validation Loss: 0.3946
	--> Epoch [34/100], Loss: 0.4055, Validation Loss: 0.3922
	--> Epoch [35/100], Loss: 0.3514, Validation Loss: 0.3851
	--> Epoch [36/100], Loss: 0.3577, Validation Loss: 0.3762
	--> Epoch [37/100], Loss: 0.2006, Validation Loss: 0.3726
	--> Epoch [38/100], Loss: 0.4628, Validation Loss: 0.3667
	--> Epoch [39/100], Loss: 0.4820, Validation Loss: 0.3617
	--> Epoch [40/100], Loss: 0.1887, Validation Loss: 0.3561
	--> Epoch [41/100], Loss: 0.1970, Validation Loss: 0.3587
	--> Epoch [42/100], Loss: 0.3037, Validation Loss: 0.3504
	--> Epoch [43/100], Loss: 0.3288, Validation Loss: 0.3473
	--> Epoch [44/100], Loss: 0.3392, Validation Loss: 0.3412
	--> Epoch [45/100], Loss: 0.2580, Validation Loss: 0.3390
	--> Epoch [46/100], Loss: 0.3812, Validation Loss: 0.3369
	--> Epoch [47/100], Loss: 0.2412, Validation Loss: 0.3338
	--> Epoch [48/100], Loss: 0.1081, Validation Loss: 0.3298
	--> Epoch [49/100], Loss: 0.1966, Validation Loss: 0.3245
	--> Epoch [50/100], Loss: 0.2525, Validation Loss: 0.3240
	--> Epoch [51/100], Loss: 0.3122, Validation Loss: 0.3247
	--> Epoch [52/100], Loss: 0.2582, Validation Loss: 0.3216
	--> Epoch [53/100], Loss: 0.2306, Validation Loss: 0.3209
	--> Epoch [54/100], Loss: 0.3814, Validation Loss: 0.3184
	--> Epoch [55/100], Loss: 0.4562, Validation Loss: 0.3160
	--> Epoch [56/100], Loss: 0.3151, Validation Loss: 0.3132
	--> Epoch [57/100], Loss: 0.3607, Validation Loss: 0.3117
	--> Epoch [58/100], Loss: 0.2957, Validation Loss: 0.3101
	--> Epoch [59/100], Loss: 0.2950, Validation Loss: 0.3050
	--> Epoch [60/100], Loss: 0.0924, Validation Loss: 0.3012
	--> Epoch [61/100], Loss: 0.3528, Validation Loss: 0.2992
	--> Epoch [62/100], Loss: 0.2850, Validation Loss: 0.3011
	--> Epoch [63/100], Loss: 0.3553, Validation Loss: 0.2981
	--> Epoch [64/100], Loss: 0.2219, Validation Loss: 0.2954
	--> Epoch [65/100], Loss: 0.2191, Validation Loss: 0.2918
	--> Epoch [66/100], Loss: 0.2806, Validation Loss: 0.2907
	--> Epoch [67/100], Loss: 0.2853, Validation Loss: 0.2907
	--> Epoch [68/100], Loss: 0.2783, Validation Loss: 0.2888
	--> Epoch [69/100], Loss: 0.1462, Validation Loss: 0.2895
	--> Epoch [70/100], Loss: 0.1556, Validation Loss: 0.2861
	--> Epoch [71/100], Loss: 0.4055, Validation Loss: 0.2840
	--> Epoch [72/100], Loss: 0.2220, Validation Loss: 0.2807
	--> Epoch [73/100], Loss: 0.2063, Validation Loss: 0.2864
	--> Epoch [74/100], Loss: 0.3317, Validation Loss: 0.2881
	--> Epoch [75/100], Loss: 0.2024, Validation Loss: 0.2889
Early stopping
	--> Training for Fold 1 took 1.078887701034546 sec, using 75 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.5752, Validation Loss: 0.7488
	--> Epoch [2/100], Loss: 0.5449, Validation Loss: 0.7046
	--> Epoch [3/100], Loss: 0.4733, Validation Loss: 0.6766
	--> Epoch [4/100], Loss: 0.4404, Validation Loss: 0.6516
	--> Epoch [5/100], Loss: 0.3986, Validation Loss: 0.6183
	--> Epoch [6/100], Loss: 0.4755, Validation Loss: 0.5998
	--> Epoch [7/100], Loss: 0.4594, Validation Loss: 0.5824
	--> Epoch [8/100], Loss: 0.3764, Validation Loss: 0.5688
	--> Epoch [9/100], Loss: 0.3123, Validation Loss: 0.5469
	--> Epoch [10/100], Loss: 0.3651, Validation Loss: 0.5288
	--> Epoch [11/100], Loss: 0.2819, Validation Loss: 0.5097
	--> Epoch [12/100], Loss: 0.3329, Validation Loss: 0.4882
	--> Epoch [13/100], Loss: 0.3399, Validation Loss: 0.4686
	--> Epoch [14/100], Loss: 0.2291, Validation Loss: 0.4515
	--> Epoch [15/100], Loss: 0.3804, Validation Loss: 0.4337
	--> Epoch [16/100], Loss: 0.3489, Validation Loss: 0.4235
	--> Epoch [17/100], Loss: 0.1879, Validation Loss: 0.4130
	--> Epoch [18/100], Loss: 0.1700, Validation Loss: 0.4001
	--> Epoch [19/100], Loss: 0.1453, Validation Loss: 0.3857
	--> Epoch [20/100], Loss: 0.0971, Validation Loss: 0.3729
	--> Epoch [21/100], Loss: 0.2959, Validation Loss: 0.3635
	--> Epoch [22/100], Loss: 0.1428, Validation Loss: 0.3573
	--> Epoch [23/100], Loss: 0.2592, Validation Loss: 0.3461
	--> Epoch [24/100], Loss: 0.1343, Validation Loss: 0.3360
	--> Epoch [25/100], Loss: 0.2684, Validation Loss: 0.3287
	--> Epoch [26/100], Loss: 0.1527, Validation Loss: 0.3228
	--> Epoch [27/100], Loss: 0.0739, Validation Loss: 0.3164
	--> Epoch [28/100], Loss: 0.1237, Validation Loss: 0.3134
	--> Epoch [29/100], Loss: 0.2514, Validation Loss: 0.3079
	--> Epoch [30/100], Loss: 0.0716, Validation Loss: 0.3075
	--> Epoch [31/100], Loss: 0.1069, Validation Loss: 0.2998
	--> Epoch [32/100], Loss: 0.1463, Validation Loss: 0.2963
	--> Epoch [33/100], Loss: 0.0661, Validation Loss: 0.2888
	--> Epoch [34/100], Loss: 0.1115, Validation Loss: 0.2867
	--> Epoch [35/100], Loss: 0.1853, Validation Loss: 0.2866
	--> Epoch [36/100], Loss: 0.1770, Validation Loss: 0.2858
	--> Epoch [37/100], Loss: 0.1298, Validation Loss: 0.2846
	--> Epoch [38/100], Loss: 0.1375, Validation Loss: 0.2816
	--> Epoch [39/100], Loss: 0.1642, Validation Loss: 0.2747
	--> Epoch [40/100], Loss: 0.1539, Validation Loss: 0.2713
	--> Epoch [41/100], Loss: 0.0537, Validation Loss: 0.2696
	--> Epoch [42/100], Loss: 0.0945, Validation Loss: 0.2664
	--> Epoch [43/100], Loss: 0.0539, Validation Loss: 0.2627
	--> Epoch [44/100], Loss: 0.0511, Validation Loss: 0.2590
	--> Epoch [45/100], Loss: 0.0183, Validation Loss: 0.2572
	--> Epoch [46/100], Loss: 0.2364, Validation Loss: 0.2555
	--> Epoch [47/100], Loss: 0.1079, Validation Loss: 0.2552
	--> Epoch [48/100], Loss: 0.0860, Validation Loss: 0.2545
	--> Epoch [49/100], Loss: 0.0893, Validation Loss: 0.2532
	--> Epoch [50/100], Loss: 0.1240, Validation Loss: 0.2530
	--> Epoch [51/100], Loss: 0.0942, Validation Loss: 0.2532
	--> Epoch [52/100], Loss: 0.0363, Validation Loss: 0.2510
	--> Epoch [53/100], Loss: 0.3264, Validation Loss: 0.2522
	--> Epoch [54/100], Loss: 0.1209, Validation Loss: 0.2482
	--> Epoch [55/100], Loss: 0.1083, Validation Loss: 0.2466
	--> Epoch [56/100], Loss: 0.2407, Validation Loss: 0.2451
	--> Epoch [57/100], Loss: 0.1625, Validation Loss: 0.2402
	--> Epoch [58/100], Loss: 0.0093, Validation Loss: 0.2397
	--> Epoch [59/100], Loss: 0.1003, Validation Loss: 0.2389
	--> Epoch [60/100], Loss: 0.0920, Validation Loss: 0.2342
	--> Epoch [61/100], Loss: 0.0687, Validation Loss: 0.2373
	--> Epoch [62/100], Loss: 0.2342, Validation Loss: 0.2367
	--> Epoch [63/100], Loss: 0.0988, Validation Loss: 0.2343
Early stopping
	--> Training for Fold 2 took 0.8020987510681152 sec, using 63 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7813, Validation Loss: 0.6583
	--> Epoch [2/100], Loss: 0.8422, Validation Loss: 0.6402
	--> Epoch [3/100], Loss: 0.7481, Validation Loss: 0.6239
	--> Epoch [4/100], Loss: 0.6741, Validation Loss: 0.6106
	--> Epoch [5/100], Loss: 0.6940, Validation Loss: 0.6021
	--> Epoch [6/100], Loss: 0.7055, Validation Loss: 0.5896
	--> Epoch [7/100], Loss: 0.5607, Validation Loss: 0.5778
	--> Epoch [8/100], Loss: 0.5375, Validation Loss: 0.5677
	--> Epoch [9/100], Loss: 0.6572, Validation Loss: 0.5528
	--> Epoch [10/100], Loss: 0.5462, Validation Loss: 0.5423
	--> Epoch [11/100], Loss: 0.5298, Validation Loss: 0.5321
	--> Epoch [12/100], Loss: 0.3929, Validation Loss: 0.5215
	--> Epoch [13/100], Loss: 0.4415, Validation Loss: 0.5070
	--> Epoch [14/100], Loss: 0.5102, Validation Loss: 0.4991
	--> Epoch [15/100], Loss: 0.3755, Validation Loss: 0.4917
	--> Epoch [16/100], Loss: 0.3970, Validation Loss: 0.4799
	--> Epoch [17/100], Loss: 0.2146, Validation Loss: 0.4679
	--> Epoch [18/100], Loss: 0.3259, Validation Loss: 0.4607
	--> Epoch [19/100], Loss: 0.3932, Validation Loss: 0.4501
	--> Epoch [20/100], Loss: 0.2751, Validation Loss: 0.4430
	--> Epoch [21/100], Loss: 0.4122, Validation Loss: 0.4337
	--> Epoch [22/100], Loss: 0.3703, Validation Loss: 0.4300
	--> Epoch [23/100], Loss: 0.4119, Validation Loss: 0.4227
	--> Epoch [24/100], Loss: 0.1443, Validation Loss: 0.4154
	--> Epoch [25/100], Loss: 0.3928, Validation Loss: 0.4118
	--> Epoch [26/100], Loss: 0.2619, Validation Loss: 0.4046
	--> Epoch [27/100], Loss: 0.2744, Validation Loss: 0.3977
	--> Epoch [28/100], Loss: 0.2251, Validation Loss: 0.3917
	--> Epoch [29/100], Loss: 0.3068, Validation Loss: 0.3912
	--> Epoch [30/100], Loss: 0.1700, Validation Loss: 0.3841
	--> Epoch [31/100], Loss: 0.2473, Validation Loss: 0.3818
	--> Epoch [32/100], Loss: 0.1771, Validation Loss: 0.3748
	--> Epoch [33/100], Loss: 0.2471, Validation Loss: 0.3681
	--> Epoch [34/100], Loss: 0.1858, Validation Loss: 0.3642
	--> Epoch [35/100], Loss: 0.1466, Validation Loss: 0.3625
	--> Epoch [36/100], Loss: 0.4113, Validation Loss: 0.3594
	--> Epoch [37/100], Loss: 0.2707, Validation Loss: 0.3560
	--> Epoch [38/100], Loss: 0.1858, Validation Loss: 0.3541
	--> Epoch [39/100], Loss: 0.1665, Validation Loss: 0.3477
	--> Epoch [40/100], Loss: 0.1258, Validation Loss: 0.3447
	--> Epoch [41/100], Loss: 0.1877, Validation Loss: 0.3437
	--> Epoch [42/100], Loss: 0.1805, Validation Loss: 0.3409
	--> Epoch [43/100], Loss: 0.2175, Validation Loss: 0.3361
	--> Epoch [44/100], Loss: 0.0878, Validation Loss: 0.3336
	--> Epoch [45/100], Loss: 0.1734, Validation Loss: 0.3326
	--> Epoch [46/100], Loss: 0.2281, Validation Loss: 0.3306
	--> Epoch [47/100], Loss: 0.1650, Validation Loss: 0.3316
	--> Epoch [48/100], Loss: 0.2607, Validation Loss: 0.3314
	--> Epoch [49/100], Loss: 0.2485, Validation Loss: 0.3292
	--> Epoch [50/100], Loss: 0.2340, Validation Loss: 0.3272
	--> Epoch [51/100], Loss: 0.1563, Validation Loss: 0.3250
	--> Epoch [52/100], Loss: 0.1567, Validation Loss: 0.3232
	--> Epoch [53/100], Loss: 0.1509, Validation Loss: 0.3201
	--> Epoch [54/100], Loss: 0.2332, Validation Loss: 0.3214
	--> Epoch [55/100], Loss: 0.2227, Validation Loss: 0.3242
	--> Epoch [56/100], Loss: 0.2874, Validation Loss: 0.3208
Early stopping
	--> Training for Fold 3 took 0.698153018951416 sec, using 56 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.7068, Validation Loss: 0.7295
	--> Epoch [2/100], Loss: 0.6381, Validation Loss: 0.6843
	--> Epoch [3/100], Loss: 0.5815, Validation Loss: 0.6573
	--> Epoch [4/100], Loss: 0.5630, Validation Loss: 0.6329
	--> Epoch [5/100], Loss: 0.4057, Validation Loss: 0.6128
	--> Epoch [6/100], Loss: 0.5274, Validation Loss: 0.5983
	--> Epoch [7/100], Loss: 0.3648, Validation Loss: 0.5735
	--> Epoch [8/100], Loss: 0.4617, Validation Loss: 0.5576
	--> Epoch [9/100], Loss: 0.3580, Validation Loss: 0.5413
	--> Epoch [10/100], Loss: 0.3654, Validation Loss: 0.5342
	--> Epoch [11/100], Loss: 0.3688, Validation Loss: 0.5191
	--> Epoch [12/100], Loss: 0.3379, Validation Loss: 0.5068
	--> Epoch [13/100], Loss: 0.3724, Validation Loss: 0.4877
	--> Epoch [14/100], Loss: 0.2113, Validation Loss: 0.4726
	--> Epoch [15/100], Loss: 0.3661, Validation Loss: 0.4641
	--> Epoch [16/100], Loss: 0.2389, Validation Loss: 0.4471
	--> Epoch [17/100], Loss: 0.2993, Validation Loss: 0.4387
	--> Epoch [18/100], Loss: 0.2267, Validation Loss: 0.4259
	--> Epoch [19/100], Loss: 0.2568, Validation Loss: 0.4115
	--> Epoch [20/100], Loss: 0.1747, Validation Loss: 0.3973
	--> Epoch [21/100], Loss: 0.1627, Validation Loss: 0.3862
	--> Epoch [22/100], Loss: 0.2392, Validation Loss: 0.3747
	--> Epoch [23/100], Loss: 0.2391, Validation Loss: 0.3749
	--> Epoch [24/100], Loss: 0.2174, Validation Loss: 0.3726
	--> Epoch [25/100], Loss: 0.2271, Validation Loss: 0.3627
	--> Epoch [26/100], Loss: 0.1055, Validation Loss: 0.3559
	--> Epoch [27/100], Loss: 0.1918, Validation Loss: 0.3502
	--> Epoch [28/100], Loss: 0.2602, Validation Loss: 0.3540
	--> Epoch [29/100], Loss: 0.1473, Validation Loss: 0.3430
	--> Epoch [30/100], Loss: 0.1639, Validation Loss: 0.3385
	--> Epoch [31/100], Loss: 0.1452, Validation Loss: 0.3319
	--> Epoch [32/100], Loss: 0.0644, Validation Loss: 0.3284
	--> Epoch [33/100], Loss: 0.0778, Validation Loss: 0.3235
	--> Epoch [34/100], Loss: 0.1933, Validation Loss: 0.3176
	--> Epoch [35/100], Loss: 0.1312, Validation Loss: 0.3157
	--> Epoch [36/100], Loss: 0.0650, Validation Loss: 0.3135
	--> Epoch [37/100], Loss: 0.1922, Validation Loss: 0.3157
	--> Epoch [38/100], Loss: 0.1213, Validation Loss: 0.3127
	--> Epoch [39/100], Loss: 0.0599, Validation Loss: 0.3083
	--> Epoch [40/100], Loss: 0.1683, Validation Loss: 0.3142
	--> Epoch [41/100], Loss: 0.1274, Validation Loss: 0.3112
	--> Epoch [42/100], Loss: 0.1825, Validation Loss: 0.3088
Early stopping
	--> Training for Fold 4 took 0.5215268135070801 sec, using 42 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7434, Validation Loss: 0.6380
	--> Epoch [2/100], Loss: 0.6223, Validation Loss: 0.6205
	--> Epoch [3/100], Loss: 0.6410, Validation Loss: 0.6069
	--> Epoch [4/100], Loss: 0.4539, Validation Loss: 0.5918
	--> Epoch [5/100], Loss: 0.5301, Validation Loss: 0.5821
	--> Epoch [6/100], Loss: 0.5558, Validation Loss: 0.5751
	--> Epoch [7/100], Loss: 0.4866, Validation Loss: 0.5669
	--> Epoch [8/100], Loss: 0.5872, Validation Loss: 0.5625
	--> Epoch [9/100], Loss: 0.3975, Validation Loss: 0.5572
	--> Epoch [10/100], Loss: 0.5382, Validation Loss: 0.5469
	--> Epoch [11/100], Loss: 0.5071, Validation Loss: 0.5443
	--> Epoch [12/100], Loss: 0.5095, Validation Loss: 0.5350
	--> Epoch [13/100], Loss: 0.4328, Validation Loss: 0.5305
	--> Epoch [14/100], Loss: 0.5362, Validation Loss: 0.5269
	--> Epoch [15/100], Loss: 0.3493, Validation Loss: 0.5294
	--> Epoch [16/100], Loss: 0.4215, Validation Loss: 0.5258
	--> Epoch [17/100], Loss: 0.4798, Validation Loss: 0.5211
	--> Epoch [18/100], Loss: 0.4050, Validation Loss: 0.5219
	--> Epoch [19/100], Loss: 0.5148, Validation Loss: 0.5161
	--> Epoch [20/100], Loss: 0.3330, Validation Loss: 0.5154
	--> Epoch [21/100], Loss: 0.4172, Validation Loss: 0.5125
	--> Epoch [22/100], Loss: 0.3694, Validation Loss: 0.5094
	--> Epoch [23/100], Loss: 0.3094, Validation Loss: 0.5071
	--> Epoch [24/100], Loss: 0.4367, Validation Loss: 0.5061
	--> Epoch [25/100], Loss: 0.3475, Validation Loss: 0.5032
	--> Epoch [26/100], Loss: 0.3976, Validation Loss: 0.4997
	--> Epoch [27/100], Loss: 0.2997, Validation Loss: 0.5015
	--> Epoch [28/100], Loss: 0.3300, Validation Loss: 0.5011
	--> Epoch [29/100], Loss: 0.3278, Validation Loss: 0.5048
Early stopping
	--> Training for Fold 5 took 0.37317371368408203 sec, using 29 epochs

Median number of epochs used: 56 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/56], Loss: 0.7375
	--> Final training Epoch [2/56], Loss: 0.7222
	--> Final training Epoch [3/56], Loss: 0.6063
	--> Final training Epoch [4/56], Loss: 0.6268
	--> Final training Epoch [5/56], Loss: 0.5061
	--> Final training Epoch [6/56], Loss: 0.5235
	--> Final training Epoch [7/56], Loss: 0.5023
	--> Final training Epoch [8/56], Loss: 0.4230
	--> Final training Epoch [9/56], Loss: 0.3068
	--> Final training Epoch [10/56], Loss: 0.4338
	--> Final training Epoch [11/56], Loss: 0.3679
	--> Final training Epoch [12/56], Loss: 0.3356
	--> Final training Epoch [13/56], Loss: 0.3404
	--> Final training Epoch [14/56], Loss: 0.2811
	--> Final training Epoch [15/56], Loss: 0.2435
	--> Final training Epoch [16/56], Loss: 0.3096
	--> Final training Epoch [17/56], Loss: 0.2773
	--> Final training Epoch [18/56], Loss: 0.2731
	--> Final training Epoch [19/56], Loss: 0.3522
	--> Final training Epoch [20/56], Loss: 0.2130
	--> Final training Epoch [21/56], Loss: 0.2445
	--> Final training Epoch [22/56], Loss: 0.3137
	--> Final training Epoch [23/56], Loss: 0.2879
	--> Final training Epoch [24/56], Loss: 0.1821
	--> Final training Epoch [25/56], Loss: 0.2633
	--> Final training Epoch [26/56], Loss: 0.1710
	--> Final training Epoch [27/56], Loss: 0.0969
	--> Final training Epoch [28/56], Loss: 0.1885
	--> Final training Epoch [29/56], Loss: 0.1568
	--> Final training Epoch [30/56], Loss: 0.2177
	--> Final training Epoch [31/56], Loss: 0.1779
	--> Final training Epoch [32/56], Loss: 0.0844
	--> Final training Epoch [33/56], Loss: 0.1579
	--> Final training Epoch [34/56], Loss: 0.2175
	--> Final training Epoch [35/56], Loss: 0.1565
	--> Final training Epoch [36/56], Loss: 0.1921
	--> Final training Epoch [37/56], Loss: 0.2667
	--> Final training Epoch [38/56], Loss: 0.0952
	--> Final training Epoch [39/56], Loss: 0.1708
	--> Final training Epoch [40/56], Loss: 0.2342
	--> Final training Epoch [41/56], Loss: 0.1301
	--> Final training Epoch [42/56], Loss: 0.2337
	--> Final training Epoch [43/56], Loss: 0.1182
	--> Final training Epoch [44/56], Loss: 0.1527
	--> Final training Epoch [45/56], Loss: 0.2133
	--> Final training Epoch [46/56], Loss: 0.0419
	--> Final training Epoch [47/56], Loss: 0.1793
	--> Final training Epoch [48/56], Loss: 0.1905
	--> Final training Epoch [49/56], Loss: 0.1227
	--> Final training Epoch [50/56], Loss: 0.1036
	--> Final training Epoch [51/56], Loss: 0.1250
	--> Final training Epoch [52/56], Loss: 0.0304
	--> Final training Epoch [53/56], Loss: 0.1272
	--> Final training Epoch [54/56], Loss: 0.1581
	--> Final training Epoch [55/56], Loss: 0.1610
	--> Final training Epoch [56/56], Loss: 0.0681

Final training took 0.794818639755249 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.8612
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.1, Accuracy: 0.8702, Validation Loss: 0.3592,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3592
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.01, Accuracy: 0.8380, Validation Loss: 0.3965,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3592
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.5, Weigh Decay: 0.001, Accuracy: 0.8251, Validation Loss: 0.3838,  Current Best Accuracy: 0.8702,  Current Best Validation Loss: 0.3592

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7472, Validation Loss: 0.6555
	--> Epoch [2/100], Loss: 0.7846, Validation Loss: 0.6306
	--> Epoch [3/100], Loss: 0.8077, Validation Loss: 0.5989
	--> Epoch [4/100], Loss: 0.5937, Validation Loss: 0.5857
	--> Epoch [5/100], Loss: 0.6781, Validation Loss: 0.5746
	--> Epoch [6/100], Loss: 0.5941, Validation Loss: 0.5625
	--> Epoch [7/100], Loss: 0.4392, Validation Loss: 0.5503
	--> Epoch [8/100], Loss: 0.6889, Validation Loss: 0.5375
	--> Epoch [9/100], Loss: 0.5332, Validation Loss: 0.5235
	--> Epoch [10/100], Loss: 0.4989, Validation Loss: 0.5135
	--> Epoch [11/100], Loss: 0.5801, Validation Loss: 0.5006
	--> Epoch [12/100], Loss: 0.5529, Validation Loss: 0.4915
	--> Epoch [13/100], Loss: 0.5602, Validation Loss: 0.4804
	--> Epoch [14/100], Loss: 0.4791, Validation Loss: 0.4684
	--> Epoch [15/100], Loss: 0.5172, Validation Loss: 0.4582
	--> Epoch [16/100], Loss: 0.6470, Validation Loss: 0.4517
	--> Epoch [17/100], Loss: 0.4822, Validation Loss: 0.4423
	--> Epoch [18/100], Loss: 0.3664, Validation Loss: 0.4359
	--> Epoch [19/100], Loss: 0.3927, Validation Loss: 0.4255
	--> Epoch [20/100], Loss: 0.3855, Validation Loss: 0.4126
	--> Epoch [21/100], Loss: 0.4365, Validation Loss: 0.4052
	--> Epoch [22/100], Loss: 0.5472, Validation Loss: 0.3992
	--> Epoch [23/100], Loss: 0.3495, Validation Loss: 0.3906
	--> Epoch [24/100], Loss: 0.3734, Validation Loss: 0.3860
	--> Epoch [25/100], Loss: 0.3034, Validation Loss: 0.3828
	--> Epoch [26/100], Loss: 0.4056, Validation Loss: 0.3762
	--> Epoch [27/100], Loss: 0.4250, Validation Loss: 0.3701
	--> Epoch [28/100], Loss: 0.2516, Validation Loss: 0.3680
	--> Epoch [29/100], Loss: 0.4333, Validation Loss: 0.3622
	--> Epoch [30/100], Loss: 0.4543, Validation Loss: 0.3604
	--> Epoch [31/100], Loss: 0.3151, Validation Loss: 0.3527
	--> Epoch [32/100], Loss: 0.2452, Validation Loss: 0.3483
	--> Epoch [33/100], Loss: 0.3153, Validation Loss: 0.3441
	--> Epoch [34/100], Loss: 0.3664, Validation Loss: 0.3386
	--> Epoch [35/100], Loss: 0.3475, Validation Loss: 0.3376
	--> Epoch [36/100], Loss: 0.3822, Validation Loss: 0.3382
	--> Epoch [37/100], Loss: 0.3188, Validation Loss: 0.3328
	--> Epoch [38/100], Loss: 0.3616, Validation Loss: 0.3296
	--> Epoch [39/100], Loss: 0.3813, Validation Loss: 0.3263
	--> Epoch [40/100], Loss: 0.3730, Validation Loss: 0.3224
	--> Epoch [41/100], Loss: 0.2385, Validation Loss: 0.3188
	--> Epoch [42/100], Loss: 0.2349, Validation Loss: 0.3152
	--> Epoch [43/100], Loss: 0.2427, Validation Loss: 0.3150
	--> Epoch [44/100], Loss: 0.3747, Validation Loss: 0.3124
	--> Epoch [45/100], Loss: 0.3174, Validation Loss: 0.3079
	--> Epoch [46/100], Loss: 0.2191, Validation Loss: 0.3057
	--> Epoch [47/100], Loss: 0.1055, Validation Loss: 0.3054
	--> Epoch [48/100], Loss: 0.3449, Validation Loss: 0.3036
	--> Epoch [49/100], Loss: 0.1822, Validation Loss: 0.3025
	--> Epoch [50/100], Loss: 0.3660, Validation Loss: 0.3028
	--> Epoch [51/100], Loss: 0.2446, Validation Loss: 0.3004
	--> Epoch [52/100], Loss: 0.3483, Validation Loss: 0.3000
	--> Epoch [53/100], Loss: 0.0550, Validation Loss: 0.2976
	--> Epoch [54/100], Loss: 0.2714, Validation Loss: 0.2942
	--> Epoch [55/100], Loss: 0.1759, Validation Loss: 0.2930
	--> Epoch [56/100], Loss: 0.2862, Validation Loss: 0.2873
	--> Epoch [57/100], Loss: 0.2934, Validation Loss: 0.2860
	--> Epoch [58/100], Loss: 0.2165, Validation Loss: 0.2834
	--> Epoch [59/100], Loss: 0.2440, Validation Loss: 0.2858
	--> Epoch [60/100], Loss: 0.3616, Validation Loss: 0.2867
	--> Epoch [61/100], Loss: 0.1517, Validation Loss: 0.2845
Early stopping
	--> Training for Fold 1 took 0.8147168159484863 sec, using 61 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6780, Validation Loss: 0.7412
	--> Epoch [2/100], Loss: 0.6805, Validation Loss: 0.6899
	--> Epoch [3/100], Loss: 0.6084, Validation Loss: 0.6508
	--> Epoch [4/100], Loss: 0.5848, Validation Loss: 0.6227
	--> Epoch [5/100], Loss: 0.5271, Validation Loss: 0.6085
	--> Epoch [6/100], Loss: 0.5167, Validation Loss: 0.5921
	--> Epoch [7/100], Loss: 0.5402, Validation Loss: 0.5814
	--> Epoch [8/100], Loss: 0.4728, Validation Loss: 0.5699
	--> Epoch [9/100], Loss: 0.3808, Validation Loss: 0.5540
	--> Epoch [10/100], Loss: 0.4909, Validation Loss: 0.5394
	--> Epoch [11/100], Loss: 0.4319, Validation Loss: 0.5248
	--> Epoch [12/100], Loss: 0.4368, Validation Loss: 0.5132
	--> Epoch [13/100], Loss: 0.4202, Validation Loss: 0.4963
	--> Epoch [14/100], Loss: 0.4077, Validation Loss: 0.4833
	--> Epoch [15/100], Loss: 0.3021, Validation Loss: 0.4697
	--> Epoch [16/100], Loss: 0.3620, Validation Loss: 0.4565
	--> Epoch [17/100], Loss: 0.3053, Validation Loss: 0.4444
	--> Epoch [18/100], Loss: 0.2835, Validation Loss: 0.4337
	--> Epoch [19/100], Loss: 0.4195, Validation Loss: 0.4288
	--> Epoch [20/100], Loss: 0.2887, Validation Loss: 0.4196
	--> Epoch [21/100], Loss: 0.2466, Validation Loss: 0.4151
	--> Epoch [22/100], Loss: 0.3032, Validation Loss: 0.4078
	--> Epoch [23/100], Loss: 0.4686, Validation Loss: 0.4015
	--> Epoch [24/100], Loss: 0.2847, Validation Loss: 0.3976
	--> Epoch [25/100], Loss: 0.2287, Validation Loss: 0.3902
	--> Epoch [26/100], Loss: 0.4078, Validation Loss: 0.3844
	--> Epoch [27/100], Loss: 0.2726, Validation Loss: 0.3813
	--> Epoch [28/100], Loss: 0.3483, Validation Loss: 0.3720
	--> Epoch [29/100], Loss: 0.2006, Validation Loss: 0.3665
	--> Epoch [30/100], Loss: 0.3384, Validation Loss: 0.3599
	--> Epoch [31/100], Loss: 0.3668, Validation Loss: 0.3555
	--> Epoch [32/100], Loss: 0.1680, Validation Loss: 0.3524
	--> Epoch [33/100], Loss: 0.3502, Validation Loss: 0.3463
	--> Epoch [34/100], Loss: 0.2850, Validation Loss: 0.3429
	--> Epoch [35/100], Loss: 0.2792, Validation Loss: 0.3357
	--> Epoch [36/100], Loss: 0.2709, Validation Loss: 0.3312
	--> Epoch [37/100], Loss: 0.2498, Validation Loss: 0.3288
	--> Epoch [38/100], Loss: 0.1907, Validation Loss: 0.3256
	--> Epoch [39/100], Loss: 0.2633, Validation Loss: 0.3245
	--> Epoch [40/100], Loss: 0.2028, Validation Loss: 0.3204
	--> Epoch [41/100], Loss: 0.2617, Validation Loss: 0.3191
	--> Epoch [42/100], Loss: 0.1563, Validation Loss: 0.3144
	--> Epoch [43/100], Loss: 0.1428, Validation Loss: 0.3142
	--> Epoch [44/100], Loss: 0.3315, Validation Loss: 0.3111
	--> Epoch [45/100], Loss: 0.3276, Validation Loss: 0.3120
	--> Epoch [46/100], Loss: 0.1467, Validation Loss: 0.3155
	--> Epoch [47/100], Loss: 0.3334, Validation Loss: 0.3037
	--> Epoch [48/100], Loss: 0.3324, Validation Loss: 0.3032
	--> Epoch [49/100], Loss: 0.0800, Validation Loss: 0.3014
	--> Epoch [50/100], Loss: 0.1940, Validation Loss: 0.2981
	--> Epoch [51/100], Loss: 0.1305, Validation Loss: 0.2950
	--> Epoch [52/100], Loss: 0.2685, Validation Loss: 0.2928
	--> Epoch [53/100], Loss: 0.1227, Validation Loss: 0.2926
	--> Epoch [54/100], Loss: 0.0740, Validation Loss: 0.2935
	--> Epoch [55/100], Loss: 0.1909, Validation Loss: 0.2937
	--> Epoch [56/100], Loss: 0.1457, Validation Loss: 0.2880
	--> Epoch [57/100], Loss: 0.2711, Validation Loss: 0.2849
	--> Epoch [58/100], Loss: 0.2660, Validation Loss: 0.2864
	--> Epoch [59/100], Loss: 0.3012, Validation Loss: 0.2837
	--> Epoch [60/100], Loss: 0.2662, Validation Loss: 0.2841
	--> Epoch [61/100], Loss: 0.1799, Validation Loss: 0.2800
	--> Epoch [62/100], Loss: 0.1278, Validation Loss: 0.2779
	--> Epoch [63/100], Loss: 0.2621, Validation Loss: 0.2768
	--> Epoch [64/100], Loss: 0.1273, Validation Loss: 0.2767
	--> Epoch [65/100], Loss: 0.2613, Validation Loss: 0.2693
	--> Epoch [66/100], Loss: 0.1260, Validation Loss: 0.2655
	--> Epoch [67/100], Loss: 0.3224, Validation Loss: 0.2670
	--> Epoch [68/100], Loss: 0.1784, Validation Loss: 0.2680
	--> Epoch [69/100], Loss: 0.4562, Validation Loss: 0.2657
Early stopping
	--> Training for Fold 2 took 0.9163801670074463 sec, using 69 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.6430, Validation Loss: 0.7297
	--> Epoch [2/100], Loss: 0.6207, Validation Loss: 0.7156
	--> Epoch [3/100], Loss: 0.5716, Validation Loss: 0.7022
	--> Epoch [4/100], Loss: 0.6053, Validation Loss: 0.6916
	--> Epoch [5/100], Loss: 0.5616, Validation Loss: 0.6824
	--> Epoch [6/100], Loss: 0.5005, Validation Loss: 0.6760
	--> Epoch [7/100], Loss: 0.5190, Validation Loss: 0.6700
	--> Epoch [8/100], Loss: 0.5109, Validation Loss: 0.6628
	--> Epoch [9/100], Loss: 0.4301, Validation Loss: 0.6563
	--> Epoch [10/100], Loss: 0.4808, Validation Loss: 0.6498
	--> Epoch [11/100], Loss: 0.6005, Validation Loss: 0.6428
	--> Epoch [12/100], Loss: 0.4158, Validation Loss: 0.6387
	--> Epoch [13/100], Loss: 0.5401, Validation Loss: 0.6330
	--> Epoch [14/100], Loss: 0.3596, Validation Loss: 0.6241
	--> Epoch [15/100], Loss: 0.3565, Validation Loss: 0.6191
	--> Epoch [16/100], Loss: 0.3938, Validation Loss: 0.6154
	--> Epoch [17/100], Loss: 0.3792, Validation Loss: 0.6095
	--> Epoch [18/100], Loss: 0.3269, Validation Loss: 0.6012
	--> Epoch [19/100], Loss: 0.2858, Validation Loss: 0.5978
	--> Epoch [20/100], Loss: 0.4446, Validation Loss: 0.5916
	--> Epoch [21/100], Loss: 0.3815, Validation Loss: 0.5913
	--> Epoch [22/100], Loss: 0.1642, Validation Loss: 0.5849
	--> Epoch [23/100], Loss: 0.3346, Validation Loss: 0.5779
	--> Epoch [24/100], Loss: 0.3784, Validation Loss: 0.5744
	--> Epoch [25/100], Loss: 0.2282, Validation Loss: 0.5707
	--> Epoch [26/100], Loss: 0.3258, Validation Loss: 0.5691
	--> Epoch [27/100], Loss: 0.0594, Validation Loss: 0.5621
	--> Epoch [28/100], Loss: 0.1359, Validation Loss: 0.5536
	--> Epoch [29/100], Loss: 0.2571, Validation Loss: 0.5496
	--> Epoch [30/100], Loss: 0.3675, Validation Loss: 0.5513
	--> Epoch [31/100], Loss: 0.1848, Validation Loss: 0.5496
	--> Epoch [32/100], Loss: 0.3875, Validation Loss: 0.5500
Early stopping
	--> Training for Fold 3 took 0.4261312484741211 sec, using 32 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.8259, Validation Loss: 0.5870
	--> Epoch [2/100], Loss: 0.8266, Validation Loss: 0.5699
	--> Epoch [3/100], Loss: 0.6714, Validation Loss: 0.5530
	--> Epoch [4/100], Loss: 0.7932, Validation Loss: 0.5368
	--> Epoch [5/100], Loss: 0.7940, Validation Loss: 0.5209
	--> Epoch [6/100], Loss: 0.7899, Validation Loss: 0.5092
	--> Epoch [7/100], Loss: 0.8303, Validation Loss: 0.5187
	--> Epoch [8/100], Loss: 0.6461, Validation Loss: 0.5203
	--> Epoch [9/100], Loss: 0.5692, Validation Loss: 0.5090
	--> Epoch [10/100], Loss: 0.5937, Validation Loss: 0.4969
	--> Epoch [11/100], Loss: 0.4681, Validation Loss: 0.4845
	--> Epoch [12/100], Loss: 0.6440, Validation Loss: 0.4865
	--> Epoch [13/100], Loss: 0.6510, Validation Loss: 0.4818
	--> Epoch [14/100], Loss: 0.4794, Validation Loss: 0.4745
	--> Epoch [15/100], Loss: 0.4729, Validation Loss: 0.4633
	--> Epoch [16/100], Loss: 0.5336, Validation Loss: 0.4534
	--> Epoch [17/100], Loss: 0.4985, Validation Loss: 0.4483
	--> Epoch [18/100], Loss: 0.4961, Validation Loss: 0.4476
	--> Epoch [19/100], Loss: 0.4046, Validation Loss: 0.4403
	--> Epoch [20/100], Loss: 0.4708, Validation Loss: 0.4363
	--> Epoch [21/100], Loss: 0.4088, Validation Loss: 0.4302
	--> Epoch [22/100], Loss: 0.3679, Validation Loss: 0.4208
	--> Epoch [23/100], Loss: 0.5554, Validation Loss: 0.4198
	--> Epoch [24/100], Loss: 0.4846, Validation Loss: 0.4177
	--> Epoch [25/100], Loss: 0.5381, Validation Loss: 0.4121
	--> Epoch [26/100], Loss: 0.3609, Validation Loss: 0.4066
	--> Epoch [27/100], Loss: 0.3236, Validation Loss: 0.4048
	--> Epoch [28/100], Loss: 0.4679, Validation Loss: 0.4015
	--> Epoch [29/100], Loss: 0.3892, Validation Loss: 0.3954
	--> Epoch [30/100], Loss: 0.3063, Validation Loss: 0.3899
	--> Epoch [31/100], Loss: 0.3761, Validation Loss: 0.3832
	--> Epoch [32/100], Loss: 0.4307, Validation Loss: 0.3757
	--> Epoch [33/100], Loss: 0.2665, Validation Loss: 0.3730
	--> Epoch [34/100], Loss: 0.3989, Validation Loss: 0.3700
	--> Epoch [35/100], Loss: 0.4740, Validation Loss: 0.3639
	--> Epoch [36/100], Loss: 0.3912, Validation Loss: 0.3625
	--> Epoch [37/100], Loss: 0.4691, Validation Loss: 0.3601
	--> Epoch [38/100], Loss: 0.7269, Validation Loss: 0.3602
	--> Epoch [39/100], Loss: 0.4117, Validation Loss: 0.3554
	--> Epoch [40/100], Loss: 0.2973, Validation Loss: 0.3535
	--> Epoch [41/100], Loss: 0.3930, Validation Loss: 0.3479
	--> Epoch [42/100], Loss: 0.2910, Validation Loss: 0.3449
	--> Epoch [43/100], Loss: 0.3655, Validation Loss: 0.3398
	--> Epoch [44/100], Loss: 0.4488, Validation Loss: 0.3377
	--> Epoch [45/100], Loss: 0.2663, Validation Loss: 0.3394
	--> Epoch [46/100], Loss: 0.3322, Validation Loss: 0.3382
	--> Epoch [47/100], Loss: 0.3995, Validation Loss: 0.3355
	--> Epoch [48/100], Loss: 0.3252, Validation Loss: 0.3339
	--> Epoch [49/100], Loss: 0.3389, Validation Loss: 0.3339
	--> Epoch [50/100], Loss: 0.2674, Validation Loss: 0.3336
	--> Epoch [51/100], Loss: 0.4392, Validation Loss: 0.3377
	--> Epoch [52/100], Loss: 0.3310, Validation Loss: 0.3323
	--> Epoch [53/100], Loss: 0.4605, Validation Loss: 0.3319
	--> Epoch [54/100], Loss: 0.2487, Validation Loss: 0.3299
	--> Epoch [55/100], Loss: 0.2401, Validation Loss: 0.3278
	--> Epoch [56/100], Loss: 0.3260, Validation Loss: 0.3256
	--> Epoch [57/100], Loss: 0.3228, Validation Loss: 0.3238
	--> Epoch [58/100], Loss: 0.4533, Validation Loss: 0.3216
	--> Epoch [59/100], Loss: 0.3414, Validation Loss: 0.3192
	--> Epoch [60/100], Loss: 0.4691, Validation Loss: 0.3178
	--> Epoch [61/100], Loss: 0.3634, Validation Loss: 0.3170
	--> Epoch [62/100], Loss: 0.2357, Validation Loss: 0.3181
	--> Epoch [63/100], Loss: 0.3325, Validation Loss: 0.3156
	--> Epoch [64/100], Loss: 0.2475, Validation Loss: 0.3137
	--> Epoch [65/100], Loss: 0.2440, Validation Loss: 0.3076
	--> Epoch [66/100], Loss: 0.2482, Validation Loss: 0.3112
	--> Epoch [67/100], Loss: 0.3690, Validation Loss: 0.3101
	--> Epoch [68/100], Loss: 0.2181, Validation Loss: 0.3102
Early stopping
	--> Training for Fold 4 took 0.9699699878692627 sec, using 68 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.7545, Validation Loss: 0.6929
	--> Epoch [2/100], Loss: 0.7605, Validation Loss: 0.6762
	--> Epoch [3/100], Loss: 0.6420, Validation Loss: 0.6673
	--> Epoch [4/100], Loss: 0.5778, Validation Loss: 0.6573
	--> Epoch [5/100], Loss: 0.7054, Validation Loss: 0.6486
	--> Epoch [6/100], Loss: 0.5686, Validation Loss: 0.6340
	--> Epoch [7/100], Loss: 0.6049, Validation Loss: 0.6201
	--> Epoch [8/100], Loss: 0.6165, Validation Loss: 0.6149
	--> Epoch [9/100], Loss: 0.6058, Validation Loss: 0.6087
	--> Epoch [10/100], Loss: 0.5320, Validation Loss: 0.6054
	--> Epoch [11/100], Loss: 0.6214, Validation Loss: 0.6000
	--> Epoch [12/100], Loss: 0.3952, Validation Loss: 0.5948
	--> Epoch [13/100], Loss: 0.3996, Validation Loss: 0.5889
	--> Epoch [14/100], Loss: 0.4798, Validation Loss: 0.5855
	--> Epoch [15/100], Loss: 0.4924, Validation Loss: 0.5802
	--> Epoch [16/100], Loss: 0.4390, Validation Loss: 0.5754
	--> Epoch [17/100], Loss: 0.3986, Validation Loss: 0.5679
	--> Epoch [18/100], Loss: 0.4345, Validation Loss: 0.5626
	--> Epoch [19/100], Loss: 0.3576, Validation Loss: 0.5578
	--> Epoch [20/100], Loss: 0.3345, Validation Loss: 0.5527
	--> Epoch [21/100], Loss: 0.4909, Validation Loss: 0.5459
	--> Epoch [22/100], Loss: 0.3896, Validation Loss: 0.5412
	--> Epoch [23/100], Loss: 0.3587, Validation Loss: 0.5349
	--> Epoch [24/100], Loss: 0.4287, Validation Loss: 0.5292
	--> Epoch [25/100], Loss: 0.2031, Validation Loss: 0.5259
	--> Epoch [26/100], Loss: 0.3209, Validation Loss: 0.5196
	--> Epoch [27/100], Loss: 0.3041, Validation Loss: 0.5127
	--> Epoch [28/100], Loss: 0.3503, Validation Loss: 0.5099
	--> Epoch [29/100], Loss: 0.2498, Validation Loss: 0.5054
	--> Epoch [30/100], Loss: 0.4334, Validation Loss: 0.5010
	--> Epoch [31/100], Loss: 0.3749, Validation Loss: 0.4970
	--> Epoch [32/100], Loss: 0.2557, Validation Loss: 0.4980
	--> Epoch [33/100], Loss: 0.4306, Validation Loss: 0.4908
	--> Epoch [34/100], Loss: 0.2953, Validation Loss: 0.4902
	--> Epoch [35/100], Loss: 0.3102, Validation Loss: 0.4892
	--> Epoch [36/100], Loss: 0.2683, Validation Loss: 0.4878
	--> Epoch [37/100], Loss: 0.2968, Validation Loss: 0.4867
	--> Epoch [38/100], Loss: 0.3776, Validation Loss: 0.4850
	--> Epoch [39/100], Loss: 0.3578, Validation Loss: 0.4802
	--> Epoch [40/100], Loss: 0.3106, Validation Loss: 0.4754
	--> Epoch [41/100], Loss: 0.2568, Validation Loss: 0.4726
	--> Epoch [42/100], Loss: 0.3438, Validation Loss: 0.4692
	--> Epoch [43/100], Loss: 0.2977, Validation Loss: 0.4678
	--> Epoch [44/100], Loss: 0.2045, Validation Loss: 0.4648
	--> Epoch [45/100], Loss: 0.2321, Validation Loss: 0.4640
	--> Epoch [46/100], Loss: 0.2499, Validation Loss: 0.4595
	--> Epoch [47/100], Loss: 0.2777, Validation Loss: 0.4602
	--> Epoch [48/100], Loss: 0.1866, Validation Loss: 0.4606
	--> Epoch [49/100], Loss: 0.1330, Validation Loss: 0.4619
Early stopping
	--> Training for Fold 5 took 0.6477313041687012 sec, using 49 epochs

Median number of epochs used: 61 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/61], Loss: 0.5907
	--> Final training Epoch [2/61], Loss: 0.6778
	--> Final training Epoch [3/61], Loss: 0.5873
	--> Final training Epoch [4/61], Loss: 0.5707
	--> Final training Epoch [5/61], Loss: 0.5338
	--> Final training Epoch [6/61], Loss: 0.5373
	--> Final training Epoch [7/61], Loss: 0.4877
	--> Final training Epoch [8/61], Loss: 0.5164
	--> Final training Epoch [9/61], Loss: 0.4346
	--> Final training Epoch [10/61], Loss: 0.4395
	--> Final training Epoch [11/61], Loss: 0.4396
	--> Final training Epoch [12/61], Loss: 0.3625
	--> Final training Epoch [13/61], Loss: 0.3316
	--> Final training Epoch [14/61], Loss: 0.3537
	--> Final training Epoch [15/61], Loss: 0.4305
	--> Final training Epoch [16/61], Loss: 0.3964
	--> Final training Epoch [17/61], Loss: 0.4098
	--> Final training Epoch [18/61], Loss: 0.3359
	--> Final training Epoch [19/61], Loss: 0.2875
	--> Final training Epoch [20/61], Loss: 0.4700
	--> Final training Epoch [21/61], Loss: 0.2647
	--> Final training Epoch [22/61], Loss: 0.2615
	--> Final training Epoch [23/61], Loss: 0.3629
	--> Final training Epoch [24/61], Loss: 0.2547
	--> Final training Epoch [25/61], Loss: 0.2754
	--> Final training Epoch [26/61], Loss: 0.3552
	--> Final training Epoch [27/61], Loss: 0.1691
	--> Final training Epoch [28/61], Loss: 0.2201
	--> Final training Epoch [29/61], Loss: 0.2566
	--> Final training Epoch [30/61], Loss: 0.2981
	--> Final training Epoch [31/61], Loss: 0.3036
	--> Final training Epoch [32/61], Loss: 0.3032
	--> Final training Epoch [33/61], Loss: 0.2008
	--> Final training Epoch [34/61], Loss: 0.1795
	--> Final training Epoch [35/61], Loss: 0.2597
	--> Final training Epoch [36/61], Loss: 0.1937
	--> Final training Epoch [37/61], Loss: 0.2449
	--> Final training Epoch [38/61], Loss: 0.4715
	--> Final training Epoch [39/61], Loss: 0.2646
	--> Final training Epoch [40/61], Loss: 0.2375
	--> Final training Epoch [41/61], Loss: 0.1372
	--> Final training Epoch [42/61], Loss: 0.2802
	--> Final training Epoch [43/61], Loss: 0.2773
	--> Final training Epoch [44/61], Loss: 0.1378
	--> Final training Epoch [45/61], Loss: 0.2434
	--> Final training Epoch [46/61], Loss: 0.1598
	--> Final training Epoch [47/61], Loss: 0.3683
	--> Final training Epoch [48/61], Loss: 0.2249
	--> Final training Epoch [49/61], Loss: 0.1400
	--> Final training Epoch [50/61], Loss: 0.2417
	--> Final training Epoch [51/61], Loss: 0.2842
	--> Final training Epoch [52/61], Loss: 0.3621
	--> Final training Epoch [53/61], Loss: 0.1790
	--> Final training Epoch [54/61], Loss: 0.3040
	--> Final training Epoch [55/61], Loss: 0.1330
	--> Final training Epoch [56/61], Loss: 0.2632
	--> Final training Epoch [57/61], Loss: 0.1833
	--> Final training Epoch [58/61], Loss: 0.2973
	--> Final training Epoch [59/61], Loss: 0.2059
	--> Final training Epoch [60/61], Loss: 0.3384
	--> Final training Epoch [61/61], Loss: 0.3453

Final training took 0.9547460079193115 sec

TESTING
	--> Testing took 0.0082 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.8864
	--> Final Precision: 0.6364
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.5833
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.1, Accuracy: 0.8275, Validation Loss: 0.3409,  Current Best Accuracy: 0.8275,  Current Best Validation Loss: 0.3409

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.7668, Validation Loss: 0.8066
	--> Epoch [2/100], Loss: 0.6767, Validation Loss: 0.7610
	--> Epoch [3/100], Loss: 0.7564, Validation Loss: 0.7448
	--> Epoch [4/100], Loss: 0.6788, Validation Loss: 0.7285
	--> Epoch [5/100], Loss: 0.6931, Validation Loss: 0.7102
	--> Epoch [6/100], Loss: 0.7229, Validation Loss: 0.6874
	--> Epoch [7/100], Loss: 0.7047, Validation Loss: 0.6665
	--> Epoch [8/100], Loss: 0.5390, Validation Loss: 0.6529
	--> Epoch [9/100], Loss: 0.6105, Validation Loss: 0.6297
	--> Epoch [10/100], Loss: 0.4947, Validation Loss: 0.6162
	--> Epoch [11/100], Loss: 0.6341, Validation Loss: 0.6068
	--> Epoch [12/100], Loss: 0.5600, Validation Loss: 0.5868
	--> Epoch [13/100], Loss: 0.5036, Validation Loss: 0.5759
	--> Epoch [14/100], Loss: 0.4583, Validation Loss: 0.5646
	--> Epoch [15/100], Loss: 0.3997, Validation Loss: 0.5562
	--> Epoch [16/100], Loss: 0.4729, Validation Loss: 0.5525
	--> Epoch [17/100], Loss: 0.5002, Validation Loss: 0.5459
	--> Epoch [18/100], Loss: 0.4808, Validation Loss: 0.5442
	--> Epoch [19/100], Loss: 0.5314, Validation Loss: 0.5380
	--> Epoch [20/100], Loss: 0.3701, Validation Loss: 0.5312
	--> Epoch [21/100], Loss: 0.3383, Validation Loss: 0.5258
	--> Epoch [22/100], Loss: 0.3576, Validation Loss: 0.5176
	--> Epoch [23/100], Loss: 0.3809, Validation Loss: 0.5064
	--> Epoch [24/100], Loss: 0.5520, Validation Loss: 0.4989
	--> Epoch [25/100], Loss: 0.5418, Validation Loss: 0.4908
	--> Epoch [26/100], Loss: 0.2500, Validation Loss: 0.4863
	--> Epoch [27/100], Loss: 0.3713, Validation Loss: 0.4829
	--> Epoch [28/100], Loss: 0.4505, Validation Loss: 0.4744
	--> Epoch [29/100], Loss: 0.5737, Validation Loss: 0.4707
	--> Epoch [30/100], Loss: 0.2330, Validation Loss: 0.4646
	--> Epoch [31/100], Loss: 0.4508, Validation Loss: 0.4669
	--> Epoch [32/100], Loss: 0.3228, Validation Loss: 0.4580
	--> Epoch [33/100], Loss: 0.3619, Validation Loss: 0.4561
	--> Epoch [34/100], Loss: 0.5246, Validation Loss: 0.4557
	--> Epoch [35/100], Loss: 0.2006, Validation Loss: 0.4481
	--> Epoch [36/100], Loss: 0.4376, Validation Loss: 0.4446
	--> Epoch [37/100], Loss: 0.2401, Validation Loss: 0.4419
	--> Epoch [38/100], Loss: 0.2626, Validation Loss: 0.4387
	--> Epoch [39/100], Loss: 0.2588, Validation Loss: 0.4329
	--> Epoch [40/100], Loss: 0.2426, Validation Loss: 0.4283
	--> Epoch [41/100], Loss: 0.1766, Validation Loss: 0.4257
	--> Epoch [42/100], Loss: 0.2966, Validation Loss: 0.4223
	--> Epoch [43/100], Loss: 0.2924, Validation Loss: 0.4194
	--> Epoch [44/100], Loss: 0.4291, Validation Loss: 0.4144
	--> Epoch [45/100], Loss: 0.2205, Validation Loss: 0.4112
	--> Epoch [46/100], Loss: 0.1873, Validation Loss: 0.4113
	--> Epoch [47/100], Loss: 0.1186, Validation Loss: 0.4075
	--> Epoch [48/100], Loss: 0.3505, Validation Loss: 0.4022
	--> Epoch [49/100], Loss: 0.3748, Validation Loss: 0.3990
	--> Epoch [50/100], Loss: 0.2452, Validation Loss: 0.3978
	--> Epoch [51/100], Loss: 0.3215, Validation Loss: 0.3976
	--> Epoch [52/100], Loss: 0.3606, Validation Loss: 0.3925
	--> Epoch [53/100], Loss: 0.2692, Validation Loss: 0.3880
	--> Epoch [54/100], Loss: 0.1168, Validation Loss: 0.3894
	--> Epoch [55/100], Loss: 0.3543, Validation Loss: 0.3877
	--> Epoch [56/100], Loss: 0.3170, Validation Loss: 0.3862
	--> Epoch [57/100], Loss: 0.3034, Validation Loss: 0.3864
	--> Epoch [58/100], Loss: 0.4037, Validation Loss: 0.3855
	--> Epoch [59/100], Loss: 0.2205, Validation Loss: 0.3846
	--> Epoch [60/100], Loss: 0.3967, Validation Loss: 0.3820
	--> Epoch [61/100], Loss: 0.1125, Validation Loss: 0.3794
	--> Epoch [62/100], Loss: 0.1388, Validation Loss: 0.3748
	--> Epoch [63/100], Loss: 0.3895, Validation Loss: 0.3752
	--> Epoch [64/100], Loss: 0.2644, Validation Loss: 0.3786
	--> Epoch [65/100], Loss: 0.2790, Validation Loss: 0.3709
	--> Epoch [66/100], Loss: 0.4996, Validation Loss: 0.3723
	--> Epoch [67/100], Loss: 0.2995, Validation Loss: 0.3696
	--> Epoch [68/100], Loss: 0.4469, Validation Loss: 0.3700
	--> Epoch [69/100], Loss: 0.1577, Validation Loss: 0.3649
	--> Epoch [70/100], Loss: 0.2079, Validation Loss: 0.3614
	--> Epoch [71/100], Loss: 0.2089, Validation Loss: 0.3591
	--> Epoch [72/100], Loss: 0.1137, Validation Loss: 0.3577
	--> Epoch [73/100], Loss: 0.1052, Validation Loss: 0.3572
	--> Epoch [74/100], Loss: 0.2054, Validation Loss: 0.3575
	--> Epoch [75/100], Loss: 0.3050, Validation Loss: 0.3582
	--> Epoch [76/100], Loss: 0.1183, Validation Loss: 0.3592
Early stopping
	--> Training for Fold 1 took 0.9742743968963623 sec, using 76 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7782, Validation Loss: 0.6685
	--> Epoch [2/100], Loss: 0.6834, Validation Loss: 0.6383
	--> Epoch [3/100], Loss: 0.6626, Validation Loss: 0.6195
	--> Epoch [4/100], Loss: 0.6155, Validation Loss: 0.6016
	--> Epoch [5/100], Loss: 0.5963, Validation Loss: 0.5876
	--> Epoch [6/100], Loss: 0.6665, Validation Loss: 0.5768
	--> Epoch [7/100], Loss: 0.5160, Validation Loss: 0.5667
	--> Epoch [8/100], Loss: 0.5655, Validation Loss: 0.5591
	--> Epoch [9/100], Loss: 0.5717, Validation Loss: 0.5466
	--> Epoch [10/100], Loss: 0.5070, Validation Loss: 0.5326
	--> Epoch [11/100], Loss: 0.5752, Validation Loss: 0.5231
	--> Epoch [12/100], Loss: 0.5138, Validation Loss: 0.5151
	--> Epoch [13/100], Loss: 0.4305, Validation Loss: 0.5063
	--> Epoch [14/100], Loss: 0.5356, Validation Loss: 0.4934
	--> Epoch [15/100], Loss: 0.3926, Validation Loss: 0.4836
	--> Epoch [16/100], Loss: 0.2793, Validation Loss: 0.4753
	--> Epoch [17/100], Loss: 0.5348, Validation Loss: 0.4638
	--> Epoch [18/100], Loss: 0.5324, Validation Loss: 0.4540
	--> Epoch [19/100], Loss: 0.2707, Validation Loss: 0.4422
	--> Epoch [20/100], Loss: 0.3714, Validation Loss: 0.4284
	--> Epoch [21/100], Loss: 0.3409, Validation Loss: 0.4209
	--> Epoch [22/100], Loss: 0.6583, Validation Loss: 0.4149
	--> Epoch [23/100], Loss: 0.3230, Validation Loss: 0.4075
	--> Epoch [24/100], Loss: 0.2471, Validation Loss: 0.3991
	--> Epoch [25/100], Loss: 0.2502, Validation Loss: 0.3929
	--> Epoch [26/100], Loss: 0.2859, Validation Loss: 0.3842
	--> Epoch [27/100], Loss: 0.2186, Validation Loss: 0.3788
	--> Epoch [28/100], Loss: 0.3589, Validation Loss: 0.3741
	--> Epoch [29/100], Loss: 0.3865, Validation Loss: 0.3671
	--> Epoch [30/100], Loss: 0.2806, Validation Loss: 0.3584
	--> Epoch [31/100], Loss: 0.2393, Validation Loss: 0.3547
	--> Epoch [32/100], Loss: 0.3736, Validation Loss: 0.3500
	--> Epoch [33/100], Loss: 0.3051, Validation Loss: 0.3433
	--> Epoch [34/100], Loss: 0.2585, Validation Loss: 0.3376
	--> Epoch [35/100], Loss: 0.2041, Validation Loss: 0.3359
	--> Epoch [36/100], Loss: 0.3365, Validation Loss: 0.3331
	--> Epoch [37/100], Loss: 0.2070, Validation Loss: 0.3313
	--> Epoch [38/100], Loss: 0.3596, Validation Loss: 0.3253
	--> Epoch [39/100], Loss: 0.2573, Validation Loss: 0.3230
	--> Epoch [40/100], Loss: 0.2755, Validation Loss: 0.3234
	--> Epoch [41/100], Loss: 0.3258, Validation Loss: 0.3221
	--> Epoch [42/100], Loss: 0.3723, Validation Loss: 0.3177
	--> Epoch [43/100], Loss: 0.1376, Validation Loss: 0.3144
	--> Epoch [44/100], Loss: 0.2478, Validation Loss: 0.3081
	--> Epoch [45/100], Loss: 0.1761, Validation Loss: 0.3059
	--> Epoch [46/100], Loss: 0.3167, Validation Loss: 0.3038
	--> Epoch [47/100], Loss: 0.2479, Validation Loss: 0.3015
	--> Epoch [48/100], Loss: 0.4077, Validation Loss: 0.2994
	--> Epoch [49/100], Loss: 0.3902, Validation Loss: 0.2974
	--> Epoch [50/100], Loss: 0.2435, Validation Loss: 0.2976
	--> Epoch [51/100], Loss: 0.3124, Validation Loss: 0.2968
	--> Epoch [52/100], Loss: 0.1870, Validation Loss: 0.2959
	--> Epoch [53/100], Loss: 0.4009, Validation Loss: 0.2955
	--> Epoch [54/100], Loss: 0.1702, Validation Loss: 0.2972
	--> Epoch [55/100], Loss: 0.1963, Validation Loss: 0.2984
	--> Epoch [56/100], Loss: 0.3250, Validation Loss: 0.2996
Early stopping
	--> Training for Fold 2 took 0.7289249897003174 sec, using 56 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.7099, Validation Loss: 0.6451
	--> Epoch [2/100], Loss: 0.5622, Validation Loss: 0.6286
	--> Epoch [3/100], Loss: 0.7572, Validation Loss: 0.6160
	--> Epoch [4/100], Loss: 0.5549, Validation Loss: 0.6082
	--> Epoch [5/100], Loss: 0.6791, Validation Loss: 0.5959
	--> Epoch [6/100], Loss: 0.6508, Validation Loss: 0.5863
	--> Epoch [7/100], Loss: 0.5051, Validation Loss: 0.5785
	--> Epoch [8/100], Loss: 0.5609, Validation Loss: 0.5702
	--> Epoch [9/100], Loss: 0.5675, Validation Loss: 0.5646
	--> Epoch [10/100], Loss: 0.4559, Validation Loss: 0.5575
	--> Epoch [11/100], Loss: 0.4029, Validation Loss: 0.5522
	--> Epoch [12/100], Loss: 0.4866, Validation Loss: 0.5454
	--> Epoch [13/100], Loss: 0.5107, Validation Loss: 0.5358
	--> Epoch [14/100], Loss: 0.3808, Validation Loss: 0.5279
	--> Epoch [15/100], Loss: 0.5986, Validation Loss: 0.5210
	--> Epoch [16/100], Loss: 0.4608, Validation Loss: 0.5127
	--> Epoch [17/100], Loss: 0.4178, Validation Loss: 0.5073
	--> Epoch [18/100], Loss: 0.4975, Validation Loss: 0.5011
	--> Epoch [19/100], Loss: 0.2458, Validation Loss: 0.4908
	--> Epoch [20/100], Loss: 0.4106, Validation Loss: 0.4834
	--> Epoch [21/100], Loss: 0.4701, Validation Loss: 0.4776
	--> Epoch [22/100], Loss: 0.3911, Validation Loss: 0.4726
	--> Epoch [23/100], Loss: 0.4068, Validation Loss: 0.4636
	--> Epoch [24/100], Loss: 0.3332, Validation Loss: 0.4553
	--> Epoch [25/100], Loss: 0.2784, Validation Loss: 0.4497
	--> Epoch [26/100], Loss: 0.2567, Validation Loss: 0.4445
	--> Epoch [27/100], Loss: 0.3660, Validation Loss: 0.4381
	--> Epoch [28/100], Loss: 0.1869, Validation Loss: 0.4302
	--> Epoch [29/100], Loss: 0.4008, Validation Loss: 0.4276
	--> Epoch [30/100], Loss: 0.1956, Validation Loss: 0.4231
	--> Epoch [31/100], Loss: 0.3635, Validation Loss: 0.4182
	--> Epoch [32/100], Loss: 0.3213, Validation Loss: 0.4143
	--> Epoch [33/100], Loss: 0.2271, Validation Loss: 0.4081
	--> Epoch [34/100], Loss: 0.3528, Validation Loss: 0.4053
	--> Epoch [35/100], Loss: 0.3573, Validation Loss: 0.3989
	--> Epoch [36/100], Loss: 0.3525, Validation Loss: 0.3914
	--> Epoch [37/100], Loss: 0.1947, Validation Loss: 0.3832
	--> Epoch [38/100], Loss: 0.1437, Validation Loss: 0.3793
	--> Epoch [39/100], Loss: 0.1162, Validation Loss: 0.3789
	--> Epoch [40/100], Loss: 0.1564, Validation Loss: 0.3743
	--> Epoch [41/100], Loss: 0.3808, Validation Loss: 0.3709
	--> Epoch [42/100], Loss: 0.2309, Validation Loss: 0.3636
	--> Epoch [43/100], Loss: 0.4369, Validation Loss: 0.3610
	--> Epoch [44/100], Loss: 0.3909, Validation Loss: 0.3585
	--> Epoch [45/100], Loss: 0.2429, Validation Loss: 0.3565
	--> Epoch [46/100], Loss: 0.2512, Validation Loss: 0.3525
	--> Epoch [47/100], Loss: 0.3120, Validation Loss: 0.3478
	--> Epoch [48/100], Loss: 0.3819, Validation Loss: 0.3489
	--> Epoch [49/100], Loss: 0.3783, Validation Loss: 0.3483
	--> Epoch [50/100], Loss: 0.3947, Validation Loss: 0.3469
	--> Epoch [51/100], Loss: 0.2382, Validation Loss: 0.3434
	--> Epoch [52/100], Loss: 0.3152, Validation Loss: 0.3428
	--> Epoch [53/100], Loss: 0.2619, Validation Loss: 0.3386
	--> Epoch [54/100], Loss: 0.1024, Validation Loss: 0.3352
	--> Epoch [55/100], Loss: 0.1793, Validation Loss: 0.3333
	--> Epoch [56/100], Loss: 0.4136, Validation Loss: 0.3298
	--> Epoch [57/100], Loss: 0.1389, Validation Loss: 0.3292
	--> Epoch [58/100], Loss: 0.3901, Validation Loss: 0.3236
	--> Epoch [59/100], Loss: 0.1088, Validation Loss: 0.3187
	--> Epoch [60/100], Loss: 0.3173, Validation Loss: 0.3197
	--> Epoch [61/100], Loss: 0.5060, Validation Loss: 0.3175
	--> Epoch [62/100], Loss: 0.3186, Validation Loss: 0.3170
	--> Epoch [63/100], Loss: 0.1691, Validation Loss: 0.3155
	--> Epoch [64/100], Loss: 0.2996, Validation Loss: 0.3153
	--> Epoch [65/100], Loss: 0.1694, Validation Loss: 0.3133
	--> Epoch [66/100], Loss: 0.3093, Validation Loss: 0.3117
	--> Epoch [67/100], Loss: 0.3008, Validation Loss: 0.3116
	--> Epoch [68/100], Loss: 0.3146, Validation Loss: 0.3100
	--> Epoch [69/100], Loss: 0.2180, Validation Loss: 0.3075
	--> Epoch [70/100], Loss: 0.3062, Validation Loss: 0.3080
	--> Epoch [71/100], Loss: 0.3075, Validation Loss: 0.3079
	--> Epoch [72/100], Loss: 0.3077, Validation Loss: 0.3052
	--> Epoch [73/100], Loss: 0.3707, Validation Loss: 0.3042
	--> Epoch [74/100], Loss: 0.3709, Validation Loss: 0.3036
	--> Epoch [75/100], Loss: 0.1653, Validation Loss: 0.2997
	--> Epoch [76/100], Loss: 0.3013, Validation Loss: 0.2996
	--> Epoch [77/100], Loss: 0.5103, Validation Loss: 0.2993
	--> Epoch [78/100], Loss: 0.1517, Validation Loss: 0.2993
	--> Epoch [79/100], Loss: 0.1606, Validation Loss: 0.2993
	--> Epoch [80/100], Loss: 0.1567, Validation Loss: 0.2977
	--> Epoch [81/100], Loss: 0.2152, Validation Loss: 0.2976
	--> Epoch [82/100], Loss: 0.1523, Validation Loss: 0.2983
	--> Epoch [83/100], Loss: 0.1727, Validation Loss: 0.2975
	--> Epoch [84/100], Loss: 0.0797, Validation Loss: 0.2978
	--> Epoch [85/100], Loss: 0.3683, Validation Loss: 0.2965
	--> Epoch [86/100], Loss: 0.1589, Validation Loss: 0.2992
	--> Epoch [87/100], Loss: 0.1527, Validation Loss: 0.3003
	--> Epoch [88/100], Loss: 0.2219, Validation Loss: 0.2984
Early stopping
	--> Training for Fold 3 took 1.139631986618042 sec, using 88 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.9051, Validation Loss: 0.5715
	--> Epoch [2/100], Loss: 0.7304, Validation Loss: 0.5581
	--> Epoch [3/100], Loss: 0.7522, Validation Loss: 0.5484
	--> Epoch [4/100], Loss: 0.9072, Validation Loss: 0.5448
	--> Epoch [5/100], Loss: 0.7216, Validation Loss: 0.5380
	--> Epoch [6/100], Loss: 0.6256, Validation Loss: 0.5246
	--> Epoch [7/100], Loss: 0.7103, Validation Loss: 0.5161
	--> Epoch [8/100], Loss: 0.6357, Validation Loss: 0.5071
	--> Epoch [9/100], Loss: 0.6400, Validation Loss: 0.4985
	--> Epoch [10/100], Loss: 0.5930, Validation Loss: 0.4878
	--> Epoch [11/100], Loss: 0.5442, Validation Loss: 0.4779
	--> Epoch [12/100], Loss: 0.6283, Validation Loss: 0.4724
	--> Epoch [13/100], Loss: 0.6281, Validation Loss: 0.4646
	--> Epoch [14/100], Loss: 0.5843, Validation Loss: 0.4566
	--> Epoch [15/100], Loss: 0.6009, Validation Loss: 0.4514
	--> Epoch [16/100], Loss: 0.4450, Validation Loss: 0.4409
	--> Epoch [17/100], Loss: 0.5241, Validation Loss: 0.4363
	--> Epoch [18/100], Loss: 0.3641, Validation Loss: 0.4274
	--> Epoch [19/100], Loss: 0.5730, Validation Loss: 0.4223
	--> Epoch [20/100], Loss: 0.3645, Validation Loss: 0.4160
	--> Epoch [21/100], Loss: 0.5648, Validation Loss: 0.4200
	--> Epoch [22/100], Loss: 0.4511, Validation Loss: 0.4154
	--> Epoch [23/100], Loss: 0.4109, Validation Loss: 0.4102
	--> Epoch [24/100], Loss: 0.6282, Validation Loss: 0.4097
	--> Epoch [25/100], Loss: 0.3935, Validation Loss: 0.4068
	--> Epoch [26/100], Loss: 0.4593, Validation Loss: 0.4042
	--> Epoch [27/100], Loss: 0.3818, Validation Loss: 0.3979
	--> Epoch [28/100], Loss: 0.2788, Validation Loss: 0.3901
	--> Epoch [29/100], Loss: 0.3497, Validation Loss: 0.3843
	--> Epoch [30/100], Loss: 0.3254, Validation Loss: 0.3868
	--> Epoch [31/100], Loss: 0.4686, Validation Loss: 0.3796
	--> Epoch [32/100], Loss: 0.3553, Validation Loss: 0.3745
	--> Epoch [33/100], Loss: 0.2903, Validation Loss: 0.3706
	--> Epoch [34/100], Loss: 0.3759, Validation Loss: 0.3675
	--> Epoch [35/100], Loss: 0.4298, Validation Loss: 0.3636
	--> Epoch [36/100], Loss: 0.4523, Validation Loss: 0.3614
	--> Epoch [37/100], Loss: 0.4126, Validation Loss: 0.3602
	--> Epoch [38/100], Loss: 0.5281, Validation Loss: 0.3633
	--> Epoch [39/100], Loss: 0.3284, Validation Loss: 0.3696
	--> Epoch [40/100], Loss: 0.3870, Validation Loss: 0.3708
Early stopping
	--> Training for Fold 4 took 0.5308756828308105 sec, using 40 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.6246, Validation Loss: 0.7651
	--> Epoch [2/100], Loss: 0.5715, Validation Loss: 0.7430
	--> Epoch [3/100], Loss: 0.5951, Validation Loss: 0.7275
	--> Epoch [4/100], Loss: 0.6106, Validation Loss: 0.7167
	--> Epoch [5/100], Loss: 0.5042, Validation Loss: 0.7052
	--> Epoch [6/100], Loss: 0.5125, Validation Loss: 0.6988
	--> Epoch [7/100], Loss: 0.4502, Validation Loss: 0.6927
	--> Epoch [8/100], Loss: 0.5228, Validation Loss: 0.6861
	--> Epoch [9/100], Loss: 0.3423, Validation Loss: 0.6832
	--> Epoch [10/100], Loss: 0.3927, Validation Loss: 0.6769
	--> Epoch [11/100], Loss: 0.3245, Validation Loss: 0.6749
	--> Epoch [12/100], Loss: 0.3299, Validation Loss: 0.6774
	--> Epoch [13/100], Loss: 0.3156, Validation Loss: 0.6755
	--> Epoch [14/100], Loss: 0.4920, Validation Loss: 0.6721
	--> Epoch [15/100], Loss: 0.3407, Validation Loss: 0.6689
	--> Epoch [16/100], Loss: 0.3086, Validation Loss: 0.6661
	--> Epoch [17/100], Loss: 0.3071, Validation Loss: 0.6662
	--> Epoch [18/100], Loss: 0.3656, Validation Loss: 0.6647
	--> Epoch [19/100], Loss: 0.3544, Validation Loss: 0.6670
	--> Epoch [20/100], Loss: 0.3422, Validation Loss: 0.6689
	--> Epoch [21/100], Loss: 0.2959, Validation Loss: 0.6710
Early stopping
	--> Training for Fold 5 took 0.26596498489379883 sec, using 21 epochs

Median number of epochs used: 56 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/56], Loss: 0.7937
	--> Final training Epoch [2/56], Loss: 0.8562
	--> Final training Epoch [3/56], Loss: 0.7250
	--> Final training Epoch [4/56], Loss: 0.7005
	--> Final training Epoch [5/56], Loss: 0.7655
	--> Final training Epoch [6/56], Loss: 0.7519
	--> Final training Epoch [7/56], Loss: 0.6135
	--> Final training Epoch [8/56], Loss: 0.4839
	--> Final training Epoch [9/56], Loss: 0.7026
	--> Final training Epoch [10/56], Loss: 0.6565
	--> Final training Epoch [11/56], Loss: 0.5767
	--> Final training Epoch [12/56], Loss: 0.6469
	--> Final training Epoch [13/56], Loss: 0.4457
	--> Final training Epoch [14/56], Loss: 0.5888
	--> Final training Epoch [15/56], Loss: 0.6616
	--> Final training Epoch [16/56], Loss: 0.5092
	--> Final training Epoch [17/56], Loss: 0.5145
	--> Final training Epoch [18/56], Loss: 0.6158
	--> Final training Epoch [19/56], Loss: 0.5309
	--> Final training Epoch [20/56], Loss: 0.4941
	--> Final training Epoch [21/56], Loss: 0.4151
	--> Final training Epoch [22/56], Loss: 0.4502
	--> Final training Epoch [23/56], Loss: 0.4230
	--> Final training Epoch [24/56], Loss: 0.5197
	--> Final training Epoch [25/56], Loss: 0.4104
	--> Final training Epoch [26/56], Loss: 0.4592
	--> Final training Epoch [27/56], Loss: 0.4408
	--> Final training Epoch [28/56], Loss: 0.3596
	--> Final training Epoch [29/56], Loss: 0.3672
	--> Final training Epoch [30/56], Loss: 0.3982
	--> Final training Epoch [31/56], Loss: 0.4681
	--> Final training Epoch [32/56], Loss: 0.3088
	--> Final training Epoch [33/56], Loss: 0.3312
	--> Final training Epoch [34/56], Loss: 0.2103
	--> Final training Epoch [35/56], Loss: 0.4618
	--> Final training Epoch [36/56], Loss: 0.2745
	--> Final training Epoch [37/56], Loss: 0.4379
	--> Final training Epoch [38/56], Loss: 0.2294
	--> Final training Epoch [39/56], Loss: 0.2652
	--> Final training Epoch [40/56], Loss: 0.3552
	--> Final training Epoch [41/56], Loss: 0.2976
	--> Final training Epoch [42/56], Loss: 0.2314
	--> Final training Epoch [43/56], Loss: 0.3054
	--> Final training Epoch [44/56], Loss: 0.3246
	--> Final training Epoch [45/56], Loss: 0.2354
	--> Final training Epoch [46/56], Loss: 0.3238
	--> Final training Epoch [47/56], Loss: 0.4117
	--> Final training Epoch [48/56], Loss: 0.2865
	--> Final training Epoch [49/56], Loss: 0.4571
	--> Final training Epoch [50/56], Loss: 0.3570
	--> Final training Epoch [51/56], Loss: 0.3710
	--> Final training Epoch [52/56], Loss: 0.3077
	--> Final training Epoch [53/56], Loss: 0.3064
	--> Final training Epoch [54/56], Loss: 0.3288
	--> Final training Epoch [55/56], Loss: 0.2681
	--> Final training Epoch [56/56], Loss: 0.3590

Final training took 0.8599183559417725 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6522
	--> Final Loss: 0.8028
	--> Final Precision: 0.6923
	--> Final Recall: 0.6923
	--> Final F1 Score: 0.6923
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.01, Accuracy: 0.8374, Validation Loss: 0.3575,  Current Best Accuracy: 0.8374,  Current Best Validation Loss: 0.3575

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6354, Validation Loss: 0.6375
	--> Epoch [2/100], Loss: 0.6676, Validation Loss: 0.5849
	--> Epoch [3/100], Loss: 0.5198, Validation Loss: 0.5429
	--> Epoch [4/100], Loss: 0.5808, Validation Loss: 0.5142
	--> Epoch [5/100], Loss: 0.5299, Validation Loss: 0.5017
	--> Epoch [6/100], Loss: 0.5385, Validation Loss: 0.4877
	--> Epoch [7/100], Loss: 0.4455, Validation Loss: 0.4743
	--> Epoch [8/100], Loss: 0.2722, Validation Loss: 0.4610
	--> Epoch [9/100], Loss: 0.3302, Validation Loss: 0.4445
	--> Epoch [10/100], Loss: 0.4210, Validation Loss: 0.4353
	--> Epoch [11/100], Loss: 0.4634, Validation Loss: 0.4252
	--> Epoch [12/100], Loss: 0.4358, Validation Loss: 0.4151
	--> Epoch [13/100], Loss: 0.4370, Validation Loss: 0.4093
	--> Epoch [14/100], Loss: 0.3700, Validation Loss: 0.4104
	--> Epoch [15/100], Loss: 0.2826, Validation Loss: 0.4041
	--> Epoch [16/100], Loss: 0.5334, Validation Loss: 0.3968
	--> Epoch [17/100], Loss: 0.2853, Validation Loss: 0.3913
	--> Epoch [18/100], Loss: 0.3801, Validation Loss: 0.3848
	--> Epoch [19/100], Loss: 0.2506, Validation Loss: 0.3798
	--> Epoch [20/100], Loss: 0.3657, Validation Loss: 0.3732
	--> Epoch [21/100], Loss: 0.2688, Validation Loss: 0.3701
	--> Epoch [22/100], Loss: 0.2993, Validation Loss: 0.3666
	--> Epoch [23/100], Loss: 0.3087, Validation Loss: 0.3621
	--> Epoch [24/100], Loss: 0.4543, Validation Loss: 0.3625
	--> Epoch [25/100], Loss: 0.4175, Validation Loss: 0.3557
	--> Epoch [26/100], Loss: 0.3851, Validation Loss: 0.3512
	--> Epoch [27/100], Loss: 0.2188, Validation Loss: 0.3469
	--> Epoch [28/100], Loss: 0.2972, Validation Loss: 0.3445
	--> Epoch [29/100], Loss: 0.2537, Validation Loss: 0.3381
	--> Epoch [30/100], Loss: 0.3296, Validation Loss: 0.3366
	--> Epoch [31/100], Loss: 0.2443, Validation Loss: 0.3349
	--> Epoch [32/100], Loss: 0.3625, Validation Loss: 0.3300
	--> Epoch [33/100], Loss: 0.1207, Validation Loss: 0.3268
	--> Epoch [34/100], Loss: 0.4673, Validation Loss: 0.3225
	--> Epoch [35/100], Loss: 0.2051, Validation Loss: 0.3180
	--> Epoch [36/100], Loss: 0.2665, Validation Loss: 0.3175
	--> Epoch [37/100], Loss: 0.2388, Validation Loss: 0.3135
	--> Epoch [38/100], Loss: 0.3785, Validation Loss: 0.3112
	--> Epoch [39/100], Loss: 0.2342, Validation Loss: 0.3102
	--> Epoch [40/100], Loss: 0.3065, Validation Loss: 0.3096
	--> Epoch [41/100], Loss: 0.2251, Validation Loss: 0.3107
	--> Epoch [42/100], Loss: 0.2187, Validation Loss: 0.3080
	--> Epoch [43/100], Loss: 0.1488, Validation Loss: 0.3054
	--> Epoch [44/100], Loss: 0.2809, Validation Loss: 0.3044
	--> Epoch [45/100], Loss: 0.4495, Validation Loss: 0.3030
	--> Epoch [46/100], Loss: 0.2177, Validation Loss: 0.3010
	--> Epoch [47/100], Loss: 0.1959, Validation Loss: 0.2990
	--> Epoch [48/100], Loss: 0.2272, Validation Loss: 0.2956
	--> Epoch [49/100], Loss: 0.3464, Validation Loss: 0.2946
	--> Epoch [50/100], Loss: 0.3952, Validation Loss: 0.2966
	--> Epoch [51/100], Loss: 0.2387, Validation Loss: 0.2936
	--> Epoch [52/100], Loss: 0.2860, Validation Loss: 0.2927
	--> Epoch [53/100], Loss: 0.2954, Validation Loss: 0.2915
	--> Epoch [54/100], Loss: 0.2156, Validation Loss: 0.2895
	--> Epoch [55/100], Loss: 0.2449, Validation Loss: 0.2904
	--> Epoch [56/100], Loss: 0.2820, Validation Loss: 0.2896
	--> Epoch [57/100], Loss: 0.2301, Validation Loss: 0.2869
	--> Epoch [58/100], Loss: 0.0993, Validation Loss: 0.2867
	--> Epoch [59/100], Loss: 0.1632, Validation Loss: 0.2855
	--> Epoch [60/100], Loss: 0.3073, Validation Loss: 0.2840
	--> Epoch [61/100], Loss: 0.1473, Validation Loss: 0.2843
	--> Epoch [62/100], Loss: 0.3519, Validation Loss: 0.2845
	--> Epoch [63/100], Loss: 0.3674, Validation Loss: 0.2812
	--> Epoch [64/100], Loss: 0.1497, Validation Loss: 0.2804
	--> Epoch [65/100], Loss: 0.2870, Validation Loss: 0.2788
	--> Epoch [66/100], Loss: 0.1725, Validation Loss: 0.2799
	--> Epoch [67/100], Loss: 0.2258, Validation Loss: 0.2745
	--> Epoch [68/100], Loss: 0.3082, Validation Loss: 0.2757
	--> Epoch [69/100], Loss: 0.3589, Validation Loss: 0.2728
	--> Epoch [70/100], Loss: 0.2147, Validation Loss: 0.2716
	--> Epoch [71/100], Loss: 0.0806, Validation Loss: 0.2722
	--> Epoch [72/100], Loss: 0.1607, Validation Loss: 0.2721
	--> Epoch [73/100], Loss: 0.1545, Validation Loss: 0.2718
Early stopping
	--> Training for Fold 1 took 0.9231939315795898 sec, using 73 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6530, Validation Loss: 0.6431
	--> Epoch [2/100], Loss: 0.8239, Validation Loss: 0.6291
	--> Epoch [3/100], Loss: 0.7590, Validation Loss: 0.6129
	--> Epoch [4/100], Loss: 0.7027, Validation Loss: 0.6013
	--> Epoch [5/100], Loss: 0.5577, Validation Loss: 0.5817
	--> Epoch [6/100], Loss: 0.6547, Validation Loss: 0.5680
	--> Epoch [7/100], Loss: 0.4873, Validation Loss: 0.5586
	--> Epoch [8/100], Loss: 0.7060, Validation Loss: 0.5435
	--> Epoch [9/100], Loss: 0.6080, Validation Loss: 0.5282
	--> Epoch [10/100], Loss: 0.6430, Validation Loss: 0.5145
	--> Epoch [11/100], Loss: 0.6498, Validation Loss: 0.5065
	--> Epoch [12/100], Loss: 0.4897, Validation Loss: 0.4943
	--> Epoch [13/100], Loss: 0.5705, Validation Loss: 0.4840
	--> Epoch [14/100], Loss: 0.6403, Validation Loss: 0.4732
	--> Epoch [15/100], Loss: 0.5555, Validation Loss: 0.4620
	--> Epoch [16/100], Loss: 0.6377, Validation Loss: 0.4528
	--> Epoch [17/100], Loss: 0.4227, Validation Loss: 0.4433
	--> Epoch [18/100], Loss: 0.5275, Validation Loss: 0.4341
	--> Epoch [19/100], Loss: 0.6257, Validation Loss: 0.4259
	--> Epoch [20/100], Loss: 0.4440, Validation Loss: 0.4170
	--> Epoch [21/100], Loss: 0.5058, Validation Loss: 0.4083
	--> Epoch [22/100], Loss: 0.6607, Validation Loss: 0.4006
	--> Epoch [23/100], Loss: 0.3999, Validation Loss: 0.3931
	--> Epoch [24/100], Loss: 0.4044, Validation Loss: 0.3855
	--> Epoch [25/100], Loss: 0.2983, Validation Loss: 0.3785
	--> Epoch [26/100], Loss: 0.2926, Validation Loss: 0.3746
	--> Epoch [27/100], Loss: 0.6799, Validation Loss: 0.3690
	--> Epoch [28/100], Loss: 0.2854, Validation Loss: 0.3622
	--> Epoch [29/100], Loss: 0.4549, Validation Loss: 0.3575
	--> Epoch [30/100], Loss: 0.4255, Validation Loss: 0.3525
	--> Epoch [31/100], Loss: 0.3676, Validation Loss: 0.3500
	--> Epoch [32/100], Loss: 0.3672, Validation Loss: 0.3433
	--> Epoch [33/100], Loss: 0.1997, Validation Loss: 0.3395
	--> Epoch [34/100], Loss: 0.2979, Validation Loss: 0.3357
	--> Epoch [35/100], Loss: 0.1902, Validation Loss: 0.3310
	--> Epoch [36/100], Loss: 0.3352, Validation Loss: 0.3261
	--> Epoch [37/100], Loss: 0.2929, Validation Loss: 0.3239
	--> Epoch [38/100], Loss: 0.3665, Validation Loss: 0.3220
	--> Epoch [39/100], Loss: 0.3506, Validation Loss: 0.3166
	--> Epoch [40/100], Loss: 0.2964, Validation Loss: 0.3167
	--> Epoch [41/100], Loss: 0.2520, Validation Loss: 0.3116
	--> Epoch [42/100], Loss: 0.2844, Validation Loss: 0.3090
	--> Epoch [43/100], Loss: 0.2983, Validation Loss: 0.3097
	--> Epoch [44/100], Loss: 0.2239, Validation Loss: 0.3047
	--> Epoch [45/100], Loss: 0.1932, Validation Loss: 0.3007
	--> Epoch [46/100], Loss: 0.2458, Validation Loss: 0.3009
	--> Epoch [47/100], Loss: 0.4387, Validation Loss: 0.2978
	--> Epoch [48/100], Loss: 0.2969, Validation Loss: 0.2941
	--> Epoch [49/100], Loss: 0.2708, Validation Loss: 0.2928
	--> Epoch [50/100], Loss: 0.1931, Validation Loss: 0.2880
	--> Epoch [51/100], Loss: 0.2529, Validation Loss: 0.2844
	--> Epoch [52/100], Loss: 0.1856, Validation Loss: 0.2850
	--> Epoch [53/100], Loss: 0.1892, Validation Loss: 0.2824
	--> Epoch [54/100], Loss: 0.3390, Validation Loss: 0.2798
	--> Epoch [55/100], Loss: 0.1738, Validation Loss: 0.2750
	--> Epoch [56/100], Loss: 0.4577, Validation Loss: 0.2708
	--> Epoch [57/100], Loss: 0.1244, Validation Loss: 0.2703
	--> Epoch [58/100], Loss: 0.2502, Validation Loss: 0.2693
	--> Epoch [59/100], Loss: 0.3169, Validation Loss: 0.2664
	--> Epoch [60/100], Loss: 0.2270, Validation Loss: 0.2642
	--> Epoch [61/100], Loss: 0.1990, Validation Loss: 0.2649
	--> Epoch [62/100], Loss: 0.1659, Validation Loss: 0.2659
	--> Epoch [63/100], Loss: 0.3956, Validation Loss: 0.2641
	--> Epoch [64/100], Loss: 0.3686, Validation Loss: 0.2641
	--> Epoch [65/100], Loss: 0.0926, Validation Loss: 0.2645
	--> Epoch [66/100], Loss: 0.4646, Validation Loss: 0.2664
Early stopping
	--> Training for Fold 2 took 0.8640942573547363 sec, using 66 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8206, Validation Loss: 0.6361
	--> Epoch [2/100], Loss: 0.8480, Validation Loss: 0.6318
	--> Epoch [3/100], Loss: 0.7886, Validation Loss: 0.6238
	--> Epoch [4/100], Loss: 0.6498, Validation Loss: 0.6141
	--> Epoch [5/100], Loss: 0.7393, Validation Loss: 0.6080
	--> Epoch [6/100], Loss: 0.7200, Validation Loss: 0.6030
	--> Epoch [7/100], Loss: 0.7109, Validation Loss: 0.5994
	--> Epoch [8/100], Loss: 0.6385, Validation Loss: 0.5978
	--> Epoch [9/100], Loss: 0.6793, Validation Loss: 0.5945
	--> Epoch [10/100], Loss: 0.7243, Validation Loss: 0.5861
	--> Epoch [11/100], Loss: 0.7543, Validation Loss: 0.5839
	--> Epoch [12/100], Loss: 0.6411, Validation Loss: 0.5775
	--> Epoch [13/100], Loss: 0.6379, Validation Loss: 0.5734
	--> Epoch [14/100], Loss: 0.6210, Validation Loss: 0.5688
	--> Epoch [15/100], Loss: 0.6224, Validation Loss: 0.5646
	--> Epoch [16/100], Loss: 0.4996, Validation Loss: 0.5609
	--> Epoch [17/100], Loss: 0.5215, Validation Loss: 0.5538
	--> Epoch [18/100], Loss: 0.6421, Validation Loss: 0.5407
	--> Epoch [19/100], Loss: 0.5426, Validation Loss: 0.5349
	--> Epoch [20/100], Loss: 0.3707, Validation Loss: 0.5289
	--> Epoch [21/100], Loss: 0.5122, Validation Loss: 0.5226
	--> Epoch [22/100], Loss: 0.5382, Validation Loss: 0.5165
	--> Epoch [23/100], Loss: 0.4288, Validation Loss: 0.5094
	--> Epoch [24/100], Loss: 0.4119, Validation Loss: 0.5014
	--> Epoch [25/100], Loss: 0.4115, Validation Loss: 0.4945
	--> Epoch [26/100], Loss: 0.3893, Validation Loss: 0.4892
	--> Epoch [27/100], Loss: 0.5353, Validation Loss: 0.4836
	--> Epoch [28/100], Loss: 0.4510, Validation Loss: 0.4785
	--> Epoch [29/100], Loss: 0.4486, Validation Loss: 0.4694
	--> Epoch [30/100], Loss: 0.3773, Validation Loss: 0.4637
	--> Epoch [31/100], Loss: 0.4481, Validation Loss: 0.4599
	--> Epoch [32/100], Loss: 0.3640, Validation Loss: 0.4533
	--> Epoch [33/100], Loss: 0.4601, Validation Loss: 0.4478
	--> Epoch [34/100], Loss: 0.4494, Validation Loss: 0.4475
	--> Epoch [35/100], Loss: 0.3808, Validation Loss: 0.4429
	--> Epoch [36/100], Loss: 0.3147, Validation Loss: 0.4403
	--> Epoch [37/100], Loss: 0.2769, Validation Loss: 0.4378
	--> Epoch [38/100], Loss: 0.3378, Validation Loss: 0.4330
	--> Epoch [39/100], Loss: 0.4054, Validation Loss: 0.4290
	--> Epoch [40/100], Loss: 0.4675, Validation Loss: 0.4267
	--> Epoch [41/100], Loss: 0.3419, Validation Loss: 0.4250
	--> Epoch [42/100], Loss: 0.5036, Validation Loss: 0.4223
	--> Epoch [43/100], Loss: 0.5031, Validation Loss: 0.4182
	--> Epoch [44/100], Loss: 0.5668, Validation Loss: 0.4133
	--> Epoch [45/100], Loss: 0.4965, Validation Loss: 0.4091
	--> Epoch [46/100], Loss: 0.3966, Validation Loss: 0.4054
	--> Epoch [47/100], Loss: 0.0977, Validation Loss: 0.4027
	--> Epoch [48/100], Loss: 0.4599, Validation Loss: 0.4014
	--> Epoch [49/100], Loss: 0.3914, Validation Loss: 0.3986
	--> Epoch [50/100], Loss: 0.4026, Validation Loss: 0.3962
	--> Epoch [51/100], Loss: 0.4137, Validation Loss: 0.3945
	--> Epoch [52/100], Loss: 0.2558, Validation Loss: 0.3985
	--> Epoch [53/100], Loss: 0.2392, Validation Loss: 0.3935
	--> Epoch [54/100], Loss: 0.3144, Validation Loss: 0.3874
	--> Epoch [55/100], Loss: 0.3822, Validation Loss: 0.3880
	--> Epoch [56/100], Loss: 0.2896, Validation Loss: 0.3833
	--> Epoch [57/100], Loss: 0.5891, Validation Loss: 0.3787
	--> Epoch [58/100], Loss: 0.3099, Validation Loss: 0.3777
	--> Epoch [59/100], Loss: 0.3942, Validation Loss: 0.3735
	--> Epoch [60/100], Loss: 0.3561, Validation Loss: 0.3706
	--> Epoch [61/100], Loss: 0.3795, Validation Loss: 0.3686
	--> Epoch [62/100], Loss: 0.4641, Validation Loss: 0.3658
	--> Epoch [63/100], Loss: 0.3016, Validation Loss: 0.3666
	--> Epoch [64/100], Loss: 0.3768, Validation Loss: 0.3644
	--> Epoch [65/100], Loss: 0.3041, Validation Loss: 0.3613
	--> Epoch [66/100], Loss: 0.3189, Validation Loss: 0.3591
	--> Epoch [67/100], Loss: 0.2562, Validation Loss: 0.3581
	--> Epoch [68/100], Loss: 0.1053, Validation Loss: 0.3559
	--> Epoch [69/100], Loss: 0.3648, Validation Loss: 0.3539
	--> Epoch [70/100], Loss: 0.5070, Validation Loss: 0.3533
	--> Epoch [71/100], Loss: 0.3148, Validation Loss: 0.3519
	--> Epoch [72/100], Loss: 0.3700, Validation Loss: 0.3526
	--> Epoch [73/100], Loss: 0.0899, Validation Loss: 0.3505
	--> Epoch [74/100], Loss: 0.3032, Validation Loss: 0.3478
	--> Epoch [75/100], Loss: 0.2157, Validation Loss: 0.3471
	--> Epoch [76/100], Loss: 0.3585, Validation Loss: 0.3443
	--> Epoch [77/100], Loss: 0.3566, Validation Loss: 0.3433
	--> Epoch [78/100], Loss: 0.4328, Validation Loss: 0.3437
	--> Epoch [79/100], Loss: 0.2938, Validation Loss: 0.3437
	--> Epoch [80/100], Loss: 0.1500, Validation Loss: 0.3426
	--> Epoch [81/100], Loss: 0.2834, Validation Loss: 0.3416
	--> Epoch [82/100], Loss: 0.2880, Validation Loss: 0.3418
	--> Epoch [83/100], Loss: 0.2207, Validation Loss: 0.3409
	--> Epoch [84/100], Loss: 0.2294, Validation Loss: 0.3406
	--> Epoch [85/100], Loss: 0.3590, Validation Loss: 0.3415
	--> Epoch [86/100], Loss: 0.1501, Validation Loss: 0.3404
	--> Epoch [87/100], Loss: 0.2889, Validation Loss: 0.3381
	--> Epoch [88/100], Loss: 0.1510, Validation Loss: 0.3408
	--> Epoch [89/100], Loss: 0.3555, Validation Loss: 0.3365
	--> Epoch [90/100], Loss: 0.2828, Validation Loss: 0.3346
	--> Epoch [91/100], Loss: 0.2091, Validation Loss: 0.3334
	--> Epoch [92/100], Loss: 0.2760, Validation Loss: 0.3320
	--> Epoch [93/100], Loss: 0.1426, Validation Loss: 0.3280
	--> Epoch [94/100], Loss: 0.2775, Validation Loss: 0.3240
	--> Epoch [95/100], Loss: 0.2139, Validation Loss: 0.3229
	--> Epoch [96/100], Loss: 0.2795, Validation Loss: 0.3255
	--> Epoch [97/100], Loss: 0.2750, Validation Loss: 0.3279
	--> Epoch [98/100], Loss: 0.2802, Validation Loss: 0.3277
Early stopping
	--> Training for Fold 3 took 1.2639408111572266 sec, using 98 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6081, Validation Loss: 0.7253
	--> Epoch [2/100], Loss: 0.6246, Validation Loss: 0.7064
	--> Epoch [3/100], Loss: 0.6066, Validation Loss: 0.6874
	--> Epoch [4/100], Loss: 0.5624, Validation Loss: 0.6676
	--> Epoch [5/100], Loss: 0.6005, Validation Loss: 0.6416
	--> Epoch [6/100], Loss: 0.5668, Validation Loss: 0.6207
	--> Epoch [7/100], Loss: 0.5137, Validation Loss: 0.6082
	--> Epoch [8/100], Loss: 0.5596, Validation Loss: 0.5931
	--> Epoch [9/100], Loss: 0.4377, Validation Loss: 0.5753
	--> Epoch [10/100], Loss: 0.7111, Validation Loss: 0.5653
	--> Epoch [11/100], Loss: 0.4993, Validation Loss: 0.5534
	--> Epoch [12/100], Loss: 0.3890, Validation Loss: 0.5373
	--> Epoch [13/100], Loss: 0.4845, Validation Loss: 0.5339
	--> Epoch [14/100], Loss: 0.3925, Validation Loss: 0.5243
	--> Epoch [15/100], Loss: 0.4096, Validation Loss: 0.5050
	--> Epoch [16/100], Loss: 0.4457, Validation Loss: 0.4975
	--> Epoch [17/100], Loss: 0.3885, Validation Loss: 0.4795
	--> Epoch [18/100], Loss: 0.2520, Validation Loss: 0.4651
	--> Epoch [19/100], Loss: 0.3999, Validation Loss: 0.4564
	--> Epoch [20/100], Loss: 0.4481, Validation Loss: 0.4455
	--> Epoch [21/100], Loss: 0.2846, Validation Loss: 0.4395
	--> Epoch [22/100], Loss: 0.3653, Validation Loss: 0.4299
	--> Epoch [23/100], Loss: 0.3007, Validation Loss: 0.4235
	--> Epoch [24/100], Loss: 0.4328, Validation Loss: 0.4188
	--> Epoch [25/100], Loss: 0.2322, Validation Loss: 0.4118
	--> Epoch [26/100], Loss: 0.3036, Validation Loss: 0.4070
	--> Epoch [27/100], Loss: 0.3177, Validation Loss: 0.4046
	--> Epoch [28/100], Loss: 0.3255, Validation Loss: 0.3978
	--> Epoch [29/100], Loss: 0.2281, Validation Loss: 0.3906
	--> Epoch [30/100], Loss: 0.2148, Validation Loss: 0.3874
	--> Epoch [31/100], Loss: 0.1759, Validation Loss: 0.3843
	--> Epoch [32/100], Loss: 0.3442, Validation Loss: 0.3793
	--> Epoch [33/100], Loss: 0.2915, Validation Loss: 0.3730
	--> Epoch [34/100], Loss: 0.2280, Validation Loss: 0.3711
	--> Epoch [35/100], Loss: 0.3363, Validation Loss: 0.3678
	--> Epoch [36/100], Loss: 0.3593, Validation Loss: 0.3675
	--> Epoch [37/100], Loss: 0.4218, Validation Loss: 0.3639
	--> Epoch [38/100], Loss: 0.2995, Validation Loss: 0.3597
	--> Epoch [39/100], Loss: 0.2183, Validation Loss: 0.3601
	--> Epoch [40/100], Loss: 0.1830, Validation Loss: 0.3511
	--> Epoch [41/100], Loss: 0.3337, Validation Loss: 0.3464
	--> Epoch [42/100], Loss: 0.2905, Validation Loss: 0.3399
	--> Epoch [43/100], Loss: 0.1321, Validation Loss: 0.3374
	--> Epoch [44/100], Loss: 0.2666, Validation Loss: 0.3362
	--> Epoch [45/100], Loss: 0.1259, Validation Loss: 0.3327
	--> Epoch [46/100], Loss: 0.1823, Validation Loss: 0.3294
	--> Epoch [47/100], Loss: 0.1762, Validation Loss: 0.3253
	--> Epoch [48/100], Loss: 0.2915, Validation Loss: 0.3230
	--> Epoch [49/100], Loss: 0.2125, Validation Loss: 0.3225
	--> Epoch [50/100], Loss: 0.2136, Validation Loss: 0.3201
	--> Epoch [51/100], Loss: 0.2077, Validation Loss: 0.3201
	--> Epoch [52/100], Loss: 0.1700, Validation Loss: 0.3181
	--> Epoch [53/100], Loss: 0.2353, Validation Loss: 0.3149
	--> Epoch [54/100], Loss: 0.2893, Validation Loss: 0.3159
	--> Epoch [55/100], Loss: 0.1087, Validation Loss: 0.3137
	--> Epoch [56/100], Loss: 0.1318, Validation Loss: 0.3110
	--> Epoch [57/100], Loss: 0.2496, Validation Loss: 0.3112
	--> Epoch [58/100], Loss: 0.2314, Validation Loss: 0.3090
	--> Epoch [59/100], Loss: 0.4101, Validation Loss: 0.3075
	--> Epoch [60/100], Loss: 0.3294, Validation Loss: 0.3065
	--> Epoch [61/100], Loss: 0.2730, Validation Loss: 0.3045
	--> Epoch [62/100], Loss: 0.2801, Validation Loss: 0.3052
	--> Epoch [63/100], Loss: 0.1524, Validation Loss: 0.3073
	--> Epoch [64/100], Loss: 0.1927, Validation Loss: 0.3042
	--> Epoch [65/100], Loss: 0.3394, Validation Loss: 0.3040
	--> Epoch [66/100], Loss: 0.0660, Validation Loss: 0.3002
	--> Epoch [67/100], Loss: 0.1054, Validation Loss: 0.3000
	--> Epoch [68/100], Loss: 0.2953, Validation Loss: 0.2988
	--> Epoch [69/100], Loss: 0.2694, Validation Loss: 0.2990
	--> Epoch [70/100], Loss: 0.2377, Validation Loss: 0.2994
	--> Epoch [71/100], Loss: 0.1528, Validation Loss: 0.2974
	--> Epoch [72/100], Loss: 0.1029, Validation Loss: 0.2973
	--> Epoch [73/100], Loss: 0.1399, Validation Loss: 0.2981
	--> Epoch [74/100], Loss: 0.2606, Validation Loss: 0.2959
	--> Epoch [75/100], Loss: 0.3129, Validation Loss: 0.2977
	--> Epoch [76/100], Loss: 0.1488, Validation Loss: 0.2997
	--> Epoch [77/100], Loss: 0.2250, Validation Loss: 0.2991
Early stopping
	--> Training for Fold 4 took 1.0073778629302979 sec, using 77 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8305, Validation Loss: 0.6688
	--> Epoch [2/100], Loss: 0.7484, Validation Loss: 0.6544
	--> Epoch [3/100], Loss: 0.7029, Validation Loss: 0.6450
	--> Epoch [4/100], Loss: 0.6307, Validation Loss: 0.6390
	--> Epoch [5/100], Loss: 0.5632, Validation Loss: 0.6324
	--> Epoch [6/100], Loss: 0.5980, Validation Loss: 0.6270
	--> Epoch [7/100], Loss: 0.6200, Validation Loss: 0.6221
	--> Epoch [8/100], Loss: 0.5766, Validation Loss: 0.6183
	--> Epoch [9/100], Loss: 0.6157, Validation Loss: 0.6123
	--> Epoch [10/100], Loss: 0.4433, Validation Loss: 0.6072
	--> Epoch [11/100], Loss: 0.3400, Validation Loss: 0.6048
	--> Epoch [12/100], Loss: 0.4375, Validation Loss: 0.6013
	--> Epoch [13/100], Loss: 0.4831, Validation Loss: 0.5947
	--> Epoch [14/100], Loss: 0.4290, Validation Loss: 0.5943
	--> Epoch [15/100], Loss: 0.4352, Validation Loss: 0.5940
	--> Epoch [16/100], Loss: 0.2874, Validation Loss: 0.5950
	--> Epoch [17/100], Loss: 0.3835, Validation Loss: 0.5976
	--> Epoch [18/100], Loss: 0.3521, Validation Loss: 0.5981
Early stopping
	--> Training for Fold 5 took 0.22418689727783203 sec, using 18 epochs

Median number of epochs used: 73 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/73], Loss: 0.5927
	--> Final training Epoch [2/73], Loss: 0.5772
	--> Final training Epoch [3/73], Loss: 0.5536
	--> Final training Epoch [4/73], Loss: 0.5677
	--> Final training Epoch [5/73], Loss: 0.5807
	--> Final training Epoch [6/73], Loss: 0.5628
	--> Final training Epoch [7/73], Loss: 0.5953
	--> Final training Epoch [8/73], Loss: 0.4881
	--> Final training Epoch [9/73], Loss: 0.4713
	--> Final training Epoch [10/73], Loss: 0.4570
	--> Final training Epoch [11/73], Loss: 0.4398
	--> Final training Epoch [12/73], Loss: 0.5309
	--> Final training Epoch [13/73], Loss: 0.5236
	--> Final training Epoch [14/73], Loss: 0.3929
	--> Final training Epoch [15/73], Loss: 0.5541
	--> Final training Epoch [16/73], Loss: 0.3889
	--> Final training Epoch [17/73], Loss: 0.4518
	--> Final training Epoch [18/73], Loss: 0.5307
	--> Final training Epoch [19/73], Loss: 0.4779
	--> Final training Epoch [20/73], Loss: 0.4279
	--> Final training Epoch [21/73], Loss: 0.3747
	--> Final training Epoch [22/73], Loss: 0.4692
	--> Final training Epoch [23/73], Loss: 0.3888
	--> Final training Epoch [24/73], Loss: 0.3193
	--> Final training Epoch [25/73], Loss: 0.3918
	--> Final training Epoch [26/73], Loss: 0.3766
	--> Final training Epoch [27/73], Loss: 0.4184
	--> Final training Epoch [28/73], Loss: 0.3930
	--> Final training Epoch [29/73], Loss: 0.3462
	--> Final training Epoch [30/73], Loss: 0.2549
	--> Final training Epoch [31/73], Loss: 0.3764
	--> Final training Epoch [32/73], Loss: 0.3913
	--> Final training Epoch [33/73], Loss: 0.2544
	--> Final training Epoch [34/73], Loss: 0.3538
	--> Final training Epoch [35/73], Loss: 0.3457
	--> Final training Epoch [36/73], Loss: 0.3502
	--> Final training Epoch [37/73], Loss: 0.2667
	--> Final training Epoch [38/73], Loss: 0.2286
	--> Final training Epoch [39/73], Loss: 0.2754
	--> Final training Epoch [40/73], Loss: 0.1826
	--> Final training Epoch [41/73], Loss: 0.2019
	--> Final training Epoch [42/73], Loss: 0.1895
	--> Final training Epoch [43/73], Loss: 0.3305
	--> Final training Epoch [44/73], Loss: 0.1167
	--> Final training Epoch [45/73], Loss: 0.1772
	--> Final training Epoch [46/73], Loss: 0.1892
	--> Final training Epoch [47/73], Loss: 0.2551
	--> Final training Epoch [48/73], Loss: 0.2901
	--> Final training Epoch [49/73], Loss: 0.2813
	--> Final training Epoch [50/73], Loss: 0.2456
	--> Final training Epoch [51/73], Loss: 0.1502
	--> Final training Epoch [52/73], Loss: 0.1558
	--> Final training Epoch [53/73], Loss: 0.2153
	--> Final training Epoch [54/73], Loss: 0.3053
	--> Final training Epoch [55/73], Loss: 0.1021
	--> Final training Epoch [56/73], Loss: 0.2401
	--> Final training Epoch [57/73], Loss: 0.1562
	--> Final training Epoch [58/73], Loss: 0.1646
	--> Final training Epoch [59/73], Loss: 0.0963
	--> Final training Epoch [60/73], Loss: 0.1608
	--> Final training Epoch [61/73], Loss: 0.2461
	--> Final training Epoch [62/73], Loss: 0.2286
	--> Final training Epoch [63/73], Loss: 0.0887
	--> Final training Epoch [64/73], Loss: 0.2125
	--> Final training Epoch [65/73], Loss: 0.2010
	--> Final training Epoch [66/73], Loss: 0.1935
	--> Final training Epoch [67/73], Loss: 0.2663
	--> Final training Epoch [68/73], Loss: 0.1593
	--> Final training Epoch [69/73], Loss: 0.3461
	--> Final training Epoch [70/73], Loss: 0.1312
	--> Final training Epoch [71/73], Loss: 0.3747
	--> Final training Epoch [72/73], Loss: 0.1692
	--> Final training Epoch [73/73], Loss: 0.2059

Final training took 1.054262399673462 sec

TESTING
	--> Testing took 0.0084 sec
	--> Final Accuracy: 0.6087
	--> Final Loss: 0.9822
	--> Final Precision: 0.7000
	--> Final Recall: 0.5385
	--> Final F1 Score: 0.6087
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.1, Dropout: 0.7, Weigh Decay: 0.001, Accuracy: 0.8596, Validation Loss: 0.3793,  Current Best Accuracy: 0.8596,  Current Best Validation Loss: 0.3793

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.8206, Validation Loss: 0.7216
	--> Epoch [2/100], Loss: 0.6150, Validation Loss: 0.6845
	--> Epoch [3/100], Loss: 0.6286, Validation Loss: 0.6533
	--> Epoch [4/100], Loss: 0.5128, Validation Loss: 0.6196
	--> Epoch [5/100], Loss: 0.5435, Validation Loss: 0.5920
	--> Epoch [6/100], Loss: 0.4383, Validation Loss: 0.5686
	--> Epoch [7/100], Loss: 0.4377, Validation Loss: 0.5498
	--> Epoch [8/100], Loss: 0.3958, Validation Loss: 0.5304
	--> Epoch [9/100], Loss: 0.3077, Validation Loss: 0.5173
	--> Epoch [10/100], Loss: 0.3652, Validation Loss: 0.4970
	--> Epoch [11/100], Loss: 0.3657, Validation Loss: 0.4818
	--> Epoch [12/100], Loss: 0.2402, Validation Loss: 0.4672
	--> Epoch [13/100], Loss: 0.3112, Validation Loss: 0.4540
	--> Epoch [14/100], Loss: 0.2642, Validation Loss: 0.4362
	--> Epoch [15/100], Loss: 0.2941, Validation Loss: 0.4248
	--> Epoch [16/100], Loss: 0.2244, Validation Loss: 0.4097
	--> Epoch [17/100], Loss: 0.2828, Validation Loss: 0.4005
	--> Epoch [18/100], Loss: 0.2754, Validation Loss: 0.3906
	--> Epoch [19/100], Loss: 0.1562, Validation Loss: 0.3787
	--> Epoch [20/100], Loss: 0.1856, Validation Loss: 0.3737
	--> Epoch [21/100], Loss: 0.2167, Validation Loss: 0.3670
	--> Epoch [22/100], Loss: 0.1378, Validation Loss: 0.3611
	--> Epoch [23/100], Loss: 0.1966, Validation Loss: 0.3602
	--> Epoch [24/100], Loss: 0.2305, Validation Loss: 0.3571
	--> Epoch [25/100], Loss: 0.1849, Validation Loss: 0.3541
	--> Epoch [26/100], Loss: 0.2015, Validation Loss: 0.3495
	--> Epoch [27/100], Loss: 0.1096, Validation Loss: 0.3489
	--> Epoch [28/100], Loss: 0.1554, Validation Loss: 0.3430
	--> Epoch [29/100], Loss: 0.2058, Validation Loss: 0.3412
	--> Epoch [30/100], Loss: 0.0816, Validation Loss: 0.3375
	--> Epoch [31/100], Loss: 0.1128, Validation Loss: 0.3370
	--> Epoch [32/100], Loss: 0.0980, Validation Loss: 0.3346
	--> Epoch [33/100], Loss: 0.0628, Validation Loss: 0.3284
	--> Epoch [34/100], Loss: 0.1370, Validation Loss: 0.3245
	--> Epoch [35/100], Loss: 0.1285, Validation Loss: 0.3279
	--> Epoch [36/100], Loss: 0.2309, Validation Loss: 0.3277
	--> Epoch [37/100], Loss: 0.0614, Validation Loss: 0.3267
Early stopping
	--> Training for Fold 1 took 0.49274230003356934 sec, using 37 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.6793, Validation Loss: 0.6373
	--> Epoch [2/100], Loss: 0.6304, Validation Loss: 0.5888
	--> Epoch [3/100], Loss: 0.5433, Validation Loss: 0.5512
	--> Epoch [4/100], Loss: 0.5141, Validation Loss: 0.5268
	--> Epoch [5/100], Loss: 0.4836, Validation Loss: 0.5036
	--> Epoch [6/100], Loss: 0.4339, Validation Loss: 0.4865
	--> Epoch [7/100], Loss: 0.5112, Validation Loss: 0.4676
	--> Epoch [8/100], Loss: 0.4135, Validation Loss: 0.4539
	--> Epoch [9/100], Loss: 0.3767, Validation Loss: 0.4365
	--> Epoch [10/100], Loss: 0.3720, Validation Loss: 0.4187
	--> Epoch [11/100], Loss: 0.4443, Validation Loss: 0.4056
	--> Epoch [12/100], Loss: 0.4099, Validation Loss: 0.3913
	--> Epoch [13/100], Loss: 0.3491, Validation Loss: 0.3774
	--> Epoch [14/100], Loss: 0.3215, Validation Loss: 0.3664
	--> Epoch [15/100], Loss: 0.2411, Validation Loss: 0.3591
	--> Epoch [16/100], Loss: 0.3413, Validation Loss: 0.3515
	--> Epoch [17/100], Loss: 0.4180, Validation Loss: 0.3395
	--> Epoch [18/100], Loss: 0.2131, Validation Loss: 0.3314
	--> Epoch [19/100], Loss: 0.2188, Validation Loss: 0.3248
	--> Epoch [20/100], Loss: 0.2113, Validation Loss: 0.3197
	--> Epoch [21/100], Loss: 0.2264, Validation Loss: 0.3149
	--> Epoch [22/100], Loss: 0.2327, Validation Loss: 0.3107
	--> Epoch [23/100], Loss: 0.1904, Validation Loss: 0.3077
	--> Epoch [24/100], Loss: 0.1671, Validation Loss: 0.3026
	--> Epoch [25/100], Loss: 0.1492, Validation Loss: 0.2985
	--> Epoch [26/100], Loss: 0.1272, Validation Loss: 0.2968
	--> Epoch [27/100], Loss: 0.1322, Validation Loss: 0.2933
	--> Epoch [28/100], Loss: 0.1132, Validation Loss: 0.2909
	--> Epoch [29/100], Loss: 0.1545, Validation Loss: 0.2880
	--> Epoch [30/100], Loss: 0.1325, Validation Loss: 0.2841
	--> Epoch [31/100], Loss: 0.1720, Validation Loss: 0.2803
	--> Epoch [32/100], Loss: 0.1854, Validation Loss: 0.2795
	--> Epoch [33/100], Loss: 0.1375, Validation Loss: 0.2750
	--> Epoch [34/100], Loss: 0.1546, Validation Loss: 0.2781
	--> Epoch [35/100], Loss: 0.1200, Validation Loss: 0.2756
	--> Epoch [36/100], Loss: 0.1357, Validation Loss: 0.2721
	--> Epoch [37/100], Loss: 0.1764, Validation Loss: 0.2683
	--> Epoch [38/100], Loss: 0.1074, Validation Loss: 0.2686
	--> Epoch [39/100], Loss: 0.1976, Validation Loss: 0.2678
	--> Epoch [40/100], Loss: 0.1133, Validation Loss: 0.2676
	--> Epoch [41/100], Loss: 0.1869, Validation Loss: 0.2669
	--> Epoch [42/100], Loss: 0.1737, Validation Loss: 0.2645
	--> Epoch [43/100], Loss: 0.1522, Validation Loss: 0.2634
	--> Epoch [44/100], Loss: 0.0835, Validation Loss: 0.2644
	--> Epoch [45/100], Loss: 0.0934, Validation Loss: 0.2616
	--> Epoch [46/100], Loss: 0.1854, Validation Loss: 0.2634
	--> Epoch [47/100], Loss: 0.0910, Validation Loss: 0.2648
	--> Epoch [48/100], Loss: 0.1125, Validation Loss: 0.2647
Early stopping
	--> Training for Fold 2 took 0.5968754291534424 sec, using 48 epochs

Fold 3/5
	--> Epoch [1/100], Loss: 0.8796, Validation Loss: 0.6226
	--> Epoch [2/100], Loss: 0.9072, Validation Loss: 0.5961
	--> Epoch [3/100], Loss: 0.6711, Validation Loss: 0.5838
	--> Epoch [4/100], Loss: 0.6848, Validation Loss: 0.5685
	--> Epoch [5/100], Loss: 0.5956, Validation Loss: 0.5562
	--> Epoch [6/100], Loss: 0.5505, Validation Loss: 0.5445
	--> Epoch [7/100], Loss: 0.3968, Validation Loss: 0.5342
	--> Epoch [8/100], Loss: 0.4072, Validation Loss: 0.5224
	--> Epoch [9/100], Loss: 0.4353, Validation Loss: 0.5107
	--> Epoch [10/100], Loss: 0.3183, Validation Loss: 0.5001
	--> Epoch [11/100], Loss: 0.2784, Validation Loss: 0.4885
	--> Epoch [12/100], Loss: 0.1651, Validation Loss: 0.4813
	--> Epoch [13/100], Loss: 0.2485, Validation Loss: 0.4723
	--> Epoch [14/100], Loss: 0.1786, Validation Loss: 0.4645
	--> Epoch [15/100], Loss: 0.2199, Validation Loss: 0.4558
	--> Epoch [16/100], Loss: 0.3320, Validation Loss: 0.4519
	--> Epoch [17/100], Loss: 0.2830, Validation Loss: 0.4465
	--> Epoch [18/100], Loss: 0.1712, Validation Loss: 0.4430
	--> Epoch [19/100], Loss: 0.1846, Validation Loss: 0.4376
	--> Epoch [20/100], Loss: 0.1790, Validation Loss: 0.4287
	--> Epoch [21/100], Loss: 0.1513, Validation Loss: 0.4239
	--> Epoch [22/100], Loss: 0.1218, Validation Loss: 0.4184
	--> Epoch [23/100], Loss: 0.0657, Validation Loss: 0.4134
	--> Epoch [24/100], Loss: 0.2509, Validation Loss: 0.4080
	--> Epoch [25/100], Loss: 0.0816, Validation Loss: 0.4070
	--> Epoch [26/100], Loss: 0.1183, Validation Loss: 0.4034
	--> Epoch [27/100], Loss: 0.1323, Validation Loss: 0.3983
	--> Epoch [28/100], Loss: 0.1264, Validation Loss: 0.3971
	--> Epoch [29/100], Loss: 0.0756, Validation Loss: 0.3940
	--> Epoch [30/100], Loss: 0.1246, Validation Loss: 0.3883
	--> Epoch [31/100], Loss: 0.1378, Validation Loss: 0.3851
	--> Epoch [32/100], Loss: 0.1722, Validation Loss: 0.3822
	--> Epoch [33/100], Loss: 0.0750, Validation Loss: 0.3770
	--> Epoch [34/100], Loss: 0.0759, Validation Loss: 0.3719
	--> Epoch [35/100], Loss: 0.1201, Validation Loss: 0.3706
	--> Epoch [36/100], Loss: 0.0517, Validation Loss: 0.3632
	--> Epoch [37/100], Loss: 0.0642, Validation Loss: 0.3614
	--> Epoch [38/100], Loss: 0.0654, Validation Loss: 0.3652
	--> Epoch [39/100], Loss: 0.0344, Validation Loss: 0.3627
	--> Epoch [40/100], Loss: 0.0387, Validation Loss: 0.3614
	--> Epoch [41/100], Loss: 0.0345, Validation Loss: 0.3613
	--> Epoch [42/100], Loss: 0.1325, Validation Loss: 0.3601
	--> Epoch [43/100], Loss: 0.0405, Validation Loss: 0.3607
	--> Epoch [44/100], Loss: 0.0369, Validation Loss: 0.3594
	--> Epoch [45/100], Loss: 0.0164, Validation Loss: 0.3597
	--> Epoch [46/100], Loss: 0.0656, Validation Loss: 0.3557
	--> Epoch [47/100], Loss: 0.0839, Validation Loss: 0.3564
	--> Epoch [48/100], Loss: 0.1139, Validation Loss: 0.3563
	--> Epoch [49/100], Loss: 0.0228, Validation Loss: 0.3551
	--> Epoch [50/100], Loss: 0.1005, Validation Loss: 0.3539
	--> Epoch [51/100], Loss: 0.0256, Validation Loss: 0.3507
	--> Epoch [52/100], Loss: 0.0140, Validation Loss: 0.3485
	--> Epoch [53/100], Loss: 0.0134, Validation Loss: 0.3476
	--> Epoch [54/100], Loss: 0.0250, Validation Loss: 0.3460
	--> Epoch [55/100], Loss: 0.0302, Validation Loss: 0.3458
	--> Epoch [56/100], Loss: 0.0220, Validation Loss: 0.3456
	--> Epoch [57/100], Loss: 0.0194, Validation Loss: 0.3462
	--> Epoch [58/100], Loss: 0.0358, Validation Loss: 0.3444
	--> Epoch [59/100], Loss: 0.0083, Validation Loss: 0.3417
	--> Epoch [60/100], Loss: 0.0974, Validation Loss: 0.3397
	--> Epoch [61/100], Loss: 0.1118, Validation Loss: 0.3384
	--> Epoch [62/100], Loss: 0.0877, Validation Loss: 0.3380
	--> Epoch [63/100], Loss: 0.0081, Validation Loss: 0.3359
	--> Epoch [64/100], Loss: 0.0180, Validation Loss: 0.3353
	--> Epoch [65/100], Loss: 0.0840, Validation Loss: 0.3329
	--> Epoch [66/100], Loss: 0.0139, Validation Loss: 0.3319
	--> Epoch [67/100], Loss: 0.1134, Validation Loss: 0.3343
	--> Epoch [68/100], Loss: 0.0850, Validation Loss: 0.3347
	--> Epoch [69/100], Loss: 0.0125, Validation Loss: 0.3369
Early stopping
	--> Training for Fold 3 took 0.8592202663421631 sec, using 69 epochs

Fold 4/5
	--> Epoch [1/100], Loss: 0.6836, Validation Loss: 0.5746
	--> Epoch [2/100], Loss: 0.6199, Validation Loss: 0.5430
	--> Epoch [3/100], Loss: 0.4877, Validation Loss: 0.5192
	--> Epoch [4/100], Loss: 0.5103, Validation Loss: 0.5036
	--> Epoch [5/100], Loss: 0.4339, Validation Loss: 0.4850
	--> Epoch [6/100], Loss: 0.4719, Validation Loss: 0.4751
	--> Epoch [7/100], Loss: 0.4437, Validation Loss: 0.4589
	--> Epoch [8/100], Loss: 0.3467, Validation Loss: 0.4425
	--> Epoch [9/100], Loss: 0.3188, Validation Loss: 0.4328
	--> Epoch [10/100], Loss: 0.2916, Validation Loss: 0.4247
	--> Epoch [11/100], Loss: 0.2530, Validation Loss: 0.4143
	--> Epoch [12/100], Loss: 0.2499, Validation Loss: 0.4079
	--> Epoch [13/100], Loss: 0.2538, Validation Loss: 0.4013
	--> Epoch [14/100], Loss: 0.1805, Validation Loss: 0.3954
	--> Epoch [15/100], Loss: 0.2816, Validation Loss: 0.3893
	--> Epoch [16/100], Loss: 0.1952, Validation Loss: 0.3812
	--> Epoch [17/100], Loss: 0.1896, Validation Loss: 0.3752
	--> Epoch [18/100], Loss: 0.2123, Validation Loss: 0.3667
	--> Epoch [19/100], Loss: 0.0943, Validation Loss: 0.3649
	--> Epoch [20/100], Loss: 0.2034, Validation Loss: 0.3588
	--> Epoch [21/100], Loss: 0.2390, Validation Loss: 0.3531
	--> Epoch [22/100], Loss: 0.1563, Validation Loss: 0.3481
	--> Epoch [23/100], Loss: 0.1262, Validation Loss: 0.3550
	--> Epoch [24/100], Loss: 0.1252, Validation Loss: 0.3470
	--> Epoch [25/100], Loss: 0.1811, Validation Loss: 0.3401
	--> Epoch [26/100], Loss: 0.2572, Validation Loss: 0.3398
	--> Epoch [27/100], Loss: 0.1623, Validation Loss: 0.3394
	--> Epoch [28/100], Loss: 0.1230, Validation Loss: 0.3364
	--> Epoch [29/100], Loss: 0.1662, Validation Loss: 0.3365
	--> Epoch [30/100], Loss: 0.1193, Validation Loss: 0.3306
	--> Epoch [31/100], Loss: 0.1190, Validation Loss: 0.3266
	--> Epoch [32/100], Loss: 0.2143, Validation Loss: 0.3249
	--> Epoch [33/100], Loss: 0.0695, Validation Loss: 0.3264
	--> Epoch [34/100], Loss: 0.0284, Validation Loss: 0.3287
	--> Epoch [35/100], Loss: 0.0914, Validation Loss: 0.3247
	--> Epoch [36/100], Loss: 0.0454, Validation Loss: 0.3284
	--> Epoch [37/100], Loss: 0.0531, Validation Loss: 0.3261
	--> Epoch [38/100], Loss: 0.1452, Validation Loss: 0.3268
Early stopping
	--> Training for Fold 4 took 0.47697877883911133 sec, using 38 epochs

Fold 5/5
	--> Epoch [1/100], Loss: 0.8072, Validation Loss: 0.6495
	--> Epoch [2/100], Loss: 0.7441, Validation Loss: 0.6357
	--> Epoch [3/100], Loss: 0.6854, Validation Loss: 0.6226
	--> Epoch [4/100], Loss: 0.5921, Validation Loss: 0.6125
	--> Epoch [5/100], Loss: 0.5424, Validation Loss: 0.6049
	--> Epoch [6/100], Loss: 0.5123, Validation Loss: 0.5960
	--> Epoch [7/100], Loss: 0.4958, Validation Loss: 0.5910
	--> Epoch [8/100], Loss: 0.4475, Validation Loss: 0.5860
	--> Epoch [9/100], Loss: 0.4774, Validation Loss: 0.5804
	--> Epoch [10/100], Loss: 0.3454, Validation Loss: 0.5747
	--> Epoch [11/100], Loss: 0.3450, Validation Loss: 0.5730
	--> Epoch [12/100], Loss: 0.3143, Validation Loss: 0.5718
	--> Epoch [13/100], Loss: 0.2879, Validation Loss: 0.5671
	--> Epoch [14/100], Loss: 0.2854, Validation Loss: 0.5662
	--> Epoch [15/100], Loss: 0.2597, Validation Loss: 0.5621
	--> Epoch [16/100], Loss: 0.2342, Validation Loss: 0.5592
	--> Epoch [17/100], Loss: 0.1713, Validation Loss: 0.5569
	--> Epoch [18/100], Loss: 0.2032, Validation Loss: 0.5508
	--> Epoch [19/100], Loss: 0.2538, Validation Loss: 0.5483
	--> Epoch [20/100], Loss: 0.1989, Validation Loss: 0.5446
	--> Epoch [21/100], Loss: 0.1958, Validation Loss: 0.5412
	--> Epoch [22/100], Loss: 0.1966, Validation Loss: 0.5405
	--> Epoch [23/100], Loss: 0.1978, Validation Loss: 0.5351
	--> Epoch [24/100], Loss: 0.1289, Validation Loss: 0.5308
	--> Epoch [25/100], Loss: 0.3414, Validation Loss: 0.5326
	--> Epoch [26/100], Loss: 0.2056, Validation Loss: 0.5371
	--> Epoch [27/100], Loss: 0.1283, Validation Loss: 0.5391
Early stopping
	--> Training for Fold 5 took 0.34016990661621094 sec, using 27 epochs

Median number of epochs used: 38 across 5 folds

Starting final training on the entire dataset:
	--> Final training Epoch [1/38], Loss: 0.8154
	--> Final training Epoch [2/38], Loss: 0.7549
	--> Final training Epoch [3/38], Loss: 0.7141
	--> Final training Epoch [4/38], Loss: 0.6571
	--> Final training Epoch [5/38], Loss: 0.6223
	--> Final training Epoch [6/38], Loss: 0.6255
	--> Final training Epoch [7/38], Loss: 0.6161
	--> Final training Epoch [8/38], Loss: 0.5280
	--> Final training Epoch [9/38], Loss: 0.5017
	--> Final training Epoch [10/38], Loss: 0.4017
	--> Final training Epoch [11/38], Loss: 0.4465
	--> Final training Epoch [12/38], Loss: 0.3952
	--> Final training Epoch [13/38], Loss: 0.4342
	--> Final training Epoch [14/38], Loss: 0.3138
	--> Final training Epoch [15/38], Loss: 0.4183
	--> Final training Epoch [16/38], Loss: 0.4145
	--> Final training Epoch [17/38], Loss: 0.3359
	--> Final training Epoch [18/38], Loss: 0.3432
	--> Final training Epoch [19/38], Loss: 0.2536
	--> Final training Epoch [20/38], Loss: 0.2330
	--> Final training Epoch [21/38], Loss: 0.2029
	--> Final training Epoch [22/38], Loss: 0.2360
	--> Final training Epoch [23/38], Loss: 0.3199
	--> Final training Epoch [24/38], Loss: 0.2105
	--> Final training Epoch [25/38], Loss: 0.1662
	--> Final training Epoch [26/38], Loss: 0.2441
	--> Final training Epoch [27/38], Loss: 0.2152
	--> Final training Epoch [28/38], Loss: 0.2373
	--> Final training Epoch [29/38], Loss: 0.1856
	--> Final training Epoch [30/38], Loss: 0.1543
	--> Final training Epoch [31/38], Loss: 0.2246
	--> Final training Epoch [32/38], Loss: 0.2401
	--> Final training Epoch [33/38], Loss: 0.2063
	--> Final training Epoch [34/38], Loss: 0.1979
	--> Final training Epoch [35/38], Loss: 0.1204
	--> Final training Epoch [36/38], Loss: 0.1661
	--> Final training Epoch [37/38], Loss: 0.1148
	--> Final training Epoch [38/38], Loss: 0.1011

Final training took 0.5407190322875977 sec

TESTING
	--> Testing took 0.0093 sec
	--> Final Accuracy: 0.5652
	--> Final Loss: 0.8214
	--> Final Precision: 0.6154
	--> Final Recall: 0.6154
	--> Final F1 Score: 0.6154
	--> Hidden Size: [8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.3, Weigh Decay: 0.1, Accuracy: 0.8485, Validation Loss: 0.3632,  Current Best Accuracy: 0.8485,  Current Best Validation Loss: 0.3632

TRAINING

Fold 1/5
	--> Epoch [1/100], Loss: 0.6752, Validation Loss: 0.6269
	--> Epoch [2/100], Loss: 0.5909, Validation Loss: 0.5989
	--> Epoch [3/100], Loss: 0.5561, Validation Loss: 0.5751
	--> Epoch [4/100], Loss: 0.5078, Validation Loss: 0.5556
	--> Epoch [5/100], Loss: 0.4451, Validation Loss: 0.5318
	--> Epoch [6/100], Loss: 0.4437, Validation Loss: 0.5086
	--> Epoch [7/100], Loss: 0.3933, Validation Loss: 0.4828
	--> Epoch [8/100], Loss: 0.4112, Validation Loss: 0.4604
	--> Epoch [9/100], Loss: 0.3882, Validation Loss: 0.4440
	--> Epoch [10/100], Loss: 0.3157, Validation Loss: 0.4241
	--> Epoch [11/100], Loss: 0.3549, Validation Loss: 0.4097
	--> Epoch [12/100], Loss: 0.2916, Validation Loss: 0.3924
	--> Epoch [13/100], Loss: 0.2764, Validation Loss: 0.3756
	--> Epoch [14/100], Loss: 0.3294, Validation Loss: 0.3602
	--> Epoch [15/100], Loss: 0.2745, Validation Loss: 0.3487
	--> Epoch [16/100], Loss: 0.2524, Validation Loss: 0.3383
	--> Epoch [17/100], Loss: 0.1977, Validation Loss: 0.3297
	--> Epoch [18/100], Loss: 0.2265, Validation Loss: 0.3210
	--> Epoch [19/100], Loss: 0.2339, Validation Loss: 0.3108
	--> Epoch [20/100], Loss: 0.1947, Validation Loss: 0.3038
	--> Epoch [21/100], Loss: 0.1653, Validation Loss: 0.2969
	--> Epoch [22/100], Loss: 0.1678, Validation Loss: 0.2876
	--> Epoch [23/100], Loss: 0.1208, Validation Loss: 0.2807
	--> Epoch [24/100], Loss: 0.1873, Validation Loss: 0.2745
	--> Epoch [25/100], Loss: 0.1198, Validation Loss: 0.2697
	--> Epoch [26/100], Loss: 0.1124, Validation Loss: 0.2655
	--> Epoch [27/100], Loss: 0.1916, Validation Loss: 0.2618
	--> Epoch [28/100], Loss: 0.0737, Validation Loss: 0.2579
	--> Epoch [29/100], Loss: 0.0466, Validation Loss: 0.2555
	--> Epoch [30/100], Loss: 0.0867, Validation Loss: 0.2533
	--> Epoch [31/100], Loss: 0.1397, Validation Loss: 0.2471
	--> Epoch [32/100], Loss: 0.1190, Validation Loss: 0.2459
	--> Epoch [33/100], Loss: 0.1310, Validation Loss: 0.2444
	--> Epoch [34/100], Loss: 0.1027, Validation Loss: 0.2397
	--> Epoch [35/100], Loss: 0.2156, Validation Loss: 0.2346
	--> Epoch [36/100], Loss: 0.0528, Validation Loss: 0.2349
	--> Epoch [37/100], Loss: 0.1351, Validation Loss: 0.2317
	--> Epoch [38/100], Loss: 0.0409, Validation Loss: 0.2292
	--> Epoch [39/100], Loss: 0.0572, Validation Loss: 0.2279
	--> Epoch [40/100], Loss: 0.1001, Validation Loss: 0.2264
	--> Epoch [41/100], Loss: 0.0370, Validation Loss: 0.2246
	--> Epoch [42/100], Loss: 0.1816, Validation Loss: 0.2235
	--> Epoch [43/100], Loss: 0.1305, Validation Loss: 0.2209
	--> Epoch [44/100], Loss: 0.0406, Validation Loss: 0.2199
	--> Epoch [45/100], Loss: 0.0799, Validation Loss: 0.2199
	--> Epoch [46/100], Loss: 0.0220, Validation Loss: 0.2185
	--> Epoch [47/100], Loss: 0.1081, Validation Loss: 0.2166
	--> Epoch [48/100], Loss: 0.0241, Validation Loss: 0.2149
	--> Epoch [49/100], Loss: 0.0805, Validation Loss: 0.2152
	--> Epoch [50/100], Loss: 0.0900, Validation Loss: 0.2139
	--> Epoch [51/100], Loss: 0.2227, Validation Loss: 0.2146
	--> Epoch [52/100], Loss: 0.0407, Validation Loss: 0.2148
	--> Epoch [53/100], Loss: 0.0134, Validation Loss: 0.2129
	--> Epoch [54/100], Loss: 0.0375, Validation Loss: 0.2118
	--> Epoch [55/100], Loss: 0.1018, Validation Loss: 0.2130
	--> Epoch [56/100], Loss: 0.0134, Validation Loss: 0.2129
	--> Epoch [57/100], Loss: 0.1551, Validation Loss: 0.2124
Early stopping
	--> Training for Fold 1 took 0.7082700729370117 sec, using 57 epochs

Fold 2/5
	--> Epoch [1/100], Loss: 0.7613, Validation Loss: 0.5880
	--> Epoch [2/100], Loss: 0.6487, Validation Loss: 0.5534
	--> Epoch [3/100], Loss: 0.5900, Validation Loss: 0.5233
	--> Epoch [4/100], Loss: 0.5349, Validation Loss: 0.5046
	--> Epoch [5/100], Loss: 0.4459, Validation Loss: 0.4849
	--> Epoch [6/100], Loss: 0.4297, Validation Loss: 0.4730
	--> Epoch [7/100], Loss: 0.4680, Validation Loss: 0.4574
	--> Epoch [8/100], Loss: 0.4457, Validation Loss: 0.4427
	--> Epoch [9/100], Loss: 0.3969, Validation Loss: 0.4261
	--> Epoch [10/100], Loss: 0.3864, Validation Loss: 0.4099
	--> Epoch [11/100], Loss: 0.3261, Validation Loss: 0.3923
	--> Epoch [12/100], Loss: 0.3235, Validation Loss: 0.3785
	--> Epoch [13/100], Loss: 0.2737, Validation Loss: 0.3624
	--> Epoch [14/100], Loss: 0.2535, Validation Loss: 0.3494
	--> Epoch [15/100], Loss: 0.3156, Validation Loss: 0.3392
	--> Epoch [16/100], Loss: 0.2422, Validation Loss: 0.3268
	--> Epoch [17/100], Loss: 0.2057, Validation Loss: 0.3137
	--> Epoch [18/100], Loss: 0.3082, Validation Loss: 0.3057
	--> Epoch [19/100], Loss: 0.1659, Validation Loss: 0.2966
	--> Epoch [20/100], Loss: 0.1803, Validation Loss: 0.2887
	--> Epoch [21/100], Loss: 0.1724, Validation Loss: 0.2799
	--> Epoch [22/100], Loss: 0.1654, Validation Loss: 0.2713
	--> Epoch [23/100], Loss: 0.1590, Validation Loss: 0.2678
	--> Epoch [24/100], Loss: 0.1370, Validation Loss: 0.2625
	--> Epoch [25/100], Loss: 0.1496, Validation Loss: 0.2585
	--> Epoch [26/100], Loss: 0.1469, Validation Loss: 0.2519
	--> Epoch [27/100], Loss: 0.1665, Validation Loss: 0.2463
	--> Epoch [28/100], Loss: 0.1644, Validation Loss: 0.2402
	--> Epoch [29/100], Loss: 0.1368, Validation Loss: 0.2367
	--> Epoch [30/100], Loss: 0.1372, Validation Loss: 0.2329
	--> Epoch [31/100], Loss: 0.1523, Validation Loss: 0.2278
	--> Epoch [32/100], Loss: 0.1682, Validation Loss: 0.2264
	--> Epoch [33/100], Loss: 0.1693, Validation Loss: 0.2223
	--> Epoch [34/100], Loss: 0.1198, Validation Loss: 0.2189
	--> Epoch [35/100], Loss: 0.1389, Validation Loss: 0.2180
	--> Epoch [36/100], Loss: 0.1418, Validation Loss: 0.2162
	--> Epoch [37/100], Loss: 0.1995, Validation Loss: 0.2113
	--> Epoch [38/100], Loss: 0.1355, Validation Loss: 0.2077
	--> Epoch [39/100], Loss: 0.1152, Validation Loss: 0.2059
	--> Epoch [40/100], Loss: 0.0940, Validation Loss: 0.2041
	--> Epoch [41/100], Loss: 0.1239, Validation Loss: 0.2036
	--> Epoch [42/100], Loss: 0.1108, Validation Loss: 0.1987
	--> Epoch [43/100], Loss: 0.1427, Validation Loss: 0.1975
	--> Epoch [44/100], Loss: 0.1839, Validation Loss: 0.1966
	--> Epoch [45/100], Loss: 0.1170, Validation Loss: 0.1924
	--> Epoch [46/100], Loss: 0.1139, Validation Loss: 0.1904
	--> Epoch [47/100], Loss: 0.1151, Validation Loss: 0.1902
	--> Epoch [48/100], Loss: 0.0994, Validation Loss: 0.1886
	--> Epoch [49/100], Loss: 0.1451, Validation Loss: 0.1892
	--> Epoch [50/100], Loss: 0.1155, Validation Loss: 0.1862
	--> Epoch [51/100], Loss: 0.1121, Validation Loss: 0.1855
	--> Epoch [52/100], Loss: 0.1048, Validation Loss: 0.1815
	--> Epoch [53/100], Loss: 0.1511, Validation Loss: 0.1813
	--> Epoch [54/100], Loss: 0.1022, Validation Loss: 0.1799
	--> Epoch [55/100], Loss: 0.1500, Validation Loss: 0.1793
	--> Epoch [56/100], Loss: 0.0904, Validation Loss: 0.1792
	--> Epoch [57/100], Loss: 0.1126, Validation Loss: 0.1759
	--> Epoch [58/100], Loss: 0.0891, Validation Loss: 0.1735
	--> Epoch [59/100], Loss: 0.0945, Validation Loss: 0.1720
	--> Epoch [60/100], Loss: 0.0936, Validation Loss: 0.1708
