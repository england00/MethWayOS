[36m 
############################### DATA ACQUISITION ############################### [39m
Data has been correctly loaded from ../../config/files/dataset_paths.yaml file
Data has been correctly loaded from ../../config/files/json_paths.yaml file
Data has been correctly loaded from ../../json_dir/indexes/gene_expression_names.json file
Data has been correctly loaded from ../../data/datasets/gene_expression_and_overall_survival_dataset.csv file
DIMENSIONS:
	--> Training Set: 223
	--> Testing Set: 56
[36m 
########################### TRAINING SET MANAGEMENT ############################ [39m
[36m 
################### EXPLORATORY DATA ANALYSIS with RAW DATA #################### [39m
[36m 
############################ FEATURES PREPROCESSING ############################ [39m
ADMITTED SAMPLES VALUES:
	--> 43 samples with a label lower than 1000
	--> 52 samples with a label bigger than 3000
[36m 
############################## FEATURES SELECTION ############################## [39m
VARIANCE SELECTION:
	--> New Feature Space Dimension: 2000
CORRELATION FILTER:
	--> New Feature Space Dimension: 500
[36m 
############################ TESTING SET MANAGEMENT ############################ [39m
[36m 
################### EXPLORATORY DATA ANALYSIS with RAW DATA #################### [39m
[36m 
############################ FEATURES PREPROCESSING ############################ [39m
ADMITTED SAMPLES VALUES:
	--> 10 samples with a label lower than 1000
	--> 11 samples with a label bigger than 3000
[36m 
############################## FEATURES SELECTION ############################## [39m
TOP FEATURES SELECTION:
	--> New Feature Space Dimension: 500
[36m 
############################### SKLEARN TO TORCH ############################### [39m
[36m 
############################ HYPERPARAMETERS LISTS ############################# [39m
[36m 
################################# GRID SEARCH ################################## [39m
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.7895
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [5, 3], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8211
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8105
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7895
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8105
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7895
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7895
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7158
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8105
	--> Hidden Size: [5, 3], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7684
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.7263
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.6105
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7053
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8000
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.7579
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.6737
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.6316
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7368
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.6737
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.5684
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.6211
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.6105
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.4842
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.6000
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.5158
	--> Hidden Size: [5, 3], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.6211
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [8, 4], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7684
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [8, 4], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.7684
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7474
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7895
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.7789
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7263
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7158
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7158
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.7263
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.6947
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8000
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.6947
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.6105
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7053
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.6211
	--> Hidden Size: [8, 4], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.6211
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7789
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [10, 5], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8000
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7789
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7895
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7053
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.6632
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7158
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7368
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7895
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.7053
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.6737
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7368
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7053
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.6211
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.6421
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.6316
	--> Hidden Size: [10, 5], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.6842
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9474
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [16, 8], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8211
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8000
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8105
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8000
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8105
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7263
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7789
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.6947
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7368
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7789
	--> Hidden Size: [16, 8], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.7263
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9474
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9474
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [20, 10], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9368
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [20, 10], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8211
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8526
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8105
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7474
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7895
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.7263
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.7368
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.7263
	--> Hidden Size: [20, 10], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8000
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9368
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9263
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9368
	--> Hidden Size: [32, 16], Learning Rate: 0.01, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.9158
	--> Hidden Size: [32, 16], Learning Rate: 0.001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.9053
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 8, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8947
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8737
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 16, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8842
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8105
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 32, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8632
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.01, Dropout: 0.0, Mean Accuracy: 0.8211
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.005, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.001, Dropout: 0.0, Mean Accuracy: 0.8316
	--> Hidden Size: [32, 16], Learning Rate: 0.0001, Batch Size: 64, Alpha: 0.0001, Dropout: 0.0, Mean Accuracy: 0.8421
	--> Best value for each hyperparameter:
	--> Hidden Size: [16, 8],
	--> Learning Rate: 0.001,
	--> Batch Size: 8,
	--> Alpha: 0.01,
	--> Dropout: 0.0
	--> Best Mean Accuracy: 0.9474
[36m 
################################### TRAINING ################################### [39m

Fold 1/5
	--> Epoch [1/100], Loss: 0.8302, Validation Loss: 0.7261
	--> Epoch [2/100], Loss: 0.8697, Validation Loss: 0.6907
	--> Epoch [3/100], Loss: 0.5323, Validation Loss: 0.6491
	--> Epoch [4/100], Loss: 0.5799, Validation Loss: 0.6448
	--> Epoch [5/100], Loss: 0.5912, Validation Loss: 0.6407
	--> Epoch [6/100], Loss: 0.4087, Validation Loss: 0.6372
	--> Epoch [7/100], Loss: 0.2056, Validation Loss: 0.6369
	--> Epoch [8/100], Loss: 0.6546, Validation Loss: 0.6365
	--> Epoch [9/100], Loss: 0.5690, Validation Loss: 0.6361
	--> Epoch [10/100], Loss: 0.5627, Validation Loss: 0.6361
	--> Epoch [11/100], Loss: 0.4225, Validation Loss: 0.6361
	--> Epoch [12/100], Loss: 0.6052, Validation Loss: 0.6360
	--> Epoch [13/100], Loss: 0.5807, Validation Loss: 0.6360
	--> Epoch [14/100], Loss: 0.5163, Validation Loss: 0.6360
	--> Epoch [15/100], Loss: 0.4581, Validation Loss: 0.6360
	--> Epoch [16/100], Loss: 0.4632, Validation Loss: 0.6360
	--> Epoch [17/100], Loss: 0.4299, Validation Loss: 0.6360
	--> Epoch [18/100], Loss: 0.5617, Validation Loss: 0.6360
	--> Epoch [19/100], Loss: 0.5451, Validation Loss: 0.6360
	--> Epoch [20/100], Loss: 0.5290, Validation Loss: 0.6360
	--> Epoch [21/100], Loss: 0.4710, Validation Loss: 0.6360
	--> Epoch [22/100], Loss: 0.7825, Validation Loss: 0.6360
	--> Epoch [23/100], Loss: 0.4673, Validation Loss: 0.6360
	--> Epoch [24/100], Loss: 0.6331, Validation Loss: 0.6360
	--> Epoch [25/100], Loss: 0.5322, Validation Loss: 0.6360
Early stopping
	--> Training for Fold 1 took 0.23323512077331543 sec

Fold 2/5
	--> Epoch [1/100], Loss: 0.7276, Validation Loss: 0.6505
	--> Epoch [2/100], Loss: 0.6350, Validation Loss: 0.6300
	--> Epoch [3/100], Loss: 0.6511, Validation Loss: 0.6033
	--> Epoch [4/100], Loss: 0.5714, Validation Loss: 0.6006
	--> Epoch [5/100], Loss: 0.4914, Validation Loss: 0.5976
	--> Epoch [6/100], Loss: 0.5036, Validation Loss: 0.5945
	--> Epoch [7/100], Loss: 0.5990, Validation Loss: 0.5942
	--> Epoch [8/100], Loss: 0.4744, Validation Loss: 0.5939
	--> Epoch [9/100], Loss: 0.4343, Validation Loss: 0.5937
	--> Epoch [10/100], Loss: 0.5491, Validation Loss: 0.5936
	--> Epoch [11/100], Loss: 0.4852, Validation Loss: 0.5936
	--> Epoch [12/100], Loss: 0.4286, Validation Loss: 0.5936
	--> Epoch [13/100], Loss: 0.4979, Validation Loss: 0.5936
	--> Epoch [14/100], Loss: 0.5245, Validation Loss: 0.5936
	--> Epoch [15/100], Loss: 0.5292, Validation Loss: 0.5936
	--> Epoch [16/100], Loss: 0.5933, Validation Loss: 0.5936
	--> Epoch [17/100], Loss: 0.5900, Validation Loss: 0.5936
	--> Epoch [18/100], Loss: 0.5345, Validation Loss: 0.5936
	--> Epoch [19/100], Loss: 0.5149, Validation Loss: 0.5936
	--> Epoch [20/100], Loss: 0.4399, Validation Loss: 0.5936
	--> Epoch [21/100], Loss: 0.4785, Validation Loss: 0.5936
	--> Epoch [22/100], Loss: 0.5015, Validation Loss: 0.5936
	--> Epoch [23/100], Loss: 0.5022, Validation Loss: 0.5936
	--> Epoch [24/100], Loss: 0.4864, Validation Loss: 0.5936
	--> Epoch [25/100], Loss: 0.4866, Validation Loss: 0.5936
	--> Epoch [26/100], Loss: 0.4087, Validation Loss: 0.5936
Early stopping
	--> Training for Fold 2 took 0.24928808212280273 sec

Fold 3/5
	--> Epoch [1/100], Loss: 0.6821, Validation Loss: 0.6364
	--> Epoch [2/100], Loss: 0.5926, Validation Loss: 0.5853
	--> Epoch [3/100], Loss: 0.5380, Validation Loss: 0.5348
	--> Epoch [4/100], Loss: 0.3492, Validation Loss: 0.5288
	--> Epoch [5/100], Loss: 0.4709, Validation Loss: 0.5229
	--> Epoch [6/100], Loss: 0.4906, Validation Loss: 0.5179
	--> Epoch [7/100], Loss: 0.3831, Validation Loss: 0.5174
	--> Epoch [8/100], Loss: 0.4012, Validation Loss: 0.5168
	--> Epoch [9/100], Loss: 0.3583, Validation Loss: 0.5162
	--> Epoch [10/100], Loss: 0.4259, Validation Loss: 0.5162
	--> Epoch [11/100], Loss: 0.4354, Validation Loss: 0.5161
	--> Epoch [12/100], Loss: 0.4967, Validation Loss: 0.5161
	--> Epoch [13/100], Loss: 0.4147, Validation Loss: 0.5161
	--> Epoch [14/100], Loss: 0.3524, Validation Loss: 0.5161
	--> Epoch [15/100], Loss: 0.3173, Validation Loss: 0.5161
	--> Epoch [16/100], Loss: 0.3653, Validation Loss: 0.5161
	--> Epoch [17/100], Loss: 0.3848, Validation Loss: 0.5161
	--> Epoch [18/100], Loss: 0.4829, Validation Loss: 0.5161
	--> Epoch [19/100], Loss: 0.5175, Validation Loss: 0.5161
	--> Epoch [20/100], Loss: 0.4884, Validation Loss: 0.5161
	--> Epoch [21/100], Loss: 0.3886, Validation Loss: 0.5161
	--> Epoch [22/100], Loss: 0.3826, Validation Loss: 0.5161
	--> Epoch [23/100], Loss: 0.3707, Validation Loss: 0.5161
	--> Epoch [24/100], Loss: 0.5463, Validation Loss: 0.5161
Early stopping
	--> Training for Fold 3 took 0.2246241569519043 sec

Fold 4/5
	--> Epoch [1/100], Loss: 0.7116, Validation Loss: 0.6571
	--> Epoch [2/100], Loss: 0.6288, Validation Loss: 0.6293
	--> Epoch [3/100], Loss: 0.7298, Validation Loss: 0.5954
	--> Epoch [4/100], Loss: 0.3433, Validation Loss: 0.5917
	--> Epoch [5/100], Loss: 0.5010, Validation Loss: 0.5887
	--> Epoch [6/100], Loss: 0.2624, Validation Loss: 0.5856
	--> Epoch [7/100], Loss: 0.4370, Validation Loss: 0.5853
	--> Epoch [8/100], Loss: 0.4687, Validation Loss: 0.5849
	--> Epoch [9/100], Loss: 0.4684, Validation Loss: 0.5846
	--> Epoch [10/100], Loss: 0.4745, Validation Loss: 0.5846
	--> Epoch [11/100], Loss: 0.4848, Validation Loss: 0.5846
	--> Epoch [12/100], Loss: 0.4383, Validation Loss: 0.5845
	--> Epoch [13/100], Loss: 0.5519, Validation Loss: 0.5845
	--> Epoch [14/100], Loss: 0.5276, Validation Loss: 0.5845
	--> Epoch [15/100], Loss: 0.6200, Validation Loss: 0.5845
	--> Epoch [16/100], Loss: 0.4493, Validation Loss: 0.5845
	--> Epoch [17/100], Loss: 0.4237, Validation Loss: 0.5845
	--> Epoch [18/100], Loss: 0.6094, Validation Loss: 0.5845
	--> Epoch [19/100], Loss: 0.4743, Validation Loss: 0.5845
	--> Epoch [20/100], Loss: 0.6121, Validation Loss: 0.5845
	--> Epoch [21/100], Loss: 0.2791, Validation Loss: 0.5845
	--> Epoch [22/100], Loss: 0.2912, Validation Loss: 0.5845
	--> Epoch [23/100], Loss: 0.5707, Validation Loss: 0.5845
	--> Epoch [24/100], Loss: 0.4065, Validation Loss: 0.5845
	--> Epoch [25/100], Loss: 0.4289, Validation Loss: 0.5845
	--> Epoch [26/100], Loss: 0.3591, Validation Loss: 0.5845
Early stopping
	--> Training for Fold 4 took 0.2470533847808838 sec

Fold 5/5
	--> Epoch [1/100], Loss: 0.6465, Validation Loss: 0.6517
	--> Epoch [2/100], Loss: 0.6029, Validation Loss: 0.6015
	--> Epoch [3/100], Loss: 0.4988, Validation Loss: 0.5476
	--> Epoch [4/100], Loss: 0.4258, Validation Loss: 0.5423
	--> Epoch [5/100], Loss: 0.3306, Validation Loss: 0.5369
	--> Epoch [6/100], Loss: 0.4444, Validation Loss: 0.5324
	--> Epoch [7/100], Loss: 0.2982, Validation Loss: 0.5319
	--> Epoch [8/100], Loss: 0.3976, Validation Loss: 0.5314
	--> Epoch [9/100], Loss: 0.4604, Validation Loss: 0.5309
	--> Epoch [10/100], Loss: 0.4138, Validation Loss: 0.5309
	--> Epoch [11/100], Loss: 0.4974, Validation Loss: 0.5308
	--> Epoch [12/100], Loss: 0.3241, Validation Loss: 0.5308
	--> Epoch [13/100], Loss: 0.4718, Validation Loss: 0.5307
	--> Epoch [14/100], Loss: 0.3536, Validation Loss: 0.5307
	--> Epoch [15/100], Loss: 0.4294, Validation Loss: 0.5307
	--> Epoch [16/100], Loss: 0.3905, Validation Loss: 0.5307
	--> Epoch [17/100], Loss: 0.4622, Validation Loss: 0.5307
	--> Epoch [18/100], Loss: 0.4897, Validation Loss: 0.5307
	--> Epoch [19/100], Loss: 0.2111, Validation Loss: 0.5307
	--> Epoch [20/100], Loss: 0.3825, Validation Loss: 0.5307
	--> Epoch [21/100], Loss: 0.3716, Validation Loss: 0.5307
	--> Epoch [22/100], Loss: 0.4380, Validation Loss: 0.5307
	--> Epoch [23/100], Loss: 0.4758, Validation Loss: 0.5307
	--> Epoch [24/100], Loss: 0.3407, Validation Loss: 0.5307
	--> Epoch [25/100], Loss: 0.4304, Validation Loss: 0.5307
	--> Epoch [26/100], Loss: 0.4316, Validation Loss: 0.5307
Early stopping
	--> Training for Fold 5 took 0.24805951118469238 sec

Best validation loss across all folds: 0.5161
[36m 
################################### TESTING #################################### [39m
	--> Testing took 0.00025177001953125 sec
	--> Final Accuracy: 0.4762
